From dev-return-9646-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 06:01:13 2014
Return-Path: <dev-return-9646-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D7CD617B44
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 06:01:13 +0000 (UTC)
Received: (qmail 71772 invoked by uid 500); 1 Oct 2014 06:01:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71702 invoked by uid 500); 1 Oct 2014 06:01:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71686 invoked by uid 99); 1 Oct 2014 06:01:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 06:01:12 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of myasuka@live.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 06:01:08 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <myasuka@live.com>)
	id 1XZCxz-00038o-Eb
	for dev@spark.incubator.apache.org; Tue, 30 Sep 2014 23:00:47 -0700
Date: Tue, 30 Sep 2014 23:00:47 -0700 (PDT)
From: myasuka <myasuka@live.com>
To: dev@spark.incubator.apache.org
Message-ID: <1412143247437-8616.post@n3.nabble.com>
In-Reply-To: <25F1FC13-A56B-46CB-B299-6277CE06C60E@gmail.com>
References: <1411898355683-8583.post@n3.nabble.com> <D586FA82-26EC-42EA-B02F-BC5EA3F071F9@gmail.com> <1411995991265-8594.post@n3.nabble.com> <25F1FC13-A56B-46CB-B299-6277CE06C60E@gmail.com>
Subject: Re: How to use multi thread in RDD map function ?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Thank for your advise, I have tried your recommended configuration, but 

SPARK_WORKER_CORES=32
SPARK_WORKER_INSTANCES=1

still work better, in the offical spark-standalone, about the parameter
'SPARK_WORKER_INSTANCES' /You can make this more than 1 if you have have
very large machines and would like multiple Spark worker processes./ Maybe
our 16 nodes cluster with 16cores, 24GB memory is not fit for more than 1
worker instance.

Yi Tian wrote
> Hi, myasuka
> 
> Have you checked the jvm gc time of each executor? 
> 
> I think you should increase the SPARK_EXECUTOR_CORES or
> SPARK_EXECUTOR_INSTANCES until you get the enough concurrency.
> 
> Here is my recommend config:
> 
> SPARK_EXECUTOR_CORES=8
> SPARK_EXECUTOR_INSTANCES=4
> SPARK_WORKER_MEMORY=8G
> 
> note: make sure you got enough memory on each node, more than
> SPARK_EXECUTOR_INSTANCES * SPARK_WORKER_MEMORY
> 
> Best Regards,
> 
> Yi Tian

> tianyi.asiainfo@

> 
> 
> 
> 
> On Sep 29, 2014, at 21:06, myasuka &lt;

> myasuka@

> &gt; wrote:
> 
>> Our cluster is a standalone cluster with 16 computing nodes, each node
>> has 16
>> cores. I set SPARK_WORKER_INSTANCES to 1, and set SPARK_WORKER_CORES to
>> 32,
>> we give 512 tasks all together, this situation can help increase the
>> concurrency. But if I  set SPARK_WORKER_INSTANCES to 2,
>> SPARK_WORKER_CORES
>> to 16, this dosen't work well.
>> 
>> Thank you for your reply.
>> 
>> 
>> Yi Tian wrote
>>> for yarn-client mode:
>>> 
>>> SPARK_EXECUTOR_CORES * SPARK_EXECUTOR_INSTANCES = 2(or 3) *
>>> TotalCoresOnYourCluster
>>> 
>>> for standlone mode:
>>> 
>>> SPARK_WORKER_INSTANCES * SPARK_WORKER_CORES = 2(or 3) *
>>> TotalCoresOnYourCluster
>>> 
>>> 
>>> 
>>> Best Regards,
>>> 
>>> Yi Tian
>> 
>>> tianyi.asiainfo@
>> 
>>> 
>>> 
>>> 
>>> 
>>> On Sep 28, 2014, at 17:59, myasuka &lt;
>> 
>>> myasuka@
>> 
>>> &gt; wrote:
>>> 
>>>> Hi, everyone
>>>>   I come across with a problem about increasing the concurency. In a
>>>> program, after shuffle write, each node should fetch 16 pair matrices
>>>> to
>>>> do
>>>> matrix multiplication. such as:
>>>> 
>>>> *import breeze.linalg.{DenseMatrix => BDM}
>>>> 
>>>> pairs.map(t => {
>>>>       val b1 = t._2._1.asInstanceOf[BDM[Double]]
>>>>       val b2 = t._2._2.asInstanceOf[BDM[Double]]
>>>> 
>>>>       val c = (b1 * b2).asInstanceOf[BDM[Double]]
>>>> 
>>>>       (new BlockID(t._1.row, t._1.column), c)
>>>>     })*
>>>> 
>>>>   Each node has 16 cores. However, no matter I set 16 tasks or more on
>>>> each node, the concurrency cannot be higher than 60%, which means not
>>>> every
>>>> core on the node is computing. Then I check the running log on the
>>>> WebUI,
>>>> according to the amount of shuffle read and write in every task, I see
>>>> some
>>>> task do once matrix multiplication, some do twice while some do none.
>>>> 
>>>>   Thus, I think of using java multi thread to increase the concurrency.
>>>> I
>>>> wrote a program in scala which calls java multi thread without Spark on
>>>> a
>>>> single node, by watch the 'top' monitor, I find this program can use
>>>> CPU
>>>> up
>>>> to 1500% ( means nearly every core are computing). But I have no idea
>>>> how
>>>> to
>>>> use Java multi thread in RDD transformation.
>>>> 
>>>>   Is there any one can provide some example code to use Java multi
>>>> thread
>>>> in RDD transformation, or give any idea to increase the concurrency ?
>>>> 
>>>> Thanks for all
>>>> 
>>>> 
>>>> 
>>>> 
>>>> --
>>>> View this message in context:
>>>> http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi-thread-in-RDD-map-function-tp8583.html
>>>> Sent from the Apache Spark Developers List mailing list archive at
>>>> Nabble.com.
>>>> 
>>>> ---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: 
>> 
>>> dev-unsubscribe@.apache
>> 
>>>> For additional commands, e-mail: 
>> 
>>> dev-help@.apache
>> 
>>>> 
>> 
>> 
>> 
>> 
>> 
>> --
>> View this message in context:
>> http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi-thread-in-RDD-map-function-tp8583p8594.html
>> Sent from the Apache Spark Developers List mailing list archive at
>> Nabble.com.
>> 
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: 

> dev-unsubscribe@.apache

>> For additional commands, e-mail: 

> dev-help@.apache





--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/How-to-use-multi-thread-in-RDD-map-function-tp8583p8616.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9647-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 09:25:39 2014
Return-Path: <dev-return-9647-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F3650172A7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 09:25:38 +0000 (UTC)
Received: (qmail 36927 invoked by uid 500); 1 Oct 2014 09:25:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36847 invoked by uid 500); 1 Oct 2014 09:25:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36826 invoked by uid 99); 1 Oct 2014 09:25:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 09:25:37 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.46] (HELO mail-qa0-f46.google.com) (209.85.216.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 09:25:34 +0000
Received: by mail-qa0-f46.google.com with SMTP id w8so218371qac.19
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 02:25:13 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:sender:in-reply-to
         :references:date:message-id:subject:from:to:cc:content-type;
        bh=DXzTQzHic2UBVMCEYXwO0+axc6WriPg6Eew5RaQzlvs=;
        b=JlJQWYf5icmfphvxmxwaXxlXh8nR/SU0S4o9vV13TgYIwvit5VccmaACjNKzArF+hX
         reisvAYqjIQd78pTiAiOaumkEtB9aQObjNbTVX7s/ZT0DC+3L08s9Hnsvdu3v64IFmUk
         jb86PNVRZvoQTdM82tUviCgF6M74oVsbFPp4XUaSCudCgkkA/2F3si3wiQ0w2aBnz8wZ
         8uNCR5uElixb1xmlRFhuWSikMqwzxILPjx7651V5sXhGlPG9EJDX/upBp9srw1gxA7AZ
         RgCbp+vph6Em5H1gaS767njtAqrfaV3dVXrnZJkS5Wwe/BDh7nTnPecd6UPFq1FUkEp+
         Xg6A==
X-Gm-Message-State: ALoCoQnZea17f8JaafwWyDwbaXYNlevLX/Z5A/SEoPSXknr6BHMCjeQnqBJAYrZSPHY8RcurV8p7
MIME-Version: 1.0
X-Received: by 10.224.3.10 with SMTP id 10mr68097100qal.70.1412155512107; Wed,
 01 Oct 2014 02:25:12 -0700 (PDT)
Reply-To: dbtsai@dbtsai.com
Sender: dbtsai@dbtsai.com
Received: by 10.229.12.73 with HTTP; Wed, 1 Oct 2014 02:25:12 -0700 (PDT)
In-Reply-To: <CAAswR-719W4rme+tj02YStY0CthxY1K+cYid6jzaWYKv87B_Cw@mail.gmail.com>
References: <CAKWX9VUHMuVxguD_=1k0h_zP5F50QZ4MVc_8bQ8SyD8HmhyOow@mail.gmail.com>
	<CAAswR-5OnpYG+9b0hmx6cvFvv0WHDCqy6R-V4KNEb4yoEnUPYg@mail.gmail.com>
	<CAKWX9VWA0Bk9uhLBqyisBcKcto5uWPxv0+UewCAk_YwW6g5Qag@mail.gmail.com>
	<CAAswR-7VFM22XYp-T7Anm5abTjXQXgYfTnyjYsHA1vM-d_QOZg@mail.gmail.com>
	<CAGOvqiqycwEmMiC1ckqdTuEB-f5=rLZti+=+frHZ0aG4O27vsw@mail.gmail.com>
	<CAAswR-6ePBExtS8CobsLaaCUOCw-Pi5X=M8bMsaEHTiwKcu24g@mail.gmail.com>
	<CAKWX9VX3R7qXWKqvRii33J9O6kHwREWxSqJB-VEKaWdv_Nxk7w@mail.gmail.com>
	<CABPQxsvUeOpu0CzxwnsOgne4TcYbv-+KfHcb7tjHDMgVu9ygVQ@mail.gmail.com>
	<CAAswR-79Q82dqYn1DvbuY=-Eyh3=bpu3thWAZW99EX-Vx97XuA@mail.gmail.com>
	<CAKWX9VXY3acp0c8UCdUA53ax-ERPRm88-Ah7VH=izomYrOePeg@mail.gmail.com>
	<CAKWX9VU1i_RHiPfqZ719qM66zvKTVeGYp+67SRvmw8uNhUu1AQ@mail.gmail.com>
	<CAKWX9VX9=ig211dkUrJqvF9hJ+HBMAyX3GQV_qx_RUXt4FJkJg@mail.gmail.com>
	<CAAswR-5LKtMAUxqusHAe-Tz1xgfhWp0kzKymkFFSEw2Y5TzH-g@mail.gmail.com>
	<CAKWX9VUEoa6J_ZCNPMttge0nucMjesxmVpvjQGYxx3+zOYjirw@mail.gmail.com>
	<CAAswR-719W4rme+tj02YStY0CthxY1K+cYid6jzaWYKv87B_Cw@mail.gmail.com>
Date: Wed, 1 Oct 2014 11:25:12 +0200
X-Google-Sender-Auth: 46WB71qtT-I5vTB9Kd-uL03yQik
Message-ID: <CAEYYnxYpH9A==N9pDYOq6RappX0U1ddyik-hZcitkGe-pv3X0Q@mail.gmail.com>
Subject: Re: parquet predicate / projection pushdown into unionAll
From: DB Tsai <dbtsai@dbtsai.com>
To: Michael Armbrust <michael@databricks.com>
Cc: Cody Koeninger <cody@koeninger.org>, Patrick Wendell <pwendell@gmail.com>, 
	Gary Malouf <malouf.gary@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	Xiangrui Meng <mengxr@gmail.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Cody and Michael,

We ran into the same issue. Each day of data we have is stored into
one parquet, and we want to query it against monthly parquet data. The
data for each data is around 600GB, and we use 300 executors with 8GB
memory for each executor. Without the patch, it took forever, and
crashed in the end.

With patch, for table obtained by unionAll with 5 parquets (around
3TB), it takes 199.126 seconds to execute a simple HIVE query, while
it takes 64.36 seconds for individual parquet file. Great work, this
patch solves the issue. Hopefully to see this in next 1.1 series.

Thanks.

Sincerely,

DB Tsai
-------------------------------------------------------
My Blog: https://www.dbtsai.com
LinkedIn: https://www.linkedin.com/in/dbtsai


On Fri, Sep 12, 2014 at 9:07 PM, Michael Armbrust
<michael@databricks.com> wrote:
> Yeah, thanks for implementing it!
>
> Since Spark SQL is an alpha component and moving quickly the plan is to
> backport all of master into the next point release in the 1.1 series.
>
> On Fri, Sep 12, 2014 at 9:27 AM, Cody Koeninger <cody@koeninger.org> wrote:
>
>> Cool, thanks for your help on this.  Any chance of adding it to the 1.1.1
>> point release, assuming there ends up being one?
>>
>> On Wed, Sep 10, 2014 at 11:39 AM, Michael Armbrust <michael@databricks.com
>> > wrote:
>>
>>> Hey Cody,
>>>
>>> Thanks for doing this!  Will look at your PR later today.
>>>
>>> Michael
>>>
>>> On Wed, Sep 10, 2014 at 9:31 AM, Cody Koeninger <cody@koeninger.org>
>>> wrote:
>>>
>>>> Tested the patch against a cluster with some real data.  Initial results
>>>> seem like going from one table to a union of 2 tables is now closer to a
>>>> doubling of query time as expected, instead of 5 to 10x.
>>>>
>>>> Let me know if you see any issues with that PR.
>>>>
>>>> On Wed, Sep 10, 2014 at 8:19 AM, Cody Koeninger <cody@koeninger.org>
>>>> wrote:
>>>>
>>>>> So the obvious thing I was missing is that the analyzer has already
>>>>> resolved attributes by the time the optimizer runs, so the references in
>>>>> the filter / projection need to be fixed up to match the children.
>>>>>
>>>>> Created a PR, let me know if there's a better way to do it.  I'll see
>>>>> about testing performance against some actual data sets.
>>>>>
>>>>> On Tue, Sep 9, 2014 at 6:09 PM, Cody Koeninger <cody@koeninger.org>
>>>>> wrote:
>>>>>
>>>>>> Ok, so looking at the optimizer code for the first time and trying the
>>>>>> simplest rule that could possibly work,
>>>>>>
>>>>>> object UnionPushdown extends Rule[LogicalPlan] {
>>>>>>   def apply(plan: LogicalPlan): LogicalPlan = plan transform {
>>>>>>     // Push down filter into
>>>>>> union
>>>>>>     case f @ Filter(condition, u @ Union(left, right)) =>
>>>>>>
>>>>>>       u.copy(left = f.copy(child = left), right = f.copy(child =
>>>>>> right))
>>>>>>
>>>>>>
>>>>>>     // Push down projection into
>>>>>> union
>>>>>>     case p @ Project(projectList, u @ Union(left, right)) =>
>>>>>>       u.copy(left = p.copy(child = left), right = p.copy(child =
>>>>>> right))
>>>>>>
>>>>>> }
>>>>>>
>>>>>> }
>>>>>>
>>>>>>
>>>>>> If I try manually applying that rule to a logical plan in the repl, it
>>>>>> produces the query shape I'd expect, and executing that plan results in
>>>>>> parquet pushdowns as I'd expect.
>>>>>>
>>>>>> But adding those cases to ColumnPruning results in a runtime exception
>>>>>> (below)
>>>>>>
>>>>>> I can keep digging, but it seems like I'm missing some obvious initial
>>>>>> context around naming of attributes.  If you can provide any pointers to
>>>>>> speed me on my way I'd appreciate it.
>>>>>>
>>>>>>
>>>>>> java.lang.AssertionError: assertion failed: ArrayBuffer() +
>>>>>> ArrayBuffer() != WrappedArray(name#6, age#7), List(name#9, age#10,
>>>>>> phones#11)
>>>>>>         at scala.Predef$.assert(Predef.scala:179)
>>>>>>         at
>>>>>> org.apache.spark.sql.parquet.ParquetTableScan.<init>(ParquetTableOperations.scala:75)
>>>>>>         at
>>>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>>>>>         at
>>>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$$anonfun$9.apply(SparkStrategies.scala:234)
>>>>>>         at
>>>>>> org.apache.spark.sql.SQLContext$SparkPlanner.pruneFilterProject(SQLContext.scala:367)
>>>>>>         at
>>>>>> org.apache.spark.sql.execution.SparkStrategies$ParquetOperations$.apply(SparkStrategies.scala:230)
>>>>>>         at
>>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>>>         at
>>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>>>         at
>>>>>> scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>>>>>         at
>>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>>>>>         at
>>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.planLater(QueryPlanner.scala:54)
>>>>>>         at
>>>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>>>>>         at
>>>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$$anonfun$12.apply(SparkStrategies.scala:282)
>>>>>>         at
>>>>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>>>>         at
>>>>>> scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
>>>>>>         at scala.collection.immutable.List.foreach(List.scala:318)
>>>>>>         at
>>>>>> scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
>>>>>>         at
>>>>>> scala.collection.AbstractTraversable.map(Traversable.scala:105)
>>>>>>         at
>>>>>> org.apache.spark.sql.execution.SparkStrategies$BasicOperators$.apply(SparkStrategies.scala:282)
>>>>>>         at
>>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>>>         at
>>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
>>>>>>         at
>>>>>> scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
>>>>>>         at
>>>>>> org.apache.spark.sql.catalyst.planning.QueryPlanner.apply(QueryPlanner.scala:59)
>>>>>>         at
>>>>>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:402)
>>>>>>         at
>>>>>> org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:400)
>>>>>>         at
>>>>>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:406)
>>>>>>         at
>>>>>> org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:406)
>>>>>>         at
>>>>>> org.apache.spark.sql.SQLContext$QueryExecution.toString(SQLContext.scala:431)
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Tue, Sep 9, 2014 at 3:02 PM, Michael Armbrust <
>>>>>> michael@databricks.com> wrote:
>>>>>>
>>>>>>> What Patrick said is correct.  Two other points:
>>>>>>>  - In the 1.2 release we are hoping to beef up the support for
>>>>>>> working with partitioned parquet independent of the metastore.
>>>>>>>  - You can actually do operations like INSERT INTO for parquet tables
>>>>>>> to add data.  This creates new parquet files for each insertion.  This will
>>>>>>> break if there are multiple concurrent writers to the same table.
>>>>>>>
>>>>>>> On Tue, Sep 9, 2014 at 12:09 PM, Patrick Wendell <pwendell@gmail.com>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> I think what Michael means is people often use this to read existing
>>>>>>>> partitioned Parquet tables that are defined in a Hive metastore
>>>>>>>> rather
>>>>>>>> than data generated directly from within Spark and then reading it
>>>>>>>> back as a table. I'd expect the latter case to become more common,
>>>>>>>> but
>>>>>>>> for now most users connect to an existing metastore.
>>>>>>>>
>>>>>>>> I think you could go this route by creating a partitioned external
>>>>>>>> table based on the on-disk layout you create. The downside is that
>>>>>>>> you'd have to go through a hive metastore whereas what you are doing
>>>>>>>> now doesn't need hive at all.
>>>>>>>>
>>>>>>>> We should also just fix the case you are mentioning where a union is
>>>>>>>> used directly from within spark. But that's the context.
>>>>>>>>
>>>>>>>> - Patrick
>>>>>>>>
>>>>>>>> On Tue, Sep 9, 2014 at 12:01 PM, Cody Koeninger <cody@koeninger.org>
>>>>>>>> wrote:
>>>>>>>> > Maybe I'm missing something, I thought parquet was generally a
>>>>>>>> write-once
>>>>>>>> > format and the sqlContext interface to it seems that way as well.
>>>>>>>> >
>>>>>>>> > d1.saveAsParquetFile("/foo/d1")
>>>>>>>> >
>>>>>>>> > // another day, another table, with same schema
>>>>>>>> > d2.saveAsParquetFile("/foo/d2")
>>>>>>>> >
>>>>>>>> > Will give a directory structure like
>>>>>>>> >
>>>>>>>> > /foo/d1/_metadata
>>>>>>>> > /foo/d1/part-r-1.parquet
>>>>>>>> > /foo/d1/part-r-2.parquet
>>>>>>>> > /foo/d1/_SUCCESS
>>>>>>>> >
>>>>>>>> > /foo/d2/_metadata
>>>>>>>> > /foo/d2/part-r-1.parquet
>>>>>>>> > /foo/d2/part-r-2.parquet
>>>>>>>> > /foo/d2/_SUCCESS
>>>>>>>> >
>>>>>>>> > // ParquetFileReader will fail, because /foo/d1 is a directory,
>>>>>>>> not a
>>>>>>>> > parquet partition
>>>>>>>> > sqlContext.parquetFile("/foo")
>>>>>>>> >
>>>>>>>> > // works, but has the noted lack of pushdown
>>>>>>>> >
>>>>>>>> sqlContext.parquetFile("/foo/d1").unionAll(sqlContext.parquetFile("/foo/d2"))
>>>>>>>> >
>>>>>>>> >
>>>>>>>> > Is there another alternative?
>>>>>>>> >
>>>>>>>> >
>>>>>>>> >
>>>>>>>> > On Tue, Sep 9, 2014 at 1:29 PM, Michael Armbrust <
>>>>>>>> michael@databricks.com>
>>>>>>>> > wrote:
>>>>>>>> >
>>>>>>>> >> I think usually people add these directories as multiple
>>>>>>>> partitions of the
>>>>>>>> >> same table instead of union.  This actually allows us to
>>>>>>>> efficiently prune
>>>>>>>> >> directories when reading in addition to standard column pruning.
>>>>>>>> >>
>>>>>>>> >> On Tue, Sep 9, 2014 at 11:26 AM, Gary Malouf <
>>>>>>>> malouf.gary@gmail.com>
>>>>>>>> >> wrote:
>>>>>>>> >>
>>>>>>>> >>> I'm kind of surprised this was not run into before.  Do people
>>>>>>>> not
>>>>>>>> >>> segregate their data by day/week in the HDFS directory structure?
>>>>>>>> >>>
>>>>>>>> >>>
>>>>>>>> >>> On Tue, Sep 9, 2014 at 2:08 PM, Michael Armbrust <
>>>>>>>> michael@databricks.com>
>>>>>>>> >>> wrote:
>>>>>>>> >>>
>>>>>>>> >>>> Thanks!
>>>>>>>> >>>>
>>>>>>>> >>>> On Tue, Sep 9, 2014 at 11:07 AM, Cody Koeninger <
>>>>>>>> cody@koeninger.org>
>>>>>>>> >>>> wrote:
>>>>>>>> >>>>
>>>>>>>> >>>> > Opened
>>>>>>>> >>>> >
>>>>>>>> >>>> > https://issues.apache.org/jira/browse/SPARK-3462
>>>>>>>> >>>> >
>>>>>>>> >>>> > I'll take a look at ColumnPruning and see what I can do
>>>>>>>> >>>> >
>>>>>>>> >>>> > On Tue, Sep 9, 2014 at 12:46 PM, Michael Armbrust <
>>>>>>>> >>>> michael@databricks.com>
>>>>>>>> >>>> > wrote:
>>>>>>>> >>>> >
>>>>>>>> >>>> >> On Tue, Sep 9, 2014 at 10:17 AM, Cody Koeninger <
>>>>>>>> cody@koeninger.org>
>>>>>>>> >>>> >> wrote:
>>>>>>>> >>>> >>>
>>>>>>>> >>>> >>> Is there a reason in general not to push projections and
>>>>>>>> predicates
>>>>>>>> >>>> down
>>>>>>>> >>>> >>> into the individual ParquetTableScans in a union?
>>>>>>>> >>>> >>>
>>>>>>>> >>>> >>
>>>>>>>> >>>> >> This would be a great case to add to ColumnPruning.  Would
>>>>>>>> be awesome
>>>>>>>> >>>> if
>>>>>>>> >>>> >> you could open a JIRA or even a PR :)
>>>>>>>> >>>> >>
>>>>>>>> >>>> >
>>>>>>>> >>>> >
>>>>>>>> >>>>
>>>>>>>> >>>
>>>>>>>> >>>
>>>>>>>> >>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9648-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 14:14:53 2014
Return-Path: <dev-return-9648-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BEE2D17B10
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 14:14:53 +0000 (UTC)
Received: (qmail 11568 invoked by uid 500); 1 Oct 2014 14:14:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11495 invoked by uid 500); 1 Oct 2014 14:14:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11454 invoked by uid 99); 1 Oct 2014 14:14:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 14:14:52 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.47 as permitted sender)
Received: from [209.85.215.47] (HELO mail-la0-f47.google.com) (209.85.215.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 14:14:27 +0000
Received: by mail-la0-f47.google.com with SMTP id pv20so433076lab.34
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 07:14:25 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=dQCksrh7dOZHE2IoTikVnufmGov4dtaJF7za0McjaQk=;
        b=SeDS0BpYVETk9rf7lyysNoRB1P27bUXvidqCkr7NgbQm8w4/uwnWm02RXWpFQ0rqFL
         wAn/zzGsovvI7VnM18qnZMFW6BjbV7pLa/sgEJjaqXITM7ZeBMfmS+FbfIvJ7GEPlfg0
         TGtA2D9R5oySdyOufqil4q3KXJ5hB5Z1cn4jmqH2yMiJ/DzTmaYuh2OKlbYR6FoAUi0w
         zjqKz8wfv/Osv56UB0c+QulHgOLH14Z12jo0JiynC9j8WrQoDkvzQgsWZj5TgCZvnEYb
         axbJZebXj+Wl21mJmDz4yZbn8LJhj4mbRG7Nj5HaLtqNHXnvs0kEqPH4FGQ0sOtfB3SB
         rTWQ==
X-Gm-Message-State: ALoCoQlzF+XmzDao+VJFf+CfFaGye4nU8uZr0pBSJc69FH3n620mDTcCbTTYCUQf3LHE37TGj0Th
X-Received: by 10.152.25.129 with SMTP id c1mr56816354lag.14.1412172865709;
 Wed, 01 Oct 2014 07:14:25 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Wed, 1 Oct 2014 07:14:05 -0700 (PDT)
In-Reply-To: <CACdU-dSK1K8VHvg25GJ4sEfBbUDB95aRG_gZuohTezmZbchDpg@mail.gmail.com>
References: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
 <CACdU-dSK1K8VHvg25GJ4sEfBbUDB95aRG_gZuohTezmZbchDpg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 1 Oct 2014 07:14:05 -0700
Message-ID: <CACdU-dQCtHmms99jLQE-eXiLvnEP5WCv6e8zdjZXYOWp5EyqSQ@mail.gmail.com>
Subject: Re: jenkins downtime/system upgrade wednesday morning, 730am PDT
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160bcb405b2d305045d1efe
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160bcb405b2d305045d1efe
Content-Type: text/plain; charset=UTF-8

jenkins is currently in quiet mode, and will be restarted once the current
crop of builds finishes.

On Tue, Sep 30, 2014 at 2:40 PM, shane knapp <sknapp@berkeley.edu> wrote:

> reminder:  this is happening tomorrow morning.  i will be putting jenkins
> in to quiet mode at ~7am, and then doing the upgrade once any stray builds
> finish.
>
> On Mon, Sep 29, 2014 at 1:43 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> happy monday, everyone!
>>
>> remember a few weeks back when i upgraded jenkins, and unwittingly began
>> DOSing our system due to massive log spam?
>>
>> well, that bug has been fixed w/the current release and i'd like to get
>> our logging levels back to something more verbose that we have now.
>>
>> downtime will be from 730am-1000am PDT (i do expect this to be done well
>> before 1000am)
>>
>> the update will be from 1.578 -> 1.582
>>
>> changelog here:  http://jenkins-ci.org/changelog
>>
>> please let me know if there are any questions or concerns.  thanks!
>>
>> shane, your friendly devops engineer
>>
>
>

--089e0160bcb405b2d305045d1efe--

From dev-return-9649-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 14:55:18 2014
Return-Path: <dev-return-9649-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E668717C7D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 14:55:17 +0000 (UTC)
Received: (qmail 11965 invoked by uid 500); 1 Oct 2014 14:55:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11891 invoked by uid 500); 1 Oct 2014 14:55:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11879 invoked by uid 99); 1 Oct 2014 14:55:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 14:55:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 14:55:12 +0000
Received: by mail-la0-f54.google.com with SMTP id gm9so531482lab.13
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 07:54:51 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=YQlPKM6NncjW+Rhy0ij3W+eB/ggH94hgu80SQdjUcM4=;
        b=f0Qy0IKpCJNWnT2a+66P7WnOA9Pw1nMBPggmUtqGRuam42MIM4hYT2G/7ebma//HIM
         XfpJp8bcoT6FE8s0qMGIFevkCNCLioC9ADcX8fPE8Ix2uv2eOqC8TlTV4XNuarP8w1iV
         AnbYTzcDxIYI0FU7pJxvYzZXClBdpEELN+ci2uJpYWg2Tcs9KovBniPuQ23tRM++Z4C+
         lUzqOM94hSQB/egBoOtfGwLruZXjGNOaBZFsLXHiXxykZhOTNE46oaTdC9M0tLfMb464
         SiOCetXJLyG15An8833nnuxxisK/kuoCqsG6oHjOYxzDm5BvEROLP3PN8WVMd3Apgmvg
         TaTw==
X-Gm-Message-State: ALoCoQlEqIljYAvQmtqPOFVY8O4EvmPEkMIxaYOwhatRvzf54NJxAkiliifogYzzSZjmCdBbKsJx
X-Received: by 10.112.184.161 with SMTP id ev1mr51189267lbc.82.1412175291149;
 Wed, 01 Oct 2014 07:54:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Wed, 1 Oct 2014 07:54:31 -0700 (PDT)
In-Reply-To: <CACdU-dQCtHmms99jLQE-eXiLvnEP5WCv6e8zdjZXYOWp5EyqSQ@mail.gmail.com>
References: <CACdU-dTTwMbtBpWwuK6wWPiaXxav-HdVoO1VVV9Hy2VtE=C2Lg@mail.gmail.com>
 <CACdU-dSK1K8VHvg25GJ4sEfBbUDB95aRG_gZuohTezmZbchDpg@mail.gmail.com> <CACdU-dQCtHmms99jLQE-eXiLvnEP5WCv6e8zdjZXYOWp5EyqSQ@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 1 Oct 2014 07:54:31 -0700
Message-ID: <CACdU-dSv6n_5aX42V9_FxZYiqkKuStATKsehzjOCtXoDj-9sbQ@mail.gmail.com>
Subject: Re: jenkins downtime/system upgrade wednesday morning, 730am PDT
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c31d0e96fa4b05045daebf
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c31d0e96fa4b05045daebf
Content-Type: text/plain; charset=UTF-8

upgrade complete!  we're back online and happily building.

On Wed, Oct 1, 2014 at 7:14 AM, shane knapp <sknapp@berkeley.edu> wrote:

> jenkins is currently in quiet mode, and will be restarted once the current
> crop of builds finishes.
>
> On Tue, Sep 30, 2014 at 2:40 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> reminder:  this is happening tomorrow morning.  i will be putting jenkins
>> in to quiet mode at ~7am, and then doing the upgrade once any stray builds
>> finish.
>>
>> On Mon, Sep 29, 2014 at 1:43 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> happy monday, everyone!
>>>
>>> remember a few weeks back when i upgraded jenkins, and unwittingly began
>>> DOSing our system due to massive log spam?
>>>
>>> well, that bug has been fixed w/the current release and i'd like to get
>>> our logging levels back to something more verbose that we have now.
>>>
>>> downtime will be from 730am-1000am PDT (i do expect this to be done well
>>> before 1000am)
>>>
>>> the update will be from 1.578 -> 1.582
>>>
>>> changelog here:  http://jenkins-ci.org/changelog
>>>
>>> please let me know if there are any questions or concerns.  thanks!
>>>
>>> shane, your friendly devops engineer
>>>
>>
>>
>

--001a11c31d0e96fa4b05045daebf--

From dev-return-9650-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 19:54:10 2014
Return-Path: <dev-return-9650-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 47D0017CDE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 19:54:10 +0000 (UTC)
Received: (qmail 64814 invoked by uid 500); 1 Oct 2014 19:54:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64739 invoked by uid 500); 1 Oct 2014 19:54:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 64726 invoked by uid 99); 1 Oct 2014 19:54:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 19:54:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.41 as permitted sender)
Received: from [74.125.82.41] (HELO mail-wg0-f41.google.com) (74.125.82.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 19:54:05 +0000
Received: by mail-wg0-f41.google.com with SMTP id b13so1462541wgh.24
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 12:53:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=B+BtBNQSBSD4nqrVxo0j2HXpssDJgukzjRPKT8CA6oo=;
        b=Z3LYZOdBw9GmG7sJZ4t8XA7/E0OTpN06M1blAO5ggYvrw+OT9hhcukwFpPhJpg16qD
         RDjtMBqq+sfwr4RLqshqdvzlI9I7szp0Yx9P1ephjIOaNwpK4TpWqe6UBx9yTTYBxHET
         oEPTYRNnxYbu0h0ILKnj9frArY/vSoObKnMUiZT4ztnb+C+eMF3/Pz/K/gfdicZ8C9uT
         Oj0iLlTL16ZGAwT1Cgn1wUjUrYa/lHnCVC6ooKpmvMQWNg/XBIpWKDl1fWnq/E2npQO+
         6R0NCiuSbxBBT8BUiSGu5F5iNbBNKadphy7XKxl45MQDiywxaJ7sq2qNrKORvgk0RIua
         LkdQ==
X-Received: by 10.194.8.232 with SMTP id u8mr67490059wja.64.1412193223991;
 Wed, 01 Oct 2014 12:53:43 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Wed, 1 Oct 2014 12:53:03 -0700 (PDT)
In-Reply-To: <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com> <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 1 Oct 2014 15:53:03 -0400
Message-ID: <CAOhmDzcjNqLHOw2E4muEZCZ1fh_B_7-4pZsiq0qEeyky01mCQA@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=047d7b5d348c78693f050461db75
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d348c78693f050461db75
Content-Type: text/plain; charset=UTF-8

On Thu, Sep 4, 2014 at 4:19 PM, shane knapp <sknapp@berkeley.edu> wrote:

> on a side note, this incident will be accelerating our plan to move the
> entire jenkins infrastructure in to a managed datacenter environment.
> this
> will be our major push over the next couple of weeks.  more details about
> this, also, as soon as i get them.
>

Are there any updates on this move of the Jenkins infrastructure to a
managed datacenter?

I remember it being mentioned that another benefit of this move would be
reduced flakiness when Jenkins tries to checkout patches for testing. For
some reason, I'm getting a lot of those
<https://github.com/apache/spark/pull/2606#issuecomment-57514540> today.

Nick

--047d7b5d348c78693f050461db75--

From dev-return-9651-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 19:57:25 2014
Return-Path: <dev-return-9651-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A4A7D17CFA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 19:57:25 +0000 (UTC)
Received: (qmail 75951 invoked by uid 500); 1 Oct 2014 19:57:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75887 invoked by uid 500); 1 Oct 2014 19:57:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75875 invoked by uid 99); 1 Oct 2014 19:57:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 19:57:24 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.44 as permitted sender)
Received: from [74.125.82.44] (HELO mail-wg0-f44.google.com) (74.125.82.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 19:57:20 +0000
Received: by mail-wg0-f44.google.com with SMTP id y10so1423796wgg.15
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 12:56:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=F3kwGdihblSy+dTbB6AkUkDOdGaTXDHy6M3PnVbKQ+4=;
        b=JhXMYGRAn2b4gp4OJMuQOnyMNaQmAkKlfFHyNNibpBJZyJJOBn7QMyNcOqowYOc0WJ
         bDVNNiDESw79cF8bFh4AG+v5UFAiwwrU4HRpj4lpT2sxSEZ9tfyphaNHa7emcXJwX3UJ
         TQiafENeHSUux7pfPL1Wgn7zz11LRW2EljJwu+P91JeB2wbu/WDZqUX99Ciaq8ehMVfU
         SHtxUioZkYwC+U/EzlDCoRbR1ULU1j+nRGnt6M3xG0MXwMsVHtWAKdc/YXIRSPU+fGP1
         jcrYE/u+i8VzHkM2hR7vNXric6COh7Gcl+Wfb2YTnfB8UOXRGrvpIMJXj5x+mdkKP22w
         5dRA==
X-Received: by 10.195.11.200 with SMTP id ek8mr67662235wjd.85.1412193418818;
 Wed, 01 Oct 2014 12:56:58 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Wed, 1 Oct 2014 12:56:18 -0700 (PDT)
In-Reply-To: <CABPQxsuD1KRpcyqb-BTLVe3jK341d9Go2+SJapf-Z3BeUk1UBg@mail.gmail.com>
References: <A60E3962126148228353AB835E22CCDB@gmail.com> <CABPQxstyc=JuZVaeecu4feKgip=8BB==oBL61JCqQTotzxUtUg@mail.gmail.com>
 <D5A0AF46FBB34F69A738DD802768718D@gmail.com> <CAOhmDzfUW_QL2qk-nMVSFv5WxK8ABBywoQHtJYHfSbf2Dtk57A@mail.gmail.com>
 <CABPQxsuD1KRpcyqb-BTLVe3jK341d9Go2+SJapf-Z3BeUk1UBg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 1 Oct 2014 15:56:18 -0400
Message-ID: <CAOhmDzdDrmvMOj+xKv1PBYjkbq6CACR0S_3pfLWv7tFUVk4_mQ@mail.gmail.com>
Subject: Re: do MIMA checking before all test cases start?
To: Patrick Wendell <pwendell@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b873762153791050461e72a
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b873762153791050461e72a
Content-Type: text/plain; charset=UTF-8

How early can MiMa checks be run? Before Spark is even built
<https://github.com/apache/spark/blob/8cc70e7e15fd800f31b94e9102069506360289db/dev/run-tests#L118>?
After the build but before the unit tests?

On Thu, Sep 25, 2014 at 6:06 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Yeah we can also move it first. Wouldn't hurt.
>
> On Thu, Sep 25, 2014 at 6:39 AM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
> > It might still make sense to make this change if MIMA checks are always
> > relatively quick, for the same reason we do style checks first.
> >
> > On Thu, Sep 25, 2014 at 12:25 AM, Nan Zhu <zhunanmcgill@gmail.com>
> wrote:
> >>
> >> yeah, I tried that, but there is always an issue when I ran dev/mima,
> >>
> >> it always gives me some binary compatibility error on Java API part....
> >>
> >> so I have to wait for Jenkins' result when fixing MIMA issues
> >>
> >> --
> >> Nan Zhu
> >>
> >>
> >> On Thursday, September 25, 2014 at 12:04 AM, Patrick Wendell wrote:
> >>
> >> > Have you considered running the mima checks locally? We prefer people
> >> > not use Jenkins for very frequent checks since it takes resources away
> >> > from other people trying to run tests.
> >> >
> >> > On Wed, Sep 24, 2014 at 6:44 PM, Nan Zhu <zhunanmcgill@gmail.com
> >> > (mailto:zhunanmcgill@gmail.com)> wrote:
> >> > > Hi, all
> >> > >
> >> > > It seems that, currently, Jenkins makes MIMA checking after all test
> >> > > cases have finished, IIRC, during the first months we introduced
> MIMA, we do
> >> > > the MIMA checking before running test cases
> >> > >
> >> > > What's the motivation to adjust this behaviour?
> >> > >
> >> > > In my opinion, if you have some binary compatibility issues, you
> just
> >> > > need to do some minor changes, but in the current environment, you
> can only
> >> > > get if your change works after all test cases finished (1 hour
> later...)
> >> > >
> >> > > Best,
> >> > >
> >> > > --
> >> > > Nan Zhu
> >> > >
> >> >
> >> >
> >> >
> >>
> >>
> >
>

--047d7b873762153791050461e72a--

From dev-return-9652-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 20:44:48 2014
Return-Path: <dev-return-9652-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8010317F1E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 20:44:48 +0000 (UTC)
Received: (qmail 42379 invoked by uid 500); 1 Oct 2014 20:44:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42313 invoked by uid 500); 1 Oct 2014 20:44:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42301 invoked by uid 99); 1 Oct 2014 20:44:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 20:44:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 20:44:22 +0000
Received: by mail-la0-f54.google.com with SMTP id gm9so1118889lab.41
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 13:44:21 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=5ColD3+bfGCn6YK+zw2BgkmBC5Iry+Josdj3vW0bGQg=;
        b=KHrXc/uIGXJ08aa/SPIDGaH7gvJsQoJpi6D88iJBYNPsbUGBi+qqJ9cTIV/T15YS28
         URRGsxzyV+VTrGO6M9xnnRPPDa/o0smfoQD+CarWERmY67hqP9oqUDuR0PX0/OcDzgYq
         AoXbkErQp13kxP7vM/7SHlDN8YGkPQ4A01INA8CeJHa97bQwpppD0eEkuIYBeO43O0+g
         oaxgVDu0u0FHJlZoiJ6ONB9Fd0CX28n327uowVuBxv1QjQczkkTalv+j/Vizp9+ZVHQu
         8/t9Aw9U63YO7dmK1jCEs6TZlZ/p8t+pCcbkfj6u8BY8kOsp8TE6As3fjd4TfgM7YvTX
         dS1g==
X-Gm-Message-State: ALoCoQmhzzRkrRsjKHuXoI0myxkr8CGRVkzqXrDpZDch+Ss9w76WjbwQfsBEVCvxRTldCwr2MhV6
X-Received: by 10.152.202.135 with SMTP id ki7mr53013261lac.16.1412196261167;
 Wed, 01 Oct 2014 13:44:21 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Wed, 1 Oct 2014 13:44:01 -0700 (PDT)
In-Reply-To: <CAOhmDzcjNqLHOw2E4muEZCZ1fh_B_7-4pZsiq0qEeyky01mCQA@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com> <CAOhmDzcjNqLHOw2E4muEZCZ1fh_B_7-4pZsiq0qEeyky01mCQA@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 1 Oct 2014 13:44:01 -0700
Message-ID: <CACdU-dTHFv-m0Ewa+QvDSb3MBB236p8Nb9i5SBhv0A_7-6=-rQ@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a1135fb428010e4050462902b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135fb428010e4050462902b
Content-Type: text/plain; charset=UTF-8

as of this morning, i've got the new jenkins up, with all of the current
builds set up (but failing).  i'm in the middle of playing setup/debug
whack-a-mole, but we're getting there.  my guess would be early next week
for the switchover.

On Wed, Oct 1, 2014 at 12:53 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> On Thu, Sep 4, 2014 at 4:19 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> on a side note, this incident will be accelerating our plan to move the
>> entire jenkins infrastructure in to a managed datacenter environment.
>> this
>> will be our major push over the next couple of weeks.  more details about
>> this, also, as soon as i get them.
>>
>
> Are there any updates on this move of the Jenkins infrastructure to a
> managed datacenter?
>
> I remember it being mentioned that another benefit of this move would be
> reduced flakiness when Jenkins tries to checkout patches for testing. For
> some reason, I'm getting a lot of those
> <https://github.com/apache/spark/pull/2606#issuecomment-57514540> today.
>
> Nick
>

--001a1135fb428010e4050462902b--

From dev-return-9653-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 20:51:27 2014
Return-Path: <dev-return-9653-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0DB7F17F5E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 20:51:27 +0000 (UTC)
Received: (qmail 60989 invoked by uid 500); 1 Oct 2014 20:51:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60911 invoked by uid 500); 1 Oct 2014 20:51:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60894 invoked by uid 99); 1 Oct 2014 20:51:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 20:51:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.47 as permitted sender)
Received: from [74.125.82.47] (HELO mail-wg0-f47.google.com) (74.125.82.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 20:51:00 +0000
Received: by mail-wg0-f47.google.com with SMTP id x13so1550624wgg.6
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 13:50:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=pZIHTuhpbGD0xzQ8fQp0G++YOzm1+orEd4/1drOzzS8=;
        b=OnGmuMO9Lw7ON6j6KLM1BS0Hl1VyBHIt8cMY6L/GdxCj2msrA5TYP5jg+jaWDSTFH+
         nM4Jfl9uNmjuyJY6OYATh0oXqHFtiQRoUrPcD2uzwtWwXWVp0sSKSAlgAH+1MhH64mSj
         wFKtNVl4/m+SVlHoyR8eb6IfmhETvkQlSBxMZac1uLts6104I1ZYvwx4RF/zzi3OUa/i
         MhPG8lrZmdhOdaF1H4bZpsr1c3Ab/yVXHmjqqYIW0aFC/cDXXJtt8PJxuK08vqL3wnNf
         GMkFmDUiUOdUaxGDAVteuxcuGtqcHqBiS2OCdTwJ63YtzaAbZ33jfM6gjR/yxkHj1k9h
         +M6A==
X-Received: by 10.194.8.232 with SMTP id u8mr67898842wja.64.1412196659757;
 Wed, 01 Oct 2014 13:50:59 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Wed, 1 Oct 2014 13:50:19 -0700 (PDT)
In-Reply-To: <CACdU-dTHFv-m0Ewa+QvDSb3MBB236p8Nb9i5SBhv0A_7-6=-rQ@mail.gmail.com>
References: <CACdU-dSqv_P-uU17sw-6XBZm9kxT8aFPMTQkd9WnT4x0gy=tbQ@mail.gmail.com>
 <CACdU-dTfD7FUFisNzNgnZQ9QYAYAsVHkF3sq98aCy-+cCz5O6w@mail.gmail.com>
 <CACdU-dS8CNarre1npnowt0hbaBNDwafN_X2v0T92j1gv5U8MkQ@mail.gmail.com>
 <CAOhmDzcjNqLHOw2E4muEZCZ1fh_B_7-4pZsiq0qEeyky01mCQA@mail.gmail.com> <CACdU-dTHFv-m0Ewa+QvDSb3MBB236p8Nb9i5SBhv0A_7-6=-rQ@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 1 Oct 2014 16:50:19 -0400
Message-ID: <CAOhmDzc7FAmWKJkzFQsFhiW6u_vOmdHnR_y2kzN7h0OuL8fsUw@mail.gmail.com>
Subject: Re: amplab jenkins is down
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>, 
	Mike Patterson <mike@databricks.com>, Matthew L Massie <massie@cs.berkeley.edu>
Content-Type: multipart/alternative; boundary=047d7b5d348c420782050462a862
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d348c420782050462a862
Content-Type: text/plain; charset=UTF-8

Sounds good! Thanks for the update Shane.

On Wed, Oct 1, 2014 at 4:44 PM, shane knapp <sknapp@berkeley.edu> wrote:

> as of this morning, i've got the new jenkins up, with all of the current
> builds set up (but failing).  i'm in the middle of playing setup/debug
> whack-a-mole, but we're getting there.  my guess would be early next week
> for the switchover.
>
> On Wed, Oct 1, 2014 at 12:53 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> On Thu, Sep 4, 2014 at 4:19 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> on a side note, this incident will be accelerating our plan to move the
>>> entire jenkins infrastructure in to a managed datacenter environment.
>>> this
>>> will be our major push over the next couple of weeks.  more details about
>>> this, also, as soon as i get them.
>>>
>>
>> Are there any updates on this move of the Jenkins infrastructure to a
>> managed datacenter?
>>
>> I remember it being mentioned that another benefit of this move would be
>> reduced flakiness when Jenkins tries to checkout patches for testing. For
>> some reason, I'm getting a lot of those
>> <https://github.com/apache/spark/pull/2606#issuecomment-57514540> today.
>>
>> Nick
>>
>
>

--047d7b5d348c420782050462a862--

From dev-return-9654-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 21:02:13 2014
Return-Path: <dev-return-9654-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1D3F91721F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 21:02:13 +0000 (UTC)
Received: (qmail 99992 invoked by uid 500); 1 Oct 2014 21:02:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99928 invoked by uid 500); 1 Oct 2014 21:02:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99915 invoked by uid 99); 1 Oct 2014 21:02:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 21:02:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.41 as permitted sender)
Received: from [74.125.82.41] (HELO mail-wg0-f41.google.com) (74.125.82.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 21:02:07 +0000
Received: by mail-wg0-f41.google.com with SMTP id b13so1557836wgh.12
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 14:01:46 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=aLfSMLkwsRYtxtH1Y5DLmyf05Nab+hbSbugpEYSVnBg=;
        b=Tul9LVQCtEIUXtMOX1mauTF/hANjObCgHUX4O4iaKbLAZ0dzhVYnQLEsYWLmMKwVVN
         fJsG5G8elC6yPbvugdnmNxDrer19yNXn/lnGTEiMnzqn0uxqUjWM/SjKh1fGK1feC1CI
         Dldlq6dBdNsPO+Mw5w1p3N/OMzwwoz2GxSkl4pm39Y4onvxPODOnh+6j7qUbqTFSAlLv
         CSMPb7M6pv8f7EAKt3szsjpAFh7pZAUSfGBn6a8UxPg/UOgfu0gA+Ruw2iySJ/nnOXuT
         J2QYPCJaRb16BwLXo84+UXsHAeXzLOfwJhHeAsnAop1Ak7nmcOLDNYw80QtNVCnV/pfs
         /OHg==
X-Received: by 10.180.20.69 with SMTP id l5mr1479266wie.45.1412197306302; Wed,
 01 Oct 2014 14:01:46 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Wed, 1 Oct 2014 14:01:06 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 1 Oct 2014 17:01:06 -0400
Message-ID: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
Subject: Extending Scala style checks
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec53f35f9cb8847050462ce87
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53f35f9cb8847050462ce87
Content-Type: text/plain; charset=UTF-8

As discussed here <https://github.com/apache/spark/pull/2619>, it would be
good to extend our Scala style checks to programmatically enforce as many
of our style rules as possible.

Does anyone know if it's relatively straightforward to enforce additional
rules like the "no trailing spaces" rule mentioned in the linked PR?

Nick

--bcaec53f35f9cb8847050462ce87--

From dev-return-9655-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 21:36:30 2014
Return-Path: <dev-return-9655-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8747017437
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 21:36:30 +0000 (UTC)
Received: (qmail 37456 invoked by uid 500); 1 Oct 2014 21:36:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37381 invoked by uid 500); 1 Oct 2014 21:36:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37364 invoked by uid 99); 1 Oct 2014 21:36:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 21:36:29 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.160.174 as permitted sender)
Received: from [209.85.160.174] (HELO mail-yk0-f174.google.com) (209.85.160.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 21:36:25 +0000
Received: by mail-yk0-f174.google.com with SMTP id 142so146436ykq.19
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 14:36:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=2nn4f7YuuH7efRVdnSu5mdeFqIWkR2PfSXmh3XMKYZo=;
        b=lMa5douHZ8G7HKyQBsaPHPYblZKTzUWNoRKYBRsp8EKw7LSicOUJFLs9wz9fWG/m7o
         OufxQ41sbbHa5Go+c6XU9yoKI7GSxd84BzqvCr3LPxDBtH4Y76tT40zfcWn965CmbgdF
         pNDEGGl+7mNmgoOOPaA/CRM3vhhJbcObjKCLF56xlmDj544VBvIKP4pWkiDdfBKzbLju
         ScNm91rRBMiWwdcteOxqQA+R2OBOCRsMJG22qyiPJPgdEgqMhKV1M6zBk68SxnrcUD7o
         pTWu9tqc7UEWg2fVnd3uUrzgWxP6m+C8PFTZsNg55SxUSwUDNH/I2xd8QxhKvV63Vig1
         SSvw==
MIME-Version: 1.0
X-Received: by 10.236.10.66 with SMTP id 42mr9086054yhu.68.1412199364651; Wed,
 01 Oct 2014 14:36:04 -0700 (PDT)
Received: by 10.170.163.70 with HTTP; Wed, 1 Oct 2014 14:36:04 -0700 (PDT)
In-Reply-To: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
Date: Wed, 1 Oct 2014 14:36:04 -0700
Message-ID: <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
Subject: Re: Extending Scala style checks
From: Ted Yu <yuzhihong@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1136b28c7b6e1d05046349a7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1136b28c7b6e1d05046349a7
Content-Type: text/plain; charset=UTF-8

Please take a look at WhitespaceEndOfLineChecker under:
http://www.scalastyle.org/rules-0.1.0.html

Cheers

On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> As discussed here <https://github.com/apache/spark/pull/2619>, it would be
> good to extend our Scala style checks to programmatically enforce as many
> of our style rules as possible.
>
> Does anyone know if it's relatively straightforward to enforce additional
> rules like the "no trailing spaces" rule mentioned in the linked PR?
>
> Nick
>

--001a1136b28c7b6e1d05046349a7--

From dev-return-9656-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  1 22:37:38 2014
Return-Path: <dev-return-9656-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6EDBF17665
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  1 Oct 2014 22:37:38 +0000 (UTC)
Received: (qmail 26738 invoked by uid 500); 1 Oct 2014 22:37:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 26660 invoked by uid 500); 1 Oct 2014 22:37:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 26641 invoked by uid 99); 1 Oct 2014 22:37:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 22:37:37 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.182 as permitted sender)
Received: from [209.85.214.182] (HELO mail-ob0-f182.google.com) (209.85.214.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 01 Oct 2014 22:37:33 +0000
Received: by mail-ob0-f182.google.com with SMTP id uy5so1210959obc.13
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 15:37:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=eQDayviiyhWxJcqm/T9CjW8JlqFeDgRRjcO03C/Z+X0=;
        b=C37I+ITaIhqJmje17LUgGo/nyMndvnriCxSVniJuRVC/2BQJ4Bs+Y7C9r3X3GZleNx
         XNiLrd+ykHDE2hu2Iph/yHqv+p6SzJCG1d/KVOd/iBhTXPcBWqhHx7QhNWQwI8+cNs04
         is3Emnj7y81L8XjNZdc8mBdVqAa6KmfRY+9Zo0s9VpGJziK6qsMqFa/ZG44F8opGdR1f
         Wp9jFhACWExC92Nqrx8dZHnutxemFvoe9cmhROjZUR6Xy9gYn4QqqUkOZl7jWc868iWJ
         CiKqMxUkK1Zn2NcAOFmgH/rMJHDWVcuBbqw8Y+c5ewuw0zFTlxZkkRj0KgFlo6i/Dr6X
         2CIQ==
MIME-Version: 1.0
X-Received: by 10.60.37.9 with SMTP id u9mr62509476oej.18.1412203031364; Wed,
 01 Oct 2014 15:37:11 -0700 (PDT)
Received: by 10.202.56.213 with HTTP; Wed, 1 Oct 2014 15:37:11 -0700 (PDT)
In-Reply-To: <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
	<CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
Date: Wed, 1 Oct 2014 15:37:11 -0700
Message-ID: <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
Subject: Re: Extending Scala style checks
From: Patrick Wendell <pwendell@gmail.com>
To: Ted Yu <yuzhihong@gmail.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Nick,

We can always take built-in rules. Back when we added this Prashant
Sharma actually did some great work that lets us write our own style
rules in cases where rules don't exist.

You can see some existing rules here:
https://github.com/apache/spark/tree/master/project/spark-style/src/main/scala/org/apache/spark/scalastyle

Prashant has over time contributed a lot of our custom rules upstream
to stalastyle, so now there are only a couple there.

- Patrick

On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
> Please take a look at WhitespaceEndOfLineChecker under:
> http://www.scalastyle.org/rules-0.1.0.html
>
> Cheers
>
> On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <nicholas.chammas@gmail.com
>> wrote:
>
>> As discussed here <https://github.com/apache/spark/pull/2619>, it would be
>> good to extend our Scala style checks to programmatically enforce as many
>> of our style rules as possible.
>>
>> Does anyone know if it's relatively straightforward to enforce additional
>> rules like the "no trailing spaces" rule mentioned in the linked PR?
>>
>> Nick
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9657-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 01:14:11 2014
Return-Path: <dev-return-9657-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BB5C717C0F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 01:14:11 +0000 (UTC)
Received: (qmail 74274 invoked by uid 500); 2 Oct 2014 01:14:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74217 invoked by uid 500); 2 Oct 2014 01:14:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74205 invoked by uid 99); 2 Oct 2014 01:14:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 01:14:10 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.181 as permitted sender)
Received: from [209.85.212.181] (HELO mail-wi0-f181.google.com) (209.85.212.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 01:14:06 +0000
Received: by mail-wi0-f181.google.com with SMTP id hi2so2442321wib.14
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 18:13:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=rnmUCK+GNiqybGIJcmf1e5J0LfajygHODGspUMP6nfk=;
        b=Ons3XZZDsmGct7RH3FbFVtfKSanN1OK7AWGK/NxQlxz8yWDdJwpgAzOoAWZBdllVSy
         rNInyfUVmnjq7cvkKhRtUKoss1RM9TeBTUcZiNPGVh0Pyz2q31Qh1KNzyYR502p2oJn9
         8+BtRcDCmRGwbPBdQTt+Nk2CXpii93G+XlIDn2TzJGB4JJS8vTK3CInk4zbaG1eP7qXP
         lIRnPmVRL/4l++n1pI9mEpIyrevaZ+7zpwErqmbNov0LkZQx4rld4qPCmKbRKs7a677A
         ZGYVsQmqWQcJzFrGwnd3Qt6e+YUYNT8xnQ+WgbqgG5gmKB0Ah7XXGX20MylerZGx+/ui
         WcpA==
X-Received: by 10.180.98.161 with SMTP id ej1mr19032041wib.45.1412212425156;
 Wed, 01 Oct 2014 18:13:45 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Wed, 1 Oct 2014 18:13:05 -0700 (PDT)
In-Reply-To: <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
 <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com> <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 1 Oct 2014 21:13:05 -0400
Message-ID: <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com>
Subject: Re: Extending Scala style checks
To: Patrick Wendell <pwendell@gmail.com>
Cc: Ted Yu <yuzhihong@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d0442815cf2ef9d05046653fb
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0442815cf2ef9d05046653fb
Content-Type: text/plain; charset=UTF-8

Ah, since there appears to be a built-in rule for end-of-line whitespace,
Michael and Cheng, y'all should be able to add this in pretty easily.

Nick

On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Nick,
>
> We can always take built-in rules. Back when we added this Prashant
> Sharma actually did some great work that lets us write our own style
> rules in cases where rules don't exist.
>
> You can see some existing rules here:
>
> https://github.com/apache/spark/tree/master/project/spark-style/src/main/scala/org/apache/spark/scalastyle
>
> Prashant has over time contributed a lot of our custom rules upstream
> to stalastyle, so now there are only a couple there.
>
> - Patrick
>
> On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
> > Please take a look at WhitespaceEndOfLineChecker under:
> > http://www.scalastyle.org/rules-0.1.0.html
> >
> > Cheers
> >
> > On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> >> wrote:
> >
> >> As discussed here <https://github.com/apache/spark/pull/2619>, it
> would be
> >> good to extend our Scala style checks to programmatically enforce as
> many
> >> of our style rules as possible.
> >>
> >> Does anyone know if it's relatively straightforward to enforce
> additional
> >> rules like the "no trailing spaces" rule mentioned in the linked PR?
> >>
> >> Nick
> >>
>

--f46d0442815cf2ef9d05046653fb--

From dev-return-9658-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 01:21:00 2014
Return-Path: <dev-return-9658-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6028B17C4A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 01:21:00 +0000 (UTC)
Received: (qmail 89372 invoked by uid 500); 2 Oct 2014 01:20:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89306 invoked by uid 500); 2 Oct 2014 01:20:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89294 invoked by uid 99); 2 Oct 2014 01:20:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 01:20:59 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 01:20:55 +0000
Received: by mail-la0-f52.google.com with SMTP id hz20so1455846lab.25
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 18:20:33 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=F2B71YCSyASZAwgxDugjfoa4G9FmggJbws3nj5ukqKs=;
        b=Jn+cC7zccPOfcDlYT41WWYnN23GnY7DzW8eGwF0ijfUaZ9lRy+eYcMQQVq9mAyD+S9
         pVE4R7pnG3PG5Mb64kVwOs+ExMqAYrwOARlcvr3xBYEua/fxq9HKHRyTt4l29Ys/bF2s
         EvNSRkvQyROiu1/YZyCcwuYmFNn+GGJ8majvcOY1c2NNjLQeaSiRadY10WXdiF7GgT6f
         7qtuJrP9xVHf+HLWT8oh0ndNSC7OSXKp7GRz9kkgpV61b6vCAXE19n2YO4aawmAVp6eC
         8ePYue/NMPfEDtZJk3OSdMQJD6rFAQOtrVy7qpzggqoUZocDojZkoWNi9BXKAxTAj7Jb
         WK6w==
X-Gm-Message-State: ALoCoQmPWIOZp/bS8EBkg2Jz2fs9detxLlu9/4kLcSn8nCDB9C0dSN0bLTiP4uRUPBGwczofn7u4
X-Received: by 10.112.147.74 with SMTP id ti10mr55852576lbb.29.1412212833064;
 Wed, 01 Oct 2014 18:20:33 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.17 with HTTP; Wed, 1 Oct 2014 18:20:13 -0700 (PDT)
In-Reply-To: <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
 <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
 <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com> <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Wed, 1 Oct 2014 18:20:13 -0700
Message-ID: <CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com>
Subject: Re: Extending Scala style checks
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Ted Yu <yuzhihong@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a84be432ae20504666c00
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a84be432ae20504666c00
Content-Type: text/plain; charset=UTF-8

The hard part here is updating the existing code base... which is going to
create merge conflicts with like all of the open PRs...

On Wed, Oct 1, 2014 at 6:13 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> Ah, since there appears to be a built-in rule for end-of-line whitespace,
> Michael and Cheng, y'all should be able to add this in pretty easily.
>
> Nick
>
> On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Hey Nick,
> >
> > We can always take built-in rules. Back when we added this Prashant
> > Sharma actually did some great work that lets us write our own style
> > rules in cases where rules don't exist.
> >
> > You can see some existing rules here:
> >
> >
> https://github.com/apache/spark/tree/master/project/spark-style/src/main/scala/org/apache/spark/scalastyle
> >
> > Prashant has over time contributed a lot of our custom rules upstream
> > to stalastyle, so now there are only a couple there.
> >
> > - Patrick
> >
> > On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
> > > Please take a look at WhitespaceEndOfLineChecker under:
> > > http://www.scalastyle.org/rules-0.1.0.html
> > >
> > > Cheers
> > >
> > > On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
> > nicholas.chammas@gmail.com
> > >> wrote:
> > >
> > >> As discussed here <https://github.com/apache/spark/pull/2619>, it
> > would be
> > >> good to extend our Scala style checks to programmatically enforce as
> > many
> > >> of our style rules as possible.
> > >>
> > >> Does anyone know if it's relatively straightforward to enforce
> > additional
> > >> rules like the "no trailing spaces" rule mentioned in the linked PR?
> > >>
> > >> Nick
> > >>
> >
>

--047d7b3a84be432ae20504666c00--

From dev-return-9659-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 01:26:02 2014
Return-Path: <dev-return-9659-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A70EE17C6A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 01:26:02 +0000 (UTC)
Received: (qmail 99840 invoked by uid 500); 2 Oct 2014 01:26:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99766 invoked by uid 500); 2 Oct 2014 01:26:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99754 invoked by uid 99); 2 Oct 2014 01:26:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 01:26:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 01:25:34 +0000
Received: by mail-wi0-f182.google.com with SMTP id n3so2487757wiv.9
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 18:25:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=d3JG7W+i9SG7qF3Mh00NaMmtA5Olc0W5+O10eMLjlKo=;
        b=GoZLOBw61gnO2XXk6OdYSyUNXxjZVc8ieoGWnkaj2+vo+VefW59/bySP7pDbuzrhqK
         BXPH6Yyee4TYb5wk5kn8xHoJRcJbfKtT3aI2BFwEstI2/vAKJqSI4bd/Co3OHXGJofj2
         Mck4ObRhO3Qtxj//aFQph01YLByIIPsOjI+Oq2jD+/TIDbxgpgeIpnra7/dpGHO+xWuC
         WKGaO6qcLCo86cfkyU8YB3AM9t5jhJPa5if6eG9qO/AQfWYcdQq0W9v4hDIUJyarLm3N
         PsmUzLEw9OQQJyKy95m+xw36Hh3+KAH5AX8pJjDmf8J3lIHYpYq+x8nCBIBwuFe4YPFp
         ZpCA==
X-Received: by 10.194.8.232 with SMTP id u8mr69520284wja.64.1412213133332;
 Wed, 01 Oct 2014 18:25:33 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Wed, 1 Oct 2014 18:24:53 -0700 (PDT)
In-Reply-To: <CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
 <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
 <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
 <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com> <CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 1 Oct 2014 21:24:53 -0400
Message-ID: <CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com>
Subject: Re: Extending Scala style checks
To: Michael Armbrust <michael@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Ted Yu <yuzhihong@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b5d348c28d5fc0504667eeb
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d348c28d5fc0504667eeb
Content-Type: text/plain; charset=UTF-8

Yeah, I remember that hell when I added PEP 8 to the build checks and fixed
all the outstanding Python style issues. I had to keep rebasing and
resolving merge conflicts until the PR was merged.

It's a rough process, but thankfully it's also a one-time process. I might
be able to help with that in the next week or two if no-one else wants to
pick it up.

Nick

On Wed, Oct 1, 2014 at 9:20 PM, Michael Armbrust <michael@databricks.com>
wrote:

> The hard part here is updating the existing code base... which is going to
> create merge conflicts with like all of the open PRs...
>
> On Wed, Oct 1, 2014 at 6:13 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Ah, since there appears to be a built-in rule for end-of-line whitespace,
>> Michael and Cheng, y'all should be able to add this in pretty easily.
>>
>> Nick
>>
>> On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>> > Hey Nick,
>> >
>> > We can always take built-in rules. Back when we added this Prashant
>> > Sharma actually did some great work that lets us write our own style
>> > rules in cases where rules don't exist.
>> >
>> > You can see some existing rules here:
>> >
>> >
>> https://github.com/apache/spark/tree/master/project/spark-style/src/main/scala/org/apache/spark/scalastyle
>> >
>> > Prashant has over time contributed a lot of our custom rules upstream
>> > to stalastyle, so now there are only a couple there.
>> >
>> > - Patrick
>> >
>> > On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>> > > Please take a look at WhitespaceEndOfLineChecker under:
>> > > http://www.scalastyle.org/rules-0.1.0.html
>> > >
>> > > Cheers
>> > >
>> > > On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
>> > nicholas.chammas@gmail.com
>> > >> wrote:
>> > >
>> > >> As discussed here <https://github.com/apache/spark/pull/2619>, it
>> > would be
>> > >> good to extend our Scala style checks to programmatically enforce as
>> > many
>> > >> of our style rules as possible.
>> > >>
>> > >> Does anyone know if it's relatively straightforward to enforce
>> > additional
>> > >> rules like the "no trailing spaces" rule mentioned in the linked PR?
>> > >>
>> > >> Nick
>> > >>
>> >
>>
>
>

--047d7b5d348c28d5fc0504667eeb--

From dev-return-9660-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 01:35:04 2014
Return-Path: <dev-return-9660-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DFE8E17C97
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 01:35:04 +0000 (UTC)
Received: (qmail 13867 invoked by uid 500); 2 Oct 2014 01:35:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13793 invoked by uid 500); 2 Oct 2014 01:35:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13780 invoked by uid 99); 2 Oct 2014 01:35:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 01:35:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.177 as permitted sender)
Received: from [209.85.212.177] (HELO mail-wi0-f177.google.com) (209.85.212.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 01:34:35 +0000
Received: by mail-wi0-f177.google.com with SMTP id ho1so2473619wib.16
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 18:34:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=n2ItkJp5FmiCumzj/QTIac7DMnH2RoHB7H+OzvuwHeY=;
        b=hWIIByrHmk7OpR614jN37TEg5Mxe8Ee66yMADPebHoq9hd3pXzIk/q1HotItbn4aGo
         8xhumvl25obFVpTY0ewrFh246BkDq3Qlc/cuM5AFG6xa94+22yYF3ISc2BG2vqkrH6+H
         6dCRT4DxnGvEJ3+zgmv5gHYdJVLHl80boH+rhsRKI1uZMxnw8973USvWO6zqs3Ym/mHc
         b4Be6FTX4qQ65rnfH9oCr0d1mIpAjfih1ob6yyarrV8d8RrXjoDZsv8sXjNJAoTyYp9H
         8D841L3ZIC1p0OvMtY76St41GimnxR+pvArKJHv6YKxsrjff/319JNQRw4fInvx8yWoD
         1Vgw==
X-Received: by 10.194.209.207 with SMTP id mo15mr64152675wjc.6.1412213675315;
 Wed, 01 Oct 2014 18:34:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Wed, 1 Oct 2014 18:33:55 -0700 (PDT)
In-Reply-To: <CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
 <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
 <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
 <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com>
 <CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com> <CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 1 Oct 2014 21:33:55 -0400
Message-ID: <CAOhmDzf5QxUPVWnGbo8OK71zOA9u8Uy2eiSbtT8077ntpRzEfw@mail.gmail.com>
Subject: Re: Extending Scala style checks
To: Michael Armbrust <michael@databricks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Ted Yu <yuzhihong@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a831476d72d0504669efe
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a831476d72d0504669efe
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Does anyone know if Scala has something equivalent to autopep8
<https://pypi.python.org/pypi/autopep8>? It would help patch up the
existing code base a lot quicker as we add in new style rules.
=E2=80=8B

On Wed, Oct 1, 2014 at 9:24 PM, Nicholas Chammas <nicholas.chammas@gmail.co=
m
> wrote:

> Yeah, I remember that hell when I added PEP 8 to the build checks and
> fixed all the outstanding Python style issues. I had to keep rebasing and
> resolving merge conflicts until the PR was merged.
>
> It's a rough process, but thankfully it's also a one-time process. I migh=
t
> be able to help with that in the next week or two if no-one else wants to
> pick it up.
>
> Nick
>
> On Wed, Oct 1, 2014 at 9:20 PM, Michael Armbrust <michael@databricks.com>
> wrote:
>
>> The hard part here is updating the existing code base... which is going
>> to create merge conflicts with like all of the open PRs...
>>
>> On Wed, Oct 1, 2014 at 6:13 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> Ah, since there appears to be a built-in rule for end-of-line whitespac=
e,
>>> Michael and Cheng, y'all should be able to add this in pretty easily.
>>>
>>> Nick
>>>
>>> On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>
>>> > Hey Nick,
>>> >
>>> > We can always take built-in rules. Back when we added this Prashant
>>> > Sharma actually did some great work that lets us write our own style
>>> > rules in cases where rules don't exist.
>>> >
>>> > You can see some existing rules here:
>>> >
>>> >
>>> https://github.com/apache/spark/tree/master/project/spark-style/src/mai=
n/scala/org/apache/spark/scalastyle
>>> >
>>> > Prashant has over time contributed a lot of our custom rules upstream
>>> > to stalastyle, so now there are only a couple there.
>>> >
>>> > - Patrick
>>> >
>>> > On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>> > > Please take a look at WhitespaceEndOfLineChecker under:
>>> > > http://www.scalastyle.org/rules-0.1.0.html
>>> > >
>>> > > Cheers
>>> > >
>>> > > On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
>>> > nicholas.chammas@gmail.com
>>> > >> wrote:
>>> > >
>>> > >> As discussed here <https://github.com/apache/spark/pull/2619>, it
>>> > would be
>>> > >> good to extend our Scala style checks to programmatically enforce =
as
>>> > many
>>> > >> of our style rules as possible.
>>> > >>
>>> > >> Does anyone know if it's relatively straightforward to enforce
>>> > additional
>>> > >> rules like the "no trailing spaces" rule mentioned in the linked P=
R?
>>> > >>
>>> > >> Nick
>>> > >>
>>> >
>>>
>>
>>
>

--047d7b3a831476d72d0504669efe--

From dev-return-9661-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 02:30:50 2014
Return-Path: <dev-return-9661-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 22C4417DAD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 02:30:50 +0000 (UTC)
Received: (qmail 80214 invoked by uid 500); 2 Oct 2014 02:30:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80163 invoked by uid 500); 2 Oct 2014 02:30:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80152 invoked by uid 99); 2 Oct 2014 02:30:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 02:30:48 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.53] (HELO mail-qa0-f53.google.com) (209.85.216.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 02:30:23 +0000
Received: by mail-qa0-f53.google.com with SMTP id v10so1217953qac.40
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 19:30:21 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=m8LHpuX8reairBNOM4MYbkRM0tcuTyDZiduEVirQpEM=;
        b=YrVUDKD21zf03evD/Cfnt0+cBSgER8nPBm4tMCW231O0QwB4N8hZSS5Scmoj7Ewc7C
         zrKLyRAN6uoKvC8QTzOOFGYH7tOYqSVm3ZMDrjiSepI4B8qDF2VKBXqwnN85sxN2uLIe
         kDOdS2GHLWTdfK5/uYUviOVHv9junEZ1PoJGbUMvUkDFgb4fsooZnoWyHryQKv6eNNj6
         CdD8xXYB6GnakdtfpsWcFXQpvuxeaD7zqMT17nVUs56HPmIkrjaw+ZRvHyvEuBuqIy6N
         aTLY8EmoREaV7DnutpW4DeSupvQr1+0dj3ifTz1ngRV3Q/TWNw6b99hsV3DdDXTEOCJi
         J61g==
X-Gm-Message-State: ALoCoQmciklRG3YgGL/20W8A9QD1SqmcgMAeTDqb/8iQQ501hx34UhbPd9oac5wNUlI5Hx1F6Zv2
MIME-Version: 1.0
X-Received: by 10.224.37.69 with SMTP id w5mr59686331qad.67.1412217020853;
 Wed, 01 Oct 2014 19:30:20 -0700 (PDT)
Received: by 10.96.47.8 with HTTP; Wed, 1 Oct 2014 19:30:20 -0700 (PDT)
In-Reply-To: <CAOhmDzf5QxUPVWnGbo8OK71zOA9u8Uy2eiSbtT8077ntpRzEfw@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
	<CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
	<CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
	<CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com>
	<CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com>
	<CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com>
	<CAOhmDzf5QxUPVWnGbo8OK71zOA9u8Uy2eiSbtT8077ntpRzEfw@mail.gmail.com>
Date: Wed, 1 Oct 2014 19:30:20 -0700
Message-ID: <CAPh_B=Y3CQfWQj15pTf-O0LDy84ExuN--j-3tFshwggtafYYog@mail.gmail.com>
Subject: Re: Extending Scala style checks
From: Reynold Xin <rxin@databricks.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Michael Armbrust <michael@databricks.com>, Patrick Wendell <pwendell@gmail.com>, 
	Ted Yu <yuzhihong@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1c9c8dfde020504676593
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1c9c8dfde020504676593
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

There is scalariform but it can be disruptive. Last time I ran it on Spark
it didn't compile due to some xml interpolation problem.

On Wednesday, October 1, 2014, Nicholas Chammas <nicholas.chammas@gmail.com=
>
wrote:

> Does anyone know if Scala has something equivalent to autopep8
> <https://pypi.python.org/pypi/autopep8>? It would help patch up the
> existing code base a lot quicker as we add in new style rules.
> =E2=80=8B
>
> On Wed, Oct 1, 2014 at 9:24 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com <javascript:;>
> > wrote:
>
> > Yeah, I remember that hell when I added PEP 8 to the build checks and
> > fixed all the outstanding Python style issues. I had to keep rebasing a=
nd
> > resolving merge conflicts until the PR was merged.
> >
> > It's a rough process, but thankfully it's also a one-time process. I
> might
> > be able to help with that in the next week or two if no-one else wants =
to
> > pick it up.
> >
> > Nick
> >
> > On Wed, Oct 1, 2014 at 9:20 PM, Michael Armbrust <michael@databricks.co=
m
> <javascript:;>>
> > wrote:
> >
> >> The hard part here is updating the existing code base... which is goin=
g
> >> to create merge conflicts with like all of the open PRs...
> >>
> >> On Wed, Oct 1, 2014 at 6:13 PM, Nicholas Chammas <
> >> nicholas.chammas@gmail.com <javascript:;>> wrote:
> >>
> >>> Ah, since there appears to be a built-in rule for end-of-line
> whitespace,
> >>> Michael and Cheng, y'all should be able to add this in pretty easily.
> >>>
> >>> Nick
> >>>
> >>> On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com
> <javascript:;>>
> >>> wrote:
> >>>
> >>> > Hey Nick,
> >>> >
> >>> > We can always take built-in rules. Back when we added this Prashant
> >>> > Sharma actually did some great work that lets us write our own styl=
e
> >>> > rules in cases where rules don't exist.
> >>> >
> >>> > You can see some existing rules here:
> >>> >
> >>> >
> >>>
> https://github.com/apache/spark/tree/master/project/spark-style/src/main/=
scala/org/apache/spark/scalastyle
> >>> >
> >>> > Prashant has over time contributed a lot of our custom rules upstre=
am
> >>> > to stalastyle, so now there are only a couple there.
> >>> >
> >>> > - Patrick
> >>> >
> >>> > On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com
> <javascript:;>> wrote:
> >>> > > Please take a look at WhitespaceEndOfLineChecker under:
> >>> > > http://www.scalastyle.org/rules-0.1.0.html
> >>> > >
> >>> > > Cheers
> >>> > >
> >>> > > On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
> >>> > nicholas.chammas@gmail.com <javascript:;>
> >>> > >> wrote:
> >>> > >
> >>> > >> As discussed here <https://github.com/apache/spark/pull/2619>, i=
t
> >>> > would be
> >>> > >> good to extend our Scala style checks to programmatically enforc=
e
> as
> >>> > many
> >>> > >> of our style rules as possible.
> >>> > >>
> >>> > >> Does anyone know if it's relatively straightforward to enforce
> >>> > additional
> >>> > >> rules like the "no trailing spaces" rule mentioned in the linked
> PR?
> >>> > >>
> >>> > >> Nick
> >>> > >>
> >>> >
> >>>
> >>
> >>
> >
>

--001a11c1c9c8dfde020504676593--

From dev-return-9662-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 04:06:55 2014
Return-Path: <dev-return-9662-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EF0A117F4F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 04:06:55 +0000 (UTC)
Received: (qmail 86576 invoked by uid 500); 2 Oct 2014 04:06:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86496 invoked by uid 500); 2 Oct 2014 04:06:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86483 invoked by uid 99); 2 Oct 2014 04:06:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 04:06:54 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.43 as permitted sender)
Received: from [209.85.220.43] (HELO mail-pa0-f43.google.com) (209.85.220.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 04:06:50 +0000
Received: by mail-pa0-f43.google.com with SMTP id lf10so1526930pab.2
        for <dev@spark.apache.org>; Wed, 01 Oct 2014 21:06:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type:content-transfer-encoding;
        bh=Bp5ElX+Hxx461GS23VDfh+B633NM9l1mZcIQ9gYaFiA=;
        b=DCGZM4Zv1b7V0lSGQKbXVTuYUU3dh0CLEvIqIw6LpbSXgfsGnJ8rv6GRDCTEbf8d/a
         J3Fx4wa363nC7ci28GQ78gdjV2XH+x4+D53pydCDj2HS40Qwy6V3szp/QBQU6aN4xLqj
         fKZzhGYuRBGZBm1vGqKug83XfgFCRQaywgE5lZBjHASeCQoCqVleuHujkHE7xfqGp+MX
         LSDDAP7IvidSBnJfO20zl5k+HdT0dIxZzpAYMp71b4IN0t10BaTrM3afrSvRwpqosn4J
         o5MSIwz4PWCDSML6XBRlhnACwqRkVVqPAgR1lY1T1Umjl7YB/JL2+n7y6yrDz8X4XaE+
         7jfw==
X-Received: by 10.66.222.199 with SMTP id qo7mr81665382pac.134.1412222789913;
        Wed, 01 Oct 2014 21:06:29 -0700 (PDT)
Received: from lian-laptop.local ([114.96.154.120])
        by mx.google.com with ESMTPSA id nv1sm2314603pbc.18.2014.10.01.21.06.27
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Wed, 01 Oct 2014 21:06:29 -0700 (PDT)
Message-ID: <542CCF41.8000105@gmail.com>
Date: Thu, 02 Oct 2014 12:06:25 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: Nicholas Chammas <nicholas.chammas@gmail.com>, 
 Michael Armbrust <michael@databricks.com>
CC: Patrick Wendell <pwendell@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
 dev <dev@spark.apache.org>
Subject: Re: Extending Scala style checks
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com> <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com> <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com> <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com> <CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com> <CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com>
In-Reply-To: <CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Since we can easily catch the list of all changed files in a PR, I think 
we can start with adding the no trailing space check for newly changed 
files only?

On 10/2/14 9:24 AM, Nicholas Chammas wrote:
> Yeah, I remember that hell when I added PEP 8 to the build checks and fixed
> all the outstanding Python style issues. I had to keep rebasing and
> resolving merge conflicts until the PR was merged.
>
> It's a rough process, but thankfully it's also a one-time process. I might
> be able to help with that in the next week or two if no-one else wants to
> pick it up.
>
> Nick
>
> On Wed, Oct 1, 2014 at 9:20 PM, Michael Armbrust <michael@databricks.com>
> wrote:
>
>> The hard part here is updating the existing code base... which is going to
>> create merge conflicts with like all of the open PRs...
>>
>> On Wed, Oct 1, 2014 at 6:13 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> Ah, since there appears to be a built-in rule for end-of-line whitespace,
>>> Michael and Cheng, y'all should be able to add this in pretty easily.
>>>
>>> Nick
>>>
>>> On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>
>>>> Hey Nick,
>>>>
>>>> We can always take built-in rules. Back when we added this Prashant
>>>> Sharma actually did some great work that lets us write our own style
>>>> rules in cases where rules don't exist.
>>>>
>>>> You can see some existing rules here:
>>>>
>>>>
>>> https://github.com/apache/spark/tree/master/project/spark-style/src/main/scala/org/apache/spark/scalastyle
>>>> Prashant has over time contributed a lot of our custom rules upstream
>>>> to stalastyle, so now there are only a couple there.
>>>>
>>>> - Patrick
>>>>
>>>> On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>>> Please take a look at WhitespaceEndOfLineChecker under:
>>>>> http://www.scalastyle.org/rules-0.1.0.html
>>>>>
>>>>> Cheers
>>>>>
>>>>> On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com
>>>>>> wrote:
>>>>>> As discussed here <https://github.com/apache/spark/pull/2619>, it
>>>> would be
>>>>>> good to extend our Scala style checks to programmatically enforce as
>>>> many
>>>>>> of our style rules as possible.
>>>>>>
>>>>>> Does anyone know if it's relatively straightforward to enforce
>>>> additional
>>>>>> rules like the "no trailing spaces" rule mentioned in the linked PR?
>>>>>>
>>>>>> Nick
>>>>>>
>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9663-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 19:40:19 2014
Return-Path: <dev-return-9663-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 54CEB17DFE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 19:40:19 +0000 (UTC)
Received: (qmail 6710 invoked by uid 500); 2 Oct 2014 19:40:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6631 invoked by uid 500); 2 Oct 2014 19:40:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5565 invoked by uid 99); 2 Oct 2014 19:40:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 19:40:17 +0000
X-ASF-Spam-Status: No, hits=2.9 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 98.139.253.105 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [98.139.253.105] (HELO mrout2-b.corp.bf1.yahoo.com) (98.139.253.105)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 19:39:52 +0000
Received: from GQ1-EX10-CAHT16.y.corp.yahoo.com (gq1-ex10-caht16.corp.gq1.yahoo.com [10.73.119.197])
	by mrout2-b.corp.bf1.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s92Jd5tH023347
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Thu, 2 Oct 2014 12:39:06 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT16.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Thu, 2
 Oct 2014 12:39:05 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: HiveContext: cache table not supported for partitioned table?
Thread-Topic: HiveContext: cache table not supported for partitioned table?
Thread-Index: AQHP3niGg0DEZrvWA0ys/Cw4g5ugeA==
Date: Thu, 2 Oct 2014 19:39:05 +0000
Message-ID: <D052F7E8.434E%lidu@yahoo-inc.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: multipart/alternative;
	boundary="_000_D052F7E8434Eliduyahooinccom_"
MIME-Version: 1.0
X-Milter-Version: master.31+4-gbc07cd5+
X-CLX-ID: 278746003
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D052F7E8434Eliduyahooinccom_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi,

In Spark 1.1 HiveContext, I ran a create partitioned table command followed=
 by a cache table command and got a java.sql.SQLSyntaxErrorException: Table=
/View 'PARTITIONS' does not exist. But cache table worked fine if the table=
 is not a partitioned table.

Can anybody confirm that cache of partitioned table is not supported yet in=
 current version?

Thanks,
Du

--_000_D052F7E8434Eliduyahooinccom_--

From dev-return-9664-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 23:31:58 2014
Return-Path: <dev-return-9664-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 702FB179D1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 23:31:58 +0000 (UTC)
Received: (qmail 47979 invoked by uid 500); 2 Oct 2014 23:31:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47884 invoked by uid 500); 2 Oct 2014 23:31:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47784 invoked by uid 99); 2 Oct 2014 23:31:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 23:31:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.179 as permitted sender)
Received: from [209.85.212.179] (HELO mail-wi0-f179.google.com) (209.85.212.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 23:31:31 +0000
Received: by mail-wi0-f179.google.com with SMTP id d1so560422wiv.0
        for <dev@spark.apache.org>; Thu, 02 Oct 2014 16:31:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=QVzU9k4MpoOC8G8rhbXWP7YQxcCPvI3Rm+w7b/paD8c=;
        b=KxGsLEML5wFIBZ2zGD2jNYy/HxBy0JyeLrvvI0ZqHzpxmlCIGlKY4kEuEL5nqFwoK9
         v6mZ4It2o7Uq9BGQF2iUmzjXQBoCxkR4Id2wNCu+W9SA2YiHIgKJ4DLfkWy4AUJQSn7h
         aX2o+PVyBTMXUG7RnmRq3SaBNfejVZDSNAwFJ2PI4GaTaUXIAUbjGAL9RnEy2NOyyTho
         KQNwhPMp1O57qnrVFOoqCc6BptmqHymHUhf0RfEwvUCfNfFXEDulTBKPvcnXhXUA2Fbu
         v7+ZdCmNzYOt80RJfLwoT5Q1mOFBbOd3nhp4PTWidY0LIfQRyKiiG1Sd3BE9pkPUsn26
         f23g==
X-Received: by 10.180.72.170 with SMTP id e10mr7659459wiv.75.1412292691246;
 Thu, 02 Oct 2014 16:31:31 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Thu, 2 Oct 2014 16:30:51 -0700 (PDT)
In-Reply-To: <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
 <057601cf9c9c$7e798c80$7b6ca580$@reactor8.com> <CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
 <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 2 Oct 2014 19:30:51 -0400
Message-ID: <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
To: dev <dev@spark.apache.org>, 
	Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
Content-Type: multipart/alternative; boundary=f46d04388ee52e446f05047904f1
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d04388ee52e446f05047904f1
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Is there perhaps a way to define an AMI programmatically? Like, a
collection of base AMI id + list of required stuff to be installed + list
of required configuration changes. I=E2=80=99m guessing that=E2=80=99s what=
 people use
things like Puppet, Ansible, or maybe also AWS CloudFormation for, right?

If we could do something like that, then with every new release of Spark we
could quickly and easily create new AMIs that have everything we need.
spark-ec2 would only have to bring up the instances and do a minimal amount
of configuration, and the only thing we=E2=80=99d need to track in the Spar=
k repo
is the code that defines what goes on the AMI, as well as a list of the AMI
ids specific to each release.

I=E2=80=99m just thinking out loud here. Does this make sense?

Nate,

Any progress on your end with this work?

Nick
=E2=80=8B

On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
shivaram@eecs.berkeley.edu> wrote:

> It should be possible to improve cluster launch time if we are careful
> about what commands we run during setup. One way to do this would be to
> walk down the list of things we do for cluster initialization and see if
> there is anything we can do make things faster. Unfortunately this might =
be
> pretty time consuming, but I don't know of a better strategy. The place t=
o
> start would be the setup.sh file at
> https://github.com/mesos/spark-ec2/blob/v3/setup.sh
>
> Here are some things that take a lot of time and could be improved:
> 1. Creating swap partitions on all machines. We could check if there is a
> way to get EC2 to always mount a swap partition
> 2. Copying / syncing things across slaves. The copy-dir script is called
> too many times right now and each time it pauses for a few milliseconds
> between slaves [1]. This could be improved by removing unnecessary copies
> 3. We could make less frequently used modules like Tachyon, persistent hd=
fs
> not a part of the default setup.
>
> [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
>
> Thanks
> Shivaram
>
>
>
>
> On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
> > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <nate@reactor8.com> wrote=
:
> >
> > > Starting to work through some automation/config stuff for spark stack
> on
> > > EC2 with a project, will be focusing the work through the apache bigt=
op
> > > effort to start, can then share with spark community directly as thin=
gs
> > > progress if people are interested
> >
> >
> > Let us know how that goes. I'm definitely interested in hearing more.
> >
> > Nick
> >
>

--f46d04388ee52e446f05047904f1--

From dev-return-9665-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  2 23:44:23 2014
Return-Path: <dev-return-9665-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A72F217A35
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  2 Oct 2014 23:44:23 +0000 (UTC)
Received: (qmail 72879 invoked by uid 500); 2 Oct 2014 23:44:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72811 invoked by uid 500); 2 Oct 2014 23:44:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 72795 invoked by uid 99); 2 Oct 2014 23:44:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 23:44:22 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of davidrowe@gmail.com designates 209.85.216.46 as permitted sender)
Received: from [209.85.216.46] (HELO mail-qa0-f46.google.com) (209.85.216.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 02 Oct 2014 23:43:57 +0000
Received: by mail-qa0-f46.google.com with SMTP id w8so108511qac.33
        for <dev@spark.apache.org>; Thu, 02 Oct 2014 16:43:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=CHRK9Y/lyMV42L2lozfsSBNEgjQcedL6uGQXpgLTFvY=;
        b=Uvf9PxAmcIrDXX/Afu/GzB4GdBw8ssTaH8MCXC7ehhDT5tN7YiR0YDATDnt3fVjkQf
         LUgrwHP+4QBekg7wffJdYuTSQJCcoS+BE8mOsLkGcra7m9kasozXjzErsBTbu+tuwZdv
         Lh3YXC2IRh5pgO8rBJ3ChUnmXYymQj23+n3za0ylaAlUlfVh3U6ZpyK36TIuEB9nBhRx
         pLhmoRIcQZvkM9R3hcXXUMWNw18hZ5Y1GZrifgK8cY4+fmUx3l0tGgVPyG1O7ptszeUA
         Oovr6lF6G8Do6qUeNLRQdeCQhFEdoh7LPTE8lVxvysZUB+jjdOgBJHDRDmojeyRRMixm
         Upaw==
X-Received: by 10.229.236.8 with SMTP id ki8mr3208381qcb.12.1412293435878;
 Thu, 02 Oct 2014 16:43:55 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.93.113 with HTTP; Thu, 2 Oct 2014 16:43:35 -0700 (PDT)
In-Reply-To: <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
 <057601cf9c9c$7e798c80$7b6ca580$@reactor8.com> <CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
 <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com> <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
From: David Rowe <davidrowe@gmail.com>
Date: Fri, 3 Oct 2014 09:43:35 +1000
Message-ID: <CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>, 
	Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
Content-Type: multipart/alternative; boundary=001a1134b16290737c050479305d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134b16290737c050479305d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I think this is exactly what packer is for. See e.g.
http://www.packer.io/intro/getting-started/build-image.html

On a related note, the current AMI for hvm systems (e.g. m3.*, r3.*) has a
bad package for httpd, whcih causes ganglia not to start. For some reason I
can't get access to the raw AMI to fix it.

On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas <nicholas.chammas@gmail.co=
m
> wrote:

> Is there perhaps a way to define an AMI programmatically? Like, a
> collection of base AMI id + list of required stuff to be installed + list
> of required configuration changes. I=E2=80=99m guessing that=E2=80=99s wh=
at people use
> things like Puppet, Ansible, or maybe also AWS CloudFormation for, right?
>
> If we could do something like that, then with every new release of Spark =
we
> could quickly and easily create new AMIs that have everything we need.
> spark-ec2 would only have to bring up the instances and do a minimal amou=
nt
> of configuration, and the only thing we=E2=80=99d need to track in the Sp=
ark repo
> is the code that defines what goes on the AMI, as well as a list of the A=
MI
> ids specific to each release.
>
> I=E2=80=99m just thinking out loud here. Does this make sense?
>
> Nate,
>
> Any progress on your end with this work?
>
> Nick
> =E2=80=8B
>
> On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
> shivaram@eecs.berkeley.edu> wrote:
>
> > It should be possible to improve cluster launch time if we are careful
> > about what commands we run during setup. One way to do this would be to
> > walk down the list of things we do for cluster initialization and see i=
f
> > there is anything we can do make things faster. Unfortunately this migh=
t
> be
> > pretty time consuming, but I don't know of a better strategy. The place
> to
> > start would be the setup.sh file at
> > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
> >
> > Here are some things that take a lot of time and could be improved:
> > 1. Creating swap partitions on all machines. We could check if there is=
 a
> > way to get EC2 to always mount a swap partition
> > 2. Copying / syncing things across slaves. The copy-dir script is calle=
d
> > too many times right now and each time it pauses for a few milliseconds
> > between slaves [1]. This could be improved by removing unnecessary copi=
es
> > 3. We could make less frequently used modules like Tachyon, persistent
> hdfs
> > not a part of the default setup.
> >
> > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
> >
> > Thanks
> > Shivaram
> >
> >
> >
> >
> > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
> > nicholas.chammas@gmail.com> wrote:
> >
> > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <nate@reactor8.com>
> wrote:
> > >
> > > > Starting to work through some automation/config stuff for spark sta=
ck
> > on
> > > > EC2 with a project, will be focusing the work through the apache
> bigtop
> > > > effort to start, can then share with spark community directly as
> things
> > > > progress if people are interested
> > >
> > >
> > > Let us know how that goes. I'm definitely interested in hearing more.
> > >
> > > Nick
> > >
> >
>

--001a1134b16290737c050479305d--

From dev-return-9666-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 00:01:16 2014
Return-Path: <dev-return-9666-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E021C17AD7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 00:01:15 +0000 (UTC)
Received: (qmail 10324 invoked by uid 500); 3 Oct 2014 00:01:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10265 invoked by uid 500); 3 Oct 2014 00:01:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10254 invoked by uid 99); 3 Oct 2014 00:01:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 00:01:14 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [216.70.64.187] (HELO n60.mail01.mtsvc.net) (216.70.64.187)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 00:01:10 +0000
Received: from 173-11-124-254-sfba.hfc.comcastbusiness.net ([173.11.124.254]:61272 helo=NODBOT)
	by n60.mail01.mtsvc.net with esmtpa (Exim 4.72)
	(envelope-from <nate@reactor8.com>)
	id 1XZqIj-0000Aw-84; Thu, 02 Oct 2014 20:00:49 -0400
From: "Nate D'Amico" <nate@reactor8.com>
To: "'dev'" <dev@spark.apache.org>
Cc: "'Nicholas Chammas'" <nicholas.chammas@gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com> <057601cf9c9c$7e798c80$7b6ca580$@reactor8.com> <CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com> <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com> <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com> <CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
In-Reply-To: <CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
Subject: RE: EC2 clusters ready in launch time + 30 seconds
Date: Thu, 2 Oct 2014 17:00:44 -0700
Message-ID: <0e7001cfde9d$14f00620$3ed01260$@reactor8.com>
MIME-Version: 1.0
Content-Type: text/plain;
	charset="utf-8"
Content-Transfer-Encoding: quoted-printable
X-Mailer: Microsoft Outlook 14.0
Thread-Index: AQILQtTfQ5EDkfN70khtIOqVZr1+XwKu2jH6AbNQW+kCRBjttwF4BhfsAYA+rmObWbxeUA==
Content-Language: en-us
X-Authenticated-User: 917868 nate@reactor8.com
X-MT-ID: 3CB1E6102B94980D10544FA93FD5F01BC02E0A63
X-Virus-Checked: Checked by ClamAV on apache.org

Bit of progress on our end, bit of lagging as well.  Our guy leading =
effort got little bogged down on client project to update hive/sql =
testbed to latest spark/sparkSQL, also launching public service so we =
have been bit scattered recently.

Will have some more updates probably after next week.  We are planning =
on taking our client work around hive/spark, plus taking over the bigtop =
automation work to modernize and get that fit for human consumption =
outside or org.  All our work and puppet modules will be open sourced, =
documented, hopefully start to rally some other folks around effort that =
find it useful

Side note, another effort we are looking into is gradle tests/support.  =
We have been leveraging serverspec for some basic infrastructure tests, =
but with bigtop switching over to gradle builds/testing setup in 0.8 we =
want to include support for that in our own efforts, probably some stuff =
that can be learned and leveraged in spark world for repeatable/tested =
infrastructure=20

If anyone has any specific automation questions to your environment you =
can drop me a line directly.., will try to help out best I can.  Else =
will post update to dev list once we get on top of our own product =
release and the bigtop work

Nate


-----Original Message-----
From: David Rowe [mailto:davidrowe@gmail.com]=20
Sent: Thursday, October 02, 2014 4:44 PM
To: Nicholas Chammas
Cc: dev; Shivaram Venkataraman
Subject: Re: EC2 clusters ready in launch time + 30 seconds

I think this is exactly what packer is for. See e.g.
http://www.packer.io/intro/getting-started/build-image.html

On a related note, the current AMI for hvm systems (e.g. m3.*, r3.*) has =
a bad package for httpd, whcih causes ganglia not to start. For some =
reason I can't get access to the raw AMI to fix it.

On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas =
<nicholas.chammas@gmail.com
> wrote:

> Is there perhaps a way to define an AMI programmatically? Like, a=20
> collection of base AMI id + list of required stuff to be installed +=20
> list of required configuration changes. I=E2=80=99m guessing =
that=E2=80=99s what=20
> people use things like Puppet, Ansible, or maybe also AWS =
CloudFormation for, right?
>
> If we could do something like that, then with every new release of=20
> Spark we could quickly and easily create new AMIs that have everything =
we need.
> spark-ec2 would only have to bring up the instances and do a minimal=20
> amount of configuration, and the only thing we=E2=80=99d need to track =
in the=20
> Spark repo is the code that defines what goes on the AMI, as well as a =

> list of the AMI ids specific to each release.
>
> I=E2=80=99m just thinking out loud here. Does this make sense?
>
> Nate,
>
> Any progress on your end with this work?
>
> Nick
> =E2=80=8B
>
> On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <=20
> shivaram@eecs.berkeley.edu> wrote:
>
> > It should be possible to improve cluster launch time if we are=20
> > careful about what commands we run during setup. One way to do this=20
> > would be to walk down the list of things we do for cluster=20
> > initialization and see if there is anything we can do make things=20
> > faster. Unfortunately this might
> be
> > pretty time consuming, but I don't know of a better strategy. The=20
> > place
> to
> > start would be the setup.sh file at
> > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
> >
> > Here are some things that take a lot of time and could be improved:
> > 1. Creating swap partitions on all machines. We could check if there =

> > is a way to get EC2 to always mount a swap partition 2. Copying /=20
> > syncing things across slaves. The copy-dir script is called too many =

> > times right now and each time it pauses for a few milliseconds=20
> > between slaves [1]. This could be improved by removing unnecessary=20
> > copies 3. We could make less frequently used modules like Tachyon,=20
> > persistent
> hdfs
> > not a part of the default setup.
> >
> > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
> >
> > Thanks
> > Shivaram
> >
> >
> >
> >
> > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <=20
> > nicholas.chammas@gmail.com> wrote:
> >
> > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <nate@reactor8.com>
> wrote:
> > >
> > > > Starting to work through some automation/config stuff for spark=20
> > > > stack
> > on
> > > > EC2 with a project, will be focusing the work through the apache
> bigtop
> > > > effort to start, can then share with spark community directly as
> things
> > > > progress if people are interested
> > >
> > >
> > > Let us know how that goes. I'm definitely interested in hearing =
more.
> > >
> > > Nick
> > >
> >
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9667-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 00:24:15 2014
Return-Path: <dev-return-9667-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BE73F17B93
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 00:24:15 +0000 (UTC)
Received: (qmail 64025 invoked by uid 500); 3 Oct 2014 00:24:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63954 invoked by uid 500); 3 Oct 2014 00:24:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63942 invoked by uid 99); 3 Oct 2014 00:24:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 00:24:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.43 as permitted sender)
Received: from [74.125.82.43] (HELO mail-wg0-f43.google.com) (74.125.82.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 00:23:47 +0000
Received: by mail-wg0-f43.google.com with SMTP id m15so219617wgh.26
        for <dev@spark.apache.org>; Thu, 02 Oct 2014 17:23:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=HAzV2lme0YbK7PF9IGKfAa3yo60l008JLwmw3yDzCXE=;
        b=cuMCoRN0ESbpNpihVmdYOfbWfXscFtPKQd77iLMCS9OZeC7J90XjaF+yZkrdUhaMBe
         GwYQ76H5bMKqjP65fVNAtRJjvxtRjBkEa985oVr47OC3sujiCWxh5XKeVlCv+F4mF91M
         4B+/9voSxg9ihBhEthIZNc0neUwE5zHAK9iMrHdMd9bgssyoaJhp/wrJZLn4I6OJJ3BP
         6gqKCMXT/RkKm2fhAe7Z1G+7V2Nm0ApQ4iSFFI+va3CX6RmF9API1Gz1CgwA9aVTe/G+
         GWYXNIcjhjMVflH54SGu79iUMwPtzA8HOtyi8nwTO/lAre3o4bynXzNkaOZCZCpuOehk
         onVg==
X-Received: by 10.194.8.232 with SMTP id u8mr2908565wja.64.1412295827118; Thu,
 02 Oct 2014 17:23:47 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Thu, 2 Oct 2014 17:23:07 -0700 (PDT)
In-Reply-To: <0e7001cfde9d$14f00620$3ed01260$@reactor8.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
 <057601cf9c9c$7e798c80$7b6ca580$@reactor8.com> <CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
 <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
 <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
 <CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com> <0e7001cfde9d$14f00620$3ed01260$@reactor8.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 2 Oct 2014 20:23:07 -0400
Message-ID: <CAOhmDzcRM_Gn7KtBJDQm--ai_G-aZBX-oE3StcK+686Y3+Jgeg@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
To: "Nate D'Amico" <nate@reactor8.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b5d348c17defc050479bf85
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d348c17defc050479bf85
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks for the update, Nate. I'm looking forward to seeing how these
projects turn out.

David, Packer looks very, very interesting. I'm gonna look into it more
next week.

Nick


On Thu, Oct 2, 2014 at 8:00 PM, Nate D'Amico <nate@reactor8.com> wrote:

> Bit of progress on our end, bit of lagging as well.  Our guy leading
> effort got little bogged down on client project to update hive/sql testbe=
d
> to latest spark/sparkSQL, also launching public service so we have been b=
it
> scattered recently.
>
> Will have some more updates probably after next week.  We are planning on
> taking our client work around hive/spark, plus taking over the bigtop
> automation work to modernize and get that fit for human consumption outsi=
de
> or org.  All our work and puppet modules will be open sourced, documented=
,
> hopefully start to rally some other folks around effort that find it usef=
ul
>
> Side note, another effort we are looking into is gradle tests/support.  W=
e
> have been leveraging serverspec for some basic infrastructure tests, but
> with bigtop switching over to gradle builds/testing setup in 0.8 we want =
to
> include support for that in our own efforts, probably some stuff that can
> be learned and leveraged in spark world for repeatable/tested infrastruct=
ure
>
> If anyone has any specific automation questions to your environment you
> can drop me a line directly.., will try to help out best I can.  Else wil=
l
> post update to dev list once we get on top of our own product release and
> the bigtop work
>
> Nate
>
>
> -----Original Message-----
> From: David Rowe [mailto:davidrowe@gmail.com]
> Sent: Thursday, October 02, 2014 4:44 PM
> To: Nicholas Chammas
> Cc: dev; Shivaram Venkataraman
> Subject: Re: EC2 clusters ready in launch time + 30 seconds
>
> I think this is exactly what packer is for. See e.g.
> http://www.packer.io/intro/getting-started/build-image.html
>
> On a related note, the current AMI for hvm systems (e.g. m3.*, r3.*) has =
a
> bad package for httpd, whcih causes ganglia not to start. For some reason=
 I
> can't get access to the raw AMI to fix it.
>
> On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> > wrote:
>
> > Is there perhaps a way to define an AMI programmatically? Like, a
> > collection of base AMI id + list of required stuff to be installed +
> > list of required configuration changes. I=E2=80=99m guessing that=E2=80=
=99s what
> > people use things like Puppet, Ansible, or maybe also AWS CloudFormatio=
n
> for, right?
> >
> > If we could do something like that, then with every new release of
> > Spark we could quickly and easily create new AMIs that have everything
> we need.
> > spark-ec2 would only have to bring up the instances and do a minimal
> > amount of configuration, and the only thing we=E2=80=99d need to track =
in the
> > Spark repo is the code that defines what goes on the AMI, as well as a
> > list of the AMI ids specific to each release.
> >
> > I=E2=80=99m just thinking out loud here. Does this make sense?
> >
> > Nate,
> >
> > Any progress on your end with this work?
> >
> > Nick
> > =E2=80=8B
> >
> > On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
> > shivaram@eecs.berkeley.edu> wrote:
> >
> > > It should be possible to improve cluster launch time if we are
> > > careful about what commands we run during setup. One way to do this
> > > would be to walk down the list of things we do for cluster
> > > initialization and see if there is anything we can do make things
> > > faster. Unfortunately this might
> > be
> > > pretty time consuming, but I don't know of a better strategy. The
> > > place
> > to
> > > start would be the setup.sh file at
> > > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
> > >
> > > Here are some things that take a lot of time and could be improved:
> > > 1. Creating swap partitions on all machines. We could check if there
> > > is a way to get EC2 to always mount a swap partition 2. Copying /
> > > syncing things across slaves. The copy-dir script is called too many
> > > times right now and each time it pauses for a few milliseconds
> > > between slaves [1]. This could be improved by removing unnecessary
> > > copies 3. We could make less frequently used modules like Tachyon,
> > > persistent
> > hdfs
> > > not a part of the default setup.
> > >
> > > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
> > >
> > > Thanks
> > > Shivaram
> > >
> > >
> > >
> > >
> > > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
> > > nicholas.chammas@gmail.com> wrote:
> > >
> > > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <nate@reactor8.com>
> > wrote:
> > > >
> > > > > Starting to work through some automation/config stuff for spark
> > > > > stack
> > > on
> > > > > EC2 with a project, will be focusing the work through the apache
> > bigtop
> > > > > effort to start, can then share with spark community directly as
> > things
> > > > > progress if people are interested
> > > >
> > > >
> > > > Let us know how that goes. I'm definitely interested in hearing mor=
e.
> > > >
> > > > Nick
> > > >
> > >
> >
>
>

--047d7b5d348c17defc050479bf85--

From dev-return-9668-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 00:37:37 2014
Return-Path: <dev-return-9668-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AD7EE17C12
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 00:37:37 +0000 (UTC)
Received: (qmail 83041 invoked by uid 500); 3 Oct 2014 00:37:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82966 invoked by uid 500); 3 Oct 2014 00:37:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82953 invoked by uid 99); 3 Oct 2014 00:37:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 00:37:35 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 00:37:30 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XZqru-0008OJ-9Q
	for dev@spark.incubator.apache.org; Thu, 02 Oct 2014 17:37:10 -0700
Date: Thu, 2 Oct 2014 17:37:10 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1412296630273-8638.post@n3.nabble.com>
Subject: What is the best way to build my developing Spark for testing on
 EC2?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all, 

I am trying to contribute some machine learning algorithms to MLlib. 
I must evaluate their performance on a cluster, changing input data 
size, the number of CPU cores and any their parameters.

I would like to build my develoipng Spark on EC2 automatically. 
Is there already a building script for a developing version like spark-ec2
script?
Or if you have any good idea to evaluate the performance of a developing 
MLlib algorithm on a spark cluster like EC2, could you tell me?

Best,



-----
-- Yu Ishikawa
--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/What-is-the-best-way-to-build-my-developing-Spark-for-testing-on-EC2-tp8638.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9669-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 00:53:40 2014
Return-Path: <dev-return-9669-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3EA9017C84
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 00:53:40 +0000 (UTC)
Received: (qmail 98455 invoked by uid 500); 3 Oct 2014 00:53:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98382 invoked by uid 500); 3 Oct 2014 00:53:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98370 invoked by uid 99); 3 Oct 2014 00:53:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 00:53:38 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of evan.sparks@gmail.com designates 209.85.192.42 as permitted sender)
Received: from [209.85.192.42] (HELO mail-qg0-f42.google.com) (209.85.192.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 00:53:12 +0000
Received: by mail-qg0-f42.google.com with SMTP id z60so211191qgd.1
        for <dev@spark.incubator.apache.org>; Thu, 02 Oct 2014 17:53:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=hjzLGc6Rfq+CubMV2GTj49VSSZKXSO4d6baAyuQupJY=;
        b=lYM7DYC96CWW5mrSdJOf+SU3rigqwMc/0t5LIzMx1/+95Ij5OcpzjfhxLyeSn4apts
         38U7ffu4o8S2H+xcioStgEO8FgQnUGsmaYKhRHdcDuh9em9+EbvL4lrhA0bX4GjSQrLR
         UhaUfd6EWqkh8nAbntIazOkowm2zZ3n23PMzsof6FC+vB3MYaL4GbDThUEdh9JqRHEjI
         CMkC6KpbeBHQgpLEiVW9g3uVng4fOh/y4uylD2/uNRPUSD7AdPGSns38Om9waNbrOIt+
         NEEWFSnNgLJajH6BuPQ/VyOSKSciet25pHw6LbwMFzlQ3cqpX+EuSgcerRHwhFlqneX6
         mQKQ==
X-Received: by 10.140.41.228 with SMTP id z91mr509683qgz.99.1412297590851;
        Thu, 02 Oct 2014 17:53:10 -0700 (PDT)
Received: from [10.0.1.116] (c-50-184-126-67.hsd1.ca.comcast.net. [50.184.126.67])
        by mx.google.com with ESMTPSA id r19sm3416292obt.26.2014.10.02.17.53.10
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 02 Oct 2014 17:53:10 -0700 (PDT)
Content-Type: text/plain;
	charset=us-ascii
Mime-Version: 1.0 (1.0)
Subject: Re: What is the best way to build my developing Spark for testing on EC2?
From: Evan Sparks <evan.sparks@gmail.com>
X-Mailer: iPhone Mail (11D257)
In-Reply-To: <1412296630273-8638.post@n3.nabble.com>
Date: Thu, 2 Oct 2014 17:53:10 -0700
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <B641E8B6-6610-439E-B7F9-48698A15E65B@gmail.com>
References: <1412296630273-8638.post@n3.nabble.com>
To: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org

I recommend using the data generators provided with MLlib to generate synthe=
tic data for your scalability tests - provided they're well suited for your a=
lgorithms. They let you control things like number of examples and dimension=
ality of your dataset, as well as number of partitions.=20

As far as cluster set up goes, I usually launch spot instances with the spar=
k-ec2 scripts, and then check out a repo which contains a simple driver appl=
ication for my code. Then I have something crude like bash scripts running m=
y program and collecting output.=20

You could have a look at the spark-perf repo if you want something a little b=
etter principled/automatic.=20

- Evan

> On Oct 2, 2014, at 5:37 PM, Yu Ishikawa <yuu.ishikawa+spark@gmail.com> wro=
te:
>=20
> Hi all,=20
>=20
> I am trying to contribute some machine learning algorithms to MLlib.=20
> I must evaluate their performance on a cluster, changing input data=20
> size, the number of CPU cores and any their parameters.
>=20
> I would like to build my develoipng Spark on EC2 automatically.=20
> Is there already a building script for a developing version like spark-ec2=

> script?
> Or if you have any good idea to evaluate the performance of a developing=20=

> MLlib algorithm on a spark cluster like EC2, could you tell me?
>=20
> Best,
>=20
>=20
>=20
> -----
> -- Yu Ishikawa
> --
> View this message in context: http://apache-spark-developers-list.1001551.=
n3.nabble.com/What-is-the-best-way-to-build-my-developing-Spark-for-testing-=
on-EC2-tp8638.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.=
com.
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9670-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 03:03:03 2014
Return-Path: <dev-return-9670-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8D80E17EBB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 03:03:03 +0000 (UTC)
Received: (qmail 51994 invoked by uid 500); 3 Oct 2014 03:03:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51844 invoked by uid 500); 3 Oct 2014 03:03:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50698 invoked by uid 99); 3 Oct 2014 03:03:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 03:03:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 03:02:32 +0000
Received: by mail-pa0-f54.google.com with SMTP id ey11so768583pad.27
        for <multiple recipients>; Thu, 02 Oct 2014 20:02:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type;
        bh=R1JtHawXZwKLugPUxlgtKV+4Hl9vGXM6oQz87fxHC5o=;
        b=LPDudb7ZKNZbM+qoYk+asfieCtYMmBOETWgphcISCtB7XbUWGCN0lvptKtDs2FaTJR
         lOV1Uteah6RH7ivFyUyiElI6emETPABywO6klbTLu9VJPwZkvZD2ySHHvzGuBk0mLYGd
         1ZHpsty9ism4wXQ3qQxW8PqRxxwrPXUJiA8+UN9U5PVRSwnaiWwUeX9DcijV3eDeSUbh
         csDz+fCZ4uIJYTGnp5z+B1V5GxWHIm+9kimL7/dytKzw1Z9LTP+SBYGh1Wdw1woOxspE
         rlMOOfIn4gBY3OXbUfjPSnUd0Lv14nRkq6ZoHmw9um3Dnj0mz+udRNIEjYdfcq6wfRk+
         Ne6A==
X-Received: by 10.68.132.105 with SMTP id ot9mr4216401pbb.76.1412305350908;
        Thu, 02 Oct 2014 20:02:30 -0700 (PDT)
Received: from lian-laptop.local ([114.96.154.120])
        by mx.google.com with ESMTPSA id h4sm5401794pat.11.2014.10.02.20.01.58
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 02 Oct 2014 20:02:00 -0700 (PDT)
Message-ID: <542E11A5.5010903@gmail.com>
Date: Fri, 03 Oct 2014 11:01:57 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: Du Li <lidu@yahoo-inc.com.INVALID>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
CC: "user@spark.apache.org" <user@spark.apache.org>
Subject: Re: HiveContext: cache table not supported for partitioned table?
References: <D052F7E8.434E%lidu@yahoo-inc.com>
In-Reply-To: <D052F7E8.434E%lidu@yahoo-inc.com>
Content-Type: multipart/alternative;
 boundary="------------060601040804030306080908"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------060601040804030306080908
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: 8bit

Cache table works with partitioned table.

I guess youre experimenting with a default local metastore and the 
metastore_db directory doesnt exist at the first place. In this case, 
all metastore tables/views dont exist at first and will throw the error 
message you saw when the |PARTITIONS| metastore table is accessed for 
the first time by Hive client. However, you should also see this line 
before this error:

    14/10/03 10:51:30 ERROR ObjectStore: Direct SQL failed, falling back
    to ORM

And then the table is created on the fly. The cache operation is also 
performed normally. You can verify this by selecting it and check the 
Spark UI for cached RDDs. If you try to uncache the table and cache it 
again, you wont see this error any more.

Normally, in production environment you wont see this error because 
metastore database is usually setup ahead of time.

On 10/3/14 3:39 AM, Du Li wrote:

> Hi,
>
> In Spark 1.1 HiveContext, I ran a create partitioned table command 
> followed by a cache table command and got 
> a java.sql.SQLSyntaxErrorException: Table/View 'PARTITIONS' does not 
> exist. But cache table worked fine if the table is not a partitioned 
> table.
>
> Can anybody confirm that cache of partitioned table is not supported 
> yet in current version?
>
> Thanks,
> Du



--------------060601040804030306080908--

From dev-return-9671-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 11:23:32 2014
Return-Path: <dev-return-9671-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B0A55179C0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 11:23:32 +0000 (UTC)
Received: (qmail 47632 invoked by uid 500); 3 Oct 2014 11:23:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47579 invoked by uid 500); 3 Oct 2014 11:23:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47128 invoked by uid 99); 3 Oct 2014 11:23:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 11:23:12 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of learnings.chitturi@gmail.com designates 209.85.192.46 as permitted sender)
Received: from [209.85.192.46] (HELO mail-qg0-f46.google.com) (209.85.192.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 11:22:46 +0000
Received: by mail-qg0-f46.google.com with SMTP id z60so748701qgd.33
        for <multiple recipients>; Fri, 03 Oct 2014 04:22:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=Hns6tEbZwAh4358h1laHUrfmImJ8WE6lQ25ckkTC9Nc=;
        b=aZUoWvEqX/hoYCMeh3Ip6+ElOijQBpP7DQ8nfPKH+0HQN3/srj7947e1/M4gd1URzK
         exCJDpXt1IrCKoXkSluf2LUY9a2Or2L0DyVegz9OemKvQ1/2ply4zi/F8wdFSht1JX2K
         0Zrg/l2ntYRRBjQKPxBKTSiE25vxcwuR6yRgt3lKx3gmgnB/PjE+FUz7zg3m0bPyYqCY
         6plUHbBlkocALdbY8Is8UZs/tNSotHglaCsapaMerKuvZBJj3TBWbg0lGoz5z0jxWjfS
         3N6JPYF8n/flHU8Y1r9XOyJEiYpKwLvV2CXDmfHpx/4FiYLaAb4BA9FpGEimOIDsngR9
         u3LQ==
MIME-Version: 1.0
X-Received: by 10.224.103.194 with SMTP id l2mr5944064qao.93.1412335364592;
 Fri, 03 Oct 2014 04:22:44 -0700 (PDT)
Received: by 10.229.133.142 with HTTP; Fri, 3 Oct 2014 04:22:44 -0700 (PDT)
Date: Fri, 3 Oct 2014 16:52:44 +0530
Message-ID: <CABXsDPrcHqwg0zPjgrenbOxWXQZtafTGEbmZ-4jir762VyM7gA@mail.gmail.com>
Subject: Breeze Library usage in Spark
From: Priya Ch <learnings.chitturi@gmail.com>
To: user@spark.apache.org, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c2c0c0b5db44050482f3d1
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2c0c0b5db44050482f3d1
Content-Type: text/plain; charset=UTF-8

Hi Team,

When I am trying to use DenseMatrix of breeze library in spark, its
throwing me the following error:

java.lang.noclassdeffounderror: breeze/storage/Zero


Can someone help me on this ?

Thanks,
Padma Ch

--001a11c2c0c0b5db44050482f3d1--

From dev-return-9672-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 16:46:09 2014
Return-Path: <dev-return-9672-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 417EF1765C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 16:46:09 +0000 (UTC)
Received: (qmail 93199 invoked by uid 500); 3 Oct 2014 16:46:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93090 invoked by uid 500); 3 Oct 2014 16:46:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92100 invoked by uid 99); 3 Oct 2014 16:46:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 16:46:07 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.213.180 as permitted sender)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 16:46:02 +0000
Received: by mail-ig0-f180.google.com with SMTP id uq10so3002189igb.13
        for <multiple recipients>; Fri, 03 Oct 2014 09:45:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=iauw6cux3m46E1AwG0onQLHHZjC2AdLs7YD1A5s/zD0=;
        b=o2y/JCrevGhjmfku10z5w0L8/ZmGMGjH8UcYTC/6vDbhc0nIpJHYoHY5sY5CeVo47W
         u0blk2BbCE7vT1T4K8DFhNCO+NtBjuqHCTGxtZ0gBNCrDkk+gkfB0Abocf8vTFLoPEvk
         q54TDGWHd+uOzNoeni3722RLWwN5kq2rkZtsciu35rt+LN94Hlno2swnI76yMhRQcXJX
         RGg44DswfojECagbDm2RSqEv4J/E5PQKib27sQxIPqgiR8xO1h2X+wba6l7ymHjmUrIR
         uDjqeX4trFlXAvg70uvuRaHcMSshfUr/A4OiGy+iw7Fkhp8wAAI0LW7/aStktrVXsWxu
         p94Q==
MIME-Version: 1.0
X-Received: by 10.51.17.66 with SMTP id gc2mr16357471igd.18.1412354741290;
 Fri, 03 Oct 2014 09:45:41 -0700 (PDT)
Received: by 10.107.152.3 with HTTP; Fri, 3 Oct 2014 09:45:41 -0700 (PDT)
In-Reply-To: <CABXsDPrcHqwg0zPjgrenbOxWXQZtafTGEbmZ-4jir762VyM7gA@mail.gmail.com>
References: <CABXsDPrcHqwg0zPjgrenbOxWXQZtafTGEbmZ-4jir762VyM7gA@mail.gmail.com>
Date: Fri, 3 Oct 2014 09:45:41 -0700
Message-ID: <CAJgQjQ9zT+SErQr8o-4tbpSX1wFrqziJy5JLe_2xt+OaOytwxA@mail.gmail.com>
Subject: Re: Breeze Library usage in Spark
From: Xiangrui Meng <mengxr@gmail.com>
To: Priya Ch <learnings.chitturi@gmail.com>
Cc: "user@spark.apache.org" <user@spark.apache.org>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Did you add a different version of breeze to the classpath? In Spark
1.0, we use breeze 0.7, and in Spark 1.1 we use 0.9. If the breeze
version you used is different from the one comes with Spark, you might
see class not found. -Xiangrui

On Fri, Oct 3, 2014 at 4:22 AM, Priya Ch <learnings.chitturi@gmail.com> wrote:
> Hi Team,
>
> When I am trying to use DenseMatrix of breeze library in spark, its throwing
> me the following error:
>
> java.lang.noclassdeffounderror: breeze/storage/Zero
>
>
> Can someone help me on this ?
>
> Thanks,
> Padma Ch
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9673-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 17:13:38 2014
Return-Path: <dev-return-9673-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 403CF1775A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 17:13:38 +0000 (UTC)
Received: (qmail 45895 invoked by uid 500); 3 Oct 2014 17:13:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45789 invoked by uid 500); 3 Oct 2014 17:13:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44864 invoked by uid 99); 3 Oct 2014 17:13:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 17:13:35 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: 216.145.54.172 is neither permitted nor denied by domain of lidu@yahoo-inc.com)
Received: from [216.145.54.172] (HELO mrout2.yahoo.com) (216.145.54.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 17:13:09 +0000
Received: from GQ1-EX10-CAHT23.y.corp.yahoo.com (gq1-ex10-caht23.corp.gq1.yahoo.com [10.73.73.233])
	by mrout2.yahoo.com (8.14.4/8.14.4/y.out) with ESMTP id s93HCZZQ089085
	(version=TLSv1/SSLv3 cipher=AES128-SHA bits=128 verify=FAIL);
	Fri, 3 Oct 2014 10:12:35 -0700 (PDT)
Received: from GQ1-MB05-02.y.corp.yahoo.com ([fe80::fd24:9461:3a25:f22]) by
 GQ1-EX10-CAHT23.y.corp.yahoo.com ([::1]) with mapi id 14.03.0195.001; Fri, 3
 Oct 2014 10:12:35 -0700
From: Du Li <lidu@yahoo-inc.com.INVALID>
To: Cheng Lian <lian.cs.zju@gmail.com>
CC: "user@spark.apache.org" <user@spark.apache.org>,
        "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: Re: HiveContext: cache table not supported for partitioned table?
Thread-Topic: HiveContext: cache table not supported for partitioned table?
Thread-Index: AQHP3niGg0DEZrvWA0ys/Cw4g5ugeJweJTCAgAB4UAA=
Date: Fri, 3 Oct 2014 17:12:34 +0000
Message-ID: <D05426E4.43B3%lidu@yahoo-inc.com>
References: <D052F7E8.434E%lidu@yahoo-inc.com> <542E11A5.5010903@gmail.com>
In-Reply-To: <542E11A5.5010903@gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.73.144.202]
Content-Type: multipart/alternative;
	boundary="_000_D05426E443B3liduyahooinccom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D05426E443B3liduyahooinccom_
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
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==

--_000_D05426E443B3liduyahooinccom_--

From dev-return-9674-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 17:31:48 2014
Return-Path: <dev-return-9674-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D6115177A8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 17:31:48 +0000 (UTC)
Received: (qmail 73460 invoked by uid 500); 3 Oct 2014 17:31:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73387 invoked by uid 500); 3 Oct 2014 17:31:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73369 invoked by uid 99); 3 Oct 2014 17:31:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 17:31:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of david.lw.hall@gmail.com designates 209.85.213.174 as permitted sender)
Received: from [209.85.213.174] (HELO mail-ig0-f174.google.com) (209.85.213.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 17:31:20 +0000
Received: by mail-ig0-f174.google.com with SMTP id l13so87644iga.13
        for <multiple recipients>; Fri, 03 Oct 2014 10:31:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=Tjb1y/WcIY4k4IGfzSIfWMZsQCR/zGaKcAIHAVYUdrM=;
        b=l4/Z2O7hqXcg8tLqhLZyVWgYq6P4spHFEb9Y70k+VHrmAVlkTaXkNKHv2Dv/h3UM/F
         5gvnbZuDp6J+/mIq2WosyOVSCSO0GvbIj5AcRplnquMd4IP7HbcnGkT7tqynlHWXt2u/
         F9utNZyE3h9KV8/VWeQVMOEtG+RBIPGAcuEFJXSE02MHywF9kWmVdtRZP+sfoKRKUm8y
         KnGorPUKKR6LthAvAHghrzvHmYPWwf0hiZ4MbdcQ6gpbXE6KXInIvSOOJcgr1H8TvrAm
         On2DellzIfaUNv6DLqcDgob2uNH++hU1NTB49lJrHkCLRDKKpVsazz5uMQO8pVjOXgP7
         F/Hg==
MIME-Version: 1.0
X-Received: by 10.50.32.2 with SMTP id e2mr650179igi.33.1412357479527; Fri, 03
 Oct 2014 10:31:19 -0700 (PDT)
Sender: david.lw.hall@gmail.com
Received: by 10.107.15.214 with HTTP; Fri, 3 Oct 2014 10:31:19 -0700 (PDT)
In-Reply-To: <CAJgQjQ9zT+SErQr8o-4tbpSX1wFrqziJy5JLe_2xt+OaOytwxA@mail.gmail.com>
References: <CABXsDPrcHqwg0zPjgrenbOxWXQZtafTGEbmZ-4jir762VyM7gA@mail.gmail.com>
	<CAJgQjQ9zT+SErQr8o-4tbpSX1wFrqziJy5JLe_2xt+OaOytwxA@mail.gmail.com>
Date: Fri, 3 Oct 2014 10:31:19 -0700
X-Google-Sender-Auth: ngssL7caqzTzxzxXRy5f-5D6LpU
Message-ID: <CALW2ey3JzezBm4jwdEXsxGxOmDaZN8XyabUy3PccH7Y6S96ENA@mail.gmail.com>
Subject: Re: Breeze Library usage in Spark
From: David Hall <dlwh@cs.berkeley.edu>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: Priya Ch <learnings.chitturi@gmail.com>, 
	"user@spark.apache.org" <user@spark.apache.org>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b10ce51dcfcd605048819a6
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b10ce51dcfcd605048819a6
Content-Type: text/plain; charset=UTF-8

yeah, breeze.storage.Zero was introduced in either 0.8 or 0.9.

On Fri, Oct 3, 2014 at 9:45 AM, Xiangrui Meng <mengxr@gmail.com> wrote:

> Did you add a different version of breeze to the classpath? In Spark
> 1.0, we use breeze 0.7, and in Spark 1.1 we use 0.9. If the breeze
> version you used is different from the one comes with Spark, you might
> see class not found. -Xiangrui
>
> On Fri, Oct 3, 2014 at 4:22 AM, Priya Ch <learnings.chitturi@gmail.com>
> wrote:
> > Hi Team,
> >
> > When I am trying to use DenseMatrix of breeze library in spark, its
> throwing
> > me the following error:
> >
> > java.lang.noclassdeffounderror: breeze/storage/Zero
> >
> >
> > Can someone help me on this ?
> >
> > Thanks,
> > Padma Ch
> >
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7b10ce51dcfcd605048819a6--

From dev-return-9675-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 17:52:01 2014
Return-Path: <dev-return-9675-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5DC8517845
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 17:52:01 +0000 (UTC)
Received: (qmail 25651 invoked by uid 500); 3 Oct 2014 17:52:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25580 invoked by uid 500); 3 Oct 2014 17:52:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25565 invoked by uid 99); 3 Oct 2014 17:52:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 17:52:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.52 as permitted sender)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 17:51:34 +0000
Received: by mail-la0-f52.google.com with SMTP id hz20so1515227lab.11
        for <dev@spark.apache.org>; Fri, 03 Oct 2014 10:51:33 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=9ty+4ZKhdqzw97Wzo1CHzuuFsGdUlRPoIHtn+ugmI40=;
        b=HDqPxsphjtBsUMufIGZfnjPzsmqyMJOzW+7RZbzWYdrw1dwSRBVvfp+9W4ftCeW3qC
         pN9scz6kWH+mnSo4y4DxVOp11EYXpwenSQL5H5vUiyx663cTYUPfQic+aXkzyEdQUjTm
         i2nRm66l3C0CE3nQPKhEGjXZmEV3k8xrQmpZ/5cXKU05M/AsFv+ZeqAuTBeAJsE6N5QX
         TSN5mx3mPmr/0nS77g0JTXEaQzwpO1mY+fNi7b69WYbvPIFBJ4MoSdRvgO6TdwjxtgTD
         fResYOB/Gr5cLPn2I4Mb8w33BfgAmMn3P1sfRYuqUbv7o2/wOzX234GQs/e/+cbJgrTL
         gGoQ==
X-Gm-Message-State: ALoCoQmNeXMXNf8NKrpAmso1M97yfPXFOXD17l0RzygXuLnZg0DY6m6ag7lK/eDqi46uuyWK9UVh
X-Received: by 10.112.83.235 with SMTP id t11mr4844780lby.101.1412358693223;
 Fri, 03 Oct 2014 10:51:33 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Fri, 3 Oct 2014 10:51:13 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 3 Oct 2014 10:51:13 -0700
Message-ID: <CACdU-dQxN4XaFz=edESfVsmQ932GrhYQ9LL8_uddsgDPXW3SKw@mail.gmail.com>
Subject: emergency jenkins restart -- massive security patch released
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a113460ce34901405048862cd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113460ce34901405048862cd
Content-Type: text/plain; charset=UTF-8

https://wiki.jenkins-ci.org/display/SECURITY/Jenkins+Security+Advisory+2014-10-01

there's some pretty big stuff that's been identified and we need to get
this upgraded asap.

i'll be killing off what's currently running, and will retrigger them all
once we're done.

sorry for the inconvenience.

shane

--001a113460ce34901405048862cd--

From dev-return-9676-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 17:55:05 2014
Return-Path: <dev-return-9676-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E459917855
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 17:55:04 +0000 (UTC)
Received: (qmail 36478 invoked by uid 500); 3 Oct 2014 17:55:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36412 invoked by uid 500); 3 Oct 2014 17:55:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36401 invoked by uid 99); 3 Oct 2014 17:55:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 17:55:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.49 as permitted sender)
Received: from [209.85.215.49] (HELO mail-la0-f49.google.com) (209.85.215.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 17:54:38 +0000
Received: by mail-la0-f49.google.com with SMTP id q1so1463493lam.8
        for <dev@spark.apache.org>; Fri, 03 Oct 2014 10:54:37 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=eC4FhcE+/5VAl+foJVGasguTqPaCqcbUBqcBOBnxQTQ=;
        b=AM0alDdE8lPUbbpmJ1RnOkSLaxrBH+HTqofijeSWpkpyYcwqQ7eyWfqn4O/kXiWTTq
         zK+WU4mXZVSjZmepP0dj5HoV9pV78T1cQRe2kuwdppzqE6BHi1JgrNlHo4+xg05eobsS
         0WV8vMZDNFo3PFBq7c6TFlLiU1H87b9ZiqSZeip6RgiZbrUlJVnWxi6Ocbd/yxWQNSDl
         TJUZnAGdw3vuikzdjRspk2KdTZfpTcIivx7S+oZ17eMbTyrs9wRo2ZlgdTTuhOI2UIIJ
         xnJrqDHzzjRjv/elTCzvHBZ33Ql32dLW1mmJBeI+Xqo7t10vX37BPHXlDxvnSGYzZhyC
         eZhA==
X-Gm-Message-State: ALoCoQm2vOkBQTQwjwG6ynteVT6Y/w6qPm8OukKGi7CQF0DOsNGF5QQsanK3z+DjReHExcSK5VT9
X-Received: by 10.112.144.228 with SMTP id sp4mr7426657lbb.54.1412358877419;
 Fri, 03 Oct 2014 10:54:37 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Fri, 3 Oct 2014 10:54:17 -0700 (PDT)
In-Reply-To: <CACdU-dQxN4XaFz=edESfVsmQ932GrhYQ9LL8_uddsgDPXW3SKw@mail.gmail.com>
References: <CACdU-dQxN4XaFz=edESfVsmQ932GrhYQ9LL8_uddsgDPXW3SKw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 3 Oct 2014 10:54:17 -0700
Message-ID: <CACdU-dSD1RtO5KWP8NZnv7XjpzU9VCeUfh1fbsyLi14nD+sMYg@mail.gmail.com>
Subject: Re: emergency jenkins restart -- massive security patch released
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=047d7b3a8f5a2f34020504886dfb
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a8f5a2f34020504886dfb
Content-Type: text/plain; charset=UTF-8

update complete.  i'm retriggering builds now.

On Fri, Oct 3, 2014 at 10:51 AM, shane knapp <sknapp@berkeley.edu> wrote:

>
> https://wiki.jenkins-ci.org/display/SECURITY/Jenkins+Security+Advisory+2014-10-01
>
> there's some pretty big stuff that's been identified and we need to get
> this upgraded asap.
>
> i'll be killing off what's currently running, and will retrigger them all
> once we're done.
>
> sorry for the inconvenience.
>
> shane
>

--047d7b3a8f5a2f34020504886dfb--

From dev-return-9677-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 18:04:44 2014
Return-Path: <dev-return-9677-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A1F51178C1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 18:04:44 +0000 (UTC)
Received: (qmail 75148 invoked by uid 500); 3 Oct 2014 18:04:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75064 invoked by uid 500); 3 Oct 2014 18:04:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74051 invoked by uid 99); 3 Oct 2014 18:04:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 18:04:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of learnings.chitturi@gmail.com designates 209.85.192.41 as permitted sender)
Received: from [209.85.192.41] (HELO mail-qg0-f41.google.com) (209.85.192.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 18:04:16 +0000
Received: by mail-qg0-f41.google.com with SMTP id f51so1329980qge.14
        for <multiple recipients>; Fri, 03 Oct 2014 11:04:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=a8K1IMdm9H9+i8X/6Erc9QM54EO6ksqZZ85v0z//FX0=;
        b=zpaFHx8nahGC5kvHlaQnkTpe6gyKINqYhkNYTGp3/5LR6zZIgeVezl2IMg662i8pcg
         WR2HyQz/VLQhl0pu/MfL/T9/5HS4QyN9b+vF9rzn9Sifx4unagv4wqagsQDhDb26u/zy
         LwLF32+Fj+Ts0k//BOdU6C8HyDa7KVGFnLXcbdmoXMBXB+SroVV2Jc9tJNIaNsMRDEwL
         /zzNb+AfhU/YJBKeqQLVwV4ZBPxebjtfIuctyHdfK+NByKJ6rvhuoEBDm5PcyVHpEXKg
         95aS1Cqwf+tgIQHINTe5FYnfpmXhJKAl/+t7WksLlur0zoqQ3aLFoD8ofxnsXA/4YruU
         Lokg==
MIME-Version: 1.0
X-Received: by 10.224.67.65 with SMTP id q1mr9490330qai.89.1412359454891; Fri,
 03 Oct 2014 11:04:14 -0700 (PDT)
Received: by 10.229.133.142 with HTTP; Fri, 3 Oct 2014 11:04:14 -0700 (PDT)
In-Reply-To: <CABXsDPpKTQJbjDsNWzfES1ZDBQcQ9QCNtUzAC8241_QXGT-Dkg@mail.gmail.com>
References: <CABXsDPrcHqwg0zPjgrenbOxWXQZtafTGEbmZ-4jir762VyM7gA@mail.gmail.com>
	<CAJgQjQ9zT+SErQr8o-4tbpSX1wFrqziJy5JLe_2xt+OaOytwxA@mail.gmail.com>
	<CALW2ey3JzezBm4jwdEXsxGxOmDaZN8XyabUy3PccH7Y6S96ENA@mail.gmail.com>
	<CABXsDPpKTQJbjDsNWzfES1ZDBQcQ9QCNtUzAC8241_QXGT-Dkg@mail.gmail.com>
Date: Fri, 3 Oct 2014 23:34:14 +0530
Message-ID: <CABXsDPqj2Q5DAoRwBmTejPUr9grp3MjrtEUjdbUph8hcPUynpw@mail.gmail.com>
Subject: Fwd: Breeze Library usage in Spark
From: Priya Ch <learnings.chitturi@gmail.com>
To: user@spark.apache.org, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c3d2fe9ab1e40504888fd8
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3d2fe9ab1e40504888fd8
Content-Type: text/plain; charset=UTF-8

yes. I have included breeze-0.9 in build.sbt file. I ll change this to 0.7.
Apart from this, do we need to include breeze jars explicitly in the spark
context as sc.addJar() ? and what about the dependencies
netlib-native_ref-linux-
      x86_64-1.1-natives.jar,
netlib-native_system-linux-x86_64-1.1-natives.jar ? Need to be included in
classpath ?

On Fri, Oct 3, 2014 at 11:01 PM, David Hall <dlwh@cs.berkeley.edu> wrote:

> yeah, breeze.storage.Zero was introduced in either 0.8 or 0.9.
>
> On Fri, Oct 3, 2014 at 9:45 AM, Xiangrui Meng <mengxr@gmail.com> wrote:
>
>> Did you add a different version of breeze to the classpath? In Spark
>> 1.0, we use breeze 0.7, and in Spark 1.1 we use 0.9. If the breeze
>> version you used is different from the one comes with Spark, you might
>> see class not found. -Xiangrui
>>
>> On Fri, Oct 3, 2014 at 4:22 AM, Priya Ch <learnings.chitturi@gmail.com>
>> wrote:
>> > Hi Team,
>> >
>> > When I am trying to use DenseMatrix of breeze library in spark, its
>> throwing
>> > me the following error:
>> >
>> > java.lang.noclassdeffounderror: breeze/storage/Zero
>> >
>> >
>> > Can someone help me on this ?
>> >
>> > Thanks,
>> > Padma Ch
>> >
>> >
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>

--001a11c3d2fe9ab1e40504888fd8--

From dev-return-9678-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct  3 20:34:08 2014
Return-Path: <dev-return-9678-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1653D17ED4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri,  3 Oct 2014 20:34:08 +0000 (UTC)
Received: (qmail 46969 invoked by uid 500); 3 Oct 2014 20:34:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46899 invoked by uid 500); 3 Oct 2014 20:34:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46887 invoked by uid 99); 3 Oct 2014 20:34:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 20:34:06 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 03 Oct 2014 20:34:01 +0000
Received: by mail-ob0-f175.google.com with SMTP id wn1so1486236obc.34
        for <dev@spark.apache.org>; Fri, 03 Oct 2014 13:33:40 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=Qr2c7ebo1OVVdRDlAnqaBsee2JiBDSSJE5xQXbgPXuU=;
        b=dsI19ysiAdH3YaxAdWLzX01ditE9BPhAj6NtUhL79jGVBV4r9qxuOYeS1Egt3VNwxv
         +qYEbPr7hJLu0Rffm54g5WRcOLKgK3Eqh5WKlDP/kdzGCssUF6jt+KnyYMXJirMEIrwy
         MEhURFO5EAT+6ZEigp29y3xiMXlF93g+6+1uosaObtd4mcEL/IU8rvHxqwC5vdmAr5d0
         xI5gOC+JnKbFoif6zch9AecXaXPR6WJEDlBuxriGQxhShnYU4dB0+2YxWJ3VXtM7qE7D
         316vGryAyr9hs8PW+LtxC29erx8HB8a0k6NHFX9gmOJ+OMfLpDaAIeGK6+dW9MxHoso+
         nxuw==
X-Gm-Message-State: ALoCoQlXOVnh3KjUxUwjEnhB/GOX0sYfsyzVD+IJazY+p7IoVCkAiScJibvsUhL/9TWBaff8YGmM
MIME-Version: 1.0
X-Received: by 10.182.181.3 with SMTP id ds3mr9646360obc.11.1412368420182;
 Fri, 03 Oct 2014 13:33:40 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Fri, 3 Oct 2014 13:33:40 -0700 (PDT)
Date: Fri, 3 Oct 2014 15:33:40 -0500
Message-ID: <CAKWX9VWaNzDcHjxFC3XpwSG+bi7Y+bM2z1jo2g2D8kR1aFES6w@mail.gmail.com>
Subject: Parquet schema migrations
From: Cody Koeninger <cody@koeninger.org>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01182856fa59df05048aa5ba
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01182856fa59df05048aa5ba
Content-Type: text/plain; charset=UTF-8

Wondering if anyone has thoughts on a path forward for parquet schema
migrations, especially for people (like us) that are using raw parquet
files rather than Hive.

So far we've gotten away with reading old files, converting, and writing to
new directories, but that obviously becomes problematic above a certain
data size.

--089e01182856fa59df05048aa5ba--

From dev-return-9679-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct  4 00:21:58 2014
Return-Path: <dev-return-9679-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 67E3317827
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  4 Oct 2014 00:21:58 +0000 (UTC)
Received: (qmail 27326 invoked by uid 500); 4 Oct 2014 00:21:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27259 invoked by uid 500); 4 Oct 2014 00:21:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27245 invoked by uid 99); 4 Oct 2014 00:21:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 00:21:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.176 as permitted sender)
Received: from [209.85.212.176] (HELO mail-wi0-f176.google.com) (209.85.212.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 00:21:31 +0000
Received: by mail-wi0-f176.google.com with SMTP id hi2so249549wib.15
        for <dev@spark.apache.org>; Fri, 03 Oct 2014 17:21:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=ThWF6HlHTyGJszn0GGehBj6+JjSczhe530aCKbhZtmA=;
        b=t774Q4TmRK4kt/cjA7+KTFDD8dDG1QEOO3yI/QKV6BjXQ/hRsWA6jeNTYFVjJO3AJp
         Gy+fYUb/coQVgFOmGmLDL392wKMO3+lqRhcaf/Rbrg2CCwzJQO2Wuu0AHc57lVIVpUyv
         PNdP0L/nxwJXVZaR2Oqf337oDZ98ku8hhR2Qyo4Po+TBQjHMMGNWcGbh1EzLy08epnWA
         uI63rI8X9RLMtw9BnW1d3QBOWA7osAHcrjhQ5dp2xFqkmUjJqYxdbyT9A8YmMKC9YAjR
         tNGdkZ3u0hS9gL/L1Ng4WsSPxNl+MZZd173yX9ZNWSGhS/XswsQ7ANLdOkbRTUqn8yLF
         DmSw==
X-Received: by 10.180.20.69 with SMTP id l5mr1844492wie.45.1412382091069; Fri,
 03 Oct 2014 17:21:31 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Fri, 3 Oct 2014 17:20:50 -0700 (PDT)
In-Reply-To: <CAOhmDzcRM_Gn7KtBJDQm--ai_G-aZBX-oE3StcK+686Y3+Jgeg@mail.gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
 <057601cf9c9c$7e798c80$7b6ca580$@reactor8.com> <CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
 <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
 <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
 <CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
 <0e7001cfde9d$14f00620$3ed01260$@reactor8.com> <CAOhmDzcRM_Gn7KtBJDQm--ai_G-aZBX-oE3StcK+686Y3+Jgeg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Fri, 3 Oct 2014 20:20:50 -0400
Message-ID: <CAOhmDzeP0RobdLjiZzeqb8T2wnTLbN1Gvh2t+cnRGYcVUK2KOQ@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
To: "Nate D'Amico" <nate@reactor8.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec53f35f9d3502705048dd49c
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53f35f9d3502705048dd49c
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

FYI: There is an existing issue -- SPARK-3314
<https://issues.apache.org/jira/browse/SPARK-3314> -- about scripting the
creation of Spark AMIs.

With Packer, it looks like we may be able to script the creation of
multiple image types (VMWare, GCE, AMI, Docker, etc...) at once from a
single Packer template. That's very cool.

I'll be looking into this.

Nick


On Thu, Oct 2, 2014 at 8:23 PM, Nicholas Chammas <nicholas.chammas@gmail.co=
m
> wrote:

> Thanks for the update, Nate. I'm looking forward to seeing how these
> projects turn out.
>
> David, Packer looks very, very interesting. I'm gonna look into it more
> next week.
>
> Nick
>
>
> On Thu, Oct 2, 2014 at 8:00 PM, Nate D'Amico <nate@reactor8.com> wrote:
>
>> Bit of progress on our end, bit of lagging as well.  Our guy leading
>> effort got little bogged down on client project to update hive/sql testb=
ed
>> to latest spark/sparkSQL, also launching public service so we have been =
bit
>> scattered recently.
>>
>> Will have some more updates probably after next week.  We are planning o=
n
>> taking our client work around hive/spark, plus taking over the bigtop
>> automation work to modernize and get that fit for human consumption outs=
ide
>> or org.  All our work and puppet modules will be open sourced, documente=
d,
>> hopefully start to rally some other folks around effort that find it use=
ful
>>
>> Side note, another effort we are looking into is gradle tests/support.
>> We have been leveraging serverspec for some basic infrastructure tests, =
but
>> with bigtop switching over to gradle builds/testing setup in 0.8 we want=
 to
>> include support for that in our own efforts, probably some stuff that ca=
n
>> be learned and leveraged in spark world for repeatable/tested infrastruc=
ture
>>
>> If anyone has any specific automation questions to your environment you
>> can drop me a line directly.., will try to help out best I can.  Else wi=
ll
>> post update to dev list once we get on top of our own product release an=
d
>> the bigtop work
>>
>> Nate
>>
>>
>> -----Original Message-----
>> From: David Rowe [mailto:davidrowe@gmail.com]
>> Sent: Thursday, October 02, 2014 4:44 PM
>> To: Nicholas Chammas
>> Cc: dev; Shivaram Venkataraman
>> Subject: Re: EC2 clusters ready in launch time + 30 seconds
>>
>> I think this is exactly what packer is for. See e.g.
>> http://www.packer.io/intro/getting-started/build-image.html
>>
>> On a related note, the current AMI for hvm systems (e.g. m3.*, r3.*) has
>> a bad package for httpd, whcih causes ganglia not to start. For some rea=
son
>> I can't get access to the raw AMI to fix it.
>>
>> On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas <
>> nicholas.chammas@gmail.com
>> > wrote:
>>
>> > Is there perhaps a way to define an AMI programmatically? Like, a
>> > collection of base AMI id + list of required stuff to be installed +
>> > list of required configuration changes. I=E2=80=99m guessing that=E2=
=80=99s what
>> > people use things like Puppet, Ansible, or maybe also AWS
>> CloudFormation for, right?
>> >
>> > If we could do something like that, then with every new release of
>> > Spark we could quickly and easily create new AMIs that have everything
>> we need.
>> > spark-ec2 would only have to bring up the instances and do a minimal
>> > amount of configuration, and the only thing we=E2=80=99d need to track=
 in the
>> > Spark repo is the code that defines what goes on the AMI, as well as a
>> > list of the AMI ids specific to each release.
>> >
>> > I=E2=80=99m just thinking out loud here. Does this make sense?
>> >
>> > Nate,
>> >
>> > Any progress on your end with this work?
>> >
>> > Nick
>> > =E2=80=8B
>> >
>> > On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
>> > shivaram@eecs.berkeley.edu> wrote:
>> >
>> > > It should be possible to improve cluster launch time if we are
>> > > careful about what commands we run during setup. One way to do this
>> > > would be to walk down the list of things we do for cluster
>> > > initialization and see if there is anything we can do make things
>> > > faster. Unfortunately this might
>> > be
>> > > pretty time consuming, but I don't know of a better strategy. The
>> > > place
>> > to
>> > > start would be the setup.sh file at
>> > > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
>> > >
>> > > Here are some things that take a lot of time and could be improved:
>> > > 1. Creating swap partitions on all machines. We could check if there
>> > > is a way to get EC2 to always mount a swap partition 2. Copying /
>> > > syncing things across slaves. The copy-dir script is called too many
>> > > times right now and each time it pauses for a few milliseconds
>> > > between slaves [1]. This could be improved by removing unnecessary
>> > > copies 3. We could make less frequently used modules like Tachyon,
>> > > persistent
>> > hdfs
>> > > not a part of the default setup.
>> > >
>> > > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
>> > >
>> > > Thanks
>> > > Shivaram
>> > >
>> > >
>> > >
>> > >
>> > > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
>> > > nicholas.chammas@gmail.com> wrote:
>> > >
>> > > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <nate@reactor8.com>
>> > wrote:
>> > > >
>> > > > > Starting to work through some automation/config stuff for spark
>> > > > > stack
>> > > on
>> > > > > EC2 with a project, will be focusing the work through the apache
>> > bigtop
>> > > > > effort to start, can then share with spark community directly as
>> > things
>> > > > > progress if people are interested
>> > > >
>> > > >
>> > > > Let us know how that goes. I'm definitely interested in hearing
>> more.
>> > > >
>> > > > Nick
>> > > >
>> > >
>> >
>>
>>
>

--bcaec53f35f9d3502705048dd49c--

From dev-return-9680-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct  4 05:27:41 2014
Return-Path: <dev-return-9680-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4E8A217D86
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  4 Oct 2014 05:27:41 +0000 (UTC)
Received: (qmail 19175 invoked by uid 500); 4 Oct 2014 05:27:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19108 invoked by uid 500); 4 Oct 2014 05:27:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19070 invoked by uid 99); 4 Oct 2014 05:27:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 05:27:39 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.216.170] (HELO mail-qc0-f170.google.com) (209.85.216.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 05:27:14 +0000
Received: by mail-qc0-f170.google.com with SMTP id m20so2054097qcx.29
        for <dev@spark.apache.org>; Fri, 03 Oct 2014 22:27:12 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:sender:in-reply-to
         :references:date:message-id:subject:from:to:cc:content-type;
        bh=9DNAg5cU3yoghE8ItZEAWwd26aDCYx8p2aakW3lvao4=;
        b=nAViH/aFyNbGtnMz2HmRfBS1cHPy9rBqENo1h2lQ1GhsVGj9tI9ZUwGZB3v+jEg6wx
         zkTZuMIcJyY+hcBulpXLso3YkD9O4lr4LNgztP+ZLP//buh1oqspSwY8g+7sb9P/sVJc
         6PsZi9hA5QX9dB/Ce/lNTIsZXbDLmYWWiRZ35HpoL5RCdLiwb6kao0wc69qUqxYMd2+N
         QKsa0GsmInxZrZS/mpT/nsm8afoHYvabwSQALBenq4T99x2lMio5bmsTMz383gDf7k8k
         zUX/ABzU2roKt5G7gQoPBDusqJ2zHYYuhjoQBP+7mfvFTyVHXm2D84NCc2U+fwZpuv1l
         IXQw==
X-Gm-Message-State: ALoCoQm/KY3er15RUHChOwaf1cDqUzJyAEljO9r+l9Xn0BNsX+6BdF5DNTYLDR41xIBmYwfP/GFv
MIME-Version: 1.0
X-Received: by 10.140.97.9 with SMTP id l9mr11049184qge.7.1412400432915; Fri,
 03 Oct 2014 22:27:12 -0700 (PDT)
Reply-To: dbtsai@dbtsai.com
Sender: dbtsai@dbtsai.com
Received: by 10.229.12.73 with HTTP; Fri, 3 Oct 2014 22:27:12 -0700 (PDT)
Received: by 10.229.12.73 with HTTP; Fri, 3 Oct 2014 22:27:12 -0700 (PDT)
In-Reply-To: <CABXsDPqj2Q5DAoRwBmTejPUr9grp3MjrtEUjdbUph8hcPUynpw@mail.gmail.com>
References: <CABXsDPrcHqwg0zPjgrenbOxWXQZtafTGEbmZ-4jir762VyM7gA@mail.gmail.com>
	<CAJgQjQ9zT+SErQr8o-4tbpSX1wFrqziJy5JLe_2xt+OaOytwxA@mail.gmail.com>
	<CALW2ey3JzezBm4jwdEXsxGxOmDaZN8XyabUy3PccH7Y6S96ENA@mail.gmail.com>
	<CABXsDPpKTQJbjDsNWzfES1ZDBQcQ9QCNtUzAC8241_QXGT-Dkg@mail.gmail.com>
	<CABXsDPqj2Q5DAoRwBmTejPUr9grp3MjrtEUjdbUph8hcPUynpw@mail.gmail.com>
Date: Sat, 4 Oct 2014 07:27:12 +0200
X-Google-Sender-Auth: eSK_U7q-keNr78ed-w2in2tQxBE
Message-ID: <CAEYYnxaVzrbfZjwjUAjPUw560xY0hV7e2ESg8ihpsSFxkrszTw@mail.gmail.com>
Subject: Re: Fwd: Breeze Library usage in Spark
From: DB Tsai <dbtsai@dbtsai.com>
To: Priya Ch <learnings.chitturi@gmail.com>
Cc: dev@spark.apache.org, user@spark.apache.org
Content-Type: multipart/alternative; boundary=001a113a977c15c8550504921aeb
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a977c15c8550504921aeb
Content-Type: text/plain; charset=UTF-8

You dont have to include breeze jar which is already in spark assembly jar.
For native one, its optional.

Sent from my Google Nexus 5
On Oct 3, 2014 8:04 PM, "Priya Ch" <learnings.chitturi@gmail.com> wrote:

>
>
>
> yes. I have included breeze-0.9 in build.sbt file. I ll change this to
> 0.7. Apart from this, do we need to include breeze jars explicitly in the
> spark context as sc.addJar() ? and what about the dependencies
> netlib-native_ref-linux-
>       x86_64-1.1-natives.jar,
> netlib-native_system-linux-x86_64-1.1-natives.jar ? Need to be included in
> classpath ?
>
> On Fri, Oct 3, 2014 at 11:01 PM, David Hall <dlwh@cs.berkeley.edu> wrote:
>
>> yeah, breeze.storage.Zero was introduced in either 0.8 or 0.9.
>>
>> On Fri, Oct 3, 2014 at 9:45 AM, Xiangrui Meng <mengxr@gmail.com> wrote:
>>
>>> Did you add a different version of breeze to the classpath? In Spark
>>> 1.0, we use breeze 0.7, and in Spark 1.1 we use 0.9. If the breeze
>>> version you used is different from the one comes with Spark, you might
>>> see class not found. -Xiangrui
>>>
>>> On Fri, Oct 3, 2014 at 4:22 AM, Priya Ch <learnings.chitturi@gmail.com>
>>> wrote:
>>> > Hi Team,
>>> >
>>> > When I am trying to use DenseMatrix of breeze library in spark, its
>>> throwing
>>> > me the following error:
>>> >
>>> > java.lang.noclassdeffounderror: breeze/storage/Zero
>>> >
>>> >
>>> > Can someone help me on this ?
>>> >
>>> > Thanks,
>>> > Padma Ch
>>> >
>>> >
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>
>>
>
>

--001a113a977c15c8550504921aeb--

From dev-return-9681-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct  4 06:49:26 2014
Return-Path: <dev-return-9681-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 66E2517E4B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  4 Oct 2014 06:49:26 +0000 (UTC)
Received: (qmail 61036 invoked by uid 500); 4 Oct 2014 06:49:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60961 invoked by uid 500); 4 Oct 2014 06:49:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60949 invoked by uid 99); 4 Oct 2014 06:49:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 06:49:25 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.171 as permitted sender)
Received: from [209.85.214.171] (HELO mail-ob0-f171.google.com) (209.85.214.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 06:49:21 +0000
Received: by mail-ob0-f171.google.com with SMTP id va2so1904838obc.30
        for <dev@spark.apache.org>; Fri, 03 Oct 2014 23:49:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=KPW0siyK0uhQcuM7ZWUsignBIJaSsuLSGZ8CeBs+CAQ=;
        b=gTLc5iVclEf9OCshOnKyVkTa2A9vLjSRlh/kjsyBx5YELB0s4vzzN+7Vf9ZTRK0yXS
         DNvB1jvnXXX2UZSqZydnXzXoh2nrpEm27772aMJOcxU9MNImAKkR9cBYPFv48GZGJvHp
         GTX6XCoBt+L+0hsOSb80XS7gzHVdDSa8FLJwDPljSZUBnWx2Bf1fuq0oD0pSlxoxnmbg
         8e5FQ7pJ9SaVCzRkGLmlEjQYjS/8O6TAgRoY4ni5WNlzcu/g5YWzEysPhNun32n9Ten1
         YaSXhXTRcd1oBuBrXmziEjimxrwTs7q0cKYSUeYOyI17pDoNfuI3MBdWEC4NdHHwklvH
         WLDA==
MIME-Version: 1.0
X-Received: by 10.182.142.67 with SMTP id ru3mr12275780obb.15.1412405340835;
 Fri, 03 Oct 2014 23:49:00 -0700 (PDT)
Received: by 10.202.56.213 with HTTP; Fri, 3 Oct 2014 23:49:00 -0700 (PDT)
In-Reply-To: <CAOhmDzeP0RobdLjiZzeqb8T2wnTLbN1Gvh2t+cnRGYcVUK2KOQ@mail.gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
	<057601cf9c9c$7e798c80$7b6ca580$@reactor8.com>
	<CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
	<CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
	<CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
	<CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
	<0e7001cfde9d$14f00620$3ed01260$@reactor8.com>
	<CAOhmDzcRM_Gn7KtBJDQm--ai_G-aZBX-oE3StcK+686Y3+Jgeg@mail.gmail.com>
	<CAOhmDzeP0RobdLjiZzeqb8T2wnTLbN1Gvh2t+cnRGYcVUK2KOQ@mail.gmail.com>
Date: Fri, 3 Oct 2014 23:49:00 -0700
Message-ID: <CABPQxstH2DLuc2e3woy-1Zx7eA7Pcrc=e2PuGtvLJvPbzbtDJA@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: "Nate D'Amico" <nate@reactor8.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey All,

Just a couple notes. I recently posted a shell script for creating the
AMI's from a clean Amazon Linux AMI.

https://github.com/mesos/spark-ec2/blob/v3/create_image.sh

I think I will update the AMI's soon to get the most recent security
updates. For spark-ec2's purpose this is probably sufficient (we'll
only need to re-create them every few months).

However, it would be cool if someone wanted to tackle providing a more
general mechanism for defining Spark-friendly "images" that can be
used more generally. I had thought that docker might be a good way to
go for something like this - but maybe this packer thing is good too.

For one thing, if we had a standard image we could use it to create
containers for running Spark's unit test, which would be really cool.
This would help a lot with random issues around port and filesystem
contention we have for unit tests.

I'm not sure if the long term place for this would be inside the spark
codebase or a community library or what. But it would definitely be
very valuable to have if someone wanted to take it on.

- Patrick

On Fri, Oct 3, 2014 at 5:20 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> FYI: There is an existing issue -- SPARK-3314
> <https://issues.apache.org/jira/browse/SPARK-3314> -- about scripting the
> creation of Spark AMIs.
>
> With Packer, it looks like we may be able to script the creation of
> multiple image types (VMWare, GCE, AMI, Docker, etc...) at once from a
> single Packer template. That's very cool.
>
> I'll be looking into this.
>
> Nick
>
>
> On Thu, Oct 2, 2014 at 8:23 PM, Nicholas Chammas <nicholas.chammas@gmail.com
>> wrote:
>
>> Thanks for the update, Nate. I'm looking forward to seeing how these
>> projects turn out.
>>
>> David, Packer looks very, very interesting. I'm gonna look into it more
>> next week.
>>
>> Nick
>>
>>
>> On Thu, Oct 2, 2014 at 8:00 PM, Nate D'Amico <nate@reactor8.com> wrote:
>>
>>> Bit of progress on our end, bit of lagging as well.  Our guy leading
>>> effort got little bogged down on client project to update hive/sql testbed
>>> to latest spark/sparkSQL, also launching public service so we have been bit
>>> scattered recently.
>>>
>>> Will have some more updates probably after next week.  We are planning on
>>> taking our client work around hive/spark, plus taking over the bigtop
>>> automation work to modernize and get that fit for human consumption outside
>>> or org.  All our work and puppet modules will be open sourced, documented,
>>> hopefully start to rally some other folks around effort that find it useful
>>>
>>> Side note, another effort we are looking into is gradle tests/support.
>>> We have been leveraging serverspec for some basic infrastructure tests, but
>>> with bigtop switching over to gradle builds/testing setup in 0.8 we want to
>>> include support for that in our own efforts, probably some stuff that can
>>> be learned and leveraged in spark world for repeatable/tested infrastructure
>>>
>>> If anyone has any specific automation questions to your environment you
>>> can drop me a line directly.., will try to help out best I can.  Else will
>>> post update to dev list once we get on top of our own product release and
>>> the bigtop work
>>>
>>> Nate
>>>
>>>
>>> -----Original Message-----
>>> From: David Rowe [mailto:davidrowe@gmail.com]
>>> Sent: Thursday, October 02, 2014 4:44 PM
>>> To: Nicholas Chammas
>>> Cc: dev; Shivaram Venkataraman
>>> Subject: Re: EC2 clusters ready in launch time + 30 seconds
>>>
>>> I think this is exactly what packer is for. See e.g.
>>> http://www.packer.io/intro/getting-started/build-image.html
>>>
>>> On a related note, the current AMI for hvm systems (e.g. m3.*, r3.*) has
>>> a bad package for httpd, whcih causes ganglia not to start. For some reason
>>> I can't get access to the raw AMI to fix it.
>>>
>>> On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com
>>> > wrote:
>>>
>>> > Is there perhaps a way to define an AMI programmatically? Like, a
>>> > collection of base AMI id + list of required stuff to be installed +
>>> > list of required configuration changes. I'm guessing that's what
>>> > people use things like Puppet, Ansible, or maybe also AWS
>>> CloudFormation for, right?
>>> >
>>> > If we could do something like that, then with every new release of
>>> > Spark we could quickly and easily create new AMIs that have everything
>>> we need.
>>> > spark-ec2 would only have to bring up the instances and do a minimal
>>> > amount of configuration, and the only thing we'd need to track in the
>>> > Spark repo is the code that defines what goes on the AMI, as well as a
>>> > list of the AMI ids specific to each release.
>>> >
>>> > I'm just thinking out loud here. Does this make sense?
>>> >
>>> > Nate,
>>> >
>>> > Any progress on your end with this work?
>>> >
>>> > Nick
>>> >
>>> >
>>> > On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
>>> > shivaram@eecs.berkeley.edu> wrote:
>>> >
>>> > > It should be possible to improve cluster launch time if we are
>>> > > careful about what commands we run during setup. One way to do this
>>> > > would be to walk down the list of things we do for cluster
>>> > > initialization and see if there is anything we can do make things
>>> > > faster. Unfortunately this might
>>> > be
>>> > > pretty time consuming, but I don't know of a better strategy. The
>>> > > place
>>> > to
>>> > > start would be the setup.sh file at
>>> > > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
>>> > >
>>> > > Here are some things that take a lot of time and could be improved:
>>> > > 1. Creating swap partitions on all machines. We could check if there
>>> > > is a way to get EC2 to always mount a swap partition 2. Copying /
>>> > > syncing things across slaves. The copy-dir script is called too many
>>> > > times right now and each time it pauses for a few milliseconds
>>> > > between slaves [1]. This could be improved by removing unnecessary
>>> > > copies 3. We could make less frequently used modules like Tachyon,
>>> > > persistent
>>> > hdfs
>>> > > not a part of the default setup.
>>> > >
>>> > > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
>>> > >
>>> > > Thanks
>>> > > Shivaram
>>> > >
>>> > >
>>> > >
>>> > >
>>> > > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
>>> > > nicholas.chammas@gmail.com> wrote:
>>> > >
>>> > > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <nate@reactor8.com>
>>> > wrote:
>>> > > >
>>> > > > > Starting to work through some automation/config stuff for spark
>>> > > > > stack
>>> > > on
>>> > > > > EC2 with a project, will be focusing the work through the apache
>>> > bigtop
>>> > > > > effort to start, can then share with spark community directly as
>>> > things
>>> > > > > progress if people are interested
>>> > > >
>>> > > >
>>> > > > Let us know how that goes. I'm definitely interested in hearing
>>> more.
>>> > > >
>>> > > > Nick
>>> > > >
>>> > >
>>> >
>>>
>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9682-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct  4 14:29:18 2014
Return-Path: <dev-return-9682-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B1C3D1759C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  4 Oct 2014 14:29:18 +0000 (UTC)
Received: (qmail 71906 invoked by uid 500); 4 Oct 2014 14:29:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71833 invoked by uid 500); 4 Oct 2014 14:29:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71821 invoked by uid 99); 4 Oct 2014 14:29:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 14:29:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 14:28:49 +0000
Received: by mail-wg0-f50.google.com with SMTP id a1so3438260wgh.33
        for <dev@spark.apache.org>; Sat, 04 Oct 2014 07:28:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=L4k8rfalf42NvyJ3gX+UiyJHYyIwfYM8H2V9NF+6i5E=;
        b=McNWFuOQHRDw5VbYdT5SYZFMiB26cGiR6nNLpi5Mn+x/QRJAmCUtc41GfELJE5YoEe
         /6/zn7QVy9b/b9+Sl6td94XVSfliUv/yJKMMSjQH020RkQk3FU4+1YGSISBwZGGZplZ+
         yUt4PEgjjXhdqG8TzOQ7Ta40t1phkQ5s2r9R2/DiqmcTTXfxOaNvSVcZLEk9XsT9v9ux
         fKPIw2a+Vv4jV8yJcBtRnhYs3mnJ/2u29j1ckkVdzv6Tird9HCeiqn6Hfs951vhzJ2Un
         9nMFPA5CqM+N03HYdCowz6hFmNeiisEs6mqV4IJNJuS7nHapTq9xxlk0ascFO/3FxaXr
         2vbw==
X-Received: by 10.180.20.69 with SMTP id l5mr5938500wie.45.1412432928714; Sat,
 04 Oct 2014 07:28:48 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.189.8 with HTTP; Sat, 4 Oct 2014 07:28:08 -0700 (PDT)
In-Reply-To: <CABPQxstH2DLuc2e3woy-1Zx7eA7Pcrc=e2PuGtvLJvPbzbtDJA@mail.gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
 <057601cf9c9c$7e798c80$7b6ca580$@reactor8.com> <CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
 <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
 <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
 <CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
 <0e7001cfde9d$14f00620$3ed01260$@reactor8.com> <CAOhmDzcRM_Gn7KtBJDQm--ai_G-aZBX-oE3StcK+686Y3+Jgeg@mail.gmail.com>
 <CAOhmDzeP0RobdLjiZzeqb8T2wnTLbN1Gvh2t+cnRGYcVUK2KOQ@mail.gmail.com> <CABPQxstH2DLuc2e3woy-1Zx7eA7Pcrc=e2PuGtvLJvPbzbtDJA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sat, 4 Oct 2014 10:28:08 -0400
Message-ID: <CAOhmDze9qQiJyruWHUFN9aGfCz3pXkSwwnSsJnAi9XiUVE4vgw@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
To: Patrick Wendell <pwendell@gmail.com>
Cc: "Nate D'Amico" <nate@reactor8.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec53f35f9fc3af0050499aa76
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec53f35f9fc3af0050499aa76
Content-Type: text/plain; charset=UTF-8

Thanks for posting that script, Patrick. It looks like a good place to
start.

Regarding Docker vs. Packer, as I understand it you can use Packer to
create Docker containers at the same time as AMIs and other image types.

Nick


On Sat, Oct 4, 2014 at 2:49 AM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey All,
>
> Just a couple notes. I recently posted a shell script for creating the
> AMI's from a clean Amazon Linux AMI.
>
> https://github.com/mesos/spark-ec2/blob/v3/create_image.sh
>
> I think I will update the AMI's soon to get the most recent security
> updates. For spark-ec2's purpose this is probably sufficient (we'll
> only need to re-create them every few months).
>
> However, it would be cool if someone wanted to tackle providing a more
> general mechanism for defining Spark-friendly "images" that can be
> used more generally. I had thought that docker might be a good way to
> go for something like this - but maybe this packer thing is good too.
>
> For one thing, if we had a standard image we could use it to create
> containers for running Spark's unit test, which would be really cool.
> This would help a lot with random issues around port and filesystem
> contention we have for unit tests.
>
> I'm not sure if the long term place for this would be inside the spark
> codebase or a community library or what. But it would definitely be
> very valuable to have if someone wanted to take it on.
>
> - Patrick
>
> On Fri, Oct 3, 2014 at 5:20 PM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
> > FYI: There is an existing issue -- SPARK-3314
> > <https://issues.apache.org/jira/browse/SPARK-3314> -- about scripting
> the
> > creation of Spark AMIs.
> >
> > With Packer, it looks like we may be able to script the creation of
> > multiple image types (VMWare, GCE, AMI, Docker, etc...) at once from a
> > single Packer template. That's very cool.
> >
> > I'll be looking into this.
> >
> > Nick
> >
> >
> > On Thu, Oct 2, 2014 at 8:23 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> >> wrote:
> >
> >> Thanks for the update, Nate. I'm looking forward to seeing how these
> >> projects turn out.
> >>
> >> David, Packer looks very, very interesting. I'm gonna look into it more
> >> next week.
> >>
> >> Nick
> >>
> >>
> >> On Thu, Oct 2, 2014 at 8:00 PM, Nate D'Amico <nate@reactor8.com> wrote:
> >>
> >>> Bit of progress on our end, bit of lagging as well.  Our guy leading
> >>> effort got little bogged down on client project to update hive/sql
> testbed
> >>> to latest spark/sparkSQL, also launching public service so we have
> been bit
> >>> scattered recently.
> >>>
> >>> Will have some more updates probably after next week.  We are planning
> on
> >>> taking our client work around hive/spark, plus taking over the bigtop
> >>> automation work to modernize and get that fit for human consumption
> outside
> >>> or org.  All our work and puppet modules will be open sourced,
> documented,
> >>> hopefully start to rally some other folks around effort that find it
> useful
> >>>
> >>> Side note, another effort we are looking into is gradle tests/support.
> >>> We have been leveraging serverspec for some basic infrastructure
> tests, but
> >>> with bigtop switching over to gradle builds/testing setup in 0.8 we
> want to
> >>> include support for that in our own efforts, probably some stuff that
> can
> >>> be learned and leveraged in spark world for repeatable/tested
> infrastructure
> >>>
> >>> If anyone has any specific automation questions to your environment you
> >>> can drop me a line directly.., will try to help out best I can.  Else
> will
> >>> post update to dev list once we get on top of our own product release
> and
> >>> the bigtop work
> >>>
> >>> Nate
> >>>
> >>>
> >>> -----Original Message-----
> >>> From: David Rowe [mailto:davidrowe@gmail.com]
> >>> Sent: Thursday, October 02, 2014 4:44 PM
> >>> To: Nicholas Chammas
> >>> Cc: dev; Shivaram Venkataraman
> >>> Subject: Re: EC2 clusters ready in launch time + 30 seconds
> >>>
> >>> I think this is exactly what packer is for. See e.g.
> >>> http://www.packer.io/intro/getting-started/build-image.html
> >>>
> >>> On a related note, the current AMI for hvm systems (e.g. m3.*, r3.*)
> has
> >>> a bad package for httpd, whcih causes ganglia not to start. For some
> reason
> >>> I can't get access to the raw AMI to fix it.
> >>>
> >>> On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas <
> >>> nicholas.chammas@gmail.com
> >>> > wrote:
> >>>
> >>> > Is there perhaps a way to define an AMI programmatically? Like, a
> >>> > collection of base AMI id + list of required stuff to be installed +
> >>> > list of required configuration changes. I'm guessing that's what
> >>> > people use things like Puppet, Ansible, or maybe also AWS
> >>> CloudFormation for, right?
> >>> >
> >>> > If we could do something like that, then with every new release of
> >>> > Spark we could quickly and easily create new AMIs that have
> everything
> >>> we need.
> >>> > spark-ec2 would only have to bring up the instances and do a minimal
> >>> > amount of configuration, and the only thing we'd need to track in the
> >>> > Spark repo is the code that defines what goes on the AMI, as well as
> a
> >>> > list of the AMI ids specific to each release.
> >>> >
> >>> > I'm just thinking out loud here. Does this make sense?
> >>> >
> >>> > Nate,
> >>> >
> >>> > Any progress on your end with this work?
> >>> >
> >>> > Nick
> >>> >
> >>> >
> >>> > On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
> >>> > shivaram@eecs.berkeley.edu> wrote:
> >>> >
> >>> > > It should be possible to improve cluster launch time if we are
> >>> > > careful about what commands we run during setup. One way to do this
> >>> > > would be to walk down the list of things we do for cluster
> >>> > > initialization and see if there is anything we can do make things
> >>> > > faster. Unfortunately this might
> >>> > be
> >>> > > pretty time consuming, but I don't know of a better strategy. The
> >>> > > place
> >>> > to
> >>> > > start would be the setup.sh file at
> >>> > > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
> >>> > >
> >>> > > Here are some things that take a lot of time and could be improved:
> >>> > > 1. Creating swap partitions on all machines. We could check if
> there
> >>> > > is a way to get EC2 to always mount a swap partition 2. Copying /
> >>> > > syncing things across slaves. The copy-dir script is called too
> many
> >>> > > times right now and each time it pauses for a few milliseconds
> >>> > > between slaves [1]. This could be improved by removing unnecessary
> >>> > > copies 3. We could make less frequently used modules like Tachyon,
> >>> > > persistent
> >>> > hdfs
> >>> > > not a part of the default setup.
> >>> > >
> >>> > > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
> >>> > >
> >>> > > Thanks
> >>> > > Shivaram
> >>> > >
> >>> > >
> >>> > >
> >>> > >
> >>> > > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
> >>> > > nicholas.chammas@gmail.com> wrote:
> >>> > >
> >>> > > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <nate@reactor8.com
> >
> >>> > wrote:
> >>> > > >
> >>> > > > > Starting to work through some automation/config stuff for spark
> >>> > > > > stack
> >>> > > on
> >>> > > > > EC2 with a project, will be focusing the work through the
> apache
> >>> > bigtop
> >>> > > > > effort to start, can then share with spark community directly
> as
> >>> > things
> >>> > > > > progress if people are interested
> >>> > > >
> >>> > > >
> >>> > > > Let us know how that goes. I'm definitely interested in hearing
> >>> more.
> >>> > > >
> >>> > > > Nick
> >>> > > >
> >>> > >
> >>> >
> >>>
> >>>
> >>
>

--bcaec53f35f9fc3af0050499aa76--

From dev-return-9683-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct  4 19:11:31 2014
Return-Path: <dev-return-9683-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D09051796D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat,  4 Oct 2014 19:11:31 +0000 (UTC)
Received: (qmail 18864 invoked by uid 500); 4 Oct 2014 19:11:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18795 invoked by uid 500); 4 Oct 2014 19:11:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18783 invoked by uid 99); 4 Oct 2014 19:11:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 19:11:30 +0000
X-ASF-Spam-Status: No, hits=2.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of cocoatomo77@gmail.com designates 209.85.217.178 as permitted sender)
Received: from [209.85.217.178] (HELO mail-lb0-f178.google.com) (209.85.217.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 04 Oct 2014 19:11:04 +0000
Received: by mail-lb0-f178.google.com with SMTP id w7so2506071lbi.37
        for <dev@spark.apache.org>; Sat, 04 Oct 2014 12:11:03 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=3TU4iZqx4medIOVa2JTHu3HXqPkRRzmLYRCKiXZGHFw=;
        b=iEZZoQsjl5pJU/rKHZsvovI1aB9YspEoxv01P5CFis3xeWjVrWTuPon219xWFNiB48
         MHJ1/Y3W62jWj4RS9DgsDI4wTRjxLs0bragYlEvJEUaZM7bHERLcD7Nubla3BlL1eEzO
         /KB38aErm8Iz5LFJnu2KWpIbc7s4QurPprQzBay1ZrXH/DNJblgR79ocs00eIVYObBrr
         WNzjms7hoA/jzxL6w+7CmMRQAnXxxZflvcu1zXKcQFx5DwlnmNGGR5h8bSiclpA0fy+Q
         bXVzyxmj3aUGvAjOG+NdNZiE6q09sfFsYNV0NPcciCQac2ru//bY9weLsFl2LT8pVdT8
         uoaw==
X-Received: by 10.152.23.69 with SMTP id k5mr14355162laf.70.1412449863668;
 Sat, 04 Oct 2014 12:11:03 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.247.102 with HTTP; Sat, 4 Oct 2014 12:10:43 -0700 (PDT)
From: tomo cocoa <cocoatomo77@gmail.com>
Date: Sun, 5 Oct 2014 04:10:43 +0900
Message-ID: <CAN_7T0KVnHoJWdwUCaFqQ2-fECRckOLXH3KcHzMoWQd54Yz4sA@mail.gmail.com>
Subject: What versions of Hadoop Spark supports?
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160bf98631b1005049d9c58
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160bf98631b1005049d9c58
Content-Type: text/plain; charset=UTF-8

Hi,

I reported this issue (https://issues.apache.org/jira/browse/SPARK-3794)
about compilation error of spark core.
This error depends on a Hadoop version, and problematic versions are
1.1.1--2.2.0.

At first, we should argue about what versions of Hadoop Spark supports.
If we decide to omit a support for those versions, things are so simple and
no modification is needed.
Otherwise, we should be careful to use only commons-io 2.1.


Regards,
cocoatomo

-- 
class Cocoatomo:
    name = 'cocoatomo'
    email_address = 'cocoatomo77@gmail.com'
    twitter_id = '@cocoatomo'

--089e0160bf98631b1005049d9c58--

From dev-return-9684-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct  5 17:17:02 2014
Return-Path: <dev-return-9684-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A14F617FAB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  5 Oct 2014 17:17:02 +0000 (UTC)
Received: (qmail 66602 invoked by uid 500); 5 Oct 2014 17:17:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66536 invoked by uid 500); 5 Oct 2014 17:17:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66525 invoked by uid 99); 5 Oct 2014 17:17:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 17:17:00 +0000
X-ASF-Spam-Status: No, hits=-1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_HI,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rcsenkbe@us.ibm.com designates 32.97.110.149 as permitted sender)
Received: from [32.97.110.149] (HELO e31.co.us.ibm.com) (32.97.110.149)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 17:16:33 +0000
Received: from /spool/local
	by e31.co.us.ibm.com with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted
	for <dev@spark.apache.org> from <rcsenkbe@us.ibm.com>;
	Sun, 5 Oct 2014 11:16:31 -0600
Received: from d03dlp03.boulder.ibm.com (9.17.202.179)
	by e31.co.us.ibm.com (192.168.1.131) with IBM ESMTP SMTP Gateway: Authorized Use Only! Violators will be prosecuted;
	Sun, 5 Oct 2014 11:16:29 -0600
Received: from b03cxnp08027.gho.boulder.ibm.com (b03cxnp08027.gho.boulder.ibm.com [9.17.130.19])
	by d03dlp03.boulder.ibm.com (Postfix) with ESMTP id F15E819D803D
	for <dev@spark.apache.org>; Sun,  5 Oct 2014 11:05:12 -0600 (MDT)
Received: from d03av05.boulder.ibm.com (d03av05.boulder.ibm.com [9.17.195.85])
	by b03cxnp08027.gho.boulder.ibm.com (8.14.9/8.14.9/NCO v10.0) with ESMTP id s95HGSfs53739670
	for <dev@spark.apache.org>; Sun, 5 Oct 2014 19:16:28 +0200
Received: from d03av05.boulder.ibm.com (localhost [127.0.0.1])
	by d03av05.boulder.ibm.com (8.14.4/8.14.4/NCO v10.0 AVout) with ESMTP id s95HGShp008302
	for <dev@spark.apache.org>; Sun, 5 Oct 2014 11:16:28 -0600
Received: from d03nm127.boulder.ibm.com (d03nm127.boulder.ibm.com [9.63.33.48])
	by d03av05.boulder.ibm.com (8.14.4/8.14.4/NCO v10.0 AVin) with ESMTP id s95HGSCU008299
	for <dev@spark.apache.org>; Sun, 5 Oct 2014 11:16:28 -0600
Subject: Jython importing pyspark?
X-KeepSent: F394170F:00254A78-87257D68:005C9BF4;
 type=4; name=$KeepSent
To: dev@spark.apache.org
X-Mailer: IBM Notes Release 9.0.1 October 14, 2013
Message-ID: <OFF394170F.00254A78-ON87257D68.005C9BF4-86257D68.005EE41E@us.ibm.com>
From: Robert C Senkbeil <rcsenkbe@us.ibm.com>
Date: Sun, 5 Oct 2014 12:16:25 -0500
X-MIMETrack: Serialize by Router on D03NM127/03/M/IBM(Release 9.0.1FP1|April  03, 2014) at
 10/05/2014 11:16:25
MIME-Version: 1.0
Content-type: multipart/alternative; 
	Boundary="0__=08BBF7FBDFCF1D648f9e8a93df938690918c08BBF7FBDFCF1D64"
Content-Disposition: inline
X-TM-AS-MML: disable
X-Content-Scanned: Fidelis XPS MAILER
x-cbid: 14100517-8236-0000-0000-000005EC870C
X-Virus-Checked: Checked by ClamAV on apache.org

--0__=08BBF7FBDFCF1D648f9e8a93df938690918c08BBF7FBDFCF1D64
Content-type: text/plain; charset=ISO-8859-1
Content-transfer-encoding: quoted-printable



Hi there,

I wanted to ask whether or not anyone has successfully used Jython with=
 the
pyspark library. I wasn't sure if the C extension support was needed fo=
r
pyspark itself or was just a bonus of using Cython.

There was a claim (
http://apache-spark-developers-list.1001551.n3.nabble.com/PySpark-Drive=
r-from-Jython-td7142.html#a7269
) that using Jython would be better - if you didn't need C extension
support - because the cost of serialization is lower. However, I have n=
ot
been able to import pyspark into a Jython session. I'm using version 2.=
7b3
of Jython and version 1.1.0 of Spark for reference.

Jython 2.7b3 (default:e81256215fb0, Aug 4 2014, 02:39:51)
[Java HotSpot(TM) 64-Bit Server VM (Oracle Corporation)] on java1.7.0_5=
1
Type "help", "copyright", "credits" or "license" for more information.
>>> from pyspark import SparkContext, SparkConf
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "pyspark/__init__.py", line 63, in <module>
  File "pyspark/context.py", line 25, in <module>
  File "pyspark/accumulators.py", line 94, in <module>
  File "pyspark/serializers.py", line 341, in <module>
  File "pyspark/serializers.py", line 328, in _hijack_namedtuple
RuntimeError: maximum recursion depth exceeded (Java StackOverflowError=
)

Is there something I am missing with this? Did Jython ever work for
pyspark? The same error happens regardless of whether I use the Python
files or compile them down to Java class files using Jython first.

I know that previous documentation (0.9.1) indicated, "PySpark requires=

Python 2.6 or higher. PySpark applications are executed using a standar=
d
CPython interpreter in order to support Python modules that use C
extensions. We have not tested PySpark with Python 3 or with alternativ=
e
Python interpreters, such as=A0PyPy=A0or=A0Jython."

In later versions, it now reflects, "Spark 1.1.0 works with Python 2.6 =
or
higher (but not Python 3). It uses the standard CPython interpreter, so=
 C
libraries like NumPy can be used."

I'm assuming this means that attempts to use other interpreters failed.=
 If
so, are there any plans to support something like Jython in the future?=


Signed,
Chip Senkbeil=

--0__=08BBF7FBDFCF1D648f9e8a93df938690918c08BBF7FBDFCF1D64--


From dev-return-9685-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct  5 20:58:43 2014
Return-Path: <dev-return-9685-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E8FF7175A2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  5 Oct 2014 20:58:43 +0000 (UTC)
Received: (qmail 74604 invoked by uid 500); 5 Oct 2014 20:58:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74554 invoked by uid 500); 5 Oct 2014 20:58:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74542 invoked by uid 99); 5 Oct 2014 20:58:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 20:58:42 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of thubregtsen@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 20:58:37 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <thubregtsen@gmail.com>)
	id 1Xassi-0007R1-7S
	for dev@spark.incubator.apache.org; Sun, 05 Oct 2014 13:58:16 -0700
Date: Sun, 5 Oct 2014 13:58:16 -0700 (PDT)
From: Tom Hubregtsen <thubregtsen@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1412542696188-8655.post@n3.nabble.com>
Subject: Impact of input format on timing
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

I ran the same version of a program with two different types of input
containing equivalent information. 
Program 1: 10,000 files with on average 50 IDs, one every line
Program 2: 1 file containing 10,000 lines. On average 50 IDs per line

My program takes the input, creates key/value pairs of them, and performs
about 7 more steps. I have compared the sets of key/value pairs after the
initialization phase, and they are equivalent. All other steps are equal.
The only difference is using wholeTextFile versus textFile and the
initialization input map function itself.  

Since I am reading in from HDFS, and the minimum part size there is 64MB,
every file in program 1 will take 64MB, even though they are KBs original.
Because of this, I expected program 2 to be faster, or equivalent as the
initialization phase may be neglectable. 

In my first comparison, I provided the program with sufficient memory, and
they both take around 2 minutes. No surprises here.

In my second comparison, I limit the memory to in this case 4 GB. Program 1
executes in a little over 4 minutes, but program 2 takes over 15 minutes
(after which I terminated the program, as I see it is getting there, but
spilling massively in every stage). The difference between the two runs is
the amount of spilling in phases later on in the program (*not* in the
initialization phase). Program 1 spills 2 chunks per stage:
14/10/05 14:52:30 INFO ExternalAppendOnlyMap: Thread 241 spilling in-memory
map of 327 MB to disk (1 time so far)
14/10/05 14:52:30 INFO ExternalAppendOnlyMap: Thread 242 spilling in-memory
map of 328 MB to disk (1 time so far)
Program 2 also spills these 2 chunks:
14/10/05 14:44:35 INFO ExternalAppendOnlyMap: Thread 240 spilling in-memory
map of 320 MB to disk (1 time so far)
14/10/05 14:44:35 INFO ExternalAppendOnlyMap: Thread 241 spilling in-memory
map of 323 MB to disk (1 time so far)
But then spills 2 * ~15,000 chuncks of <1MB:
14/10/05 14:44:41 INFO ExternalAppendOnlyMap: Thread 240 spilling in-memory
map of 0 MB to disk (15561 time so far)
14/10/05 14:44:41 INFO ExternalAppendOnlyMap: Thread 240 spilling in-memory
map of 0 MB to disk (13866 times so far)

I understand that RDDs with narrow dependencies to their parents are
pipelined, and form a stage. These all point to the parent RDD. This parent
RDD will have different partitioning and different data placement between
the two programs. Because of this, I did expect a difference in this stage,
but as we change from JavaRDD to JavaPairRDD and do a reduceByKey after the
initialization, I expected this difference to be gone in the next stages.
Can anyone explain this behavior, or point me in a direction?

Thanks in advance!




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Impact-of-input-format-on-timing-tp8655.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9686-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct  5 22:07:51 2014
Return-Path: <dev-return-9686-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4AD9C176A1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  5 Oct 2014 22:07:51 +0000 (UTC)
Received: (qmail 35211 invoked by uid 500); 5 Oct 2014 22:07:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35142 invoked by uid 500); 5 Oct 2014 22:07:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35130 invoked by uid 99); 5 Oct 2014 22:07:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 22:07:50 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.50 as permitted sender)
Received: from [209.85.220.50] (HELO mail-pa0-f50.google.com) (209.85.220.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 22:07:22 +0000
Received: by mail-pa0-f50.google.com with SMTP id kx10so4317664pab.9
        for <dev@spark.incubator.apache.org>; Sun, 05 Oct 2014 15:07:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=xsOIHDNuwxU8V03o9LgNxo+kCd+fhAtsmSrQaxEzOJ8=;
        b=CWcTnTuxmMVR7rIhfpLjwolhCij+Izu7RSgBaa8a+rLZVBBlrEjY88DIbw9K7Da5kE
         4laWlx/R6eJ5oxLlHG5oms08NADL0bK2XaoHKlboHk3SWETAXyOCnz3+6R79fFI9v2cc
         py9oUdNOewp91J4r6rpLOGTzkynibXeNoL6lMQipOOAU3WnIsOIfkwKkVE//F2J5w6y9
         nQs4OodWCwh1fiSN/5k5mdcbUuOEuK/J/R09qGVzAdQHfzJ4UztVxD8x0TvoPN9r6A/N
         CBf7QENz4uA5xE2SYPtSmG7MBiSnzl83Dwp1YD2sgcYMjuUkME8fDHy0MCOkBQXRIyaE
         ErdQ==
X-Received: by 10.70.44.137 with SMTP id e9mr4133332pdm.122.1412546840591;
        Sun, 05 Oct 2014 15:07:20 -0700 (PDT)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id ti8sm11769690pac.20.2014.10.05.15.07.19
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 05 Oct 2014 15:07:19 -0700 (PDT)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Impact of input format on timing
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <1412542696188-8655.post@n3.nabble.com>
Date: Sun, 5 Oct 2014 15:07:17 -0700
Cc: dev@spark.incubator.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <014262D9-9BC4-4956-A6A6-83C9A85723E3@gmail.com>
References: <1412542696188-8655.post@n3.nabble.com>
To: Tom Hubregtsen <thubregtsen@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Tom,

HDFS and Spark don't actually have a minimum block size -- so in that =
first dataset, the files won't each be costing you 64 MB. However, the =
main reason for difference in performance here is probably the number of =
RDD partitions. In the first case, Spark will create an RDD with 10000 =
partitions, one per file, while in the second case it will likely have =
only 1-2 of them. The number of partitions affects the level of =
parallelism of operations like reduceByKey (by default, reduceByKey uses =
as many partitions as the parent RDD it runs on), and in this case, I =
think it's causing reduceByKey to spill to disk within tasks in the =
second case and not in the first case, because each task has more input =
data.

You can see the number of partitions in each stage of your computation =
on the application web UI at http://<driver>:4040 if you want to confirm =
this. Also, for both programs, you can manually set the number of =
partitions for the reduce by passing a second argument to reduceByKey =
(e.g. reduceByKey(myFunc, 100)). In general it's best to choose this so =
that the input data for each reduce task fits in memory to avoid =
spilling.

Matei

On Oct 5, 2014, at 1:58 PM, Tom Hubregtsen <thubregtsen@gmail.com> =
wrote:

> Hi,
>=20
> I ran the same version of a program with two different types of input
> containing equivalent information.=20
> Program 1: 10,000 files with on average 50 IDs, one every line
> Program 2: 1 file containing 10,000 lines. On average 50 IDs per line
>=20
> My program takes the input, creates key/value pairs of them, and =
performs
> about 7 more steps. I have compared the sets of key/value pairs after =
the
> initialization phase, and they are equivalent. All other steps are =
equal.
> The only difference is using wholeTextFile versus textFile and the
> initialization input map function itself. =20
>=20
> Since I am reading in from HDFS, and the minimum part size there is =
64MB,
> every file in program 1 will take 64MB, even though they are KBs =
original.
> Because of this, I expected program 2 to be faster, or equivalent as =
the
> initialization phase may be neglectable.=20
>=20
> In my first comparison, I provided the program with sufficient memory, =
and
> they both take around 2 minutes. No surprises here.
>=20
> In my second comparison, I limit the memory to in this case 4 GB. =
Program 1
> executes in a little over 4 minutes, but program 2 takes over 15 =
minutes
> (after which I terminated the program, as I see it is getting there, =
but
> spilling massively in every stage). The difference between the two =
runs is
> the amount of spilling in phases later on in the program (*not* in the
> initialization phase). Program 1 spills 2 chunks per stage:
> 14/10/05 14:52:30 INFO ExternalAppendOnlyMap: Thread 241 spilling =
in-memory
> map of 327 MB to disk (1 time so far)
> 14/10/05 14:52:30 INFO ExternalAppendOnlyMap: Thread 242 spilling =
in-memory
> map of 328 MB to disk (1 time so far)
> Program 2 also spills these 2 chunks:
> 14/10/05 14:44:35 INFO ExternalAppendOnlyMap: Thread 240 spilling =
in-memory
> map of 320 MB to disk (1 time so far)
> 14/10/05 14:44:35 INFO ExternalAppendOnlyMap: Thread 241 spilling =
in-memory
> map of 323 MB to disk (1 time so far)
> But then spills 2 * ~15,000 chuncks of <1MB:
> 14/10/05 14:44:41 INFO ExternalAppendOnlyMap: Thread 240 spilling =
in-memory
> map of 0 MB to disk (15561 time so far)
> 14/10/05 14:44:41 INFO ExternalAppendOnlyMap: Thread 240 spilling =
in-memory
> map of 0 MB to disk (13866 times so far)
>=20
> I understand that RDDs with narrow dependencies to their parents are
> pipelined, and form a stage. These all point to the parent RDD. This =
parent
> RDD will have different partitioning and different data placement =
between
> the two programs. Because of this, I did expect a difference in this =
stage,
> but as we change from JavaRDD to JavaPairRDD and do a reduceByKey =
after the
> initialization, I expected this difference to be gone in the next =
stages.
> Can anyone explain this behavior, or point me in a direction?
>=20
> Thanks in advance!
>=20
>=20
>=20
>=20
> --
> View this message in context: =
http://apache-spark-developers-list.1001551.n3.nabble.com/Impact-of-input-=
format-on-timing-tp8655.html
> Sent from the Apache Spark Developers List mailing list archive at =
Nabble.com.
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9687-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct  5 22:59:45 2014
Return-Path: <dev-return-9687-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 571E91777B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  5 Oct 2014 22:59:45 +0000 (UTC)
Received: (qmail 80302 invoked by uid 500); 5 Oct 2014 22:59:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80223 invoked by uid 500); 5 Oct 2014 22:59:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80177 invoked by uid 99); 5 Oct 2014 22:59:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 22:59:44 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.220.176] (HELO mail-vc0-f176.google.com) (209.85.220.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 22:59:17 +0000
Received: by mail-vc0-f176.google.com with SMTP id hq11so2410906vcb.7
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 15:59:15 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=Bh6PbhYGMUq2G3njluC5DESzMW4YcRYmL2/by9djC8k=;
        b=lm0oegbkhAFer4D/1i7VR5nXkmYqNAw4g71RE79QKabvDlCjZIztCt0AywecAOHTdp
         +pqSf/oQ+VJzqmQKiiLXpUV+KhbQxswcoSb0A1c/Ft5sywc4EwgdEju1Q3fGEn7vvWHQ
         rCJA0qu6Q/lJhzIsDYWNL7bOh9xlL7kOcyvRnHBs2uggrBjY1QL/vsF/y8thIzXpO2HL
         fhEq8+4gWTIVqpjpum9S2nYjHSlfIcEEngTEj4SJGWbIpjAs3LNz3Zur17Kn64F55iBN
         P78elhwKit7QazWFk7l+WTpHbcOeCwGa8t9LSfcEHihtFUIDFiRnRa4Joq+kqQN/sIbu
         bOkA==
X-Gm-Message-State: ALoCoQl/Z7MN9aKFflF64YHRSdZ1JRxbKoTi0lIqUdt58UmFCy19SQrZ+eyamsWZXW7G92n3TuZ6
X-Received: by 10.52.53.105 with SMTP id a9mr12687169vdp.5.1412549955659;
        Sun, 05 Oct 2014 15:59:15 -0700 (PDT)
Received: from mail-vc0-f176.google.com (mail-vc0-f176.google.com [209.85.220.176])
        by mx.google.com with ESMTPSA id yf12sm2742207vdc.18.2014.10.05.15.59.14
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 05 Oct 2014 15:59:14 -0700 (PDT)
Received: by mail-vc0-f176.google.com with SMTP id hq11so2410896vcb.7
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 15:59:14 -0700 (PDT)
X-Received: by 10.221.26.70 with SMTP id rl6mr15429729vcb.0.1412549954150;
 Sun, 05 Oct 2014 15:59:14 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.220.17.197 with HTTP; Sun, 5 Oct 2014 15:58:54 -0700 (PDT)
In-Reply-To: <CAKWX9VWaNzDcHjxFC3XpwSG+bi7Y+bM2z1jo2g2D8kR1aFES6w@mail.gmail.com>
References: <CAKWX9VWaNzDcHjxFC3XpwSG+bi7Y+bM2z1jo2g2D8kR1aFES6w@mail.gmail.com>
From: Andrew Ash <andrew@andrewash.com>
Date: Sun, 5 Oct 2014 18:58:54 -0400
Message-ID: <CA+-p3AGEW78LtPbDBHvf1qzsV3bYSwtpBQAS04jRkFq5e0rBzw@mail.gmail.com>
Subject: Re: Parquet schema migrations
To: Cody Koeninger <cody@koeninger.org>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11339b5a3eabab0504b4ea2d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11339b5a3eabab0504b4ea2d
Content-Type: text/plain; charset=UTF-8

Hi Cody,

I wasn't aware there were different versions of the parquet format.  What's
the difference between "raw parquet" and the Hive-written parquet files?

As for your migration question, the approaches I've often seen are
convert-on-read and convert-all-at-once.  Apache Cassandra for example does
both -- when upgrading between Cassandra versions that change the on-disk
sstable format, it will do a convert-on-read as you access the sstables, or
you can run the upgradesstables command to convert them all at once
post-upgrade.

Andrew

On Fri, Oct 3, 2014 at 4:33 PM, Cody Koeninger <cody@koeninger.org> wrote:

> Wondering if anyone has thoughts on a path forward for parquet schema
> migrations, especially for people (like us) that are using raw parquet
> files rather than Hive.
>
> So far we've gotten away with reading old files, converting, and writing to
> new directories, but that obviously becomes problematic above a certain
> data size.
>

--001a11339b5a3eabab0504b4ea2d--

From dev-return-9688-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct  5 23:13:39 2014
Return-Path: <dev-return-9688-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A83F6177B5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun,  5 Oct 2014 23:13:39 +0000 (UTC)
Received: (qmail 90731 invoked by uid 500); 5 Oct 2014 23:13:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90661 invoked by uid 500); 5 Oct 2014 23:13:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90648 invoked by uid 99); 5 Oct 2014 23:13:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 23:13:38 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.179 as permitted sender)
Received: from [209.85.192.179] (HELO mail-pd0-f179.google.com) (209.85.192.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 05 Oct 2014 23:13:10 +0000
Received: by mail-pd0-f179.google.com with SMTP id r10so2332830pdi.38
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 16:13:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=BUBYVhfB1VeKxMdTBkU2Q+Hrh3afEjWwgsCHXD93tt0=;
        b=IJ//31H3jFn9f6tr9hoyiWeGl2D6iKBvEQ9mmUodiyIyuPO4BQCln64QjbY6mw9HBZ
         w7eQzAM9B9G+mQcV8VNUunDsG/t509Qfh5wydpy9AeoPwNLQoFxCUIHQAxKBPXLqQMFF
         XBSYio2Zsq/9YGgT8MV1AhdDRGPigWv6S5xNFRY/1glRsSvFaasmvkCOSOeMKzgffOBH
         /0YcX8coalwh8+iNmSbjUKBjEQeHB9lwSrgSqUDOMBmpW1WWR+WzSfGmVFrvDkjCHPXY
         r97pdBQTNh/GlRwMgv1C2dZ/WRMQNIzlroawtGboLXcuCQY7Xo2tXi3lLp81YLpql+Ss
         ia5g==
X-Received: by 10.66.158.165 with SMTP id wv5mr1072517pab.36.1412550789068;
        Sun, 05 Oct 2014 16:13:09 -0700 (PDT)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id bz2sm4012677pdb.17.2014.10.05.16.13.08
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 05 Oct 2014 16:13:08 -0700 (PDT)
Content-Type: text/plain; charset=iso-8859-1
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Jython importing pyspark?
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <OFF394170F.00254A78-ON87257D68.005C9BF4-86257D68.005EE41E@us.ibm.com>
Date: Sun, 5 Oct 2014 16:13:06 -0700
Cc: dev@spark.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <B99D3831-1185-410A-94A4-C2458E4A6AF8@gmail.com>
References: <OFF394170F.00254A78-ON87257D68.005C9BF4-86257D68.005EE41E@us.ibm.com>
To: Robert C Senkbeil <rcsenkbe@us.ibm.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

PySpark doesn't attempt to support Jython at present. IMO while it might =
be a bit faster, it would lose a lot of the benefits of Python, which =
are the very strong data processing libraries (NumPy, SciPy, Pandas, =
etc). So I'm not sure it's worth supporting unless someone demonstrates =
a really major performance benefit.

There was actually a recent patch to add PyPy support =
(https://github.com/apache/spark/pull/2144), which is worth a try if you =
want Python applications to run faster. It might actually be faster =
overall than Jython.

Matei

On Oct 5, 2014, at 10:16 AM, Robert C Senkbeil <rcsenkbe@us.ibm.com> =
wrote:

>=20
>=20
> Hi there,
>=20
> I wanted to ask whether or not anyone has successfully used Jython =
with the
> pyspark library. I wasn't sure if the C extension support was needed =
for
> pyspark itself or was just a bonus of using Cython.
>=20
> There was a claim (
> =
http://apache-spark-developers-list.1001551.n3.nabble.com/PySpark-Driver-f=
rom-Jython-td7142.html#a7269
> ) that using Jython would be better - if you didn't need C extension
> support - because the cost of serialization is lower. However, I have =
not
> been able to import pyspark into a Jython session. I'm using version =
2.7b3
> of Jython and version 1.1.0 of Spark for reference.
>=20
> Jython 2.7b3 (default:e81256215fb0, Aug 4 2014, 02:39:51)
> [Java HotSpot(TM) 64-Bit Server VM (Oracle Corporation)] on =
java1.7.0_51
> Type "help", "copyright", "credits" or "license" for more information.
>>>> from pyspark import SparkContext, SparkConf
> Traceback (most recent call last):
>  File "<stdin>", line 1, in <module>
>  File "pyspark/__init__.py", line 63, in <module>
>  File "pyspark/context.py", line 25, in <module>
>  File "pyspark/accumulators.py", line 94, in <module>
>  File "pyspark/serializers.py", line 341, in <module>
>  File "pyspark/serializers.py", line 328, in _hijack_namedtuple
> RuntimeError: maximum recursion depth exceeded (Java =
StackOverflowError)
>=20
> Is there something I am missing with this? Did Jython ever work for
> pyspark? The same error happens regardless of whether I use the Python
> files or compile them down to Java class files using Jython first.
>=20
> I know that previous documentation (0.9.1) indicated, "PySpark =
requires
> Python 2.6 or higher. PySpark applications are executed using a =
standard
> CPython interpreter in order to support Python modules that use C
> extensions. We have not tested PySpark with Python 3 or with =
alternative
> Python interpreters, such as PyPy or Jython."
>=20
> In later versions, it now reflects, "Spark 1.1.0 works with Python 2.6 =
or
> higher (but not Python 3). It uses the standard CPython interpreter, =
so C
> libraries like NumPy can be used."
>=20
> I'm assuming this means that attempts to use other interpreters =
failed. If
> so, are there any plans to support something like Jython in the =
future?
>=20
> Signed,
> Chip Senkbeil


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9689-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 00:36:55 2014
Return-Path: <dev-return-9689-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6354A178C3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 00:36:55 +0000 (UTC)
Received: (qmail 54690 invoked by uid 500); 6 Oct 2014 00:36:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54619 invoked by uid 500); 6 Oct 2014 00:36:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54608 invoked by uid 99); 6 Oct 2014 00:36:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 00:36:54 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_RHS_DOB
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.215.43] (HELO mail-la0-f43.google.com) (209.85.215.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 00:36:50 +0000
Received: by mail-la0-f43.google.com with SMTP id mc6so3535568lab.30
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 17:36:27 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=tiKzSrcKBrLOg3oKmWbVVMk6WfC9Gtje2onmJ0YP2is=;
        b=RAeByF8mPJSn3KxO9PUXIgojvoPvpfQvo4Jlalfs3hAuW0JgA4QaaTtM7kXHPYVVd9
         eFdI8krj1UwlxJJVyXzgffc3A5drBZQU1OSexmXGFYCQa1Iwfk2tasR0QELUZZ501Gtd
         a2VUhaLaLedxKBjSzLF/M0cHOXEpqP2/eslAMEGkyMB8xGo3nI787bVwEA+JjwzpO5j+
         Rui28wKSnZqGXDyvzj8x/f/XH+2ORpE2a4KBBVdJFiOisaVsOxeswRSgi1SYtsOWejiy
         FW31P+lsUtbk0csCR+6vnBYbUfad2As+OkpETDEm2Lxn4TFM1S3F83zEuY1p6BOB8Ijv
         60cA==
X-Gm-Message-State: ALoCoQk9nFds79HeUSdz3PXsi15jUybTPbH3/XNCMpeYWNiR4r+VJsaN4JOKBaikgbW+Wf601hHi
X-Received: by 10.112.129.228 with SMTP id nz4mr20373327lbb.9.1412555787486;
 Sun, 05 Oct 2014 17:36:27 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.17 with HTTP; Sun, 5 Oct 2014 17:36:07 -0700 (PDT)
In-Reply-To: <CA+-p3AGEW78LtPbDBHvf1qzsV3bYSwtpBQAS04jRkFq5e0rBzw@mail.gmail.com>
References: <CAKWX9VWaNzDcHjxFC3XpwSG+bi7Y+bM2z1jo2g2D8kR1aFES6w@mail.gmail.com>
 <CA+-p3AGEW78LtPbDBHvf1qzsV3bYSwtpBQAS04jRkFq5e0rBzw@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Sun, 5 Oct 2014 17:36:07 -0700
Message-ID: <CAAswR-4-Z7m7z0+Sp1NHhSS1-YNx1vTVn_Kag7-PKuGgn-DwmA@mail.gmail.com>
Subject: Re: Parquet schema migrations
To: Andrew Ash <andrew@andrewash.com>
Cc: Cody Koeninger <cody@koeninger.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a83aef05c250504b645a0
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a83aef05c250504b645a0
Content-Type: text/plain; charset=UTF-8

Hi Cody,

Assuming you are talking about 'safe' changes to the schema (i.e. existing
column names are never reused with incompatible types), this is something
I'd love to support.  Perhaps you can describe more what sorts of changes
you are making, and if simple merging of the schemas would be sufficient.
If so, we can open a JIRA, though I'm not sure when we'll have resources to
dedicate to this.

In the near term, I'd suggest writing converters for each version of the
schema, that translate to some desired master schema.  You can then union
all of these together and avoid the cost of batch conversion.  It seems
like in most cases this should be pretty efficient, at least now that we
have good pushdown past union operators :)

Michael

On Sun, Oct 5, 2014 at 3:58 PM, Andrew Ash <andrew@andrewash.com> wrote:

> Hi Cody,
>
> I wasn't aware there were different versions of the parquet format.  What's
> the difference between "raw parquet" and the Hive-written parquet files?
>
> As for your migration question, the approaches I've often seen are
> convert-on-read and convert-all-at-once.  Apache Cassandra for example does
> both -- when upgrading between Cassandra versions that change the on-disk
> sstable format, it will do a convert-on-read as you access the sstables, or
> you can run the upgradesstables command to convert them all at once
> post-upgrade.
>
> Andrew
>
> On Fri, Oct 3, 2014 at 4:33 PM, Cody Koeninger <cody@koeninger.org> wrote:
>
> > Wondering if anyone has thoughts on a path forward for parquet schema
> > migrations, especially for people (like us) that are using raw parquet
> > files rather than Hive.
> >
> > So far we've gotten away with reading old files, converting, and writing
> to
> > new directories, but that obviously becomes problematic above a certain
> > data size.
> >
>

--047d7b3a83aef05c250504b645a0--

From dev-return-9690-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 02:28:51 2014
Return-Path: <dev-return-9690-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7AA8D17A08
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 02:28:51 +0000 (UTC)
Received: (qmail 34148 invoked by uid 500); 6 Oct 2014 02:28:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34076 invoked by uid 500); 6 Oct 2014 02:28:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34062 invoked by uid 99); 6 Oct 2014 02:28:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 02:28:50 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lochanac@gmail.com designates 209.85.192.174 as permitted sender)
Received: from [209.85.192.174] (HELO mail-pd0-f174.google.com) (209.85.192.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 02:28:22 +0000
Received: by mail-pd0-f174.google.com with SMTP id y13so2515516pdi.19
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 19:28:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject
         :content-type:content-transfer-encoding;
        bh=TKMz5YY9rDfhe5adhUnhK4f7tAhI1K/Yw5LmUhHdfyE=;
        b=D3Lm1OXnVwatHfJqS0mXnmuOz+fTRpFrA7Mhg271AkXrCK6bmp+wtqeaFeA8+xNPLR
         AELkahETr+e6za0hNhCTUetnU14MbTJWxD8e8g9FseIWp9l4eaAlrQNrveFbvJJ059EC
         5jTyWsgIiEh3mA9uXvJGW6TjHuPAD1LkV/vt1D76D7doUC6a9Vt3+gQqMcnYc79bSUsU
         ctPqpJ/7jaH3X4gjmrXH/2A1WFCw/hG0RUBmYPM4is95UjYwuWZkH8GfR7mrgN0LMmNg
         q0n+995HwLBgx599htBfi+Ke6JIThmNzbqjfHNiJVlplq2PhkQoBuPv1TFoR2hiMPdF0
         nisg==
X-Received: by 10.66.188.4 with SMTP id fw4mr14999696pac.67.1412562501231;
        Sun, 05 Oct 2014 19:28:21 -0700 (PDT)
Received: from Lochanas-MacBook-Pro.local ([203.94.95.4])
        by mx.google.com with ESMTPSA id d17sm999972pdj.32.2014.10.05.19.28.19
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Sun, 05 Oct 2014 19:28:20 -0700 (PDT)
Message-ID: <5431FE42.2080502@gmail.com>
Date: Mon, 06 Oct 2014 07:58:18 +0530
From: Lochana Menikarachchi <lochanac@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Hyper Parameter Tuning Algorithms
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Found this thread from April..

http://mail-archives.apache.org/mod_mbox/spark-user/201404.mbox/%3CCABjXkq6b7SfAxie4+AqTCmD8jSqBZnsxSFw6V5o0WWWouOBbCw@mail.gmail.com%3E

Wondering what the status of this.. We are thinking about implementing 
these algorithms.. Would be a waste if they are already available?

Please advice.

Thanks.

Lochana

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9691-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 03:41:22 2014
Return-Path: <dev-return-9691-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1064917B4D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 03:41:22 +0000 (UTC)
Received: (qmail 90427 invoked by uid 500); 6 Oct 2014 03:41:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90356 invoked by uid 500); 6 Oct 2014 03:41:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90344 invoked by uid 99); 6 Oct 2014 03:41:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 03:41:20 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of kumar.soumitra@gmail.com designates 209.85.192.53 as permitted sender)
Received: from [209.85.192.53] (HELO mail-qg0-f53.google.com) (209.85.192.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 03:40:54 +0000
Received: by mail-qg0-f53.google.com with SMTP id a108so3161338qge.26
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 20:40:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:subject:mime-version
         :content-type:content-transfer-encoding;
        bh=4aZUzxNtAIV3cS0dZXPvhGF5oWvaP4FBmj0QxRF8JnE=;
        b=ZnJOKoLbemVIDFIoy0TDS/8TE2zO4FlDEedS6YRZ1maE3BQWL04fkkxW6PuSumZJbf
         kCDK1BvyOhchKMTfz6xLVX6J8EGMC+SGyEKtrQDELedqhG0RDrvWzkEsz3MV8T+/saus
         BGR+Fj8EFpopm6ZLsgUDVePg600MCm+eCsQ+D8a3/fulLlZxPRJ9ZnnuqzIvGP+U/CFU
         5jwDXLVW/V0Q4ABpDFDzhIIOSe4DoC75m9DNlXdAVtzqfJMtTgLlTg9a6dM9dFDrNkOP
         Bi5Mt8IVNa4P9RD/tKR1LYw/LEfKJQcJJAvNmfIKXNLtgg7nCe7BmWfiRbAJ8llupZG0
         IFLQ==
X-Received: by 10.224.137.3 with SMTP id u3mr6784453qat.82.1412566852697;
        Sun, 05 Oct 2014 20:40:52 -0700 (PDT)
Received: from localhost (99-90-64-194.lightspeed.sntcca.sbcglobal.net. [99.90.64.194])
        by mx.google.com with ESMTPSA id l46sm11702052qgd.27.2014.10.05.20.40.51
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Sun, 05 Oct 2014 20:40:52 -0700 (PDT)
Date: Sun, 5 Oct 2014 20:40:48 -0700 (PDT)
From: Soumitra Kumar <kumar.soumitra@gmail.com>
To: dev@spark.apache.org
Message-ID: <3953931.93.1412566843923.JavaMail.soumitra@tharthari>
In-Reply-To: <954579.172.1411504097809.JavaMail.soumitra@tharthari>
Subject: Re: SPARK-3660 : Initial RDD for updateStateByKey transformation
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I have submitted a pull request (Adding support of initial value for state update. #2665), please review and let me know.

Excited to submit my first pull request.

-Soumitra.

----- Original Message -----
From: "Soumitra Kumar" <kumar.soumitra@gmail.com>
To: dev@spark.apache.org
Sent: Tuesday, September 23, 2014 1:28:21 PM
Subject: SPARK-3660 : Initial RDD for updateStateByKey transformation

Hello fellow developers,

Thanks TD for relevant pointers.

I have created an issue :
https://issues.apache.org/jira/browse/SPARK-3660

Copying the description from JIRA:
"
How to initialize state tranformation updateStateByKey?

I have word counts from previous spark-submit run, and want to load that in next spark-submit job to start counting over that.

One proposal is to add following argument to updateStateByKey methods.
initial : Option [RDD [(K, S)]] = None

This will maintain the backward compatibility as well.

I have a working code as well.

This thread started on spark-user list at:
http://apache-spark-user-list.1001560.n3.nabble.com/How-to-initialize-updateStateByKey-operation-td14772.html
"

Please let me know if I shall add a parameter "initial : Option [RDD [(K, S)]] = None" to all updateStateByKey methods or create new ones?

Thanks,
-Soumitra.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9692-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 06:01:35 2014
Return-Path: <dev-return-9692-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1F22217E84
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 06:01:35 +0000 (UTC)
Received: (qmail 23096 invoked by uid 500); 6 Oct 2014 06:01:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23018 invoked by uid 500); 6 Oct 2014 06:01:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23006 invoked by uid 99); 6 Oct 2014 06:01:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 06:01:11 +0000
X-ASF-Spam-Status: No, hits=2.6 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FROM_EXCESS_BASE64,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of cwk32@vip.qq.com designates 103.7.29.139 as permitted sender)
Received: from [103.7.29.139] (HELO smtpbg64.qq.com) (103.7.29.139)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 06:00:42 +0000
X-QQ-FEAT: 00ti1PLKM+80DnDUxvtKrvSs5+6/7KZpiYaUKMuK8zhpGMArs9ZiVzvnjtqzs
	NfrWUelSCUZw5316LG67SYPTpxwDtvQfpLQEXlgIKETDSfX1X7ajkO43M8nd18NsOgJZ3+k
	rS4F/3qNijgGtM1r888ikyN2U3sye43fLhbgDq7LQoxuoCAR0IdEpDcaQ38ceS1xUVVZUOv
	vPl2uBWJMZ87FdXnaH30k
X-QQ-SSF: 00000000000000F000000000000000Z
X-HAS-ATTACH: no
X-QQ-BUSINESS-ORIGIN: 2
X-Originating-IP: 202.141.236.219
X-QQ-STYLE: 
X-QQ-mid: webmail236t1412575229t5776495
From: "=?utf-8?B?VHJpZGVudA==?=" <cwk32@vip.qq.com>
To: "=?utf-8?B?ZGV2?=" <dev@spark.apache.org>
Subject: Too big data Spark SQL on Hive table on version 1.0.2 has some strange output
Mime-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----=_NextPart_54322FFD_08EA8190_36625AFC"
Content-Transfer-Encoding: 8Bit
Date: Mon, 6 Oct 2014 14:00:29 +0800
X-Priority: 3
Message-ID: <tencent_3C70B70305C6C02B50D3BC0A@qq.com>
X-QQ-MIME: TCMime 1.0 by Tencent
X-Mailer: QQMail 2.x
X-QQ-Mailer: QQMail 2.x
X-QQ-SENDSIZE: 520
X-Virus-Checked: Checked by ClamAV on apache.org

------=_NextPart_54322FFD_08EA8190_36625AFC
Content-Type: text/plain;
	charset="utf-8"
Content-Transfer-Encoding: base64
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------=_NextPart_54322FFD_08EA8190_36625AFC--


From dev-return-9693-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 06:19:33 2014
Return-Path: <dev-return-9693-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4C2A417EEF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 06:19:33 +0000 (UTC)
Received: (qmail 41939 invoked by uid 500); 6 Oct 2014 06:19:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41856 invoked by uid 500); 6 Oct 2014 06:19:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41835 invoked by uid 99); 6 Oct 2014 06:19:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 06:19:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of fairizazizi@gmail.com designates 74.125.82.52 as permitted sender)
Received: from [74.125.82.52] (HELO mail-wg0-f52.google.com) (74.125.82.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 06:19:25 +0000
Received: by mail-wg0-f52.google.com with SMTP id a1so5622801wgh.35
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 23:19:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:date:message-id:subject:from:to:content-type;
        bh=QVzW38kgD1YYiG3FmquPJiPSIObsCH9kz/MVXYodKJA=;
        b=jsyggskKlrH9xepjBmTKt2grRmskmGPC1MoSUP/PIhg+oUPhzzZg8tXu+4UH1Y2ltl
         FwycOS02Df37iBwoLLvx1zp/oqXc55T823GfxCaumhqrUx8+OZO0CXSWzf25gkAtagl6
         f5vfS5wBoz4CiTvLg8XkpkhgWs2g6Dc4WRo+c6CZRLPcSGMZ25I8pVgayyUSpob7Ra9u
         t41G/IDKv+/OqqXF/ibBHWsDP5DJwIyzpJ1bf8DRfEreOOg02X5OQBnjxmwgbQOzAMc/
         sxXi3EkJDysvj3yDD5wPBsjWgHZP3rVU8GlYOlReBFVy+f/BUFddrwro2BkCw0bFDE1w
         f5BQ==
MIME-Version: 1.0
X-Received: by 10.194.157.230 with SMTP id wp6mr27381013wjb.15.1412576344172;
 Sun, 05 Oct 2014 23:19:04 -0700 (PDT)
Sender: fairizazizi@gmail.com
Received: by 10.194.219.2 with HTTP; Sun, 5 Oct 2014 23:19:04 -0700 (PDT)
Received: by 10.194.219.2 with HTTP; Sun, 5 Oct 2014 23:19:04 -0700 (PDT)
Date: Sun, 5 Oct 2014 23:19:04 -0700
X-Google-Sender-Auth: m8T6Je8X_Gb8hyeavk_LwHsN9v4
Message-ID: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
Subject: Spark on Mesos 0.20
From: Fairiz Azizi <coderfi@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e013c64683671a10504bb0f77
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c64683671a10504bb0f77
Content-Type: text/plain; charset=UTF-8

The Spark online docs indicate that Spark is compatible with Mesos 0.18.1

I've gotten it to work just fine on 0.18.1 and 0.18.2

Has anyone tried Spark on a newer version of Mesos, i.e. Mesos v0.20.0?

-Fi

--089e013c64683671a10504bb0f77--

From dev-return-9694-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 06:45:23 2014
Return-Path: <dev-return-9694-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1C0DD17F30
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 06:45:23 +0000 (UTC)
Received: (qmail 64453 invoked by uid 500); 6 Oct 2014 06:45:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64385 invoked by uid 500); 6 Oct 2014 06:45:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 64374 invoked by uid 99); 6 Oct 2014 06:45:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 06:45:21 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of gurvinder.singh@uninett.no designates 158.38.180.100 as permitted sender)
Received: from [158.38.180.100] (HELO epost.uninett.no) (158.38.180.100)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 06:45:15 +0000
Received: from [158.38.62.52] (scintilla.uninett.no [158.38.62.52])
	(using TLSv1 with cipher DHE-RSA-AES128-SHA (128/128 bits))
	(No client certificate requested)
	by epost.uninett.no (Postfix) with ESMTPSA id CEB2A336585;
	Mon,  6 Oct 2014 08:44:52 +0200 (CEST)
Message-ID: <54323A64.2090205@uninett.no>
Date: Mon, 06 Oct 2014 08:44:52 +0200
From: Gurvinder Singh <gurvinder.singh@uninett.no>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.6.0
MIME-Version: 1.0
To: Fairiz Azizi <coderfi@gmail.com>, dev@spark.apache.org
Subject: Re: Spark on Mesos 0.20
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
In-Reply-To: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
> The Spark online docs indicate that Spark is compatible with Mesos 0.18.1
> 
> I've gotten it to work just fine on 0.18.1 and 0.18.2
> 
> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos v0.20.0?
> 
> -Fi
> 
Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in coarse
mode, in fine grain mode there is an issue with blockmanager names
conflict. I have been waiting for it to be fixed but it is still there.

-Gurvinder

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9695-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 06:59:12 2014
Return-Path: <dev-return-9695-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CB3FE17F68
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 06:59:12 +0000 (UTC)
Received: (qmail 75871 invoked by uid 500); 6 Oct 2014 06:59:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75801 invoked by uid 500); 6 Oct 2014 06:59:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75789 invoked by uid 99); 6 Oct 2014 06:59:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 06:59:11 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.47] (HELO mail-qa0-f47.google.com) (209.85.216.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 06:59:06 +0000
Received: by mail-qa0-f47.google.com with SMTP id cm18so3127068qab.6
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 23:58:46 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=Jzs3ZotAYY+jQscBooVllFgWwf2PiCxL2yozqVtxGVU=;
        b=ESWCjNmcRD4MOEP/aDcsRa1O0D9yTXkLh/qQ/mTIyK2dASZ8HCio8RfHjt2EewK37E
         GPbaXG2YI/ISvh7Wbr1kh+aqwqv0YDp/KmLKylKxntcC+19fF0T53998cX1LtyCVUx6A
         ZHlLfhcxwbpN7FgfAvTiCvfJaEpHuTMuQAsat9CD57k1oPwPnCcglOi9wxV93HXiCtOm
         3EZuxHT90njJtDQkXoUO9/+f1XjPHCIQSK/QmKd/i8GNyEpW2UCKyu0twPtT1Snpalfi
         csiGOey1Wd1h4kX9la8dm/Qr2J9heHmV4jTVVx5RnXA0I8+4bZHpJQZxKd+2hXz7qYHC
         wlxg==
X-Gm-Message-State: ALoCoQnvyAtLkVIR8spsVv58jQafH2d0WWxx6LarSMG4tS9KvSDCdMnvC5jGwSLRdAi1Py4+FIL7
X-Received: by 10.224.97.72 with SMTP id k8mr27236328qan.21.1412578725936;
        Sun, 05 Oct 2014 23:58:45 -0700 (PDT)
Received: from mail-qa0-f41.google.com (mail-qa0-f41.google.com [209.85.216.41])
        by mx.google.com with ESMTPSA id b102sm2930080qge.37.2014.10.05.23.58.44
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 05 Oct 2014 23:58:44 -0700 (PDT)
Received: by mail-qa0-f41.google.com with SMTP id n8so3186770qaq.28
        for <dev@spark.apache.org>; Sun, 05 Oct 2014 23:58:44 -0700 (PDT)
X-Received: by 10.224.161.139 with SMTP id r11mr27966329qax.68.1412578724578;
 Sun, 05 Oct 2014 23:58:44 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.109.225 with HTTP; Sun, 5 Oct 2014 23:58:24 -0700 (PDT)
In-Reply-To: <54323A64.2090205@uninett.no>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
 <54323A64.2090205@uninett.no>
From: Andrew Ash <andrew@andrewash.com>
Date: Mon, 6 Oct 2014 02:58:24 -0400
Message-ID: <CA+-p3AGWz0MSo3oB=2qCMt4-fPHSoMhNGZoshGfDXndr39eRJQ@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
To: Gurvinder Singh <gurvinder.singh@uninett.no>
Cc: Fairiz Azizi <coderfi@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01536924188e770504bb9d92
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01536924188e770504bb9d92
Content-Type: text/plain; charset=UTF-8

Hi Gurvinder,

Is there a SPARK ticket tracking the issue you describe?

On Mon, Oct 6, 2014 at 2:44 AM, Gurvinder Singh <gurvinder.singh@uninett.no>
wrote:

> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
> > The Spark online docs indicate that Spark is compatible with Mesos 0.18.1
> >
> > I've gotten it to work just fine on 0.18.1 and 0.18.2
> >
> > Has anyone tried Spark on a newer version of Mesos, i.e. Mesos v0.20.0?
> >
> > -Fi
> >
> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in coarse
> mode, in fine grain mode there is an issue with blockmanager names
> conflict. I have been waiting for it to be fixed but it is still there.
>
> -Gurvinder
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e01536924188e770504bb9d92--

From dev-return-9696-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 07:30:42 2014
Return-Path: <dev-return-9696-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 42DEC171D5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 07:30:42 +0000 (UTC)
Received: (qmail 11313 invoked by uid 500); 6 Oct 2014 07:30:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11231 invoked by uid 500); 6 Oct 2014 07:30:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11219 invoked by uid 99); 6 Oct 2014 07:30:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 07:30:40 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tnachen@gmail.com designates 209.85.218.52 as permitted sender)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 07:30:15 +0000
Received: by mail-oi0-f52.google.com with SMTP id a3so3175864oib.39
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 00:30:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=1ZdosPqnA5Hjon99AUZ1XygY9jWcniiuglBammFOSZE=;
        b=YDazcShlrwLjaEylAS2pD8t8VXyB8j7dtL80L18FAimuztxQOFsIJYoV7rFOeQVPe+
         u1Bpdi4DJiM7GJVmgvSOCZYFfLVbZvRfBWNmhjAUV3R5xWLv6b5PURhgTbSDgZPDk1po
         VocXLAAABsbjNItaaSQTrA1CzwdRfSxbv6Ylx4zP2Faf6AVwYKr05jZeWWWAzw1DJsX1
         C8vpwRadwsgsPIHGKQ/iooexaa0l6z82Ou8PSAnNQJwrgmtd9oG5nKf3s1UicydMW1fc
         eZxxmPBRtLnSHHhuOdOO8FdUC9MwAv/IlLZd9nLBJB/yndRyHHbPYk23f79olsmZSgKG
         7Mag==
MIME-Version: 1.0
X-Received: by 10.60.125.135 with SMTP id mq7mr11944647oeb.11.1412580614045;
 Mon, 06 Oct 2014 00:30:14 -0700 (PDT)
Received: by 10.60.174.227 with HTTP; Mon, 6 Oct 2014 00:30:13 -0700 (PDT)
In-Reply-To: <54323A64.2090205@uninett.no>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
	<54323A64.2090205@uninett.no>
Date: Mon, 6 Oct 2014 00:30:13 -0700
Message-ID: <CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
From: Timothy Chen <tnachen@gmail.com>
To: Gurvinder Singh <gurvinder.singh@uninett.no>
Cc: Fairiz Azizi <coderfi@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Gurvinder,

I tried fine grain mode before and didn't get into that problem.


On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
<gurvinder.singh@uninett.no> wrote:
> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>> The Spark online docs indicate that Spark is compatible with Mesos 0.18.1
>>
>> I've gotten it to work just fine on 0.18.1 and 0.18.2
>>
>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos v0.20.0?
>>
>> -Fi
>>
> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in coarse
> mode, in fine grain mode there is an issue with blockmanager names
> conflict. I have been waiting for it to be fixed but it is still there.
>
> -Gurvinder
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9697-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 07:31:12 2014
Return-Path: <dev-return-9697-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DBE7B171DA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 07:31:11 +0000 (UTC)
Received: (qmail 12785 invoked by uid 500); 6 Oct 2014 07:31:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12706 invoked by uid 500); 6 Oct 2014 07:31:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12694 invoked by uid 99); 6 Oct 2014 07:31:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 07:31:10 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of tnachen@gmail.com designates 209.85.218.44 as permitted sender)
Received: from [209.85.218.44] (HELO mail-oi0-f44.google.com) (209.85.218.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 07:31:06 +0000
Received: by mail-oi0-f44.google.com with SMTP id x69so3212281oia.17
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 00:30:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=n3tLFBMY4JFgylGoEP0FZUwdwMQEoDFjtvkKLZDybIQ=;
        b=a4gFRm7UUDsqVgWybWKnsSsfuCXhR/FiFjgnlMzd5kJUe1PbwZCd45HbFqe3o7tQDG
         QLpJ0HqryPXzjFuE+1eries7L0ULlCbS98QQiMmUiH3XlAgEvtSDlbhQzFY9vSIQ22Ja
         p6X4qhh8LSxUEtHt6mTwzYENdCYBWQXJYaOIDSY840kDwmlL6c8+nszoD4eHSmwSZfRq
         9xGCf5gBINAq1Y59mClvrR4uAKQQ2fcVDJ+XqceEB5ZjTuow/Sk/cCBQyN5PoWx10GrT
         nBaTVDnuYo8x+r2FTY8K9zthK2JRTHLvWsmzRuVIH+6r5HZwch0AXF3cSA5YSw1bFXy+
         A13w==
MIME-Version: 1.0
X-Received: by 10.60.219.8 with SMTP id pk8mr25111491oec.28.1412580645426;
 Mon, 06 Oct 2014 00:30:45 -0700 (PDT)
Received: by 10.60.174.227 with HTTP; Mon, 6 Oct 2014 00:30:45 -0700 (PDT)
In-Reply-To: <CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
	<54323A64.2090205@uninett.no>
	<CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
Date: Mon, 6 Oct 2014 00:30:45 -0700
Message-ID: <CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
From: Timothy Chen <tnachen@gmail.com>
To: Gurvinder Singh <gurvinder.singh@uninett.no>
Cc: Fairiz Azizi <coderfi@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

(Hit enter too soon...)

What is your setup and steps to repro this?

Tim

On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com> wrote:
> Hi Gurvinder,
>
> I tried fine grain mode before and didn't get into that problem.
>
>
> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
> <gurvinder.singh@uninett.no> wrote:
>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>>> The Spark online docs indicate that Spark is compatible with Mesos 0.18.1
>>>
>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
>>>
>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos v0.20.0?
>>>
>>> -Fi
>>>
>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in coarse
>> mode, in fine grain mode there is an issue with blockmanager names
>> conflict. I have been waiting for it to be fixed but it is still there.
>>
>> -Gurvinder
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9698-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 07:50:47 2014
Return-Path: <dev-return-9698-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C9D521726E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 07:50:47 +0000 (UTC)
Received: (qmail 53081 invoked by uid 500); 6 Oct 2014 07:50:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53014 invoked by uid 500); 6 Oct 2014 07:50:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53003 invoked by uid 99); 6 Oct 2014 07:50:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 07:50:46 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of gurvinder.singh@uninett.no designates 158.38.180.100 as permitted sender)
Received: from [158.38.180.100] (HELO epost.uninett.no) (158.38.180.100)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 07:50:41 +0000
Received: from [158.38.62.52] (scintilla.uninett.no [158.38.62.52])
	(using TLSv1 with cipher DHE-RSA-AES128-SHA (128/128 bits))
	(No client certificate requested)
	by epost.uninett.no (Postfix) with ESMTPSA id 81FBF336715;
	Mon,  6 Oct 2014 09:50:19 +0200 (CEST)
Message-ID: <543249BB.505@uninett.no>
Date: Mon, 06 Oct 2014 09:50:19 +0200
From: Gurvinder Singh <gurvinder.singh@uninett.no>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.6.0
MIME-Version: 1.0
To: Timothy Chen <tnachen@gmail.com>
CC: Fairiz Azizi <coderfi@gmail.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: Spark on Mesos 0.20
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>	<54323A64.2090205@uninett.no>	<CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com> <CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
In-Reply-To: <CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

The issue does not occur if the task at hand has small number of map
tasks. I have a task which has 978 map tasks and I see this error as

14/10/06 09:34:40 ERROR BlockManagerMasterActor: Got two different block
manager registrations on 20140711-081617-711206558-5050-2543-5

Here is the log from the mesos-slave where this container was running.

http://pastebin.com/Q1Cuzm6Q

If you look for the code from where error produced by spark, you will
see that it simply exit and saying in comments "this should never
happen, lets just quit" :-)

- Gurvinder
On 10/06/2014 09:30 AM, Timothy Chen wrote:
> (Hit enter too soon...)
> 
> What is your setup and steps to repro this?
> 
> Tim
> 
> On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com> wrote:
>> Hi Gurvinder,
>>
>> I tried fine grain mode before and didn't get into that problem.
>>
>>
>> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
>> <gurvinder.singh@uninett.no> wrote:
>>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>>>> The Spark online docs indicate that Spark is compatible with Mesos 0.18.1
>>>>
>>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
>>>>
>>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos v0.20.0?
>>>>
>>>> -Fi
>>>>
>>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in coarse
>>> mode, in fine grain mode there is an issue with blockmanager names
>>> conflict. I have been waiting for it to be fixed but it is still there.
>>>
>>> -Gurvinder
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9699-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 08:27:42 2014
Return-Path: <dev-return-9699-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 86004173C6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 08:27:42 +0000 (UTC)
Received: (qmail 97990 invoked by uid 500); 6 Oct 2014 08:27:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97911 invoked by uid 500); 6 Oct 2014 08:27:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95521 invoked by uid 99); 6 Oct 2014 08:27:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 08:27:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of guillaume.pitel@exensa.com designates 91.121.232.90 as permitted sender)
Received: from [91.121.232.90] (HELO mail.exensa.com) (91.121.232.90)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 08:27:28 +0000
Received: from localhost (localhost [127.0.0.1])
	by mail.exensa.com (Postfix) with ESMTP id E6CF4640197
	for <dev@spark.apache.org>; Mon,  6 Oct 2014 08:27:06 +0000 (UTC)
Received: from mail.exensa.com ([127.0.0.1])
	by localhost (mail.exensa.com [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id 9r8v7BsHKzO3 for <dev@spark.apache.org>;
	Mon,  6 Oct 2014 08:27:06 +0000 (UTC)
Received: from [10.1.42.6] (LPuteaux-656-01-229-158.w80-12.abo.wanadoo.fr [80.12.90.158])
	(using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128 bits))
	(No client certificate requested)
	by mail.exensa.com (Postfix) with ESMTPSA id C40416400B0
	for <dev@spark.apache.org>; Mon,  6 Oct 2014 08:27:06 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=exensa.com;
	s=default; t=1412584026;
	bh=Pdi/6QdCTiy4+qVsUb58P0By0JKUUwRrHS22GoVJrbQ=;
	h=Date:From:To:Subject;
	b=UhyPGWDKffwxZbFZ+woLSz71zQoSbR+9l3Xd/b3VAwvOcqLdUCl0ebRTH2ZqHNoPL
	 NgGtmifl1fYqUdWWAxpGWVMFCoQYBfLUmk70iTSA7HfC9jnl11X4PmfPcFZbbra
Message-ID: <5432525A.8040109@exensa.com>
Date: Mon, 06 Oct 2014 10:27:06 +0200
From: Guillaume Pitel <guillaume.pitel@exensa.com>
Organization: eXenSa
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: TorrentBroadcast slow performance
Content-Type: multipart/alternative;
 boundary="------------000303060207080209060705"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------000303060207080209060705
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

Hi,

I've had no answer to this on user@spark.apache.org, so I post it on dev before 
filing a JIRA (in case the problem or solution is already identified)

We've had some performance issues since switching to 1.1.0, and we finally found 
the origin : TorrentBroadcast seems to be very slow in our setting (and it 
became default with 1.1.0)

The logs of a 4MB variable with TorrentBroadcast : (15s)

14/10/01 15:47:13 INFO storage.MemoryStore: Block broadcast_84_piece1 stored as 
bytes in memory (estimated size 171.6 KB, free 7.2 GB)
14/10/01 15:47:13 INFO storage.BlockManagerMaster: Updated info of block 
broadcast_84_piece1
14/10/01 15:47:23 INFO storage.MemoryStore: ensureFreeSpace(4194304) called with 
curMem=1401611984, maxMem=9168696115
14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84_piece0 stored as 
bytes in memory (estimated size 4.0 MB, free 7.2 GB)
14/10/01 15:47:23 INFO storage.BlockManagerMaster: Updated info of block 
broadcast_84_piece0
14/10/01 15:47:23 INFO broadcast.TorrentBroadcast: Reading broadcast variable 84 
took 15.202260006 s
14/10/01 15:47:23 INFO storage.MemoryStore: ensureFreeSpace(4371392) called with 
curMem=1405806288, maxMem=9168696115
14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84 stored as values 
in memory (estimated size 4.2 MB, free 7.2 GB)

(notice that a 10s lag happens after the "Updated info of block broadcast_..." 
and before the MemoryStore log

And with HttpBroadcast (0.3s):

14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Started reading broadcast 
variable 147
14/10/01 16:05:58 INFO storage.MemoryStore: ensureFreeSpace(4369376) called with 
curMem=1373493232, maxMem=9168696115
14/10/01 16:05:58 INFO storage.MemoryStore: Block broadcast_147 stored as values 
in memory (estimated size 4.2 MB, free 7.3 GB)
14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Reading broadcast variable 147 
took 0.320907112 s 14/10/01 16:05:58 INFO storage.BlockManager: Found block 
broadcast_147 locally

Since Torrent is supposed to perform much better than Http, we suspect a 
configuration error from our side, but are unable to pin it down. Does someone 
have any idea of the origin of the problem ?

For now we're sticking with the HttpBroadcast workaround.

Guillaume
-- 
eXenSa

	
*Guillaume PITEL, Prsident*
+33(0)626 222 431

eXenSa S.A.S. <http://www.exensa.com/>
41, rue Prier - 92120 Montrouge - FRANCE
Tel +33(0)184 163 677 / Fax +33(0)972 283 705


--------------000303060207080209060705
Content-Type: multipart/related;
 boundary="------------060706070304060607040305"


--------------060706070304060607040305
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: 8bit

<html>
  <head>

    <meta http-equiv="content-type" content="text/html; charset=utf-8">
  </head>
  <body bgcolor="#FFFFFF" text="#000000">
    Hi,<br>
    <br>
    I've had no answer to this on <a class="moz-txt-link-abbreviated" href="mailto:user@spark.apache.org">user@spark.apache.org</a>, so I post it on
    dev before filing a JIRA (in case the problem or solution is already
    identified)<br>
    <br>
    We've had some performance issues since switching to 1.1.0, and we
    finally found the origin : TorrentBroadcast seems to be very slow in
    our setting (and it became default with 1.1.0)<br>
    <br>
    The logs of a 4MB variable with TorrentBroadcast : (15s) <br>
    <br>
    <tt>14/10/01 15:47:13 INFO storage.MemoryStore: Block
      broadcast_84_piece1 stored as bytes in memory (estimated size
      171.6 KB, free 7.2 GB) </tt><tt><br>
    </tt><tt>14/10/01 15:47:13 INFO storage.BlockManagerMaster: Updated
      info of block broadcast_84_piece1 </tt><tt><br>
    </tt><tt>14/10/01 15:47:23 INFO storage.MemoryStore:
      ensureFreeSpace(4194304) called with curMem=1401611984,
      maxMem=9168696115 </tt><tt><br>
    </tt><tt>14/10/01 15:47:23 INFO storage.MemoryStore: Block
      broadcast_84_piece0 stored as bytes in memory (estimated size 4.0
      MB, free 7.2 GB) </tt><tt><br>
    </tt><tt>14/10/01 15:47:23 INFO storage.BlockManagerMaster: Updated
      info of block broadcast_84_piece0 </tt><tt><br>
    </tt><tt>14/10/01 15:47:23 INFO broadcast.TorrentBroadcast: Reading
      broadcast variable 84 took 15.202260006 s </tt><tt><br>
    </tt><tt>14/10/01 15:47:23 INFO storage.MemoryStore:
      ensureFreeSpace(4371392) called with curMem=1405806288,
      maxMem=9168696115 </tt><tt><br>
    </tt><tt>14/10/01 15:47:23 INFO storage.MemoryStore: Block
      broadcast_84 stored as values in memory (estimated size 4.2 MB,
      free 7.2 GB)</tt><br>
    <br>
    (notice that a 10s lag happens after the "Updated info of block
    broadcast_..." and before the MemoryStore log<br>
    <br>
    And with HttpBroadcast (0.3s):<br>
    <br>
    <tt>14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Started reading
      broadcast variable 147 </tt><tt><br>
    </tt><tt>14/10/01 16:05:58 INFO storage.MemoryStore:
      ensureFreeSpace(4369376) called with curMem=1373493232,
      maxMem=9168696115 </tt><tt><br>
    </tt><tt>14/10/01 16:05:58 INFO storage.MemoryStore: Block
      broadcast_147 stored as values in memory (estimated size 4.2 MB,
      free 7.3 GB) </tt><tt><br>
    </tt><tt>14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Reading
      broadcast variable 147 took 0.320907112 s 14/10/01 16:05:58 INFO
      storage.BlockManager: Found block broadcast_147 locally</tt><br>
    <br>
    Since Torrent is supposed to perform much better than Http, we
    suspect a configuration error from our side, but are unable to pin
    it down. Does someone have any idea of the origin of the problem ?<br>
    <br>
    For now we're sticking with the HttpBroadcast workaround.<br>
    <br>
    Guillaume
    <div class="moz-signature">-- <br>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <span style="font-size: 8.5pt; color: rgb(51, 51, 51);
        font-family: Helvetica;">
        <div style="width: 529px;" align="left">
          <table style="width: 524px;" border="0" cellpadding="0"
            cellspacing="0">
            <tbody>
              <tr>
                <td style="border-top: medium none rgb(236, 233, 216);
                  border-right: medium none rgb(236, 233, 216);
                  border-bottom: medium none rgb(236, 233, 216);
                  padding-right: 0cm; width: 219px; height: 33.75pt;
                  background-color: transparent; vertical-align:
                  middle;">
                  <center style="width: 210px;"><img style="border: 0px
                      solid ; width: 160px; height: 64px;" alt="eXenSa"
                      src="cid:part1.08070100.07060202@exensa.com"></center>
                </td>
                <td style="padding-left:10px; border-top: medium none
                  rgb(236, 233, 216); border-right: medium none rgb(236,
                  233, 216); border-bottom: medium none rgb(236, 233,
                  216); padding-right: 0cm; width: 358px; height:
                  33.75pt; background-color: transparent;
                  vertical-align: top;">
                  <div style="text-align: left; width: 299px;"
                    align="left"> <span style="font-size: 7.5pt; color:
                      rgb(75, 80, 85); font-family: Helvetica;"> <b>Guillaume
                        PITEL, Prsident</b> <br>
                      +33(0)626 222 431<br>
                    </span> <br>
                    <span style="font-size: 7.5pt; color: #505050;
                      font-family: Helvetica;"><a
                        href="http://www.exensa.com/" target="_blank">eXenSa
                        S.A.S.</a> </span><br>
                    <span style="font-size: 7.5pt; color: rgb(75, 80,
                      85);"> <font face="Helvetica">41, rue Prier -
                        92120 Montrouge - FRANCE <br>
                        Tel +33(0)184 163 677 / Fax +33(0)972 283 705 </font>
                    </span> </div>
                </td>
              </tr>
            </tbody>
          </table>
        </div>
      </span>
    </div>
  </body>
</html>

--------------060706070304060607040305
Content-Type: image/png;
 name="exensa_logo_mail.png"
Content-Transfer-Encoding: base64
Content-ID: <part1.08070100.07060202@exensa.com>
Content-Disposition: inline;
 filename="exensa_logo_mail.png"
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==
--------------060706070304060607040305--

--------------000303060207080209060705--

From dev-return-9700-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 13:08:52 2014
Return-Path: <dev-return-9700-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F0EEE17BBE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 13:08:52 +0000 (UTC)
Received: (qmail 97810 invoked by uid 500); 6 Oct 2014 13:08:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97744 invoked by uid 500); 6 Oct 2014 13:08:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97720 invoked by uid 99); 6 Oct 2014 13:08:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 13:08:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rnowling@gmail.com designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 13:08:24 +0000
Received: by mail-wi0-f178.google.com with SMTP id cc10so4514551wib.11
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 06:08:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=9SyzTNMbi2p1O/W5shcMIQIYXNlrYM3Lt/Z2xKOy0Ss=;
        b=MYfyD4IY/WicBBi41V8AJVSnc00fVf10EjiC4UW54KNjZClWi7AgW48QurlpEjkCJq
         AE0fxXB5mRBnG1meVwuqq0i5SO0aDY4HbtyqoD9lOqLXCB6VpSYoFIdrYwVxjEOsZLg9
         VZKf4ph+UplXYP4iL2SYOMKnG6nbfvsHLYhDqzdCU4reGn9eTl5db4+Uk5T2jpCG9lJN
         73FNTfnOKQ6nRtEoJiruhmiCxWD3tLnKD7RudFt0NYkon3k3d6joQS5RnRjgpLPv6RRX
         b3t7JGGrs0kEQ39I2b0NWvTTL/YKLk1SDXvMTyylg18Wd209hq9Jbh2hcBe7pNwrTCdM
         XbFQ==
MIME-Version: 1.0
X-Received: by 10.180.99.163 with SMTP id er3mr18910533wib.23.1412600903683;
 Mon, 06 Oct 2014 06:08:23 -0700 (PDT)
Received: by 10.194.57.80 with HTTP; Mon, 6 Oct 2014 06:08:23 -0700 (PDT)
In-Reply-To: <543249BB.505@uninett.no>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
	<54323A64.2090205@uninett.no>
	<CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
	<CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
	<543249BB.505@uninett.no>
Date: Mon, 6 Oct 2014 09:08:23 -0400
Message-ID: <CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
From: RJ Nowling <rnowling@gmail.com>
To: Gurvinder Singh <gurvinder.singh@uninett.no>
Cc: Timothy Chen <tnachen@gmail.com>, Fairiz Azizi <coderfi@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d041825a212d2e00504c0c7e9
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d041825a212d2e00504c0c7e9
Content-Type: text/plain; charset=UTF-8

I've recently run into this issue as well. I get it from running Spark
examples such as log query.  Maybe that'll help reproduce the issue.

On Monday, October 6, 2014, Gurvinder Singh <gurvinder.singh@uninett.no>
wrote:

> The issue does not occur if the task at hand has small number of map
> tasks. I have a task which has 978 map tasks and I see this error as
>
> 14/10/06 09:34:40 ERROR BlockManagerMasterActor: Got two different block
> manager registrations on 20140711-081617-711206558-5050-2543-5
>
> Here is the log from the mesos-slave where this container was running.
>
> http://pastebin.com/Q1Cuzm6Q
>
> If you look for the code from where error produced by spark, you will
> see that it simply exit and saying in comments "this should never
> happen, lets just quit" :-)
>
> - Gurvinder
> On 10/06/2014 09:30 AM, Timothy Chen wrote:
> > (Hit enter too soon...)
> >
> > What is your setup and steps to repro this?
> >
> > Tim
> >
> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com
> <javascript:;>> wrote:
> >> Hi Gurvinder,
> >>
> >> I tried fine grain mode before and didn't get into that problem.
> >>
> >>
> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
> >> <gurvinder.singh@uninett.no <javascript:;>> wrote:
> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
> >>>> The Spark online docs indicate that Spark is compatible with Mesos
> 0.18.1
> >>>>
> >>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
> >>>>
> >>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos
> v0.20.0?
> >>>>
> >>>> -Fi
> >>>>
> >>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in coarse
> >>> mode, in fine grain mode there is an issue with blockmanager names
> >>> conflict. I have been waiting for it to be fixed but it is still there.
> >>>
> >>> -Gurvinder
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> <javascript:;>
> >>> For additional commands, e-mail: dev-help@spark.apache.org
> <javascript:;>
> >>>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> For additional commands, e-mail: dev-help@spark.apache.org <javascript:;>
>
>

-- 
em rnowling@gmail.com
c 954.496.2314

--f46d041825a212d2e00504c0c7e9--

From dev-return-9701-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 14:07:49 2014
Return-Path: <dev-return-9701-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E3C2D17D84
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 14:07:49 +0000 (UTC)
Received: (qmail 49809 invoked by uid 500); 6 Oct 2014 14:07:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49739 invoked by uid 500); 6 Oct 2014 14:07:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49714 invoked by uid 99); 6 Oct 2014 14:07:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 14:07:48 +0000
X-ASF-Spam-Status: No, hits=2.4 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_RHS_DOB
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.214.182] (HELO mail-ob0-f182.google.com) (209.85.214.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 14:07:23 +0000
Received: by mail-ob0-f182.google.com with SMTP id uy5so3902788obc.41
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 07:07:21 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=ICzWPU2CG9eUdXok6coEc3lab+Qol1tI0m4LN1FAA18=;
        b=AW3m9Pt3+1wx7b34SzXLhsaUV2Vszmjhbm7L5sbbq0g8rae5O/2FA0TkGlnFvCBCSS
         7jdieqJew5EE4wkZNt9Qj+ZUBKK7UBtUqmHl4lVgLFEMrl/lUBpLAm12ZJUfnGMzplpv
         EtZ4NJfIr16450IDuRfXB6wbnTCdwebq19AgQoye2Ej1eAIkBuOoy9bvRjnGIIQvFEjy
         fYzQBM7n4gH011/3VkIosQHAeu7mH9tZ42i2RMRbsu9voD163G0WKg5MNxXocWDnQSVN
         qbvgIY0SmemRrexgNE/gIpGSaVdk7tej//4086htw7liLbiYpDm8STqSkR0RgFE0GWwL
         Au2g==
X-Gm-Message-State: ALoCoQl/nLgvez+y8NQuISXmfx2K8JlusAP235WJMLMYl0441rAqC3/lYiGQ8+Q38M6ydA4iJw8G
MIME-Version: 1.0
X-Received: by 10.60.82.163 with SMTP id j3mr9342714oey.44.1412604440748; Mon,
 06 Oct 2014 07:07:20 -0700 (PDT)
Received: by 10.76.158.162 with HTTP; Mon, 6 Oct 2014 07:07:20 -0700 (PDT)
In-Reply-To: <CAAswR-4-Z7m7z0+Sp1NHhSS1-YNx1vTVn_Kag7-PKuGgn-DwmA@mail.gmail.com>
References: <CAKWX9VWaNzDcHjxFC3XpwSG+bi7Y+bM2z1jo2g2D8kR1aFES6w@mail.gmail.com>
	<CA+-p3AGEW78LtPbDBHvf1qzsV3bYSwtpBQAS04jRkFq5e0rBzw@mail.gmail.com>
	<CAAswR-4-Z7m7z0+Sp1NHhSS1-YNx1vTVn_Kag7-PKuGgn-DwmA@mail.gmail.com>
Date: Mon, 6 Oct 2014 09:07:20 -0500
Message-ID: <CAKWX9VXu4yv2ubKE3-5o6FYHZh068Fk_0f98Mac8tK4Aw--1-w@mail.gmail.com>
Subject: Re: Parquet schema migrations
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: Andrew Ash <andrew@andrewash.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b5dbcfae63e950504c1999d
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5dbcfae63e950504c1999d
Content-Type: text/plain; charset=UTF-8

Sorry, by "raw parquet" I just meant there is no external metadata store,
only the schema written as part of the parquet format.

We've done several different kinds of changes, including column rename and
widening the data type of an existing column.  I don't think it's feasible
to support those.

The kind of change we've made that it probably makes most sense to support
is adding a nullable column. I think that also implies supporting
"removing" a nullable column, as long as you don't end up with columns of
the same name but different type.

I'm not sure semantically that it makes sense to do schema merging as part
of union all, and definitely doesn't make sense to do it by default.  I
wouldn't want two accidentally compatible schema to get merged without
warning.  It's also a little odd since unlike a normal sql database union
all can happen before there are any projections or filters... e.g. what
order do columns come back in if someone does select *.

Seems like there should be either a separate api call, or an optional
argument to union all.

As far as resources go, I can probably put some personal time into this if
we come up with a plan that makes sense.


On Sun, Oct 5, 2014 at 7:36 PM, Michael Armbrust <michael@databricks.com>
wrote:

> Hi Cody,
>
> Assuming you are talking about 'safe' changes to the schema (i.e. existing
> column names are never reused with incompatible types), this is something
> I'd love to support.  Perhaps you can describe more what sorts of changes
> you are making, and if simple merging of the schemas would be sufficient.
> If so, we can open a JIRA, though I'm not sure when we'll have resources to
> dedicate to this.
>
> In the near term, I'd suggest writing converters for each version of the
> schema, that translate to some desired master schema.  You can then union
> all of these together and avoid the cost of batch conversion.  It seems
> like in most cases this should be pretty efficient, at least now that we
> have good pushdown past union operators :)
>
> Michael
>
> On Sun, Oct 5, 2014 at 3:58 PM, Andrew Ash <andrew@andrewash.com> wrote:
>
>> Hi Cody,
>>
>> I wasn't aware there were different versions of the parquet format.
>> What's
>> the difference between "raw parquet" and the Hive-written parquet files?
>>
>> As for your migration question, the approaches I've often seen are
>> convert-on-read and convert-all-at-once.  Apache Cassandra for example
>> does
>> both -- when upgrading between Cassandra versions that change the on-disk
>> sstable format, it will do a convert-on-read as you access the sstables,
>> or
>> you can run the upgradesstables command to convert them all at once
>> post-upgrade.
>>
>> Andrew
>>
>> On Fri, Oct 3, 2014 at 4:33 PM, Cody Koeninger <cody@koeninger.org>
>> wrote:
>>
>> > Wondering if anyone has thoughts on a path forward for parquet schema
>> > migrations, especially for people (like us) that are using raw parquet
>> > files rather than Hive.
>> >
>> > So far we've gotten away with reading old files, converting, and
>> writing to
>> > new directories, but that obviously becomes problematic above a certain
>> > data size.
>> >
>>
>
>

--047d7b5dbcfae63e950504c1999d--

From dev-return-9702-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 16:21:17 2014
Return-Path: <dev-return-9702-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 05D511737D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 16:21:17 +0000 (UTC)
Received: (qmail 72800 invoked by uid 500); 6 Oct 2014 16:21:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 72722 invoked by uid 500); 6 Oct 2014 16:21:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 72708 invoked by uid 99); 6 Oct 2014 16:21:15 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 16:21:15 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of tnachen@gmail.com designates 209.85.214.173 as permitted sender)
Received: from [209.85.214.173] (HELO mail-ob0-f173.google.com) (209.85.214.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 16:20:50 +0000
Received: by mail-ob0-f173.google.com with SMTP id wp4so4209413obc.32
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 09:20:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=SJBzEtbfEDaR9O+c828bYWUVJVlvhdO3dqRoxjCPlDU=;
        b=cqtoA8ZfmrJCkjdA/K3Z6KISuYE3KEglIZ3na7APYMXyPmV62IGcCIY0VC07Uq47tf
         U+ycCdZ1/pbFZgA3rqKxSR20GR29CIW/CxJV8qCifty6nsKt8alZTUfXt2tm2H9x92ZW
         s3xVA+p9IGzHqbQVVDPuJTx1kWW6Kj4wrxGbfVuRVshr5TAxSh8XC8FHFAIJjOL6SIBh
         sDF2XgtCGBxECiHHd2TdyGFx2LAYppi8cLJL4eVtrZfk0dSZO7JqvrMIu2qPu2ngFQhc
         E7icxcNvf6itS2BT/2HED6wYlAh2VgVwFwKYzUmRGmkG3vBaIraerj1o6VVjOp/BB4aW
         GL6g==
MIME-Version: 1.0
X-Received: by 10.60.23.8 with SMTP id i8mr28819956oef.42.1412612449342; Mon,
 06 Oct 2014 09:20:49 -0700 (PDT)
Received: by 10.60.174.227 with HTTP; Mon, 6 Oct 2014 09:20:49 -0700 (PDT)
In-Reply-To: <CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
	<54323A64.2090205@uninett.no>
	<CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
	<CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
	<543249BB.505@uninett.no>
	<CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
Date: Mon, 6 Oct 2014 09:20:49 -0700
Message-ID: <CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
From: Timothy Chen <tnachen@gmail.com>
To: RJ Nowling <rnowling@gmail.com>
Cc: Gurvinder Singh <gurvinder.singh@uninett.no>, Fairiz Azizi <coderfi@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Ok I created SPARK-3817 to track this, will try to repro it as well.

Tim

On Mon, Oct 6, 2014 at 6:08 AM, RJ Nowling <rnowling@gmail.com> wrote:
> I've recently run into this issue as well. I get it from running Spark
> examples such as log query.  Maybe that'll help reproduce the issue.
>
>
> On Monday, October 6, 2014, Gurvinder Singh <gurvinder.singh@uninett.no>
> wrote:
>>
>> The issue does not occur if the task at hand has small number of map
>> tasks. I have a task which has 978 map tasks and I see this error as
>>
>> 14/10/06 09:34:40 ERROR BlockManagerMasterActor: Got two different block
>> manager registrations on 20140711-081617-711206558-5050-2543-5
>>
>> Here is the log from the mesos-slave where this container was running.
>>
>> http://pastebin.com/Q1Cuzm6Q
>>
>> If you look for the code from where error produced by spark, you will
>> see that it simply exit and saying in comments "this should never
>> happen, lets just quit" :-)
>>
>> - Gurvinder
>> On 10/06/2014 09:30 AM, Timothy Chen wrote:
>> > (Hit enter too soon...)
>> >
>> > What is your setup and steps to repro this?
>> >
>> > Tim
>> >
>> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com> wrote:
>> >> Hi Gurvinder,
>> >>
>> >> I tried fine grain mode before and didn't get into that problem.
>> >>
>> >>
>> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
>> >> <gurvinder.singh@uninett.no> wrote:
>> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>> >>>> The Spark online docs indicate that Spark is compatible with Mesos
>> >>>> 0.18.1
>> >>>>
>> >>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
>> >>>>
>> >>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos
>> >>>> v0.20.0?
>> >>>>
>> >>>> -Fi
>> >>>>
>> >>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in
>> >>> coarse
>> >>> mode, in fine grain mode there is an issue with blockmanager names
>> >>> conflict. I have been waiting for it to be fixed but it is still
>> >>> there.
>> >>>
>> >>> -Gurvinder
>> >>>
>> >>> ---------------------------------------------------------------------
>> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >>> For additional commands, e-mail: dev-help@spark.apache.org
>> >>>
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>
>
> --
> em rnowling@gmail.com
> c 954.496.2314

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9703-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 20:49:08 2014
Return-Path: <dev-return-9703-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7784417368
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 20:49:08 +0000 (UTC)
Received: (qmail 75144 invoked by uid 500); 6 Oct 2014 20:49:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75063 invoked by uid 500); 6 Oct 2014 20:49:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75052 invoked by uid 99); 6 Oct 2014 20:49:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 20:49:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of daniil.osipov@shazam.com designates 209.85.213.182 as permitted sender)
Received: from [209.85.213.182] (HELO mail-ig0-f182.google.com) (209.85.213.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 20:49:02 +0000
Received: by mail-ig0-f182.google.com with SMTP id hn18so3538022igb.9
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 13:48:40 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=IJO/2Bryjt6kBXfvUP8N1vrsjLWsOpEsbOgMWNN0KXs=;
        b=POzOyfkizZdt84yUTnh4yDXIu/KMvwHxtgGsbKrHJ0JkmYxNoHkZd/iOMZyGlG1ETe
         4Vt/ylGYp2tfGEBH1kvYCkPp5LYQy5iGcwybbk4lEa1z9esTHUKANB1ZZgaDBFBSmejv
         H7YJV2RI5ZeImytyc70KHG/g1S4x3MLQCtJFYUx2nPIJFng6afdbHLfNKLhK42rFbVKF
         QlEs1XB40gNEOLB6W0vD8XPYf7J9vTG9kh6MaRJaB8nL+Ilbv6Q3HnCRTTcoQV4JU+hI
         DAa0W0cVotVPmnYILmiBxnBCERlneFw7foPQVxZcsW3X07TH4bi3f5WSeezD83qS0eS+
         3R+Q==
X-Gm-Message-State: ALoCoQlgvBq5A2wTaqhJCn+ct8RdJekoltl7F/XCnR3x5CLMNQV5qSCu1/GIN6xAzQcp+wtfq5DPHd9E7I45lU4EODOWfYNRN7wlqLiLsTZxQTFiPfALJeonjqi8RdC7ZMIerNE/QMmXXcPUSuFbO9vFmgboAlNoCz/kbgin0/oWS43XoNgSL04=
MIME-Version: 1.0
X-Received: by 10.50.66.36 with SMTP id c4mr25463983igt.48.1412628520140; Mon,
 06 Oct 2014 13:48:40 -0700 (PDT)
Received: by 10.50.79.135 with HTTP; Mon, 6 Oct 2014 13:48:40 -0700 (PDT)
In-Reply-To: <CAOhmDze9qQiJyruWHUFN9aGfCz3pXkSwwnSsJnAi9XiUVE4vgw@mail.gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
	<057601cf9c9c$7e798c80$7b6ca580$@reactor8.com>
	<CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
	<CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
	<CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
	<CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
	<0e7001cfde9d$14f00620$3ed01260$@reactor8.com>
	<CAOhmDzcRM_Gn7KtBJDQm--ai_G-aZBX-oE3StcK+686Y3+Jgeg@mail.gmail.com>
	<CAOhmDzeP0RobdLjiZzeqb8T2wnTLbN1Gvh2t+cnRGYcVUK2KOQ@mail.gmail.com>
	<CABPQxstH2DLuc2e3woy-1Zx7eA7Pcrc=e2PuGtvLJvPbzbtDJA@mail.gmail.com>
	<CAOhmDze9qQiJyruWHUFN9aGfCz3pXkSwwnSsJnAi9XiUVE4vgw@mail.gmail.com>
Date: Mon, 6 Oct 2014 13:48:40 -0700
Message-ID: <CA+HOc9PEt=RU+Qm2+1jEZCtWTN__80epsmGxTCSawh8tMTTAAA@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
From: Daniil Osipov <daniil.osipov@shazam.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "Nate D'Amico" <nate@reactor8.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1134cc1e24a5030504c735a2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134cc1e24a5030504c735a2
Content-Type: text/plain; charset=UTF-8

I've also been looking at this. Basically, the Spark EC2 script is
excellent for small development clusters of several nodes, but isn't
suitable for production. It handles instance setup in a single threaded
manner, while it can easily be parallelized. It also doesn't handle failure
well, ex when an instance fails to start or is taking too long to respond.

Our desire was to have an equivalent to Amazon EMR[1] API that would
trigger Spark jobs, including specified cluster setup. I've done some work
towards that end, and it would benefit from an updated AMI greatly.

Dan

[1]
http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-cli-commands.html

On Sat, Oct 4, 2014 at 7:28 AM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> Thanks for posting that script, Patrick. It looks like a good place to
> start.
>
> Regarding Docker vs. Packer, as I understand it you can use Packer to
> create Docker containers at the same time as AMIs and other image types.
>
> Nick
>
>
> On Sat, Oct 4, 2014 at 2:49 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
> > Hey All,
> >
> > Just a couple notes. I recently posted a shell script for creating the
> > AMI's from a clean Amazon Linux AMI.
> >
> > https://github.com/mesos/spark-ec2/blob/v3/create_image.sh
> >
> > I think I will update the AMI's soon to get the most recent security
> > updates. For spark-ec2's purpose this is probably sufficient (we'll
> > only need to re-create them every few months).
> >
> > However, it would be cool if someone wanted to tackle providing a more
> > general mechanism for defining Spark-friendly "images" that can be
> > used more generally. I had thought that docker might be a good way to
> > go for something like this - but maybe this packer thing is good too.
> >
> > For one thing, if we had a standard image we could use it to create
> > containers for running Spark's unit test, which would be really cool.
> > This would help a lot with random issues around port and filesystem
> > contention we have for unit tests.
> >
> > I'm not sure if the long term place for this would be inside the spark
> > codebase or a community library or what. But it would definitely be
> > very valuable to have if someone wanted to take it on.
> >
> > - Patrick
> >
> > On Fri, Oct 3, 2014 at 5:20 PM, Nicholas Chammas
> > <nicholas.chammas@gmail.com> wrote:
> > > FYI: There is an existing issue -- SPARK-3314
> > > <https://issues.apache.org/jira/browse/SPARK-3314> -- about scripting
> > the
> > > creation of Spark AMIs.
> > >
> > > With Packer, it looks like we may be able to script the creation of
> > > multiple image types (VMWare, GCE, AMI, Docker, etc...) at once from a
> > > single Packer template. That's very cool.
> > >
> > > I'll be looking into this.
> > >
> > > Nick
> > >
> > >
> > > On Thu, Oct 2, 2014 at 8:23 PM, Nicholas Chammas <
> > nicholas.chammas@gmail.com
> > >> wrote:
> > >
> > >> Thanks for the update, Nate. I'm looking forward to seeing how these
> > >> projects turn out.
> > >>
> > >> David, Packer looks very, very interesting. I'm gonna look into it
> more
> > >> next week.
> > >>
> > >> Nick
> > >>
> > >>
> > >> On Thu, Oct 2, 2014 at 8:00 PM, Nate D'Amico <nate@reactor8.com>
> wrote:
> > >>
> > >>> Bit of progress on our end, bit of lagging as well.  Our guy leading
> > >>> effort got little bogged down on client project to update hive/sql
> > testbed
> > >>> to latest spark/sparkSQL, also launching public service so we have
> > been bit
> > >>> scattered recently.
> > >>>
> > >>> Will have some more updates probably after next week.  We are
> planning
> > on
> > >>> taking our client work around hive/spark, plus taking over the bigtop
> > >>> automation work to modernize and get that fit for human consumption
> > outside
> > >>> or org.  All our work and puppet modules will be open sourced,
> > documented,
> > >>> hopefully start to rally some other folks around effort that find it
> > useful
> > >>>
> > >>> Side note, another effort we are looking into is gradle
> tests/support.
> > >>> We have been leveraging serverspec for some basic infrastructure
> > tests, but
> > >>> with bigtop switching over to gradle builds/testing setup in 0.8 we
> > want to
> > >>> include support for that in our own efforts, probably some stuff that
> > can
> > >>> be learned and leveraged in spark world for repeatable/tested
> > infrastructure
> > >>>
> > >>> If anyone has any specific automation questions to your environment
> you
> > >>> can drop me a line directly.., will try to help out best I can.  Else
> > will
> > >>> post update to dev list once we get on top of our own product release
> > and
> > >>> the bigtop work
> > >>>
> > >>> Nate
> > >>>
> > >>>
> > >>> -----Original Message-----
> > >>> From: David Rowe [mailto:davidrowe@gmail.com]
> > >>> Sent: Thursday, October 02, 2014 4:44 PM
> > >>> To: Nicholas Chammas
> > >>> Cc: dev; Shivaram Venkataraman
> > >>> Subject: Re: EC2 clusters ready in launch time + 30 seconds
> > >>>
> > >>> I think this is exactly what packer is for. See e.g.
> > >>> http://www.packer.io/intro/getting-started/build-image.html
> > >>>
> > >>> On a related note, the current AMI for hvm systems (e.g. m3.*, r3.*)
> > has
> > >>> a bad package for httpd, whcih causes ganglia not to start. For some
> > reason
> > >>> I can't get access to the raw AMI to fix it.
> > >>>
> > >>> On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas <
> > >>> nicholas.chammas@gmail.com
> > >>> > wrote:
> > >>>
> > >>> > Is there perhaps a way to define an AMI programmatically? Like, a
> > >>> > collection of base AMI id + list of required stuff to be installed
> +
> > >>> > list of required configuration changes. I'm guessing that's what
> > >>> > people use things like Puppet, Ansible, or maybe also AWS
> > >>> CloudFormation for, right?
> > >>> >
> > >>> > If we could do something like that, then with every new release of
> > >>> > Spark we could quickly and easily create new AMIs that have
> > everything
> > >>> we need.
> > >>> > spark-ec2 would only have to bring up the instances and do a
> minimal
> > >>> > amount of configuration, and the only thing we'd need to track in
> the
> > >>> > Spark repo is the code that defines what goes on the AMI, as well
> as
> > a
> > >>> > list of the AMI ids specific to each release.
> > >>> >
> > >>> > I'm just thinking out loud here. Does this make sense?
> > >>> >
> > >>> > Nate,
> > >>> >
> > >>> > Any progress on your end with this work?
> > >>> >
> > >>> > Nick
> > >>> >
> > >>> >
> > >>> > On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
> > >>> > shivaram@eecs.berkeley.edu> wrote:
> > >>> >
> > >>> > > It should be possible to improve cluster launch time if we are
> > >>> > > careful about what commands we run during setup. One way to do
> this
> > >>> > > would be to walk down the list of things we do for cluster
> > >>> > > initialization and see if there is anything we can do make things
> > >>> > > faster. Unfortunately this might
> > >>> > be
> > >>> > > pretty time consuming, but I don't know of a better strategy. The
> > >>> > > place
> > >>> > to
> > >>> > > start would be the setup.sh file at
> > >>> > > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
> > >>> > >
> > >>> > > Here are some things that take a lot of time and could be
> improved:
> > >>> > > 1. Creating swap partitions on all machines. We could check if
> > there
> > >>> > > is a way to get EC2 to always mount a swap partition 2. Copying /
> > >>> > > syncing things across slaves. The copy-dir script is called too
> > many
> > >>> > > times right now and each time it pauses for a few milliseconds
> > >>> > > between slaves [1]. This could be improved by removing
> unnecessary
> > >>> > > copies 3. We could make less frequently used modules like
> Tachyon,
> > >>> > > persistent
> > >>> > hdfs
> > >>> > > not a part of the default setup.
> > >>> > >
> > >>> > > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
> > >>> > >
> > >>> > > Thanks
> > >>> > > Shivaram
> > >>> > >
> > >>> > >
> > >>> > >
> > >>> > >
> > >>> > > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
> > >>> > > nicholas.chammas@gmail.com> wrote:
> > >>> > >
> > >>> > > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <
> nate@reactor8.com
> > >
> > >>> > wrote:
> > >>> > > >
> > >>> > > > > Starting to work through some automation/config stuff for
> spark
> > >>> > > > > stack
> > >>> > > on
> > >>> > > > > EC2 with a project, will be focusing the work through the
> > apache
> > >>> > bigtop
> > >>> > > > > effort to start, can then share with spark community directly
> > as
> > >>> > things
> > >>> > > > > progress if people are interested
> > >>> > > >
> > >>> > > >
> > >>> > > > Let us know how that goes. I'm definitely interested in hearing
> > >>> more.
> > >>> > > >
> > >>> > > > Nick
> > >>> > > >
> > >>> > >
> > >>> >
> > >>>
> > >>>
> > >>
> >
>

--001a1134cc1e24a5030504c735a2--

From dev-return-9704-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 21:15:28 2014
Return-Path: <dev-return-9704-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F196F174DB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 21:15:28 +0000 (UTC)
Received: (qmail 66787 invoked by uid 500); 6 Oct 2014 21:15:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66706 invoked by uid 500); 6 Oct 2014 21:15:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66692 invoked by uid 99); 6 Oct 2014 21:15:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 21:15:27 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_RHS_DOB
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.177 as permitted sender)
Received: from [209.85.212.177] (HELO mail-wi0-f177.google.com) (209.85.212.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 21:15:01 +0000
Received: by mail-wi0-f177.google.com with SMTP id fb4so5971238wid.16
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 14:15:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=DY0KTSTRaUXAJd7TgtBjDxAxYj2WBarMn3kIklyAmFw=;
        b=ALC9gqMtbJTW0hLMkp/N9W2SlLVxKx+02vkeJw5/wJWaInQcNyKjqoCuM7F7FSGTxe
         lvsyImAea+JOemxbWNF6RNc7oR+shyzV2yH9VPogUIitS8ylT40qvgTpGuTnjT19QjFz
         dG0Rc6yMZoglmOpek8RLRu+FC8Rv8sxkSGxyeojSKCaF6KXJTgmUX9uVITWKEt87pYDt
         vnGykLuT3YbPjU26HGpsIJIC+f0wvW2D1zQNIBEEaM65PPeKzddAWznXY81ksCQRwa0f
         XlIR9zF/1hcPrt0fMCEjbM6MaG5p6X27uBkYdGYZ9lEA8cHJdUCjQi76ZyhqVbqtihcg
         RMgg==
X-Received: by 10.180.12.206 with SMTP id a14mr9686199wic.75.1412630100433;
 Mon, 06 Oct 2014 14:15:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 6 Oct 2014 14:14:20 -0700 (PDT)
In-Reply-To: <CA+HOc9PEt=RU+Qm2+1jEZCtWTN__80epsmGxTCSawh8tMTTAAA@mail.gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
 <057601cf9c9c$7e798c80$7b6ca580$@reactor8.com> <CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
 <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
 <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
 <CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
 <0e7001cfde9d$14f00620$3ed01260$@reactor8.com> <CAOhmDzcRM_Gn7KtBJDQm--ai_G-aZBX-oE3StcK+686Y3+Jgeg@mail.gmail.com>
 <CAOhmDzeP0RobdLjiZzeqb8T2wnTLbN1Gvh2t+cnRGYcVUK2KOQ@mail.gmail.com>
 <CABPQxstH2DLuc2e3woy-1Zx7eA7Pcrc=e2PuGtvLJvPbzbtDJA@mail.gmail.com>
 <CAOhmDze9qQiJyruWHUFN9aGfCz3pXkSwwnSsJnAi9XiUVE4vgw@mail.gmail.com> <CA+HOc9PEt=RU+Qm2+1jEZCtWTN__80epsmGxTCSawh8tMTTAAA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 6 Oct 2014 17:14:20 -0400
Message-ID: <CAOhmDzd+FuLepPKgWJkh7GieQ0+6_rz4-NC=n4pVZ6YS5jaxqw@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
To: Daniil Osipov <daniil.osipov@shazam.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "Nate D'Amico" <nate@reactor8.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c24c9a55e2d40504c79349
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c24c9a55e2d40504c79349
Content-Type: text/plain; charset=UTF-8

FYI: I've created SPARK-3821: Develop an automated way of creating Spark
images (AMI, Docker, and others)
<https://issues.apache.org/jira/browse/SPARK-3821>

On Mon, Oct 6, 2014 at 4:48 PM, Daniil Osipov <daniil.osipov@shazam.com>
wrote:

> I've also been looking at this. Basically, the Spark EC2 script is
> excellent for small development clusters of several nodes, but isn't
> suitable for production. It handles instance setup in a single threaded
> manner, while it can easily be parallelized. It also doesn't handle failure
> well, ex when an instance fails to start or is taking too long to respond.
>
> Our desire was to have an equivalent to Amazon EMR[1] API that would
> trigger Spark jobs, including specified cluster setup. I've done some work
> towards that end, and it would benefit from an updated AMI greatly.
>
> Dan
>
> [1]
> http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-cli-commands.html
>
> On Sat, Oct 4, 2014 at 7:28 AM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Thanks for posting that script, Patrick. It looks like a good place to
>> start.
>>
>> Regarding Docker vs. Packer, as I understand it you can use Packer to
>> create Docker containers at the same time as AMIs and other image types.
>>
>> Nick
>>
>>
>> On Sat, Oct 4, 2014 at 2:49 AM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>> > Hey All,
>> >
>> > Just a couple notes. I recently posted a shell script for creating the
>> > AMI's from a clean Amazon Linux AMI.
>> >
>> > https://github.com/mesos/spark-ec2/blob/v3/create_image.sh
>> >
>> > I think I will update the AMI's soon to get the most recent security
>> > updates. For spark-ec2's purpose this is probably sufficient (we'll
>> > only need to re-create them every few months).
>> >
>> > However, it would be cool if someone wanted to tackle providing a more
>> > general mechanism for defining Spark-friendly "images" that can be
>> > used more generally. I had thought that docker might be a good way to
>> > go for something like this - but maybe this packer thing is good too.
>> >
>> > For one thing, if we had a standard image we could use it to create
>> > containers for running Spark's unit test, which would be really cool.
>> > This would help a lot with random issues around port and filesystem
>> > contention we have for unit tests.
>> >
>> > I'm not sure if the long term place for this would be inside the spark
>> > codebase or a community library or what. But it would definitely be
>> > very valuable to have if someone wanted to take it on.
>> >
>> > - Patrick
>> >
>> > On Fri, Oct 3, 2014 at 5:20 PM, Nicholas Chammas
>> > <nicholas.chammas@gmail.com> wrote:
>> > > FYI: There is an existing issue -- SPARK-3314
>> > > <https://issues.apache.org/jira/browse/SPARK-3314> -- about scripting
>> > the
>> > > creation of Spark AMIs.
>> > >
>> > > With Packer, it looks like we may be able to script the creation of
>> > > multiple image types (VMWare, GCE, AMI, Docker, etc...) at once from a
>> > > single Packer template. That's very cool.
>> > >
>> > > I'll be looking into this.
>> > >
>> > > Nick
>> > >
>> > >
>> > > On Thu, Oct 2, 2014 at 8:23 PM, Nicholas Chammas <
>> > nicholas.chammas@gmail.com
>> > >> wrote:
>> > >
>> > >> Thanks for the update, Nate. I'm looking forward to seeing how these
>> > >> projects turn out.
>> > >>
>> > >> David, Packer looks very, very interesting. I'm gonna look into it
>> more
>> > >> next week.
>> > >>
>> > >> Nick
>> > >>
>> > >>
>> > >> On Thu, Oct 2, 2014 at 8:00 PM, Nate D'Amico <nate@reactor8.com>
>> wrote:
>> > >>
>> > >>> Bit of progress on our end, bit of lagging as well.  Our guy leading
>> > >>> effort got little bogged down on client project to update hive/sql
>> > testbed
>> > >>> to latest spark/sparkSQL, also launching public service so we have
>> > been bit
>> > >>> scattered recently.
>> > >>>
>> > >>> Will have some more updates probably after next week.  We are
>> planning
>> > on
>> > >>> taking our client work around hive/spark, plus taking over the
>> bigtop
>> > >>> automation work to modernize and get that fit for human consumption
>> > outside
>> > >>> or org.  All our work and puppet modules will be open sourced,
>> > documented,
>> > >>> hopefully start to rally some other folks around effort that find it
>> > useful
>> > >>>
>> > >>> Side note, another effort we are looking into is gradle
>> tests/support.
>> > >>> We have been leveraging serverspec for some basic infrastructure
>> > tests, but
>> > >>> with bigtop switching over to gradle builds/testing setup in 0.8 we
>> > want to
>> > >>> include support for that in our own efforts, probably some stuff
>> that
>> > can
>> > >>> be learned and leveraged in spark world for repeatable/tested
>> > infrastructure
>> > >>>
>> > >>> If anyone has any specific automation questions to your environment
>> you
>> > >>> can drop me a line directly.., will try to help out best I can.
>> Else
>> > will
>> > >>> post update to dev list once we get on top of our own product
>> release
>> > and
>> > >>> the bigtop work
>> > >>>
>> > >>> Nate
>> > >>>
>> > >>>
>> > >>> -----Original Message-----
>> > >>> From: David Rowe [mailto:davidrowe@gmail.com]
>> > >>> Sent: Thursday, October 02, 2014 4:44 PM
>> > >>> To: Nicholas Chammas
>> > >>> Cc: dev; Shivaram Venkataraman
>> > >>> Subject: Re: EC2 clusters ready in launch time + 30 seconds
>> > >>>
>> > >>> I think this is exactly what packer is for. See e.g.
>> > >>> http://www.packer.io/intro/getting-started/build-image.html
>> > >>>
>> > >>> On a related note, the current AMI for hvm systems (e.g. m3.*, r3.*)
>> > has
>> > >>> a bad package for httpd, whcih causes ganglia not to start. For some
>> > reason
>> > >>> I can't get access to the raw AMI to fix it.
>> > >>>
>> > >>> On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas <
>> > >>> nicholas.chammas@gmail.com
>> > >>> > wrote:
>> > >>>
>> > >>> > Is there perhaps a way to define an AMI programmatically? Like, a
>> > >>> > collection of base AMI id + list of required stuff to be
>> installed +
>> > >>> > list of required configuration changes. I'm guessing that's what
>> > >>> > people use things like Puppet, Ansible, or maybe also AWS
>> > >>> CloudFormation for, right?
>> > >>> >
>> > >>> > If we could do something like that, then with every new release of
>> > >>> > Spark we could quickly and easily create new AMIs that have
>> > everything
>> > >>> we need.
>> > >>> > spark-ec2 would only have to bring up the instances and do a
>> minimal
>> > >>> > amount of configuration, and the only thing we'd need to track in
>> the
>> > >>> > Spark repo is the code that defines what goes on the AMI, as well
>> as
>> > a
>> > >>> > list of the AMI ids specific to each release.
>> > >>> >
>> > >>> > I'm just thinking out loud here. Does this make sense?
>> > >>> >
>> > >>> > Nate,
>> > >>> >
>> > >>> > Any progress on your end with this work?
>> > >>> >
>> > >>> > Nick
>> > >>> >
>> > >>> >
>> > >>> > On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
>> > >>> > shivaram@eecs.berkeley.edu> wrote:
>> > >>> >
>> > >>> > > It should be possible to improve cluster launch time if we are
>> > >>> > > careful about what commands we run during setup. One way to do
>> this
>> > >>> > > would be to walk down the list of things we do for cluster
>> > >>> > > initialization and see if there is anything we can do make
>> things
>> > >>> > > faster. Unfortunately this might
>> > >>> > be
>> > >>> > > pretty time consuming, but I don't know of a better strategy.
>> The
>> > >>> > > place
>> > >>> > to
>> > >>> > > start would be the setup.sh file at
>> > >>> > > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
>> > >>> > >
>> > >>> > > Here are some things that take a lot of time and could be
>> improved:
>> > >>> > > 1. Creating swap partitions on all machines. We could check if
>> > there
>> > >>> > > is a way to get EC2 to always mount a swap partition 2. Copying
>> /
>> > >>> > > syncing things across slaves. The copy-dir script is called too
>> > many
>> > >>> > > times right now and each time it pauses for a few milliseconds
>> > >>> > > between slaves [1]. This could be improved by removing
>> unnecessary
>> > >>> > > copies 3. We could make less frequently used modules like
>> Tachyon,
>> > >>> > > persistent
>> > >>> > hdfs
>> > >>> > > not a part of the default setup.
>> > >>> > >
>> > >>> > > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
>> > >>> > >
>> > >>> > > Thanks
>> > >>> > > Shivaram
>> > >>> > >
>> > >>> > >
>> > >>> > >
>> > >>> > >
>> > >>> > > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
>> > >>> > > nicholas.chammas@gmail.com> wrote:
>> > >>> > >
>> > >>> > > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <
>> nate@reactor8.com
>> > >
>> > >>> > wrote:
>> > >>> > > >
>> > >>> > > > > Starting to work through some automation/config stuff for
>> spark
>> > >>> > > > > stack
>> > >>> > > on
>> > >>> > > > > EC2 with a project, will be focusing the work through the
>> > apache
>> > >>> > bigtop
>> > >>> > > > > effort to start, can then share with spark community
>> directly
>> > as
>> > >>> > things
>> > >>> > > > > progress if people are interested
>> > >>> > > >
>> > >>> > > >
>> > >>> > > > Let us know how that goes. I'm definitely interested in
>> hearing
>> > >>> more.
>> > >>> > > >
>> > >>> > > > Nick
>> > >>> > > >
>> > >>> > >
>> > >>> >
>> > >>>
>> > >>>
>> > >>
>> >
>>
>
>

--001a11c24c9a55e2d40504c79349--

From dev-return-9705-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct  6 23:41:14 2014
Return-Path: <dev-return-9705-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2A04A17AA9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon,  6 Oct 2014 23:41:14 +0000 (UTC)
Received: (qmail 58998 invoked by uid 500); 6 Oct 2014 23:41:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 58928 invoked by uid 500); 6 Oct 2014 23:41:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 58916 invoked by uid 99); 6 Oct 2014 23:41:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 23:41:12 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of davidrowe@gmail.com designates 209.85.216.177 as permitted sender)
Received: from [209.85.216.177] (HELO mail-qc0-f177.google.com) (209.85.216.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 06 Oct 2014 23:41:09 +0000
Received: by mail-qc0-f177.google.com with SMTP id c9so4843977qcz.36
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 16:40:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=GOmw/Wc+GdzIVnHVngj67eH1XG1SPxrx6xMtUDvgsBI=;
        b=iRkfiV6s1SR1UQAWvlWaCmE+KbvoM0alg9UvO5R0j99FKxbFLmXnkWYLsnAU0/GBrZ
         uWowWBRqCQyQdgc0ypUSb5wjj2zCO+/aEPB2TpxryFuKiOaiHNE9V5iz2ohoVMjUp30Z
         +1dFMum1sgpmyjRkpqsGeLiDrgUL8J6cCPHFKK3q+tS/E/yIEbEYLtQilVpgbcsIT0pU
         ywPZVFMU7Lm7VO/57sDH2Q1Pd+vVcT9wQ2DU6zwVi9AW5jVd+rY+9gRAUp4TiQJ7bEd3
         c+awvltAnCErb2h/r4afZvQzrjxirlBDgeCpTxSnL84rQWjTmjX61t3FoqTFomDwe9Ro
         zeVA==
X-Received: by 10.229.7.198 with SMTP id e6mr80391qce.0.1412638848264; Mon, 06
 Oct 2014 16:40:48 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.93.113 with HTTP; Mon, 6 Oct 2014 16:40:28 -0700 (PDT)
In-Reply-To: <CA+HOc9PEt=RU+Qm2+1jEZCtWTN__80epsmGxTCSawh8tMTTAAA@mail.gmail.com>
References: <CAOhmDzch1e=zOaqhi7VNNX+doGuNSi3PQCBSHZKXFRW8E9B+uA@mail.gmail.com>
 <057601cf9c9c$7e798c80$7b6ca580$@reactor8.com> <CAOhmDzceR8E+ij6R185Q0tOqWRiMgtEQ_saO1H3Ne2SW8tXZOg@mail.gmail.com>
 <CAKx7Bf8F=bKwR-2vWcYFhL=qUWgw-TTYZiWupjdJhz6KR31WgQ@mail.gmail.com>
 <CAOhmDzehbKJFn4Zn_HiZ8VqKKVXyYJhchMbp8mp4Bnz-efnBkw@mail.gmail.com>
 <CAAdRV=PLYwCLPB3u_4k=5QwFoZpvj9ejCi-OVKT-kWaf-BkAKQ@mail.gmail.com>
 <0e7001cfde9d$14f00620$3ed01260$@reactor8.com> <CAOhmDzcRM_Gn7KtBJDQm--ai_G-aZBX-oE3StcK+686Y3+Jgeg@mail.gmail.com>
 <CAOhmDzeP0RobdLjiZzeqb8T2wnTLbN1Gvh2t+cnRGYcVUK2KOQ@mail.gmail.com>
 <CABPQxstH2DLuc2e3woy-1Zx7eA7Pcrc=e2PuGtvLJvPbzbtDJA@mail.gmail.com>
 <CAOhmDze9qQiJyruWHUFN9aGfCz3pXkSwwnSsJnAi9XiUVE4vgw@mail.gmail.com> <CA+HOc9PEt=RU+Qm2+1jEZCtWTN__80epsmGxTCSawh8tMTTAAA@mail.gmail.com>
From: David Rowe <davidrowe@gmail.com>
Date: Tue, 7 Oct 2014 10:40:28 +1100
Message-ID: <CAAdRV=NAMfgJeJB2hUXcBe3SsOc9KicJ-08YtvsbkYRfjCRBdA@mail.gmail.com>
Subject: Re: EC2 clusters ready in launch time + 30 seconds
To: Daniil Osipov <daniil.osipov@shazam.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, Patrick Wendell <pwendell@gmail.com>, 
	"Nate D'Amico" <nate@reactor8.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133cdb0bf32500504c99cec
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133cdb0bf32500504c99cec
Content-Type: text/plain; charset=UTF-8

I agree with this - there is also the issue of different sized masters and
slaves, and numbers of executors for hefty machines (e.g. r3.8xlarges),
tagging of instances and volumes (we use this for cost attribution at my
workplace), and running in VPCs.

I think think it might be useful to take a layered approach: the first step
could be getting a good reliable image produced - Nick's ticket - then
doing some work on the launch script.

Regarding the EMR like service - I think I heard that AWS is planning to
add spark support to EMR, but as usual there's nothing firm until it's
released.


On Tue, Oct 7, 2014 at 7:48 AM, Daniil Osipov <daniil.osipov@shazam.com>
wrote:

> I've also been looking at this. Basically, the Spark EC2 script is
> excellent for small development clusters of several nodes, but isn't
> suitable for production. It handles instance setup in a single threaded
> manner, while it can easily be parallelized. It also doesn't handle failure
> well, ex when an instance fails to start or is taking too long to respond.
>
> Our desire was to have an equivalent to Amazon EMR[1] API that would
> trigger Spark jobs, including specified cluster setup. I've done some work
> towards that end, and it would benefit from an updated AMI greatly.
>
> Dan
>
> [1]
>
> http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-cli-commands.html
>
> On Sat, Oct 4, 2014 at 7:28 AM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> > wrote:
>
> > Thanks for posting that script, Patrick. It looks like a good place to
> > start.
> >
> > Regarding Docker vs. Packer, as I understand it you can use Packer to
> > create Docker containers at the same time as AMIs and other image types.
> >
> > Nick
> >
> >
> > On Sat, Oct 4, 2014 at 2:49 AM, Patrick Wendell <pwendell@gmail.com>
> > wrote:
> >
> > > Hey All,
> > >
> > > Just a couple notes. I recently posted a shell script for creating the
> > > AMI's from a clean Amazon Linux AMI.
> > >
> > > https://github.com/mesos/spark-ec2/blob/v3/create_image.sh
> > >
> > > I think I will update the AMI's soon to get the most recent security
> > > updates. For spark-ec2's purpose this is probably sufficient (we'll
> > > only need to re-create them every few months).
> > >
> > > However, it would be cool if someone wanted to tackle providing a more
> > > general mechanism for defining Spark-friendly "images" that can be
> > > used more generally. I had thought that docker might be a good way to
> > > go for something like this - but maybe this packer thing is good too.
> > >
> > > For one thing, if we had a standard image we could use it to create
> > > containers for running Spark's unit test, which would be really cool.
> > > This would help a lot with random issues around port and filesystem
> > > contention we have for unit tests.
> > >
> > > I'm not sure if the long term place for this would be inside the spark
> > > codebase or a community library or what. But it would definitely be
> > > very valuable to have if someone wanted to take it on.
> > >
> > > - Patrick
> > >
> > > On Fri, Oct 3, 2014 at 5:20 PM, Nicholas Chammas
> > > <nicholas.chammas@gmail.com> wrote:
> > > > FYI: There is an existing issue -- SPARK-3314
> > > > <https://issues.apache.org/jira/browse/SPARK-3314> -- about
> scripting
> > > the
> > > > creation of Spark AMIs.
> > > >
> > > > With Packer, it looks like we may be able to script the creation of
> > > > multiple image types (VMWare, GCE, AMI, Docker, etc...) at once from
> a
> > > > single Packer template. That's very cool.
> > > >
> > > > I'll be looking into this.
> > > >
> > > > Nick
> > > >
> > > >
> > > > On Thu, Oct 2, 2014 at 8:23 PM, Nicholas Chammas <
> > > nicholas.chammas@gmail.com
> > > >> wrote:
> > > >
> > > >> Thanks for the update, Nate. I'm looking forward to seeing how these
> > > >> projects turn out.
> > > >>
> > > >> David, Packer looks very, very interesting. I'm gonna look into it
> > more
> > > >> next week.
> > > >>
> > > >> Nick
> > > >>
> > > >>
> > > >> On Thu, Oct 2, 2014 at 8:00 PM, Nate D'Amico <nate@reactor8.com>
> > wrote:
> > > >>
> > > >>> Bit of progress on our end, bit of lagging as well.  Our guy
> leading
> > > >>> effort got little bogged down on client project to update hive/sql
> > > testbed
> > > >>> to latest spark/sparkSQL, also launching public service so we have
> > > been bit
> > > >>> scattered recently.
> > > >>>
> > > >>> Will have some more updates probably after next week.  We are
> > planning
> > > on
> > > >>> taking our client work around hive/spark, plus taking over the
> bigtop
> > > >>> automation work to modernize and get that fit for human consumption
> > > outside
> > > >>> or org.  All our work and puppet modules will be open sourced,
> > > documented,
> > > >>> hopefully start to rally some other folks around effort that find
> it
> > > useful
> > > >>>
> > > >>> Side note, another effort we are looking into is gradle
> > tests/support.
> > > >>> We have been leveraging serverspec for some basic infrastructure
> > > tests, but
> > > >>> with bigtop switching over to gradle builds/testing setup in 0.8 we
> > > want to
> > > >>> include support for that in our own efforts, probably some stuff
> that
> > > can
> > > >>> be learned and leveraged in spark world for repeatable/tested
> > > infrastructure
> > > >>>
> > > >>> If anyone has any specific automation questions to your environment
> > you
> > > >>> can drop me a line directly.., will try to help out best I can.
> Else
> > > will
> > > >>> post update to dev list once we get on top of our own product
> release
> > > and
> > > >>> the bigtop work
> > > >>>
> > > >>> Nate
> > > >>>
> > > >>>
> > > >>> -----Original Message-----
> > > >>> From: David Rowe [mailto:davidrowe@gmail.com]
> > > >>> Sent: Thursday, October 02, 2014 4:44 PM
> > > >>> To: Nicholas Chammas
> > > >>> Cc: dev; Shivaram Venkataraman
> > > >>> Subject: Re: EC2 clusters ready in launch time + 30 seconds
> > > >>>
> > > >>> I think this is exactly what packer is for. See e.g.
> > > >>> http://www.packer.io/intro/getting-started/build-image.html
> > > >>>
> > > >>> On a related note, the current AMI for hvm systems (e.g. m3.*,
> r3.*)
> > > has
> > > >>> a bad package for httpd, whcih causes ganglia not to start. For
> some
> > > reason
> > > >>> I can't get access to the raw AMI to fix it.
> > > >>>
> > > >>> On Fri, Oct 3, 2014 at 9:30 AM, Nicholas Chammas <
> > > >>> nicholas.chammas@gmail.com
> > > >>> > wrote:
> > > >>>
> > > >>> > Is there perhaps a way to define an AMI programmatically? Like, a
> > > >>> > collection of base AMI id + list of required stuff to be
> installed
> > +
> > > >>> > list of required configuration changes. I'm guessing that's what
> > > >>> > people use things like Puppet, Ansible, or maybe also AWS
> > > >>> CloudFormation for, right?
> > > >>> >
> > > >>> > If we could do something like that, then with every new release
> of
> > > >>> > Spark we could quickly and easily create new AMIs that have
> > > everything
> > > >>> we need.
> > > >>> > spark-ec2 would only have to bring up the instances and do a
> > minimal
> > > >>> > amount of configuration, and the only thing we'd need to track in
> > the
> > > >>> > Spark repo is the code that defines what goes on the AMI, as well
> > as
> > > a
> > > >>> > list of the AMI ids specific to each release.
> > > >>> >
> > > >>> > I'm just thinking out loud here. Does this make sense?
> > > >>> >
> > > >>> > Nate,
> > > >>> >
> > > >>> > Any progress on your end with this work?
> > > >>> >
> > > >>> > Nick
> > > >>> >
> > > >>> >
> > > >>> > On Sun, Jul 13, 2014 at 8:53 PM, Shivaram Venkataraman <
> > > >>> > shivaram@eecs.berkeley.edu> wrote:
> > > >>> >
> > > >>> > > It should be possible to improve cluster launch time if we are
> > > >>> > > careful about what commands we run during setup. One way to do
> > this
> > > >>> > > would be to walk down the list of things we do for cluster
> > > >>> > > initialization and see if there is anything we can do make
> things
> > > >>> > > faster. Unfortunately this might
> > > >>> > be
> > > >>> > > pretty time consuming, but I don't know of a better strategy.
> The
> > > >>> > > place
> > > >>> > to
> > > >>> > > start would be the setup.sh file at
> > > >>> > > https://github.com/mesos/spark-ec2/blob/v3/setup.sh
> > > >>> > >
> > > >>> > > Here are some things that take a lot of time and could be
> > improved:
> > > >>> > > 1. Creating swap partitions on all machines. We could check if
> > > there
> > > >>> > > is a way to get EC2 to always mount a swap partition 2.
> Copying /
> > > >>> > > syncing things across slaves. The copy-dir script is called too
> > > many
> > > >>> > > times right now and each time it pauses for a few milliseconds
> > > >>> > > between slaves [1]. This could be improved by removing
> > unnecessary
> > > >>> > > copies 3. We could make less frequently used modules like
> > Tachyon,
> > > >>> > > persistent
> > > >>> > hdfs
> > > >>> > > not a part of the default setup.
> > > >>> > >
> > > >>> > > [1] https://github.com/mesos/spark-ec2/blob/v3/copy-dir.sh#L42
> > > >>> > >
> > > >>> > > Thanks
> > > >>> > > Shivaram
> > > >>> > >
> > > >>> > >
> > > >>> > >
> > > >>> > >
> > > >>> > > On Sat, Jul 12, 2014 at 7:02 PM, Nicholas Chammas <
> > > >>> > > nicholas.chammas@gmail.com> wrote:
> > > >>> > >
> > > >>> > > > On Thu, Jul 10, 2014 at 8:10 PM, Nate D'Amico <
> > nate@reactor8.com
> > > >
> > > >>> > wrote:
> > > >>> > > >
> > > >>> > > > > Starting to work through some automation/config stuff for
> > spark
> > > >>> > > > > stack
> > > >>> > > on
> > > >>> > > > > EC2 with a project, will be focusing the work through the
> > > apache
> > > >>> > bigtop
> > > >>> > > > > effort to start, can then share with spark community
> directly
> > > as
> > > >>> > things
> > > >>> > > > > progress if people are interested
> > > >>> > > >
> > > >>> > > >
> > > >>> > > > Let us know how that goes. I'm definitely interested in
> hearing
> > > >>> more.
> > > >>> > > >
> > > >>> > > > Nick
> > > >>> > > >
> > > >>> > >
> > > >>> >
> > > >>>
> > > >>>
> > > >>
> > >
> >
>

--001a1133cdb0bf32500504c99cec--

From dev-return-9706-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 00:08:13 2014
Return-Path: <dev-return-9706-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BF87F17B67
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 00:08:13 +0000 (UTC)
Received: (qmail 7172 invoked by uid 500); 7 Oct 2014 00:08:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7103 invoked by uid 500); 7 Oct 2014 00:08:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 7089 invoked by uid 99); 7 Oct 2014 00:08:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 00:08:11 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of fairizazizi@gmail.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 00:07:45 +0000
Received: by mail-wi0-f182.google.com with SMTP id n3so6248049wiv.15
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 17:07:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=zf5Ys3LgAfApvycNcMpxlGT/VlPAz9sRMdvcCRC/brI=;
        b=UeoBl8611mF80Z7CjgNQBSj4vsaj61i4BiE5dLKfj5R2E+DMeUvmvJMnJ3n0VDAZov
         BGrXWpJAaUwmR6WAnhm8Urzq6yYKZtPFMbc8e/TA8OaVUc8/R+hWG1bRnS++gBIn3ryw
         XmXYZSliN3OxfBYLj1JMG0QgA6UrhuuMzjqi71skHbnf1KzyrSYR5o/Uy+1lg9DV1MXb
         sWB2wAbd7OkxvS+VnOD5RygXNBWKl5RRAKqL82lFrC3Gxr8EsYBbO8n9nFtMGLZrQNbF
         Wl6fHXk6Z8CwZDQ9Y5AAtC8fcUmwvnRJECYv8327MnY2tP0Un8F/rxTYVkvxSwTJNC1S
         2Rig==
X-Received: by 10.180.73.103 with SMTP id k7mr22694893wiv.1.1412640465115;
 Mon, 06 Oct 2014 17:07:45 -0700 (PDT)
MIME-Version: 1.0
Sender: fairizazizi@gmail.com
Received: by 10.194.219.2 with HTTP; Mon, 6 Oct 2014 17:07:25 -0700 (PDT)
In-Reply-To: <CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
 <54323A64.2090205@uninett.no> <CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
 <CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
 <543249BB.505@uninett.no> <CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
 <CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com>
From: Fairiz Azizi <coderfi@gmail.com>
Date: Mon, 6 Oct 2014 17:07:25 -0700
X-Google-Sender-Auth: riYvYyzDBUZ7aW6XIFfSbVxaoXw
Message-ID: <CAAHrQ0kc4V-B357hMX2OEDsauxnpniTDPbf9ycx+9oh6qVKXiw@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
To: Timothy Chen <tnachen@gmail.com>
Cc: RJ Nowling <rnowling@gmail.com>, Gurvinder Singh <gurvinder.singh@uninett.no>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043c815e1e5eb10504c9fd1a
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c815e1e5eb10504c9fd1a
Content-Type: text/plain; charset=UTF-8

That's what great about Spark, the community is so active! :)

I compiled Mesos 0.20.1 from the source tarball.

Using the Mapr3 Spark 1.1.0 distribution from the Spark downloads page
 (spark-1.1.0-bin-mapr3.tgz).

I see no problems for the workloads we are trying.

However, the cluster is small (less than 100 cores across 3 nodes).

The workloads reads in just a few gigabytes from HDFS, via an ipython
notebook spark shell.

thanks,
Fi



Fairiz "Fi" Azizi

On Mon, Oct 6, 2014 at 9:20 AM, Timothy Chen <tnachen@gmail.com> wrote:

> Ok I created SPARK-3817 to track this, will try to repro it as well.
>
> Tim
>
> On Mon, Oct 6, 2014 at 6:08 AM, RJ Nowling <rnowling@gmail.com> wrote:
> > I've recently run into this issue as well. I get it from running Spark
> > examples such as log query.  Maybe that'll help reproduce the issue.
> >
> >
> > On Monday, October 6, 2014, Gurvinder Singh <gurvinder.singh@uninett.no>
> > wrote:
> >>
> >> The issue does not occur if the task at hand has small number of map
> >> tasks. I have a task which has 978 map tasks and I see this error as
> >>
> >> 14/10/06 09:34:40 ERROR BlockManagerMasterActor: Got two different block
> >> manager registrations on 20140711-081617-711206558-5050-2543-5
> >>
> >> Here is the log from the mesos-slave where this container was running.
> >>
> >> http://pastebin.com/Q1Cuzm6Q
> >>
> >> If you look for the code from where error produced by spark, you will
> >> see that it simply exit and saying in comments "this should never
> >> happen, lets just quit" :-)
> >>
> >> - Gurvinder
> >> On 10/06/2014 09:30 AM, Timothy Chen wrote:
> >> > (Hit enter too soon...)
> >> >
> >> > What is your setup and steps to repro this?
> >> >
> >> > Tim
> >> >
> >> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com>
> wrote:
> >> >> Hi Gurvinder,
> >> >>
> >> >> I tried fine grain mode before and didn't get into that problem.
> >> >>
> >> >>
> >> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
> >> >> <gurvinder.singh@uninett.no> wrote:
> >> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
> >> >>>> The Spark online docs indicate that Spark is compatible with Mesos
> >> >>>> 0.18.1
> >> >>>>
> >> >>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
> >> >>>>
> >> >>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos
> >> >>>> v0.20.0?
> >> >>>>
> >> >>>> -Fi
> >> >>>>
> >> >>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in
> >> >>> coarse
> >> >>> mode, in fine grain mode there is an issue with blockmanager names
> >> >>> conflict. I have been waiting for it to be fixed but it is still
> >> >>> there.
> >> >>>
> >> >>> -Gurvinder
> >> >>>
> >> >>>
> ---------------------------------------------------------------------
> >> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> >>> For additional commands, e-mail: dev-help@spark.apache.org
> >> >>>
> >>
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
> >
> >
> > --
> > em rnowling@gmail.com
> > c 954.496.2314
>

--f46d043c815e1e5eb10504c9fd1a--

From dev-return-9707-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 00:20:00 2014
Return-Path: <dev-return-9707-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4F5B017BCB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 00:20:00 +0000 (UTC)
Received: (qmail 36757 invoked by uid 500); 7 Oct 2014 00:19:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36674 invoked by uid 500); 7 Oct 2014 00:19:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36663 invoked by uid 99); 7 Oct 2014 00:19:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 00:19:59 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 00:19:54 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XbIV4-0004pY-54
	for dev@spark.incubator.apache.org; Mon, 06 Oct 2014 17:19:34 -0700
Date: Mon, 6 Oct 2014 17:19:34 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1412641174148-8677.post@n3.nabble.com>
In-Reply-To: <B641E8B6-6610-439E-B7F9-48698A15E65B@gmail.com>
References: <1412296630273-8638.post@n3.nabble.com> <B641E8B6-6610-439E-B7F9-48698A15E65B@gmail.com>
Subject: Re: What is the best way to build my developing Spark for testing
 on EC2?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Evan,

Sorry for my replay late. And Thank you for your comment.

> As far as cluster set up goes, I usually launch spot instances with the
> spark-ec2 scripts, 
> and then check out a repo which contains a simple driver application for
> my code. 
> Then I have something crude like bash scripts running my program and
> collecting output. 

It's just as you thought.  I agree with you.

> You could have a look at the spark-perf repo if you want something a
> little better principled/automatic. 

I overlooked this. I will give it a try.

best,



-----
-- Yu Ishikawa
--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/What-is-the-best-way-to-build-my-developing-Spark-for-testing-on-EC2-tp8638p8677.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9708-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 02:32:30 2014
Return-Path: <dev-return-9708-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 810C917ED3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 02:32:30 +0000 (UTC)
Received: (qmail 83132 invoked by uid 500); 7 Oct 2014 02:32:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83065 invoked by uid 500); 7 Oct 2014 02:32:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83052 invoked by uid 99); 7 Oct 2014 02:32:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 02:32:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bbejeck@gmail.com designates 209.85.223.173 as permitted sender)
Received: from [209.85.223.173] (HELO mail-ie0-f173.google.com) (209.85.223.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 02:32:02 +0000
Received: by mail-ie0-f173.google.com with SMTP id tp5so4561604ieb.32
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 19:32:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=WkKmDT/ANHvDyRDq4RDnct+wgemK6RT4INsX6GQftyI=;
        b=GA6wwxsvsVhnPv1qGwWi6byUdXJ4vd4pd1VT8tswAF7O6vtBtgzJMPGX3RIUN7CxUk
         i3sNEm4Y6CqcaWzI8W0X/d9JPnZ5+d1TL5KjKdCm4lgt9DWoaoYeIgzcphijBzNY9b1B
         I0FpzeJAsWI5HkQyot9MHhzfp6L8kXDfsymoYaD7lbAMu6WOI6QA1ssMIgLtgRF7h9kN
         l5X+xPq3uGpR7D/gOhIOL9NSqeuOKL0KEufWFrID0x7B9duAvVVokj1GgP86NpcbT6iw
         2AVDF/uWWdzc4hay498j8MU70fWelg3AmXDHxv4L9i1W5IV3jJgEkkU49KJU78l62bQ1
         cHzg==
MIME-Version: 1.0
X-Received: by 10.50.43.225 with SMTP id z1mr936880igl.17.1412649120743; Mon,
 06 Oct 2014 19:32:00 -0700 (PDT)
Received: by 10.64.242.196 with HTTP; Mon, 6 Oct 2014 19:32:00 -0700 (PDT)
Date: Mon, 6 Oct 2014 22:32:00 -0400
Message-ID: <CAF7WS+qVxq7BZBWRPTmKhJGH3fUvjWFQ1mrOPb_Yat3dOnJ0aA@mail.gmail.com>
Subject: Pull Requests
From: Bill Bejeck <bbejeck@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e010d8dd608ce200504cc0154
X-Virus-Checked: Checked by ClamAV on apache.org

--089e010d8dd608ce200504cc0154
Content-Type: text/plain; charset=UTF-8

Once a PR has been tested and verified, when does it get pulled back into
the trunk?

--089e010d8dd608ce200504cc0154--

From dev-return-9709-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 02:58:42 2014
Return-Path: <dev-return-9709-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D3F9D17F24
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 02:58:42 +0000 (UTC)
Received: (qmail 11277 invoked by uid 500); 7 Oct 2014 02:58:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11212 invoked by uid 500); 7 Oct 2014 02:58:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11200 invoked by uid 99); 7 Oct 2014 02:58:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 02:58:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of bbejeck@gmail.com designates 209.85.223.170 as permitted sender)
Received: from [209.85.223.170] (HELO mail-ie0-f170.google.com) (209.85.223.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 02:58:36 +0000
Received: by mail-ie0-f170.google.com with SMTP id rd18so4628643iec.1
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 19:58:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=ca4WA+N3z6UEUytwvwwKjsEo693Dglle4uyj3NICERo=;
        b=hygnN758oiAWuiXrI4xy4uKpo8x/3o7rTn/0aBOoPxUTqH97NRr/DhZJHw8ab8G+qv
         Ev+fJ5AEOuX3uA5SeVWA8Ojsz2eYdkf96TseuQ6ljZKsdyuTcpxtZOyksHLN7mjq+8oI
         jUP5ZyVl+zutnsUTeBPlEumnmsvAqikgOYGEilLJ9g9R30kcjn7mg0C13JVRTWJPNRbD
         k5UlG7xv9tesEWpVVuna9XvWbjpok4SPala5znOdcr67EHpOE5L9LP3dEw1mmO93b6dr
         V3iJnpms1R0RyNjYBmidRrLFGYuxrO55SDv24cp6Dt4LEVQxUv6HFeD1bJ17ZblPrWC/
         w1tQ==
MIME-Version: 1.0
X-Received: by 10.50.43.225 with SMTP id z1mr1066296igl.17.1412650695518; Mon,
 06 Oct 2014 19:58:15 -0700 (PDT)
Received: by 10.64.242.196 with HTTP; Mon, 6 Oct 2014 19:58:15 -0700 (PDT)
In-Reply-To: <CABPQxsu22hmtpL4UcUpBbORroCw16Hpf5mhJ4c3Rv0ygYH-V3g@mail.gmail.com>
References: <CAF7WS+qVxq7BZBWRPTmKhJGH3fUvjWFQ1mrOPb_Yat3dOnJ0aA@mail.gmail.com>
	<CABPQxsu22hmtpL4UcUpBbORroCw16Hpf5mhJ4c3Rv0ygYH-V3g@mail.gmail.com>
Date: Mon, 6 Oct 2014 22:58:15 -0400
Message-ID: <CAF7WS+qmj--ruKEcqaYm6b-XBTUER4mkp6aVSOWLOyfvDO_niw@mail.gmail.com>
Subject: Re: Pull Requests
From: Bill Bejeck <bbejeck@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e010d8dd6e5f3950504cc5e00
X-Virus-Checked: Checked by ClamAV on apache.org

--089e010d8dd6e5f3950504cc5e00
Content-Type: text/plain; charset=UTF-8

Can someone review patch #2309 (jira task SPARK-3178)

Thanks

On Mon, Oct 6, 2014 at 10:41 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> Hey Bill,
>
> Automated testing is just one small part of the process that performs
> basic sanity checks on code. All patches need to be championed and
> merged by a committer to make it into Spark. For large patches we also
> ask users to propose a design before sending a patch.
>
> This is discussed in our contributing page:
> https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
>
> If there is a patch that you are waiting for feedback on feel free to
> just ping this list with the patch number. Is there one you are
> waiting for feedback on?
>
> - Patrick
>
> On Mon, Oct 6, 2014 at 7:32 PM, Bill Bejeck <bbejeck@gmail.com> wrote:
> > Once a PR has been tested and verified, when does it get pulled back into
> > the trunk?
>

--089e010d8dd6e5f3950504cc5e00--

From dev-return-9710-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 05:36:52 2014
Return-Path: <dev-return-9710-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 13E6F17497
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 05:36:52 +0000 (UTC)
Received: (qmail 16750 invoked by uid 500); 7 Oct 2014 05:36:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16668 invoked by uid 500); 7 Oct 2014 05:36:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16650 invoked by uid 99); 7 Oct 2014 05:36:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 05:36:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of atalwalkar@gmail.com designates 209.85.215.50 as permitted sender)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 05:36:24 +0000
Received: by mail-la0-f50.google.com with SMTP id s18so5646712lam.37
        for <dev@spark.apache.org>; Mon, 06 Oct 2014 22:36:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=YemaFmtvxtrPiBhHcrYWvPZquyU04xnv+ikhzblVILE=;
        b=Z5jZ8YOszr8Ovfuh+RU58fXKn5gStBeP5ioudMzSjltY8bLwkbWWVe+WBThQcXqMy7
         AG4Hx1s9VhVwC3WOg1CmLk/cNuAO/MsW51v6SLAOqOe72Pr2ya0J0U6uwaF1w+b7TU0f
         qVNZQ2Eh9cx8SYFMmRX4ON2RbIRdfFBszRWf6iY+vkMzlJctn98TG2190prWp1L6/5xs
         6wIsBSF1On8o6DU7yuRzh3w25w9lLZGaO+InE7gdTPORecBeUwxtjnaxp7OjuUQphtbm
         8xkVFyy7oWHLCzkNY0CEaOI2uxiGhF3a97VH4kOH0ksXU6v2qhw1b7kcAR/eK7MAIZux
         6OIQ==
X-Received: by 10.152.23.199 with SMTP id o7mr1462711laf.26.1412660183349;
 Mon, 06 Oct 2014 22:36:23 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.10.134 with HTTP; Mon, 6 Oct 2014 22:36:03 -0700 (PDT)
In-Reply-To: <5431FE42.2080502@gmail.com>
References: <5431FE42.2080502@gmail.com>
From: Ameet Talwalkar <atalwalkar@gmail.com>
Date: Mon, 6 Oct 2014 22:36:03 -0700
Message-ID: <CAH3_EVNv=fFNhnC_BQo4+vFyAxViKNCV+CTvzLdi3V4LihaLOw@mail.gmail.com>
Subject: Re: Hyper Parameter Tuning Algorithms
To: Lochana Menikarachchi <lochanac@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158c95a6abfd60504ce9424
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158c95a6abfd60504ce9424
Content-Type: text/plain; charset=UTF-8

Hi Lochana,

This post is also referring to the MLbase project I mentioned in my
previous email.  We have not open-sourced this work, but plan to do so.

Moreover, you might want to check out the following JIRA ticket
<https://issues.apache.org/jira/browse/SPARK-3530>that includes the design
doc for ML pipelines and parameters in MLlib.  This design will include
many of the ideas from our MLbase work.

-Ameet

On Sun, Oct 5, 2014 at 7:28 PM, Lochana Menikarachchi <lochanac@gmail.com>
wrote:

> Found this thread from April..
>
> http://mail-archives.apache.org/mod_mbox/spark-user/201404.mbox/%
> 3CCABjXkq6b7SfAxie4+AqTCmD8jSqBZnsxSFw6V5o0WWWouOBbCw@mail.gmail.com%3E
>
> Wondering what the status of this.. We are thinking about implementing
> these algorithms.. Would be a waste if they are already available?
>
> Please advice.
>
> Thanks.
>
> Lochana
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e0158c95a6abfd60504ce9424--

From dev-return-9711-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 13:30:17 2014
Return-Path: <dev-return-9711-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 54EC617BAE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 13:30:17 +0000 (UTC)
Received: (qmail 42448 invoked by uid 500); 7 Oct 2014 13:30:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42376 invoked by uid 500); 7 Oct 2014 13:30:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42364 invoked by uid 99); 7 Oct 2014 13:30:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 13:30:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rnowling@gmail.com designates 74.125.82.43 as permitted sender)
Received: from [74.125.82.43] (HELO mail-wg0-f43.google.com) (74.125.82.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 13:30:12 +0000
Received: by mail-wg0-f43.google.com with SMTP id m15so9315555wgh.14
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 06:29:50 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Bq+tvmrOLqmpZs53UsWUBE3sXA6xNNGLLT5mGSY4vc4=;
        b=Pc3yXdpubxlwUlLV2sfGR5Jttv/8M7j9D84l4gst03vd/rLJWrbRIwLwfl24i1bYsa
         SbquQa9Tu8k/QPk93p5hFBk57F3eOU3NYYHpvc7yizlP4inXYsDDgzNPYKLLGYw2eVqj
         ukbTdiG7QiCNV1smR4p9y0x8aRDK0DCrwzU1cwI9IOhEOhSSisL2MPoG5XyLc+g4OMII
         E+M+y+RQxOnyKzEz/7zyW+vbH4IUSmGgQHJwznjMJC4tTEbB1S2owfmvcGw0tiDuJYy0
         QKDwgRD4Ba59g38n1/Twm93MjdE093xm+RG+PnGHrg8bnhQ8zq0blSzhlqi4fI05OSXz
         4IBg==
MIME-Version: 1.0
X-Received: by 10.194.78.136 with SMTP id b8mr4808879wjx.106.1412688590778;
 Tue, 07 Oct 2014 06:29:50 -0700 (PDT)
Received: by 10.194.57.80 with HTTP; Tue, 7 Oct 2014 06:29:50 -0700 (PDT)
In-Reply-To: <CAAHrQ0kc4V-B357hMX2OEDsauxnpniTDPbf9ycx+9oh6qVKXiw@mail.gmail.com>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
	<54323A64.2090205@uninett.no>
	<CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
	<CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
	<543249BB.505@uninett.no>
	<CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
	<CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com>
	<CAAHrQ0kc4V-B357hMX2OEDsauxnpniTDPbf9ycx+9oh6qVKXiw@mail.gmail.com>
Date: Tue, 7 Oct 2014 09:29:50 -0400
Message-ID: <CADtDQQJzkWAW-AZ2zQEYqXy02QnpZ-rHTuf9fYZc5MS3SAgv4w@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
From: RJ Nowling <rnowling@gmail.com>
To: Fairiz Azizi <coderfi@gmail.com>
Cc: Timothy Chen <tnachen@gmail.com>, Gurvinder Singh <gurvinder.singh@uninett.no>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bd91a8ca1d3dc0504d5319b
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bd91a8ca1d3dc0504d5319b
Content-Type: text/plain; charset=UTF-8

I was able to reproduce it on a small 4 node cluster (1 mesos master and 3
mesos slaves) with relatively low-end specs.  As I said, I just ran the log
query examples with the fine-grained mesos mode.

Spark 1.1.0 and mesos 0.20.1.

Fairiz, could you try running the logquery example included with Spark and
see what you get?

Thanks!

On Mon, Oct 6, 2014 at 8:07 PM, Fairiz Azizi <coderfi@gmail.com> wrote:

> That's what great about Spark, the community is so active! :)
>
> I compiled Mesos 0.20.1 from the source tarball.
>
> Using the Mapr3 Spark 1.1.0 distribution from the Spark downloads page
>  (spark-1.1.0-bin-mapr3.tgz).
>
> I see no problems for the workloads we are trying.
>
> However, the cluster is small (less than 100 cores across 3 nodes).
>
> The workloads reads in just a few gigabytes from HDFS, via an ipython
> notebook spark shell.
>
> thanks,
> Fi
>
>
>
> Fairiz "Fi" Azizi
>
> On Mon, Oct 6, 2014 at 9:20 AM, Timothy Chen <tnachen@gmail.com> wrote:
>
>> Ok I created SPARK-3817 to track this, will try to repro it as well.
>>
>> Tim
>>
>> On Mon, Oct 6, 2014 at 6:08 AM, RJ Nowling <rnowling@gmail.com> wrote:
>> > I've recently run into this issue as well. I get it from running Spark
>> > examples such as log query.  Maybe that'll help reproduce the issue.
>> >
>> >
>> > On Monday, October 6, 2014, Gurvinder Singh <gurvinder.singh@uninett.no
>> >
>> > wrote:
>> >>
>> >> The issue does not occur if the task at hand has small number of map
>> >> tasks. I have a task which has 978 map tasks and I see this error as
>> >>
>> >> 14/10/06 09:34:40 ERROR BlockManagerMasterActor: Got two different
>> block
>> >> manager registrations on 20140711-081617-711206558-5050-2543-5
>> >>
>> >> Here is the log from the mesos-slave where this container was running.
>> >>
>> >> http://pastebin.com/Q1Cuzm6Q
>> >>
>> >> If you look for the code from where error produced by spark, you will
>> >> see that it simply exit and saying in comments "this should never
>> >> happen, lets just quit" :-)
>> >>
>> >> - Gurvinder
>> >> On 10/06/2014 09:30 AM, Timothy Chen wrote:
>> >> > (Hit enter too soon...)
>> >> >
>> >> > What is your setup and steps to repro this?
>> >> >
>> >> > Tim
>> >> >
>> >> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com>
>> wrote:
>> >> >> Hi Gurvinder,
>> >> >>
>> >> >> I tried fine grain mode before and didn't get into that problem.
>> >> >>
>> >> >>
>> >> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
>> >> >> <gurvinder.singh@uninett.no> wrote:
>> >> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>> >> >>>> The Spark online docs indicate that Spark is compatible with Mesos
>> >> >>>> 0.18.1
>> >> >>>>
>> >> >>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
>> >> >>>>
>> >> >>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos
>> >> >>>> v0.20.0?
>> >> >>>>
>> >> >>>> -Fi
>> >> >>>>
>> >> >>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in
>> >> >>> coarse
>> >> >>> mode, in fine grain mode there is an issue with blockmanager names
>> >> >>> conflict. I have been waiting for it to be fixed but it is still
>> >> >>> there.
>> >> >>>
>> >> >>> -Gurvinder
>> >> >>>
>> >> >>>
>> ---------------------------------------------------------------------
>> >> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >> >>> For additional commands, e-mail: dev-help@spark.apache.org
>> >> >>>
>> >>
>> >>
>> >> ---------------------------------------------------------------------
>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >> For additional commands, e-mail: dev-help@spark.apache.org
>> >>
>> >
>> >
>> > --
>> > em rnowling@gmail.com
>> > c 954.496.2314
>>
>
>


-- 
em rnowling@gmail.com
c 954.496.2314

--047d7bd91a8ca1d3dc0504d5319b--

From dev-return-9712-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 18:43:04 2014
Return-Path: <dev-return-9712-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 86BCB178A4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 18:43:04 +0000 (UTC)
Received: (qmail 21543 invoked by uid 500); 7 Oct 2014 18:43:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21482 invoked by uid 500); 7 Oct 2014 18:43:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21470 invoked by uid 99); 7 Oct 2014 18:43:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 18:43:02 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.181 as permitted sender)
Received: from [209.85.217.181] (HELO mail-lb0-f181.google.com) (209.85.217.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 18:42:36 +0000
Received: by mail-lb0-f181.google.com with SMTP id l4so6764131lbv.12
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 11:42:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=FeSDtsD1pX3GTk46UmcBgLGQd+HT1nyBegG7/yPG7sc=;
        b=Bqn1mPIWm9cvXTrePLr6wztYKTKU1kF5L6Bfeg4iHcoftztTcgku5k6tEkrL2LWX03
         6hSc/zM9MBSEWfyrW3oro+j9Ffo+pDiA7EZpfkP0wfEgnV8oKFKsS3IrSl8wu84o7eET
         /MHUADEzrUGCVRemLSFRN4CMPL30P8zeRUWOG890g1wL0+wgz7Ck1sPGY0UVg+x/U37V
         2hFcEfmtdQbUT+chgRbtqJDSAllwf0yFt9cPB8eL9aP4dRnaAIqvPQdE8CZaOzw/5e5A
         tzlK2bzneGDPsVTTK1tG2hmMxxTuzXxOdCGEBhW3p+ye5xi2s0gGuY3aqYzbgD0knevH
         W9QA==
MIME-Version: 1.0
X-Received: by 10.152.88.43 with SMTP id bd11mr6193723lab.62.1412707355465;
 Tue, 07 Oct 2014 11:42:35 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Tue, 7 Oct 2014 11:42:35 -0700 (PDT)
Date: Tue, 7 Oct 2014 11:42:35 -0700
Message-ID: <CA+B-+fxa5VAN0edS7ST2EGDz2JXy4Y+Y0Rcx-cVXvGfQTR-dPA@mail.gmail.com>
Subject: Local tests logging to log4j
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c35452181cb60504d99006
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c35452181cb60504d99006
Content-Type: text/plain; charset=UTF-8

Hi,

I have added some changes to ALS tests and I am re-running tests as:

mvn -Dhadoop.version=2.3.0-cdh5.1.0 -Phadoop-2.3 -Pyarn
-DwildcardSuites=org.apache.spark.mllib.recommendation.ALSSuite test

I have some INFO logs in the code which I want to see on my console. They
work fine if I add println.

I copied conf/log4j.properties.template to conf/log4j.properties

The options are:

log4j.rootCategory=INFO, console

log4j.appender.console=org.apache.log4j.ConsoleAppender

log4j.appender.console.target=System.err

I still don't see the INFO msgs on the console.

Any idea if I am setting up my log4j properties correctly ?

Thanks.

Deb

--001a11c35452181cb60504d99006--

From dev-return-9713-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 18:43:19 2014
Return-Path: <dev-return-9713-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 12F2A178A5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 18:43:19 +0000 (UTC)
Received: (qmail 22890 invoked by uid 500); 7 Oct 2014 18:43:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22816 invoked by uid 500); 7 Oct 2014 18:43:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22805 invoked by uid 99); 7 Oct 2014 18:43:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 18:43:17 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.215.45] (HELO mail-la0-f45.google.com) (209.85.215.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 18:43:13 +0000
Received: by mail-la0-f45.google.com with SMTP id q1so6947586lam.32
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 11:42:50 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=Cp6vDXPpkVloV+vA2ettOvh57ZJTUl5tWEDIFgzMlEU=;
        b=H/f/A1vbcD/+8HXgL81VctAo61izXt3zhSLp6W74GmA6b9AjSdNGH4BwRdFF9li3ob
         d1x5+AkV8DjEFUCVR7aKGo14yOvtiE2PZFac7lUodgNlXxqDngUP4ZUVusRTZ5mza6Mz
         pWX8a1wB7kLJ4Cv3lozjTST59M+gthrZeoXCMHAJeI6II7RkrxNa/N1AZqyYET1A7/oE
         1YY9Yi6KIcYArjzycoRCQJruksZFX7giG70KEBqhRVjoxIrOeNoDUWmilVHB2vrypTk1
         flgHGjHTZH/qcaF9KmTN8Hn/HMil9fEvRrn7tpw8WmTzgE4CFTc3f/+6A0Q5b42TZuvZ
         u/FA==
X-Gm-Message-State: ALoCoQlwFJG8JZk+2OiQox/2CoVLsA4oRsz8gty8Wp6g9P/iBcU/uYQc9tbxoohtfG7CYS9lNWNl
MIME-Version: 1.0
X-Received: by 10.152.21.130 with SMTP id v2mr5266909lae.94.1412707370848;
 Tue, 07 Oct 2014 11:42:50 -0700 (PDT)
Received: by 10.25.162.15 with HTTP; Tue, 7 Oct 2014 11:42:50 -0700 (PDT)
In-Reply-To: <5432525A.8040109@exensa.com>
References: <5432525A.8040109@exensa.com>
Date: Tue, 7 Oct 2014 11:42:50 -0700
Message-ID: <CA+2Pv=jyH-K-cHSu=FzsyQwvrSPUkTbWY=SYJK+5WFH2iB=XNw@mail.gmail.com>
Subject: Re: TorrentBroadcast slow performance
From: Davies Liu <davies@databricks.com>
To: Guillaume Pitel <guillaume.pitel@exensa.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Could you create a JIRA for it? maybe it's a regression after
https://issues.apache.org/jira/browse/SPARK-3119.

We will appreciate that if you could tell how to reproduce it.

On Mon, Oct 6, 2014 at 1:27 AM, Guillaume Pitel
<guillaume.pitel@exensa.com> wrote:
> Hi,
>
> I've had no answer to this on user@spark.apache.org, so I post it on dev
> before filing a JIRA (in case the problem or solution is already identifi=
ed)
>
> We've had some performance issues since switching to 1.1.0, and we finall=
y
> found the origin : TorrentBroadcast seems to be very slow in our setting
> (and it became default with 1.1.0)
>
> The logs of a 4MB variable with TorrentBroadcast : (15s)
>
> 14/10/01 15:47:13 INFO storage.MemoryStore: Block broadcast_84_piece1 sto=
red
> as bytes in memory (estimated size 171.6 KB, free 7.2 GB)
> 14/10/01 15:47:13 INFO storage.BlockManagerMaster: Updated info of block
> broadcast_84_piece1
> 14/10/01 15:47:23 INFO storage.MemoryStore: ensureFreeSpace(4194304) call=
ed
> with curMem=3D1401611984, maxMem=3D9168696115
> 14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84_piece0 sto=
red
> as bytes in memory (estimated size 4.0 MB, free 7.2 GB)
> 14/10/01 15:47:23 INFO storage.BlockManagerMaster: Updated info of block
> broadcast_84_piece0
> 14/10/01 15:47:23 INFO broadcast.TorrentBroadcast: Reading broadcast
> variable 84 took 15.202260006 s
> 14/10/01 15:47:23 INFO storage.MemoryStore: ensureFreeSpace(4371392) call=
ed
> with curMem=3D1405806288, maxMem=3D9168696115
> 14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84 stored as
> values in memory (estimated size 4.2 MB, free 7.2 GB)
>
> (notice that a 10s lag happens after the "Updated info of block
> broadcast_..." and before the MemoryStore log
>
> And with HttpBroadcast (0.3s):
>
> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Started reading broadcast
> variable 147
> 14/10/01 16:05:58 INFO storage.MemoryStore: ensureFreeSpace(4369376) call=
ed
> with curMem=3D1373493232, maxMem=3D9168696115
> 14/10/01 16:05:58 INFO storage.MemoryStore: Block broadcast_147 stored as
> values in memory (estimated size 4.2 MB, free 7.3 GB)
> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Reading broadcast variabl=
e
> 147 took 0.320907112 s 14/10/01 16:05:58 INFO storage.BlockManager: Found
> block broadcast_147 locally
>
> Since Torrent is supposed to perform much better than Http, we suspect a
> configuration error from our side, but are unable to pin it down. Does
> someone have any idea of the origin of the problem ?
>
> For now we're sticking with the HttpBroadcast workaround.
>
> Guillaume
> --
> Guillaume PITEL, Pr=C3=A9sident
> +33(0)626 222 431
>
> eXenSa S.A.S.
> 41, rue P=C3=A9rier - 92120 Montrouge - FRANCE
> Tel +33(0)184 163 677 / Fax +33(0)972 283 705

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9714-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 18:52:51 2014
Return-Path: <dev-return-9714-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D67AD17907
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 18:52:51 +0000 (UTC)
Received: (qmail 51330 invoked by uid 500); 7 Oct 2014 18:52:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51254 invoked by uid 500); 7 Oct 2014 18:52:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51237 invoked by uid 99); 7 Oct 2014 18:52:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 18:52:50 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.42 as permitted sender)
Received: from [209.85.220.42] (HELO mail-pa0-f42.google.com) (209.85.220.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 18:52:46 +0000
Received: by mail-pa0-f42.google.com with SMTP id bj1so7648109pad.15
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 11:52:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=qdEneA1iURZtTw5hdfNZw6g5fO9MljT8Ddb8vxAIPI4=;
        b=qZeDVUBGuGeq2WnhUCL+KM0m50/dEbi/wuEMfhyW3xVP5z28xTT6E1yev+kJe95Dhq
         UcsTFj8YpFfi9bWuOMHOgnDFJhBM5myzmCWacxfpmpLiPiVmAOdMyyzuIrUSxyCssZ0h
         o/EBM0MC67tfnRTEIeOThp+m5+QkIWDN+5fbOKcQEO5dW/aLBICElVOkWleDG6Ql57SB
         F+9ZR7g5b6gelZVy6x78ewH5LNuxcd0H+zxg8r4XpVx/2uqLmVLKqcZz1QdAkCU0/NM1
         oAhzLvCYU1US3nrB6Xj7ozA5D/qWmA7DosGp61slyB8CyZHojZEeQBbwY+GOm4TWl1kf
         oVWQ==
X-Received: by 10.66.141.197 with SMTP id rq5mr5387844pab.124.1412707945612;
        Tue, 07 Oct 2014 11:52:25 -0700 (PDT)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id kk10sm14464074pdb.63.2014.10.07.11.52.24
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 07 Oct 2014 11:52:24 -0700 (PDT)
Content-Type: text/plain; charset=iso-8859-1
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: TorrentBroadcast slow performance
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CA+2Pv=jyH-K-cHSu=FzsyQwvrSPUkTbWY=SYJK+5WFH2iB=XNw@mail.gmail.com>
Date: Tue, 7 Oct 2014 11:52:22 -0700
Cc: Guillaume Pitel <guillaume.pitel@exensa.com>,
 "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <5F5B1AD7-4440-4579-BBE9-55FE7090CB99@gmail.com>
References: <5432525A.8040109@exensa.com> <CA+2Pv=jyH-K-cHSu=FzsyQwvrSPUkTbWY=SYJK+5WFH2iB=XNw@mail.gmail.com>
To: Davies Liu <davies@databricks.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Maybe there is a firewall issue that makes it slow for your nodes to =
connect through the IP addresses they're configured with. I see there's =
this 10 second pause between "Updated info of block broadcast_84_piece1" =
and "ensureFreeSpace(4194304) called" (where it actually receives the =
block). HTTP broadcast used only HTTP fetches from the executors to the =
driver, but TorrentBroadcast has connections between the executors =
themselves and between executors and the driver over a different port. =
Where are you running your driver app and nodes?

Matei

On Oct 7, 2014, at 11:42 AM, Davies Liu <davies@databricks.com> wrote:

> Could you create a JIRA for it? maybe it's a regression after
> https://issues.apache.org/jira/browse/SPARK-3119.
>=20
> We will appreciate that if you could tell how to reproduce it.
>=20
> On Mon, Oct 6, 2014 at 1:27 AM, Guillaume Pitel
> <guillaume.pitel@exensa.com> wrote:
>> Hi,
>>=20
>> I've had no answer to this on user@spark.apache.org, so I post it on =
dev
>> before filing a JIRA (in case the problem or solution is already =
identified)
>>=20
>> We've had some performance issues since switching to 1.1.0, and we =
finally
>> found the origin : TorrentBroadcast seems to be very slow in our =
setting
>> (and it became default with 1.1.0)
>>=20
>> The logs of a 4MB variable with TorrentBroadcast : (15s)
>>=20
>> 14/10/01 15:47:13 INFO storage.MemoryStore: Block broadcast_84_piece1 =
stored
>> as bytes in memory (estimated size 171.6 KB, free 7.2 GB)
>> 14/10/01 15:47:13 INFO storage.BlockManagerMaster: Updated info of =
block
>> broadcast_84_piece1
>> 14/10/01 15:47:23 INFO storage.MemoryStore: ensureFreeSpace(4194304) =
called
>> with curMem=3D1401611984, maxMem=3D9168696115
>> 14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84_piece0 =
stored
>> as bytes in memory (estimated size 4.0 MB, free 7.2 GB)
>> 14/10/01 15:47:23 INFO storage.BlockManagerMaster: Updated info of =
block
>> broadcast_84_piece0
>> 14/10/01 15:47:23 INFO broadcast.TorrentBroadcast: Reading broadcast
>> variable 84 took 15.202260006 s
>> 14/10/01 15:47:23 INFO storage.MemoryStore: ensureFreeSpace(4371392) =
called
>> with curMem=3D1405806288, maxMem=3D9168696115
>> 14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84 stored =
as
>> values in memory (estimated size 4.2 MB, free 7.2 GB)
>>=20
>> (notice that a 10s lag happens after the "Updated info of block
>> broadcast_..." and before the MemoryStore log
>>=20
>> And with HttpBroadcast (0.3s):
>>=20
>> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Started reading =
broadcast
>> variable 147
>> 14/10/01 16:05:58 INFO storage.MemoryStore: ensureFreeSpace(4369376) =
called
>> with curMem=3D1373493232, maxMem=3D9168696115
>> 14/10/01 16:05:58 INFO storage.MemoryStore: Block broadcast_147 =
stored as
>> values in memory (estimated size 4.2 MB, free 7.3 GB)
>> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Reading broadcast =
variable
>> 147 took 0.320907112 s 14/10/01 16:05:58 INFO storage.BlockManager: =
Found
>> block broadcast_147 locally
>>=20
>> Since Torrent is supposed to perform much better than Http, we =
suspect a
>> configuration error from our side, but are unable to pin it down. =
Does
>> someone have any idea of the origin of the problem ?
>>=20
>> For now we're sticking with the HttpBroadcast workaround.
>>=20
>> Guillaume
>> --
>> Guillaume PITEL, Pr=E9sident
>> +33(0)626 222 431
>>=20
>> eXenSa S.A.S.
>> 41, rue P=E9rier - 92120 Montrouge - FRANCE
>> Tel +33(0)184 163 677 / Fax +33(0)972 283 705
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9715-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 19:24:52 2014
Return-Path: <dev-return-9715-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 09CBE17AA1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 19:24:52 +0000 (UTC)
Received: (qmail 51941 invoked by uid 500); 7 Oct 2014 19:24:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51875 invoked by uid 500); 7 Oct 2014 19:24:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51858 invoked by uid 99); 7 Oct 2014 19:24:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 19:24:50 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 74.125.82.47 as permitted sender)
Received: from [74.125.82.47] (HELO mail-wg0-f47.google.com) (74.125.82.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 19:24:45 +0000
Received: by mail-wg0-f47.google.com with SMTP id x13so10235375wgg.30
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 12:24:24 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=USIFlTfZzv0K66PD516nFhetDnfm9wlhENMfuuHQh0w=;
        b=ZF5T0B/2ESQI5zLWtufos2mQlxp+HqWvq7TRKK3BmwUlFOdftNsi/taIc4h0Z0MMGY
         rOWyXh0CumsZzeU9QQRUhYFKCQ3ndZ69x3/8JFp9AuN/ltxhsvzgPHURkEf7ALd1DIef
         5az826GkYCsfloVBxQF8z5e88opWBVEJWIkrYxhK3048tOu3Mn00MZQQkaaGV3VTQu5S
         8Mvm41xe9JsCWLf6rKMmvG2UA4Y0RTdxT5YYwZoLJFX7cCpN812lKQZJqFKPW5tWFAJs
         x0QEicJjV1SP2/DBSM6OpZ/LZZi+ssCQg0c0JyCjuJCZcvmGlJPCyh7+uinnyoW4ayIA
         lV7A==
X-Gm-Message-State: ALoCoQk0tdo5n1hSfCgx1pNhauiTto41zHpDtdUfbJdfjzc6SwFEpNuCGaYEbnnKkL9JzdQV7nMX
X-Received: by 10.194.71.229 with SMTP id y5mr6023097wju.129.1412709864343;
 Tue, 07 Oct 2014 12:24:24 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.27.179.132 with HTTP; Tue, 7 Oct 2014 12:24:04 -0700 (PDT)
In-Reply-To: <CA+B-+fxa5VAN0edS7ST2EGDz2JXy4Y+Y0Rcx-cVXvGfQTR-dPA@mail.gmail.com>
References: <CA+B-+fxa5VAN0edS7ST2EGDz2JXy4Y+Y0Rcx-cVXvGfQTR-dPA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 7 Oct 2014 20:24:04 +0100
Message-ID: <CAMAsSdKTU+Y6X2HjHsabacCZd+FG6U2ip5KHTb8+EeJhbXpq7A@mail.gmail.com>
Subject: Re: Local tests logging to log4j
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

What has worked for me is to bundle log4j.properties in the root of
the application's .jar file, since log4j will look for it there, and
configuring log4j will turn off Spark's default log4j configuration.

I don't think conf/log4j.properties is going to do anything by itself,
but -Dlog4j.configuration=/path/to/file should cause it read a config
file on the file system.

But for messing with a local build of Spark, just edit
core/src/main/resources/org/apache/spark/log4j-defaults.properties and
rebuild.

Yes I think your syntax is OK; here's some of mine where I turn off a
bunch of INFO messages:

log4j.rootLogger=INFO, stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p %c{1}:%L %m%n
log4j.logger.org.apache.hadoop=WARN
log4j.logger.org.apache.kafka=WARN
log4j.logger.kafka=WARN
log4j.logger.akka=WARN
log4j.logger.org.apache.spark=WARN
log4j.logger.org.apache.spark.storage.BlockManager=ERROR
log4j.logger.org.apache.zookeeper=WARN
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.I0Itec.zkclient=WARN

On Tue, Oct 7, 2014 at 7:42 PM, Debasish Das <debasish.das83@gmail.com> wrote:
> Hi,
>
> I have added some changes to ALS tests and I am re-running tests as:
>
> mvn -Dhadoop.version=2.3.0-cdh5.1.0 -Phadoop-2.3 -Pyarn
> -DwildcardSuites=org.apache.spark.mllib.recommendation.ALSSuite test
>
> I have some INFO logs in the code which I want to see on my console. They
> work fine if I add println.
>
> I copied conf/log4j.properties.template to conf/log4j.properties
>
> The options are:
>
> log4j.rootCategory=INFO, console
>
> log4j.appender.console=org.apache.log4j.ConsoleAppender
>
> log4j.appender.console.target=System.err
>
> I still don't see the INFO msgs on the console.
>
> Any idea if I am setting up my log4j properties correctly ?
>
> Thanks.
>
> Deb

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9716-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 20:46:08 2014
Return-Path: <dev-return-9716-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 80D0D17E7F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 20:46:08 +0000 (UTC)
Received: (qmail 78899 invoked by uid 500); 7 Oct 2014 20:46:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78821 invoked by uid 500); 7 Oct 2014 20:46:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78800 invoked by uid 99); 7 Oct 2014 20:46:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 20:46:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.171 as permitted sender)
Received: from [209.85.212.171] (HELO mail-wi0-f171.google.com) (209.85.212.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 20:45:41 +0000
Received: by mail-wi0-f171.google.com with SMTP id em10so9091787wid.4
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 13:45:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=3a3Z/fRX6EWaaJtrWok36VT99gIV0T6yb4xhfKQxgWc=;
        b=lbGzsjTGyqk0t849XgvSou9AWbrYmh+lK5z28DWRvFRZ7ZsfMQGu2P/rHhLe558/lw
         /psjeeQDs7WrjH0eJM9ru1Mo7/PAOnZ1xCHUKg9Lu93vJfBK8x5olqlZuufnm3KKVbAh
         9ukpLyKorMaAzatQokMX28Xtjkrq2NaLomLtKUgs4QobX3cjK0/8uCFfmZptMbGMuFaR
         SUSOfNV2Mdqo4ysvufcr4nYWbYi2En38jFueowD81rI5LFtV2KfJUAZCPPmjOcON84UH
         Q09eUWLbvVaJmeqmU287gZcguSCCArqzBMaUab7pfzPDoJUxia074xbaJNqEC3TQqZem
         IAgA==
X-Received: by 10.180.79.41 with SMTP id g9mr7128236wix.75.1412714741356; Tue,
 07 Oct 2014 13:45:41 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Tue, 7 Oct 2014 13:45:01 -0700 (PDT)
In-Reply-To: <542CCF41.8000105@gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
 <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
 <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
 <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com>
 <CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com>
 <CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com> <542CCF41.8000105@gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 7 Oct 2014 16:45:01 -0400
Message-ID: <CAOhmDzfWXfdFn9DNKJvsh2psXhQ1NCH9i=tfTML0m5HO1CLNyA@mail.gmail.com>
Subject: Re: Extending Scala style checks
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Michael Armbrust <michael@databricks.com>, Patrick Wendell <pwendell@gmail.com>, 
	Ted Yu <yuzhihong@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d0443042e53df7f0504db48eb
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0443042e53df7f0504db48eb
Content-Type: text/plain; charset=UTF-8

For starters, do we have a list of all the Scala style rules that are
currently not enforced automatically but are likely well-suited for
automation?

Let's put such a list together in a JIRA issue and work through
implementing them.

Nick

On Thu, Oct 2, 2014 at 12:06 AM, Cheng Lian <lian.cs.zju@gmail.com> wrote:

> Since we can easily catch the list of all changed files in a PR, I think
> we can start with adding the no trailing space check for newly changed
> files only?
>
>
> On 10/2/14 9:24 AM, Nicholas Chammas wrote:
>
>> Yeah, I remember that hell when I added PEP 8 to the build checks and
>> fixed
>> all the outstanding Python style issues. I had to keep rebasing and
>> resolving merge conflicts until the PR was merged.
>>
>> It's a rough process, but thankfully it's also a one-time process. I might
>> be able to help with that in the next week or two if no-one else wants to
>> pick it up.
>>
>> Nick
>>
>> On Wed, Oct 1, 2014 at 9:20 PM, Michael Armbrust <michael@databricks.com>
>> wrote:
>>
>>  The hard part here is updating the existing code base... which is going
>>> to
>>> create merge conflicts with like all of the open PRs...
>>>
>>> On Wed, Oct 1, 2014 at 6:13 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>  Ah, since there appears to be a built-in rule for end-of-line
>>>> whitespace,
>>>> Michael and Cheng, y'all should be able to add this in pretty easily.
>>>>
>>>> Nick
>>>>
>>>> On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com>
>>>> wrote:
>>>>
>>>>  Hey Nick,
>>>>>
>>>>> We can always take built-in rules. Back when we added this Prashant
>>>>> Sharma actually did some great work that lets us write our own style
>>>>> rules in cases where rules don't exist.
>>>>>
>>>>> You can see some existing rules here:
>>>>>
>>>>>
>>>>>  https://github.com/apache/spark/tree/master/project/
>>>> spark-style/src/main/scala/org/apache/spark/scalastyle
>>>>
>>>>> Prashant has over time contributed a lot of our custom rules upstream
>>>>> to stalastyle, so now there are only a couple there.
>>>>>
>>>>> - Patrick
>>>>>
>>>>> On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>>>
>>>>>> Please take a look at WhitespaceEndOfLineChecker under:
>>>>>> http://www.scalastyle.org/rules-0.1.0.html
>>>>>>
>>>>>> Cheers
>>>>>>
>>>>>> On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
>>>>>>
>>>>> nicholas.chammas@gmail.com
>>>>>
>>>>>> wrote:
>>>>>>> As discussed here <https://github.com/apache/spark/pull/2619>, it
>>>>>>>
>>>>>> would be
>>>>>
>>>>>> good to extend our Scala style checks to programmatically enforce as
>>>>>>>
>>>>>> many
>>>>>
>>>>>> of our style rules as possible.
>>>>>>>
>>>>>>> Does anyone know if it's relatively straightforward to enforce
>>>>>>>
>>>>>> additional
>>>>>
>>>>>> rules like the "no trailing spaces" rule mentioned in the linked PR?
>>>>>>>
>>>>>>> Nick
>>>>>>>
>>>>>>>
>>>
>

--f46d0443042e53df7f0504db48eb--

From dev-return-9717-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct  7 21:02:58 2014
Return-Path: <dev-return-9717-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9597E17F1B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue,  7 Oct 2014 21:02:58 +0000 (UTC)
Received: (qmail 44204 invoked by uid 500); 7 Oct 2014 21:02:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44135 invoked by uid 500); 7 Oct 2014 21:02:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44121 invoked by uid 99); 7 Oct 2014 21:02:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 21:02:57 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.181 as permitted sender)
Received: from [209.85.217.181] (HELO mail-lb0-f181.google.com) (209.85.217.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 07 Oct 2014 21:02:32 +0000
Received: by mail-lb0-f181.google.com with SMTP id l4so6789208lbv.40
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 14:02:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=WnYos48a55dmTPQbwuQyAhMdWBWdWm/kmxVR641CKbM=;
        b=Ktsy9Ci48KiSfTM4fORlYrpxPsw/dbgB2sxAMME0QMDp6J5jxuzFtsam/Eo7fKs73e
         S+0LB+B/gllzIQn72cYNQ1MuDXZBQKf9I4Ek8v9erJRV1BxIWXROSjNfrnlWNW9wdjGU
         nIusyx1gZToSHiBV2GkjgOkQ9EI2ou4rmIiPTNbvtxTi+9MJe9rHC2dLPNokVn3hheoB
         d35tGxx69LI9jQaI9C28nXySISsresqWTRorxjSoMZV32FKhN8TI+l3vkPtuS/AgxtDB
         Ly4aEJpxDM0a+sQFzzxP4DPRBauG+iW+ElUVrABcOY9zkXVlYZPRGbTWDfEEpf3jhmRX
         8hVA==
MIME-Version: 1.0
X-Received: by 10.152.205.9 with SMTP id lc9mr6716680lac.37.1412715751104;
 Tue, 07 Oct 2014 14:02:31 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Tue, 7 Oct 2014 14:02:31 -0700 (PDT)
In-Reply-To: <CAMAsSdKTU+Y6X2HjHsabacCZd+FG6U2ip5KHTb8+EeJhbXpq7A@mail.gmail.com>
References: <CA+B-+fxa5VAN0edS7ST2EGDz2JXy4Y+Y0Rcx-cVXvGfQTR-dPA@mail.gmail.com>
	<CAMAsSdKTU+Y6X2HjHsabacCZd+FG6U2ip5KHTb8+EeJhbXpq7A@mail.gmail.com>
Date: Tue, 7 Oct 2014 14:02:31 -0700
Message-ID: <CA+B-+fwNBdY-8sB_J-rVXEg9S-ZX5kTnJ6n5ZzM=_f==5JWGCA@mail.gmail.com>
Subject: Re: Local tests logging to log4j
From: Debasish Das <debasish.das83@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11349af083680e0504db84cb
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11349af083680e0504db84cb
Content-Type: text/plain; charset=UTF-8

Thanks Sean...trying them out...

On Tue, Oct 7, 2014 at 12:24 PM, Sean Owen <sowen@cloudera.com> wrote:

> What has worked for me is to bundle log4j.properties in the root of
> the application's .jar file, since log4j will look for it there, and
> configuring log4j will turn off Spark's default log4j configuration.
>
> I don't think conf/log4j.properties is going to do anything by itself,
> but -Dlog4j.configuration=/path/to/file should cause it read a config
> file on the file system.
>
> But for messing with a local build of Spark, just edit
> core/src/main/resources/org/apache/spark/log4j-defaults.properties and
> rebuild.
>
> Yes I think your syntax is OK; here's some of mine where I turn off a
> bunch of INFO messages:
>
> log4j.rootLogger=INFO, stdout
> log4j.appender.stdout=org.apache.log4j.ConsoleAppender
> log4j.appender.stdout.Target=System.out
> log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
> log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p %c{1}:%L
> %m%n
> log4j.logger.org.apache.hadoop=WARN
> log4j.logger.org.apache.kafka=WARN
> log4j.logger.kafka=WARN
> log4j.logger.akka=WARN
> log4j.logger.org.apache.spark=WARN
> log4j.logger.org.apache.spark.storage.BlockManager=ERROR
> log4j.logger.org.apache.zookeeper=WARN
> log4j.logger.org.eclipse.jetty=WARN
> log4j.logger.org.I0Itec.zkclient=WARN
>
> On Tue, Oct 7, 2014 at 7:42 PM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > Hi,
> >
> > I have added some changes to ALS tests and I am re-running tests as:
> >
> > mvn -Dhadoop.version=2.3.0-cdh5.1.0 -Phadoop-2.3 -Pyarn
> > -DwildcardSuites=org.apache.spark.mllib.recommendation.ALSSuite test
> >
> > I have some INFO logs in the code which I want to see on my console. They
> > work fine if I add println.
> >
> > I copied conf/log4j.properties.template to conf/log4j.properties
> >
> > The options are:
> >
> > log4j.rootCategory=INFO, console
> >
> > log4j.appender.console=org.apache.log4j.ConsoleAppender
> >
> > log4j.appender.console.target=System.err
> >
> > I still don't see the INFO msgs on the console.
> >
> > Any idea if I am setting up my log4j properties correctly ?
> >
> > Thanks.
> >
> > Deb
>

--001a11349af083680e0504db84cb--

From dev-return-9718-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 00:37:29 2014
Return-Path: <dev-return-9718-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 52C1C17A46
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 00:37:29 +0000 (UTC)
Received: (qmail 23704 invoked by uid 500); 8 Oct 2014 00:37:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23629 invoked by uid 500); 8 Oct 2014 00:37:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23612 invoked by uid 99); 8 Oct 2014 00:37:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 00:37:28 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of fairizazizi@gmail.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 00:37:24 +0000
Received: by mail-wi0-f182.google.com with SMTP id n3so9461943wiv.15
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 17:37:03 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=4MVDN6+hoinEudJ6QaMoiMJgf92e6BPcFZE4f28c8BA=;
        b=lg2ICf20d8RGvQzC+ZhK9YRcyhEpcjywi7XVE6oZFwCcGa1ocBmNBzy+VOtorPMcoe
         MQ7XHclBMSqioZ19m4mdfB+FXmodT0NBgIPrqB4wQgcW20nAiIGQqqK+IJo53ibkB85R
         4t69tj+3jhOrV+wf4zW8LjcPOGVg/5KgPTwGNSHLBvqqPhqEHEERrc/Ci/qG6ZiSuPG/
         N27kXugcC42YhalCSq+yxW54mJJERYrcOJzVWMxW4G1AP8FoVSSqLOwsMqzQSBavptVH
         ir9vPACAjbQGP+OkcQEoTbjiTKbKgBAKNoo/yUMPtzjS+3iYzp8v+GftzxAXoqPZfMsa
         OTAQ==
X-Received: by 10.180.108.9 with SMTP id hg9mr393224wib.1.1412728622969; Tue,
 07 Oct 2014 17:37:02 -0700 (PDT)
MIME-Version: 1.0
Sender: fairizazizi@gmail.com
Received: by 10.194.219.2 with HTTP; Tue, 7 Oct 2014 17:36:42 -0700 (PDT)
In-Reply-To: <CADtDQQJzkWAW-AZ2zQEYqXy02QnpZ-rHTuf9fYZc5MS3SAgv4w@mail.gmail.com>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
 <54323A64.2090205@uninett.no> <CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
 <CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
 <543249BB.505@uninett.no> <CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
 <CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com>
 <CAAHrQ0kc4V-B357hMX2OEDsauxnpniTDPbf9ycx+9oh6qVKXiw@mail.gmail.com> <CADtDQQJzkWAW-AZ2zQEYqXy02QnpZ-rHTuf9fYZc5MS3SAgv4w@mail.gmail.com>
From: Fairiz Azizi <coderfi@gmail.com>
Date: Tue, 7 Oct 2014 17:36:42 -0700
X-Google-Sender-Auth: dEaFhqUoOqvV-8a9psHG83B2FT8
Message-ID: <CAAHrQ0=_XLNuGs+E_SB4eGs54xU=M70-uD+vd5NzZ=3-c-KGyA@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
To: RJ Nowling <rnowling@gmail.com>
Cc: Timothy Chen <tnachen@gmail.com>, Gurvinder Singh <gurvinder.singh@uninett.no>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8f3ba329bc7c130504de8349
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f3ba329bc7c130504de8349
Content-Type: text/plain; charset=UTF-8

Sure, could you point me to the example?

The only thing I could find was
https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala

So do you mean running it like:
   MASTER="mesos://xxxxxxx*:5050*" ./run-example LogQuery

I tried that and I can see the job run and the tasks complete on the slave
nodes, but the client process seems to hang forever, it's probably a
different problem. BTW, only a dozen or so tasks kick off.

I actually haven't done much with Scala and Spark (it's been all python).

Fi



Fairiz "Fi" Azizi

On Tue, Oct 7, 2014 at 6:29 AM, RJ Nowling <rnowling@gmail.com> wrote:

> I was able to reproduce it on a small 4 node cluster (1 mesos master and 3
> mesos slaves) with relatively low-end specs.  As I said, I just ran the log
> query examples with the fine-grained mesos mode.
>
> Spark 1.1.0 and mesos 0.20.1.
>
> Fairiz, could you try running the logquery example included with Spark and
> see what you get?
>
> Thanks!
>
> On Mon, Oct 6, 2014 at 8:07 PM, Fairiz Azizi <coderfi@gmail.com> wrote:
>
>> That's what great about Spark, the community is so active! :)
>>
>> I compiled Mesos 0.20.1 from the source tarball.
>>
>> Using the Mapr3 Spark 1.1.0 distribution from the Spark downloads page
>>  (spark-1.1.0-bin-mapr3.tgz).
>>
>> I see no problems for the workloads we are trying.
>>
>> However, the cluster is small (less than 100 cores across 3 nodes).
>>
>> The workloads reads in just a few gigabytes from HDFS, via an ipython
>> notebook spark shell.
>>
>> thanks,
>> Fi
>>
>>
>>
>> Fairiz "Fi" Azizi
>>
>> On Mon, Oct 6, 2014 at 9:20 AM, Timothy Chen <tnachen@gmail.com> wrote:
>>
>>> Ok I created SPARK-3817 to track this, will try to repro it as well.
>>>
>>> Tim
>>>
>>> On Mon, Oct 6, 2014 at 6:08 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>> > I've recently run into this issue as well. I get it from running Spark
>>> > examples such as log query.  Maybe that'll help reproduce the issue.
>>> >
>>> >
>>> > On Monday, October 6, 2014, Gurvinder Singh <
>>> gurvinder.singh@uninett.no>
>>> > wrote:
>>> >>
>>> >> The issue does not occur if the task at hand has small number of map
>>> >> tasks. I have a task which has 978 map tasks and I see this error as
>>> >>
>>> >> 14/10/06 09:34:40 ERROR BlockManagerMasterActor: Got two different
>>> block
>>> >> manager registrations on 20140711-081617-711206558-5050-2543-5
>>> >>
>>> >> Here is the log from the mesos-slave where this container was running.
>>> >>
>>> >> http://pastebin.com/Q1Cuzm6Q
>>> >>
>>> >> If you look for the code from where error produced by spark, you will
>>> >> see that it simply exit and saying in comments "this should never
>>> >> happen, lets just quit" :-)
>>> >>
>>> >> - Gurvinder
>>> >> On 10/06/2014 09:30 AM, Timothy Chen wrote:
>>> >> > (Hit enter too soon...)
>>> >> >
>>> >> > What is your setup and steps to repro this?
>>> >> >
>>> >> > Tim
>>> >> >
>>> >> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com>
>>> wrote:
>>> >> >> Hi Gurvinder,
>>> >> >>
>>> >> >> I tried fine grain mode before and didn't get into that problem.
>>> >> >>
>>> >> >>
>>> >> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
>>> >> >> <gurvinder.singh@uninett.no> wrote:
>>> >> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>>> >> >>>> The Spark online docs indicate that Spark is compatible with
>>> Mesos
>>> >> >>>> 0.18.1
>>> >> >>>>
>>> >> >>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
>>> >> >>>>
>>> >> >>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos
>>> >> >>>> v0.20.0?
>>> >> >>>>
>>> >> >>>> -Fi
>>> >> >>>>
>>> >> >>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in
>>> >> >>> coarse
>>> >> >>> mode, in fine grain mode there is an issue with blockmanager names
>>> >> >>> conflict. I have been waiting for it to be fixed but it is still
>>> >> >>> there.
>>> >> >>>
>>> >> >>> -Gurvinder
>>> >> >>>
>>> >> >>>
>>> ---------------------------------------------------------------------
>>> >> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> >> >>> For additional commands, e-mail: dev-help@spark.apache.org
>>> >> >>>
>>> >>
>>> >>
>>> >> ---------------------------------------------------------------------
>>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> >> For additional commands, e-mail: dev-help@spark.apache.org
>>> >>
>>> >
>>> >
>>> > --
>>> > em rnowling@gmail.com
>>> > c 954.496.2314
>>>
>>
>>
>
>
> --
> em rnowling@gmail.com
> c 954.496.2314
>

--e89a8f3ba329bc7c130504de8349--

From dev-return-9719-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 01:26:30 2014
Return-Path: <dev-return-9719-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0C2EA17B8D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 01:26:30 +0000 (UTC)
Received: (qmail 6880 invoked by uid 500); 8 Oct 2014 01:26:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6807 invoked by uid 500); 8 Oct 2014 01:26:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6795 invoked by uid 99); 8 Oct 2014 01:26:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 01:26:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.52 as permitted sender)
Received: from [74.125.82.52] (HELO mail-wg0-f52.google.com) (74.125.82.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 01:26:23 +0000
Received: by mail-wg0-f52.google.com with SMTP id a1so10545271wgh.23
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 18:26:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=L+9GIObUQe+SWBie7KVAJrfygOwE53LmAHxN4v/dao8=;
        b=RzHXJiEpA4runQ72ipC9vQbHVsjyZO2zL7N9jsL/rV3GbJVHA8LW7e2WP5vtbX97lS
         YOjqeGP6FSKqE8UMBN6HWPiKk5swoPME6MQmXsj2AYxWEnJjstZ2OPt4/tnce/c4gUib
         JRuKwolEF8GiFqz0iMwWKJRILJCLaB/YQMWZwEeuFdjPXLthBVZcZwu1xZzvyRSWrXW4
         FrlwLJFeikC2ufNQJkTu/ik0nZV9PBvJAGVLADMtcHapnkxqTxGuVhp4rMr3gcji5mGf
         sl7K+BXpIocQiFMhxWx3j9/mDKZime3h96vCJ6oDtmPHWXTMHoWElplv1fbe06b8LoLC
         a6YQ==
X-Received: by 10.181.13.132 with SMTP id ey4mr30465848wid.33.1412731562151;
 Tue, 07 Oct 2014 18:26:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Tue, 7 Oct 2014 18:25:22 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Tue, 7 Oct 2014 21:25:22 -0400
Message-ID: <CAOhmDzco++JC5fMP+XDyiLXvgtOHn+EiHVvMjZsUC4JDuP=5tA@mail.gmail.com>
Subject: Unneeded branches/tags
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d0438904fecd44c0504df32ac
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0438904fecd44c0504df32ac
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Just curious: Are there branches and/or tags on the repo that we don=E2=80=
=99t need
anymore?

What are the scala-2.9 and streaming branches for, for example? And do we
still need branches for older versions of Spark that we are not backporting
stuff to, like branch-0.5?

Nick
=E2=80=8B

--f46d0438904fecd44c0504df32ac--

From dev-return-9720-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 01:28:34 2014
Return-Path: <dev-return-9720-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 64B4317B98
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 01:28:34 +0000 (UTC)
Received: (qmail 10242 invoked by uid 500); 8 Oct 2014 01:28:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10177 invoked by uid 500); 8 Oct 2014 01:28:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10152 invoked by uid 99); 8 Oct 2014 01:28:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 01:28:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.171] (HELO mail-qc0-f171.google.com) (209.85.216.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 01:28:27 +0000
Received: by mail-qc0-f171.google.com with SMTP id i17so6859490qcy.30
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 18:28:05 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=RSlC28ugfnTCxyFtwGwu7gsnNlH+mRSRa/244qhM/mA=;
        b=gEIB8cxbzbeGDWWTDAkhcgUpRCwy3WCMMSLtniVm82IMikrd9JITFEwsivJLLVMFLp
         T1Y0/aNYGGVGf24Z86IK+WByj1Gv4SmuPIXvit3sO0dfgTqXl2y2JrTuA8jM23xHLv1p
         ky2T3YZoNfWJL/30JjccTdzxBFIA7ur7WpX/NFMgJSHZanMi6fW4GCL6HoMQQXGUYq9g
         XOcWgg69g/NwvWCFQo4P93set8bezBjeQLbi5l3dyNZO4fK208y4bGW56DuC2nzHLIMk
         8DmRfcPCDRtfBso7SNkY07kfNOezhuW+GQ7xXl7fMp1Pp1yc/wXXnHA1UqBp7tYY+mgQ
         1Cxg==
X-Gm-Message-State: ALoCoQldOxC+UK/DXQX9c+bDCWPtnjccTRNW2vTiAu6+4WaAsoizmjYpY8wh7U/7J7yZG8/Hcqp7
X-Received: by 10.224.22.143 with SMTP id n15mr8886150qab.53.1412731685741;
 Tue, 07 Oct 2014 18:28:05 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.47.8 with HTTP; Tue, 7 Oct 2014 18:27:45 -0700 (PDT)
In-Reply-To: <CAOhmDzco++JC5fMP+XDyiLXvgtOHn+EiHVvMjZsUC4JDuP=5tA@mail.gmail.com>
References: <CAOhmDzco++JC5fMP+XDyiLXvgtOHn+EiHVvMjZsUC4JDuP=5tA@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Tue, 7 Oct 2014 18:27:45 -0700
Message-ID: <CAPh_B=Yv+d7jD8ROdfTe3H5tG=9LvZ4s2RJYDFRsdh-Yp_Gpgw@mail.gmail.com>
Subject: Re: Unneeded branches/tags
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bf0d4aa4afd5f0504df3a1d
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bf0d4aa4afd5f0504df3a1d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Those branches are no longer active. However, I don't think we can delete
branches from github due to the way ASF mirroring works. I might be wrong
there.



On Tue, Oct 7, 2014 at 6:25 PM, Nicholas Chammas <nicholas.chammas@gmail.co=
m
> wrote:

> Just curious: Are there branches and/or tags on the repo that we don=E2=
=80=99t need
> anymore?
>
> What are the scala-2.9 and streaming branches for, for example? And do we
> still need branches for older versions of Spark that we are not backporti=
ng
> stuff to, like branch-0.5?
>
> Nick
> =E2=80=8B
>

--047d7bf0d4aa4afd5f0504df3a1d--

From dev-return-9721-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 05:52:41 2014
Return-Path: <dev-return-9721-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B37DD174B5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 05:52:41 +0000 (UTC)
Received: (qmail 85348 invoked by uid 500); 8 Oct 2014 05:52:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85275 invoked by uid 500); 8 Oct 2014 05:52:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 84837 invoked by uid 99); 8 Oct 2014 05:52:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 05:52:38 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.49 as permitted sender)
Received: from [209.85.218.49] (HELO mail-oi0-f49.google.com) (209.85.218.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 05:52:34 +0000
Received: by mail-oi0-f49.google.com with SMTP id a3so3564050oib.36
        for <dev@spark.apache.org>; Tue, 07 Oct 2014 22:52:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=PE1b5BVHDEHp9kdc48kkdn2jRU4fv+UJ7zYPKC/kzhk=;
        b=0YHW7/EuYgenkHn3LV5Wfle3eOOD4GV4DbwsgKGnQwgGo61Vgt9fooIwtX2VI7y3Bs
         LI5zf6qDA1hsOHThdnF+ZGxQNN2v/YXI9B5QLTW4QRWXlKR368u8Zm7SwAdyXr/S9ZC3
         OLDt1nzVgm5UM3jLcJ/xg9E0ePhqbGQ8LPkRbyhRIlqVJOxk+cWUs3gfysT4PU1HJy8s
         OA+GgXNvZgC0aU8o9FXYGedbYJ88+K1ganc01f2+eAeSlmBxZKY9G4DpYvDXqvbR1R8m
         2xjKuqHVFIAwvYpvztflAAlvx8/k1RZ6vY9k2dU34De73mV6dRa1N4KBthphhc9OlOqn
         XOnA==
MIME-Version: 1.0
X-Received: by 10.182.28.70 with SMTP id z6mr9516757obg.49.1412747533725; Tue,
 07 Oct 2014 22:52:13 -0700 (PDT)
Received: by 10.202.56.213 with HTTP; Tue, 7 Oct 2014 22:52:13 -0700 (PDT)
In-Reply-To: <CAPh_B=Yv+d7jD8ROdfTe3H5tG=9LvZ4s2RJYDFRsdh-Yp_Gpgw@mail.gmail.com>
References: <CAOhmDzco++JC5fMP+XDyiLXvgtOHn+EiHVvMjZsUC4JDuP=5tA@mail.gmail.com>
	<CAPh_B=Yv+d7jD8ROdfTe3H5tG=9LvZ4s2RJYDFRsdh-Yp_Gpgw@mail.gmail.com>
Date: Tue, 7 Oct 2014 22:52:13 -0700
Message-ID: <CABPQxsv8QLcLr6WDw6fVVnotMhSO+nG8cjw1f5SjnyJ24wBftA@mail.gmail.com>
Subject: Re: Unneeded branches/tags
From: Patrick Wendell <pwendell@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Actually - weirdly - we can delete old tags and it works with the
mirroring. Nick if you put together a list of un-needed tags I can
delete them.

On Tue, Oct 7, 2014 at 6:27 PM, Reynold Xin <rxin@databricks.com> wrote:
> Those branches are no longer active. However, I don't think we can delete
> branches from github due to the way ASF mirroring works. I might be wrong
> there.
>
>
>
> On Tue, Oct 7, 2014 at 6:25 PM, Nicholas Chammas <nicholas.chammas@gmail.com
>> wrote:
>
>> Just curious: Are there branches and/or tags on the repo that we don't need
>> anymore?
>>
>> What are the scala-2.9 and streaming branches for, for example? And do we
>> still need branches for older versions of Spark that we are not backporting
>> stuff to, like branch-0.5?
>>
>> Nick
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9722-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 06:05:36 2014
Return-Path: <dev-return-9722-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 79A8617502
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 06:05:36 +0000 (UTC)
Received: (qmail 10518 invoked by uid 500); 8 Oct 2014 06:05:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10412 invoked by uid 500); 8 Oct 2014 06:05:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9359 invoked by uid 99); 8 Oct 2014 06:05:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 06:05:32 +0000
X-ASF-Spam-Status: No, hits=2.5 required=5.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [203.81.22.165] (HELO mail1.qilinsoft.com) (203.81.22.165)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 06:05:06 +0000
X-MimeOLE: Produced By Microsoft Exchange V6.5
Content-class: urn:content-classes:message
MIME-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----_=_NextPart_001_01CFE2BE.34879C80"
Subject: RE: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
Date: Wed, 8 Oct 2014 14:04:55 +0800
Message-ID: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC76@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
In-Reply-To: <CAJmC80-Tk-paEsq94DUJubq2CRO7A7Y1Yia4frwfLkD3ug8nsg@mail.gmail.com>
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
Thread-Topic: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
Thread-Index: Ac/cmngdYz+7W3IyR5OTDBU4xjomvwGIvpoA
From: "Haopu Wang" <HWang@qilinsoft.com>
To: "Liquan Pei" <liquanpei@gmail.com>
Cc: <dev@spark.apache.org>,
	"user" <user@spark.apache.org>
X-Virus-Checked: Checked by ClamAV on apache.org

------_=_NextPart_001_01CFE2BE.34879C80
Content-Type: text/plain;
	charset="GB2312"
Content-Transfer-Encoding: quoted-printable

Liquan, yes, for full outer join, one hash table on both sides is more =
efficient.

=20

For the left/right outer join, it looks like one hash table should be =
enought.

=20

________________________________

From: Liquan Pei [mailto:liquanpei@gmail.com]=20
Sent: 2014=C4=EA9=D4=C230=C8=D5 18:34
To: Haopu Wang
Cc: dev@spark.apache.org; user
Subject: Re: Spark SQL question: why build hashtable for both sides in =
HashOuterJoin?

=20

Hi Haopu,

=20

How about full outer join? One hash table may not be efficient for this =
case.=20

=20

Liquan

=20

On Mon, Sep 29, 2014 at 11:47 PM, Haopu Wang <HWang@qilinsoft.com> =
wrote:

Hi, Liquan, thanks for the response.

=20

In your example, I think the hash table should be built on the "right" =
side, so Spark can iterate through the left side and find matches in the =
right side from the hash table efficiently. Please comment and suggest, =
thanks again!

=20

________________________________

From: Liquan Pei [mailto:liquanpei@gmail.com]=20
Sent: 2014=C4=EA9=D4=C230=C8=D5 12:31
To: Haopu Wang
Cc: dev@spark.apache.org; user
Subject: Re: Spark SQL question: why build hashtable for both sides in =
HashOuterJoin?

=20

Hi Haopu,

=20

My understanding is that the hashtable on both left and right side is =
used for including null values in result in an efficient manner. If hash =
table is only built on one side, let's say left side and we perform a =
left outer join, for each row in left side, a scan over the right side =
is needed to make sure that no matching tuples for that row on left =
side.=20

=20

Hope this helps!

Liquan

=20

On Mon, Sep 29, 2014 at 8:36 PM, Haopu Wang <HWang@qilinsoft.com> wrote:

I take a look at HashOuterJoin and it's building a Hashtable for both
sides.

This consumes quite a lot of memory when the partition is big. And it
doesn't reduce the iteration on streamed relation, right?

Thanks!

---------------------------------------------------------------------
To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
For additional commands, e-mail: user-help@spark.apache.org





=20

--=20
Liquan Pei=20
Department of Physics=20
University of Massachusetts Amherst=20





=20

--=20
Liquan Pei=20
Department of Physics=20
University of Massachusetts Amherst=20


------_=_NextPart_001_01CFE2BE.34879C80--

From dev-return-9723-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 06:19:26 2014
Return-Path: <dev-return-9723-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 945D917549
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 06:19:26 +0000 (UTC)
Received: (qmail 43605 invoked by uid 500); 8 Oct 2014 06:19:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43496 invoked by uid 500); 8 Oct 2014 06:19:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42555 invoked by uid 99); 8 Oct 2014 06:19:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 06:19:24 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jianshi.huang@gmail.com designates 209.85.217.174 as permitted sender)
Received: from [209.85.217.174] (HELO mail-lb0-f174.google.com) (209.85.217.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 06:18:58 +0000
Received: by mail-lb0-f174.google.com with SMTP id p9so7472868lbv.19
        for <multiple recipients>; Tue, 07 Oct 2014 23:18:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=kZPuubIQVJfO2BL0buYURR7tO4P919Oxme+ZbFH7N1s=;
        b=oZLmdm5vGyrFbVjXHVOQCdd89s+sxrH+CqWzYfE6JmwStQRMurtmrGmZSi36zGQWvI
         rp0eoH4AylbsFMWxCwJk4g6Pm/lJ5/tb9QmW3m+KK/3h/dCWfW4x8pcOkDJjtGs9Itb+
         /761rXP5UNnxqWq2em/BzWJOE0pnz+i6OW0D/Km2Gooejek6HRgsFgJ9VKEieBLgopfY
         qnY541jTGcochPTm6hFKOZcwlXBNh84VuS5qeOuEKyq7EwnyprSYHv29RvpZf72bnjUi
         98jjc0PUb43Niz6fxlrTedrcVs6N+HBTAvW+3krBKaFwf7/mKZxjU7fpG9ey0RWx6OUZ
         Y74w==
X-Received: by 10.152.204.231 with SMTP id lb7mr8920148lac.44.1412749137577;
 Tue, 07 Oct 2014 23:18:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.161.208 with HTTP; Tue, 7 Oct 2014 23:18:37 -0700 (PDT)
In-Reply-To: <CACA1tWKNwvPWw7=6SLdqZGyktOpVNTpOTVYJwrA_8HcqnJN_+Q@mail.gmail.com>
References: <CACA1tWKf1purfZMGWjjTraxFr-Ac8oOEKVfgef5DK-tNriyVbg@mail.gmail.com>
 <CALte62xka0O9+YyY26MBPPxC8U2DJuZY=wiLrXJAGKsvu+h3gA@mail.gmail.com> <CACA1tWKNwvPWw7=6SLdqZGyktOpVNTpOTVYJwrA_8HcqnJN_+Q@mail.gmail.com>
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Wed, 8 Oct 2014 14:18:37 +0800
Message-ID: <CACA1tWJvw10CGtrRzZ8R1+AhGit-+Zmm-Pi14E3MKfjc7H+NOg@mail.gmail.com>
Subject: Re: How to do broadcast join in SparkSQL
To: Ted Yu <yuzhihong@gmail.com>
Cc: user <user@spark.apache.org>, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a1134d304808c680504e34a3e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134d304808c680504e34a3e
Content-Type: text/plain; charset=UTF-8

Looks like https://issues.apache.org/jira/browse/SPARK-1800 is not merged
into master?

I cannot find spark.sql.hints.broadcastTables in latest master, but it's in
the following patch.


https://github.com/apache/spark/commit/76ca4341036b95f71763f631049fdae033990ab5


Jianshi


On Mon, Sep 29, 2014 at 1:24 AM, Jianshi Huang <jianshi.huang@gmail.com>
wrote:

> Yes, looks like it can only be controlled by the
> parameter spark.sql.autoBroadcastJoinThreshold, which is a little bit weird
> to me.
>
> How am I suppose to know the exact bytes of a table? Let me specify the
> join algorithm is preferred I think.
>
> Jianshi
>
> On Sun, Sep 28, 2014 at 11:57 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>
>> Have you looked at SPARK-1800 ?
>>
>> e.g. see sql/core/src/test/scala/org/apache/spark/sql/JoinSuite.scala
>> Cheers
>>
>> On Sun, Sep 28, 2014 at 1:55 AM, Jianshi Huang <jianshi.huang@gmail.com>
>> wrote:
>>
>>> I cannot find it in the documentation. And I have a dozen dimension
>>> tables to (left) join...
>>>
>>>
>>> Cheers,
>>> --
>>> Jianshi Huang
>>>
>>> LinkedIn: jianshi
>>> Twitter: @jshuang
>>> Github & Blog: http://huangjs.github.com/
>>>
>>
>>
>
>
> --
> Jianshi Huang
>
> LinkedIn: jianshi
> Twitter: @jshuang
> Github & Blog: http://huangjs.github.com/
>



-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--001a1134d304808c680504e34a3e--

From dev-return-9724-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 07:09:40 2014
Return-Path: <dev-return-9724-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9D25F176AA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 07:09:40 +0000 (UTC)
Received: (qmail 61786 invoked by uid 500); 8 Oct 2014 07:09:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61674 invoked by uid 500); 8 Oct 2014 07:09:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60685 invoked by uid 99); 8 Oct 2014 07:09:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 07:09:38 +0000
X-ASF-Spam-Status: No, hits=2.8 required=5.0
	tests=FREEMAIL_REPLY,HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.171 as permitted sender)
Received: from [209.85.192.171] (HELO mail-pd0-f171.google.com) (209.85.192.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 07:09:11 +0000
Received: by mail-pd0-f171.google.com with SMTP id ft15so6420963pdb.2
        for <multiple recipients>; Wed, 08 Oct 2014 00:09:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=6VNDPvWze9CKuAFwV6EZ3+dgWh/WeeuuYP8+Ih3MGZc=;
        b=0tFXu5UyRMVdm+tZpULDCRVIcC8GiIWInFlY9sbyMkXR4isAUbq+FLwwHRe6ABOgTH
         fTI2SuaOFE4GgKVpETR43fE475EV4V1tHKJdDmGssaVnx5E+8Z+25byfCotV9byXRxn4
         X1IfUqgabTJBrcMs92xz/jaQ7plccemBMN5eXMy60liqy7rpwAzImgALQKfWV+ZVFN4I
         uhjsVJYMjZsR6XEUUiPG7Rxi4LqANB1iO66rZR6I9cCpMLq5sbPY2YY1LtYx8twH6UVI
         DzRiNQkXuV/MjeshmbRxjMACuNbGZsoRBpfJEbURvWo1xeU5WmXRZ4CxmRYLaxFkP1nr
         sJ3g==
X-Received: by 10.68.164.35 with SMTP id yn3mr8482998pbb.104.1412752149076;
        Wed, 08 Oct 2014 00:09:09 -0700 (PDT)
Received: from [192.168.1.106] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id a1sm15558158pdc.68.2014.10.08.00.09.07
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Wed, 08 Oct 2014 00:09:08 -0700 (PDT)
Content-Type: multipart/alternative; boundary="Apple-Mail=_5AEED892-A611-4300-BD38-071EC544AC76"
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC76@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
Date: Wed, 8 Oct 2014 00:09:05 -0700
Cc: Liquan Pei <liquanpei@gmail.com>,
 dev@spark.apache.org,
 user <user@spark.apache.org>
Message-Id: <8F99364C-90BD-4949-BD28-40699FED9F35@gmail.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC76@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
To: Haopu Wang <HWang@qilinsoft.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_5AEED892-A611-4300-BD38-071EC544AC76
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=GB2312

I'm pretty sure inner joins on Spark SQL already build only one of the =
sides. Take a look at ShuffledHashJoin, which calls =
HashJoin.joinIterators. Only outer joins do both, and it seems like we =
could optimize it for those that are not full.

Matei


On Oct 7, 2014, at 11:04 PM, Haopu Wang <HWang@qilinsoft.com> wrote:

> Liquan, yes, for full outer join, one hash table on both sides is more =
efficient.
> =20
> For the left/right outer join, it looks like one hash table should be =
enought.
> =20
> From: Liquan Pei [mailto:liquanpei@gmail.com]=20
> Sent: 2014=C4=EA9=D4=C230=C8=D5 18:34
> To: Haopu Wang
> Cc: dev@spark.apache.org; user
> Subject: Re: Spark SQL question: why build hashtable for both sides in =
HashOuterJoin?
> =20
> Hi Haopu,
> =20
> How about full outer join? One hash table may not be efficient for =
this case.=20
> =20
> Liquan
> =20
> On Mon, Sep 29, 2014 at 11:47 PM, Haopu Wang <HWang@qilinsoft.com> =
wrote:
> Hi, Liquan, thanks for the response.
> =20
> In your example, I think the hash table should be built on the "right" =
side, so Spark can iterate through the left side and find matches in the =
right side from the hash table efficiently. Please comment and suggest, =
thanks again!
> =20
> From: Liquan Pei [mailto:liquanpei@gmail.com]=20
> Sent: 2014=C4=EA9=D4=C230=C8=D5 12:31
> To: Haopu Wang
> Cc: dev@spark.apache.org; user
> Subject: Re: Spark SQL question: why build hashtable for both sides in =
HashOuterJoin?
> =20
> Hi Haopu,
> =20
> My understanding is that the hashtable on both left and right side is =
used for including null values in result in an efficient manner. If hash =
table is only built on one side, let's say left side and we perform a =
left outer join, for each row in left side, a scan over the right side =
is needed to make sure that no matching tuples for that row on left =
side.=20
> =20
> Hope this helps!
> Liquan
> =20
> On Mon, Sep 29, 2014 at 8:36 PM, Haopu Wang <HWang@qilinsoft.com> =
wrote:
> I take a look at HashOuterJoin and it's building a Hashtable for both
> sides.
>=20
> This consumes quite a lot of memory when the partition is big. And it
> doesn't reduce the iteration on streamed relation, right?
>=20
> Thanks!
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>=20
>=20
>=20
> =20
> --=20
> Liquan Pei=20
> Department of Physics=20
> University of Massachusetts Amherst
>=20
>=20
> =20
> --=20
> Liquan Pei=20
> Department of Physics=20
> University of Massachusetts Amherst


--Apple-Mail=_5AEED892-A611-4300-BD38-071EC544AC76--

From dev-return-9725-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 07:12:45 2014
Return-Path: <dev-return-9725-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 80BC8176C6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 07:12:45 +0000 (UTC)
Received: (qmail 74911 invoked by uid 500); 8 Oct 2014 07:12:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74802 invoked by uid 500); 8 Oct 2014 07:12:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73950 invoked by uid 99); 8 Oct 2014 07:12:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 07:12:42 +0000
X-ASF-Spam-Status: No, hits=1.8 required=5.0
	tests=HTML_FONT_FACE_BAD,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of liquanpei@gmail.com designates 209.85.218.51 as permitted sender)
Received: from [209.85.218.51] (HELO mail-oi0-f51.google.com) (209.85.218.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 07:12:38 +0000
Received: by mail-oi0-f51.google.com with SMTP id h136so3846228oig.24
        for <multiple recipients>; Wed, 08 Oct 2014 00:12:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=7d+N6AxH2QjH3P+YTSBRXtmJsMzFpcnOeyJVTrM+5dE=;
        b=lJzE9jgfiKS7prSRqP7EV7RwtTg4ecccLbms/5ncai2sSj9XKpr65o66zY9uQhKE3f
         RloESvDUZ4f1fAIELkxC9Iegwra/o5Pii9RW/eMTkH8dRIO5/rzyAE6dd8Fdp8uYQ93d
         uTnnS3Pffst32c4/oLcceIgAE5rzVYztDWHY/ZKMcnP9PXDT2dRKyDP5gxmv/+5keeWt
         xdH0f27F/Km1LSQRv9yZ/xKO1MGJlnxPY0oMBawQU1aY6c/IkG92veYi7nfd88ZpbJ9n
         Afu1RWIbOshHhqEQAzjUIFGHV+ytPLzUPOMXTaa9ZI1z+FvEcSOu8owaTDIqNtM90y2v
         m5Kg==
MIME-Version: 1.0
X-Received: by 10.182.76.104 with SMTP id j8mr1005284obw.78.1412752337401;
 Wed, 08 Oct 2014 00:12:17 -0700 (PDT)
Received: by 10.76.128.75 with HTTP; Wed, 8 Oct 2014 00:12:17 -0700 (PDT)
In-Reply-To: <8F99364C-90BD-4949-BD28-40699FED9F35@gmail.com>
References: <2EB23AF5EEEA2140946B8F292EB2EB9F13AC76@QS-PEK-DC1.qilinsoftcorp.qilinsoft.com>
	<8F99364C-90BD-4949-BD28-40699FED9F35@gmail.com>
Date: Wed, 8 Oct 2014 00:12:17 -0700
Message-ID: <CAJmC80_HVGU4PP3-=FHoBDdcAigfLAy3KtgmX5vSj+uO3AeKMQ@mail.gmail.com>
Subject: Re: Spark SQL question: why build hashtable for both sides in HashOuterJoin?
From: Liquan Pei <liquanpei@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: Haopu Wang <HWang@qilinsoft.com>, dev@spark.apache.org, user <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b67737c39fcd70504e40987
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b67737c39fcd70504e40987
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I am working on a PR to leverage the HashJoin trait code to optimize the
Left/Right outer join. It's already been tested locally and will send out
the PR soon after some clean up.

Thanks,
Liquan

On Wed, Oct 8, 2014 at 12:09 AM, Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> I'm pretty sure inner joins on Spark SQL already build only one of the
> sides. Take a look at ShuffledHashJoin, which calls HashJoin.joinIterator=
s.
> Only outer joins do both, and it seems like we could optimize it for thos=
e
> that are not full.
>
> Matei
>
>
>
> On Oct 7, 2014, at 11:04 PM, Haopu Wang <HWang@qilinsoft.com> wrote:
>
> Liquan, yes, for full outer join, one hash table on both sides is more
> efficient.
>
> For the left/right outer join, it looks like one hash table should be
> enought.
>
> ------------------------------
> *From:* Liquan Pei [mailto:liquanpei@gmail.com <liquanpei@gmail.com>]
> *Sent:* 2014=E5=B9=B49=E6=9C=8830=E6=97=A5 18:34
> *To:* Haopu Wang
> *Cc:* dev@spark.apache.org; user
> *Subject:* Re: Spark SQL question: why build hashtable for both sides in
> HashOuterJoin?
>
> Hi Haopu,
>
> How about full outer join? One hash table may not be efficient for this
> case.
>
> Liquan
>
> On Mon, Sep 29, 2014 at 11:47 PM, Haopu Wang <HWang@qilinsoft.com> wrote:
> Hi, Liquan, thanks for the response.
>
> In your example, I think the hash table should be built on the "right"
> side, so Spark can iterate through the left side and find matches in the
> right side from the hash table efficiently. Please comment and suggest,
> thanks again!
>
> ------------------------------
> *From:* Liquan Pei [mailto:liquanpei@gmail.com]
> *Sent:* 2014=E5=B9=B49=E6=9C=8830=E6=97=A5 12:31
> *To:* Haopu Wang
> *Cc:* dev@spark.apache.org; user
> *Subject:* Re: Spark SQL question: why build hashtable for both sides in
> HashOuterJoin?
>
> Hi Haopu,
>
> My understanding is that the hashtable on both left and right side is use=
d
> for including null values in result in an efficient manner. If hash table
> is only built on one side, let's say left side and we perform a left oute=
r
> join, for each row in left side, a scan over the right side is needed to
> make sure that no matching tuples for that row on left side.
>
> Hope this helps!
> Liquan
>
> On Mon, Sep 29, 2014 at 8:36 PM, Haopu Wang <HWang@qilinsoft.com> wrote:
>
> I take a look at HashOuterJoin and it's building a Hashtable for both
> sides.
>
> This consumes quite a lot of memory when the partition is big. And it
> doesn't reduce the iteration on streamed relation, right?
>
> Thanks!
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
>
>
> --
> Liquan Pei
> Department of Physics
> University of Massachusetts Amherst
>
>
>
> --
> Liquan Pei
> Department of Physics
> University of Massachusetts Amherst
>
>
>


--=20
Liquan Pei
Department of Physics
University of Massachusetts Amherst

--047d7b67737c39fcd70504e40987--

From dev-return-9726-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 08:45:05 2014
Return-Path: <dev-return-9726-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6D8E6178DE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 08:45:05 +0000 (UTC)
Received: (qmail 5287 invoked by uid 500); 8 Oct 2014 08:45:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5177 invoked by uid 500); 8 Oct 2014 08:45:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4099 invoked by uid 99); 8 Oct 2014 08:45:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 08:45:02 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jianshi.huang@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 08:44:36 +0000
Received: by mail-la0-f51.google.com with SMTP id ge10so7987119lab.10
        for <multiple recipients>; Wed, 08 Oct 2014 01:44:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=lZFOaj22xmnaByexs0VF0q7Ea1R1CNuvp3FYdqwRYk4=;
        b=nPzolGp4qFtSwJqRQRQJIERSx3b+nm4CNNeOM3U4INnBT0S6BwL8NBfwaHTKoanIXN
         LdjLfvFUVU7QUwgas2bcVwFktWptnmehbBCmoV52XtNp2GfhxxkQTV6deSsbMDFV2HLF
         V16MwvrXuvM6HOkVuqbb7a4yueMaJOES6WOJ/f6Qh2X4tsjxAM24pU/1wGa1os+6F9pY
         45+zH4Ibb8bLhrW29Wj8otT6hwhAND2j59x73/4NqZtr9T5UTglFYWuhzGRu2/jp47O/
         dyr/zRnhV7z9YGsCGzPvm/g5Dh+QeGVnCsBk8N2kRCGVCyTjB4dNZH4mE4oH36OETg8V
         TEGw==
X-Received: by 10.152.204.231 with SMTP id lb7mr9735819lac.44.1412757875592;
 Wed, 08 Oct 2014 01:44:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.161.208 with HTTP; Wed, 8 Oct 2014 01:44:15 -0700 (PDT)
In-Reply-To: <CACA1tWJvw10CGtrRzZ8R1+AhGit-+Zmm-Pi14E3MKfjc7H+NOg@mail.gmail.com>
References: <CACA1tWKf1purfZMGWjjTraxFr-Ac8oOEKVfgef5DK-tNriyVbg@mail.gmail.com>
 <CALte62xka0O9+YyY26MBPPxC8U2DJuZY=wiLrXJAGKsvu+h3gA@mail.gmail.com>
 <CACA1tWKNwvPWw7=6SLdqZGyktOpVNTpOTVYJwrA_8HcqnJN_+Q@mail.gmail.com> <CACA1tWJvw10CGtrRzZ8R1+AhGit-+Zmm-Pi14E3MKfjc7H+NOg@mail.gmail.com>
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Wed, 8 Oct 2014 16:44:15 +0800
Message-ID: <CACA1tWJ5asqTnV3D1HmYP+U-T7bTODJMLhNBuFA=1-a5B9fDHA@mail.gmail.com>
Subject: Re: How to do broadcast join in SparkSQL
To: Ted Yu <yuzhihong@gmail.com>
Cc: user <user@spark.apache.org>, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a1134d3045414e70504e5537d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134d3045414e70504e5537d
Content-Type: text/plain; charset=UTF-8

Ok, currently there's cost-based optimization however Parquet statistics is
not implemented...

What's the good way if I want to join a big fact table with several tiny
dimension tables in Spark SQL (1.1)?

I wish we can allow user hint for the join.

Jianshi

On Wed, Oct 8, 2014 at 2:18 PM, Jianshi Huang <jianshi.huang@gmail.com>
wrote:

> Looks like https://issues.apache.org/jira/browse/SPARK-1800 is not merged
> into master?
>
> I cannot find spark.sql.hints.broadcastTables in latest master, but it's
> in the following patch.
>
>
> https://github.com/apache/spark/commit/76ca4341036b95f71763f631049fdae033990ab5
>
>
> Jianshi
>
>
> On Mon, Sep 29, 2014 at 1:24 AM, Jianshi Huang <jianshi.huang@gmail.com>
> wrote:
>
>> Yes, looks like it can only be controlled by the
>> parameter spark.sql.autoBroadcastJoinThreshold, which is a little bit weird
>> to me.
>>
>> How am I suppose to know the exact bytes of a table? Let me specify the
>> join algorithm is preferred I think.
>>
>> Jianshi
>>
>> On Sun, Sep 28, 2014 at 11:57 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>
>>> Have you looked at SPARK-1800 ?
>>>
>>> e.g. see sql/core/src/test/scala/org/apache/spark/sql/JoinSuite.scala
>>> Cheers
>>>
>>> On Sun, Sep 28, 2014 at 1:55 AM, Jianshi Huang <jianshi.huang@gmail.com>
>>> wrote:
>>>
>>>> I cannot find it in the documentation. And I have a dozen dimension
>>>> tables to (left) join...
>>>>
>>>>
>>>> Cheers,
>>>> --
>>>> Jianshi Huang
>>>>
>>>> LinkedIn: jianshi
>>>> Twitter: @jshuang
>>>> Github & Blog: http://huangjs.github.com/
>>>>
>>>
>>>
>>
>>
>> --
>> Jianshi Huang
>>
>> LinkedIn: jianshi
>> Twitter: @jshuang
>> Github & Blog: http://huangjs.github.com/
>>
>
>
>
> --
> Jianshi Huang
>
> LinkedIn: jianshi
> Twitter: @jshuang
> Github & Blog: http://huangjs.github.com/
>



-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--001a1134d3045414e70504e5537d--

From dev-return-9727-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 11:20:13 2014
Return-Path: <dev-return-9727-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CA378172AD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 11:20:13 +0000 (UTC)
Received: (qmail 12369 invoked by uid 500); 8 Oct 2014 11:20:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12293 invoked by uid 500); 8 Oct 2014 11:20:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12279 invoked by uid 99); 8 Oct 2014 11:20:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 11:20:12 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 11:20:08 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XbpHX-0005na-Tt
	for dev@spark.incubator.apache.org; Wed, 08 Oct 2014 04:19:47 -0700
Date: Wed, 8 Oct 2014 04:19:47 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1412767187902-8697.post@n3.nabble.com>
Subject: Standardized Distance Functions in MLlib
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all, 

In my limited understanding of the MLlib, it is a good idea to use the
various distance functions on some machine learning algorithms. For example,
we can only use Euclidean distance metric in KMeans. And I am tackling with
contributing hierarchical clustering to MLlib
(https://issues.apache.org/jira/browse/SPARK-2429). I would like to support
the various distance functions in it.

Should we support the standardized distance function in MLlib or not?
You know, Spark depends on Breeze. So I think we have two approaches in
order to use distance functions in MLlib. One is implementing some distance
functions in MLlib. The other is wrapping the functions of Breeze. And I am
a bit worried about using Breeze directly in Spark. For example,  we can't
absolutely control the release of Breeze. 

I sent a PR before. But it is stopping. I'd like to get your thoughts on it,
community.
https://github.com/apache/spark/pull/1964#issuecomment-54953348

Best,



-----
-- Yu Ishikawa
--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Standardized-Distance-Functions-in-MLlib-tp8697.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9728-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 14:22:34 2014
Return-Path: <dev-return-9728-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2220817877
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 14:22:34 +0000 (UTC)
Received: (qmail 11971 invoked by uid 500); 8 Oct 2014 14:22:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11904 invoked by uid 500); 8 Oct 2014 14:22:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11886 invoked by uid 99); 8 Oct 2014 14:22:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 14:22:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 14:22:07 +0000
Received: by mail-wg0-f50.google.com with SMTP id a1so11480458wgh.21
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 07:22:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=Ln7KT5zz7adhqOJiHiO9k6Fjs4YF+d0f3f4FRKde2sY=;
        b=EhETYGJwBnHpTk8wAL2e3ZfIZ+0jArc4bJ+rZqnno7xP+QUR3sTFzIGm+ZsE4n+2ct
         X/uKcn/z9CBDATbIxCELFa79drmlqjgWlHKZ2dp64zBh3apCANT0wHvNiLJ9o5POZg3r
         yJb7sdjd0gpu9EfjWLUudHumvp2yh5Xw9MMvsjt+nMKR5EP3GQWszuhp3f2eCnYmaXfo
         f6fKjFDfqWcPI+YFzDOje03Q2DW0x0IkqUoflkxJ4FXmmfjARXY5hfzphk/r9liWplMj
         L4o/yuxbP2ceTlOU5d2+auVwFlBvmE5VywsNV1UFfxTP0Ks4HWgAiu/Kko2O3SD2eEde
         uctw==
X-Received: by 10.180.90.71 with SMTP id bu7mr11243175wib.33.1412778126477;
 Wed, 08 Oct 2014 07:22:06 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Wed, 8 Oct 2014 07:21:26 -0700 (PDT)
In-Reply-To: <CABPQxsv8QLcLr6WDw6fVVnotMhSO+nG8cjw1f5SjnyJ24wBftA@mail.gmail.com>
References: <CAOhmDzco++JC5fMP+XDyiLXvgtOHn+EiHVvMjZsUC4JDuP=5tA@mail.gmail.com>
 <CAPh_B=Yv+d7jD8ROdfTe3H5tG=9LvZ4s2RJYDFRsdh-Yp_Gpgw@mail.gmail.com> <CABPQxsv8QLcLr6WDw6fVVnotMhSO+nG8cjw1f5SjnyJ24wBftA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 8 Oct 2014 10:21:26 -0400
Message-ID: <CAOhmDzeeLux46sRo3vLaxNc-uybuH1Sjr7mDZibUb7HVvpfvFQ@mail.gmail.com>
Subject: Re: Unneeded branches/tags
To: Patrick Wendell <pwendell@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043be0f4600ebf0504ea0a05
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043be0f4600ebf0504ea0a05
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

So:

   - tags: can delete
   - branches: stuck with =E2=80=98em

Correct?

Nick
=E2=80=8B

On Wed, Oct 8, 2014 at 1:52 AM, Patrick Wendell <pwendell@gmail.com> wrote:

> Actually - weirdly - we can delete old tags and it works with the
> mirroring. Nick if you put together a list of un-needed tags I can
> delete them.
>
> On Tue, Oct 7, 2014 at 6:27 PM, Reynold Xin <rxin@databricks.com> wrote:
> > Those branches are no longer active. However, I don't think we can dele=
te
> > branches from github due to the way ASF mirroring works. I might be wro=
ng
> > there.
> >
> >
> >
> > On Tue, Oct 7, 2014 at 6:25 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> >> wrote:
> >
> >> Just curious: Are there branches and/or tags on the repo that we don't
> need
> >> anymore?
> >>
> >> What are the scala-2.9 and streaming branches for, for example? And do
> we
> >> still need branches for older versions of Spark that we are not
> backporting
> >> stuff to, like branch-0.5?
> >>
> >> Nick
> >>
> >>
>

--f46d043be0f4600ebf0504ea0a05--

From dev-return-9729-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 14:54:48 2014
Return-Path: <dev-return-9729-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7AFBC17976
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 14:54:48 +0000 (UTC)
Received: (qmail 70590 invoked by uid 500); 8 Oct 2014 14:54:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70518 invoked by uid 500); 8 Oct 2014 14:54:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70506 invoked by uid 99); 8 Oct 2014 14:54:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 14:54:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rnowling@gmail.com designates 209.85.212.176 as permitted sender)
Received: from [209.85.212.176] (HELO mail-wi0-f176.google.com) (209.85.212.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 14:54:20 +0000
Received: by mail-wi0-f176.google.com with SMTP id hi2so10807829wib.3
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 07:54:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=soDfBLl0USA3a3wz+8a3eqCPXvGLSWCsXNdBsugKVtQ=;
        b=Ch2Wn2S06iAVHaGQXbMBb+hM8tIZmXPpJw4pfAC3a6Xjs1feNphksuyp8iBYG7haar
         in8xAIK4vcpf1rhfjxj6duqtLt1zD8zh69289EwmTJcsOQrzcxntLGFw+x5u5rGEJjDO
         d8nYjuMiYPutMQVb3t1ZTtYEEMT63xWm5en2EnJZnWM4ZUbv+b2dTFubbidIFtRnGVm6
         4d7lnkKBG2EhhJIbfFXHKAIfZeZp9Gpb6ldToBLV/Rw18ekdRGjxUWFiCY23FlfKqvfF
         luLOv2k38V9+ukW0nFbwqJrJB+LeyZ+vgbZFzNGly5uVGqqh98+BtIkDgJvctO4ZAGly
         hr1g==
MIME-Version: 1.0
X-Received: by 10.194.206.103 with SMTP id ln7mr12273339wjc.30.1412780059760;
 Wed, 08 Oct 2014 07:54:19 -0700 (PDT)
Received: by 10.194.57.80 with HTTP; Wed, 8 Oct 2014 07:54:19 -0700 (PDT)
In-Reply-To: <CAAHrQ0=_XLNuGs+E_SB4eGs54xU=M70-uD+vd5NzZ=3-c-KGyA@mail.gmail.com>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
	<54323A64.2090205@uninett.no>
	<CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
	<CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
	<543249BB.505@uninett.no>
	<CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
	<CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com>
	<CAAHrQ0kc4V-B357hMX2OEDsauxnpniTDPbf9ycx+9oh6qVKXiw@mail.gmail.com>
	<CADtDQQJzkWAW-AZ2zQEYqXy02QnpZ-rHTuf9fYZc5MS3SAgv4w@mail.gmail.com>
	<CAAHrQ0=_XLNuGs+E_SB4eGs54xU=M70-uD+vd5NzZ=3-c-KGyA@mail.gmail.com>
Date: Wed, 8 Oct 2014 10:54:19 -0400
Message-ID: <CADtDQQJc97mU+P4WV3WwRPi5SohRmn=u5ZdSqJrfLjFgkM1KaA@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
From: RJ Nowling <rnowling@gmail.com>
To: Fairiz Azizi <coderfi@gmail.com>
Cc: Timothy Chen <tnachen@gmail.com>, Gurvinder Singh <gurvinder.singh@uninett.no>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bb708e09ba01e0504ea7d25
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bb708e09ba01e0504ea7d25
Content-Type: text/plain; charset=UTF-8

Yep!  That's the example I was talking about.

Is an error message printed when it hangs? I get :

14/09/30 13:23:14 ERROR BlockManagerMasterActor: Got two different
block manager registrations on 20140930-131734-1723727882-5050-1895-1



On Tue, Oct 7, 2014 at 8:36 PM, Fairiz Azizi <coderfi@gmail.com> wrote:

> Sure, could you point me to the example?
>
> The only thing I could find was
>
> https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala
>
> So do you mean running it like:
>    MASTER="mesos://xxxxxxx*:5050*" ./run-example LogQuery
>
> I tried that and I can see the job run and the tasks complete on the slave
> nodes, but the client process seems to hang forever, it's probably a
> different problem. BTW, only a dozen or so tasks kick off.
>
> I actually haven't done much with Scala and Spark (it's been all python).
>
> Fi
>
>
>
> Fairiz "Fi" Azizi
>
> On Tue, Oct 7, 2014 at 6:29 AM, RJ Nowling <rnowling@gmail.com> wrote:
>
>> I was able to reproduce it on a small 4 node cluster (1 mesos master and
>> 3 mesos slaves) with relatively low-end specs.  As I said, I just ran the
>> log query examples with the fine-grained mesos mode.
>>
>> Spark 1.1.0 and mesos 0.20.1.
>>
>> Fairiz, could you try running the logquery example included with Spark
>> and see what you get?
>>
>> Thanks!
>>
>> On Mon, Oct 6, 2014 at 8:07 PM, Fairiz Azizi <coderfi@gmail.com> wrote:
>>
>>> That's what great about Spark, the community is so active! :)
>>>
>>> I compiled Mesos 0.20.1 from the source tarball.
>>>
>>> Using the Mapr3 Spark 1.1.0 distribution from the Spark downloads page
>>>  (spark-1.1.0-bin-mapr3.tgz).
>>>
>>> I see no problems for the workloads we are trying.
>>>
>>> However, the cluster is small (less than 100 cores across 3 nodes).
>>>
>>> The workloads reads in just a few gigabytes from HDFS, via an ipython
>>> notebook spark shell.
>>>
>>> thanks,
>>> Fi
>>>
>>>
>>>
>>> Fairiz "Fi" Azizi
>>>
>>> On Mon, Oct 6, 2014 at 9:20 AM, Timothy Chen <tnachen@gmail.com> wrote:
>>>
>>>> Ok I created SPARK-3817 to track this, will try to repro it as well.
>>>>
>>>> Tim
>>>>
>>>> On Mon, Oct 6, 2014 at 6:08 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>>> > I've recently run into this issue as well. I get it from running Spark
>>>> > examples such as log query.  Maybe that'll help reproduce the issue.
>>>> >
>>>> >
>>>> > On Monday, October 6, 2014, Gurvinder Singh <
>>>> gurvinder.singh@uninett.no>
>>>> > wrote:
>>>> >>
>>>> >> The issue does not occur if the task at hand has small number of map
>>>> >> tasks. I have a task which has 978 map tasks and I see this error as
>>>> >>
>>>> >> 14/10/06 09:34:40 ERROR BlockManagerMasterActor: Got two different
>>>> block
>>>> >> manager registrations on 20140711-081617-711206558-5050-2543-5
>>>> >>
>>>> >> Here is the log from the mesos-slave where this container was
>>>> running.
>>>> >>
>>>> >> http://pastebin.com/Q1Cuzm6Q
>>>> >>
>>>> >> If you look for the code from where error produced by spark, you will
>>>> >> see that it simply exit and saying in comments "this should never
>>>> >> happen, lets just quit" :-)
>>>> >>
>>>> >> - Gurvinder
>>>> >> On 10/06/2014 09:30 AM, Timothy Chen wrote:
>>>> >> > (Hit enter too soon...)
>>>> >> >
>>>> >> > What is your setup and steps to repro this?
>>>> >> >
>>>> >> > Tim
>>>> >> >
>>>> >> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com>
>>>> wrote:
>>>> >> >> Hi Gurvinder,
>>>> >> >>
>>>> >> >> I tried fine grain mode before and didn't get into that problem.
>>>> >> >>
>>>> >> >>
>>>> >> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
>>>> >> >> <gurvinder.singh@uninett.no> wrote:
>>>> >> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>>>> >> >>>> The Spark online docs indicate that Spark is compatible with
>>>> Mesos
>>>> >> >>>> 0.18.1
>>>> >> >>>>
>>>> >> >>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
>>>> >> >>>>
>>>> >> >>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos
>>>> >> >>>> v0.20.0?
>>>> >> >>>>
>>>> >> >>>> -Fi
>>>> >> >>>>
>>>> >> >>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in
>>>> >> >>> coarse
>>>> >> >>> mode, in fine grain mode there is an issue with blockmanager
>>>> names
>>>> >> >>> conflict. I have been waiting for it to be fixed but it is still
>>>> >> >>> there.
>>>> >> >>>
>>>> >> >>> -Gurvinder
>>>> >> >>>
>>>> >> >>>
>>>> ---------------------------------------------------------------------
>>>> >> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> >> >>> For additional commands, e-mail: dev-help@spark.apache.org
>>>> >> >>>
>>>> >>
>>>> >>
>>>> >> ---------------------------------------------------------------------
>>>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> >> For additional commands, e-mail: dev-help@spark.apache.org
>>>> >>
>>>> >
>>>> >
>>>> > --
>>>> > em rnowling@gmail.com
>>>> > c 954.496.2314
>>>>
>>>
>>>
>>
>>
>> --
>> em rnowling@gmail.com
>> c 954.496.2314
>>
>
>


-- 
em rnowling@gmail.com
c 954.496.2314

--047d7bb708e09ba01e0504ea7d25--

From dev-return-9730-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 15:50:18 2014
Return-Path: <dev-return-9730-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5E92317B6E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 15:50:18 +0000 (UTC)
Received: (qmail 86937 invoked by uid 500); 8 Oct 2014 15:50:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86866 invoked by uid 500); 8 Oct 2014 15:50:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86848 invoked by uid 99); 8 Oct 2014 15:50:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 15:50:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 15:49:48 +0000
Received: by mail-wg0-f50.google.com with SMTP id a1so11734080wgh.33
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 08:49:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=YEsgtu6XZIf173kkcCxAXIJi93MunZxVArtQ7uq9yPo=;
        b=bMHhkqcD7F7UXo4h/gw5JWWVH9gvGvqZB8gyLQ4uX49GAyYXf8QhSIEB7n4i4oruSU
         0y65Sv/Yqir0Nt+6wpBXmeoK5SRZ0ukEUlja2UZ8Wq6iQR0xVHFIu8JjCnnqck45OeJq
         GJ+1BKXJ9is4KqB2LMA5tfV9b81Q9eD/z90lBsaquajuwTC9F7YRnGUqlHipiP2t0DpL
         6ARKseufOLtm9WokZI9nhFJ6e9dhnyf2cZyZF0pXdheJ8YncYDng8GYJ1ksn0kBvOn3G
         sLn3NTIl41MA7633KtDX9edXlD1zS/nDYPMdW5yZgpzMOYZOK4BfcJQBdHUqQZztIeXi
         X84Q==
X-Received: by 10.194.209.207 with SMTP id mo15mr12272251wjc.6.1412783388294;
 Wed, 08 Oct 2014 08:49:48 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Wed, 8 Oct 2014 08:49:08 -0700 (PDT)
In-Reply-To: <CAOhmDzfWXfdFn9DNKJvsh2psXhQ1NCH9i=tfTML0m5HO1CLNyA@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
 <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
 <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
 <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com>
 <CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com>
 <CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com>
 <542CCF41.8000105@gmail.com> <CAOhmDzfWXfdFn9DNKJvsh2psXhQ1NCH9i=tfTML0m5HO1CLNyA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 8 Oct 2014 11:49:08 -0400
Message-ID: <CAOhmDzcrLkKeRSmSo7Huk-No4dt=AjRhMKdjUcrhrfnsugSacw@mail.gmail.com>
Subject: Re: Extending Scala style checks
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Michael Armbrust <michael@databricks.com>, Patrick Wendell <pwendell@gmail.com>, 
	Ted Yu <yuzhihong@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a83140106450504eb448a
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a83140106450504eb448a
Content-Type: text/plain; charset=UTF-8

I've created SPARK-3849: Automate remaining Scala style rules
<https://issues.apache.org/jira/browse/SPARK-3849>.

Please create sub-tasks on this issue for rules that we have not automated
and let's work through them as possible.

I went ahead and created the first sub-task, SPARK-3850: Scala style:
Disallow trailing spaces <https://issues.apache.org/jira/browse/SPARK-3850>.

Nick

On Tue, Oct 7, 2014 at 4:45 PM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> For starters, do we have a list of all the Scala style rules that are
> currently not enforced automatically but are likely well-suited for
> automation?
>
> Let's put such a list together in a JIRA issue and work through
> implementing them.
>
> Nick
>
> On Thu, Oct 2, 2014 at 12:06 AM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
>
>> Since we can easily catch the list of all changed files in a PR, I think
>> we can start with adding the no trailing space check for newly changed
>> files only?
>>
>>
>> On 10/2/14 9:24 AM, Nicholas Chammas wrote:
>>
>>> Yeah, I remember that hell when I added PEP 8 to the build checks and
>>> fixed
>>> all the outstanding Python style issues. I had to keep rebasing and
>>> resolving merge conflicts until the PR was merged.
>>>
>>> It's a rough process, but thankfully it's also a one-time process. I
>>> might
>>> be able to help with that in the next week or two if no-one else wants to
>>> pick it up.
>>>
>>> Nick
>>>
>>> On Wed, Oct 1, 2014 at 9:20 PM, Michael Armbrust <michael@databricks.com
>>> >
>>> wrote:
>>>
>>>  The hard part here is updating the existing code base... which is going
>>>> to
>>>> create merge conflicts with like all of the open PRs...
>>>>
>>>> On Wed, Oct 1, 2014 at 6:13 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>  Ah, since there appears to be a built-in rule for end-of-line
>>>>> whitespace,
>>>>> Michael and Cheng, y'all should be able to add this in pretty easily.
>>>>>
>>>>> Nick
>>>>>
>>>>> On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com>
>>>>> wrote:
>>>>>
>>>>>  Hey Nick,
>>>>>>
>>>>>> We can always take built-in rules. Back when we added this Prashant
>>>>>> Sharma actually did some great work that lets us write our own style
>>>>>> rules in cases where rules don't exist.
>>>>>>
>>>>>> You can see some existing rules here:
>>>>>>
>>>>>>
>>>>>>  https://github.com/apache/spark/tree/master/project/
>>>>> spark-style/src/main/scala/org/apache/spark/scalastyle
>>>>>
>>>>>> Prashant has over time contributed a lot of our custom rules upstream
>>>>>> to stalastyle, so now there are only a couple there.
>>>>>>
>>>>>> - Patrick
>>>>>>
>>>>>> On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>>>>
>>>>>>> Please take a look at WhitespaceEndOfLineChecker under:
>>>>>>> http://www.scalastyle.org/rules-0.1.0.html
>>>>>>>
>>>>>>> Cheers
>>>>>>>
>>>>>>> On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
>>>>>>>
>>>>>> nicholas.chammas@gmail.com
>>>>>>
>>>>>>> wrote:
>>>>>>>> As discussed here <https://github.com/apache/spark/pull/2619>, it
>>>>>>>>
>>>>>>> would be
>>>>>>
>>>>>>> good to extend our Scala style checks to programmatically enforce as
>>>>>>>>
>>>>>>> many
>>>>>>
>>>>>>> of our style rules as possible.
>>>>>>>>
>>>>>>>> Does anyone know if it's relatively straightforward to enforce
>>>>>>>>
>>>>>>> additional
>>>>>>
>>>>>>> rules like the "no trailing spaces" rule mentioned in the linked PR?
>>>>>>>>
>>>>>>>> Nick
>>>>>>>>
>>>>>>>>
>>>>
>>
>

--047d7b3a83140106450504eb448a--

From dev-return-9731-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 17:03:39 2014
Return-Path: <dev-return-9731-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id ECDCF17EDA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 17:03:39 +0000 (UTC)
Received: (qmail 48250 invoked by uid 500); 8 Oct 2014 17:03:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48176 invoked by uid 500); 8 Oct 2014 17:03:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48160 invoked by uid 99); 8 Oct 2014 17:03:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 17:03:38 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jym2307@gmail.com designates 209.85.215.52 as permitted sender)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 17:03:33 +0000
Received: by mail-la0-f52.google.com with SMTP id hz20so8811567lab.39
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 10:03:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=MVY8/dU0srQbrsG9k6YWvRqdy3Xw8EKthGly2hpuRFc=;
        b=zr8gOln1Kgxxv6jOXDFDV3A80gtxTTU6Y3lbV9PVimw4X05/G/zxmjhRW1TJiQpFQX
         id5d1ReU0BkgBZXri6nlORRulwSuUsS0GOHRAutFY83wY9HHC5PkRWzNptmjCkNaqUMA
         BOXLFfIpn38DrffhOCc12GzuY/TTX8oDidjXNNMKWp0gTzBXOY4ZbwJVonGUtBOSUL4g
         gJgBpr/18A0IR/oBOZkh30da9r+0rfDQ6biP+sP9quqpbc+/RascwZBWfCw6tMy9d+SA
         3/s5uuTmpuTShSh4Jdx/iUQoQ0FFfkImQpokh0V0ChctVJLbXRn/Rt9MYHWKS5gTS5Bh
         GOFA==
MIME-Version: 1.0
X-Received: by 10.152.28.167 with SMTP id c7mr12711326lah.27.1412787791718;
 Wed, 08 Oct 2014 10:03:11 -0700 (PDT)
Received: by 10.112.3.99 with HTTP; Wed, 8 Oct 2014 10:03:11 -0700 (PDT)
Date: Wed, 8 Oct 2014 10:03:11 -0700
Message-ID: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>
Subject: will/when Spark/SparkSQL will support ORCFile format
From: James Yu <jym2307@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e0160b61677f0000504ec4a1d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160b61677f0000504ec4a1d
Content-Type: text/plain; charset=ISO-8859-1

Didn't see anyone asked the question before, but I was wondering if anyone
knows if Spark/SparkSQL will support ORCFile format soon? ORCFile is
getting more and more popular hi Hive world.

Thanks,
James

--089e0160b61677f0000504ec4a1d--

From dev-return-9732-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 18:02:14 2014
Return-Path: <dev-return-9732-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AA8261735D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 18:02:14 +0000 (UTC)
Received: (qmail 1289 invoked by uid 500); 8 Oct 2014 18:02:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1219 invoked by uid 500); 8 Oct 2014 18:02:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1207 invoked by uid 99); 8 Oct 2014 18:02:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 18:02:13 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of velvia.github@gmail.com designates 209.85.217.179 as permitted sender)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 18:01:46 +0000
Received: by mail-lb0-f179.google.com with SMTP id l4so8673399lbv.10
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 11:01:46 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=0aq7Qj50f4p59O/kpgKk0k4sBxUXaVFD5831NM7Nf2M=;
        b=SlrKDZkn43pqzWEDD32rWS91/UWNMkqQzS3WZHI6aAz04tlJScfs8bXTuWGUqRzJ8x
         x5cSYcBEiRZPF0mO8W/9Z05woOTJk+o7jPzz+DUD5SLFl16VvX3xD/PbGhLJ39ZlKo4Y
         vHyANA9qhtuf89dIlORVEOZMwbBA1vE9W6Fcb7hsLwidySNZn9Yu5mhluOSKazJdqcIm
         xoi9HZoDofV2LYAfRi+fGU00Has0gyR5A1q0THSNSKSxVHXJPjVUJJce74KvWxU8zgnK
         5u38OSbuYM+yHzVuiy9FzIL6PbFBjlNUVe30rt9mPFGyBabzLO2cmlJpl9qIXFUnnCsX
         q4Vw==
MIME-Version: 1.0
X-Received: by 10.112.77.5 with SMTP id o5mr12656201lbw.71.1412791306152; Wed,
 08 Oct 2014 11:01:46 -0700 (PDT)
Received: by 10.152.122.17 with HTTP; Wed, 8 Oct 2014 11:01:46 -0700 (PDT)
In-Reply-To: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>
References: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>
Date: Wed, 8 Oct 2014 11:01:46 -0700
Message-ID: <CAN6Vra3oCudcLmVq15zGeKi+ESC11P3V9ENDrEGFhbvAgiNRDQ@mail.gmail.com>
Subject: Re: will/when Spark/SparkSQL will support ORCFile format
From: Evan Chan <velvia.github@gmail.com>
To: James Yu <jym2307@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

James,

Michael at the meetup last night said there was some development
activity around ORCFiles.

I'm curious though, what are the pros and cons of ORCFiles vs Parquet?

On Wed, Oct 8, 2014 at 10:03 AM, James Yu <jym2307@gmail.com> wrote:
> Didn't see anyone asked the question before, but I was wondering if anyone
> knows if Spark/SparkSQL will support ORCFile format soon? ORCFile is
> getting more and more popular hi Hive world.
>
> Thanks,
> James

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9733-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 18:12:41 2014
Return-Path: <dev-return-9733-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 79B13173E8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 18:12:41 +0000 (UTC)
Received: (qmail 40614 invoked by uid 500); 8 Oct 2014 18:12:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40546 invoked by uid 500); 8 Oct 2014 18:12:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40535 invoked by uid 99); 8 Oct 2014 18:12:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 18:12:40 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mark@clearstorydata.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 18:12:14 +0000
Received: by mail-ig0-f177.google.com with SMTP id a13so9709931igq.4
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 11:12:12 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=yyNMAaPtVOiZqWmXXFVheSd0CNk1XJQsG7gHgTQKFKo=;
        b=S28QJLZkCiP1SdAEEwh6wHU+tKgfc4CmqIgV6ZlqFwYl4Jzp9JybKwOvNikVZKVvDV
         o87YNcLvnwBldW/KI4bZu0ncEX4sIS5ftvziCPIprhbUXWxP2LMJxYno+Yc5S3aqHKhk
         tDy00M5j1C5E+Q3WE4xn4G5VHUZuxWWU6/ufrDXo0JIyAS756xDykTfDKTsWFKUZkKGk
         AEr1BS3O5ZWi8MNRQ26BGFgODKEXMCE0eegK/qg+6z0Y4y67D5BE0zq10fKL9h1XALKt
         LOBso8PRyPJVE9EoDwUd7bfHgcUE9oVS/l304+rUYy1pvlcI1atrv8FZ3JnpFy5txkKE
         TlcA==
X-Gm-Message-State: ALoCoQmBmqC9yP5fOxqBwp2vnHYBU8/5zWPwQasZ/XD7rHOmbAVrrZ3mfdKrESc3gkdrZshXAUdx
MIME-Version: 1.0
X-Received: by 10.43.54.5 with SMTP id vs5mr15564464icb.84.1412791932202; Wed,
 08 Oct 2014 11:12:12 -0700 (PDT)
Received: by 10.107.45.133 with HTTP; Wed, 8 Oct 2014 11:12:12 -0700 (PDT)
In-Reply-To: <CAN6Vra3oCudcLmVq15zGeKi+ESC11P3V9ENDrEGFhbvAgiNRDQ@mail.gmail.com>
References: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>
	<CAN6Vra3oCudcLmVq15zGeKi+ESC11P3V9ENDrEGFhbvAgiNRDQ@mail.gmail.com>
Date: Wed, 8 Oct 2014 11:12:12 -0700
Message-ID: <CAAsvFPnQ68hkk-=zRySdGci+xhqsiE1Dact_p8PxP+nW3Do18w@mail.gmail.com>
Subject: Re: will/when Spark/SparkSQL will support ORCFile format
From: Mark Hamstra <mark@clearstorydata.com>
To: Evan Chan <velvia.github@gmail.com>
Cc: James Yu <jym2307@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec51b1b5742c57c0504ed4183
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec51b1b5742c57c0504ed4183
Content-Type: text/plain; charset=UTF-8

https://github.com/apache/spark/pull/2576



On Wed, Oct 8, 2014 at 11:01 AM, Evan Chan <velvia.github@gmail.com> wrote:

> James,
>
> Michael at the meetup last night said there was some development
> activity around ORCFiles.
>
> I'm curious though, what are the pros and cons of ORCFiles vs Parquet?
>
> On Wed, Oct 8, 2014 at 10:03 AM, James Yu <jym2307@gmail.com> wrote:
> > Didn't see anyone asked the question before, but I was wondering if
> anyone
> > knows if Spark/SparkSQL will support ORCFile format soon? ORCFile is
> > getting more and more popular hi Hive world.
> >
> > Thanks,
> > James
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--bcaec51b1b5742c57c0504ed4183--

From dev-return-9734-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 18:15:32 2014
Return-Path: <dev-return-9734-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6952417471
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 18:15:32 +0000 (UTC)
Received: (qmail 53361 invoked by uid 500); 8 Oct 2014 18:15:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53286 invoked by uid 500); 8 Oct 2014 18:15:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53274 invoked by uid 99); 8 Oct 2014 18:15:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 18:15:29 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mengxr@gmail.com designates 209.85.213.175 as permitted sender)
Received: from [209.85.213.175] (HELO mail-ig0-f175.google.com) (209.85.213.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 18:15:04 +0000
Received: by mail-ig0-f175.google.com with SMTP id uq10so8351959igb.8
        for <dev@spark.incubator.apache.org>; Wed, 08 Oct 2014 11:15:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=eVsrgrBBuaP9tF/gXnLIStpGdNp7Ff7ZgfapU3ni+QM=;
        b=cHe6vF55e/+SpMIarwIdRHX1PQgE9xfxxk57thXZkcobQ/fl/CxRGKhYNiiJbHUI+4
         Cb0+MjQAwCCoVhHby2Lcawbwz0JsssRJSd4mYYd4KKZdWyPPCBPRHEk5ouZ1Dhl/T3q7
         pBztq6GBmz3ASgnVsePVmd6HA1rmVrVknSB6QrfO0IeLxpHyCktCMVlXqxdu23rfNhEb
         UZ7znm0A2D3xCsJsR2+2H6nmi4cCGwGrhde4AZ/eLv7dNQzv4UcRJW7jGhnK0IqMkcQd
         sMLuESizYNcLaAj3dN2fywRdEcdRNtplSeW7UhIB8QFslUS5SJrB4bDA4t1SlPehCRxA
         b22w==
MIME-Version: 1.0
X-Received: by 10.50.61.99 with SMTP id o3mr18811696igr.30.1412792102398; Wed,
 08 Oct 2014 11:15:02 -0700 (PDT)
Received: by 10.107.34.3 with HTTP; Wed, 8 Oct 2014 11:15:02 -0700 (PDT)
In-Reply-To: <1412767187902-8697.post@n3.nabble.com>
References: <1412767187902-8697.post@n3.nabble.com>
Date: Wed, 8 Oct 2014 11:15:02 -0700
Message-ID: <CAJgQjQ-sQB9tj_cXqHnTQq99CHtpa7_ad82s1R2oz3JdU5JMyA@mail.gmail.com>
Subject: Re: Standardized Distance Functions in MLlib
From: Xiangrui Meng <mengxr@gmail.com>
To: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
Cc: dev <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Yu,

We upgraded breeze to 0.10 yesterday. So we can call the distance
functions you contributed to breeze easily. We don't want to maintain
another copy of the implementation in MLlib to keep the maintenance
cost low. Both spark and breeze are open-source projects. We should
try our best to avoid duplicate effort and forking, even though we
don't have control the release of breeze.

As we discussed in the PR, if we want users to call them directly,
they should live in breeze. If we want users to specify them in
clustering algorithms, we should hide the implementation from users.
So simple wrappers over the breeze implementation should be
sufficient. We are reviewing

https://github.com/apache/spark/pull/2634

and try to see how we can embed distance measures there. In the
k-means implementation, we don't use (Vector, Vector) => Double.
Instead, we cache the norms and use inner product to derive the
distance, which is faster and takes advantage of sparsity. It would be
really nice if you can help review it and discuss how to embed
distance measures there. Thanks!

Best,
Xiangrui

On Wed, Oct 8, 2014 at 4:19 AM, Yu Ishikawa
<yuu.ishikawa+spark@gmail.com> wrote:
> Hi all,
>
> In my limited understanding of the MLlib, it is a good idea to use the
> various distance functions on some machine learning algorithms. For example,
> we can only use Euclidean distance metric in KMeans. And I am tackling with
> contributing hierarchical clustering to MLlib
> (https://issues.apache.org/jira/browse/SPARK-2429). I would like to support
> the various distance functions in it.
>
> Should we support the standardized distance function in MLlib or not?
> You know, Spark depends on Breeze. So I think we have two approaches in
> order to use distance functions in MLlib. One is implementing some distance
> functions in MLlib. The other is wrapping the functions of Breeze. And I am
> a bit worried about using Breeze directly in Spark. For example,  we can't
> absolutely control the release of Breeze.
>
> I sent a PR before. But it is stopping. I'd like to get your thoughts on it,
> community.
> https://github.com/apache/spark/pull/1964#issuecomment-54953348
>
> Best,
>
>
>
> -----
> -- Yu Ishikawa
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Standardized-Distance-Functions-in-MLlib-tp8697.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9735-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 19:11:36 2014
Return-Path: <dev-return-9735-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BAE2217759
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 19:11:36 +0000 (UTC)
Received: (qmail 37962 invoked by uid 500); 8 Oct 2014 19:11:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37902 invoked by uid 500); 8 Oct 2014 19:11:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36851 invoked by uid 99); 8 Oct 2014 19:11:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 19:11:33 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 19:11:07 +0000
Received: by mail-lb0-f172.google.com with SMTP id b6so8822137lbj.31
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 12:11:05 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=hhPdnCYhpe6tnEoHgewMLOZE+PCOBU+caKHDElJHcDc=;
        b=UGF6pYc3rwQLL0U/vR4jvVde9ZoQ6/rSaL7QX97CietrKoIU7pQX1+GZiuEpLbgfd3
         TebwmyPEBPuEVF2svEDksUMQ6rzF8uE72mN0cm5pw6tjyMm6QH6psrDkjXFPs3qyv3yO
         Z27CPy+GgqPVr/gtR/Kt5G0zPjyflVQ4I/Y3qptw32Ghs5f6M6WMDljY/1X+CoAsnhJN
         DYYBvcr2qNqEBAbRoo2T6NpaKV4UrIYkP0oSe+oBVDeGEBaXo3Z4nkhTubbo7Eoj3/Fq
         2ig4ClyAdLd5I4l/apSDcUZ65CtS8AtlwpOVp0bfCTH3ubyQPg1f5d3ZKN3MA1UU7Pgv
         4Afw==
X-Gm-Message-State: ALoCoQmjQpb1yCJ6K+Ky7xSdJ4qfILe51emnYUpKNrF72EG2zVxoRiGc+sBkzuj3mC0kEziGnge2
X-Received: by 10.152.6.228 with SMTP id e4mr14019384laa.12.1412795465535;
 Wed, 08 Oct 2014 12:11:05 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.17 with HTTP; Wed, 8 Oct 2014 12:10:45 -0700 (PDT)
In-Reply-To: <CACA1tWJ5asqTnV3D1HmYP+U-T7bTODJMLhNBuFA=1-a5B9fDHA@mail.gmail.com>
References: <CACA1tWKf1purfZMGWjjTraxFr-Ac8oOEKVfgef5DK-tNriyVbg@mail.gmail.com>
 <CALte62xka0O9+YyY26MBPPxC8U2DJuZY=wiLrXJAGKsvu+h3gA@mail.gmail.com>
 <CACA1tWKNwvPWw7=6SLdqZGyktOpVNTpOTVYJwrA_8HcqnJN_+Q@mail.gmail.com>
 <CACA1tWJvw10CGtrRzZ8R1+AhGit-+Zmm-Pi14E3MKfjc7H+NOg@mail.gmail.com> <CACA1tWJ5asqTnV3D1HmYP+U-T7bTODJMLhNBuFA=1-a5B9fDHA@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Wed, 8 Oct 2014 12:10:45 -0700
Message-ID: <CAAswR-6wQpKR5iyyqEpNtFwqkV3ywz58kRXd4TrO4eYUO+B0Wg@mail.gmail.com>
Subject: Re: How to do broadcast join in SparkSQL
To: Jianshi Huang <jianshi.huang@gmail.com>
Cc: Ted Yu <yuzhihong@gmail.com>, user <user@spark.apache.org>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013d0f8add281a0504ee136f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d0f8add281a0504ee136f
Content-Type: text/plain; charset=UTF-8

Thanks for the input.  We purposefully made sure that the config option did
not make it into a release as it is not something that we are willing to
support long term.  That said we'll try and make this easier in the future
either through hints or better support for statistics.

In this particular case you can get what you want by registering the tables
as external tables and setting an flag.  Here's a helper function to do
what you need.

/**
 * Sugar for creating a Hive external table from a parquet path.
 */
def createParquetTable(name: String, file: String): Unit = {
  import org.apache.spark.sql.hive.HiveMetastoreTypes

  val rdd = parquetFile(file)
  val schema = rdd.schema.fields.map(f => s"${f.name}
${HiveMetastoreTypes.toMetastoreType(f.dataType)}").mkString(",\n")
  val ddl = s"""
    |CREATE EXTERNAL TABLE $name (
    |  $schema
    |)
    |ROW FORMAT SERDE 'parquet.hive.serde.ParquetHiveSerDe'
    |STORED AS INPUTFORMAT 'parquet.hive.DeprecatedParquetInputFormat'
    |OUTPUTFORMAT 'parquet.hive.DeprecatedParquetOutputFormat'
    |LOCATION '$file'""".stripMargin
  sql(ddl)
  setConf("spark.sql.hive.convertMetastoreParquet", "true")
}

You'll also need to run this to populate the statistics:

ANALYZE TABLE  tableName COMPUTE STATISTICS noscan;


On Wed, Oct 8, 2014 at 1:44 AM, Jianshi Huang <jianshi.huang@gmail.com>
wrote:

> Ok, currently there's cost-based optimization however Parquet statistics
> is not implemented...
>
> What's the good way if I want to join a big fact table with several tiny
> dimension tables in Spark SQL (1.1)?
>
> I wish we can allow user hint for the join.
>
> Jianshi
>
> On Wed, Oct 8, 2014 at 2:18 PM, Jianshi Huang <jianshi.huang@gmail.com>
> wrote:
>
>> Looks like https://issues.apache.org/jira/browse/SPARK-1800 is not
>> merged into master?
>>
>> I cannot find spark.sql.hints.broadcastTables in latest master, but it's
>> in the following patch.
>>
>>
>> https://github.com/apache/spark/commit/76ca4341036b95f71763f631049fdae033990ab5
>>
>>
>> Jianshi
>>
>>
>> On Mon, Sep 29, 2014 at 1:24 AM, Jianshi Huang <jianshi.huang@gmail.com>
>> wrote:
>>
>>> Yes, looks like it can only be controlled by the
>>> parameter spark.sql.autoBroadcastJoinThreshold, which is a little bit weird
>>> to me.
>>>
>>> How am I suppose to know the exact bytes of a table? Let me specify the
>>> join algorithm is preferred I think.
>>>
>>> Jianshi
>>>
>>> On Sun, Sep 28, 2014 at 11:57 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>
>>>> Have you looked at SPARK-1800 ?
>>>>
>>>> e.g. see sql/core/src/test/scala/org/apache/spark/sql/JoinSuite.scala
>>>> Cheers
>>>>
>>>> On Sun, Sep 28, 2014 at 1:55 AM, Jianshi Huang <jianshi.huang@gmail.com
>>>> > wrote:
>>>>
>>>>> I cannot find it in the documentation. And I have a dozen dimension
>>>>> tables to (left) join...
>>>>>
>>>>>
>>>>> Cheers,
>>>>> --
>>>>> Jianshi Huang
>>>>>
>>>>> LinkedIn: jianshi
>>>>> Twitter: @jshuang
>>>>> Github & Blog: http://huangjs.github.com/
>>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> Jianshi Huang
>>>
>>> LinkedIn: jianshi
>>> Twitter: @jshuang
>>> Github & Blog: http://huangjs.github.com/
>>>
>>
>>
>>
>> --
>> Jianshi Huang
>>
>> LinkedIn: jianshi
>> Twitter: @jshuang
>> Github & Blog: http://huangjs.github.com/
>>
>
>
>
> --
> Jianshi Huang
>
> LinkedIn: jianshi
> Twitter: @jshuang
> Github & Blog: http://huangjs.github.com/
>

--089e013d0f8add281a0504ee136f--

From dev-return-9736-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 20:20:46 2014
Return-Path: <dev-return-9736-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4505517AA8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 20:20:46 +0000 (UTC)
Received: (qmail 51453 invoked by uid 500); 8 Oct 2014 20:20:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51379 invoked by uid 500); 8 Oct 2014 20:20:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51363 invoked by uid 99); 8 Oct 2014 20:20:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 20:20:44 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 20:20:18 +0000
Received: by mail-lb0-f180.google.com with SMTP id n15so1767045lbi.25
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 13:20:15 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=65444s1gb/oBJFux8o2r9m4q/L5pl8/X6+Z56OZUbo8=;
        b=fmTdqX8zrntYE1gR8EGCfFPCaufrbo83BcE+ZSL0CKoIeiaOrne5gQz8TkjDeaBZbg
         fOEe069bx6linU1V4I+o4JEFc8KFb5dEfxITyaUSVbEVyIZZUPmBpV8w5KjmLW/1rUaI
         VTH1cM0qw9RRgOeST54eUOjQL1QDezk4Ryef10h2PkxEPVDeOREtIK6emNKhy7IlDlaW
         H6e6FpAI9QLGEDFzKiGQ9HBMJh+/RcLBbl7uVvGC1W/xD6JJ7hU4K8zcDp7hEbvmRO4n
         WV9EVS5mtjQL3RBdKhS/6OiMQ+YFv24jBix8dZyHlna0QITcep/tdA8hUIS1EjoN8joJ
         8DlQ==
X-Gm-Message-State: ALoCoQn7xnyiwQtm2aDTKVz0CXqbxVAlULJDHvPaaeTPN0M62Jf8nRLe5DzeDVBgquUBUo+rHenp
X-Received: by 10.112.155.8 with SMTP id vs8mr13527024lbb.55.1412799615448;
 Wed, 08 Oct 2014 13:20:15 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.17 with HTTP; Wed, 8 Oct 2014 13:19:55 -0700 (PDT)
In-Reply-To: <CAKWX9VXu4yv2ubKE3-5o6FYHZh068Fk_0f98Mac8tK4Aw--1-w@mail.gmail.com>
References: <CAKWX9VWaNzDcHjxFC3XpwSG+bi7Y+bM2z1jo2g2D8kR1aFES6w@mail.gmail.com>
 <CA+-p3AGEW78LtPbDBHvf1qzsV3bYSwtpBQAS04jRkFq5e0rBzw@mail.gmail.com>
 <CAAswR-4-Z7m7z0+Sp1NHhSS1-YNx1vTVn_Kag7-PKuGgn-DwmA@mail.gmail.com> <CAKWX9VXu4yv2ubKE3-5o6FYHZh068Fk_0f98Mac8tK4Aw--1-w@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Wed, 8 Oct 2014 13:19:55 -0700
Message-ID: <CAAswR-5KJhBm8oNgGWjDQCnh+Qq=ZwbtkQM43jsL5CSh-Qzqrg@mail.gmail.com>
Subject: Re: Parquet schema migrations
To: Cody Koeninger <cody@koeninger.org>
Cc: Andrew Ash <andrew@andrewash.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8f50362a37be450504ef0b89
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f50362a37be450504ef0b89
Content-Type: text/plain; charset=UTF-8

>
> The kind of change we've made that it probably makes most sense to support
> is adding a nullable column. I think that also implies supporting
> "removing" a nullable column, as long as you don't end up with columns of
> the same name but different type.
>

Filed here: https://issues.apache.org/jira/browse/SPARK-3851


> I'm not sure semantically that it makes sense to do schema merging as part
> of union all, and definitely doesn't make sense to do it by default.  I
> wouldn't want two accidentally compatible schema to get merged without
> warning.  It's also a little odd since unlike a normal sql database union
> all can happen before there are any projections or filters... e.g. what
> order do columns come back in if someone does select *.
>

I was proposing you manually convert each different format into one unified
format  (by adding literal nulls and such for missing columns) and then
union these converted datasets.  It would be weird to have union all try
and do this automatically.

--e89a8f50362a37be450504ef0b89--

From dev-return-9737-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 20:51:24 2014
Return-Path: <dev-return-9737-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CE1E117B95
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 20:51:24 +0000 (UTC)
Received: (qmail 36004 invoked by uid 500); 8 Oct 2014 20:51:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35940 invoked by uid 500); 8 Oct 2014 20:51:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35921 invoked by uid 99); 8 Oct 2014 20:51:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 20:51:22 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 20:51:18 +0000
Received: by mail-wi0-f178.google.com with SMTP id cc10so167134wib.5
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 13:50:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=m/BFSS+jZDg/M8fhzgqPtI+3c8y46W1039w6I1WbRzE=;
        b=YAWZ0PuNUFYujX78T+8nfyP72pdvKBG0W+M0ItT6p3F/qE/aLXy7vfphmYgTTIhL0r
         RvVF18dUpG9bOqqFbd67u1ApYicM8/2nrM6qb5NSvfrlKwrksYhDO0V2iQLwNKUtyFcv
         4rj/Gw0/jmHOfJS02koRUn8/RxtLmpX7RnoVpoC8rcbnYsKnVERpAhI+XKateZWrEafY
         ZOKyBD9GDm6Fg01yWodgbLU7s05C+F3Pjf/C/Y1STTBnepa/YjTFeVlUNLLDB2nOnZt+
         eMA30CHuP3hMIFYpNFaaOGeQITupeWDu8H3NIvwed/2SroUsr4CpU0BUzcQ9DDt8Ct1D
         AntA==
X-Received: by 10.180.90.71 with SMTP id bu7mr116855wib.33.1412801457786; Wed,
 08 Oct 2014 13:50:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Wed, 8 Oct 2014 13:50:17 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 8 Oct 2014 16:50:17 -0400
Message-ID: <CAOhmDze4JpySzRac-Ww5fNeC+hpvLGdUDx+oa=FP1OnhqYxeGA@mail.gmail.com>
Subject: spark-ec2 can't initialize spark-standalone module
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043be0f40796a20504ef79ed
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043be0f40796a20504ef79ed
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

This line
<https://github.com/mesos/spark-ec2/blob/bd2b0bd89f4fe42be51b3b6431f04ca682=
3b43dd/setup.sh#L109>
in setup.sh initializes several modules, which are defined here
<https://github.com/apache/spark/blob/bc4418727b40c9b6ba5194ead6e2698539272=
280/ec2/spark_ec2.py#L575>
.

# Install / Init module
for module in $MODULES; do
  echo "Initializing $module"
  if [[ -e $module/init.sh ]]; then
    source $module/init.sh
  fi
  cd /root/spark-ec2  # guard against init.sh changing the cwd
done

One of these modules is spark-standalone. However, it does not have an
init.sh file
<https://github.com/mesos/spark-ec2/tree/bd2b0bd89f4fe42be51b3b6431f04ca682=
3b43dd/spark-standalone>
.

Should it have one? It=E2=80=99s the only module without an init.sh.

Nick
=E2=80=8B

--f46d043be0f40796a20504ef79ed--

From dev-return-9738-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 21:08:44 2014
Return-Path: <dev-return-9738-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 29B2817C31
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 21:08:44 +0000 (UTC)
Received: (qmail 87241 invoked by uid 500); 8 Oct 2014 21:08:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87188 invoked by uid 500); 8 Oct 2014 21:08:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87177 invoked by uid 99); 8 Oct 2014 21:08:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 21:08:42 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 21:08:17 +0000
Received: by mail-oi0-f52.google.com with SMTP id a3so8943470oib.39
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 14:08:15 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=nhWNiGazqzXKWR15HySHpXU8LfxaKM15I45o+LjJ7kc=;
        b=AoP1TOj1tJ/gVXTaOyonUPeOoDTSNdp0R7IB6wnZOQ85l6Yf+jwg4hRJYyZ0Gf0lGU
         l2QUKb2x5tWHMuiMUjKXSCcfIDg1g8IcNx8+Us3YKZsAts+iivmX3vzuL3SCponrZ0DA
         ubOPk1p4cOMHgi9flLsFjmWC/sR0OnTZJB4QwXDlDEaHcnTr+j/dsrUS16NIB2J8KGbt
         P+xETa+GzKKrUQkTnqAu0B6Yo8EJqruZdQehjqNkpTaLcRIJNgfpFiR8HQXuU9T9ji49
         +1vgKbAIQLfUgvcI73QgXaDtyLiPU5F8EqguiXNm4EplksrYuBie9e8s5qnerrTXenxK
         5riQ==
X-Gm-Message-State: ALoCoQkFPe1B2qyeLvzrmhy1quLvUkVlRKPuldHYx8u7FciPbWXizf4+D+YsphKz0FPwml7tu2Xl
MIME-Version: 1.0
X-Received: by 10.182.181.3 with SMTP id ds3mr15304769obc.11.1412802495054;
 Wed, 08 Oct 2014 14:08:15 -0700 (PDT)
Received: by 10.76.7.228 with HTTP; Wed, 8 Oct 2014 14:08:14 -0700 (PDT)
In-Reply-To: <CAAswR-5KJhBm8oNgGWjDQCnh+Qq=ZwbtkQM43jsL5CSh-Qzqrg@mail.gmail.com>
References: <CAKWX9VWaNzDcHjxFC3XpwSG+bi7Y+bM2z1jo2g2D8kR1aFES6w@mail.gmail.com>
	<CA+-p3AGEW78LtPbDBHvf1qzsV3bYSwtpBQAS04jRkFq5e0rBzw@mail.gmail.com>
	<CAAswR-4-Z7m7z0+Sp1NHhSS1-YNx1vTVn_Kag7-PKuGgn-DwmA@mail.gmail.com>
	<CAKWX9VXu4yv2ubKE3-5o6FYHZh068Fk_0f98Mac8tK4Aw--1-w@mail.gmail.com>
	<CAAswR-5KJhBm8oNgGWjDQCnh+Qq=ZwbtkQM43jsL5CSh-Qzqrg@mail.gmail.com>
Date: Wed, 8 Oct 2014 16:08:14 -0500
Message-ID: <CAKWX9VV2j0m2Axsa9OUHB4T0CW7GDZs-Zi3DsyCgqWs-Zc4k8Q@mail.gmail.com>
Subject: Re: Parquet schema migrations
From: Cody Koeninger <cody@koeninger.org>
To: Michael Armbrust <michael@databricks.com>
Cc: Andrew Ash <andrew@andrewash.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01182856db1d220504efb64e
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01182856db1d220504efb64e
Content-Type: text/plain; charset=UTF-8

On Wed, Oct 8, 2014 at 3:19 PM, Michael Armbrust <michael@databricks.com>
wrote:

>
> I was proposing you manually convert each different format into one
> unified format  (by adding literal nulls and such for missing columns) and
> then union these converted datasets.  It would be weird to have union all
> try and do this automatically.
>


Sure, I was just musing on what an api for doing the merging without manual
user input should look like / do.   I'll comment on the ticket, thanks for
making it

--089e01182856db1d220504efb64e--

From dev-return-9739-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 21:54:06 2014
Return-Path: <dev-return-9739-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B63D417D96
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 21:54:06 +0000 (UTC)
Received: (qmail 87297 invoked by uid 500); 8 Oct 2014 21:54:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87224 invoked by uid 500); 8 Oct 2014 21:54:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87208 invoked by uid 99); 8 Oct 2014 21:53:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 21:53:59 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nkronenfeld@oculusinfo.com designates 209.85.160.181 as permitted sender)
Received: from [209.85.160.181] (HELO mail-yk0-f181.google.com) (209.85.160.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 21:53:55 +0000
Received: by mail-yk0-f181.google.com with SMTP id q200so4403ykb.12
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 14:53:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=oculusinfo.com; s=google;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=V4pIG+74FHhgsknI6RQOf1xe+udkN2vnTqGO3v5OCTY=;
        b=YjQjvMY+1yONrX7ZJtq9q7l9sUGRu6r6vWKXV64H6lELC5OlUye2aycHQ3/Ikau/4Q
         Xb5bepGAN9PmN2djLXP2bhkywoXBp9U1XiV7zeKQktR1/RpVtOokfRIVQ2CmrO9mf+vk
         sP8k7my9vT40meuGsp1DS7WJ8asKJjXuJOGcI=
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=V4pIG+74FHhgsknI6RQOf1xe+udkN2vnTqGO3v5OCTY=;
        b=Fw8hd3tTi9xFeL2lYw77j6PXVmzZOW+AgNUCZczNICKKO6M+ihUpXoLyN+l3EzkhAl
         c6wjmw25hbxt7VDws3Otk7++JbeBDwCpH8EA04v0KjCrCMzNwVctZTIztHjlYIbsEmRc
         fLs3n/YboMdPNlYwllcM50gEn5lZdQxTm2rP7VCGinzikcjw3aDpNrT32jY4wKYhS13s
         bitB+geIs5V2KRs7gdll11mjo5L9GmEfb5NQJ4ccj9oCB1JVORfd9JMDIzq8mAAwmr92
         u88IQ7FSWQBxc1HYShYJqHYv6U5UIjnJqIQ3QhfEzMmpXRwo/g1AVHgisot7N4FPy6R7
         A+fQ==
X-Gm-Message-State: ALoCoQmOf1lIw2gHk3GxVcvCq3gQoCqcgvztpEwRfwX1D0ldjadKrPqx8k8dKMwagWELnBevdNZY
MIME-Version: 1.0
X-Received: by 10.236.93.39 with SMTP id k27mr19524176yhf.129.1412805214073;
 Wed, 08 Oct 2014 14:53:34 -0700 (PDT)
Received: by 10.170.134.216 with HTTP; Wed, 8 Oct 2014 14:53:34 -0700 (PDT)
In-Reply-To: <CAEpWh4_TF-CPjnBvyzSnBM3NqXdPb6rfokPSSXZ7JuA7siQefQ@mail.gmail.com>
References: <CAEpWh4_TF-CPjnBvyzSnBM3NqXdPb6rfokPSSXZ7JuA7siQefQ@mail.gmail.com>
Date: Wed, 8 Oct 2014 17:53:34 -0400
Message-ID: <CAEpWh49-gFnnAdrs8vS-gW1+9a3x1MNCX2jzopRnBaTfUmrZhg@mail.gmail.com>
Subject: Fwd: Accumulator question
From: Nathan Kronenfeld <nkronenfeld@oculusinfo.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=20cf301b5f6bec08e80504f05813
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf301b5f6bec08e80504f05813
Content-Type: text/plain; charset=UTF-8

I notice that accumulators register themselves with a private Accumulators
object.

I don't notice any way to unregister them when one is done.

Am I missing something? If not, is there any plan for how to free up that
memory?

I've a case where we're gathering data from repeated queries using some
relatively sizable accumulators; at the moment, we're creating one per
query, and running out of memory after far too few queries.

I've tried methods that don't involve accumulators; they involve a shuffle
instead, and take 10x as long.

Thanks,
                  -Nathan




-- 
Nathan Kronenfeld
Senior Visualization Developer
Oculus Info Inc
2 Berkeley Street, Suite 600,
Toronto, Ontario M5A 4J5
Phone:  +1-416-203-3003 x 238
Email:  nkronenfeld@oculusinfo.com

--20cf301b5f6bec08e80504f05813--

From dev-return-9740-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct  8 22:08:54 2014
Return-Path: <dev-return-9740-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7A77B17E06
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed,  8 Oct 2014 22:08:54 +0000 (UTC)
Received: (qmail 8243 invoked by uid 500); 8 Oct 2014 22:08:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7626 invoked by uid 500); 8 Oct 2014 22:08:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4402 invoked by uid 99); 8 Oct 2014 22:01:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 22:01:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.180 as permitted sender)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 08 Oct 2014 22:01:46 +0000
Received: by mail-lb0-f180.google.com with SMTP id n15so18177lbi.11
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 15:01:25 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=HLg/q4BPrUm2PdyBdkpbaReRCf9qZEEMTveMilZETn0=;
        b=jKtUzMPfcsh8ZaTVaMLhqYs4UAQWesxEjTbgJEQC4vnflIDxbQ/H3xa59DM1qRKMbm
         0E5Td+ilMcpSDUbwHxqIqm/SCZlL3W13/xuI9abjaeMG4cvnFGGPjlvRdGEEpUUYHYzc
         2PiPg/rw134W61xd0jAal0RiOn4ko9o4U50hHpNwUrDXwvWiZNjFPCFf3kUQVoUjqJSt
         trh4flGVtFySy1XL/ZYkQsRCdS6l3Dg1KEaaeVJOn4JvXFaO01KFbvrJZGjkMsUOjdFE
         n1+DKbadxaE3B7X26I0OjbNDRqLeZENSmtuG3z+YBXTGnvxauX4F7Fl6oFcnSu2jAAQB
         PoQQ==
X-Gm-Message-State: ALoCoQl7OG/HP7c8GGIjKVJjXZSNjlDcY4qgFETkgBNTXW5R1WmaEuPigYgoA08xlPkW34653g3b
X-Received: by 10.112.185.68 with SMTP id fa4mr13384856lbc.77.1412805684889;
 Wed, 08 Oct 2014 15:01:24 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Wed, 8 Oct 2014 15:01:04 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 8 Oct 2014 15:01:04 -0700
Message-ID: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
Subject: new jenkins update + tentative release date
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11c3caa4fc206d0504f07498
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3caa4fc206d0504f07498
Content-Type: text/plain; charset=UTF-8

greetings!

i've got some updates regarding our new jenkins infrastructure, as well as
the initial date and plan for rolling things out:

*** current testing/build break whack-a-mole:
a lot of out of date artifacts are cached in the current jenkins, which has
caused a few builds during my testing to break due to dependency resolution
failure[1][2].

bumping these versions can cause your builds to fail, due to public api
changes and the like.  consider yourself warned that some projects might
require some debugging...  :)

tomorrow, i will be at databricks working w/@joshrosen to make sure that
the spark builds have any bugs hammered out.

***  deployment plan:
unless something completely horrible happens, THE NEW JENKINS WILL GO LIVE
ON MONDAY (october 13th).

all jenkins infrastructure will be DOWN for the entirety of the day
(starting at ~8am).  this means no builds, period.  i'm hoping that the
downtime will be much shorter than this, but we'll have to see how
everything goes.

all test/build history WILL BE PRESERVED.  i will be rsyncing the jenkins
jobs/ directory over, complete w/history as part of the deployment.

once i'm feeling good about the state of things, i'll point the original
url to the new instances and send out an all clear.

if you are a student at UC berkeley, you can log in to jenkins using your
LDAP login, and (by default) view but not change plans.  if you do not have
a UC berkeley LDAP login, you can still view plans anonymously.

IF YOU ARE A PLAN ADMIN, THEN PLEASE REACH OUT, ASAP, PRIVATELY AND I WILL
SET UP ADMIN ACCESS TO YOUR BUILDS.

***  post deployment plan:
fix all of the things that break!

i will be keeping a VERY close eye on the builds, checking for breaks, and
helping out where i can.  if the situation is dire, i can always roll back
to the old jenkins infra...  but i hope we never get to that point!  :)

i'm hoping that things will go smoothly, but please be patient as i'm
certain we'll hit a few bumps in the road.

please let me know if you guys have any comments/questions/concerns...  :)

shane

1 - https://github.com/bigdatagenomics/bdg-services/pull/18
2 - https://github.com/bigdatagenomics/avocado/pull/111

--001a11c3caa4fc206d0504f07498--

From dev-return-9741-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 00:20:12 2014
Return-Path: <dev-return-9741-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 50E8517454
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 00:20:12 +0000 (UTC)
Received: (qmail 36270 invoked by uid 500); 9 Oct 2014 00:20:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36200 invoked by uid 500); 9 Oct 2014 00:20:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36187 invoked by uid 99); 9 Oct 2014 00:20:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 00:20:10 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 00:20:06 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1Xc1SL-0006Wq-EM
	for dev@spark.incubator.apache.org; Wed, 08 Oct 2014 17:19:45 -0700
Date: Wed, 8 Oct 2014 17:19:45 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1412813985423-8711.post@n3.nabble.com>
In-Reply-To: <CAJgQjQ-sQB9tj_cXqHnTQq99CHtpa7_ad82s1R2oz3JdU5JMyA@mail.gmail.com>
References: <1412767187902-8697.post@n3.nabble.com> <CAJgQjQ-sQB9tj_cXqHnTQq99CHtpa7_ad82s1R2oz3JdU5JMyA@mail.gmail.com>
Subject: Re: Standardized Distance Functions in MLlib
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Xiangrui, 

Thank you very much for replying and letting me know that you upgraded
breeze to 0.10 yesterday.
Sorry that I didn't know that.

> We don't want to maintain 
> another copy of the implementation in MLlib to keep the maintenance 
> cost low. Both spark and breeze are open-source projects. We should 
> try our best to avoid duplicate effort and forking, even though we 
> don't have control the release of breeze. 

I got it. I agree with keeping linear algebra in MLlib lightweight.

> It would be really nice if you can help review it and discuss how to embed
> distance measures there. 

All right. I will check it.

thanks,
Yu Ishikawa



-----
-- Yu Ishikawa
--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Standardized-Distance-Functions-in-MLlib-tp8697p8711.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9742-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 00:23:08 2014
Return-Path: <dev-return-9742-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4F9551746C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 00:23:08 +0000 (UTC)
Received: (qmail 44865 invoked by uid 500); 9 Oct 2014 00:23:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44797 invoked by uid 500); 9 Oct 2014 00:23:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44781 invoked by uid 99); 9 Oct 2014 00:23:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 00:23:07 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jym2307@gmail.com designates 209.85.215.52 as permitted sender)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 00:23:03 +0000
Received: by mail-la0-f52.google.com with SMTP id hz20so170947lab.11
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 17:22:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=DIdLdplSyP8hJFdadSrkWJhBvPCbdtnmbDCuRBnDDaQ=;
        b=ld482pSByFCtPBh9CGvR3L3wrixUYTX4eAQA/ud+78gLlhVW5oWbPPvuYjFCuzqf7W
         mmSSrU/0CmEkSPNahNngE81FpTCuGMLwIw9I4VlcPid1RpmGFFlw4sI6EHQ31J4zCZwl
         RbPkfhQBjyobxHa878ac1mopTEGQeQbK/FHLceGbaDKamGamF5D9UKdDVycJrq1Hm/fx
         K7nchpkx1DkEZeEFqjERj9laRwekEy/xYjiDLZi3Cu0DAL4ay1ChELfzCazTCMqZOPtK
         wAPD9cs1kxzXV16tGNYjb5J5MKbfi5vrkP0craoUUdjpy9eD/y/xBbw/TE1f9YSsR1jT
         P45g==
MIME-Version: 1.0
X-Received: by 10.152.37.135 with SMTP id y7mr14796929laj.66.1412814161676;
 Wed, 08 Oct 2014 17:22:41 -0700 (PDT)
Received: by 10.112.3.99 with HTTP; Wed, 8 Oct 2014 17:22:41 -0700 (PDT)
In-Reply-To: <CAAsvFPnQ68hkk-=zRySdGci+xhqsiE1Dact_p8PxP+nW3Do18w@mail.gmail.com>
References: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>
	<CAN6Vra3oCudcLmVq15zGeKi+ESC11P3V9ENDrEGFhbvAgiNRDQ@mail.gmail.com>
	<CAAsvFPnQ68hkk-=zRySdGci+xhqsiE1Dact_p8PxP+nW3Do18w@mail.gmail.com>
Date: Wed, 8 Oct 2014 17:22:41 -0700
Message-ID: <CADJKNppACFGWwbKXu30-zmjX3zW7ivCxuuV6iWiN_uu6sqJsXQ@mail.gmail.com>
Subject: Re: will/when Spark/SparkSQL will support ORCFile format
From: James Yu <jym2307@gmail.com>
To: Mark Hamstra <mark@clearstorydata.com>
Cc: Evan Chan <velvia.github@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01493a143d8fa20504f26e6f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01493a143d8fa20504f26e6f
Content-Type: text/plain; charset=ISO-8859-1

Thanks Mark! I will keep eye on it.

@Evan, I saw people use both format, so I really want to have Spark support
ORCFile.


On Wed, Oct 8, 2014 at 11:12 AM, Mark Hamstra <mark@clearstorydata.com>
wrote:

> https://github.com/apache/spark/pull/2576
>
>
>
> On Wed, Oct 8, 2014 at 11:01 AM, Evan Chan <velvia.github@gmail.com>
> wrote:
>
>> James,
>>
>> Michael at the meetup last night said there was some development
>> activity around ORCFiles.
>>
>> I'm curious though, what are the pros and cons of ORCFiles vs Parquet?
>>
>> On Wed, Oct 8, 2014 at 10:03 AM, James Yu <jym2307@gmail.com> wrote:
>> > Didn't see anyone asked the question before, but I was wondering if
>> anyone
>> > knows if Spark/SparkSQL will support ORCFile format soon? ORCFile is
>> > getting more and more popular hi Hive world.
>> >
>> > Thanks,
>> > James
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>

--089e01493a143d8fa20504f26e6f--

From dev-return-9743-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 05:10:31 2014
Return-Path: <dev-return-9743-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 221DD17C2F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 05:10:31 +0000 (UTC)
Received: (qmail 84684 invoked by uid 500); 9 Oct 2014 05:10:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84601 invoked by uid 500); 9 Oct 2014 05:10:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 84590 invoked by uid 99); 9 Oct 2014 05:10:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 05:10:29 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of shivaram@berkeley.edu designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 05:10:04 +0000
Received: by mail-wg0-f46.google.com with SMTP id l18so399398wgh.29
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 22:10:02 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=pQB3NPQzLO8p/3kPU+7u/cmHK3nbW43PUb4Q4iRwjD4=;
        b=VD1mI5YukbGYwFz2ie7iezOmnAevQSPw3HaqcKc0dzyY9k7aFirhsStWS4lbRSqMpH
         d9hdpTpBtsNo5StyZu5Min4daqCl0uLY7DxgwHzmNQ1rqJn/FmfLZoQhrzXPsEGrVOoI
         nm7Zaiu8apF2dFbw5os9L+7c8GOsibyF3hNSM7M1x5QXQsO02kepluv9wMYyM0rwEfK0
         sMmI42cbnA2AgzkEIw1NI/+3WWCuJOpawrUKZz8Od3nkdrY7pPC5PuoEsxdGn0zVNGZz
         cfMbOwDYymlWVwnsSaNljQIvXiNV0VOvp9oU5d9GPiV/G6weIWDt0EA6oFJ+Bnv6gSKH
         ZQEg==
X-Gm-Message-State: ALoCoQnjRPVF12eMsNxMbOQrsLiw/7jcoFU2Vo3Gh/l9xp3lOt35WjXNw+IC84NWfyUdb/lAbXYS
MIME-Version: 1.0
X-Received: by 10.194.190.116 with SMTP id gp20mr15752945wjc.27.1412831402487;
 Wed, 08 Oct 2014 22:10:02 -0700 (PDT)
Reply-To: shivaram@eecs.berkeley.edu
Received: by 10.217.95.133 with HTTP; Wed, 8 Oct 2014 22:10:02 -0700 (PDT)
In-Reply-To: <CAOhmDze4JpySzRac-Ww5fNeC+hpvLGdUDx+oa=FP1OnhqYxeGA@mail.gmail.com>
References: <CAOhmDze4JpySzRac-Ww5fNeC+hpvLGdUDx+oa=FP1OnhqYxeGA@mail.gmail.com>
Date: Wed, 8 Oct 2014 23:10:02 -0600
Message-ID: <CAKx7Bf-6HB-C2Fj7xvXdUVVQXzYs60iFObFfDXOz456pEd7+4A@mail.gmail.com>
Subject: Re: spark-ec2 can't initialize spark-standalone module
From: Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

There is a check to see if init.sh file exists (` if [[ -e
$module/init.sh ]]; then`), so it just won't get called. Regarding
spark-standalone not having a init.sh that is because we dont have any
initialization work to do for it  (its not necessary for all modules
to have a init.sh) as the spark module downloads and installs Spark.

Thanks
Shivaram

On Wed, Oct 8, 2014 at 2:50 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> This line
> <https://github.com/mesos/spark-ec2/blob/bd2b0bd89f4fe42be51b3b6431f04ca6=
823b43dd/setup.sh#L109>
> in setup.sh initializes several modules, which are defined here
> <https://github.com/apache/spark/blob/bc4418727b40c9b6ba5194ead6e26985392=
72280/ec2/spark_ec2.py#L575>
> .
>
> # Install / Init module
> for module in $MODULES; do
>   echo "Initializing $module"
>   if [[ -e $module/init.sh ]]; then
>     source $module/init.sh
>   fi
>   cd /root/spark-ec2  # guard against init.sh changing the cwd
> done
>
> One of these modules is spark-standalone. However, it does not have an
> init.sh file
> <https://github.com/mesos/spark-ec2/tree/bd2b0bd89f4fe42be51b3b6431f04ca6=
823b43dd/spark-standalone>
> .
>
> Should it have one? It=E2=80=99s the only module without an init.sh.
>
> Nick
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9744-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 06:03:54 2014
Return-Path: <dev-return-9744-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A15CD17D70
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 06:03:54 +0000 (UTC)
Received: (qmail 75383 invoked by uid 500); 9 Oct 2014 06:03:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75311 invoked by uid 500); 9 Oct 2014 06:03:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75299 invoked by uid 99); 9 Oct 2014 06:03:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 06:03:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.218.41 as permitted sender)
Received: from [209.85.218.41] (HELO mail-oi0-f41.google.com) (209.85.218.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 06:03:27 +0000
Received: by mail-oi0-f41.google.com with SMTP id u20so1162100oif.28
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 23:03:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type:content-transfer-encoding;
        bh=twkC6GvX36X9xkMmilaqVvFLsL0cNmF1DRoeCEGR5U8=;
        b=x+im6fWMUDxzkJF2wHFrgiwpmFIKYCpkduq+bdtTybKnUTnAM6U+cDRy5j+Dad3fr5
         v33mcq9vp3m4Uf6IWInMTAoAxzFrtKoIcdTY0tv6przcYdJST8WhD/BnuC9yqNw5j8kd
         41HGR9qXOHrOAW1PN94Ke2ALyj0bqXcTskD1qQWCf3sqZ6yc2SqiGIMCWzWKV3kSWJnr
         T++0c/HsAWK7xjZU2kqcKo+1zTemrbE6lXNc0u29dEZcDLOW7scl61kPe79Drnm1jTzq
         sOz3ZnafK04eQVL7PLEx38VF6KrE4t5TIwLEJyJ7pnhJuIhGMv5oWsfpE+kBep6vrSHH
         PXWA==
X-Received: by 10.60.130.170 with SMTP id of10mr19170327oeb.10.1412834605508;
        Wed, 08 Oct 2014 23:03:25 -0700 (PDT)
Received: from lian-laptop.local ([116.251.221.75])
        by mx.google.com with ESMTPSA id p17sm2437509oem.10.2014.10.08.23.03.22
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Wed, 08 Oct 2014 23:03:25 -0700 (PDT)
Message-ID: <54362529.6060705@gmail.com>
Date: Thu, 09 Oct 2014 14:03:21 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: James Yu <jym2307@gmail.com>, Mark Hamstra <mark@clearstorydata.com>
CC: Evan Chan <velvia.github@gmail.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: will/when Spark/SparkSQL will support ORCFile format
References: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>	<CAN6Vra3oCudcLmVq15zGeKi+ESC11P3V9ENDrEGFhbvAgiNRDQ@mail.gmail.com>	<CAAsvFPnQ68hkk-=zRySdGci+xhqsiE1Dact_p8PxP+nW3Do18w@mail.gmail.com> <CADJKNppACFGWwbKXu30-zmjX3zW7ivCxuuV6iWiN_uu6sqJsXQ@mail.gmail.com>
In-Reply-To: <CADJKNppACFGWwbKXu30-zmjX3zW7ivCxuuV6iWiN_uu6sqJsXQ@mail.gmail.com>
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

The foreign data source API PR also matters here 
https://www.github.com/apache/spark/pull/2475

Foreign data source like ORC can be added more easily and systematically 
after this PR is merged.

On 10/9/14 8:22 AM, James Yu wrote:
> Thanks Mark! I will keep eye on it.
>
> @Evan, I saw people use both format, so I really want to have Spark support
> ORCFile.
>
>
> On Wed, Oct 8, 2014 at 11:12 AM, Mark Hamstra <mark@clearstorydata.com>
> wrote:
>
>> https://github.com/apache/spark/pull/2576
>>
>>
>>
>> On Wed, Oct 8, 2014 at 11:01 AM, Evan Chan <velvia.github@gmail.com>
>> wrote:
>>
>>> James,
>>>
>>> Michael at the meetup last night said there was some development
>>> activity around ORCFiles.
>>>
>>> I'm curious though, what are the pros and cons of ORCFiles vs Parquet?
>>>
>>> On Wed, Oct 8, 2014 at 10:03 AM, James Yu <jym2307@gmail.com> wrote:
>>>> Didn't see anyone asked the question before, but I was wondering if
>>> anyone
>>>> knows if Spark/SparkSQL will support ORCFile format soon? ORCFile is
>>>> getting more and more popular hi Hive world.
>>>>
>>>> Thanks,
>>>> James
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9745-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 06:56:56 2014
Return-Path: <dev-return-9745-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2159317E83
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 06:56:56 +0000 (UTC)
Received: (qmail 54570 invoked by uid 500); 9 Oct 2014 06:56:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 54497 invoked by uid 500); 9 Oct 2014 06:56:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54486 invoked by uid 99); 9 Oct 2014 06:56:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 06:56:54 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.192.44] (HELO mail-qg0-f44.google.com) (209.85.192.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 06:56:51 +0000
Received: by mail-qg0-f44.google.com with SMTP id j5so764208qga.3
        for <dev@spark.apache.org>; Wed, 08 Oct 2014 23:56:29 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=TIk8HfbArjDLX2dYqXX98LISx6sSIE3m2aDxqCN1LAA=;
        b=UqyWRr0SB2pjD9bBul3rqGqNJM7Z1wQ6o/rXHDV69m7u6GzHRdL2HP2t/ytAeTpxAn
         /BPBTRB1m9Agf5/fALRJyvAoCKCr5Jlb/DF7rhsutBY3kMZA4qmwH1PDgP55kX91Ro5D
         WZj+P5aueW772NWpOk4BwcjRY5H7nYPtJruEmwQ8zPdtidlhVSat1StV8o2l9uCOfZVm
         JU5XNTsOIoFMSju+S7p6MIvwPfp8FKh2w3zS3X/rp6lEQfaNe4WQWUTm/rYcFatZ079i
         1mDDuVb/2Fz2vc1zXF2El5qoAuKK4wTn411CdWNw+kaHlbPnLZ9ptUVRTEd7+7apGJtZ
         2Ukg==
X-Gm-Message-State: ALoCoQkAQlyvDOtMZbJ5A7KHWaMv38oEHmSb3+y+p1slaDDSSA831Za4ug7q4Nezh+FuPbHTQX4P
X-Received: by 10.229.131.5 with SMTP id v5mr20607959qcs.21.1412837789770;
 Wed, 08 Oct 2014 23:56:29 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.47.8 with HTTP; Wed, 8 Oct 2014 23:56:09 -0700 (PDT)
In-Reply-To: <CAOhmDzcrLkKeRSmSo7Huk-No4dt=AjRhMKdjUcrhrfnsugSacw@mail.gmail.com>
References: <CAOhmDzdhq=puUXZPyVtebS2Pn2n1CpqcJ4SpcZ6a_pRC87kjVQ@mail.gmail.com>
 <CALte62y7a6WyBDUFDcGUwbf8WCpttViE+PAo4pZOR+_-nB2UTw@mail.gmail.com>
 <CABPQxsvDNDNyfO86vUMHW622Tb7fkwK94M1O=u-8U2ANGA3CEQ@mail.gmail.com>
 <CAOhmDzeAevbfC_YYt+bBN6vO1CZYVVLWJ_XA_fuO0xTYLnNm7g@mail.gmail.com>
 <CAAswR-5EnHKb9SKk=E7T84-ckLDoXwdeqRSuz3KK5Yy2F=p6Jg@mail.gmail.com>
 <CAOhmDzeNVb4Gk2-xf3UV1d4doSzdZmB0TkUOR_QTm4U-NVER9A@mail.gmail.com>
 <542CCF41.8000105@gmail.com> <CAOhmDzfWXfdFn9DNKJvsh2psXhQ1NCH9i=tfTML0m5HO1CLNyA@mail.gmail.com>
 <CAOhmDzcrLkKeRSmSo7Huk-No4dt=AjRhMKdjUcrhrfnsugSacw@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Wed, 8 Oct 2014 23:56:09 -0700
Message-ID: <CAPh_B=YB6AXNaOG4TwNwr-+q7XN9sCjHr1_OtXjK2r2t0Gd-xA@mail.gmail.com>
Subject: Re: Extending Scala style checks
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Michael Armbrust <michael@databricks.com>, 
	Patrick Wendell <pwendell@gmail.com>, Ted Yu <yuzhihong@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1132e2b695c4d30504f7eeb8
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1132e2b695c4d30504f7eeb8
Content-Type: text/plain; charset=UTF-8

Thanks. I added one.


On Wed, Oct 8, 2014 at 8:49 AM, Nicholas Chammas <nicholas.chammas@gmail.com
> wrote:

> I've created SPARK-3849: Automate remaining Scala style rules
> <https://issues.apache.org/jira/browse/SPARK-3849>.
>
> Please create sub-tasks on this issue for rules that we have not automated
> and let's work through them as possible.
>
> I went ahead and created the first sub-task, SPARK-3850: Scala style:
> Disallow trailing spaces <https://issues.apache.org/jira/browse/SPARK-3850
> >.
>
> Nick
>
> On Tue, Oct 7, 2014 at 4:45 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> > wrote:
>
> > For starters, do we have a list of all the Scala style rules that are
> > currently not enforced automatically but are likely well-suited for
> > automation?
> >
> > Let's put such a list together in a JIRA issue and work through
> > implementing them.
> >
> > Nick
> >
> > On Thu, Oct 2, 2014 at 12:06 AM, Cheng Lian <lian.cs.zju@gmail.com>
> wrote:
> >
> >> Since we can easily catch the list of all changed files in a PR, I think
> >> we can start with adding the no trailing space check for newly changed
> >> files only?
> >>
> >>
> >> On 10/2/14 9:24 AM, Nicholas Chammas wrote:
> >>
> >>> Yeah, I remember that hell when I added PEP 8 to the build checks and
> >>> fixed
> >>> all the outstanding Python style issues. I had to keep rebasing and
> >>> resolving merge conflicts until the PR was merged.
> >>>
> >>> It's a rough process, but thankfully it's also a one-time process. I
> >>> might
> >>> be able to help with that in the next week or two if no-one else wants
> to
> >>> pick it up.
> >>>
> >>> Nick
> >>>
> >>> On Wed, Oct 1, 2014 at 9:20 PM, Michael Armbrust <
> michael@databricks.com
> >>> >
> >>> wrote:
> >>>
> >>>  The hard part here is updating the existing code base... which is
> going
> >>>> to
> >>>> create merge conflicts with like all of the open PRs...
> >>>>
> >>>> On Wed, Oct 1, 2014 at 6:13 PM, Nicholas Chammas <
> >>>> nicholas.chammas@gmail.com> wrote:
> >>>>
> >>>>  Ah, since there appears to be a built-in rule for end-of-line
> >>>>> whitespace,
> >>>>> Michael and Cheng, y'all should be able to add this in pretty easily.
> >>>>>
> >>>>> Nick
> >>>>>
> >>>>> On Wed, Oct 1, 2014 at 6:37 PM, Patrick Wendell <pwendell@gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>  Hey Nick,
> >>>>>>
> >>>>>> We can always take built-in rules. Back when we added this Prashant
> >>>>>> Sharma actually did some great work that lets us write our own style
> >>>>>> rules in cases where rules don't exist.
> >>>>>>
> >>>>>> You can see some existing rules here:
> >>>>>>
> >>>>>>
> >>>>>>  https://github.com/apache/spark/tree/master/project/
> >>>>> spark-style/src/main/scala/org/apache/spark/scalastyle
> >>>>>
> >>>>>> Prashant has over time contributed a lot of our custom rules
> upstream
> >>>>>> to stalastyle, so now there are only a couple there.
> >>>>>>
> >>>>>> - Patrick
> >>>>>>
> >>>>>> On Wed, Oct 1, 2014 at 2:36 PM, Ted Yu <yuzhihong@gmail.com> wrote:
> >>>>>>
> >>>>>>> Please take a look at WhitespaceEndOfLineChecker under:
> >>>>>>> http://www.scalastyle.org/rules-0.1.0.html
> >>>>>>>
> >>>>>>> Cheers
> >>>>>>>
> >>>>>>> On Wed, Oct 1, 2014 at 2:01 PM, Nicholas Chammas <
> >>>>>>>
> >>>>>> nicholas.chammas@gmail.com
> >>>>>>
> >>>>>>> wrote:
> >>>>>>>> As discussed here <https://github.com/apache/spark/pull/2619>, it
> >>>>>>>>
> >>>>>>> would be
> >>>>>>
> >>>>>>> good to extend our Scala style checks to programmatically enforce
> as
> >>>>>>>>
> >>>>>>> many
> >>>>>>
> >>>>>>> of our style rules as possible.
> >>>>>>>>
> >>>>>>>> Does anyone know if it's relatively straightforward to enforce
> >>>>>>>>
> >>>>>>> additional
> >>>>>>
> >>>>>>> rules like the "no trailing spaces" rule mentioned in the linked
> PR?
> >>>>>>>>
> >>>>>>>> Nick
> >>>>>>>>
> >>>>>>>>
> >>>>
> >>
> >
>

--001a1132e2b695c4d30504f7eeb8--

From dev-return-9746-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 09:23:54 2014
Return-Path: <dev-return-9746-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 47A09174B4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 09:23:54 +0000 (UTC)
Received: (qmail 14342 invoked by uid 500); 9 Oct 2014 09:23:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14286 invoked by uid 500); 9 Oct 2014 09:23:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13342 invoked by uid 99); 9 Oct 2014 09:23:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 09:23:50 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.192.47] (HELO mail-qg0-f47.google.com) (209.85.192.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 09:23:46 +0000
Received: by mail-qg0-f47.google.com with SMTP id i50so1090786qgf.20
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 02:23:25 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:sender:in-reply-to
         :references:date:message-id:subject:from:to:cc:content-type;
        bh=9QKI6vot6P+NsJwZrYtBhkNYO/sgFFMbiqdrADlFrD0=;
        b=Lfkd+qrTaruLb4QTuLsSL6hx2YuW43tUgbbPT8LCMYU4Ccnpi+4NSR8KKi0iup6QjT
         D6b44mCcvMD6Fq7gvyLqAFdqCCHpY1y2g25lEudFrWto6/Yf8PwQSkUWxzJJYd4XW6GO
         CCIjwJksi51mpDNQ4YycjlLqNAgjlVu0vwTmTxVxFZkItOk4GqjB4AsWDfm+J51UWoS2
         2cVkOIuBm08pIBNIDLVVNIiKxzpwYDeGzlOkv5dg/GLtr8uiFpflierssHs+Yk0onG3l
         fikXUE75ltYhk3Ygz43PttwYSQ9W5ve0YbWQuMefzLE7/DoShdP42e43sKWGZs4uWNPA
         kLsw==
X-Gm-Message-State: ALoCoQntfBrLDE3EewJrBlR4idt7wrdUmExc0g4pSIKMZYpKy3OTzj/vOV1BsgnP4ZRFX3k4hj86
MIME-Version: 1.0
X-Received: by 10.224.4.5 with SMTP id 5mr22014805qap.83.1412846605194; Thu,
 09 Oct 2014 02:23:25 -0700 (PDT)
Reply-To: dbtsai@dbtsai.com
Sender: dbtsai@dbtsai.com
Received: by 10.229.12.73 with HTTP; Thu, 9 Oct 2014 02:23:25 -0700 (PDT)
In-Reply-To: <CALDQvdf7q_T=_=OAEkTZesoT7VTmNSJ+Pn0DDnYWA8yBf0nWeA@mail.gmail.com>
References: <CALDQvdewbW4D-a1o=HLboQ10WBszBmFM4gSEWU3=8bBoitExeA@mail.gmail.com>
	<CAEYYnxbe1siwZKGizuOtw=uDBePxU9etf9UMYxi7pHXHK7Fu0A@mail.gmail.com>
	<CALDQvdf7q_T=_=OAEkTZesoT7VTmNSJ+Pn0DDnYWA8yBf0nWeA@mail.gmail.com>
Date: Thu, 9 Oct 2014 11:23:25 +0200
X-Google-Sender-Auth: Tug0XEaF9FWLz7WuZEbLZOgaRQk
Message-ID: <CAEYYnxZ1L2TaMaRaLhXyVW_QL-MW-u8KgVp2sS3pg=gfT7vdNQ@mail.gmail.com>
Subject: Re: [MLlib] LogisticRegressionWithSGD and LogisticRegressionWithLBFGS
 converge with different weights.
From: DB Tsai <dbtsai@dbtsai.com>
To: Yanbo Liang <yanbohappy@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>, 
	Xiangrui Meng <mengxr@gmail.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Nice to hear that your experiment is consistent to my assumption. The
current L1/L2 will penalize the intercept as well which is not idea.
I'm working on GLMNET in Spark using OWLQN, and I can exactly get the
same solution as R but with scalability in # of rows and columns. Stay
tuned!

Sincerely,

DB Tsai
-------------------------------------------------------
My Blog: https://www.dbtsai.com
LinkedIn: https://www.linkedin.com/in/dbtsai


On Mon, Sep 29, 2014 at 11:45 AM, Yanbo Liang <yanbohappy@gmail.com> wrote:
> Thank you for all your patient response.
>
> I can conclude that if the data is totally separable or over-fit occurs,
> weights may be different.
> And it also consistent with my experiment.
>
> I have evaluate two different dataset and the result as followed:
> Loss function: LogisticGradient
> Regularizer: L2
> regParam: 1.0
> numIterations: 10000 (SGD)
>
> Dataset 1: spark-1.1.0/data/mllib/sample_binary_classification_data.txt
> # of classes: 2
> # of samples: 100
> # of features: 692
> areaUnderROC of both SGD and LBFGS can reach nearly 1.0
> Loss function of both optimization method converge nearly
> 1.7147811767900675E-5 (very very small)
> Weights of each optimization method is different but looks like multiple
> relationship (not very strict) just as what DB Tsai mention above.  It might
> be the dataset is totally separable.
>
> Dataset 2:
> http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#german.numer
> # of classes: 2
> # of samples: 1000
> # of features: 24
> areaUnderROC of both SGD and LBFGS both are nearly 0.8
> Loss function of both optimization method converge nearly 0.5367041390107519
> Weights of each optimization method is just the same.
>
>
>
> 2014-09-29 16:05 GMT+08:00 DB Tsai <dbtsai@dbtsai.com>:
>>
>> Can you check the loss of both LBFGS and SGD implementation? One
>> reason maybe SGD doesn't converge well and you can see that by
>> comparing both log-likelihoods. One other potential reason maybe the
>> label of your training data is totally separable, so you can always
>> increase the log-likelihood by multiply a constant to the weights.
>>
>> Sincerely,
>>
>> DB Tsai
>> -------------------------------------------------------
>> My Blog: https://www.dbtsai.com
>> LinkedIn: https://www.linkedin.com/in/dbtsai
>>
>>
>> On Sun, Sep 28, 2014 at 11:48 AM, Yanbo Liang <yanbohappy@gmail.com>
>> wrote:
>> > Hi
>> >
>> > We have used LogisticRegression with two different optimization method
>> > SGD
>> > and LBFGS in MLlib.
>> > With the same dataset and the same training and test split, but get
>> > different weights vector.
>> >
>> > For example, we use
>> > spark-1.1.0/data/mllib/sample_binary_classification_data.txt as our
>> > training
>> > and test dataset.
>> > With LogisticRegressionWithSGD and LogisticRegressionWithLBFGS as
>> > training
>> > method and the same other parameters.
>> >
>> > The precisions of these two methods almost near 100% and AUCs are also
>> > near
>> > 1.0.
>> > As far as I know, the convex optimization problem will converge to the
>> > global minimum value. (We use SGD with mini batch fraction as 1.0)
>> > But I got two different weights vector? Is this expectation or make
>> > sense?
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9747-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 18:14:51 2014
Return-Path: <dev-return-9747-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AF342177B2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 18:14:51 +0000 (UTC)
Received: (qmail 23656 invoked by uid 500); 9 Oct 2014 18:14:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23591 invoked by uid 500); 9 Oct 2014 18:14:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 72610 invoked by uid 99); 9 Oct 2014 14:11:22 -0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yana.kadiyska@gmail.com does not designate 216.139.236.26 as permitted sender)
Date: Thu, 9 Oct 2014 07:10:57 -0700 (PDT)
From: Yana <yana.kadiyska@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1412863857647-8717.post@n3.nabble.com>
Subject: Trouble running tests
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi, apologies if I missed a FAQ somewhere.

I am trying to submit a bug fix for the very first time. Reading
instructions, I forked the git repo (at
c9ae79fba25cd49ca70ca398bc75434202d26a97) and am trying to run tests.

I run this: ./dev/run-tests  _SQL_TESTS_ONLY=true

and after a while get the following error: 

[info] ScalaTest
[info] Run completed in 3 minutes, 37 seconds.
[info] Total number of tests run: 224
[info] Suites: completed 19, aborted 0
[info] Tests: succeeded 224, failed 0, canceled 0, ignored 5, pending 0
[info] All tests passed.
[info] Passed: Total 224, Failed 0, Errors 0, Passed 224, Ignored 5
[success] Total time: 301 s, completed Oct 9, 2014 9:31:23 AM
[error] Expected ID character
[error] Not a valid command: hive-thriftserver
[error] Expected project ID
[error] Expected configuration
[error] Expected ':' (if selecting a configuration)
[error] Expected key
[error] Not a valid key: hive-thriftserver
[error] hive-thriftserver/test
[error]                  ^


(I am running this without my changes)

I have 2 questions:
1. How to fix this
2. Is there a best practice on what to fork so you start off with a "good
state"? I'm wondering if I should sync the latest changes or go back to a
label?

thanks in advance




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Trouble-running-tests-tp8717.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9748-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 18:19:18 2014
Return-Path: <dev-return-9748-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DC8B1177DC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 18:19:18 +0000 (UTC)
Received: (qmail 39430 invoked by uid 500); 9 Oct 2014 18:19:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39364 invoked by uid 500); 9 Oct 2014 18:19:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39348 invoked by uid 99); 9 Oct 2014 18:19:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 18:19:17 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of devl.development@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 18:19:13 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <devl.development@gmail.com>)
	id 1XcIIe-000283-G3
	for dev@spark.incubator.apache.org; Thu, 09 Oct 2014 11:18:52 -0700
Date: Thu, 9 Oct 2014 11:18:52 -0700 (PDT)
From: "devl.development" <devl.development@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1412878732488-8718.post@n3.nabble.com>
Subject: Introduction to Spark Blog
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Spark community

Having spent some time getting up to speed with the various Spark components
in the core package, I've written a blog to help other newcomers and
contributors.

By no means am I a Spark expert so would be grateful for any advice,
comments or edit suggestions. 

Thanks very much here's the post.

http://batchinsights.wordpress.com/2014/10/09/a-short-dive-into-apache-spark/

Dev





--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Introduction-to-Spark-Blog-tp8718.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9749-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 18:42:06 2014
Return-Path: <dev-return-9749-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0BC29178F4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 18:42:06 +0000 (UTC)
Received: (qmail 4438 invoked by uid 500); 9 Oct 2014 18:42:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4373 invoked by uid 500); 9 Oct 2014 18:42:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4361 invoked by uid 99); 9 Oct 2014 18:42:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 18:42:04 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.169 as permitted sender)
Received: from [209.85.212.169] (HELO mail-wi0-f169.google.com) (209.85.212.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 18:41:38 +0000
Received: by mail-wi0-f169.google.com with SMTP id cc10so2293102wib.2
        for <dev@spark.incubator.apache.org>; Thu, 09 Oct 2014 11:41:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=jSHTYM/Yi2MZDGCQYkunNSvRwBNwTrTcZiIW9vOlG3Y=;
        b=uJeyHZNaX7ebynPnvz64S+Jd5274TbFDF3nXz5gQAOjteKqLHEbdL92uBowiGklKpj
         /8ceAqB1ZbKFGwI0OLJVVahAropwaxN5wL+USRczH/MmkIGVCrZQDt5qpYCoEA5kNs0Q
         HiwOrL39dEd5j8f8aTWNpaDGjrVs/uC7NsZUQSW/JTMpQF8EJbViEulPII+blzn5inrR
         jNWHoiqUzI/Z9ebotwqvx30AcFILvnIx1CzgTBj90ZiQEVjm9p+m+9WplddZbbx0nLuS
         nEFlC1Gj+J3ieuAQPeMpoFNEP/RLkaXlQal5UHRfI3zVnsJqkXvW4BhiPzqcJ5zY/nLY
         PdyA==
X-Received: by 10.194.209.207 with SMTP id mo15mr19655825wjc.6.1412880097733;
 Thu, 09 Oct 2014 11:41:37 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Thu, 9 Oct 2014 11:40:57 -0700 (PDT)
In-Reply-To: <1412863857647-8717.post@n3.nabble.com>
References: <1412863857647-8717.post@n3.nabble.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 9 Oct 2014 14:40:57 -0400
Message-ID: <CAOhmDzeYHJh2rsZhkPJTUZT0XM=fOFGY8DDz0QJ+YBvUd=ojLg@mail.gmail.com>
Subject: Re: Trouble running tests
To: Yana <yana.kadiyska@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a831455f344050501c83a
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a831455f344050501c83a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

_RUN_SQL_TESTS needs to be true as well. Those two _... variables set get
correctly when tests are run on Jenkins. They=E2=80=99re not meant to be
manipulated directly by testers.

Did you want to run SQL tests only locally? You can try faking being
Jenkins by setting AMPLAB_JENKINS=3Dtrue before calling run-tests. That
should be simpler than futzing with the _... variables.

Nick
=E2=80=8B

On Thu, Oct 9, 2014 at 10:10 AM, Yana <yana.kadiyska@gmail.com> wrote:

> Hi, apologies if I missed a FAQ somewhere.
>
> I am trying to submit a bug fix for the very first time. Reading
> instructions, I forked the git repo (at
> c9ae79fba25cd49ca70ca398bc75434202d26a97) and am trying to run tests.
>
> I run this: ./dev/run-tests  _SQL_TESTS_ONLY=3Dtrue
>
> and after a while get the following error:
>
> [info] ScalaTest
> [info] Run completed in 3 minutes, 37 seconds.
> [info] Total number of tests run: 224
> [info] Suites: completed 19, aborted 0
> [info] Tests: succeeded 224, failed 0, canceled 0, ignored 5, pending 0
> [info] All tests passed.
> [info] Passed: Total 224, Failed 0, Errors 0, Passed 224, Ignored 5
> [success] Total time: 301 s, completed Oct 9, 2014 9:31:23 AM
> [error] Expected ID character
> [error] Not a valid command: hive-thriftserver
> [error] Expected project ID
> [error] Expected configuration
> [error] Expected ':' (if selecting a configuration)
> [error] Expected key
> [error] Not a valid key: hive-thriftserver
> [error] hive-thriftserver/test
> [error]                  ^
>
>
> (I am running this without my changes)
>
> I have 2 questions:
> 1. How to fix this
> 2. Is there a best practice on what to fork so you start off with a "good
> state"? I'm wondering if I should sync the latest changes or go back to a
> label?
>
> thanks in advance
>
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/Trouble-running=
-tests-tp8717.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7b3a831455f344050501c83a--

From dev-return-9750-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 19:10:48 2014
Return-Path: <dev-return-9750-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C74C217A87
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 19:10:48 +0000 (UTC)
Received: (qmail 17287 invoked by uid 500); 9 Oct 2014 19:10:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17219 invoked by uid 500); 9 Oct 2014 19:10:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17198 invoked by uid 99); 9 Oct 2014 19:10:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 19:10:46 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of guillaume.pitel@exensa.com designates 91.121.232.90 as permitted sender)
Received: from [91.121.232.90] (HELO mail.exensa.com) (91.121.232.90)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 19:10:15 +0000
Received: from localhost (localhost [127.0.0.1])
	by mail.exensa.com (Postfix) with ESMTP id 20E89640197
	for <dev@spark.apache.org>; Thu,  9 Oct 2014 19:10:15 +0000 (UTC)
Received: from mail.exensa.com ([127.0.0.1])
	by localhost (mail.exensa.com [127.0.0.1]) (amavisd-new, port 10024)
	with ESMTP id hdIhDYFMt6b7 for <dev@spark.apache.org>;
	Thu,  9 Oct 2014 19:10:15 +0000 (UTC)
Received: from [192.168.1.101] (unknown [89.157.16.79])
	(using TLSv1 with cipher ECDHE-RSA-AES128-SHA (128/128 bits))
	(No client certificate requested)
	by mail.exensa.com (Postfix) with ESMTPSA id ED2076400B0
	for <dev@spark.apache.org>; Thu,  9 Oct 2014 19:10:14 +0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple; d=exensa.com;
	s=default; t=1412881815;
	bh=ebeQ3WUSP63cXqAM+aSHWKuUSD2c4C2F4XJgBYkdKew=;
	h=Date:From:To:Subject:References:In-Reply-To;
	b=rirnSWw2e86YX2X1dFMqwBSWjqCzrFHw5f7/wTTQs1NZAFocjOAxz6fF2S+KYYehL
	 8nO5VGL3LemhKkXdxuBv1sc0+hdvLJPNOpWOL1ddVH9rKsw4XVgk7Y2+MZt+N5e
Message-ID: <5436DDE5.3030705@exensa.com>
Date: Thu, 09 Oct 2014 21:11:33 +0200
From: Guillaume Pitel <guillaume.pitel@exensa.com>
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:24.0) Gecko/20100101 Thunderbird/24.6.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Re: TorrentBroadcast slow performance
References: <5432525A.8040109@exensa.com> <CA+2Pv=jyH-K-cHSu=FzsyQwvrSPUkTbWY=SYJK+5WFH2iB=XNw@mail.gmail.com> <5F5B1AD7-4440-4579-BBE9-55FE7090CB99@gmail.com>
In-Reply-To: <5F5B1AD7-4440-4579-BBE9-55FE7090CB99@gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

Thanks to your answer, we've found the problem. It was on reverse IP 
resolution on the drivers we used (wrong configuration of the local 
bind9). Apparently, not being able to reverse-resolve the IP address of 
the nodes was the culprit of the 10s delay.

We've hit two other secondary problems with TorrentBroadcast though, in 
case you're interested  :

1 - Broadcasting a variable of about 2GB (1.8GB exactly) triggers a 
"java.lang.OutOfMemoryError: Requested array size exceeds VM limit", 
which is not the case with HttpBroadcast (I guess HttpBroadcast splits 
the serialized variable in small chunks)
2 - Memory use of Torrent seems to be higher than Http (i.e. switching 
from Http to Torrent triggers several OOM).

Additionally, a question : while HttpBroadcast stores the broadcast 
pieces on disk (in spark.local.dir/spark-... ), TorrentBroadcast seems 
not to use disk backend storage. Does it mean that HttpBroadcast can 
handle bigger broadcast out of memory ? If so, it's too bad that this 
design choice wasn't used for Torrent.

  That being said, hats off to the people in charge of the broadcast 
unloading wrt the lineage, this stuff works great !

Guillaume


> Maybe there is a firewall issue that makes it slow for your nodes to connect through the IP addresses they're configured with. I see there's this 10 second pause between "Updated info of block broadcast_84_piece1" and "ensureFreeSpace(4194304) called" (where it actually receives the block). HTTP broadcast used only HTTP fetches from the executors to the driver, but TorrentBroadcast has connections between the executors themselves and between executors and the driver over a different port. Where are you running your driver app and nodes?
>
> Matei
>
> On Oct 7, 2014, at 11:42 AM, Davies Liu <davies@databricks.com> wrote:
>
>> Could you create a JIRA for it? maybe it's a regression after
>> https://issues.apache.org/jira/browse/SPARK-3119.
>>
>> We will appreciate that if you could tell how to reproduce it.
>>
>> On Mon, Oct 6, 2014 at 1:27 AM, Guillaume Pitel
>> <guillaume.pitel@exensa.com> wrote:
>>> Hi,
>>>
>>> I've had no answer to this on user@spark.apache.org, so I post it on dev
>>> before filing a JIRA (in case the problem or solution is already identified)
>>>
>>> We've had some performance issues since switching to 1.1.0, and we finally
>>> found the origin : TorrentBroadcast seems to be very slow in our setting
>>> (and it became default with 1.1.0)
>>>
>>> The logs of a 4MB variable with TorrentBroadcast : (15s)
>>>
>>> 14/10/01 15:47:13 INFO storage.MemoryStore: Block broadcast_84_piece1 stored
>>> as bytes in memory (estimated size 171.6 KB, free 7.2 GB)
>>> 14/10/01 15:47:13 INFO storage.BlockManagerMaster: Updated info of block
>>> broadcast_84_piece1
>>> 14/10/01 15:47:23 INFO storage.MemoryStore: ensureFreeSpace(4194304) called
>>> with curMem=1401611984, maxMem=9168696115
>>> 14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84_piece0 stored
>>> as bytes in memory (estimated size 4.0 MB, free 7.2 GB)
>>> 14/10/01 15:47:23 INFO storage.BlockManagerMaster: Updated info of block
>>> broadcast_84_piece0
>>> 14/10/01 15:47:23 INFO broadcast.TorrentBroadcast: Reading broadcast
>>> variable 84 took 15.202260006 s
>>> 14/10/01 15:47:23 INFO storage.MemoryStore: ensureFreeSpace(4371392) called
>>> with curMem=1405806288, maxMem=9168696115
>>> 14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84 stored as
>>> values in memory (estimated size 4.2 MB, free 7.2 GB)
>>>
>>> (notice that a 10s lag happens after the "Updated info of block
>>> broadcast_..." and before the MemoryStore log
>>>
>>> And with HttpBroadcast (0.3s):
>>>
>>> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Started reading broadcast
>>> variable 147
>>> 14/10/01 16:05:58 INFO storage.MemoryStore: ensureFreeSpace(4369376) called
>>> with curMem=1373493232, maxMem=9168696115
>>> 14/10/01 16:05:58 INFO storage.MemoryStore: Block broadcast_147 stored as
>>> values in memory (estimated size 4.2 MB, free 7.3 GB)
>>> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Reading broadcast variable
>>> 147 took 0.320907112 s 14/10/01 16:05:58 INFO storage.BlockManager: Found
>>> block broadcast_147 locally
>>>
>>> Since Torrent is supposed to perform much better than Http, we suspect a
>>> configuration error from our side, but are unable to pin it down. Does
>>> someone have any idea of the origin of the problem ?
>>>
>>> For now we're sticking with the HttpBroadcast workaround.
>>>
>>> Guillaume
>>> --
>>> Guillaume PITEL, Prsident
>>> +33(0)626 222 431
>>>
>>> eXenSa S.A.S.
>>> 41, rue Prier - 92120 Montrouge - FRANCE
>>> Tel +33(0)184 163 677 / Fax +33(0)972 283 705
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9751-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 21:18:37 2014
Return-Path: <dev-return-9751-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3939E17F82
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 21:18:37 +0000 (UTC)
Received: (qmail 74316 invoked by uid 500); 9 Oct 2014 21:18:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74250 invoked by uid 500); 9 Oct 2014 21:18:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74235 invoked by uid 99); 9 Oct 2014 21:18:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 21:18:35 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jym2307@gmail.com designates 209.85.217.176 as permitted sender)
Received: from [209.85.217.176] (HELO mail-lb0-f176.google.com) (209.85.217.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 21:18:10 +0000
Received: by mail-lb0-f176.google.com with SMTP id p9so1893013lbv.21
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 14:18:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=VtnppLQ3sJFRfP8vBzSUJaHMdpu5hOC/2l8nmwSwAC4=;
        b=AG6qRyo94zk6AvnjBOr9N3kw7cDuU6ip3XrJlai4V/CPQQkXIIp3PfJmx7ywCQTKfc
         UVrFFAF0GJnnjI80JBAsr0mP+BSIFUt4CqtsX7tYgQ9NU0hv9J8mNr38OKggte0TR17x
         80bbOGysOPw4RdRuOhkKbw/4vGoffZndlO8gRzp1vflLtoJ+acI/IAHhNwwanDMS00A/
         kFTQRf1NKihDtJ4pYONhHmTSZKuUs9ud4RAgNUpxRIMxwlpFpZaoITlcP3cZb/GfPei4
         tUkLRQfFhfLXeel5j2BZMlgLM5THMvk/jjjA0aqlFOzKI0dJ6iJNQIRyuO0AbC7EERrb
         ZzDg==
MIME-Version: 1.0
X-Received: by 10.152.202.135 with SMTP id ki7mr387968lac.16.1412889489749;
 Thu, 09 Oct 2014 14:18:09 -0700 (PDT)
Received: by 10.112.3.99 with HTTP; Thu, 9 Oct 2014 14:18:09 -0700 (PDT)
In-Reply-To: <54362529.6060705@gmail.com>
References: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>
	<CAN6Vra3oCudcLmVq15zGeKi+ESC11P3V9ENDrEGFhbvAgiNRDQ@mail.gmail.com>
	<CAAsvFPnQ68hkk-=zRySdGci+xhqsiE1Dact_p8PxP+nW3Do18w@mail.gmail.com>
	<CADJKNppACFGWwbKXu30-zmjX3zW7ivCxuuV6iWiN_uu6sqJsXQ@mail.gmail.com>
	<54362529.6060705@gmail.com>
Date: Thu, 9 Oct 2014 14:18:09 -0700
Message-ID: <CADJKNpqjV-WZXTa4AfWE4TX-WOUJek-2h4-wpGk14RsNoeXMDA@mail.gmail.com>
Subject: Re: will/when Spark/SparkSQL will support ORCFile format
From: James Yu <jym2307@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Mark Hamstra <mark@clearstorydata.com>, Evan Chan <velvia.github@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1135fb4224be68050503f843
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1135fb4224be68050503f843
Content-Type: text/plain; charset=ISO-8859-1

For performance, will foreign data format support, same as native ones?

Thanks,
James


On Wed, Oct 8, 2014 at 11:03 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:

> The foreign data source API PR also matters here
> https://www.github.com/apache/spark/pull/2475
>
> Foreign data source like ORC can be added more easily and systematically
> after this PR is merged.
>
> On 10/9/14 8:22 AM, James Yu wrote:
>
>> Thanks Mark! I will keep eye on it.
>>
>> @Evan, I saw people use both format, so I really want to have Spark
>> support
>> ORCFile.
>>
>>
>> On Wed, Oct 8, 2014 at 11:12 AM, Mark Hamstra <mark@clearstorydata.com>
>> wrote:
>>
>>  https://github.com/apache/spark/pull/2576
>>>
>>>
>>>
>>> On Wed, Oct 8, 2014 at 11:01 AM, Evan Chan <velvia.github@gmail.com>
>>> wrote:
>>>
>>>  James,
>>>>
>>>> Michael at the meetup last night said there was some development
>>>> activity around ORCFiles.
>>>>
>>>> I'm curious though, what are the pros and cons of ORCFiles vs Parquet?
>>>>
>>>> On Wed, Oct 8, 2014 at 10:03 AM, James Yu <jym2307@gmail.com> wrote:
>>>>
>>>>> Didn't see anyone asked the question before, but I was wondering if
>>>>>
>>>> anyone
>>>>
>>>>> knows if Spark/SparkSQL will support ORCFile format soon? ORCFile is
>>>>> getting more and more popular hi Hive world.
>>>>>
>>>>> Thanks,
>>>>> James
>>>>>
>>>> ---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>
>>>>
>>>>
>

--001a1135fb4224be68050503f843--

From dev-return-9752-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 21:23:46 2014
Return-Path: <dev-return-9752-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5E29D17FC1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 21:23:46 +0000 (UTC)
Received: (qmail 91490 invoked by uid 500); 9 Oct 2014 21:23:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91423 invoked by uid 500); 9 Oct 2014 21:23:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91412 invoked by uid 99); 9 Oct 2014 21:23:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 21:23:44 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 21:23:40 +0000
Received: by mail-la0-f52.google.com with SMTP id hz20so2029012lab.39
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 14:23:18 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=0cAsHIfn44mYoCHuLDX7OziLWaTNeRM4f5Ffm1Iez7s=;
        b=bzmvlaDYo2CBHr0EJmjUxUudOdypfG3JoRg0jhhgCqXTjQqhxdqoaz0jLvDIoNI6G6
         8KV4kAj6HwxoX2yL5C21LSAiJ1IHBoND233d/nCa8gwmKmh1lX4ImNQQeN0Ic0XlMRb2
         PIUeROq25rbQFpTtD2CezyKipAmRu7xCepi/F/suCR4jO7PiKXgvla9yHfl4Cg9Jt7o2
         j/YRfBVRJ8CRIWDXf9aKXbxOcBSAcvABLLNUk59z8N8jXZa3suos+OF6PS7/pJgZb31l
         2E+0fb31rtYZbxdQTjLbhOJiq3GuryDbuitZ68colHlJSmjNdFzcOzmxjTbUh4XP3DrG
         oRJA==
X-Gm-Message-State: ALoCoQkBHclf1bWYyjQpnYxi9yFqhIRIHNr0adrD5cTZxCOS8KIPeF3giOmq2YtsSZVfFw8n1EXw
X-Received: by 10.152.6.228 with SMTP id e4mr427141laa.12.1412889798070; Thu,
 09 Oct 2014 14:23:18 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.17 with HTTP; Thu, 9 Oct 2014 14:22:58 -0700 (PDT)
In-Reply-To: <CADJKNpqjV-WZXTa4AfWE4TX-WOUJek-2h4-wpGk14RsNoeXMDA@mail.gmail.com>
References: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>
 <CAN6Vra3oCudcLmVq15zGeKi+ESC11P3V9ENDrEGFhbvAgiNRDQ@mail.gmail.com>
 <CAAsvFPnQ68hkk-=zRySdGci+xhqsiE1Dact_p8PxP+nW3Do18w@mail.gmail.com>
 <CADJKNppACFGWwbKXu30-zmjX3zW7ivCxuuV6iWiN_uu6sqJsXQ@mail.gmail.com>
 <54362529.6060705@gmail.com> <CADJKNpqjV-WZXTa4AfWE4TX-WOUJek-2h4-wpGk14RsNoeXMDA@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Thu, 9 Oct 2014 14:22:58 -0700
Message-ID: <CAAswR-7RVSn4OoQFDySdwTxztkERwinGc8VH7UrW=28M7tuYwg@mail.gmail.com>
Subject: Re: will/when Spark/SparkSQL will support ORCFile format
To: James Yu <jym2307@gmail.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Mark Hamstra <mark@clearstorydata.com>, 
	Evan Chan <velvia.github@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013d0f8a856cc20505040a8c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013d0f8a856cc20505040a8c
Content-Type: text/plain; charset=UTF-8

Yes, the foreign sources work is only about exposing a stable set of APIs
for external libraries to link against (to avoid the spark assembly
becoming a dependency mess).  The code path these APIs use will be the same
as that for datasources included in the core spark sql library.

Michael

On Thu, Oct 9, 2014 at 2:18 PM, James Yu <jym2307@gmail.com> wrote:

> For performance, will foreign data format support, same as native ones?
>
> Thanks,
> James
>
>
> On Wed, Oct 8, 2014 at 11:03 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
>
> > The foreign data source API PR also matters here
> > https://www.github.com/apache/spark/pull/2475
> >
> > Foreign data source like ORC can be added more easily and systematically
> > after this PR is merged.
> >
> > On 10/9/14 8:22 AM, James Yu wrote:
> >
> >> Thanks Mark! I will keep eye on it.
> >>
> >> @Evan, I saw people use both format, so I really want to have Spark
> >> support
> >> ORCFile.
> >>
> >>
> >> On Wed, Oct 8, 2014 at 11:12 AM, Mark Hamstra <mark@clearstorydata.com>
> >> wrote:
> >>
> >>  https://github.com/apache/spark/pull/2576
> >>>
> >>>
> >>>
> >>> On Wed, Oct 8, 2014 at 11:01 AM, Evan Chan <velvia.github@gmail.com>
> >>> wrote:
> >>>
> >>>  James,
> >>>>
> >>>> Michael at the meetup last night said there was some development
> >>>> activity around ORCFiles.
> >>>>
> >>>> I'm curious though, what are the pros and cons of ORCFiles vs Parquet?
> >>>>
> >>>> On Wed, Oct 8, 2014 at 10:03 AM, James Yu <jym2307@gmail.com> wrote:
> >>>>
> >>>>> Didn't see anyone asked the question before, but I was wondering if
> >>>>>
> >>>> anyone
> >>>>
> >>>>> knows if Spark/SparkSQL will support ORCFile format soon? ORCFile is
> >>>>> getting more and more popular hi Hive world.
> >>>>>
> >>>>> Thanks,
> >>>>> James
> >>>>>
> >>>> ---------------------------------------------------------------------
> >>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>>> For additional commands, e-mail: dev-help@spark.apache.org
> >>>>
> >>>>
> >>>>
> >
>

--089e013d0f8a856cc20505040a8c--

From dev-return-9753-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 21:27:21 2014
Return-Path: <dev-return-9753-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 62EA917FDE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 21:27:21 +0000 (UTC)
Received: (qmail 9588 invoked by uid 500); 9 Oct 2014 21:27:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9507 invoked by uid 500); 9 Oct 2014 21:27:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9484 invoked by uid 99); 9 Oct 2014 21:27:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 21:27:20 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 21:26:53 +0000
Received: by mail-pa0-f51.google.com with SMTP id lj1so440517pab.24
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 14:26:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=jH1Uwx0ydiXUIIZqiSaNkXx1DsyBWbq24kSi/BGnYXQ=;
        b=azZIGaJIdrq0sCz7RRRMgHhvXx4iV6gQUxd2ChTb2hi+0wzd69a4YIT+HXjr9+xzUG
         oRv0fbkW3IyfWjRDfLuWrrf1MnocQLbUBAkJJCqMnevBdMe0PXwAocVMPl37mKkEGXqc
         MR/tTTEaGKcU1uarI2mQ2UHekjGFbzisUwSmhTkcglxqhExVQaN3tWe2Xa0DQrVIx4jE
         65jyzhIXbzyvmPT8FzYZ/jB52Saf2AZcqr0PysC8ms9eEBCqSVBSHq9cbXqmtR1Eotre
         cViy1uPekggEuUcG7IEe716MWcq6DauZejlTjvbM0UOQX7VGoHzpSTyhOD3GBsYxxnRP
         YRNQ==
X-Received: by 10.68.178.97 with SMTP id cx1mr630176pbc.25.1412890011681;
        Thu, 09 Oct 2014 14:26:51 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id r9sm1401923pdl.60.2014.10.09.14.26.50
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Thu, 09 Oct 2014 14:26:51 -0700 (PDT)
Date: Thu, 9 Oct 2014 14:26:49 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Nathan Kronenfeld <nkronenfeld@oculusinfo.com>, 
 dev@spark.apache.org
Message-ID: <etPan.5436fd99.66334873.ba20@joshs-mbp>
In-Reply-To: <CAEpWh49-gFnnAdrs8vS-gW1+9a3x1MNCX2jzopRnBaTfUmrZhg@mail.gmail.com>
References: <CAEpWh4_TF-CPjnBvyzSnBM3NqXdPb6rfokPSSXZ7JuA7siQefQ@mail.gmail.com>
 <CAEpWh49-gFnnAdrs8vS-gW1+9a3x1MNCX2jzopRnBaTfUmrZhg@mail.gmail.com>
Subject: Re: Fwd: Accumulator question
X-Mailer: Airmail Beta (261)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5436fd99_74b0dc51_ba20"
X-Virus-Checked: Checked by ClamAV on apache.org

--5436fd99_74b0dc51_ba20
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hi Nathan,

You=E2=80=99re right, it looks like we don=E2=80=99t currently provide a =
method to unregister accumulators. =C2=A0I=E2=80=99ve opened a JIRA to di=
scuss a fix:=C2=A0https://issues.apache.org/jira/browse/SPARK-3885

In the meantime, here=E2=80=99s a workaround that might work: =C2=A0Accum=
ulators have a public setValue() method that can be called (only by the d=
river) to change an accumulator=E2=80=99s value. =C2=A0You might be able =
to use this to reset accumulators=E2=80=99 values to smaller objects (e.g=
. the =E2=80=9Czero=E2=80=9D object of whatever your accumulator type is,=
 or =E2=80=98null=E2=80=99 if you=E2=80=99re sure that the accumulator wi=
ll never be accessed again).

Hope this helps,
Josh

On October 8, 2014 at 2:54:33 PM, Nathan Kronenfeld (nkronenfeld=40oculus=
info.com) wrote:

I notice that accumulators register themselves with a private Accumulator=
s =20
object. =20

I don't notice any way to unregister them when one is done. =20

Am I missing something=3F If not, is there any plan for how to free up th=
at =20
memory=3F =20

I've a case where we're gathering data from repeated queries using some =20
relatively sizable accumulators; at the moment, we're creating one per =20
query, and running out of memory after far too few queries. =20

I've tried methods that don't involve accumulators; they involve a shuffl=
e =20
instead, and take 10x as long. =20

Thanks, =20
-Nathan =20




-- =20
Nathan Kronenfeld =20
Senior Visualization Developer =20
Oculus Info Inc =20
2 Berkeley Street, Suite 600, =20
Toronto, Ontario M5A 4J5 =20
Phone: +1-416-203-3003 x 238 =20
Email: nkronenfeld=40oculusinfo.com =20

--5436fd99_74b0dc51_ba20--


From dev-return-9754-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 21:27:43 2014
Return-Path: <dev-return-9754-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DE12217FF5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 21:27:42 +0000 (UTC)
Received: (qmail 13686 invoked by uid 500); 9 Oct 2014 21:27:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13621 invoked by uid 500); 9 Oct 2014 21:27:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13609 invoked by uid 99); 9 Oct 2014 21:27:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 21:27:41 +0000
X-ASF-Spam-Status: No, hits=3.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.217.169] (HELO mail-lb0-f169.google.com) (209.85.217.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 21:27:15 +0000
Received: by mail-lb0-f169.google.com with SMTP id 10so1992572lbg.0
        for <dev@spark.incubator.apache.org>; Thu, 09 Oct 2014 14:27:14 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=fNnCAi8wQSo8gnf2JLM5HK5GPVXBn7jAgOcODNEqcF4=;
        b=UjaQ9YJj+qt4XPAiPiUduADljiK+BZ6nxFyamQeDdSCNzhl9HLaKJDQHu2f4ClxoMl
         PJdMOdufJTr2zvQiynmmyabhEcSo30qBo61sC0fjQaTZ38cXqyTfIvEawPMxfanON9ri
         71rLj/KoiKQEoB4X+WMwF/gHAYezokOmfH7uhWfmOuRCpsKbFuxHiQbY3vdGPXxQPxl7
         OCfL74l024h+s3K32muUhH1XJpdySdjzTHYMOwXg7g+hTRF0tHt4OnN07smJk9/Kl5Y9
         LEHyWouudzGUf0Kahdwee/n6MwME7ct87oLtDYT1SrqinTUibAZrvpkeh2hc4NsqXvRX
         wzSg==
X-Gm-Message-State: ALoCoQlEKQIJnVzbP3z28TISIv0MWJkH61bS/k2lyy0Cbi1MSN6vXV4k6p5GoAAQwTtP9G7Is+v+
X-Received: by 10.112.52.74 with SMTP id r10mr117149lbo.3.1412890033676; Thu,
 09 Oct 2014 14:27:13 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.17 with HTTP; Thu, 9 Oct 2014 14:26:53 -0700 (PDT)
In-Reply-To: <CAOhmDzeYHJh2rsZhkPJTUZT0XM=fOFGY8DDz0QJ+YBvUd=ojLg@mail.gmail.com>
References: <1412863857647-8717.post@n3.nabble.com> <CAOhmDzeYHJh2rsZhkPJTUZT0XM=fOFGY8DDz0QJ+YBvUd=ojLg@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Thu, 9 Oct 2014 14:26:53 -0700
Message-ID: <CAAswR-6j-3qswZmENuZuDkkRDkwHfDgt5ssT0wUXbQP4SNcDWg@mail.gmail.com>
Subject: Re: Trouble running tests
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Yana <yana.kadiyska@gmail.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3f8aa90794d05050418d8
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3f8aa90794d05050418d8
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Also, in general for SQL only changes it is sufficient to run "sbt/sbt
catatlyst/test sql/test hive/test".  The "hive/test" part takes the
longest, so I usually leave that out until just before submitting unless my
changes are hive specific.

On Thu, Oct 9, 2014 at 11:40 AM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> _RUN_SQL_TESTS needs to be true as well. Those two _... variables set get
> correctly when tests are run on Jenkins. They=E2=80=99re not meant to be
> manipulated directly by testers.
>
> Did you want to run SQL tests only locally? You can try faking being
> Jenkins by setting AMPLAB_JENKINS=3Dtrue before calling run-tests. That
> should be simpler than futzing with the _... variables.
>
> Nick
> =E2=80=8B
>
> On Thu, Oct 9, 2014 at 10:10 AM, Yana <yana.kadiyska@gmail.com> wrote:
>
> > Hi, apologies if I missed a FAQ somewhere.
> >
> > I am trying to submit a bug fix for the very first time. Reading
> > instructions, I forked the git repo (at
> > c9ae79fba25cd49ca70ca398bc75434202d26a97) and am trying to run tests.
> >
> > I run this: ./dev/run-tests  _SQL_TESTS_ONLY=3Dtrue
> >
> > and after a while get the following error:
> >
> > [info] ScalaTest
> > [info] Run completed in 3 minutes, 37 seconds.
> > [info] Total number of tests run: 224
> > [info] Suites: completed 19, aborted 0
> > [info] Tests: succeeded 224, failed 0, canceled 0, ignored 5, pending 0
> > [info] All tests passed.
> > [info] Passed: Total 224, Failed 0, Errors 0, Passed 224, Ignored 5
> > [success] Total time: 301 s, completed Oct 9, 2014 9:31:23 AM
> > [error] Expected ID character
> > [error] Not a valid command: hive-thriftserver
> > [error] Expected project ID
> > [error] Expected configuration
> > [error] Expected ':' (if selecting a configuration)
> > [error] Expected key
> > [error] Not a valid key: hive-thriftserver
> > [error] hive-thriftserver/test
> > [error]                  ^
> >
> >
> > (I am running this without my changes)
> >
> > I have 2 questions:
> > 1. How to fix this
> > 2. Is there a best practice on what to fork so you start off with a "go=
od
> > state"? I'm wondering if I should sync the latest changes or go back to=
 a
> > label?
> >
> > thanks in advance
> >
> >
> >
> >
> > --
> > View this message in context:
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/Trouble-running=
-tests-tp8717.html
> > Sent from the Apache Spark Developers List mailing list archive at
> > Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--001a11c3f8aa90794d05050418d8--

From dev-return-9755-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 22:04:55 2014
Return-Path: <dev-return-9755-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8510A17353
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 22:04:55 +0000 (UTC)
Received: (qmail 12097 invoked by uid 500); 9 Oct 2014 22:04:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12024 invoked by uid 500); 9 Oct 2014 22:04:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12012 invoked by uid 99); 9 Oct 2014 22:04:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 22:04:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.170 as permitted sender)
Received: from [209.85.192.170] (HELO mail-pd0-f170.google.com) (209.85.192.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 22:04:28 +0000
Received: by mail-pd0-f170.google.com with SMTP id p10so469180pdj.29
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 15:04:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=/DagZjrh1SmB1DCcdTne0vahT4qKzCC5xPnc6d0Hp/E=;
        b=EdU8Z/9zrfq4DK+C1ZKTlciRhgwsiKCo9F2wu2xqqUkuBiRZ1oi6VBXGfh/m03vmGE
         jvrzXWG02xKMUlp/PAF66ZueUy07cvUa3frO4JbwQQT6hAGTdqyVsTsMzUDibYir8Tbe
         B43YXeK87oijGVYp7xPyBbYxEXr/yYscN6Pg9ZjnsG3oxFeljPiETLGFA6UFsOg8pkfn
         4um+cfKtvT0KlzxfZbA4fmvwxRpkGp+Gct0K263mZRKLmr2AxSn2PyZjJFr3OC9NC4I+
         nI6eJxcea8nC8Qty2+fqC+S38q8l/WzvdRjQz9gaN4sXNm7FxqXY6eLqb8k0dH8D0Kyk
         rvVg==
X-Received: by 10.68.231.228 with SMTP id tj4mr837273pbc.126.1412892266308;
        Thu, 09 Oct 2014 15:04:26 -0700 (PDT)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id 16sm1468423pdj.42.2014.10.09.15.04.25
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 09 Oct 2014 15:04:25 -0700 (PDT)
Content-Type: multipart/alternative; boundary="Apple-Mail=_F56DE824-6F31-4361-88EB-090789C27C01"
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: TorrentBroadcast slow performance
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <5436DDE5.3030705@exensa.com>
Date: Thu, 9 Oct 2014 15:04:23 -0700
Cc: dev@spark.apache.org
Message-Id: <9BEADFEC-C81D-4C8D-BEC4-1C92BD13D8B5@gmail.com>
References: <5432525A.8040109@exensa.com> <CA+2Pv=jyH-K-cHSu=FzsyQwvrSPUkTbWY=SYJK+5WFH2iB=XNw@mail.gmail.com> <5F5B1AD7-4440-4579-BBE9-55FE7090CB99@gmail.com> <5436DDE5.3030705@exensa.com>
To: Guillaume Pitel <guillaume.pitel@exensa.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_F56DE824-6F31-4361-88EB-090789C27C01
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=iso-8859-1

Thanks for the feedback. For 1, there is an open patch: =
https://github.com/apache/spark/pull/2659. For 2, broadcast blocks =
actually use MEMORY_AND_DISK storage, so they will spill to disk if you =
have low memory, but they're faster to access otherwise.

Matei

On Oct 9, 2014, at 12:11 PM, Guillaume Pitel =
<guillaume.pitel@exensa.com> wrote:

> Hi,
>=20
> Thanks to your answer, we've found the problem. It was on reverse IP =
resolution on the drivers we used (wrong configuration of the local =
bind9). Apparently, not being able to reverse-resolve the IP address of =
the nodes was the culprit of the 10s delay.
>=20
> We've hit two other secondary problems with TorrentBroadcast though, =
in case you're interested  :
>=20
> 1 - Broadcasting a variable of about 2GB (1.8GB exactly) triggers a =
"java.lang.OutOfMemoryError: Requested array size exceeds VM limit", =
which is not the case with HttpBroadcast (I guess HttpBroadcast splits =
the serialized variable in small chunks)
> 2 - Memory use of Torrent seems to be higher than Http (i.e. switching =
from Http to Torrent triggers several OOM).
>=20
> Additionally, a question : while HttpBroadcast stores the broadcast =
pieces on disk (in spark.local.dir/spark-... ), TorrentBroadcast seems =
not to use disk backend storage. Does it mean that HttpBroadcast can =
handle bigger broadcast out of memory ? If so, it's too bad that this =
design choice wasn't used for Torrent.
>=20
> That being said, hats off to the people in charge of the broadcast =
unloading wrt the lineage, this stuff works great !
>=20
> Guillaume
>=20
>=20
>> Maybe there is a firewall issue that makes it slow for your nodes to =
connect through the IP addresses they're configured with. I see there's =
this 10 second pause between "Updated info of block broadcast_84_piece1" =
and "ensureFreeSpace(4194304) called" (where it actually receives the =
block). HTTP broadcast used only HTTP fetches from the executors to the =
driver, but TorrentBroadcast has connections between the executors =
themselves and between executors and the driver over a different port. =
Where are you running your driver app and nodes?
>>=20
>> Matei
>>=20
>> On Oct 7, 2014, at 11:42 AM, Davies Liu <davies@databricks.com> =
wrote:
>>=20
>>> Could you create a JIRA for it? maybe it's a regression after
>>> https://issues.apache.org/jira/browse/SPARK-3119.
>>>=20
>>> We will appreciate that if you could tell how to reproduce it.
>>>=20
>>> On Mon, Oct 6, 2014 at 1:27 AM, Guillaume Pitel
>>> <guillaume.pitel@exensa.com> wrote:
>>>> Hi,
>>>>=20
>>>> I've had no answer to this on user@spark.apache.org, so I post it =
on dev
>>>> before filing a JIRA (in case the problem or solution is already =
identified)
>>>>=20
>>>> We've had some performance issues since switching to 1.1.0, and we =
finally
>>>> found the origin : TorrentBroadcast seems to be very slow in our =
setting
>>>> (and it became default with 1.1.0)
>>>>=20
>>>> The logs of a 4MB variable with TorrentBroadcast : (15s)
>>>>=20
>>>> 14/10/01 15:47:13 INFO storage.MemoryStore: Block =
broadcast_84_piece1 stored
>>>> as bytes in memory (estimated size 171.6 KB, free 7.2 GB)
>>>> 14/10/01 15:47:13 INFO storage.BlockManagerMaster: Updated info of =
block
>>>> broadcast_84_piece1
>>>> 14/10/01 15:47:23 INFO storage.MemoryStore: =
ensureFreeSpace(4194304) called
>>>> with curMem=3D1401611984, maxMem=3D9168696115
>>>> 14/10/01 15:47:23 INFO storage.MemoryStore: Block =
broadcast_84_piece0 stored
>>>> as bytes in memory (estimated size 4.0 MB, free 7.2 GB)
>>>> 14/10/01 15:47:23 INFO storage.BlockManagerMaster: Updated info of =
block
>>>> broadcast_84_piece0
>>>> 14/10/01 15:47:23 INFO broadcast.TorrentBroadcast: Reading =
broadcast
>>>> variable 84 took 15.202260006 s
>>>> 14/10/01 15:47:23 INFO storage.MemoryStore: =
ensureFreeSpace(4371392) called
>>>> with curMem=3D1405806288, maxMem=3D9168696115
>>>> 14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84 =
stored as
>>>> values in memory (estimated size 4.2 MB, free 7.2 GB)
>>>>=20
>>>> (notice that a 10s lag happens after the "Updated info of block
>>>> broadcast_..." and before the MemoryStore log
>>>>=20
>>>> And with HttpBroadcast (0.3s):
>>>>=20
>>>> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Started reading =
broadcast
>>>> variable 147
>>>> 14/10/01 16:05:58 INFO storage.MemoryStore: =
ensureFreeSpace(4369376) called
>>>> with curMem=3D1373493232, maxMem=3D9168696115
>>>> 14/10/01 16:05:58 INFO storage.MemoryStore: Block broadcast_147 =
stored as
>>>> values in memory (estimated size 4.2 MB, free 7.3 GB)
>>>> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Reading broadcast =
variable
>>>> 147 took 0.320907112 s 14/10/01 16:05:58 INFO storage.BlockManager: =
Found
>>>> block broadcast_147 locally
>>>>=20
>>>> Since Torrent is supposed to perform much better than Http, we =
suspect a
>>>> configuration error from our side, but are unable to pin it down. =
Does
>>>> someone have any idea of the origin of the problem ?
>>>>=20
>>>> For now we're sticking with the HttpBroadcast workaround.
>>>>=20
>>>> Guillaume
>>>> --
>>>> Guillaume PITEL, Pr=E9sident
>>>> +33(0)626 222 431
>>>>=20
>>>> eXenSa S.A.S.
>>>> 41, rue P=E9rier - 92120 Montrouge - FRANCE
>>>> Tel +33(0)184 163 677 / Fax +33(0)972 283 705
>>> =
---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>=20
>>=20
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20
>=20
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


--Apple-Mail=_F56DE824-6F31-4361-88EB-090789C27C01--

From dev-return-9756-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 22:07:59 2014
Return-Path: <dev-return-9756-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6F62217371
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 22:07:59 +0000 (UTC)
Received: (qmail 22239 invoked by uid 500); 9 Oct 2014 22:07:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22170 invoked by uid 500); 9 Oct 2014 22:07:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22158 invoked by uid 99); 9 Oct 2014 22:07:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 22:07:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 22:07:32 +0000
Received: by mail-pa0-f51.google.com with SMTP id lj1so497256pab.10
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 15:07:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=OHVUkoIgS32e5Mk0KuNwG44Lie+Rbvri2ZzcHNrd0+0=;
        b=XIkOq97h5OwpfFyYssQRpv7IduWxYwZzyzWemutV1nWVSruHVByCZvy1ws7JWmeE21
         iF/SiJQFT8M0dYu4XJ1FldiM5L0f7vET51plnGQZrY4V3nqfcEn8718CJFyCGmy/yg1t
         W3yt3xuutT1CLU3T4oQcOdKfIhUJcLP88ewIUrO4/mfGBgcUwaoRnTNZBhxehA9r+8JN
         XL3nwfrEyNqRvyMhw+CQlalXXHz4ExAIO+8tMlJHDMNbAZhZzl6ghlAH9zYcWa00z3zz
         Xef0CArE7FMVCOSkhqWb2Ne4se5CEEZZQYHeyQatcEkzV+6/n9uH33zqbqozouBCvS/m
         QiCQ==
X-Received: by 10.66.149.97 with SMTP id tz1mr720066pab.113.1412892450385;
        Thu, 09 Oct 2014 15:07:30 -0700 (PDT)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id x7sm1478290pdj.36.2014.10.09.15.07.29
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 09 Oct 2014 15:07:29 -0700 (PDT)
Content-Type: multipart/alternative; boundary="Apple-Mail=_D6951EB9-6C6D-4BD7-988D-4265B763938B"
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: TorrentBroadcast slow performance
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <9BEADFEC-C81D-4C8D-BEC4-1C92BD13D8B5@gmail.com>
Date: Thu, 9 Oct 2014 15:07:27 -0700
Cc: dev@spark.apache.org
Message-Id: <94615618-BE67-4784-8AF5-621209DD3E39@gmail.com>
References: <5432525A.8040109@exensa.com> <CA+2Pv=jyH-K-cHSu=FzsyQwvrSPUkTbWY=SYJK+5WFH2iB=XNw@mail.gmail.com> <5F5B1AD7-4440-4579-BBE9-55FE7090CB99@gmail.com> <5436DDE5.3030705@exensa.com> <9BEADFEC-C81D-4C8D-BEC4-1C92BD13D8B5@gmail.com>
To: Guillaume Pitel <guillaume.pitel@exensa.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_D6951EB9-6C6D-4BD7-988D-4265B763938B
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=iso-8859-1

Oops I forgot to add, for 2, maybe we can add a flag to use DISK_ONLY =
for TorrentBroadcast, or if the broadcasts are bigger than some size.

Matei

On Oct 9, 2014, at 3:04 PM, Matei Zaharia <matei.zaharia@gmail.com> =
wrote:

> Thanks for the feedback. For 1, there is an open patch: =
https://github.com/apache/spark/pull/2659. For 2, broadcast blocks =
actually use MEMORY_AND_DISK storage, so they will spill to disk if you =
have low memory, but they're faster to access otherwise.
>=20
> Matei
>=20
> On Oct 9, 2014, at 12:11 PM, Guillaume Pitel =
<guillaume.pitel@exensa.com> wrote:
>=20
>> Hi,
>>=20
>> Thanks to your answer, we've found the problem. It was on reverse IP =
resolution on the drivers we used (wrong configuration of the local =
bind9). Apparently, not being able to reverse-resolve the IP address of =
the nodes was the culprit of the 10s delay.
>>=20
>> We've hit two other secondary problems with TorrentBroadcast though, =
in case you're interested  :
>>=20
>> 1 - Broadcasting a variable of about 2GB (1.8GB exactly) triggers a =
"java.lang.OutOfMemoryError: Requested array size exceeds VM limit", =
which is not the case with HttpBroadcast (I guess HttpBroadcast splits =
the serialized variable in small chunks)
>> 2 - Memory use of Torrent seems to be higher than Http (i.e. =
switching from Http to Torrent triggers several OOM).
>>=20
>> Additionally, a question : while HttpBroadcast stores the broadcast =
pieces on disk (in spark.local.dir/spark-... ), TorrentBroadcast seems =
not to use disk backend storage. Does it mean that HttpBroadcast can =
handle bigger broadcast out of memory ? If so, it's too bad that this =
design choice wasn't used for Torrent.
>>=20
>> That being said, hats off to the people in charge of the broadcast =
unloading wrt the lineage, this stuff works great !
>>=20
>> Guillaume
>>=20
>>=20
>>> Maybe there is a firewall issue that makes it slow for your nodes to =
connect through the IP addresses they're configured with. I see there's =
this 10 second pause between "Updated info of block broadcast_84_piece1" =
and "ensureFreeSpace(4194304) called" (where it actually receives the =
block). HTTP broadcast used only HTTP fetches from the executors to the =
driver, but TorrentBroadcast has connections between the executors =
themselves and between executors and the driver over a different port. =
Where are you running your driver app and nodes?
>>>=20
>>> Matei
>>>=20
>>> On Oct 7, 2014, at 11:42 AM, Davies Liu <davies@databricks.com> =
wrote:
>>>=20
>>>> Could you create a JIRA for it? maybe it's a regression after
>>>> https://issues.apache.org/jira/browse/SPARK-3119.
>>>>=20
>>>> We will appreciate that if you could tell how to reproduce it.
>>>>=20
>>>> On Mon, Oct 6, 2014 at 1:27 AM, Guillaume Pitel
>>>> <guillaume.pitel@exensa.com> wrote:
>>>>> Hi,
>>>>>=20
>>>>> I've had no answer to this on user@spark.apache.org, so I post it =
on dev
>>>>> before filing a JIRA (in case the problem or solution is already =
identified)
>>>>>=20
>>>>> We've had some performance issues since switching to 1.1.0, and we =
finally
>>>>> found the origin : TorrentBroadcast seems to be very slow in our =
setting
>>>>> (and it became default with 1.1.0)
>>>>>=20
>>>>> The logs of a 4MB variable with TorrentBroadcast : (15s)
>>>>>=20
>>>>> 14/10/01 15:47:13 INFO storage.MemoryStore: Block =
broadcast_84_piece1 stored
>>>>> as bytes in memory (estimated size 171.6 KB, free 7.2 GB)
>>>>> 14/10/01 15:47:13 INFO storage.BlockManagerMaster: Updated info of =
block
>>>>> broadcast_84_piece1
>>>>> 14/10/01 15:47:23 INFO storage.MemoryStore: =
ensureFreeSpace(4194304) called
>>>>> with curMem=3D1401611984, maxMem=3D9168696115
>>>>> 14/10/01 15:47:23 INFO storage.MemoryStore: Block =
broadcast_84_piece0 stored
>>>>> as bytes in memory (estimated size 4.0 MB, free 7.2 GB)
>>>>> 14/10/01 15:47:23 INFO storage.BlockManagerMaster: Updated info of =
block
>>>>> broadcast_84_piece0
>>>>> 14/10/01 15:47:23 INFO broadcast.TorrentBroadcast: Reading =
broadcast
>>>>> variable 84 took 15.202260006 s
>>>>> 14/10/01 15:47:23 INFO storage.MemoryStore: =
ensureFreeSpace(4371392) called
>>>>> with curMem=3D1405806288, maxMem=3D9168696115
>>>>> 14/10/01 15:47:23 INFO storage.MemoryStore: Block broadcast_84 =
stored as
>>>>> values in memory (estimated size 4.2 MB, free 7.2 GB)
>>>>>=20
>>>>> (notice that a 10s lag happens after the "Updated info of block
>>>>> broadcast_..." and before the MemoryStore log
>>>>>=20
>>>>> And with HttpBroadcast (0.3s):
>>>>>=20
>>>>> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Started reading =
broadcast
>>>>> variable 147
>>>>> 14/10/01 16:05:58 INFO storage.MemoryStore: =
ensureFreeSpace(4369376) called
>>>>> with curMem=3D1373493232, maxMem=3D9168696115
>>>>> 14/10/01 16:05:58 INFO storage.MemoryStore: Block broadcast_147 =
stored as
>>>>> values in memory (estimated size 4.2 MB, free 7.3 GB)
>>>>> 14/10/01 16:05:58 INFO broadcast.HttpBroadcast: Reading broadcast =
variable
>>>>> 147 took 0.320907112 s 14/10/01 16:05:58 INFO =
storage.BlockManager: Found
>>>>> block broadcast_147 locally
>>>>>=20
>>>>> Since Torrent is supposed to perform much better than Http, we =
suspect a
>>>>> configuration error from our side, but are unable to pin it down. =
Does
>>>>> someone have any idea of the origin of the problem ?
>>>>>=20
>>>>> For now we're sticking with the HttpBroadcast workaround.
>>>>>=20
>>>>> Guillaume
>>>>> --
>>>>> Guillaume PITEL, Pr=E9sident
>>>>> +33(0)626 222 431
>>>>>=20
>>>>> eXenSa S.A.S.
>>>>> 41, rue P=E9rier - 92120 Montrouge - FRANCE
>>>>> Tel +33(0)184 163 677 / Fax +33(0)972 283 705
>>>> =
---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>=20
>>>=20
>>> =
---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>=20
>>=20
>>=20
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20
>=20


--Apple-Mail=_D6951EB9-6C6D-4BD7-988D-4265B763938B--

From dev-return-9757-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct  9 23:46:59 2014
Return-Path: <dev-return-9757-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E223D1767F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu,  9 Oct 2014 23:46:58 +0000 (UTC)
Received: (qmail 57245 invoked by uid 500); 9 Oct 2014 23:46:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57170 invoked by uid 500); 9 Oct 2014 23:46:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57157 invoked by uid 99); 9 Oct 2014 23:46:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 23:46:57 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jym2307@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 09 Oct 2014 23:46:32 +0000
Received: by mail-la0-f51.google.com with SMTP id ge10so2193784lab.38
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 16:46:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=yoWoxCSz4clOk4pthkvy4zm5GGWJ6/HUD6+KNTO4p1w=;
        b=q77Wl07yALY1AUV2wy0C0lpSYmdwaL1/IqFcuHiISWHuUuCK///Uvy6FKZB0LMlQDl
         BXT+H6LqsvFvDlREcAMgq7m4I1Gz6PFL3KViF2fuNYgyClsvkODz6dCVQS0Y618i+Lqi
         0wKil4s9SAThjqfZbI0Sz14R/mxrAQhHOUZINlnSQh6fMCNH1mrl2eHCi+Zh7Z5yCcik
         Q8SsbludmNK0fqKbWom2ZSDspjzGAMEOxYOwuojSHbI433w1It5bTsi/law9XPFbqdmh
         tYIJXI3iQpw5KzuBGoxA3F/kW5hd2Vnd2N7SfXpDgeCWuZ0f/Mk7e6Qwoie2Ete9IGJy
         a62Q==
MIME-Version: 1.0
X-Received: by 10.112.243.43 with SMTP id wv11mr525908lbc.95.1412898391260;
 Thu, 09 Oct 2014 16:46:31 -0700 (PDT)
Received: by 10.112.3.99 with HTTP; Thu, 9 Oct 2014 16:46:31 -0700 (PDT)
In-Reply-To: <CAAswR-7RVSn4OoQFDySdwTxztkERwinGc8VH7UrW=28M7tuYwg@mail.gmail.com>
References: <CADJKNpqZhO0NPEQzD14ow7i4k3gwUajJp==Xm9r_8FW9OqTLbQ@mail.gmail.com>
	<CAN6Vra3oCudcLmVq15zGeKi+ESC11P3V9ENDrEGFhbvAgiNRDQ@mail.gmail.com>
	<CAAsvFPnQ68hkk-=zRySdGci+xhqsiE1Dact_p8PxP+nW3Do18w@mail.gmail.com>
	<CADJKNppACFGWwbKXu30-zmjX3zW7ivCxuuV6iWiN_uu6sqJsXQ@mail.gmail.com>
	<54362529.6060705@gmail.com>
	<CADJKNpqjV-WZXTa4AfWE4TX-WOUJek-2h4-wpGk14RsNoeXMDA@mail.gmail.com>
	<CAAswR-7RVSn4OoQFDySdwTxztkERwinGc8VH7UrW=28M7tuYwg@mail.gmail.com>
Date: Thu, 9 Oct 2014 16:46:31 -0700
Message-ID: <CADJKNpoW4tBCJdsddqp4AJP+SFyoWy-M7uLJ6OaD14wXAQP9Vw@mail.gmail.com>
Subject: Re: will/when Spark/SparkSQL will support ORCFile format
From: James Yu <jym2307@gmail.com>
To: Michael Armbrust <michael@databricks.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Mark Hamstra <mark@clearstorydata.com>, 
	Evan Chan <velvia.github@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11345c0ab705c90505060a77
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11345c0ab705c90505060a77
Content-Type: text/plain; charset=ISO-8859-1

Sounds great, thanks!



On Thu, Oct 9, 2014 at 2:22 PM, Michael Armbrust <michael@databricks.com>
wrote:

> Yes, the foreign sources work is only about exposing a stable set of APIs
> for external libraries to link against (to avoid the spark assembly
> becoming a dependency mess).  The code path these APIs use will be the same
> as that for datasources included in the core spark sql library.
>
> Michael
>
> On Thu, Oct 9, 2014 at 2:18 PM, James Yu <jym2307@gmail.com> wrote:
>
>> For performance, will foreign data format support, same as native ones?
>>
>> Thanks,
>> James
>>
>>
>> On Wed, Oct 8, 2014 at 11:03 PM, Cheng Lian <lian.cs.zju@gmail.com>
>> wrote:
>>
>> > The foreign data source API PR also matters here
>> > https://www.github.com/apache/spark/pull/2475
>> >
>> > Foreign data source like ORC can be added more easily and systematically
>> > after this PR is merged.
>> >
>> > On 10/9/14 8:22 AM, James Yu wrote:
>> >
>> >> Thanks Mark! I will keep eye on it.
>> >>
>> >> @Evan, I saw people use both format, so I really want to have Spark
>> >> support
>> >> ORCFile.
>> >>
>> >>
>> >> On Wed, Oct 8, 2014 at 11:12 AM, Mark Hamstra <mark@clearstorydata.com
>> >
>> >> wrote:
>> >>
>> >>  https://github.com/apache/spark/pull/2576
>> >>>
>> >>>
>> >>>
>> >>> On Wed, Oct 8, 2014 at 11:01 AM, Evan Chan <velvia.github@gmail.com>
>> >>> wrote:
>> >>>
>> >>>  James,
>> >>>>
>> >>>> Michael at the meetup last night said there was some development
>> >>>> activity around ORCFiles.
>> >>>>
>> >>>> I'm curious though, what are the pros and cons of ORCFiles vs
>> Parquet?
>> >>>>
>> >>>> On Wed, Oct 8, 2014 at 10:03 AM, James Yu <jym2307@gmail.com> wrote:
>> >>>>
>> >>>>> Didn't see anyone asked the question before, but I was wondering if
>> >>>>>
>> >>>> anyone
>> >>>>
>> >>>>> knows if Spark/SparkSQL will support ORCFile format soon? ORCFile is
>> >>>>> getting more and more popular hi Hive world.
>> >>>>>
>> >>>>> Thanks,
>> >>>>> James
>> >>>>>
>> >>>> ---------------------------------------------------------------------
>> >>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >>>> For additional commands, e-mail: dev-help@spark.apache.org
>> >>>>
>> >>>>
>> >>>>
>> >
>>
>
>

--001a11345c0ab705c90505060a77--

From dev-return-9758-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 01:20:14 2014
Return-Path: <dev-return-9758-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C945517A01
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 01:20:14 +0000 (UTC)
Received: (qmail 41169 invoked by uid 500); 10 Oct 2014 01:20:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41084 invoked by uid 500); 10 Oct 2014 01:20:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41072 invoked by uid 99); 10 Oct 2014 01:20:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 01:20:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.177 as permitted sender)
Received: from [209.85.212.177] (HELO mail-wi0-f177.google.com) (209.85.212.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 01:19:45 +0000
Received: by mail-wi0-f177.google.com with SMTP id fb4so561933wid.16
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 18:19:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=ykNXDqIvNpI27aJorxwZkdXH6M00GZDRHynkf+7Ppss=;
        b=XPe9r7h/ckf340s7tH9vxr+FKbNe2E19Mdvbs/SibLItYdtdXbEAEqzFu1z33jxpXz
         nknXqt/JmzM/udt9sAvz1tP74D0/BXx3nUquBTcKC8N56d92/EDT/Pz9FKvisyVzA1XL
         VB2RTAGqOfIwUKFsA8bChMv5xnrpWjf4xFqVtl9FE+8vpaRK8NIn3mieUJ+Y20x9ph4c
         Aw3DWizsxGvnl80zfGpK4dF5iyTKhnHK7aixJWb221kBeUZGlARc/fsOFVt5jEpnbJoY
         AD3RivtlhpQQ9RGvVdqPg30WBBoAhyRQgbeaI8T5f08mmmzhT0s8F/7HHCAA+D5ML8BP
         ETNw==
MIME-Version: 1.0
X-Received: by 10.194.157.10 with SMTP id wi10mr1194395wjb.66.1412903984921;
 Thu, 09 Oct 2014 18:19:44 -0700 (PDT)
Received: by 10.180.99.70 with HTTP; Thu, 9 Oct 2014 18:19:44 -0700 (PDT)
Date: Thu, 9 Oct 2014 21:19:44 -0400
Message-ID: <CAOhmDzcc4oDRXOzpOKaGF1UBXQ2jL1AZM-BokmtstF71jgTTXw@mail.gmail.com>
Subject: spark-prs and mesos/spark-ec2
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122ebe21f8042050507584d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122ebe21f8042050507584d
Content-Type: text/plain; charset=UTF-8

Does it make sense to point the Spark PR review board to read from
mesos/spark-ec2 as well? PRs submitted against that repo may reference
Spark JIRAs and need review just like any other Spark PR.

Nick

--089e0122ebe21f8042050507584d--

From dev-return-9759-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 02:10:14 2014
Return-Path: <dev-return-9759-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 298F117B22
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 02:10:14 +0000 (UTC)
Received: (qmail 10152 invoked by uid 500); 10 Oct 2014 02:10:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10097 invoked by uid 500); 10 Oct 2014 02:10:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10085 invoked by uid 99); 10 Oct 2014 02:10:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 02:10:12 +0000
X-ASF-Spam-Status: No, hits=2.6 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FROM_EXCESS_BASE64,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cwk32@vip.qq.com designates 103.7.29.150 as permitted sender)
Received: from [103.7.29.150] (HELO smtpbg63.qq.com) (103.7.29.150)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 02:10:07 +0000
X-QQ-FEAT: bUTPB8/q2mheNSPN3M4QxOAxRSXSUax7Qy7l74t2qheAdvX0SE/9C4VmENi8Q
	n0NIxJi52yAaFkhWqZstjWs1ceGI1yGd9bb0aFf9aLeLe4L5KG0bKUcQdj4LUTZghR1RMiW
	NvBbOkT5FX1R3sr5MDh+4X1omY0vZkmI2BQ2St9LZbNE9PQ/bhUj6PAs2p4asQNBI+qUYY4
	S3YSGb06IweYt4NxG0+U4
X-QQ-SSF: 00000000000000F000000000000000Z
X-HAS-ATTACH: no
X-QQ-BUSINESS-ORIGIN: 2
X-Originating-IP: 202.141.236.219
X-QQ-STYLE: 
X-QQ-mid: webmail236t1412906981t9624402
From: "=?utf-8?B?VHJpZGVudA==?=" <cwk32@vip.qq.com>
To: "=?utf-8?B?ZGV2?=" <dev@spark.apache.org>
Subject: [Spark SQL] Strange NPE in Spark SQL with Hive
Mime-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----=_NextPart_54373FE5_09301D90_4F72F442"
Content-Transfer-Encoding: 8Bit
Date: Fri, 10 Oct 2014 10:09:41 +0800
X-Priority: 3
Message-ID: <tencent_6F90023837C796892EEE464F@qq.com>
X-QQ-MIME: TCMime 1.0 by Tencent
X-Mailer: QQMail 2.x
X-QQ-Mailer: QQMail 2.x
X-QQ-SENDSIZE: 520
X-Virus-Checked: Checked by ClamAV on apache.org

------=_NextPart_54373FE5_09301D90_4F72F442
Content-Type: text/plain;
	charset="utf-8"
Content-Transfer-Encoding: base64
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------=_NextPart_54373FE5_09301D90_4F72F442--


From dev-return-9760-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 02:54:24 2014
Return-Path: <dev-return-9760-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 21FC517C1B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 02:54:24 +0000 (UTC)
Received: (qmail 70293 invoked by uid 500); 10 Oct 2014 02:54:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70223 invoked by uid 500); 10 Oct 2014 02:54:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70194 invoked by uid 99); 10 Oct 2014 02:54:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 02:54:22 +0000
X-ASF-Spam-Status: No, hits=2.6 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,FROM_EXCESS_BASE64,HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cwk32@vip.qq.com designates 54.207.19.206 as permitted sender)
Received: from [54.207.19.206] (HELO smtpbgbr1.qq.com) (54.207.19.206)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 02:54:17 +0000
X-QQ-FEAT: O95TlgELvYo8IWu81ir3lWQMnjm/z6c7gG7qsaI7eQHyyg+yNZrWZDFSPl7LS
	QQzliUNsHcB8OTAEDp5l1Ng/K/3cD+9M2KOA2jzw41qYTc9/q6bTheWFss8usl3oiB9KGsu
	+0sWmhYmRmw0qHHvCF1NTG7TfcsHyc1qnU1vrJZCQHMcaF44xYImWXga2zJfeFWRUAKMrIx
	dBrkO6T4wPrbBYdXcFvIM
X-QQ-SSF: 00000000000000F000000000000000Z
X-HAS-ATTACH: no
X-QQ-BUSINESS-ORIGIN: 2
X-Originating-IP: 202.141.236.219
X-QQ-STYLE: 
X-QQ-mid: webmail236t1412909625t6824784
From: "=?utf-8?B?VHJpZGVudA==?=" <cwk32@vip.qq.com>
To: "=?utf-8?B?ZGV2?=" <dev@spark.apache.org>
Subject: [Spark SQL Continue] Sorry, it is not only limited in SQL, may due to network 
Mime-Version: 1.0
Content-Type: multipart/alternative;
	boundary="----=_NextPart_54374A39_092A2620_25203634"
Content-Transfer-Encoding: 8Bit
Date: Fri, 10 Oct 2014 10:53:45 +0800
X-Priority: 3
Message-ID: <tencent_106A2F7D68BBF486793D3F5C@qq.com>
X-QQ-MIME: TCMime 1.0 by Tencent
X-Mailer: QQMail 2.x
X-QQ-Mailer: QQMail 2.x
X-QQ-SENDSIZE: 520
X-QQ-Bgrelay: 1
X-Virus-Checked: Checked by ClamAV on apache.org

------=_NextPart_54374A39_092A2620_25203634
Content-Type: text/plain;
	charset="utf-8"
Content-Transfer-Encoding: base64
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=

------=_NextPart_54374A39_092A2620_25203634--




From dev-return-9761-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 04:12:41 2014
Return-Path: <dev-return-9761-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 822C517E76
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 04:12:41 +0000 (UTC)
Received: (qmail 92584 invoked by uid 500); 10 Oct 2014 04:12:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92513 invoked by uid 500); 10 Oct 2014 04:12:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92501 invoked by uid 99); 10 Oct 2014 04:12:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 04:12:39 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of fairizazizi@gmail.com designates 209.85.212.173 as permitted sender)
Received: from [209.85.212.173] (HELO mail-wi0-f173.google.com) (209.85.212.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 04:12:13 +0000
Received: by mail-wi0-f173.google.com with SMTP id fb4so784612wid.12
        for <dev@spark.apache.org>; Thu, 09 Oct 2014 21:12:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=/R4p2dn8jcvhN2MsbFYMm9OBlLxrP91z2VvCGxTToww=;
        b=Z+MAiFwMbuhgqJMVdNOZ3ujFDiJjmrSNfHpze5CG/tPD+FB8VyFlkh5OkyzAt01gVz
         tkop9A+1sk47vZp02zY+9Y0CVcMUgZoTzxjxqknce1KYkaOvUz+Q4wZkpjn7ykzb0vAj
         /Z2CtKid8KaQ9Zylk2HJxySTP/0HWuwsGdJ7+I1Q0q8MLfyfGHRy/T0ecrRkrhjIUNMj
         WNVYJd1skgjPKELl2lgUvuhLnAcJ8kHLwcr6YjvQpeRSGsDigROV87dyZOQDGdBFvXaJ
         Xb7LgFAPIa0j2Vk5f34WDI9726apzyL/unZlnfyKaAirQMZoYyaLcqul+NpjK3koic3N
         RQEg==
X-Received: by 10.180.74.227 with SMTP id x3mr1948058wiv.80.1412914332725;
 Thu, 09 Oct 2014 21:12:12 -0700 (PDT)
MIME-Version: 1.0
Sender: fairizazizi@gmail.com
Received: by 10.194.219.2 with HTTP; Thu, 9 Oct 2014 21:11:52 -0700 (PDT)
In-Reply-To: <CADtDQQJc97mU+P4WV3WwRPi5SohRmn=u5ZdSqJrfLjFgkM1KaA@mail.gmail.com>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
 <54323A64.2090205@uninett.no> <CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
 <CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
 <543249BB.505@uninett.no> <CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
 <CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com>
 <CAAHrQ0kc4V-B357hMX2OEDsauxnpniTDPbf9ycx+9oh6qVKXiw@mail.gmail.com>
 <CADtDQQJzkWAW-AZ2zQEYqXy02QnpZ-rHTuf9fYZc5MS3SAgv4w@mail.gmail.com>
 <CAAHrQ0=_XLNuGs+E_SB4eGs54xU=M70-uD+vd5NzZ=3-c-KGyA@mail.gmail.com> <CADtDQQJc97mU+P4WV3WwRPi5SohRmn=u5ZdSqJrfLjFgkM1KaA@mail.gmail.com>
From: Fairiz Azizi <coderfi@gmail.com>
Date: Thu, 9 Oct 2014 21:11:52 -0700
X-Google-Sender-Auth: KXXSUpcQZsavC_ez8aIz5B8Vqsg
Message-ID: <CAAHrQ0kkg-AgMN2_TVPfCf+XPOYHfc30Py8TvO5QvNbB1=Q2Fw@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
To: RJ Nowling <rnowling@gmail.com>
Cc: Timothy Chen <tnachen@gmail.com>, Gurvinder Singh <gurvinder.singh@uninett.no>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043c7eeee677fd050509c0e1
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c7eeee677fd050509c0e1
Content-Type: text/plain; charset=UTF-8

Hello,

Sorry for the late reply.

When I tried the LogQuery example this time, things now seem to be fine!

...

14/10/10 04:01:21 INFO scheduler.DAGScheduler: Stage 0 (collect at
LogQuery.scala:80) finished in 0.429 s

14/10/10 04:01:21 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0,
whose tasks have all completed, from pool defa

14/10/10 04:01:21 INFO spark.SparkContext: Job finished: collect at
LogQuery.scala:80, took 12.802743914 s

(10.10.10.10,"FRED",GET http://images.com/2013/Generic.jpg HTTP/1.1)
bytes=621       n=2


Not sure if this is the correct response for that example.

Our mesos/spark builds have since been updated since I last wrote.

Possibly, the JDK version was updated to 1.7.0_67

If you are using an older JDK, maybe try updating that?


- Fi



Fairiz "Fi" Azizi

On Wed, Oct 8, 2014 at 7:54 AM, RJ Nowling <rnowling@gmail.com> wrote:

> Yep!  That's the example I was talking about.
>
> Is an error message printed when it hangs? I get :
>
> 14/09/30 13:23:14 ERROR BlockManagerMasterActor: Got two different block manager registrations on 20140930-131734-1723727882-5050-1895-1
>
>
>
> On Tue, Oct 7, 2014 at 8:36 PM, Fairiz Azizi <coderfi@gmail.com> wrote:
>
>> Sure, could you point me to the example?
>>
>> The only thing I could find was
>>
>> https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala
>>
>> So do you mean running it like:
>>    MASTER="mesos://xxxxxxx*:5050*" ./run-example LogQuery
>>
>> I tried that and I can see the job run and the tasks complete on the
>> slave nodes, but the client process seems to hang forever, it's probably a
>> different problem. BTW, only a dozen or so tasks kick off.
>>
>> I actually haven't done much with Scala and Spark (it's been all python).
>>
>> Fi
>>
>>
>>
>> Fairiz "Fi" Azizi
>>
>> On Tue, Oct 7, 2014 at 6:29 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>
>>> I was able to reproduce it on a small 4 node cluster (1 mesos master and
>>> 3 mesos slaves) with relatively low-end specs.  As I said, I just ran the
>>> log query examples with the fine-grained mesos mode.
>>>
>>> Spark 1.1.0 and mesos 0.20.1.
>>>
>>> Fairiz, could you try running the logquery example included with Spark
>>> and see what you get?
>>>
>>> Thanks!
>>>
>>> On Mon, Oct 6, 2014 at 8:07 PM, Fairiz Azizi <coderfi@gmail.com> wrote:
>>>
>>>> That's what great about Spark, the community is so active! :)
>>>>
>>>> I compiled Mesos 0.20.1 from the source tarball.
>>>>
>>>> Using the Mapr3 Spark 1.1.0 distribution from the Spark downloads page
>>>>  (spark-1.1.0-bin-mapr3.tgz).
>>>>
>>>> I see no problems for the workloads we are trying.
>>>>
>>>> However, the cluster is small (less than 100 cores across 3 nodes).
>>>>
>>>> The workloads reads in just a few gigabytes from HDFS, via an ipython
>>>> notebook spark shell.
>>>>
>>>> thanks,
>>>> Fi
>>>>
>>>>
>>>>
>>>> Fairiz "Fi" Azizi
>>>>
>>>> On Mon, Oct 6, 2014 at 9:20 AM, Timothy Chen <tnachen@gmail.com> wrote:
>>>>
>>>>> Ok I created SPARK-3817 to track this, will try to repro it as well.
>>>>>
>>>>> Tim
>>>>>
>>>>> On Mon, Oct 6, 2014 at 6:08 AM, RJ Nowling <rnowling@gmail.com> wrote:
>>>>> > I've recently run into this issue as well. I get it from running
>>>>> Spark
>>>>> > examples such as log query.  Maybe that'll help reproduce the issue.
>>>>> >
>>>>> >
>>>>> > On Monday, October 6, 2014, Gurvinder Singh <
>>>>> gurvinder.singh@uninett.no>
>>>>> > wrote:
>>>>> >>
>>>>> >> The issue does not occur if the task at hand has small number of map
>>>>> >> tasks. I have a task which has 978 map tasks and I see this error as
>>>>> >>
>>>>> >> 14/10/06 09:34:40 ERROR BlockManagerMasterActor: Got two different
>>>>> block
>>>>> >> manager registrations on 20140711-081617-711206558-5050-2543-5
>>>>> >>
>>>>> >> Here is the log from the mesos-slave where this container was
>>>>> running.
>>>>> >>
>>>>> >> http://pastebin.com/Q1Cuzm6Q
>>>>> >>
>>>>> >> If you look for the code from where error produced by spark, you
>>>>> will
>>>>> >> see that it simply exit and saying in comments "this should never
>>>>> >> happen, lets just quit" :-)
>>>>> >>
>>>>> >> - Gurvinder
>>>>> >> On 10/06/2014 09:30 AM, Timothy Chen wrote:
>>>>> >> > (Hit enter too soon...)
>>>>> >> >
>>>>> >> > What is your setup and steps to repro this?
>>>>> >> >
>>>>> >> > Tim
>>>>> >> >
>>>>> >> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen <tnachen@gmail.com>
>>>>> wrote:
>>>>> >> >> Hi Gurvinder,
>>>>> >> >>
>>>>> >> >> I tried fine grain mode before and didn't get into that problem.
>>>>> >> >>
>>>>> >> >>
>>>>> >> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
>>>>> >> >> <gurvinder.singh@uninett.no> wrote:
>>>>> >> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>>>>> >> >>>> The Spark online docs indicate that Spark is compatible with
>>>>> Mesos
>>>>> >> >>>> 0.18.1
>>>>> >> >>>>
>>>>> >> >>>> I've gotten it to work just fine on 0.18.1 and 0.18.2
>>>>> >> >>>>
>>>>> >> >>>> Has anyone tried Spark on a newer version of Mesos, i.e. Mesos
>>>>> >> >>>> v0.20.0?
>>>>> >> >>>>
>>>>> >> >>>> -Fi
>>>>> >> >>>>
>>>>> >> >>> Yeah we are using Spark 1.1.0 with Mesos 0.20.1. It runs fine in
>>>>> >> >>> coarse
>>>>> >> >>> mode, in fine grain mode there is an issue with blockmanager
>>>>> names
>>>>> >> >>> conflict. I have been waiting for it to be fixed but it is still
>>>>> >> >>> there.
>>>>> >> >>>
>>>>> >> >>> -Gurvinder
>>>>> >> >>>
>>>>> >> >>>
>>>>> ---------------------------------------------------------------------
>>>>> >> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>> >> >>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>> >> >>>
>>>>> >>
>>>>> >>
>>>>> >>
>>>>> ---------------------------------------------------------------------
>>>>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>> >> For additional commands, e-mail: dev-help@spark.apache.org
>>>>> >>
>>>>> >
>>>>> >
>>>>> > --
>>>>> > em rnowling@gmail.com
>>>>> > c 954.496.2314
>>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> em rnowling@gmail.com
>>> c 954.496.2314
>>>
>>
>>
>
>
> --
> em rnowling@gmail.com
> c 954.496.2314
>

--f46d043c7eeee677fd050509c0e1--

From dev-return-9762-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 06:36:01 2014
Return-Path: <dev-return-9762-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7338B1733B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 06:36:01 +0000 (UTC)
Received: (qmail 81388 invoked by uid 500); 10 Oct 2014 06:36:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81325 invoked by uid 500); 10 Oct 2014 06:36:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81311 invoked by uid 99); 10 Oct 2014 06:36:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 06:36:00 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gurvinder.singh@uninett.no designates 158.38.180.100 as permitted sender)
Received: from [158.38.180.100] (HELO epost.uninett.no) (158.38.180.100)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 06:35:34 +0000
Received: from [158.38.62.52] (scintilla.uninett.no [158.38.62.52])
	(using TLSv1 with cipher DHE-RSA-AES128-SHA (128/128 bits))
	(No client certificate requested)
	by epost.uninett.no (Postfix) with ESMTPSA id C54DD3367BC;
	Fri, 10 Oct 2014 08:35:33 +0200 (CEST)
Message-ID: <54377E35.6050209@uninett.no>
Date: Fri, 10 Oct 2014 08:35:33 +0200
From: Gurvinder Singh <gurvinder.singh@uninett.no>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Thunderbird/24.6.0
MIME-Version: 1.0
To: Fairiz Azizi <coderfi@gmail.com>, RJ Nowling <rnowling@gmail.com>
CC: Timothy Chen <tnachen@gmail.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: Spark on Mesos 0.20
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com> <54323A64.2090205@uninett.no> <CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com> <CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com> <543249BB.505@uninett.no> <CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com> <CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com> <CAAHrQ0kc4V-B357hMX2OEDsauxnpniTDPbf9ycx+9oh6qVKXiw@mail.gmail.com> <CADtDQQJzkWAW-AZ2zQEYqXy02QnpZ-rHTuf9fYZc5MS3SAgv4w@mail.gmail.com> <CAAHrQ0=_XLNuGs+E_SB4eGs54xU=M70-uD+vd5NzZ=3-c-KGyA@mail.gmail.com> <CADtDQQJc97mU+P4WV3WwRPi5SohRmn=u5ZdSqJrfLjFgkM1KaA@mail.gmail.com> <CAAHrQ0kkg-AgMN2_TVPfCf+XPOYHfc30Py8TvO5QvNbB1=Q2Fw@mail.gmail.com>
In-Reply-To: <CAAHrQ0kkg-AgMN2_TVPfCf+XPOYHfc30Py8TvO5QvNbB1=Q2Fw@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

On 10/10/2014 06:11 AM, Fairiz Azizi wrote:
> Hello,
> 
> Sorry for the late reply.
> 
> When I tried the LogQuery example this time, things now seem to be fine!
> 
> ...
> 
> 14/10/10 04:01:21 INFO scheduler.DAGScheduler: Stage 0 (collect at
> LogQuery.scala:80) finished in 0.429 s
> 
> 14/10/10 04:01:21 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0,
> whose tasks have all completed, from pool defa
> 
> 14/10/10 04:01:21 INFO spark.SparkContext: Job finished: collect at
> LogQuery.scala:80, took 12.802743914 s
> 
> (10.10.10.10,"FRED",GET http://images.com/2013/Generic.jpg HTTP/1.1)   
> bytes=621       n=2
> 
> 
> Not sure if this is the correct response for that example.
> 
> Our mesos/spark builds have since been updated since I last wrote.
> 
> Possibly, the JDK version was updated to 1.7.0_67
> 
> If you are using an older JDK, maybe try updating that?
I have tested on current JDK 7 and now I am running JDK 8, the problem
still exist. Can you run logquery on data of size say 100+ GB, so that
you have more map tasks. As we start to see the issue on larger tasks.

- Gurvinder
> 
> 
> - Fi
> 
> 
> 
> Fairiz "Fi" Azizi
> 
> On Wed, Oct 8, 2014 at 7:54 AM, RJ Nowling <rnowling@gmail.com
> <mailto:rnowling@gmail.com>> wrote:
> 
>     Yep!  That's the example I was talking about.
> 
>     Is an error message printed when it hangs? I get :
> 
>     14/09/30 13:23:14 ERROR BlockManagerMasterActor: Got two different block manager registrations on 20140930-131734-1723727882-5050-1895-1
> 
> 
> 
>     On Tue, Oct 7, 2014 at 8:36 PM, Fairiz Azizi <coderfi@gmail.com
>     <mailto:coderfi@gmail.com>> wrote:
> 
>         Sure, could you point me to the example?
> 
>         The only thing I could find was
>         https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala
> 
>         So do you mean running it like:
>            MASTER="mesos://xxxxxxx_:5050_" ./run-example LogQuery
> 
>         I tried that and I can see the job run and the tasks complete on
>         the slave nodes, but the client process seems to hang forever,
>         it's probably a different problem. BTW, only a dozen or so tasks
>         kick off.
> 
>         I actually haven't done much with Scala and Spark (it's been all
>         python).
> 
>         Fi
> 
> 
> 
>         Fairiz "Fi" Azizi
> 
>         On Tue, Oct 7, 2014 at 6:29 AM, RJ Nowling <rnowling@gmail.com
>         <mailto:rnowling@gmail.com>> wrote:
> 
>             I was able to reproduce it on a small 4 node cluster (1
>             mesos master and 3 mesos slaves) with relatively low-end
>             specs.  As I said, I just ran the log query examples with
>             the fine-grained mesos mode.
> 
>             Spark 1.1.0 and mesos 0.20.1.
> 
>             Fairiz, could you try running the logquery example included
>             with Spark and see what you get?
> 
>             Thanks!
> 
>             On Mon, Oct 6, 2014 at 8:07 PM, Fairiz Azizi
>             <coderfi@gmail.com <mailto:coderfi@gmail.com>> wrote:
> 
>                 That's what great about Spark, the community is so
>                 active! :)
> 
>                 I compiled Mesos 0.20.1 from the source tarball.
> 
>                 Using the Mapr3 Spark 1.1.0 distribution from the Spark
>                 downloads page  (spark-1.1.0-bin-mapr3.tgz).
> 
>                 I see no problems for the workloads we are trying. 
> 
>                 However, the cluster is small (less than 100 cores
>                 across 3 nodes).
> 
>                 The workloads reads in just a few gigabytes from HDFS,
>                 via an ipython notebook spark shell.
> 
>                 thanks,
>                 Fi
> 
> 
> 
>                 Fairiz "Fi" Azizi
> 
>                 On Mon, Oct 6, 2014 at 9:20 AM, Timothy Chen
>                 <tnachen@gmail.com <mailto:tnachen@gmail.com>> wrote:
> 
>                     Ok I created SPARK-3817 to track this, will try to
>                     repro it as well.
> 
>                     Tim
> 
>                     On Mon, Oct 6, 2014 at 6:08 AM, RJ Nowling
>                     <rnowling@gmail.com <mailto:rnowling@gmail.com>> wrote:
>                     > I've recently run into this issue as well. I get
>                     it from running Spark
>                     > examples such as log query.  Maybe that'll help
>                     reproduce the issue.
>                     >
>                     >
>                     > On Monday, October 6, 2014, Gurvinder Singh
>                     <gurvinder.singh@uninett.no
>                     <mailto:gurvinder.singh@uninett.no>>
>                     > wrote:
>                     >>
>                     >> The issue does not occur if the task at hand has
>                     small number of map
>                     >> tasks. I have a task which has 978 map tasks and
>                     I see this error as
>                     >>
>                     >> 14/10/06 09:34:40 ERROR BlockManagerMasterActor:
>                     Got two different block
>                     >> manager registrations on
>                     20140711-081617-711206558-5050-2543-5
>                     >>
>                     >> Here is the log from the mesos-slave where this
>                     container was running.
>                     >>
>                     >> http://pastebin.com/Q1Cuzm6Q
>                     >>
>                     >> If you look for the code from where error
>                     produced by spark, you will
>                     >> see that it simply exit and saying in comments
>                     "this should never
>                     >> happen, lets just quit" :-)
>                     >>
>                     >> - Gurvinder
>                     >> On 10/06/2014 09:30 AM, Timothy Chen wrote:
>                     >> > (Hit enter too soon...)
>                     >> >
>                     >> > What is your setup and steps to repro this?
>                     >> >
>                     >> > Tim
>                     >> >
>                     >> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen
>                     <tnachen@gmail.com <mailto:tnachen@gmail.com>> wrote:
>                     >> >> Hi Gurvinder,
>                     >> >>
>                     >> >> I tried fine grain mode before and didn't get
>                     into that problem.
>                     >> >>
>                     >> >>
>                     >> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder Singh
>                     >> >> <gurvinder.singh@uninett.no
>                     <mailto:gurvinder.singh@uninett.no>> wrote:
>                     >> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
>                     >> >>>> The Spark online docs indicate that Spark is
>                     compatible with Mesos
>                     >> >>>> 0.18.1
>                     >> >>>>
>                     >> >>>> I've gotten it to work just fine on 0.18.1
>                     and 0.18.2
>                     >> >>>>
>                     >> >>>> Has anyone tried Spark on a newer version of
>                     Mesos, i.e. Mesos
>                     >> >>>> v0.20.0?
>                     >> >>>>
>                     >> >>>> -Fi
>                     >> >>>>
>                     >> >>> Yeah we are using Spark 1.1.0 with Mesos
>                     0.20.1. It runs fine in
>                     >> >>> coarse
>                     >> >>> mode, in fine grain mode there is an issue
>                     with blockmanager names
>                     >> >>> conflict. I have been waiting for it to be
>                     fixed but it is still
>                     >> >>> there.
>                     >> >>>
>                     >> >>> -Gurvinder
>                     >> >>>
>                     >> >>>
>                     ---------------------------------------------------------------------
>                     >> >>> To unsubscribe, e-mail:
>                     dev-unsubscribe@spark.apache.org
>                     <mailto:dev-unsubscribe@spark.apache.org>
>                     >> >>> For additional commands, e-mail:
>                     dev-help@spark.apache.org
>                     <mailto:dev-help@spark.apache.org>
>                     >> >>>
>                     >>
>                     >>
>                     >>
>                     ---------------------------------------------------------------------
>                     >> To unsubscribe, e-mail:
>                     dev-unsubscribe@spark.apache.org
>                     <mailto:dev-unsubscribe@spark.apache.org>
>                     >> For additional commands, e-mail:
>                     dev-help@spark.apache.org
>                     <mailto:dev-help@spark.apache.org>
>                     >>
>                     >
>                     >
>                     > --
>                     > em rnowling@gmail.com <mailto:rnowling@gmail.com>
>                     > c 954.496.2314 <tel:954.496.2314>
> 
> 
> 
> 
> 
>             -- 
>             em rnowling@gmail.com <mailto:rnowling@gmail.com>
>             c 954.496.2314 <tel:954.496.2314>
> 
> 
> 
> 
> 
>     -- 
>     em rnowling@gmail.com <mailto:rnowling@gmail.com>
>     c 954.496.2314 <tel:954.496.2314>
> 
> 


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9763-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 14:54:50 2014
Return-Path: <dev-return-9763-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C61881721C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 14:54:50 +0000 (UTC)
Received: (qmail 30488 invoked by uid 500); 10 Oct 2014 14:54:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30366 invoked by uid 500); 10 Oct 2014 14:54:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 29428 invoked by uid 99); 10 Oct 2014 14:54:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 14:54:47 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.52 as permitted sender)
Received: from [209.85.220.52] (HELO mail-pa0-f52.google.com) (209.85.220.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 14:54:21 +0000
Received: by mail-pa0-f52.google.com with SMTP id fb1so1900913pad.11
        for <multiple recipients>; Fri, 10 Oct 2014 07:54:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:content-type:content-transfer-encoding:subject:message-id:date
         :to:mime-version;
        bh=o6FOx1u/AtRIofVqDwFK+AjA/7mld/8yycYaZ/8nPKI=;
        b=lgRU+TgoQUsTJqw++dSTv+HCM4c1NZ0h517zKQzJj5yjn+c+JTBtf2js2D4nff0JRo
         LFWouCN/Ehx3k0pSEemDEOukpnt2sFMija8rEenXGEw/AN85rbzxoHEYy6LmxE0Zby4j
         RaP7QJR84/pAQbtIflD94XfCHH4vF/G0sdJabukvvUaPSUo4HClzi6huP9rM9O7gl7yO
         rEZPfLzqexGcSRyfis+22/txzsJmLFocqmPYrDO8t5/wVLV2VciokjA1JkEe79S6vv00
         y22fxDgR8II/j1AntJIdY7tVYUmbP16nxEw0e1UNFpPJ/+Wg+L+NzEdmwKcecAkENNSk
         osuQ==
X-Received: by 10.67.4.163 with SMTP id cf3mr5753868pad.92.1412952859553;
        Fri, 10 Oct 2014 07:54:19 -0700 (PDT)
Received: from [192.168.1.106] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id i2sm3821249pat.3.2014.10.10.07.54.18
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 10 Oct 2014 07:54:18 -0700 (PDT)
From: Matei Zaharia <matei.zaharia@gmail.com>
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Subject: Breaking the previous large-scale sort record with Spark
Message-Id: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
Date: Fri, 10 Oct 2014 07:54:16 -0700
To: user <user@spark.apache.org>,
 dev@spark.apache.org
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi folks,

I interrupt your regularly scheduled user / dev list to bring you some =
pretty cool news for the project, which is that we've been able to use =
Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x =
faster on 10x fewer nodes. There's a detailed writeup at =
http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-so=
rt-record.html. Summary: while Hadoop MapReduce held last year's 100 TB =
world record by sorting 100 TB in 72 minutes on 2100 nodes, we sorted it =
in 23 minutes on 206 nodes; and we also scaled up to sort 1 PB in 234 =
minutes.

I want to thank Reynold Xin for leading this effort over the past few =
weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali =
Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for =
providing the machines to make this possible. Finally, this result would =
of course not be possible without the many many other contributions, =
testing and feature requests from throughout the community.

For an engine to scale from these multi-hour petabyte batch jobs down to =
100-millisecond streaming and interactive queries is quite uncommon, and =
it's thanks to all of you folks that we are able to make this happen.

Matei=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9764-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 15:18:04 2014
Return-Path: <dev-return-9764-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BB84C17317
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 15:18:04 +0000 (UTC)
Received: (qmail 83626 invoked by uid 500); 10 Oct 2014 15:18:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83567 invoked by uid 500); 10 Oct 2014 15:18:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82450 invoked by uid 99); 10 Oct 2014 15:18:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:18:01 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:17:36 +0000
Received: by mail-la0-f54.google.com with SMTP id gm9so3476267lab.27
        for <multiple recipients>; Fri, 10 Oct 2014 08:17:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Ie33EK7PAq7pW633aLCnzgdkKK07ctXkgxhEnFaIv4U=;
        b=RK3y+c2AhQUg+OknyT+e6jRLe9R3C+o2/FFOqUTFrMJ//DQgxHWlUf7awovzhvuRkc
         fplqY3gKKkou3W8RDExGq09Zl64k+SZM0j2+9eHZtkFs04PFxXJcAqSi3JeqcZGFqC5f
         VQDOnnEOfaRMEA2lvwvc/ivOt+OdNI/TlOA7/O31bMJHkTRNPH87K9A8rsiwDSCkODb9
         Ew6UxR6gG3Jt7NaGiIlg4Ni1ISHxU+6rlvH8K+ukSNQFtiq7LlETjSqtjlx6YO5T8sSC
         iVI86jjPog0GljqhH21KsZoRTZmaoch7gz5EsarTusAQuLjKzG97VKRF8AFqpRjDo4b8
         yq6A==
MIME-Version: 1.0
X-Received: by 10.152.88.43 with SMTP id bd11mr5713791lab.62.1412954254538;
 Fri, 10 Oct 2014 08:17:34 -0700 (PDT)
Received: by 10.25.30.19 with HTTP; Fri, 10 Oct 2014 08:17:34 -0700 (PDT)
In-Reply-To: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
Date: Fri, 10 Oct 2014 08:17:34 -0700
Message-ID: <CA+B-+fzZHa=XoOpnayzRSV0wBZ0rY45b1gvAzQB_1_5FEvPO5A@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Debasish Das <debasish.das83@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: user <user@spark.apache.org>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c354526cfb9d0505130c58
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c354526cfb9d0505130c58
Content-Type: text/plain; charset=UTF-8

Awesome news Matei !

Congratulations to the databricks team and all the community members...

On Fri, Oct 10, 2014 at 7:54 AM, Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> Hi folks,
>
> I interrupt your regularly scheduled user / dev list to bring you some
> pretty cool news for the project, which is that we've been able to use
> Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x
> faster on 10x fewer nodes. There's a detailed writeup at
> http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-record.html.
> Summary: while Hadoop MapReduce held last year's 100 TB world record by
> sorting 100 TB in 72 minutes on 2100 nodes, we sorted it in 23 minutes on
> 206 nodes; and we also scaled up to sort 1 PB in 234 minutes.
>
> I want to thank Reynold Xin for leading this effort over the past few
> weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali
> Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for
> providing the machines to make this possible. Finally, this result would of
> course not be possible without the many many other contributions, testing
> and feature requests from throughout the community.
>
> For an engine to scale from these multi-hour petabyte batch jobs down to
> 100-millisecond streaming and interactive queries is quite uncommon, and
> it's thanks to all of you folks that we are able to make this happen.
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
>

--001a11c354526cfb9d0505130c58--

From dev-return-9765-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 15:19:57 2014
Return-Path: <dev-return-9765-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1B66F1731D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 15:19:57 +0000 (UTC)
Received: (qmail 87555 invoked by uid 500); 10 Oct 2014 15:19:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87433 invoked by uid 500); 10 Oct 2014 15:19:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 87410 invoked by uid 99); 10 Oct 2014 15:19:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:19:53 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mridul@gmail.com designates 209.85.216.51 as permitted sender)
Received: from [209.85.216.51] (HELO mail-qa0-f51.google.com) (209.85.216.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:19:49 +0000
Received: by mail-qa0-f51.google.com with SMTP id k15so1742365qaq.24
        for <multiple recipients>; Fri, 10 Oct 2014 08:19:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=v7LgJxpDQTyvf91/aLNNJl9dG1FbRz/d5Sq8u/iRMqs=;
        b=AoTczhGpjmGalCCH3S4zDiVG2z71cXiJ0W9Zyc+ckruOmjuowP/kxJDEzTXTRvG9YJ
         SpQeaN7qTDIhHM7otdJgj6A3vtT/g5AiBCSGAcNMKKsKuE/BSzgah7QNY65C2BXTU81B
         /KNwkYrHHOaiJ49waaaccLJ5YjXRpGvbIb2strd2fHPxTKroFobG8nBYRNeNEtv2yBdI
         SwB7dck21EtdP/4MU7QeHotPF2ueSU7x0HBM/O+DvguUstPRiMAvzzuF/JSSMR9ngzFz
         Q09lBf4WHUqRzeCqvLrSCPuhrlGziHuhoyzSqkaz29rqDs7yq2l9ZPQbF6kujKhMjQAA
         Y6qQ==
MIME-Version: 1.0
X-Received: by 10.224.23.131 with SMTP id r3mr6299079qab.90.1412954368111;
 Fri, 10 Oct 2014 08:19:28 -0700 (PDT)
Received: by 10.140.40.40 with HTTP; Fri, 10 Oct 2014 08:19:28 -0700 (PDT)
In-Reply-To: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
Date: Fri, 10 Oct 2014 20:49:28 +0530
Message-ID: <CAJiQeY+-_gL3sdvcvHSVgM2avE4axrYVJNnNBrKm14NnLV_2EQ@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Mridul Muralidharan <mridul@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: user <user@spark.apache.org>, dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Brilliant stuff ! Congrats all :-)
This is indeed really heartening news !

Regards,
Mridul


On Fri, Oct 10, 2014 at 8:24 PM, Matei Zaharia <matei.zaharia@gmail.com> wr=
ote:
> Hi folks,
>
> I interrupt your regularly scheduled user / dev list to bring you some pr=
etty cool news for the project, which is that we've been able to use Spark =
to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x faster o=
n 10x fewer nodes. There's a detailed writeup at http://databricks.com/blog=
/2014/10/10/spark-breaks-previous-large-scale-sort-record.html. Summary: wh=
ile Hadoop MapReduce held last year's 100 TB world record by sorting 100 TB=
 in 72 minutes on 2100 nodes, we sorted it in 23 minutes on 206 nodes; and =
we also scaled up to sort 1 PB in 234 minutes.
>
> I want to thank Reynold Xin for leading this effort over the past few wee=
ks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali Ghodsi.=
 In addition, we'd really like to thank Amazon's EC2 team for providing the=
 machines to make this possible. Finally, this result would of course not b=
e possible without the many many other contributions, testing and feature r=
equests from throughout the community.
>
> For an engine to scale from these multi-hour petabyte batch jobs down to =
100-millisecond streaming and interactive queries is quite uncommon, and it=
's thanks to all of you folks that we are able to make this happen.
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9766-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 15:22:14 2014
Return-Path: <dev-return-9766-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3F0C817329
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 15:22:14 +0000 (UTC)
Received: (qmail 740 invoked by uid 500); 10 Oct 2014 15:22:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 659 invoked by uid 500); 10 Oct 2014 15:22:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 641 invoked by uid 99); 10 Oct 2014 15:22:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:22:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ted.malaska@cloudera.com designates 209.85.218.47 as permitted sender)
Received: from [209.85.218.47] (HELO mail-oi0-f47.google.com) (209.85.218.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:21:47 +0000
Received: by mail-oi0-f47.google.com with SMTP id a141so7134749oig.6
        for <dev@spark.apache.org>; Fri, 10 Oct 2014 08:21:46 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=77/b7ZuEbzBkExSOM7beUI1L08Dtg4LE3LuBPW1xJrE=;
        b=Jn1armz6XdDal94rG3sEDf6JYgOyWha8D1+ZPb2mxZu2XyyxdunX0dDTR3aFYLes8x
         E5lAgTKUqFPjI84czTQlf29gFxwXrvf1GyfMHkMJlmchYGGDECplKH5UT1ZKsN1dro1M
         VP+Blc+lq/dEI0L5+VXFHbZOqb4GCGblW+Mnob6IFjg1/z6pcDN2HMVIzJPCQcJ3oqOc
         2EkYQcir9Z2LhtGOeBsYhdgzQOwatAsDZPM+rwoNkK/XHyni5mb7HL+fQeSwN7ozCNqn
         x2zyTboOx5laCC+o5sEe322cRK8v3/6c1+sN/WiH1iXMcZhW3znHpD1VRecICPE0+ivn
         TzNA==
X-Gm-Message-State: ALoCoQmd9DTfciG3QKxEdNGeKZj0tP7dhCthxIXIz3VgosdlSVr4X5qYJDQhp6Zbcx8V/0FTT1f+
MIME-Version: 1.0
X-Received: by 10.202.183.139 with SMTP id h133mr2451600oif.17.1412954505501;
 Fri, 10 Oct 2014 08:21:45 -0700 (PDT)
Received: by 10.76.5.146 with HTTP; Fri, 10 Oct 2014 08:21:45 -0700 (PDT)
In-Reply-To: <CAJiQeY+-_gL3sdvcvHSVgM2avE4axrYVJNnNBrKm14NnLV_2EQ@mail.gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
	<CAJiQeY+-_gL3sdvcvHSVgM2avE4axrYVJNnNBrKm14NnLV_2EQ@mail.gmail.com>
Date: Fri, 10 Oct 2014 11:21:45 -0400
Message-ID: <CANc1aFOVzuTarOyi-R95oa7FQxMo2a-+F_cTpKi5Y+83niFM-A@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Ted Malaska <ted.malaska@cloudera.com>
To: Mridul Muralidharan <mridul@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, user <user@spark.apache.org>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113cd22a6271b80505131bea
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113cd22a6271b80505131bea
Content-Type: text/plain; charset=UTF-8

This is a bad deal, great job.

On Fri, Oct 10, 2014 at 11:19 AM, Mridul Muralidharan <mridul@gmail.com>
wrote:

> Brilliant stuff ! Congrats all :-)
> This is indeed really heartening news !
>
> Regards,
> Mridul
>
>
> On Fri, Oct 10, 2014 at 8:24 PM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
> > Hi folks,
> >
> > I interrupt your regularly scheduled user / dev list to bring you some
> pretty cool news for the project, which is that we've been able to use
> Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x
> faster on 10x fewer nodes. There's a detailed writeup at
> http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-record.html.
> Summary: while Hadoop MapReduce held last year's 100 TB world record by
> sorting 100 TB in 72 minutes on 2100 nodes, we sorted it in 23 minutes on
> 206 nodes; and we also scaled up to sort 1 PB in 234 minutes.
> >
> > I want to thank Reynold Xin for leading this effort over the past few
> weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali
> Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for
> providing the machines to make this possible. Finally, this result would of
> course not be possible without the many many other contributions, testing
> and feature requests from throughout the community.
> >
> > For an engine to scale from these multi-hour petabyte batch jobs down to
> 100-millisecond streaming and interactive queries is quite uncommon, and
> it's thanks to all of you folks that we are able to make this happen.
> >
> > Matei
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113cd22a6271b80505131bea--

From dev-return-9767-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 15:39:21 2014
Return-Path: <dev-return-9767-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F26C717394
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 15:39:20 +0000 (UTC)
Received: (qmail 51803 invoked by uid 500); 10 Oct 2014 15:39:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51744 invoked by uid 500); 10 Oct 2014 15:39:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51726 invoked by uid 99); 10 Oct 2014 15:39:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:39:19 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of dineshjweerakkody@gmail.com designates 209.85.213.180 as permitted sender)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:38:53 +0000
Received: by mail-ig0-f180.google.com with SMTP id uq10so3181153igb.7
        for <multiple recipients>; Fri, 10 Oct 2014 08:38:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=tblkJAYE2aDsat9cOEvt69Zf1X5wjpwM3XMqgOGqBnQ=;
        b=Lqo1ytgXAGq68q7Pws7xAV8Kh0AdmE0pb0uqY6beHkZ9+j0gXwmd4wRXY1LmXGojkn
         woM1DRwDISquyy5yJS4AU3NB8ZRbXErLXul07k2ztCQTPLq5RhvcJL1SK+G7JzcKOu/1
         iHEIcIg6Y/lnhSGJF0yqP6S14iUCiJ3FIzqto+ty4LuSuao427nUbFq7xOzns7fFtUYf
         pNn2puMPjgdfP0nAlpNT76ViTgJY69P6wl8NgnQllOLf54jir/KCnJKbDwV8KsgZHEvb
         RVy23JS0vj9+FJQONNPT0FnCvM5wo0mTsfhKWwtJBDXMRp15bZSWzi7+uGTd0URESpXD
         Fugg==
MIME-Version: 1.0
X-Received: by 10.42.207.131 with SMTP id fy3mr17240457icb.67.1412955531733;
 Fri, 10 Oct 2014 08:38:51 -0700 (PDT)
Received: by 10.107.136.41 with HTTP; Fri, 10 Oct 2014 08:38:51 -0700 (PDT)
In-Reply-To: <CANc1aFOVzuTarOyi-R95oa7FQxMo2a-+F_cTpKi5Y+83niFM-A@mail.gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
	<CAJiQeY+-_gL3sdvcvHSVgM2avE4axrYVJNnNBrKm14NnLV_2EQ@mail.gmail.com>
	<CANc1aFOVzuTarOyi-R95oa7FQxMo2a-+F_cTpKi5Y+83niFM-A@mail.gmail.com>
Date: Fri, 10 Oct 2014 21:08:51 +0530
Message-ID: <CAGC4hZu5fq8BKm1G6hDEaBYSMH1pPUgAdPpqEfWJAWhL0cVf9Q@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
From: "Dinesh J. Weerakkody" <dineshjweerakkody@gmail.com>
To: Ted Malaska <ted.malaska@cloudera.com>
Cc: Mridul Muralidharan <mridul@gmail.com>, Matei Zaharia <matei.zaharia@gmail.com>, 
	user <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf303f65048d712e05051358f3
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf303f65048d712e05051358f3
Content-Type: text/plain; charset=UTF-8

Wow.. Cool.. Congratulations.. :)

On Fri, Oct 10, 2014 at 8:51 PM, Ted Malaska <ted.malaska@cloudera.com>
wrote:

> This is a bad deal, great job.
>
> On Fri, Oct 10, 2014 at 11:19 AM, Mridul Muralidharan <mridul@gmail.com>
> wrote:
>
> > Brilliant stuff ! Congrats all :-)
> > This is indeed really heartening news !
> >
> > Regards,
> > Mridul
> >
> >
> > On Fri, Oct 10, 2014 at 8:24 PM, Matei Zaharia <matei.zaharia@gmail.com>
> > wrote:
> > > Hi folks,
> > >
> > > I interrupt your regularly scheduled user / dev list to bring you some
> > pretty cool news for the project, which is that we've been able to use
> > Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x
> > faster on 10x fewer nodes. There's a detailed writeup at
> >
> http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-record.html
> .
> > Summary: while Hadoop MapReduce held last year's 100 TB world record by
> > sorting 100 TB in 72 minutes on 2100 nodes, we sorted it in 23 minutes on
> > 206 nodes; and we also scaled up to sort 1 PB in 234 minutes.
> > >
> > > I want to thank Reynold Xin for leading this effort over the past few
> > weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali
> > Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for
> > providing the machines to make this possible. Finally, this result would
> of
> > course not be possible without the many many other contributions, testing
> > and feature requests from throughout the community.
> > >
> > > For an engine to scale from these multi-hour petabyte batch jobs down
> to
> > 100-millisecond streaming and interactive queries is quite uncommon, and
> > it's thanks to all of you folks that we are able to make this happen.
> > >
> > > Matei
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>



-- 
Thanks & Best Regards,

*Dinesh J. Weerakkody*
*www.dineshjweerakkody.com <http://www.dineshjweerakkody.com>*

--20cf303f65048d712e05051358f3--

From dev-return-9768-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 15:45:26 2014
Return-Path: <dev-return-9768-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 67B1B173CB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 15:45:26 +0000 (UTC)
Received: (qmail 67673 invoked by uid 500); 10 Oct 2014 15:45:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67563 invoked by uid 500); 10 Oct 2014 15:45:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66546 invoked by uid 99); 10 Oct 2014 15:45:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:45:23 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.192.51 as permitted sender)
Received: from [209.85.192.51] (HELO mail-qg0-f51.google.com) (209.85.192.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:45:18 +0000
Received: by mail-qg0-f51.google.com with SMTP id z107so3971657qgd.24
        for <multiple recipients>; Fri, 10 Oct 2014 08:44:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=0anJtc+g/Z5AgARADtjDMH2LIEJh2tLrvH1TFt3IO5g=;
        b=G/hIDzzQS43LP7DzIlgzKeDVQ3ib/s2H+qcy4l+PHWE6i2aggfQ0ADq1epeSXp3nzZ
         wVYF8/4h3tVb8FsnPeL/nU4y7GPQG1OTb/p5msUMjTGCwRlWn893qHV7Jo48d92Kt3A/
         4UxwryeCy2cMA4FZ2p1pIL2CsXY4bFvgfM/T6iq5SdaRqU3aXg90hBEU9Hqeo0Cd1X92
         VjU6b7PPeF+F7heuSuX6f/MJAaedzOnJS1VKWStnELP4nd/rxT9gdx9SPrrRRKKua8l8
         g7gVGa902kUcEyi+nOnjxOht+3r8LgnOwXR5PLILB7blZOFDwBC1LsSbiVCBsMkFnkYw
         UomA==
X-Received: by 10.224.76.5 with SMTP id a5mr10054731qak.72.1412955896708;
        Fri, 10 Oct 2014 08:44:56 -0700 (PDT)
Received: from [192.168.1.146] (MTRLPQ02-1177746539.sdsl.bell.ca. [70.50.252.107])
        by mx.google.com with ESMTPSA id n78sm5323986qgd.41.2014.10.10.08.44.55
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Fri, 10 Oct 2014 08:44:56 -0700 (PDT)
Date: Fri, 10 Oct 2014 12:00:19 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Mridul Muralidharan <mridul@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, user
 <user@spark.apache.org>, dev@spark.apache.org
Message-ID: <F679C798047540FBAAA2F01AB7939392@gmail.com>
In-Reply-To: <CAJiQeY+-_gL3sdvcvHSVgM2avE4axrYVJNnNBrKm14NnLV_2EQ@mail.gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
 <CAJiQeY+-_gL3sdvcvHSVgM2avE4axrYVJNnNBrKm14NnLV_2EQ@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54380293_5e884adc_242"
X-Virus-Checked: Checked by ClamAV on apache.org

--54380293_5e884adc_242
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

Great! Congratulations! 

-- 
Nan Zhu


On Friday, October 10, 2014 at 11:19 AM, Mridul Muralidharan wrote:

> Brilliant stuff ! Congrats all :-)
> This is indeed really heartening news !
> 
> Regards,
> Mridul
> 
> 
> On Fri, Oct 10, 2014 at 8:24 PM, Matei Zaharia <matei.zaharia@gmail.com (mailto:matei.zaharia@gmail.com)> wrote:
> > Hi folks,
> > 
> > I interrupt your regularly scheduled user / dev list to bring you some pretty cool news for the project, which is that we've been able to use Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x faster on 10x fewer nodes. There's a detailed writeup at http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-record.html. Summary: while Hadoop MapReduce held last year's 100 TB world record by sorting 100 TB in 72 minutes on 2100 nodes, we sorted it in 23 minutes on 206 nodes; and we also scaled up to sort 1 PB in 234 minutes.
> > 
> > I want to thank Reynold Xin for leading this effort over the past few weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for providing the machines to make this possible. Finally, this result would of course not be possible without the many many other contributions, testing and feature requests from throughout the community.
> > 
> > For an engine to scale from these multi-hour petabyte batch jobs down to 100-millisecond streaming and interactive queries is quite uncommon, and it's thanks to all of you folks that we are able to make this happen.
> > 
> > Matei
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org (mailto:dev-unsubscribe@spark.apache.org)
> > For additional commands, e-mail: dev-help@spark.apache.org (mailto:dev-help@spark.apache.org)
> > 
> 
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org (mailto:user-unsubscribe@spark.apache.org)
> For additional commands, e-mail: user-help@spark.apache.org (mailto:user-help@spark.apache.org)
> 
> 



--54380293_5e884adc_242--


From dev-return-9769-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 15:47:11 2014
Return-Path: <dev-return-9769-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 88DC1173D9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 15:47:11 +0000 (UTC)
Received: (qmail 76408 invoked by uid 500); 10 Oct 2014 15:47:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76293 invoked by uid 500); 10 Oct 2014 15:47:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75267 invoked by uid 99); 10 Oct 2014 15:47:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:47:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of arthur.hk.chan@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 15:47:03 +0000
Received: by mail-pa0-f51.google.com with SMTP id lj1so1942572pab.24
        for <multiple recipients>; Fri, 10 Oct 2014 08:46:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=TxFdXSEU7KEz5H+F4+h0TgoQjBuHCFXi84WyauaV59s=;
        b=TlwO/G15603wz3jC2KB8goPVpa5YF8zbxh/AWdkXMt5pBKFO82Ih5H/0clrYn4P7tS
         MYh3L0slMjUlfwvLF2PZadLbh5pVfZrRMrpKIso3sMxLBNLXzkuILtW1eVDy2fF8rP3X
         WxI4BilY95pgLYQGreULLpCmoSz2DvoGTn93mZqtRx3ntSNy3hvyvbC868B3a76wjCk2
         bKLQD9e9s9IZCmGmicJ2Dqk2NHZj/YdNWeKIPvdbwQkyk64T55WEq6Se3pKiniLaJWAp
         23yaXs5SiSKnhy9nQOOw9djPLQsag2oY9Xs9nT+uo/WR42uM7nr6rBzAkzVUcWZx2PKF
         RP4Q==
X-Received: by 10.70.92.43 with SMTP id cj11mr6241002pdb.94.1412956003156;
        Fri, 10 Oct 2014 08:46:43 -0700 (PDT)
Received: from [192.168.0.106] (014136185055.ctinets.com. [14.136.185.55])
        by mx.google.com with ESMTPSA id fk10sm3822663pdb.49.2014.10.10.08.46.40
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 10 Oct 2014 08:46:42 -0700 (PDT)
Content-Type: multipart/alternative; boundary="Apple-Mail=_3F366F02-5C14-462B-9E19-3D00E395A0B3"
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Breaking the previous large-scale sort record with Spark
From: "Arthur.hk.chan@gmail.com" <arthur.hk.chan@gmail.com>
In-Reply-To: <F679C798047540FBAAA2F01AB7939392@gmail.com>
Date: Fri, 10 Oct 2014 23:46:15 +0800
Cc: "Arthur.hk.chan@gmail.com" <arthur.hk.chan@gmail.com>,
 Mridul Muralidharan <mridul@gmail.com>,
 user <user@spark.apache.org>,
 dev@spark.apache.org,
 Nan Zhu <zhunanmcgill@gmail.com>
Message-Id: <7FD6B534-0FE5-4F6E-A458-B8CA4C983BCF@gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com> <CAJiQeY+-_gL3sdvcvHSVgM2avE4axrYVJNnNBrKm14NnLV_2EQ@mail.gmail.com> <F679C798047540FBAAA2F01AB7939392@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_3F366F02-5C14-462B-9E19-3D00E395A0B3
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=us-ascii

Wonderful !!

On 11 Oct, 2014, at 12:00 am, Nan Zhu <zhunanmcgill@gmail.com> wrote:

> Great! Congratulations!
>=20
> --=20
> Nan Zhu
> On Friday, October 10, 2014 at 11:19 AM, Mridul Muralidharan wrote:
>=20
>> Brilliant stuff ! Congrats all :-)
>> This is indeed really heartening news !
>>=20
>> Regards,
>> Mridul
>>=20
>>=20
>> On Fri, Oct 10, 2014 at 8:24 PM, Matei Zaharia =
<matei.zaharia@gmail.com> wrote:
>>> Hi folks,
>>>=20
>>> I interrupt your regularly scheduled user / dev list to bring you =
some pretty cool news for the project, which is that we've been able to =
use Spark to break MapReduce's 100 TB and 1 PB sort records, sorting =
data 3x faster on 10x fewer nodes. There's a detailed writeup at =
http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-so=
rt-record.html. Summary: while Hadoop MapReduce held last year's 100 TB =
world record by sorting 100 TB in 72 minutes on 2100 nodes, we sorted it =
in 23 minutes on 206 nodes; and we also scaled up to sort 1 PB in 234 =
minutes.
>>>=20
>>> I want to thank Reynold Xin for leading this effort over the past =
few weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and =
Ali Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for =
providing the machines to make this possible. Finally, this result would =
of course not be possible without the many many other contributions, =
testing and feature requests from throughout the community.
>>>=20
>>> For an engine to scale from these multi-hour petabyte batch jobs =
down to 100-millisecond streaming and interactive queries is quite =
uncommon, and it's thanks to all of you folks that we are able to make =
this happen.
>>>=20
>>> Matei
>>> =
---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
>> For additional commands, e-mail: user-help@spark.apache.org
>=20


--Apple-Mail=_3F366F02-5C14-462B-9E19-3D00E395A0B3--

From dev-return-9770-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 16:18:22 2014
Return-Path: <dev-return-9770-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E3452174EE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 16:18:22 +0000 (UTC)
Received: (qmail 53811 invoked by uid 500); 10 Oct 2014 16:18:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53745 invoked by uid 500); 10 Oct 2014 16:18:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53732 invoked by uid 99); 10 Oct 2014 16:18:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 16:18:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of snunez@hortonworks.com designates 209.85.192.182 as permitted sender)
Received: from [209.85.192.182] (HELO mail-pd0-f182.google.com) (209.85.192.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 16:17:54 +0000
Received: by mail-pd0-f182.google.com with SMTP id y10so1945837pdj.13
        for <dev@spark.apache.org>; Fri, 10 Oct 2014 09:17:52 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:user-agent:date:subject:from:to:cc:message-id
         :thread-topic:references:in-reply-to:mime-version:content-type;
        bh=h4FzeYZ9UMpGJuOcXY1c+ETHCNUe3JJWCsKbuSzKLHc=;
        b=ioAguAB2B1jkockdhhEPr+wNzWcPWuVoPtryYbvVFBv/iS7/9on1KeXNhXMLbY6tVJ
         Ido20UBMOwQym7oygUsBjsbcPm2alCswkuOZV/mU7sOd0APFFGYdDbIo7B8EEnW0Pre0
         7ej6N+m3TvdmydtUrMnjhkOXX+f+W57D2UBuI9SAUwrwXktwBmER6rDHtz+47PuvG7mW
         rpTeLS/9BDaKxgs5aUX0z1fP69Hn4rPnMZgmCG8U+qYQOXRpsC0s13rYvhp7UmjC6W59
         /Q1ZagVnAlEUAbWM2NpFuhm29WptexsyZ1cud3aop3kVu+QDpBPKryWy+cmhpv2BVeoS
         YzNw==
X-Gm-Message-State: ALoCoQneoGywD+JnzRF5UHhbFCE4ZWdS5fBWPEyPFMKRbH8am91f4FdcifepfgO44+RLyyCxSuRf7Spj0ARVSFCmlosRMZH6ywASmz+bR++N8B7yJMe8mrY=
X-Received: by 10.70.36.237 with SMTP id t13mr6430198pdj.134.1412957871966;
        Fri, 10 Oct 2014 09:17:51 -0700 (PDT)
Received: from [10.11.3.247] (outbound.hortonworks.com. [192.175.27.2])
        by mx.google.com with ESMTPSA id cw5sm3934007pbc.9.2014.10.10.09.17.48
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Fri, 10 Oct 2014 09:17:51 -0700 (PDT)
User-Agent: Microsoft-MacOutlook/14.4.4.140807
Date: Fri, 10 Oct 2014 09:17:46 -0700
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Steve Nunez <snunez@hortonworks.com>
To: Debasish Das <debasish.das83@gmail.com>,
	Matei Zaharia <matei.zaharia@gmail.com>
CC: user <user@spark.apache.org>,
	dev <dev@spark.apache.org>
Message-ID: <D05D545A.AFC7%snunez@hortonworks.com>
Thread-Topic: Breaking the previous large-scale sort record with Spark
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
 <CA+B-+fzZHa=XoOpnayzRSV0wBZ0rY45b1gvAzQB_1_5FEvPO5A@mail.gmail.com>
In-Reply-To: <CA+B-+fzZHa=XoOpnayzRSV0wBZ0rY45b1gvAzQB_1_5FEvPO5A@mail.gmail.com>
Mime-version: 1.0
Content-type: multipart/alternative;
	boundary="B_3495777470_3832880"
X-Virus-Checked: Checked by ClamAV on apache.org

--B_3495777470_3832880
Content-type: text/plain; charset=US-ASCII

Great stuff. Wonderful to see such progress in so short a time.

How about some links to code and instructions so that these benchmarks can
be reproduced?

Regards,
- Steve

From:  Debasish Das <debasish.das83@gmail.com>
Date:  Friday, October 10, 2014 at 8:17
To:  Matei Zaharia <matei.zaharia@gmail.com>
Cc:  user <user@spark.apache.org>, dev <dev@spark.apache.org>
Subject:  Re: Breaking the previous large-scale sort record with Spark

> Awesome news Matei !
> 
> Congratulations to the databricks team and all the community members...
> 
> On Fri, Oct 10, 2014 at 7:54 AM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
>> Hi folks,
>> 
>> I interrupt your regularly scheduled user / dev list to bring you some pretty
>> cool news for the project, which is that we've been able to use Spark to
>> break MapReduce's 100 TB and 1 PB sort records, sorting data 3x faster on 10x
>> fewer nodes. There's a detailed writeup at
>> http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-
>> record.html. Summary: while Hadoop MapReduce held last year's 100 TB world
>> record by sorting 100 TB in 72 minutes on 2100 nodes, we sorted it in 23
>> minutes on 206 nodes; and we also scaled up to sort 1 PB in 234 minutes.
>> 
>> I want to thank Reynold Xin for leading this effort over the past few weeks,
>> along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali Ghodsi. In
>> addition, we'd really like to thank Amazon's EC2 team for providing the
>> machines to make this possible. Finally, this result would of course not be
>> possible without the many many other contributions, testing and feature
>> requests from throughout the community.
>> 
>> For an engine to scale from these multi-hour petabyte batch jobs down to
>> 100-millisecond streaming and interactive queries is quite uncommon, and it's
>> thanks to all of you folks that we are able to make this happen.
>> 
>> Matei
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
>> For additional commands, e-mail: user-help@spark.apache.org
>> 
> 



-- 
CONFIDENTIALITY NOTICE
NOTICE: This message is intended for the use of the individual or entity to 
which it is addressed and may contain information that is confidential, 
privileged and exempt from disclosure under applicable law. If the reader 
of this message is not the intended recipient, you are hereby notified that 
any printing, copying, dissemination, distribution, disclosure or 
forwarding of this communication is strictly prohibited. If you have 
received this communication in error, please contact the sender immediately 
and delete it from your system. Thank You.

--B_3495777470_3832880--



From dev-return-9771-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 17:38:50 2014
Return-Path: <dev-return-9771-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3C8E817986
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 17:38:50 +0000 (UTC)
Received: (qmail 95695 invoked by uid 500); 10 Oct 2014 17:38:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95625 invoked by uid 500); 10 Oct 2014 17:38:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95613 invoked by uid 99); 10 Oct 2014 17:38:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 17:38:48 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.44 as permitted sender)
Received: from [74.125.82.44] (HELO mail-wg0-f44.google.com) (74.125.82.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 17:38:22 +0000
Received: by mail-wg0-f44.google.com with SMTP id y10so4447125wgg.3
        for <dev@spark.incubator.apache.org>; Fri, 10 Oct 2014 10:38:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=iEQsz8+NqsXRs5NJaFquzXAsOiprx+mr1w++73M35KY=;
        b=L2aGpY4s2r4EMy92PUc1AUhfil3vZb95HpYXNOKriN2izKtNC8167FJZ1Jp0lxsC3U
         r0NN2o7oGAIjGOw4mjbptFlLs/nHhyoQgdOK4sBLGKff5U44IeghvQBpN2pNzELasz59
         VMz2GwmnRulEJKXbtOVFIXjAG2GO49nnygy4Wv6waZlJKMm2lqgYc9VDXSudUDFLCEEB
         4JcP2ZfLZ4ZqBMOCZ73BEY0ssMUxID/IPR3zChidHocWkV1JYntR0lSuExZsE92so3Kb
         PiM6vPEsHO75eN5HVALCQ5L8UwvwK3lyn7Tk9Gr7cytmNyKSgfShzZAEaQ0WZ+H9yWg+
         4NoA==
MIME-Version: 1.0
X-Received: by 10.180.12.206 with SMTP id a14mr6053989wic.75.1412962702117;
 Fri, 10 Oct 2014 10:38:22 -0700 (PDT)
Received: by 10.180.99.70 with HTTP; Fri, 10 Oct 2014 10:38:22 -0700 (PDT)
In-Reply-To: <CAJ4HpHFCF8-WprDMX+wGpd0TqLBHCapWV3Z799-TSfj75jFOrw@mail.gmail.com>
References: <1412863857647-8717.post@n3.nabble.com>
	<CAOhmDzeYHJh2rsZhkPJTUZT0XM=fOFGY8DDz0QJ+YBvUd=ojLg@mail.gmail.com>
	<CAAswR-6j-3qswZmENuZuDkkRDkwHfDgt5ssT0wUXbQP4SNcDWg@mail.gmail.com>
	<CAJ4HpHFCF8-WprDMX+wGpd0TqLBHCapWV3Z799-TSfj75jFOrw@mail.gmail.com>
Date: Fri, 10 Oct 2014 13:38:22 -0400
Message-ID: <CAOhmDzcM3pTz1n8taG=GczYO1sFzAZBEktcJQQjfA+AC0+ncZA@mail.gmail.com>
Subject: Re: Trouble running tests
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: "yana.kadiyska@gmail.com" <yana.kadiyska@gmail.com>
Cc: Michael Armbrust <michael@databricks.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c24c9af0d171050515030e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c24c9af0d171050515030e
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Running dev/run-tests as-is should work and will test everything. That's
what the contributing guide recommends, if I remember correctly.

At some point we should make it easier to test individual components
locally using the dev script, but calling sbt on the various tests suites
as Michael pointed out will always work.

Nick

On Friday, October 10, 2014, Yana Kadiyska <yana.kadiyska@gmail.com> wrote:

> Thanks Nicholas and Michael-- yes, I wanted to make sure all tests pass
> before I submitted a pull request.
>
> AMPLAB_JENKINS=3Dtrue ./dev/run-tests fails for me in mlib and yarn
> suites(synced to 14f222f7f76cc93633aae27a94c0e556e289ec56).
>
> I was however able to run Michael's suggested tests and my changes affect
> the SQL project only, so I'll go ahead with the pull request...
>
> I'd like to know if people run the full suite locally though -- I can
> imagine cases where a change is not clearly isolated to a single module.
>
> thanks again
>
> On Thu, Oct 9, 2014 at 5:26 PM, Michael Armbrust <michael@databricks.com
> <javascript:_e(%7B%7D,'cvml','michael@databricks.com');>> wrote:
>
>> Also, in general for SQL only changes it is sufficient to run "sbt/sbt
>> catatlyst/test sql/test hive/test".  The "hive/test" part takes the
>> longest, so I usually leave that out until just before submitting unless=
 my
>> changes are hive specific.
>>
>> On Thu, Oct 9, 2014 at 11:40 AM, Nicholas Chammas <
>> nicholas.chammas@gmail.com
>> <javascript:_e(%7B%7D,'cvml','nicholas.chammas@gmail.com');>> wrote:
>>
>>> _RUN_SQL_TESTS needs to be true as well. Those two _... variables set g=
et
>>> correctly when tests are run on Jenkins. They=E2=80=99re not meant to b=
e
>>> manipulated directly by testers.
>>>
>>> Did you want to run SQL tests only locally? You can try faking being
>>> Jenkins by setting AMPLAB_JENKINS=3Dtrue before calling run-tests. That
>>> should be simpler than futzing with the _... variables.
>>>
>>> Nick
>>> =E2=80=8B
>>>
>>> On Thu, Oct 9, 2014 at 10:10 AM, Yana <yana.kadiyska@gmail.com
>>> <javascript:_e(%7B%7D,'cvml','yana.kadiyska@gmail.com');>> wrote:
>>>
>>> > Hi, apologies if I missed a FAQ somewhere.
>>> >
>>> > I am trying to submit a bug fix for the very first time. Reading
>>> > instructions, I forked the git repo (at
>>> > c9ae79fba25cd49ca70ca398bc75434202d26a97) and am trying to run tests.
>>> >
>>> > I run this: ./dev/run-tests  _SQL_TESTS_ONLY=3Dtrue
>>> >
>>> > and after a while get the following error:
>>> >
>>> > [info] ScalaTest
>>> > [info] Run completed in 3 minutes, 37 seconds.
>>> > [info] Total number of tests run: 224
>>> > [info] Suites: completed 19, aborted 0
>>> > [info] Tests: succeeded 224, failed 0, canceled 0, ignored 5, pending=
 0
>>> > [info] All tests passed.
>>> > [info] Passed: Total 224, Failed 0, Errors 0, Passed 224, Ignored 5
>>> > [success] Total time: 301 s, completed Oct 9, 2014 9:31:23 AM
>>> > [error] Expected ID character
>>> > [error] Not a valid command: hive-thriftserver
>>> > [error] Expected project ID
>>> > [error] Expected configuration
>>> > [error] Expected ':' (if selecting a configuration)
>>> > [error] Expected key
>>> > [error] Not a valid key: hive-thriftserver
>>> > [error] hive-thriftserver/test
>>> > [error]                  ^
>>> >
>>> >
>>> > (I am running this without my changes)
>>> >
>>> > I have 2 questions:
>>> > 1. How to fix this
>>> > 2. Is there a best practice on what to fork so you start off with a
>>> "good
>>> > state"? I'm wondering if I should sync the latest changes or go back
>>> to a
>>> > label?
>>> >
>>> > thanks in advance
>>> >
>>> >
>>> >
>>> >
>>> > --
>>> > View this message in context:
>>> >
>>> http://apache-spark-developers-list.1001551.n3.nabble.com/Trouble-runni=
ng-tests-tp8717.html
>>> > Sent from the Apache Spark Developers List mailing list archive at
>>> > Nabble.com.
>>> >
>>> > ---------------------------------------------------------------------
>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> <javascript:_e(%7B%7D,'cvml','dev-unsubscribe@spark.apache.org');>
>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>> <javascript:_e(%7B%7D,'cvml','dev-help@spark.apache.org');>
>>> >
>>> >
>>>
>>
>>
>

--001a11c24c9af0d171050515030e--

From dev-return-9772-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 19:06:34 2014
Return-Path: <dev-return-9772-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 545F517D63
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 19:06:34 +0000 (UTC)
Received: (qmail 83199 invoked by uid 500); 10 Oct 2014 19:06:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83128 invoked by uid 500); 10 Oct 2014 19:06:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83114 invoked by uid 99); 10 Oct 2014 19:06:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 19:06:33 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 19:06:26 +0000
Received: by mail-pd0-f172.google.com with SMTP id ft15so2175880pdb.3
        for <dev@spark.apache.org>; Fri, 10 Oct 2014 12:06:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=5N9SIEmy5OJpmfEGItFlIIsP4lOQOfqVM45pZglt2VQ=;
        b=0CDAmwCelRbYCB7IrjnSRsk3AF0p9FuMedc+7z60Nb0/yE/OzeakUcB1znLRTy82f4
         SJGYRRbvbqD4JVHb8xuajib/zO/lpoR18dCvmWxdJM5WMq+0KzJxgzR9Ti00eZD11Tfg
         QYv5iRmA1k5fn+fxulRB7E+3LoqF3WcsXIvb1onDZLgzC4SJ3QqU3afSdJ2LQz8fZZtJ
         8okyjqTz0Qf3Xk4zmcmgksitaZxQ/byyaeouTxegrDFso2vI8kNjMYXlK3d3HhJT7WdN
         WCA2vIpRVzQjiL4Pwd55xgGXEgCpYWVvSVWKHOsM+5XotMjiMgHDmeMj4pgehBZOVU7K
         oucA==
X-Received: by 10.68.196.137 with SMTP id im9mr7218745pbc.57.1412967966266;
        Fri, 10 Oct 2014 12:06:06 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id kj9sm3298911pbc.37.2014.10.10.12.06.05
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Fri, 10 Oct 2014 12:06:05 -0700 (PDT)
Date: Fri, 10 Oct 2014 12:06:04 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>, dev
 <dev@spark.apache.org>
Message-ID: <etPan.54382e1c.6b8b4567.d2c9@joshs-mbp>
In-Reply-To: <CAOhmDzcc4oDRXOzpOKaGF1UBXQ2jL1AZM-BokmtstF71jgTTXw@mail.gmail.com>
References: <CAOhmDzcc4oDRXOzpOKaGF1UBXQ2jL1AZM-BokmtstF71jgTTXw@mail.gmail.com>
Subject: Re: spark-prs and mesos/spark-ec2
X-Mailer: Airmail Beta (261)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54382e1c_327b23c6_d2c9"
X-Virus-Checked: Checked by ClamAV on apache.org

--54382e1c_327b23c6_d2c9
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I think this would require fairly significant refactoring of the PR board=
 code. =C2=A0I=E2=80=99d love it if the PR board code was more easily con=
figurable to support different JIRA / GitHub repositories, etc, but I don=
=E2=80=99t have the time to work on this myself.

- Josh

On October 9, 2014 at 6:20:12 PM, Nicholas Chammas (nicholas.chammas=40gm=
ail.com) wrote:

Does it make sense to point the Spark PR review board to read from =20
mesos/spark-ec2 as well=3F PRs submitted against that repo may reference =
=20
Spark JIRAs and need review just like any other Spark PR. =20

Nick =20

--54382e1c_327b23c6_d2c9--


From dev-return-9773-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 10 20:01:47 2014
Return-Path: <dev-return-9773-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 26E2F17F9F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 10 Oct 2014 20:01:47 +0000 (UTC)
Received: (qmail 42059 invoked by uid 500); 10 Oct 2014 20:01:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41994 invoked by uid 500); 10 Oct 2014 20:01:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41983 invoked by uid 99); 10 Oct 2014 20:01:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 20:01:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 10 Oct 2014 20:01:42 +0000
Received: by mail-la0-f54.google.com with SMTP id gm9so3949366lab.27
        for <dev@spark.apache.org>; Fri, 10 Oct 2014 13:01:20 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=Uu6CCGyIOs7kzQRJzuelZxvOHs3iq9QxfCSNqAJSHcE=;
        b=lHAZXZwuvaCopeJZ7hDwhJIJHbutjBvqllSZQQ3h1NnjO0Vhz5gPQz1yn9g4fynf5G
         ofaVYHVtyx4ZkUDT/cxF8+Th5KBmZAXamcaNONIU5ex5VE6YLb415wAvsUmrSo0HHfF0
         MIQH9vKfS+ULEV+m0ZtQfgHew2w+NUs1om6A+mcN5O0KjRuqcjJz6Bp2FI/8IYMo4SiY
         vfEh9r2s6mFKhjrUCt1lxk8vGNHgzfYwB6pMBOifbnpB/nzymb44NRAZlnlgmQzICJD5
         Lwmsj1kbnAaWukdkx6yNmAi27yrGKu1ksoXrCKl7hZPxAA0ENCn5s7+/qMFcOLzt0i9L
         nSVQ==
X-Gm-Message-State: ALoCoQndwylLjCrAk/foANOO6Qy/fe9SB57COJovTGiw4se3ou+rRQ0dW/KeiN7EOCR/KbOS03WD
X-Received: by 10.112.151.99 with SMTP id up3mr7053958lbb.45.1412971280214;
 Fri, 10 Oct 2014 13:01:20 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.115.1.133 with HTTP; Fri, 10 Oct 2014 13:01:00 -0700 (PDT)
In-Reply-To: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 10 Oct 2014 13:01:00 -0700
Message-ID: <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=047d7b33dcb23c3f1805051703a6
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b33dcb23c3f1805051703a6
Content-Type: text/plain; charset=UTF-8

reminder:  this IS happening, first thing monday morning PDT.  :)

On Wed, Oct 8, 2014 at 3:01 PM, shane knapp <sknapp@berkeley.edu> wrote:

> greetings!
>
> i've got some updates regarding our new jenkins infrastructure, as well as
> the initial date and plan for rolling things out:
>
> *** current testing/build break whack-a-mole:
> a lot of out of date artifacts are cached in the current jenkins, which
> has caused a few builds during my testing to break due to dependency
> resolution failure[1][2].
>
> bumping these versions can cause your builds to fail, due to public api
> changes and the like.  consider yourself warned that some projects might
> require some debugging...  :)
>
> tomorrow, i will be at databricks working w/@joshrosen to make sure that
> the spark builds have any bugs hammered out.
>
> ***  deployment plan:
> unless something completely horrible happens, THE NEW JENKINS WILL GO LIVE
> ON MONDAY (october 13th).
>
> all jenkins infrastructure will be DOWN for the entirety of the day
> (starting at ~8am).  this means no builds, period.  i'm hoping that the
> downtime will be much shorter than this, but we'll have to see how
> everything goes.
>
> all test/build history WILL BE PRESERVED.  i will be rsyncing the jenkins
> jobs/ directory over, complete w/history as part of the deployment.
>
> once i'm feeling good about the state of things, i'll point the original
> url to the new instances and send out an all clear.
>
> if you are a student at UC berkeley, you can log in to jenkins using your
> LDAP login, and (by default) view but not change plans.  if you do not have
> a UC berkeley LDAP login, you can still view plans anonymously.
>
> IF YOU ARE A PLAN ADMIN, THEN PLEASE REACH OUT, ASAP, PRIVATELY AND I WILL
> SET UP ADMIN ACCESS TO YOUR BUILDS.
>
> ***  post deployment plan:
> fix all of the things that break!
>
> i will be keeping a VERY close eye on the builds, checking for breaks, and
> helping out where i can.  if the situation is dire, i can always roll back
> to the old jenkins infra...  but i hope we never get to that point!  :)
>
> i'm hoping that things will go smoothly, but please be patient as i'm
> certain we'll hit a few bumps in the road.
>
> please let me know if you guys have any comments/questions/concerns...  :)
>
> shane
>
> 1 - https://github.com/bigdatagenomics/bdg-services/pull/18
> 2 - https://github.com/bigdatagenomics/avocado/pull/111
>

--047d7b33dcb23c3f1805051703a6--

From dev-return-9774-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 11 06:04:35 2014
Return-Path: <dev-return-9774-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B129C172E4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 11 Oct 2014 06:04:35 +0000 (UTC)
Received: (qmail 87467 invoked by uid 500); 11 Oct 2014 06:04:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87356 invoked by uid 500); 11 Oct 2014 06:04:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86387 invoked by uid 99); 11 Oct 2014 06:04:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 11 Oct 2014 06:04:33 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of henry.saputra@gmail.com designates 209.85.215.45 as permitted sender)
Received: from [209.85.215.45] (HELO mail-la0-f45.google.com) (209.85.215.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 11 Oct 2014 06:04:28 +0000
Received: by mail-la0-f45.google.com with SMTP id q1so4380293lam.32
        for <multiple recipients>; Fri, 10 Oct 2014 23:04:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=Maop9h4SMvRjrY3Avn2zENoB5/pi3pIZu3IcoI3S1Bo=;
        b=KW+Icc98XDcJGISDqQjpUK8nTG4UFDRSa8ok2kos0h68DcbqX3K0YUI3sixsQekN+A
         z7vdIeqq9qWsz64IU+RaQcCQlhjarMn2pcCySbySKkh9j0HEho9hJCHr8+H0SzI+ncol
         PZfqA7ygGrpKNPldAp5nkO/clqXddxRa38SZIcgGtNBTi5Sjg79j/ccqv19ki5iZPpmt
         QaSyGWzBZL58FJpLU4z6L6Z5xhobLcTvesonYicsGXxnYChqhNbWLazfiJZlWoeIG7jr
         TZqeLCHrYlpc7CNAqlzx5uBlmrsxFI7St2mt+nm0ZDgrEzON1p4LfZuVOoNTmEUdVhdY
         CArw==
MIME-Version: 1.0
X-Received: by 10.112.14.34 with SMTP id m2mr9129889lbc.74.1413007447259; Fri,
 10 Oct 2014 23:04:07 -0700 (PDT)
Received: by 10.25.31.75 with HTTP; Fri, 10 Oct 2014 23:04:07 -0700 (PDT)
In-Reply-To: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
Date: Fri, 10 Oct 2014 23:04:07 -0700
Message-ID: <CALuGr6ZntDmEcqfvsxdCzUXNAoHmBa+v-1Vc+HqhnuiVWVRmOA@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Henry Saputra <henry.saputra@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: user <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Congrats to Reynold et al leading this effort!

- Henry

On Fri, Oct 10, 2014 at 7:54 AM, Matei Zaharia <matei.zaharia@gmail.com> wr=
ote:
> Hi folks,
>
> I interrupt your regularly scheduled user / dev list to bring you some pr=
etty cool news for the project, which is that we've been able to use Spark =
to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x faster o=
n 10x fewer nodes. There's a detailed writeup at http://databricks.com/blog=
/2014/10/10/spark-breaks-previous-large-scale-sort-record.html. Summary: wh=
ile Hadoop MapReduce held last year's 100 TB world record by sorting 100 TB=
 in 72 minutes on 2100 nodes, we sorted it in 23 minutes on 206 nodes; and =
we also scaled up to sort 1 PB in 234 minutes.
>
> I want to thank Reynold Xin for leading this effort over the past few wee=
ks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali Ghodsi.=
 In addition, we'd really like to thank Amazon's EC2 team for providing the=
 machines to make this possible. Finally, this result would of course not b=
e possible without the many many other contributions, testing and feature r=
equests from throughout the community.
>
> For an engine to scale from these multi-hour petabyte batch jobs down to =
100-millisecond streaming and interactive queries is quite uncommon, and it=
's thanks to all of you folks that we are able to make this happen.
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9775-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 11 06:19:11 2014
Return-Path: <dev-return-9775-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A8F3A17321
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 11 Oct 2014 06:19:11 +0000 (UTC)
Received: (qmail 10159 invoked by uid 500); 11 Oct 2014 06:19:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10038 invoked by uid 500); 11 Oct 2014 06:19:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9059 invoked by uid 99); 11 Oct 2014 06:19:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 11 Oct 2014 06:19:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jianshi.huang@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 11 Oct 2014 06:19:04 +0000
Received: by mail-la0-f51.google.com with SMTP id ge10so4410570lab.10
        for <multiple recipients>; Fri, 10 Oct 2014 23:18:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=lnKj+Ytsf4xLTG2VcXfvXVOgRri+ezM2cJvpfDwXWNo=;
        b=i3Hevt4zYYf1aBVwVqxEppxE8qh+EQXG39BZP1TwiECABVsJ2MyzTUuigjtoGS7PC1
         7YsWHS6Xn0Gy32OV4fxJcElFK1cmhU6s4H8qjatXH7NHBQxEfqy+1b5oJTQjsBMhr/sq
         BM+mJwS+1Zo7EaUT4d6wA2Ta58wLt5mrSNN2OGETSqudtQDfwnlvvauy69ncrfpjYNhp
         rr1GVTnhWyat0hDcZ5Cgu7dOItksWKEp89ef3ZFoQzdYGL/8hzgktswAssZuUK23ERLk
         /NWlqtcR7ntBT6f9BUdELnudEUbs7s5Kx0vKAuMKzSlwpNwPJ7OGZ5Q5WrQXCT46KKGQ
         tjlg==
X-Received: by 10.152.5.130 with SMTP id s2mr9700424las.0.1413008322780; Fri,
 10 Oct 2014 23:18:42 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.161.208 with HTTP; Fri, 10 Oct 2014 23:18:22 -0700 (PDT)
In-Reply-To: <CAAswR-6wQpKR5iyyqEpNtFwqkV3ywz58kRXd4TrO4eYUO+B0Wg@mail.gmail.com>
References: <CACA1tWKf1purfZMGWjjTraxFr-Ac8oOEKVfgef5DK-tNriyVbg@mail.gmail.com>
 <CALte62xka0O9+YyY26MBPPxC8U2DJuZY=wiLrXJAGKsvu+h3gA@mail.gmail.com>
 <CACA1tWKNwvPWw7=6SLdqZGyktOpVNTpOTVYJwrA_8HcqnJN_+Q@mail.gmail.com>
 <CACA1tWJvw10CGtrRzZ8R1+AhGit-+Zmm-Pi14E3MKfjc7H+NOg@mail.gmail.com>
 <CACA1tWJ5asqTnV3D1HmYP+U-T7bTODJMLhNBuFA=1-a5B9fDHA@mail.gmail.com> <CAAswR-6wQpKR5iyyqEpNtFwqkV3ywz58kRXd4TrO4eYUO+B0Wg@mail.gmail.com>
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Sat, 11 Oct 2014 14:18:22 +0800
Message-ID: <CACA1tWJc+hHEBjgKUWAtQRkhDOGvL17Qt0o6_NVLJ0rqdYT4Ng@mail.gmail.com>
Subject: Re: How to do broadcast join in SparkSQL
To: Michael Armbrust <michael@databricks.com>
Cc: Ted Yu <yuzhihong@gmail.com>, user <user@spark.apache.org>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0141a1d024e3e305051fa32d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0141a1d024e3e305051fa32d
Content-Type: text/plain; charset=UTF-8

It works fine, thanks for the help Michael.

Liancheng also told me a trick, using a subquery with LIMIT n. It works in
latest 1.2.0

BTW, looks like the broadcast optimization won't be recognized if I do a
left join instead of a inner join. Is that true? How can I make it work for
left joins?

Cheers,
Jianshi

On Thu, Oct 9, 2014 at 3:10 AM, Michael Armbrust <michael@databricks.com>
wrote:

> Thanks for the input.  We purposefully made sure that the config option
> did not make it into a release as it is not something that we are willing
> to support long term.  That said we'll try and make this easier in the
> future either through hints or better support for statistics.
>
> In this particular case you can get what you want by registering the
> tables as external tables and setting an flag.  Here's a helper function to
> do what you need.
>
> /**
>  * Sugar for creating a Hive external table from a parquet path.
>  */
> def createParquetTable(name: String, file: String): Unit = {
>   import org.apache.spark.sql.hive.HiveMetastoreTypes
>
>   val rdd = parquetFile(file)
>   val schema = rdd.schema.fields.map(f => s"${f.name}
> ${HiveMetastoreTypes.toMetastoreType(f.dataType)}").mkString(",\n")
>   val ddl = s"""
>     |CREATE EXTERNAL TABLE $name (
>     |  $schema
>     |)
>     |ROW FORMAT SERDE 'parquet.hive.serde.ParquetHiveSerDe'
>     |STORED AS INPUTFORMAT 'parquet.hive.DeprecatedParquetInputFormat'
>     |OUTPUTFORMAT 'parquet.hive.DeprecatedParquetOutputFormat'
>     |LOCATION '$file'""".stripMargin
>   sql(ddl)
>   setConf("spark.sql.hive.convertMetastoreParquet", "true")
> }
>
> You'll also need to run this to populate the statistics:
>
> ANALYZE TABLE  tableName COMPUTE STATISTICS noscan;
>
>
> On Wed, Oct 8, 2014 at 1:44 AM, Jianshi Huang <jianshi.huang@gmail.com>
> wrote:
>
>> Ok, currently there's cost-based optimization however Parquet statistics
>> is not implemented...
>>
>> What's the good way if I want to join a big fact table with several tiny
>> dimension tables in Spark SQL (1.1)?
>>
>> I wish we can allow user hint for the join.
>>
>> Jianshi
>>
>> On Wed, Oct 8, 2014 at 2:18 PM, Jianshi Huang <jianshi.huang@gmail.com>
>> wrote:
>>
>>> Looks like https://issues.apache.org/jira/browse/SPARK-1800 is not
>>> merged into master?
>>>
>>> I cannot find spark.sql.hints.broadcastTables in latest master, but
>>> it's in the following patch.
>>>
>>>
>>> https://github.com/apache/spark/commit/76ca4341036b95f71763f631049fdae033990ab5
>>>
>>>
>>> Jianshi
>>>
>>>
>>> On Mon, Sep 29, 2014 at 1:24 AM, Jianshi Huang <jianshi.huang@gmail.com>
>>> wrote:
>>>
>>>> Yes, looks like it can only be controlled by the
>>>> parameter spark.sql.autoBroadcastJoinThreshold, which is a little bit weird
>>>> to me.
>>>>
>>>> How am I suppose to know the exact bytes of a table? Let me specify the
>>>> join algorithm is preferred I think.
>>>>
>>>> Jianshi
>>>>
>>>> On Sun, Sep 28, 2014 at 11:57 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>>
>>>>> Have you looked at SPARK-1800 ?
>>>>>
>>>>> e.g. see sql/core/src/test/scala/org/apache/spark/sql/JoinSuite.scala
>>>>> Cheers
>>>>>
>>>>> On Sun, Sep 28, 2014 at 1:55 AM, Jianshi Huang <
>>>>> jianshi.huang@gmail.com> wrote:
>>>>>
>>>>>> I cannot find it in the documentation. And I have a dozen dimension
>>>>>> tables to (left) join...
>>>>>>
>>>>>>
>>>>>> Cheers,
>>>>>> --
>>>>>> Jianshi Huang
>>>>>>
>>>>>> LinkedIn: jianshi
>>>>>> Twitter: @jshuang
>>>>>> Github & Blog: http://huangjs.github.com/
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> Jianshi Huang
>>>>
>>>> LinkedIn: jianshi
>>>> Twitter: @jshuang
>>>> Github & Blog: http://huangjs.github.com/
>>>>
>>>
>>>
>>>
>>> --
>>> Jianshi Huang
>>>
>>> LinkedIn: jianshi
>>> Twitter: @jshuang
>>> Github & Blog: http://huangjs.github.com/
>>>
>>
>>
>>
>> --
>> Jianshi Huang
>>
>> LinkedIn: jianshi
>> Twitter: @jshuang
>> Github & Blog: http://huangjs.github.com/
>>
>
>


-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--089e0141a1d024e3e305051fa32d--

From dev-return-9776-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 11 06:19:32 2014
Return-Path: <dev-return-9776-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 32C5817322
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 11 Oct 2014 06:19:32 +0000 (UTC)
Received: (qmail 12628 invoked by uid 500); 11 Oct 2014 06:19:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12560 invoked by uid 500); 11 Oct 2014 06:19:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 22477 invoked by uid 99); 11 Oct 2014 05:09:57 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ilganeli@gmail.com designates 209.85.213.172 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ptgH09izJ/WOvE2SHwa+PCz8QClf63tUyBDCbj5Wo3s=;
        b=LpbT3giuLVTZ8L1UZoEJT8DSWhWED/cLlxwkCKOGK7Ol3DVMDAdzi2Um+TsdllPDsv
         pUf0Jcaa88KzHHlrJoRjXgSzArOlvLSt8kwUTIY/j57Te3POFHZuoHJwCRXxrUNIesnv
         C3ZlfinPMmiU9/glOXNckh7Os/0HWvJpQ3ty9eo2jIuQGAxzdXbNDsLc3r1ohTWR34OE
         Hsif62eOO1yQ7Uye2c/ECCQ8IXjCg+pz8/rEvoLKWozXJRtw/7AZAthuL5QwRv18Mu4W
         fY2LIW36YcYRnUq42uScbTKzxOZiVlwg3XhwTDmWWZUhQEdHwzhKNt41JgJoDEok1K2M
         tDsQ==
MIME-Version: 1.0
X-Received: by 10.42.38.134 with SMTP id c6mr21158936ice.16.1413004172549;
 Fri, 10 Oct 2014 22:09:32 -0700 (PDT)
In-Reply-To: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
Date: Sat, 11 Oct 2014 01:09:32 -0400
Message-ID: <CAM-S9zTYKdhSdWaqUL-LuXCOrMDrERCY_kA87Wgb+KwJth3o=g@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Ilya Ganelin <ilganeli@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: dev@spark.apache.org, user@spark.apache.org
Content-Type: multipart/alternative; boundary=20cf30364003c5638c05051eab49
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf30364003c5638c05051eab49
Content-Type: text/plain; charset=UTF-8

Hi Matei - I read your post with great interest. Could you possibly comment
in more depth on some of the issues you guys saw when scaling up spark and
how you resolved them? I am interested specifically in spark-related
problems. I'm working on scaling up spark to very large datasets and have
been running into a variety of issues. Thanks in advance!
On Oct 10, 2014 10:54 AM, "Matei Zaharia" <matei.zaharia@gmail.com> wrote:

> Hi folks,
>
> I interrupt your regularly scheduled user / dev list to bring you some
> pretty cool news for the project, which is that we've been able to use
> Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x
> faster on 10x fewer nodes. There's a detailed writeup at
> http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-record.html.
> Summary: while Hadoop MapReduce held last year's 100 TB world record by
> sorting 100 TB in 72 minutes on 2100 nodes, we sorted it in 23 minutes on
> 206 nodes; and we also scaled up to sort 1 PB in 234 minutes.
>
> I want to thank Reynold Xin for leading this effort over the past few
> weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali
> Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for
> providing the machines to make this possible. Finally, this result would of
> course not be possible without the many many other contributions, testing
> and feature requests from throughout the community.
>
> For an engine to scale from these multi-hour petabyte batch jobs down to
> 100-millisecond streaming and interactive queries is quite uncommon, and
> it's thanks to all of you folks that we are able to make this happen.
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
>

--20cf30364003c5638c05051eab49--

From dev-return-9777-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 12 18:50:57 2014
Return-Path: <dev-return-9777-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8997117942
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 12 Oct 2014 18:50:57 +0000 (UTC)
Received: (qmail 91709 invoked by uid 500); 12 Oct 2014 18:50:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91636 invoked by uid 500); 12 Oct 2014 18:50:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91624 invoked by uid 99); 12 Oct 2014 18:50:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 12 Oct 2014 18:50:56 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.213.176 as permitted sender)
Received: from [209.85.213.176] (HELO mail-ig0-f176.google.com) (209.85.213.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 12 Oct 2014 18:50:29 +0000
Received: by mail-ig0-f176.google.com with SMTP id hn15so8231363igb.3
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 11:50:28 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=VOPP/AUyDvP2pfagttnGVF6z+vudVZoHj8w17PcWi8Q=;
        b=aKJKWthNFNAgvgq79TjZ82+vRMrP70zXTq9VP7sDOWv/OsSeZ45Mk9k9RAESD4NdfZ
         AyEKVawSHZtzzIlqGwHcMu2Y5FhsXx8Yj2llOWE7bM9efloaBHdILi13lHSHS7EZJ4Th
         qsNKsz8kLrgNyT6cS3/YER/XUuyBzzjXSni7SP0vtuJKgxiwFeoaMp3JNIlFl5VeGZ+E
         sI9WKejALTDbwCcDlKzXerxZc0T5v7h6EY7ZOAjLTqZQbdJ1k5lw1rFhvblFm2fUQrc4
         Fv2ZB6b0vXYMA2OvvNHjO6VZRJ8aa0eUDos9pUOu2C8sPa0F+SrK3NU+RriHKb2vn0M6
         mhuQ==
X-Gm-Message-State: ALoCoQniSnV5Z1Qe9HilBT3IgPtlF4cDnNg/8x1gc9AQyfvA6Pv2c3Zz1Q81B2sFKLas6BvdnHlf
X-Received: by 10.42.106.204 with SMTP id a12mr3906858icp.88.1413139828214;
 Sun, 12 Oct 2014 11:50:28 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Sun, 12 Oct 2014 11:50:08 -0700 (PDT)
From: Sean Owen <sowen@cloudera.com>
Date: Sun, 12 Oct 2014 19:50:08 +0100
Message-ID: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
Subject: Decision forests don't work with non-trivial categorical features
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

I'm having trouble getting decision forests to work with categorical
features. I have a dataset with a categorical feature with 40 values.
It seems to be treated as a continuous/numeric value by the
implementation.

Digging deeper, I see there is some logic in the code that indicates
that categorical features over N values do not work unless the number
of bins is at least 2*((2^N - 1) - 1) bins. I understand this as the
naive brute force condition, wherein the decision tree will test all
possible splits of the categorical value.

However, this gets unusable quickly as the number of bins should be
tens or hundreds at best, and this requirement rules out categorical
values over more than 10 or so features as a result. But, of course,
it's not unusual to have categorical features with high cardinality.
It's almost common.

There are some pretty fine heuristics for selecting 'bins' over
categorical features when the number of bins is far fewer than the
complete, exhaustive set.

Before I open a JIRA or continue, does anyone know what I am talking
about, am I mistaken? Is this a real limitation and is it worth
pursuing these heuristics? I can't figure out how to proceed with
decision forests in MLlib otherwise.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9778-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 12 20:51:51 2014
Return-Path: <dev-return-9778-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AB42B17B60
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 12 Oct 2014 20:51:51 +0000 (UTC)
Received: (qmail 893 invoked by uid 500); 12 Oct 2014 20:51:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 815 invoked by uid 500); 12 Oct 2014 20:51:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 803 invoked by uid 99); 12 Oct 2014 20:51:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 12 Oct 2014 20:51:50 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.220.49] (HELO mail-pa0-f49.google.com) (209.85.220.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 12 Oct 2014 20:51:43 +0000
Received: by mail-pa0-f49.google.com with SMTP id hz1so4763374pad.36
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 13:51:23 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:from:content-type:content-transfer-encoding
         :subject:message-id:date:to:mime-version;
        bh=ubmuRgbd20n6XJ9XDnB3qpjVCBzCKXi1tPnvGT0BS+s=;
        b=FaFR4QPCj8am6OSqdXQSCUefcalojo7ZtGqj1RALhEOH4hjeFmHegWphPdXlC/6w4Y
         MF5jWQenbPHbzjRyanKDyqCvwhaV/xiJix38vX1o0L1EP6Zn228uvp3dE838Ab+1Tf2T
         pjapj5XusTt/uFR9FtpwLg61FJ9cYq8asZhoCtq2CSLORimGVEtVnJMbGKPlO694m1Wx
         NeoyEsXWM9UdjN4NI5ejsfSz6+K2bcgy6Yc4G2WfL1NIfeFWoVhFsiKcv/4lDpXowlqG
         s7H0YE1Jd2opa+/Sv4THVziH4AEi/xwXirepgucXtjbSw3hqGNdIk3dBfEIzxK0ROfFj
         Mfsg==
X-Gm-Message-State: ALoCoQnQ8CZBkaUjO/jm+MnwM9DvHtJOMB6F2U54NQFKnFuSuvmnN2BXnsvy49wX67s0TGTGZ0Pb
X-Received: by 10.66.65.130 with SMTP id x2mr19347769pas.79.1413147083463;
        Sun, 12 Oct 2014 13:51:23 -0700 (PDT)
Received: from [10.0.1.203] (50-1-154-50.dsl.dynamic.fusionbroadband.com. [50.1.154.50])
        by mx.google.com with ESMTPSA id x7sm9267098pdj.36.2014.10.12.13.51.22
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 12 Oct 2014 13:51:23 -0700 (PDT)
From: Michael Allman <michael@videoamp.com>
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Subject: reading/writing parquet decimal type
Message-Id: <6D485596-9181-44B5-AF05-CFB44E22902F@videoamp.com>
Date: Sun, 12 Oct 2014 13:51:21 -0700
To: dev@spark.apache.org
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Hello,

I'm interested in reading/writing parquet SchemaRDDs that support the =
Parquet Decimal converted type. The first thing I did was update the =
Spark parquet dependency to version 1.5.0, as this version introduced =
support for decimals in parquet. However, conversion between the =
catalyst decimal type and the parquet decimal type is complicated by the =
fact that the catalyst type does not specify a decimal precision and =
scale but the parquet type requires them.

I'm wondering if perhaps we could add an optional precision and scale to =
the catalyst decimal type? The catalyst decimal type would have =
unspecified precision and scale by default for backwards compatibility, =
but users who want to serialize a SchemaRDD with decimal(s) to parquet =
would have to narrow their decimal type(s) by specifying a precision and =
scale.

Thoughts?

Michael=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9779-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 12 22:32:58 2014
Return-Path: <dev-return-9779-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C84B517CB3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 12 Oct 2014 22:32:58 +0000 (UTC)
Received: (qmail 4733 invoked by uid 500); 12 Oct 2014 22:32:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4645 invoked by uid 500); 12 Oct 2014 22:32:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4628 invoked by uid 99); 12 Oct 2014 22:32:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 12 Oct 2014 22:32:57 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.43 as permitted sender)
Received: from [209.85.220.43] (HELO mail-pa0-f43.google.com) (209.85.220.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 12 Oct 2014 22:32:52 +0000
Received: by mail-pa0-f43.google.com with SMTP id lf10so4804898pab.2
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 15:32:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=IHXzvfSvDcEWsaCy4OY5Lldd2NkicvROplpE4pyLFX8=;
        b=x7MlPpWsoEivLJ6PggwhCHfP9Y4y/PqpLkEfbPzLCmBEq6FL7g+LDR1/G7u1JDCCnI
         U7Pxr95W09ar3d/1/9EiqBgnBOlhwtcOFmaDpKNEB/zHMwi1LxPOXT8Jq7WEYV5EAoyD
         9do4q3CCyd/UWHl/ef0SF17TU+VxfN0g9ojV12NCz+uQ5T9kPZUSIPrqRivUhSxtI7KD
         dNxXuAOIIlFW897wvU2aIH3OyDUCco2+WjmguHQoTB9rqPsM6bdnbEeHrrsytfMJPnUT
         fCsFffsGTwYLbX5THDYlqo+hM0PJ8ZWUgaYDKL2WU2J6gBPyx2gtzMCubLFsWylvzq1h
         9g1w==
X-Received: by 10.70.126.101 with SMTP id mx5mr19917237pdb.112.1413153152093;
        Sun, 12 Oct 2014 15:32:32 -0700 (PDT)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id y2sm6550085pdp.31.2014.10.12.15.32.30
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 12 Oct 2014 15:32:31 -0700 (PDT)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: reading/writing parquet decimal type
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <6D485596-9181-44B5-AF05-CFB44E22902F@videoamp.com>
Date: Sun, 12 Oct 2014 15:32:29 -0700
Cc: dev@spark.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <2089C711-2427-4BB5-90CB-32F2E5123DD3@gmail.com>
References: <6D485596-9181-44B5-AF05-CFB44E22902F@videoamp.com>
To: Michael Allman <michael@videoamp.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Michael,

I've been working on this in my repo: =
https://github.com/mateiz/spark/tree/decimal. I'll make some pull =
requests with these features soon, but meanwhile you can try this =
branch. See https://github.com/mateiz/spark/compare/decimal for the =
individual commits that went into it. It has exactly the precision stuff =
you need, plus some optimizations for working on decimals.

Matei

On Oct 12, 2014, at 1:51 PM, Michael Allman <michael@videoamp.com> =
wrote:

> Hello,
>=20
> I'm interested in reading/writing parquet SchemaRDDs that support the =
Parquet Decimal converted type. The first thing I did was update the =
Spark parquet dependency to version 1.5.0, as this version introduced =
support for decimals in parquet. However, conversion between the =
catalyst decimal type and the parquet decimal type is complicated by the =
fact that the catalyst type does not specify a decimal precision and =
scale but the parquet type requires them.
>=20
> I'm wondering if perhaps we could add an optional precision and scale =
to the catalyst decimal type? The catalyst decimal type would have =
unspecified precision and scale by default for backwards compatibility, =
but users who want to serialize a SchemaRDD with decimal(s) to parquet =
would have to narrow their decimal type(s) by specifying a precision and =
scale.
>=20
> Thoughts?
>=20
> Michael
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9780-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 02:35:17 2014
Return-Path: <dev-return-9780-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BFD0017F9C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 02:35:17 +0000 (UTC)
Received: (qmail 16965 invoked by uid 500); 13 Oct 2014 02:35:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16889 invoked by uid 500); 13 Oct 2014 02:35:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16876 invoked by uid 99); 13 Oct 2014 02:35:16 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 02:35:16 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of evan.sparks@gmail.com designates 209.85.192.177 as permitted sender)
Received: from [209.85.192.177] (HELO mail-pd0-f177.google.com) (209.85.192.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 02:34:49 +0000
Received: by mail-pd0-f177.google.com with SMTP id v10so4865165pde.36
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 19:34:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=VJ6qLzQjVCOeE0LovsPHFePI1boo0TWMRHsA5s7Z6yo=;
        b=nzmmqg1yE2QycTJUqOCTHJZsm0hkWHgFV1hsAyFE8+ffye8wi4/mmpZyrlVBmqA95/
         b+SVT8hmfCgA9aRK8DnAwBRZEjPvbPqNAyiBm7JA/dDQmyptMeWMDGTrRooe5RgeOSGT
         YVewg3paBxIDTwtWHVW6mEh0oHcB8rsgKZwIfeKhAW8g3xKV5jYZsTYYZY/XVDw9YgaR
         SpoepwB45MiZiUJ4H6jRtS6s7AI7CD5yjUJvN3stQKbrUotitNVzv3P/dh9513K9v+0k
         BZLODEBiICatZDtV6x+PKMPmeuheT9jftKouJXYbc9VnnpwfDfUb0DUSM/glMPfIC6vV
         iHeg==
X-Received: by 10.68.141.173 with SMTP id rp13mr20544920pbb.18.1413167688223;
        Sun, 12 Oct 2014 19:34:48 -0700 (PDT)
Received: from [10.166.188.187] (mobile-107-107-62-197.mycingular.net. [107.107.62.197])
        by mx.google.com with ESMTPSA id i10sm9655895pdn.26.2014.10.12.19.34.47
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 12 Oct 2014 19:34:47 -0700 (PDT)
Content-Type: text/plain;
	charset=us-ascii
Mime-Version: 1.0 (1.0)
Subject: Re: Decision forests don't work with non-trivial categorical features
From: Evan Sparks <evan.sparks@gmail.com>
X-Mailer: iPhone Mail (11D257)
In-Reply-To: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
Date: Sun, 12 Oct 2014 22:34:43 -0400
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <0AA6CFCF-B93C-4CD2-B5B1-881A727780F0@gmail.com>
References: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
To: Sean Owen <sowen@cloudera.com>
X-Virus-Checked: Checked by ClamAV on apache.org

I was under the impression that we were using the usual sort by average resp=
onse value heuristic when storing histogram bins (and searching for optimal s=
plits) in the tree code.=20

Maybe Manish or Joseph can clarify?

> On Oct 12, 2014, at 2:50 PM, Sean Owen <sowen@cloudera.com> wrote:
>=20
> I'm having trouble getting decision forests to work with categorical
> features. I have a dataset with a categorical feature with 40 values.
> It seems to be treated as a continuous/numeric value by the
> implementation.
>=20
> Digging deeper, I see there is some logic in the code that indicates
> that categorical features over N values do not work unless the number
> of bins is at least 2*((2^N - 1) - 1) bins. I understand this as the
> naive brute force condition, wherein the decision tree will test all
> possible splits of the categorical value.
>=20
> However, this gets unusable quickly as the number of bins should be
> tens or hundreds at best, and this requirement rules out categorical
> values over more than 10 or so features as a result. But, of course,
> it's not unusual to have categorical features with high cardinality.
> It's almost common.
>=20
> There are some pretty fine heuristics for selecting 'bins' over
> categorical features when the number of bins is far fewer than the
> complete, exhaustive set.
>=20
> Before I open a JIRA or continue, does anyone know what I am talking
> about, am I mistaken? Is this a real limitation and is it worth
> pursuing these heuristics? I can't figure out how to proceed with
> decision forests in MLlib otherwise.
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9781-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 03:20:43 2014
Return-Path: <dev-return-9781-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 66CCA17212
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 03:20:43 +0000 (UTC)
Received: (qmail 56605 invoked by uid 500); 13 Oct 2014 03:20:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56521 invoked by uid 500); 13 Oct 2014 03:20:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56510 invoked by uid 99); 13 Oct 2014 03:20:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 03:20:42 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.220.52] (HELO mail-pa0-f52.google.com) (209.85.220.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 03:20:16 +0000
Received: by mail-pa0-f52.google.com with SMTP id fb1so5162999pad.11
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 20:20:14 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:content-type:mime-version:subject:from
         :in-reply-to:date:cc:content-transfer-encoding:message-id:references
         :to;
        bh=Qxurrts0H/s/4fxEjenGi/JeEZGYBqFRbX2iIAbuaEc=;
        b=eBp0biktxhVV4I4k1ppvuEmPMFRycK5TWHJNnuVbcoBvPCngyQsIcuJc+RL40534BH
         9zIVqfvpV/CpQVgEdC3ZeCoLN9J+S7GeZ7v5tcY2sCR9On6d6yH9nHD/uYmRIKwjXKk7
         1Y68s3Ab/+yLL4vOIg3itVReIcY0Hn30Rrd8Lr2zX4yrze9QbDmLRN37k0q0f0BJ+krq
         AV4IO1/iLDYXTFQ6I8UWZ6Z5Bn40g3OxEQiGT9Vh/IyjjTt8txs6XSlL6BCQk/oDEelI
         Qn7LiFQfAyLh5pqVIdsRxrXUDeQyyrrJO4yrEQNqRf/+RbcX6bbHWFTmwbjyVARPmlVr
         WNrQ==
X-Gm-Message-State: ALoCoQlVex/ky4nf2zJWGESxEL48TjxPH66tiBkWn9lhK3ZnoTO+Er7O225ZE5tKsefTMCD85ziJ
X-Received: by 10.70.140.199 with SMTP id ri7mr20860547pdb.47.1413170414190;
        Sun, 12 Oct 2014 20:20:14 -0700 (PDT)
Received: from [10.0.1.203] (50-1-154-50.dsl.dynamic.fusionbroadband.com. [50.1.154.50])
        by mx.google.com with ESMTPSA id ap5sm9818380pad.22.2014.10.12.20.20.13
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 12 Oct 2014 20:20:13 -0700 (PDT)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: reading/writing parquet decimal type
From: Michael Allman <michael@videoamp.com>
In-Reply-To: <2089C711-2427-4BB5-90CB-32F2E5123DD3@gmail.com>
Date: Sun, 12 Oct 2014 20:20:11 -0700
Cc: dev@spark.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <0ED145D3-33D8-48DB-943F-7BA69924B036@videoamp.com>
References: <6D485596-9181-44B5-AF05-CFB44E22902F@videoamp.com> <2089C711-2427-4BB5-90CB-32F2E5123DD3@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Matei,

Thanks, I can see you've been hard at work on this! I examined your =
patch and do have a question. It appears you're limiting the precision =
of decimals written to parquet to those that will fit in a long, yet =
you're writing the values as a parquet binary type. Why not write them =
using the int64 parquet type instead?

Cheers,

Michael

On Oct 12, 2014, at 3:32 PM, Matei Zaharia <matei.zaharia@gmail.com> =
wrote:

> Hi Michael,
>=20
> I've been working on this in my repo: =
https://github.com/mateiz/spark/tree/decimal. I'll make some pull =
requests with these features soon, but meanwhile you can try this =
branch. See https://github.com/mateiz/spark/compare/decimal for the =
individual commits that went into it. It has exactly the precision stuff =
you need, plus some optimizations for working on decimals.
>=20
> Matei
>=20
> On Oct 12, 2014, at 1:51 PM, Michael Allman <michael@videoamp.com> =
wrote:
>=20
>> Hello,
>>=20
>> I'm interested in reading/writing parquet SchemaRDDs that support the =
Parquet Decimal converted type. The first thing I did was update the =
Spark parquet dependency to version 1.5.0, as this version introduced =
support for decimals in parquet. However, conversion between the =
catalyst decimal type and the parquet decimal type is complicated by the =
fact that the catalyst type does not specify a decimal precision and =
scale but the parquet type requires them.
>>=20
>> I'm wondering if perhaps we could add an optional precision and scale =
to the catalyst decimal type? The catalyst decimal type would have =
unspecified precision and scale by default for backwards compatibility, =
but users who want to serialize a SchemaRDD with decimal(s) to parquet =
would have to narrow their decimal type(s) by specifying a precision and =
scale.
>>=20
>> Thoughts?
>>=20
>> Michael
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9782-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 04:37:37 2014
Return-Path: <dev-return-9782-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6DAE117349
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 04:37:37 +0000 (UTC)
Received: (qmail 14385 invoked by uid 500); 13 Oct 2014 04:37:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14307 invoked by uid 500); 13 Oct 2014 04:37:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14291 invoked by uid 99); 13 Oct 2014 04:37:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 04:37:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.192.170 as permitted sender)
Received: from [209.85.192.170] (HELO mail-pd0-f170.google.com) (209.85.192.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 04:37:08 +0000
Received: by mail-pd0-f170.google.com with SMTP id p10so5044438pdj.29
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 21:37:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:subject:mime-version:content-type;
        bh=OnQXJfDXsAmF6oTJ5PlehS8zCfTxalscng81GaWlegM=;
        b=epEvwz7xPVHranxV69f2JwWHKYH265eOWeZ7Y9Am2PUunFDkyxiGYfu81/OKkD6fzP
         you80NudTsqPR5WWmaYKm6zKFcGZ3qKOm84r/z5RWS4ezIi8hS4lZhCNueVa5ogP3OZX
         XEycOcjN1sxvvTnDatjLsA1lEohvMtOUjNEkgifAWEAgTT2263BYBihIBoTbsUBCdObE
         HZQjW38O+ATT94J1KQc24L+OaZIaCtfUYr0bppJLtuaW2G4yDY+Rli8SHxStDCGH4cHX
         I5EY8BPiXi5zjrstHU2tdU/oRXMiIlCEwmXqahZ0ehQnnsrnDXmqV95iI0YIN2y77OU1
         HJ3Q==
X-Received: by 10.70.125.163 with SMTP id mr3mr21760965pdb.24.1413175026533;
        Sun, 12 Oct 2014 21:37:06 -0700 (PDT)
Received: from joshs-mbp.att.net ([2602:306:cdd1:b10:1480:3569:2cba:67f1])
        by mx.google.com with ESMTPSA id kk10sm9819156pdb.63.2014.10.12.21.37.05
        for <dev@spark.apache.org>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Sun, 12 Oct 2014 21:37:06 -0700 (PDT)
Date: Sun, 12 Oct 2014 21:37:04 -0700
From: Josh Rosen <rosenville@gmail.com>
To: dev <dev@spark.apache.org>
Message-ID: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net>
Subject: Scalastyle improvements / large code reformatting
X-Mailer: Airmail Beta (261)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="543b56f0_327b23c6_105"
X-Virus-Checked: Checked by ClamAV on apache.org

--543b56f0_327b23c6_105
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

There are a number of open pull requests that aim to extend Spark=E2=80=99=
s automated style checks (see=C2=A0https://issues.apache.org/jira/browse/=
SPARK-3849=C2=A0for an umbrella JIRA). =C2=A0These fixes are mostly good,=
 but I have some concerns about merging these patches. =C2=A0Several of t=
hese patches make large reformatting changes in nearly every file of Spar=
k, which makes it more difficult to use =60git blame=60 and has the poten=
tial to introduce merge conflicts with all open PRs and all backport patc=
hes.

I feel that most of the value of automated style-checks comes from allowi=
ng reviewers/committers to focus on the technical content of pull request=
s rather than their formatting.=C2=A0 My concern is that the convenience =
added by these new style rules will not outweigh the other overheads that=
 these reformatting patches will create for the committers.

If possible, it would be great if we could extend the style checker to en=
force the more stringent rules only for new code additions / deletions. =C2=
=A0If not, I don=E2=80=99t think that we should proceed with the reformat=
ting. =C2=A0Others might disagree, though, so I welcome comments / discus=
sion.

- Josh
--543b56f0_327b23c6_105--


From dev-return-9783-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 04:40:21 2014
Return-Path: <dev-return-9783-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3CADC1734B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 04:40:21 +0000 (UTC)
Received: (qmail 16671 invoked by uid 500); 13 Oct 2014 04:40:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16584 invoked by uid 500); 13 Oct 2014 04:40:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16573 invoked by uid 99); 13 Oct 2014 04:40:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 04:40:19 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.192.48] (HELO mail-qg0-f48.google.com) (209.85.192.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 04:39:52 +0000
Received: by mail-qg0-f48.google.com with SMTP id i50so6394171qgf.35
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 21:39:50 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=9XTfimFpMGw20YlGxIpTAmnVzPB9u/OlzO/b2OrrPK8=;
        b=DeacKWSsvoKlsA7fco4oRfFQkd6omeca/Ts5oww0Qc05r5RJ0xR9Gb+aogQYEgPe3e
         Zs0vBIIzQWhWxyqmALB+WJZOb7+VAMkzNcc4Fp3JI/OGMZvAYhyh5rGmkjF4T3ciRKDf
         m5Unt9k4ALL9y39+F2nCy3vRHWr7WiVVckw10h/QTD5qiH2iktPfP7lWLyWOFOfYPOa5
         tT1imGE8qzTS/F9E8wZQhpQdC0MKGE4CMd0rlszdW/q0Jtsniog0gdZ0MWw89m5Ftvpq
         PFe8Lip/YibE9dAIxyW/7vQKxX4hoLP1IjRR2lris/T/9Xu5WoL5qyqe+DqZ51ku69F8
         7A4A==
X-Gm-Message-State: ALoCoQmo3mgTidDOWHNpxpuXjkHC7mQmXHpOjbrbdCIl04uCptkNKBVYGf2WwlJ+BshpI5QKD3B/
X-Received: by 10.140.98.197 with SMTP id o63mr35078241qge.78.1413175189952;
 Sun, 12 Oct 2014 21:39:49 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.47.8 with HTTP; Sun, 12 Oct 2014 21:39:29 -0700 (PDT)
In-Reply-To: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net>
References: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net>
From: Reynold Xin <rxin@databricks.com>
Date: Sun, 12 Oct 2014 21:39:29 -0700
Message-ID: <CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com>
Subject: Re: Scalastyle improvements / large code reformatting
To: Josh Rosen <rosenville@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a544e3419c70505467d6d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a544e3419c70505467d6d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I actually think we should just take the bite and follow through with the
reformatting. Many rules are simply not possible to enforce only on deltas
(e.g. import ordering).

That said, maybe there are better windows to do this, e.g. during the QA
period.

On Sun, Oct 12, 2014 at 9:37 PM, Josh Rosen <rosenville@gmail.com> wrote:

> There are a number of open pull requests that aim to extend Spark=E2=80=
=99s
> automated style checks (see
> https://issues.apache.org/jira/browse/SPARK-3849 for an umbrella JIRA).
> These fixes are mostly good, but I have some concerns about merging these
> patches.  Several of these patches make large reformatting changes in
> nearly every file of Spark, which makes it more difficult to use `git
> blame` and has the potential to introduce merge conflicts with all open P=
Rs
> and all backport patches.
>
> I feel that most of the value of automated style-checks comes from
> allowing reviewers/committers to focus on the technical content of pull
> requests rather than their formatting.  My concern is that the convenienc=
e
> added by these new style rules will not outweigh the other overheads that
> these reformatting patches will create for the committers.
>
> If possible, it would be great if we could extend the style checker to
> enforce the more stringent rules only for new code additions / deletions.
> If not, I don=E2=80=99t think that we should proceed with the reformattin=
g.  Others
> might disagree, though, so I welcome comments / discussion.
>
> - Josh

--001a113a544e3419c70505467d6d--

From dev-return-9784-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 05:17:21 2014
Return-Path: <dev-return-9784-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C19FB1744F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 05:17:21 +0000 (UTC)
Received: (qmail 71762 invoked by uid 500); 13 Oct 2014 05:17:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71710 invoked by uid 500); 13 Oct 2014 05:17:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71698 invoked by uid 99); 13 Oct 2014 05:17:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 05:17:19 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.48 as permitted sender)
Received: from [209.85.218.48] (HELO mail-oi0-f48.google.com) (209.85.218.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 05:16:54 +0000
Received: by mail-oi0-f48.google.com with SMTP id g201so12021195oib.7
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 22:16:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=nAwsrUjtql0b8xVk7wRWL73Bkr4P2I3bcK6/hcUC0+k=;
        b=K6PyTuRBwev0jcTeUh6pYgGLbMCEN/kZol0DV41NmSBDYXtdK8LAVg+PboO4mmqckw
         sI/xpJJHZIfQso0mreJyDTH8JSBGOvznSczE0IG9mnnghCjhIlkNfToK8HKs9EsjH/Jp
         zCqomf6pOVQpG4kfdXvlWwpGCpbsKpblYVY+kzQbDyUKCESp9btrN0xiWvTflxeoDvdH
         rEA3XY6R+z4jbkorA5/dT1gpg5hZtxev5j3hJxBtI07u+7jT+U0+id316GAzjjWqU5ka
         +z32agshEYBfoh7+oCpl2pob9HjsxncBQJ/2/xoNYXOQORmALHGV/VMIqRsnwOmNufDl
         Qi5Q==
MIME-Version: 1.0
X-Received: by 10.60.103.13 with SMTP id fs13mr123102oeb.48.1413177412532;
 Sun, 12 Oct 2014 22:16:52 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Sun, 12 Oct 2014 22:16:52 -0700 (PDT)
In-Reply-To: <CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com>
References: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net>
	<CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com>
Date: Sun, 12 Oct 2014 22:16:52 -0700
Message-ID: <CABPQxssViFY129Bn9WF8yEvZGy63nJ-9BpMTKLNnVx825LZhcg@mail.gmail.com>
Subject: Re: Scalastyle improvements / large code reformatting
From: Patrick Wendell <pwendell@gmail.com>
To: Reynold Xin <rxin@databricks.com>
Cc: Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Another big problem with these patches are that they make it almost
impossible to backport changes to older branches cleanly (there
becomes like 100% chance of a merge conflict).

One proposal is to do this:
1. We only consider new style rules at the end of a release cycle,
when there is the smallest chance of wanting to backport stuff.
2. We require that they are submitted in individual patches with a (a)
new style rule and (b) the associated changes. Then we can also
evaluate on a case-by-case basis how large the change is for each
rule. For rules that require sweeping changes across the codebase,
personally I'd vote against them. For rules like import ordering that
won't cause too much pain on the diff (it's pretty easy to deal with
those conflicts) I'd be okay with it.

If we went with this, we'd also have to warn people that we might not
accept new style rules if they are too costly to enforce. I'm guessing
people will still contribute even with those expectations.

- Patrick

On Sun, Oct 12, 2014 at 9:39 PM, Reynold Xin <rxin@databricks.com> wrote:
> I actually think we should just take the bite and follow through with the
> reformatting. Many rules are simply not possible to enforce only on deltas
> (e.g. import ordering).
>
> That said, maybe there are better windows to do this, e.g. during the QA
> period.
>
> On Sun, Oct 12, 2014 at 9:37 PM, Josh Rosen <rosenville@gmail.com> wrote:
>
>> There are a number of open pull requests that aim to extend Spark's
>> automated style checks (see
>> https://issues.apache.org/jira/browse/SPARK-3849 for an umbrella JIRA).
>> These fixes are mostly good, but I have some concerns about merging these
>> patches.  Several of these patches make large reformatting changes in
>> nearly every file of Spark, which makes it more difficult to use `git
>> blame` and has the potential to introduce merge conflicts with all open PRs
>> and all backport patches.
>>
>> I feel that most of the value of automated style-checks comes from
>> allowing reviewers/committers to focus on the technical content of pull
>> requests rather than their formatting.  My concern is that the convenience
>> added by these new style rules will not outweigh the other overheads that
>> these reformatting patches will create for the committers.
>>
>> If possible, it would be great if we could extend the style checker to
>> enforce the more stringent rules only for new code additions / deletions.
>> If not, I don't think that we should proceed with the reformatting.  Others
>> might disagree, though, so I welcome comments / discussion.
>>
>> - Josh

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9785-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 05:23:55 2014
Return-Path: <dev-return-9785-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E1A0817465
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 05:23:55 +0000 (UTC)
Received: (qmail 77133 invoked by uid 500); 13 Oct 2014 05:23:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77054 invoked by uid 500); 13 Oct 2014 05:23:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77037 invoked by uid 99); 13 Oct 2014 05:23:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 05:23:54 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.176 as permitted sender)
Received: from [209.85.192.176] (HELO mail-pd0-f176.google.com) (209.85.192.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 05:23:49 +0000
Received: by mail-pd0-f176.google.com with SMTP id fp1so4970966pdb.7
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 22:23:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=Hm0hHJD0L90yrZVkZe5DeRwslrtTAqFyMF8mjU3nfdo=;
        b=D5Am872iBgXRbdu6pdbwGCDq0ZkXqOYbHzOXCfCeeCq4lBnzsgvjHsgadUZvzg2WIS
         y0WN/N8KuQD08UwU7+e8QCsbqwraqMkvY/K03eaSuPfsmJlXjVmu1Y1eZm0sAHcNgRvq
         uY/UkghRENCyq1fOnlZ1NN0WZLR9hW5JmoxtKU3qYuy4f07HWBC2Z8SInTv7NzLTUV7p
         dpTPD+x5EuIkxlRz5J+w4Oms6iC2Hgn3ZR6u95Qb8fNcdGM3FqcnR8YYNZvsjdN/xJIG
         N+ICGxqwThKFHZYvnzKqxtji/GyOcJqjA5JXCmNF3/60yfOMUjh4nyzH3sjzF16qLtn5
         GC9Q==
X-Received: by 10.70.54.8 with SMTP id f8mr21132314pdp.110.1413177808996;
        Sun, 12 Oct 2014 22:23:28 -0700 (PDT)
Received: from [192.168.1.106] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id cy9sm9975825pdb.28.2014.10.12.22.23.27
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 12 Oct 2014 22:23:28 -0700 (PDT)
Content-Type: text/plain; charset=iso-8859-1
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Scalastyle improvements / large code reformatting
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CABPQxssViFY129Bn9WF8yEvZGy63nJ-9BpMTKLNnVx825LZhcg@mail.gmail.com>
Date: Sun, 12 Oct 2014 22:23:25 -0700
Cc: Reynold Xin <rxin@databricks.com>,
 Josh Rosen <rosenville@gmail.com>,
 dev <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <2760C3F7-35E9-4448-9C90-229FE2C852A0@gmail.com>
References: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net> <CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com> <CABPQxssViFY129Bn9WF8yEvZGy63nJ-9BpMTKLNnVx825LZhcg@mail.gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

I'm also against these huge reformattings. They slow down development =
and backporting for trivial reasons. Let's not do that at this point, =
the style of the current code is quite consistent and we have plenty of =
other things to worry about. Instead, what you can do is as you edit a =
file when you're working on a feature, fix up style issues you see. Or, =
as Josh suggested, some way to make this apply only to new files would =
help.

Matei

On Oct 12, 2014, at 10:16 PM, Patrick Wendell <pwendell@gmail.com> =
wrote:

> Another big problem with these patches are that they make it almost
> impossible to backport changes to older branches cleanly (there
> becomes like 100% chance of a merge conflict).
>=20
> One proposal is to do this:
> 1. We only consider new style rules at the end of a release cycle,
> when there is the smallest chance of wanting to backport stuff.
> 2. We require that they are submitted in individual patches with a (a)
> new style rule and (b) the associated changes. Then we can also
> evaluate on a case-by-case basis how large the change is for each
> rule. For rules that require sweeping changes across the codebase,
> personally I'd vote against them. For rules like import ordering that
> won't cause too much pain on the diff (it's pretty easy to deal with
> those conflicts) I'd be okay with it.
>=20
> If we went with this, we'd also have to warn people that we might not
> accept new style rules if they are too costly to enforce. I'm guessing
> people will still contribute even with those expectations.
>=20
> - Patrick
>=20
> On Sun, Oct 12, 2014 at 9:39 PM, Reynold Xin <rxin@databricks.com> =
wrote:
>> I actually think we should just take the bite and follow through with =
the
>> reformatting. Many rules are simply not possible to enforce only on =
deltas
>> (e.g. import ordering).
>>=20
>> That said, maybe there are better windows to do this, e.g. during the =
QA
>> period.
>>=20
>> On Sun, Oct 12, 2014 at 9:37 PM, Josh Rosen <rosenville@gmail.com> =
wrote:
>>=20
>>> There are a number of open pull requests that aim to extend Spark's
>>> automated style checks (see
>>> https://issues.apache.org/jira/browse/SPARK-3849 for an umbrella =
JIRA).
>>> These fixes are mostly good, but I have some concerns about merging =
these
>>> patches.  Several of these patches make large reformatting changes =
in
>>> nearly every file of Spark, which makes it more difficult to use =
`git
>>> blame` and has the potential to introduce merge conflicts with all =
open PRs
>>> and all backport patches.
>>>=20
>>> I feel that most of the value of automated style-checks comes from
>>> allowing reviewers/committers to focus on the technical content of =
pull
>>> requests rather than their formatting.  My concern is that the =
convenience
>>> added by these new style rules will not outweigh the other overheads =
that
>>> these reformatting patches will create for the committers.
>>>=20
>>> If possible, it would be great if we could extend the style checker =
to
>>> enforce the more stringent rules only for new code additions / =
deletions.
>>> If not, I don't think that we should proceed with the reformatting.  =
Others
>>> might disagree, though, so I welcome comments / discussion.
>>>=20
>>> - Josh
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9786-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 05:48:54 2014
Return-Path: <dev-return-9786-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 24EEF174FD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 05:48:54 +0000 (UTC)
Received: (qmail 5354 invoked by uid 500); 13 Oct 2014 05:48:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5279 invoked by uid 500); 13 Oct 2014 05:48:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5267 invoked by uid 99); 13 Oct 2014 05:48:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 05:48:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.182 as permitted sender)
Received: from [209.85.192.182] (HELO mail-pd0-f182.google.com) (209.85.192.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 05:48:27 +0000
Received: by mail-pd0-f182.google.com with SMTP id y10so5082929pdj.27
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 22:48:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=7QZvMe0NNbNjItwFyJaOkDvq7UQgHjHrJyWkdVGWahw=;
        b=f0Ats6O0AYvdaFnHT6Hpimfztih+cjoDPGEKmLfCrU5HBVxXprR7t+CP/Ud5hQCsEK
         GREe2GEWmehAwbsCa8xZZTJpE5yPIDtxYDqEVXLnse878DNdT0+F9bs99dg7bheB9xNO
         d/a03yGAhFr05svsF4EMtiQ91M3X4Ag/e2yPS0ExWZIQGhHk7oshr2q0Qb5wlNwS9pRM
         kNgdyxoASGwJpcYkUMSmiw/bnRrec559OVVAnN92yFouEwRWmKvSFVqkow2qd8ubFi4x
         gx0fuuwSOAZsxvZCyFB4V/KyVj5ogLpN/cZxu/OvVTz8C0uQwWpm9uRKIzRyIJaP+dby
         CaDA==
X-Received: by 10.66.250.227 with SMTP id zf3mr63064pac.135.1413179305570;
        Sun, 12 Oct 2014 22:48:25 -0700 (PDT)
Received: from [192.168.1.106] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id sa6sm9647212pbb.29.2014.10.12.22.48.24
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 12 Oct 2014 22:48:24 -0700 (PDT)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: reading/writing parquet decimal type
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <0ED145D3-33D8-48DB-943F-7BA69924B036@videoamp.com>
Date: Sun, 12 Oct 2014 22:48:22 -0700
Cc: dev@spark.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <90908724-1C31-4075-9B9C-014470B240DC@gmail.com>
References: <6D485596-9181-44B5-AF05-CFB44E22902F@videoamp.com> <2089C711-2427-4BB5-90CB-32F2E5123DD3@gmail.com> <0ED145D3-33D8-48DB-943F-7BA69924B036@videoamp.com>
To: Michael Allman <michael@videoamp.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

The fixed-length binary type can hold fewer bytes than an int64, though =
many encodings of int64 can probably do the right thing. We can look =
into supporting multiple ways to do this -- the spec does say that you =
should at least be able to read int32s and int64s.

Matei

On Oct 12, 2014, at 8:20 PM, Michael Allman <michael@videoamp.com> =
wrote:

> Hi Matei,
>=20
> Thanks, I can see you've been hard at work on this! I examined your =
patch and do have a question. It appears you're limiting the precision =
of decimals written to parquet to those that will fit in a long, yet =
you're writing the values as a parquet binary type. Why not write them =
using the int64 parquet type instead?
>=20
> Cheers,
>=20
> Michael
>=20
> On Oct 12, 2014, at 3:32 PM, Matei Zaharia <matei.zaharia@gmail.com> =
wrote:
>=20
>> Hi Michael,
>>=20
>> I've been working on this in my repo: =
https://github.com/mateiz/spark/tree/decimal. I'll make some pull =
requests with these features soon, but meanwhile you can try this =
branch. See https://github.com/mateiz/spark/compare/decimal for the =
individual commits that went into it. It has exactly the precision stuff =
you need, plus some optimizations for working on decimals.
>>=20
>> Matei
>>=20
>> On Oct 12, 2014, at 1:51 PM, Michael Allman <michael@videoamp.com> =
wrote:
>>=20
>>> Hello,
>>>=20
>>> I'm interested in reading/writing parquet SchemaRDDs that support =
the Parquet Decimal converted type. The first thing I did was update the =
Spark parquet dependency to version 1.5.0, as this version introduced =
support for decimals in parquet. However, conversion between the =
catalyst decimal type and the parquet decimal type is complicated by the =
fact that the catalyst type does not specify a decimal precision and =
scale but the parquet type requires them.
>>>=20
>>> I'm wondering if perhaps we could add an optional precision and =
scale to the catalyst decimal type? The catalyst decimal type would have =
unspecified precision and scale by default for backwards compatibility, =
but users who want to serialize a SchemaRDD with decimal(s) to parquet =
would have to narrow their decimal type(s) by specifying a precision and =
scale.
>>>=20
>>> Thoughts?
>>>=20
>>> Michael
>>> =
---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>=20
>>=20
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9787-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 06:26:41 2014
Return-Path: <dev-return-9787-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E5C8817630
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 06:26:40 +0000 (UTC)
Received: (qmail 61839 invoked by uid 500); 13 Oct 2014 06:26:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61770 invoked by uid 500); 13 Oct 2014 06:26:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61745 invoked by uid 99); 13 Oct 2014 06:26:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 06:26:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.220.52 as permitted sender)
Received: from [209.85.220.52] (HELO mail-pa0-f52.google.com) (209.85.220.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 06:26:23 +0000
Received: by mail-pa0-f52.google.com with SMTP id fb1so5257658pad.25
        for <dev@spark.apache.org>; Sun, 12 Oct 2014 23:26:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=qYvfjxZoPcN5J/wwoeUsZgdUoc7O4uSgR9MGNTkWMKw=;
        b=UGDqce85A5eHkggDFtep4Dea5GtNM+l/YkVe4mj0MxTJK7eTewz1KhT5+57xRa+jzL
         gSp47CZxDb5Ldg83RXqbWEKZeKCLyxSoscGVOmB4UZyHHDA1P7gNdKzGIeAUhpxXtDIm
         dUYKhptf6rpI6a1ZplWlNkNDwbpFeTo8c52eTAPAPefsbn76wuwbziBqykUp/KM/rHzj
         ui0xcYzVpzRcPa4cNARSi3tFLc8Sx90ubYtVqlJM5MaDq4xoY2vHdUtMNIbf48Fk+bgY
         N9a9NhVkIv6wmVKtFlL8ugYjQ/OXMVZ1Zjn+vH6Q2jyXWmn6BRJ7HxOq+DnCUl0k+/BC
         N/jw==
MIME-Version: 1.0
X-Received: by 10.66.240.173 with SMTP id wb13mr2050601pac.103.1413181562473;
 Sun, 12 Oct 2014 23:26:02 -0700 (PDT)
Received: by 10.70.68.69 with HTTP; Sun, 12 Oct 2014 23:26:02 -0700 (PDT)
In-Reply-To: <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
	<CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
Date: Sun, 12 Oct 2014 23:26:02 -0700
Message-ID: <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
From: Josh Rosen <rosenville@gmail.com>
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Cc: shane knapp <sknapp@berkeley.edu>
Content-Type: multipart/alternative; boundary=047d7b11218d08d410050547f925
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b11218d08d410050547f925
Content-Type: text/plain; charset=UTF-8

Reminder: this Jenkins migration is happening tomorrow morning (Monday).

On Fri, Oct 10, 2014 at 1:01 PM, shane knapp <sknapp@berkeley.edu> wrote:

> reminder:  this IS happening, first thing monday morning PDT.  :)
>
> On Wed, Oct 8, 2014 at 3:01 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
> > greetings!
> >
> > i've got some updates regarding our new jenkins infrastructure, as well
> as
> > the initial date and plan for rolling things out:
> >
> > *** current testing/build break whack-a-mole:
> > a lot of out of date artifacts are cached in the current jenkins, which
> > has caused a few builds during my testing to break due to dependency
> > resolution failure[1][2].
> >
> > bumping these versions can cause your builds to fail, due to public api
> > changes and the like.  consider yourself warned that some projects might
> > require some debugging...  :)
> >
> > tomorrow, i will be at databricks working w/@joshrosen to make sure that
> > the spark builds have any bugs hammered out.
> >
> > ***  deployment plan:
> > unless something completely horrible happens, THE NEW JENKINS WILL GO
> LIVE
> > ON MONDAY (october 13th).
> >
> > all jenkins infrastructure will be DOWN for the entirety of the day
> > (starting at ~8am).  this means no builds, period.  i'm hoping that the
> > downtime will be much shorter than this, but we'll have to see how
> > everything goes.
> >
> > all test/build history WILL BE PRESERVED.  i will be rsyncing the jenkins
> > jobs/ directory over, complete w/history as part of the deployment.
> >
> > once i'm feeling good about the state of things, i'll point the original
> > url to the new instances and send out an all clear.
> >
> > if you are a student at UC berkeley, you can log in to jenkins using your
> > LDAP login, and (by default) view but not change plans.  if you do not
> have
> > a UC berkeley LDAP login, you can still view plans anonymously.
> >
> > IF YOU ARE A PLAN ADMIN, THEN PLEASE REACH OUT, ASAP, PRIVATELY AND I
> WILL
> > SET UP ADMIN ACCESS TO YOUR BUILDS.
> >
> > ***  post deployment plan:
> > fix all of the things that break!
> >
> > i will be keeping a VERY close eye on the builds, checking for breaks,
> and
> > helping out where i can.  if the situation is dire, i can always roll
> back
> > to the old jenkins infra...  but i hope we never get to that point!  :)
> >
> > i'm hoping that things will go smoothly, but please be patient as i'm
> > certain we'll hit a few bumps in the road.
> >
> > please let me know if you guys have any comments/questions/concerns...
> :)
> >
> > shane
> >
> > 1 - https://github.com/bigdatagenomics/bdg-services/pull/18
> > 2 - https://github.com/bigdatagenomics/avocado/pull/111
> >
>

--047d7b11218d08d410050547f925--

From dev-return-9788-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 08:05:21 2014
Return-Path: <dev-return-9788-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C05B117853
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 08:05:21 +0000 (UTC)
Received: (qmail 9752 invoked by uid 500); 13 Oct 2014 08:05:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9684 invoked by uid 500); 13 Oct 2014 08:05:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9673 invoked by uid 99); 13 Oct 2014 08:05:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 08:05:08 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.213.180 as permitted sender)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 08:05:03 +0000
Received: by mail-ig0-f180.google.com with SMTP id uq10so9587718igb.1
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 01:04:43 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=kZztnWR5dURcqbBdY7lm6mMZLbhYLSikwbWoNJp9V1c=;
        b=j9IukDF+z+B6MykzedxPVdaW3SpIUtMlgL8a2A6e7n3YSpSHdfOVYkLWE9CzvANU7B
         M78rX7AHagFf+AatVdasur272VU1A04bPiBN/RQuLCD0v1cd7s08YhT9dc5jKofmlkjP
         xqjGWbBMSwLG6NnFAHPgmLABnrsfAzrGkoaSK4GAgJG1YwmAeKBw9k1eniHI+dbd+NKb
         WeUBkMxt3G0sO8cw+FXPHF5XPb+xhkcGuSblP7Q98+gX9PaDLxy7ldt8VP2+5TONQ3kW
         jg05DZnGpE6vnCCbBOpXINMRS6kIa5sw8x3d1ll/q7mU+dKzH//MxGYF6SSghlEZ/gJi
         Pjkg==
X-Gm-Message-State: ALoCoQk6OaRinBrmvb0a7b1+3qld7rgsz3dswZgud/39EGn5g82JYRp6hD7wW16uMAPMsS8KGUMi
X-Received: by 10.50.122.1 with SMTP id lo1mr28007061igb.5.1413187483292; Mon,
 13 Oct 2014 01:04:43 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Mon, 13 Oct 2014 01:04:23 -0700 (PDT)
In-Reply-To: <0AA6CFCF-B93C-4CD2-B5B1-881A727780F0@gmail.com>
References: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
 <0AA6CFCF-B93C-4CD2-B5B1-881A727780F0@gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 13 Oct 2014 09:04:23 +0100
Message-ID: <CAMAsSdK50QTOLV5_j4A_Bi337Deq1q7F4Aqf5y+ivDwS=19Efg@mail.gmail.com>
Subject: Re: Decision forests don't work with non-trivial categorical features
To: Evan Sparks <evan.sparks@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

I'm looking at this bit of code in DecisionTreeMetadata ...

val maxCategoriesForUnorderedFeature =
  ((math.log(maxPossibleBins / 2 + 1) / math.log(2.0)) + 1).floor.toInt
strategy.categoricalFeaturesInfo.foreach { case (featureIndex, numCategories) =>
  // Decide if some categorical features should be treated as
unordered features,
  //  which require 2 * ((1 << numCategories - 1) - 1) bins.
  // We do this check with log values to prevent overflows in case
numCategories is large.
  // The next check is equivalent to: 2 * ((1 << numCategories - 1) -
1) <= maxBins
  if (numCategories <= maxCategoriesForUnorderedFeature) {
    unorderedFeatures.add(featureIndex)
    numBins(featureIndex) = numUnorderedBins(numCategories)
  } else {
    numBins(featureIndex) = numCategories
  }
}

So if I have a feature with 40 values and less than about a trillion
bins, it gets treated as a continuous feature, which is meaningless.
It shortly throws an exception though since other parts of the code
expect this to be a categorical feature.

I think there's a bug here somewhere but wasn't sure whether it was
just 'not implemented' yet and so needs a better error message (and
should be implemented), or something else preventing this from working
as expected.

I'll wait a beat to get more info and then if needed open a JIRA. Thanks all.

On Mon, Oct 13, 2014 at 3:34 AM, Evan Sparks <evan.sparks@gmail.com> wrote:
> I was under the impression that we were using the usual sort by average response value heuristic when storing histogram bins (and searching for optimal splits) in the tree code.
>
> Maybe Manish or Joseph can clarify?
>
>> On Oct 12, 2014, at 2:50 PM, Sean Owen <sowen@cloudera.com> wrote:
>>
>> I'm having trouble getting decision forests to work with categorical
>> features. I have a dataset with a categorical feature with 40 values.
>> It seems to be treated as a continuous/numeric value by the
>> implementation.
>>
>> Digging deeper, I see there is some logic in the code that indicates
>> that categorical features over N values do not work unless the number
>> of bins is at least 2*((2^N - 1) - 1) bins. I understand this as the
>> naive brute force condition, wherein the decision tree will test all
>> possible splits of the categorical value.
>>
>> However, this gets unusable quickly as the number of bins should be
>> tens or hundreds at best, and this requirement rules out categorical
>> values over more than 10 or so features as a result. But, of course,
>> it's not unusual to have categorical features with high cardinality.
>> It's almost common.
>>
>> There are some pretty fine heuristics for selecting 'bins' over
>> categorical features when the number of bins is far fewer than the
>> complete, exhaustive set.
>>
>> Before I open a JIRA or continue, does anyone know what I am talking
>> about, am I mistaken? Is this a real limitation and is it worth
>> pursuing these heuristics? I can't figure out how to proceed with
>> decision forests in MLlib otherwise.
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9789-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 08:15:52 2014
Return-Path: <dev-return-9789-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6C6351788E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 08:15:51 +0000 (UTC)
Received: (qmail 27115 invoked by uid 500); 13 Oct 2014 08:15:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27037 invoked by uid 500); 13 Oct 2014 08:15:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25979 invoked by uid 99); 13 Oct 2014 08:15:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 08:15:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jianshi.huang@gmail.com designates 209.85.215.41 as permitted sender)
Received: from [209.85.215.41] (HELO mail-la0-f41.google.com) (209.85.215.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 08:15:44 +0000
Received: by mail-la0-f41.google.com with SMTP id pn19so6241400lab.0
        for <multiple recipients>; Mon, 13 Oct 2014 01:15:22 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=hMcJHQ5xmwDbVD5STCob1sjqcF14/d45phAQzZ76L9o=;
        b=hJ4zkCoN4B7kPf/+XDU8gAp9731XjrFSDubmAVcdaa13ol+M7Zc+1HgDge354+o0HH
         Dcj/7JMyKW5j6TYrAXm/qfHqvw3oBIA7PSeC6V3f8f2ERAYkOZQjquN8DJNtrt5TvdF6
         fCV3lCgKZQ8pHFBQuxbXmn/hxDghOFK49FVV/UJlZYpH4eBs93ZT4FNsj1TG62qrRyvh
         AzIvdHoW/D6ixNXSZosDpZL7nl5I0isrVKkC1SZYrs9V8QP1m17nA6PaueaV+ZEXMOWH
         N3QyoEjTZgADiV2FMyeDxD4jqMnUkQcvYe30xYb1/IUV7vdgZFgrz+DXiM38KjDfL6r0
         HCJQ==
X-Received: by 10.112.149.36 with SMTP id tx4mr1788178lbb.79.1413188122667;
 Mon, 13 Oct 2014 01:15:22 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.161.208 with HTTP; Mon, 13 Oct 2014 01:15:02 -0700 (PDT)
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Mon, 13 Oct 2014 16:15:02 +0800
Message-ID: <CACA1tW+oBk3m4V7Paq9bQ_nQ_7G=FATC8CL=sPxDncSCYAubrw@mail.gmail.com>
Subject: SPARK-3106 fixed?
To: user <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b342f4e0d71900505498062
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b342f4e0d71900505498062
Content-Type: text/plain; charset=UTF-8

https://issues.apache.org/jira/browse/SPARK-3106

I'm having the saming errors described in SPARK-3106 (no other types of
errors confirmed), running a bunch sql queries on spark 1.2.0 built from
latest master HEAD.

Any updates to this issue?

My main task is to join a huge fact table with a dozen dim tables (using
HiveContext) and then map it to my class object. It failed a couple of
times and now I cached the intermediate table and currently it seems
working fine... no idea why until I found SPARK-3106

Cheers,
-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--047d7b342f4e0d71900505498062--

From dev-return-9790-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 08:16:49 2014
Return-Path: <dev-return-9790-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5319D17892
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 08:16:49 +0000 (UTC)
Received: (qmail 30159 invoked by uid 500); 13 Oct 2014 08:16:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30082 invoked by uid 500); 13 Oct 2014 08:16:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30071 invoked by uid 99); 13 Oct 2014 08:16:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 08:16:48 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.192.53 as permitted sender)
Received: from [209.85.192.53] (HELO mail-qg0-f53.google.com) (209.85.192.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 08:16:43 +0000
Received: by mail-qg0-f53.google.com with SMTP id q107so794298qgd.40
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 01:16:23 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=bSOMe7su+FAtQpt3tviNMhObxNhPPG5k7iDETjQhOTM=;
        b=NvFexcFEmtZULY+Yfn5c2+py+3WYP7qLkDTnctbQ4mO7zM9T05ElIxmxGmapDphrt6
         fYUibYEJfPa91uXTeOp425IEOKc6Uc9yR2sKm0ND/M8EZm3w7fThuiQwtcTvgZshlHqC
         Fl5aO8Z8oCZYzpNLCVZqnL8LoGIdQdZU37in4pP0W2z1MsWxxHV88UTcigyP0rMAYDw+
         lQx8kTe6hSwKFyQIR2At7nxXEv7AXJqXN7VgDijZjf30RN+zfn9o2Qmei9L2yO9VSsw6
         +neXpBsjm40avM8GHJbjymaiDmtsf+m++wbTniv80iMQIAv2lQEBhix4AG0In4fQeESv
         X41g==
X-Gm-Message-State: ALoCoQkMfoIBjekz862VD14ruU13Gqqzi0mgBwf4KjIVoPvco3xx7xlmEHRGoCZ5+i+wY31aOzSL
X-Received: by 10.140.23.177 with SMTP id 46mr36382798qgp.64.1413188183254;
 Mon, 13 Oct 2014 01:16:23 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.131.105 with HTTP; Mon, 13 Oct 2014 01:16:03 -0700 (PDT)
In-Reply-To: <CAMAsSdK50QTOLV5_j4A_Bi337Deq1q7F4Aqf5y+ivDwS=19Efg@mail.gmail.com>
References: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
 <0AA6CFCF-B93C-4CD2-B5B1-881A727780F0@gmail.com> <CAMAsSdK50QTOLV5_j4A_Bi337Deq1q7F4Aqf5y+ivDwS=19Efg@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 13 Oct 2014 09:16:03 +0100
Message-ID: <CAMAsSdJhANFcnEaLpL-dLjRvxXEbyhqOjKhFWDt80+8J_SKNrg@mail.gmail.com>
Subject: Re: Decision forests don't work with non-trivial categorical features
To: Evan Sparks <evan.sparks@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hm, no I don't think I'm quite right there. There's an issue but
that's not quite it.

So I have a categorical feature with 40 value, and 300 bins. The error
I see in the end is:

java.lang.IllegalArgumentException: requirement failed:
DTStatsAggregator.getLeftRightFeatureOffsets is for unordered features
only, but was called for ordered feature 4.
at scala.Predef$.require(Predef.scala:233)
at org.apache.spark.mllib.tree.impl.DTStatsAggregator.getLeftRightFeatureOffsets(DTStatsAggregator.scala:143)
at org.apache.spark.mllib.tree.DecisionTree$.org$apache$spark$mllib$tree$DecisionTree$$mixedBinSeqOp(DecisionTree.scala:363)
...

So this categorical is treated as an ordered feature because you would
have to have a load of bins to match the condition in the code I
quote. But something isn't expecting that. Is that much worth a JIRA?

Hm, but what's the theory of giving meaning to the ordering of the
arbitrary categorical values? is that what this is trying to do, or is
it in fact ordering by some function of the target (average value for
regression, average 1-vs-all entropy for classification)? I suppose I
didn't expect to encounter logic like this.

On Mon, Oct 13, 2014 at 9:04 AM, Sean Owen <sowen@cloudera.com> wrote:
> I'm looking at this bit of code in DecisionTreeMetadata ...
>
> val maxCategoriesForUnorderedFeature =
>   ((math.log(maxPossibleBins / 2 + 1) / math.log(2.0)) + 1).floor.toInt
> strategy.categoricalFeaturesInfo.foreach { case (featureIndex, numCategories) =>
>   // Decide if some categorical features should be treated as
> unordered features,
>   //  which require 2 * ((1 << numCategories - 1) - 1) bins.
>   // We do this check with log values to prevent overflows in case
> numCategories is large.
>   // The next check is equivalent to: 2 * ((1 << numCategories - 1) -
> 1) <= maxBins
>   if (numCategories <= maxCategoriesForUnorderedFeature) {
>     unorderedFeatures.add(featureIndex)
>     numBins(featureIndex) = numUnorderedBins(numCategories)
>   } else {
>     numBins(featureIndex) = numCategories
>   }
> }
>
> So if I have a feature with 40 values and less than about a trillion
> bins, it gets treated as a continuous feature, which is meaningless.
> It shortly throws an exception though since other parts of the code
> expect this to be a categorical feature.
>
> I think there's a bug here somewhere but wasn't sure whether it was
> just 'not implemented' yet and so needs a better error message (and
> should be implemented), or something else preventing this from working
> as expected.
>
> I'll wait a beat to get more info and then if needed open a JIRA. Thanks all.
>
> On Mon, Oct 13, 2014 at 3:34 AM, Evan Sparks <evan.sparks@gmail.com> wrote:
>> I was under the impression that we were using the usual sort by average response value heuristic when storing histogram bins (and searching for optimal splits) in the tree code.
>>
>> Maybe Manish or Joseph can clarify?
>>
>>> On Oct 12, 2014, at 2:50 PM, Sean Owen <sowen@cloudera.com> wrote:
>>>
>>> I'm having trouble getting decision forests to work with categorical
>>> features. I have a dataset with a categorical feature with 40 values.
>>> It seems to be treated as a continuous/numeric value by the
>>> implementation.
>>>
>>> Digging deeper, I see there is some logic in the code that indicates
>>> that categorical features over N values do not work unless the number
>>> of bins is at least 2*((2^N - 1) - 1) bins. I understand this as the
>>> naive brute force condition, wherein the decision tree will test all
>>> possible splits of the categorical value.
>>>
>>> However, this gets unusable quickly as the number of bins should be
>>> tens or hundreds at best, and this requirement rules out categorical
>>> values over more than 10 or so features as a result. But, of course,
>>> it's not unusual to have categorical features with high cardinality.
>>> It's almost common.
>>>
>>> There are some pretty fine heuristics for selecting 'bins' over
>>> categorical features when the number of bins is far fewer than the
>>> complete, exhaustive set.
>>>
>>> Before I open a JIRA or continue, does anyone know what I am talking
>>> about, am I mistaken? Is this a real limitation and is it worth
>>> pursuing these heuristics? I can't figure out how to proceed with
>>> decision forests in MLlib otherwise.
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9791-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 08:25:13 2014
Return-Path: <dev-return-9791-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BDCC8178C0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 08:25:13 +0000 (UTC)
Received: (qmail 49811 invoked by uid 500); 13 Oct 2014 08:25:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49693 invoked by uid 500); 13 Oct 2014 08:25:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48670 invoked by uid 99); 13 Oct 2014 08:25:11 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 08:25:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jianshi.huang@gmail.com designates 209.85.215.46 as permitted sender)
Received: from [209.85.215.46] (HELO mail-la0-f46.google.com) (209.85.215.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 08:24:45 +0000
Received: by mail-la0-f46.google.com with SMTP id gi9so6239279lab.19
        for <multiple recipients>; Mon, 13 Oct 2014 01:24:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=hB5+T6tPkh9gOluJxMopjx2qAk+gWPlrTdu3JhsHhEo=;
        b=Fk8V7ufYtQyzAvn/jsc/3/GFJYqcmglBVwb3FAQ5rQ7U1lHmd4qz73T/RAOdJQGpM9
         GOoQ1CfPL71zDWgjrt+gEZ7veQpxyueV6fUoZaAL3qtnIrpulvtvuMXfY524vd3EuU54
         Cc4+pn1SLEJNsguJXsLXzugkjKgCPJ191E4qEAqE3A75+pafnD2ufCmSSvWU4DUP+POJ
         StqOtJytE8KGJ7LUC3iYKwpSlbngwf4n/NwU9uZFco4jBRWTz3v3s5aFhjooc2/9pHUj
         BB+zYcT2kHBPpUaAc4PzgelQPPjJwEPIf2d7mvm6ud/4wZ7kBiCuLHaH5gpOOjVbV26r
         Zgsw==
X-Received: by 10.112.7.101 with SMTP id i5mr22092295lba.57.1413188684788;
 Mon, 13 Oct 2014 01:24:44 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.161.208 with HTTP; Mon, 13 Oct 2014 01:24:24 -0700 (PDT)
In-Reply-To: <CACA1tW+oBk3m4V7Paq9bQ_nQ_7G=FATC8CL=sPxDncSCYAubrw@mail.gmail.com>
References: <CACA1tW+oBk3m4V7Paq9bQ_nQ_7G=FATC8CL=sPxDncSCYAubrw@mail.gmail.com>
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Mon, 13 Oct 2014 16:24:24 +0800
Message-ID: <CACA1tWJGots4FNZvof0jp5DBSnGQRGDm3UTaOy7rmgCU4TDAAw@mail.gmail.com>
Subject: Re: SPARK-3106 fixed?
To: user <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=14dae94749d98ebc6e050549a159
X-Virus-Checked: Checked by ClamAV on apache.org

--14dae94749d98ebc6e050549a159
Content-Type: text/plain; charset=UTF-8

Hmm... it failed again, just lasted a little bit longer.

Jianshi

On Mon, Oct 13, 2014 at 4:15 PM, Jianshi Huang <jianshi.huang@gmail.com>
wrote:

> https://issues.apache.org/jira/browse/SPARK-3106
>
> I'm having the saming errors described in SPARK-3106 (no other types of
> errors confirmed), running a bunch sql queries on spark 1.2.0 built from
> latest master HEAD.
>
> Any updates to this issue?
>
> My main task is to join a huge fact table with a dozen dim tables (using
> HiveContext) and then map it to my class object. It failed a couple of
> times and now I cached the intermediate table and currently it seems
> working fine... no idea why until I found SPARK-3106
>
> Cheers,
> --
> Jianshi Huang
>
> LinkedIn: jianshi
> Twitter: @jshuang
> Github & Blog: http://huangjs.github.com/
>



-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--14dae94749d98ebc6e050549a159--

From dev-return-9792-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 12:47:16 2014
Return-Path: <dev-return-9792-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1D1F617F7B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 12:47:16 +0000 (UTC)
Received: (qmail 88900 invoked by uid 500); 13 Oct 2014 12:47:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88834 invoked by uid 500); 13 Oct 2014 12:47:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88822 invoked by uid 99); 13 Oct 2014 12:47:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 12:47:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.173 as permitted sender)
Received: from [209.85.212.173] (HELO mail-wi0-f173.google.com) (209.85.212.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 12:46:48 +0000
Received: by mail-wi0-f173.google.com with SMTP id fb4so7297818wid.6
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 05:46:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Kov50v2EfTtoiO8CJIO2gJIUHlB2SpIhvuodgVVb9XI=;
        b=jfpE7TFj0ceLPt0TYDoV0FSaUbP6/4hizyd2b1kIE3lpc7eFH0AJTHcpJS4Kj9S+wR
         ndk2QruGOTF2uZIMjd7rbC0eDBZFSy+aZ+pPIgzFHmC4NH9sGN/LF7LU5kUnDY/ysVu5
         LyGGGbGKUnHkjWZeuiyitLku2PvKb8GnE4fH29LPka/jJzfL8/WaLSUJm/SpKNK8Yp7H
         IOynqUSgVQ75CZ2a04NHj4Ral8NK7cpXy53Z9DwGFF5lcHQeQ8CrWq7JZPuCWiYSWtHZ
         9JyjRuYrHDQgi89cHauaDYxYlkTyYhxfEQYlW8dQnuyvKoNcOZkz0K8ItbS8lhCCSsT3
         CV/g==
MIME-Version: 1.0
X-Received: by 10.194.8.232 with SMTP id u8mr21413692wja.64.1413204408177;
 Mon, 13 Oct 2014 05:46:48 -0700 (PDT)
Received: by 10.180.99.70 with HTTP; Mon, 13 Oct 2014 05:46:48 -0700 (PDT)
In-Reply-To: <2760C3F7-35E9-4448-9C90-229FE2C852A0@gmail.com>
References: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net>
	<CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com>
	<CABPQxssViFY129Bn9WF8yEvZGy63nJ-9BpMTKLNnVx825LZhcg@mail.gmail.com>
	<2760C3F7-35E9-4448-9C90-229FE2C852A0@gmail.com>
Date: Mon, 13 Oct 2014 08:46:48 -0400
Message-ID: <CAOhmDzf0kH2XrUoutn=81ihAAXx6u+VwJDc28M2AQqq_M+cAZg@mail.gmail.com>
Subject: Re: Scalastyle improvements / large code reformatting
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Reynold Xin <rxin@databricks.com>, 
	Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b5d348cbe9d4205054d4af3
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d348cbe9d4205054d4af3
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

The arguments against large scale refactorings make sense. Doing them, if
at all, during QA cycles or around releases sounds like a promising idea.

Coupled with that, would it be useful to implement new rules outside of
these potential windows for refactoring in such a way that they report on
style errors without failing the build?

That way they work like a nag and encourage developers to fix style
problems in the course of working on their original patch. Coupled with a
clear policy to fix style only where code is being changed anyway, this
could be a helpful way to steadily fix problems related to new rules over
time. Then, when we get close to the "finish line", we can make a final
patch to fix the remaining issues for a given rule and enforce it as part
of the build. Having the style report should also make it easier for
committers to review style. We will have to do some work to show reports on
new rules in a digestible way, as they will probably be very large at
first, but I think that's a tractable problem.

What do committers/reviewers think of that?

As an aside, enforcing new style rules for new files only is an interesting
idea, but you'd have to track that a file was added after the new rules
were enforced. Otherwise bad style will be allowed after the initial
checkin of that file. Also, enforcing style rules on changes may work in
some (e.g. space required  before "{") but is impossible in other (import
ordering) cases, as Reynold pointed out.

Nick


2014=EB=85=84 10=EC=9B=94 13=EC=9D=BC =EC=9B=94=EC=9A=94=EC=9D=BC, Matei Za=
haria<matei.zaharia@gmail.com>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=
=9C =EB=A9=94=EC=8B=9C=EC=A7=80:

> I'm also against these huge reformattings. They slow down development and
> backporting for trivial reasons. Let's not do that at this point, the sty=
le
> of the current code is quite consistent and we have plenty of other thing=
s
> to worry about. Instead, what you can do is as you edit a file when you'r=
e
> working on a feature, fix up style issues you see. Or, as Josh suggested,
> some way to make this apply only to new files would help.
>
> Matei
>
> On Oct 12, 2014, at 10:16 PM, Patrick Wendell <pwendell@gmail.com
> <javascript:;>> wrote:
>
> > Another big problem with these patches are that they make it almost
> > impossible to backport changes to older branches cleanly (there
> > becomes like 100% chance of a merge conflict).
> >
> > One proposal is to do this:
> > 1. We only consider new style rules at the end of a release cycle,
> > when there is the smallest chance of wanting to backport stuff.
> > 2. We require that they are submitted in individual patches with a (a)
> > new style rule and (b) the associated changes. Then we can also
> > evaluate on a case-by-case basis how large the change is for each
> > rule. For rules that require sweeping changes across the codebase,
> > personally I'd vote against them. For rules like import ordering that
> > won't cause too much pain on the diff (it's pretty easy to deal with
> > those conflicts) I'd be okay with it.
> >
> > If we went with this, we'd also have to warn people that we might not
> > accept new style rules if they are too costly to enforce. I'm guessing
> > people will still contribute even with those expectations.
> >
> > - Patrick
> >
> > On Sun, Oct 12, 2014 at 9:39 PM, Reynold Xin <rxin@databricks.com
> <javascript:;>> wrote:
> >> I actually think we should just take the bite and follow through with
> the
> >> reformatting. Many rules are simply not possible to enforce only on
> deltas
> >> (e.g. import ordering).
> >>
> >> That said, maybe there are better windows to do this, e.g. during the =
QA
> >> period.
> >>
> >> On Sun, Oct 12, 2014 at 9:37 PM, Josh Rosen <rosenville@gmail.com
> <javascript:;>> wrote:
> >>
> >>> There are a number of open pull requests that aim to extend Spark's
> >>> automated style checks (see
> >>> https://issues.apache.org/jira/browse/SPARK-3849 for an umbrella
> JIRA).
> >>> These fixes are mostly good, but I have some concerns about merging
> these
> >>> patches.  Several of these patches make large reformatting changes in
> >>> nearly every file of Spark, which makes it more difficult to use `git
> >>> blame` and has the potential to introduce merge conflicts with all
> open PRs
> >>> and all backport patches.
> >>>
> >>> I feel that most of the value of automated style-checks comes from
> >>> allowing reviewers/committers to focus on the technical content of pu=
ll
> >>> requests rather than their formatting.  My concern is that the
> convenience
> >>> added by these new style rules will not outweigh the other overheads
> that
> >>> these reformatting patches will create for the committers.
> >>>
> >>> If possible, it would be great if we could extend the style checker t=
o
> >>> enforce the more stringent rules only for new code additions /
> deletions.
> >>> If not, I don't think that we should proceed with the reformatting.
> Others
> >>> might disagree, though, so I welcome comments / discussion.
> >>>
> >>> - Josh
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> > For additional commands, e-mail: dev-help@spark.apache.org
> <javascript:;>
> >
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> For additional commands, e-mail: dev-help@spark.apache.org <javascript:;>
>
>

--047d7b5d348cbe9d4205054d4af3--

From dev-return-9793-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 13:11:02 2014
Return-Path: <dev-return-9793-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4D37E17257
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 13:11:02 +0000 (UTC)
Received: (qmail 25031 invoked by uid 500); 13 Oct 2014 13:11:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24965 invoked by uid 500); 13 Oct 2014 13:11:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24916 invoked by uid 99); 13 Oct 2014 13:11:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 13:11:00 +0000
X-ASF-Spam-Status: No, hits=2.2 required=5.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jin.oyj@alibaba-inc.com designates 42.120.133.2 as permitted sender)
Received: from [42.120.133.2] (HELO out4133-2.mail.aliyun.com) (42.120.133.2)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 13:10:56 +0000
DKIM-Signature:v=1; a=rsa-sha256; c=relaxed/relaxed;
	d=alibaba-inc.com; s=default;
	t=1413205833; h=Date:From:To:Message-ID:Subject:MIME-Version:Content-Type;
	bh=ccSoN7Wu3TJJDN7RpHSbeK8uYNgC5o0pxH3Q8qAj3ws=;
	b=ndal3bxswnl7ZKd4G2avjhvFagGb0C1tvAYo94Z2DyfhtAsawSOO/AoiIeGHXrhacg6Eo3ccmEFnTNJhFUpsnvEVI0h3vrUjRdItd8YPwNBMOh1XojJfnYzuE9rcwuC6SOLCBhv+J59rVM0A3RDqNprB9hdrPYca/M7/hC3uDB0=
X-Alimail-AntiSpam:AC=PASS;BC=-1|-1;BR=01201311R711e4;FP=0|-1|-1|-1|0|-1|-1|-1;HT=r46d02041;MF=jin.oyj@alibaba-inc.com;PH=DW;RN=3;RT=3;SR=0;
Received: from WS-web (jin.oyj@alibaba-inc.com[182.92.253.16]) by r46d02014.xy2.aliyun.com at Mon, 13 Oct 2014 21:10:30 +0800
Date: Mon, 13 Oct 2014 21:10:30 +0800
From: "=?UTF-8?B?5qyn6Ziz5pmLKOasp+mYs+aZiyk=?=" <jin.oyj@alibaba-inc.com>
To: "user" <user@spark.apache.org>,
  "dev" <dev@spark.apache.org>,
  "Matei Zaharia" <matei.zaharia@gmail.com>
Reply-To: "=?UTF-8?B?5qyn6Ziz5pmLKOasp+mYs+aZiyk=?=" <jin.oyj@alibaba-inc.com>
Message-ID: <ccfbbfa1-b89d-4e10-961b-ae3aeddd2a72@alibaba-inc.com>
Subject: =?UTF-8?B?UmXvvJpCcmVha2luZyB0aGUgcHJldmlvdXMgbGFyZ2Utc2NhbGUgc29ydCByZWNvcmQgd2l0?=
  =?UTF-8?B?aCBTcGFyaw==?=
X-Mailer: Alimail-Mailagent revision 2658173
MIME-Version: 1.0
References: 2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com
In-Reply-To: 2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com
Content-Type: multipart/alternative;
  boundary="----=ALIBOUNDARY_13543_43c54940_543bcf46_2d249"
X-Virus-Checked: Checked by ClamAV on apache.org

------=ALIBOUNDARY_13543_43c54940_543bcf46_2d249
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

=0AGreat News!=0A=0AStill some questions for this Sort benchmark=0A1 How many =
Map tasks run in the sort? I think the 2,50,000 is the # of reduce tasks. (if =
the unsorted file is read from HDFS and use the default 64MB chunk size, the #=
 of map task will be about 1PB/64MB?)2 How long a single Reduce task run ? I t=
hink becuase the #of reduce task is very large , a single reduce task will not=
 last a long time, so the record the reduce read in will also be very small?3 =
How much memory a single Reduce task use in one run?=C2=A0--------------------=
----------------------------------------------=0A=E5=8F=91=E4=BB=B6=E4=BA=BA=EF=
=BC=9AMatei Zaharia <matei.zaharia@gmail.com>=0A=E5=8F=91=E9=80=81=E6=97=B6=E9=
=97=B4=EF=BC=9A2014=E5=B9=B410=E6=9C=8810=E6=97=A5(=E6=98=9F=E6=9C=9F=E4=BA=94=
) 22:54=0A=E6=94=B6=E4=BB=B6=E4=BA=BA=EF=BC=9Auser <user@spark.apache.org>; de=
v <dev@spark.apache.org>=0A=E4=B8=BB=E3=80=80=E9=A2=98=EF=BC=9ABreaking the pr=
evious large-scale sort record with Spark=0A=0AHi folks,=0A=0AI interrupt your=
 regularly scheduled user / dev list to bring you some pretty cool news for th=
e project, which is that we've been able to use Spark to break MapReduce's 100=
 TB and 1 PB sort records, sorting data 3x faster on 10x fewer nodes. There's =
a detailed writeup at http://databricks.com/blog/2014/10/10/spark-breaks-previ=
ous-large-scale-sort-record.html. Summary: while Hadoop MapReduce held last ye=
ar's 100 TB world record by sorting 100 TB in 72 minutes on 2100 nodes, we sor=
ted it in 23 minutes on 206 nodes; and we also scaled up to sort 1 PB in 234 m=
inutes.=0A=0AI want to thank Reynold Xin for leading this effort over the past=
 few weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali Gh=
odsi. In addition, we'd really like to thank Amazon's EC2 team for providing t=
he machines to make this possible. Finally, this result would of course not be=
 possible without the many many other contributions, testing and feature reque=
sts from throughout the community.=0A=0AFor an engine to scale from these mult=
i-hour petabyte batch jobs down to 100-millisecond streaming and interactive q=
ueries is quite uncommon, and it's thanks to all of you folks that we are able=
 to make this happen.=0A=0AMatei=0A-------------------------------------------=
--------------------------=0ATo unsubscribe, e-mail: dev-unsubscribe@spark.apa=
che.org=0AFor additional commands, e-mail: dev-help@spark.apache.org
------=ALIBOUNDARY_13543_43c54940_543bcf46_2d249--


From dev-return-9794-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 14:55:05 2014
Return-Path: <dev-return-9794-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2E58A17606
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 14:55:05 +0000 (UTC)
Received: (qmail 92661 invoked by uid 500); 13 Oct 2014 14:55:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 92588 invoked by uid 500); 13 Oct 2014 14:55:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 92576 invoked by uid 99); 13 Oct 2014 14:55:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 14:55:04 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.180 as permitted sender)
Received: from [209.85.217.180] (HELO mail-lb0-f180.google.com) (209.85.217.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 14:54:38 +0000
Received: by mail-lb0-f180.google.com with SMTP id n15so6502735lbi.39
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 07:54:37 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=aXbTQ8egf56WzY9TY8H3GYjm/vQ5Imo+rYhxiRk8jks=;
        b=lfvxqY+VAlQa4AO45hfc38RwVFFcxxM2XtpvElrkiB/kiF2WeaSEV3SsSQ6uTszQfl
         EVyeUqELnXjinMeXJZbg/L+G/oEAHYI1pgiYOJbzaJGtJtcyzS9UJK+iiN0RfABdkcd+
         5e0OP2lebPekPSAzmTTnTjZYfkZodvGVew8fXySLqNsBf/zLCCYwZG2woHK+OGrsyD99
         yNSbxmMhbun4EiXNWtM7q8izVjWmaxBw88C10X2I0CXxg6nzvRfEU6mVoXrk8ObGZc2k
         2ThMURbys1odR9FjE3HukkJTl1klhZreb9NxV9o9HRsA9RyDypJOMbRYnlq/Ta9ap+Dz
         TX7Q==
X-Gm-Message-State: ALoCoQk4LhD8Bk4XQ1oVTjv9XtbLTq+mSKkXwKTOjy2NSrZ/B2v4pJcAmVGL/Qmw8Ekjcmwe+SDu
X-Received: by 10.152.5.169 with SMTP id t9mr24643727lat.33.1413212076933;
 Mon, 13 Oct 2014 07:54:36 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Mon, 13 Oct 2014 07:54:16 -0700 (PDT)
In-Reply-To: <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
 <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com> <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 13 Oct 2014 07:54:16 -0700
Message-ID: <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: Josh Rosen <rosenville@gmail.com>
Cc: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=047d7bf0e266d68f6a05054f1362
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bf0e266d68f6a05054f1362
Content-Type: text/plain; charset=UTF-8

Jenkins is in quiet mode and the move will be starting after i have my
coffee.  :)

On Sun, Oct 12, 2014 at 11:26 PM, Josh Rosen <rosenville@gmail.com> wrote:

> Reminder: this Jenkins migration is happening tomorrow morning (Monday).
>
> On Fri, Oct 10, 2014 at 1:01 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> reminder:  this IS happening, first thing monday morning PDT.  :)
>>
>> On Wed, Oct 8, 2014 at 3:01 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>> > greetings!
>> >
>> > i've got some updates regarding our new jenkins infrastructure, as well
>> as
>> > the initial date and plan for rolling things out:
>> >
>> > *** current testing/build break whack-a-mole:
>> > a lot of out of date artifacts are cached in the current jenkins, which
>> > has caused a few builds during my testing to break due to dependency
>> > resolution failure[1][2].
>> >
>> > bumping these versions can cause your builds to fail, due to public api
>> > changes and the like.  consider yourself warned that some projects might
>> > require some debugging...  :)
>> >
>> > tomorrow, i will be at databricks working w/@joshrosen to make sure that
>> > the spark builds have any bugs hammered out.
>> >
>> > ***  deployment plan:
>> > unless something completely horrible happens, THE NEW JENKINS WILL GO
>> LIVE
>> > ON MONDAY (october 13th).
>> >
>> > all jenkins infrastructure will be DOWN for the entirety of the day
>> > (starting at ~8am).  this means no builds, period.  i'm hoping that the
>> > downtime will be much shorter than this, but we'll have to see how
>> > everything goes.
>> >
>> > all test/build history WILL BE PRESERVED.  i will be rsyncing the
>> jenkins
>> > jobs/ directory over, complete w/history as part of the deployment.
>> >
>> > once i'm feeling good about the state of things, i'll point the original
>> > url to the new instances and send out an all clear.
>> >
>> > if you are a student at UC berkeley, you can log in to jenkins using
>> your
>> > LDAP login, and (by default) view but not change plans.  if you do not
>> have
>> > a UC berkeley LDAP login, you can still view plans anonymously.
>> >
>> > IF YOU ARE A PLAN ADMIN, THEN PLEASE REACH OUT, ASAP, PRIVATELY AND I
>> WILL
>> > SET UP ADMIN ACCESS TO YOUR BUILDS.
>> >
>> > ***  post deployment plan:
>> > fix all of the things that break!
>> >
>> > i will be keeping a VERY close eye on the builds, checking for breaks,
>> and
>> > helping out where i can.  if the situation is dire, i can always roll
>> back
>> > to the old jenkins infra...  but i hope we never get to that point!  :)
>> >
>> > i'm hoping that things will go smoothly, but please be patient as i'm
>> > certain we'll hit a few bumps in the road.
>> >
>> > please let me know if you guys have any comments/questions/concerns...
>> :)
>> >
>> > shane
>> >
>> > 1 - https://github.com/bigdatagenomics/bdg-services/pull/18
>> > 2 - https://github.com/bigdatagenomics/avocado/pull/111
>> >
>>
>
>

--047d7bf0e266d68f6a05054f1362--

From dev-return-9795-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 15:57:46 2014
Return-Path: <dev-return-9795-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5A3CB17880
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 15:57:46 +0000 (UTC)
Received: (qmail 51561 invoked by uid 500); 13 Oct 2014 15:57:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51492 invoked by uid 500); 13 Oct 2014 15:57:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51480 invoked by uid 99); 13 Oct 2014 15:57:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 15:57:44 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.47 as permitted sender)
Received: from [209.85.218.47] (HELO mail-oi0-f47.google.com) (209.85.218.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 15:57:40 +0000
Received: by mail-oi0-f47.google.com with SMTP id a141so13660766oig.34
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 08:57:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=0bUhZhBPI54i/lMdVukzt5xABYZTS2YLps3XqJg8/Zs=;
        b=M193CX4Jb8E0NgFanxCWNMoI1Dzn3e2NRBDLAUn247HRqskcW+oTBN6FjWdh4J3up2
         84Gfy2fnFWmoC4oMo24Sn7BgRFJyuUqSDBMEUCxkwSw038pmmsIUSW8xnji9/PANghe2
         98TjR4HR3hLegu5D2jN/Rl2h6ry3DI0FEo2fg1ExNlULoCX+OfG/StnlY7scLEVoIItx
         dAwjWMpFtGmi20nWBg3lqo6HU9/YD/oNPMKnK4kJ3EjErj53Riwvi/X0d3Yis8N2EazF
         K2r1+QNbtpJ+10PaHkhw0NjnPPJdLNiSU5Nr7WVyXn81iWEMRX46zXJP0c5ASLgFh8h0
         IxhQ==
MIME-Version: 1.0
X-Received: by 10.202.225.139 with SMTP id y133mr21211768oig.14.1413215839803;
 Mon, 13 Oct 2014 08:57:19 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Mon, 13 Oct 2014 08:57:19 -0700 (PDT)
In-Reply-To: <CAOhmDzf0kH2XrUoutn=81ihAAXx6u+VwJDc28M2AQqq_M+cAZg@mail.gmail.com>
References: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net>
	<CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com>
	<CABPQxssViFY129Bn9WF8yEvZGy63nJ-9BpMTKLNnVx825LZhcg@mail.gmail.com>
	<2760C3F7-35E9-4448-9C90-229FE2C852A0@gmail.com>
	<CAOhmDzf0kH2XrUoutn=81ihAAXx6u+VwJDc28M2AQqq_M+cAZg@mail.gmail.com>
Date: Mon, 13 Oct 2014 08:57:19 -0700
Message-ID: <CABPQxstcdeK1ySXKHbOvgWwSzuAWxZvbW9h_r=uxFvKGR5Oc9w@mail.gmail.com>
Subject: Re: Scalastyle improvements / large code reformatting
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, Reynold Xin <rxin@databricks.com>, 
	Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=EUC-KR
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Nick,

I think the best solution is really to find a way to only apply
certain rules to code modified after a certain date. I also don't
think it would be that hard to implement because git can output
per-line information about modification times. So you'd just run the
scalastyle rules and then if you saw errors from rules with a special
"if modified since" property, we'd only fail the line has been
modified after that date. That would even work for imports as well,
you'd just have a thing where if anyone modified some imports they
would have to fix all the imports in that file. It's at least worth a
try.

Overall I think that's the only real solution here. Doing things
closer to releases reduces the overhead of backporting, but overall
it's still going to be a very high overhead.

- Patrick

On Mon, Oct 13, 2014 at 5:46 AM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> The arguments against large scale refactorings make sense. Doing them, if=
 at
> all, during QA cycles or around releases sounds like a promising idea.
>
> Coupled with that, would it be useful to implement new rules outside of
> these potential windows for refactoring in such a way that they report on
> style errors without failing the build?
>
> That way they work like a nag and encourage developers to fix style probl=
ems
> in the course of working on their original patch. Coupled with a clear
> policy to fix style only where code is being changed anyway, this could b=
e a
> helpful way to steadily fix problems related to new rules over time. Then=
,
> when we get close to the "finish line", we can make a final patch to fix =
the
> remaining issues for a given rule and enforce it as part of the build.
> Having the style report should also make it easier for committers to revi=
ew
> style. We will have to do some work to show reports on new rules in a
> digestible way, as they will probably be very large at first, but I think
> that's a tractable problem.
>
> What do committers/reviewers think of that?
>
> As an aside, enforcing new style rules for new files only is an interesti=
ng
> idea, but you'd have to track that a file was added after the new rules w=
ere
> enforced. Otherwise bad style will be allowed after the initial checkin o=
f
> that file. Also, enforcing style rules on changes may work in some (e.g.
> space required  before "{") but is impossible in other (import ordering)
> cases, as Reynold pointed out.
>
> Nick
>
>
> 2014=B3=E2 10=BF=F9 13=C0=CF =BF=F9=BF=E4=C0=CF, Matei Zaharia<matei.zaha=
ria@gmail.com>=B4=D4=C0=CC =C0=DB=BC=BA=C7=D1 =B8=DE=BD=C3=C1=F6:
>
>> I'm also against these huge reformattings. They slow down development an=
d
>> backporting for trivial reasons. Let's not do that at this point, the st=
yle
>> of the current code is quite consistent and we have plenty of other thin=
gs
>> to worry about. Instead, what you can do is as you edit a file when you'=
re
>> working on a feature, fix up style issues you see. Or, as Josh suggested=
,
>> some way to make this apply only to new files would help.
>>
>> Matei
>>
>> On Oct 12, 2014, at 10:16 PM, Patrick Wendell <pwendell@gmail.com> wrote=
:
>>
>> > Another big problem with these patches are that they make it almost
>> > impossible to backport changes to older branches cleanly (there
>> > becomes like 100% chance of a merge conflict).
>> >
>> > One proposal is to do this:
>> > 1. We only consider new style rules at the end of a release cycle,
>> > when there is the smallest chance of wanting to backport stuff.
>> > 2. We require that they are submitted in individual patches with a (a)
>> > new style rule and (b) the associated changes. Then we can also
>> > evaluate on a case-by-case basis how large the change is for each
>> > rule. For rules that require sweeping changes across the codebase,
>> > personally I'd vote against them. For rules like import ordering that
>> > won't cause too much pain on the diff (it's pretty easy to deal with
>> > those conflicts) I'd be okay with it.
>> >
>> > If we went with this, we'd also have to warn people that we might not
>> > accept new style rules if they are too costly to enforce. I'm guessing
>> > people will still contribute even with those expectations.
>> >
>> > - Patrick
>> >
>> > On Sun, Oct 12, 2014 at 9:39 PM, Reynold Xin <rxin@databricks.com>
>> > wrote:
>> >> I actually think we should just take the bite and follow through with
>> >> the
>> >> reformatting. Many rules are simply not possible to enforce only on
>> >> deltas
>> >> (e.g. import ordering).
>> >>
>> >> That said, maybe there are better windows to do this, e.g. during the
>> >> QA
>> >> period.
>> >>
>> >> On Sun, Oct 12, 2014 at 9:37 PM, Josh Rosen <rosenville@gmail.com>
>> >> wrote:
>> >>
>> >>> There are a number of open pull requests that aim to extend Spark's
>> >>> automated style checks (see
>> >>> https://issues.apache.org/jira/browse/SPARK-3849 for an umbrella
>> >>> JIRA).
>> >>> These fixes are mostly good, but I have some concerns about merging
>> >>> these
>> >>> patches.  Several of these patches make large reformatting changes i=
n
>> >>> nearly every file of Spark, which makes it more difficult to use `gi=
t
>> >>> blame` and has the potential to introduce merge conflicts with all
>> >>> open PRs
>> >>> and all backport patches.
>> >>>
>> >>> I feel that most of the value of automated style-checks comes from
>> >>> allowing reviewers/committers to focus on the technical content of
>> >>> pull
>> >>> requests rather than their formatting.  My concern is that the
>> >>> convenience
>> >>> added by these new style rules will not outweigh the other overheads
>> >>> that
>> >>> these reformatting patches will create for the committers.
>> >>>
>> >>> If possible, it would be great if we could extend the style checker =
to
>> >>> enforce the more stringent rules only for new code additions /
>> >>> deletions.
>> >>> If not, I don't think that we should proceed with the reformatting.
>> >>> Others
>> >>> might disagree, though, so I welcome comments / discussion.
>> >>>
>> >>> - Josh
>> >
>> > ---------------------------------------------------------------------
>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > For additional commands, e-mail: dev-help@spark.apache.org
>> >
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9796-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 17:13:02 2014
Return-Path: <dev-return-9796-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A1BC317BC3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 17:13:02 +0000 (UTC)
Received: (qmail 75389 invoked by uid 500); 13 Oct 2014 17:13:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75310 invoked by uid 500); 13 Oct 2014 17:13:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75299 invoked by uid 99); 13 Oct 2014 17:13:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:13:01 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.216.169 as permitted sender)
Received: from [209.85.216.169] (HELO mail-qc0-f169.google.com) (209.85.216.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:12:57 +0000
Received: by mail-qc0-f169.google.com with SMTP id o8so5403433qcw.14
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 10:12:36 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=IyssCPKYr2CAicKcCrfuutwN3ccCSkTAweLR3W0YfdE=;
        b=GyyM0sMubMMVQKqJjmZsa/LBy4v3dOR/unP5ibIkSZkOjFrXCWdHUh9d5TBSH0OzaY
         p/mstq/IRPZN7X3hjmtkStSYTy+BV9xJrE77f1N7hHhPhrWEpTD61KGvPdlsJqFOpnTx
         Sz2rieavy/O3wr+tKurnfSr5lmGPJSHNis4pqiricdK0oh6uPqUxjykaPyxG6C3Nuwya
         pbhX31ql6oakOhH1qHFNC7MiauIo7Ey4I0R8iZ6NZ+X/EyfTsOq+5wwyLVfRUK4ioZs2
         O4sZ7PwiN0Y9CnpbfrJdKwW9mRGILK6FqhHgFbQdwAXZhJ8SRQ08EQK1DlDn3la0dvI8
         K8Vg==
X-Gm-Message-State: ALoCoQm5QSstxh7ZNNg6NZPGeUNklWIi7xhr7MrWLZbssQdOU1bIQQI8QU5eH/E66s0+wIxPpzM9
MIME-Version: 1.0
X-Received: by 10.140.88.208 with SMTP id t74mr40623896qgd.29.1413220356328;
 Mon, 13 Oct 2014 10:12:36 -0700 (PDT)
Received: by 10.229.8.68 with HTTP; Mon, 13 Oct 2014 10:12:36 -0700 (PDT)
In-Reply-To: <CABPQxstcdeK1ySXKHbOvgWwSzuAWxZvbW9h_r=uxFvKGR5Oc9w@mail.gmail.com>
References: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net>
	<CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com>
	<CABPQxssViFY129Bn9WF8yEvZGy63nJ-9BpMTKLNnVx825LZhcg@mail.gmail.com>
	<2760C3F7-35E9-4448-9C90-229FE2C852A0@gmail.com>
	<CAOhmDzf0kH2XrUoutn=81ihAAXx6u+VwJDc28M2AQqq_M+cAZg@mail.gmail.com>
	<CABPQxstcdeK1ySXKHbOvgWwSzuAWxZvbW9h_r=uxFvKGR5Oc9w@mail.gmail.com>
Date: Mon, 13 Oct 2014 10:12:36 -0700
Message-ID: <CAAOnQ7sq63w3UkgZx10D_84QbWdTzXsTY4WJF7qEEZG5U-8wNw@mail.gmail.com>
Subject: Re: Scalastyle improvements / large code reformatting
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, Matei Zaharia <matei.zaharia@gmail.com>, 
	Reynold Xin <rxin@databricks.com>, Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Another option is to add new style rules that trigger too many errors
as warnings, and slowly clean them up. This means that reviewers will
be burdened with manually enforcing the rules for a while, and we need
to remember to turn them to errors once some threshold is reached.

(The Hadoop build had this check where it compared the number of
warnings against the last known good build, and yelled at you if you
added any new warnings. That might be something to look at also,
although not sure how easy it would be and I seem to remember it
having false positives.)

On Mon, Oct 13, 2014 at 8:57 AM, Patrick Wendell <pwendell@gmail.com> wrote=
:
> Hey Nick,
>
> I think the best solution is really to find a way to only apply
> certain rules to code modified after a certain date. I also don't
> think it would be that hard to implement because git can output
> per-line information about modification times. So you'd just run the
> scalastyle rules and then if you saw errors from rules with a special
> "if modified since" property, we'd only fail the line has been
> modified after that date. That would even work for imports as well,
> you'd just have a thing where if anyone modified some imports they
> would have to fix all the imports in that file. It's at least worth a
> try.
>
> Overall I think that's the only real solution here. Doing things
> closer to releases reduces the overhead of backporting, but overall
> it's still going to be a very high overhead.
>
> - Patrick
>
> On Mon, Oct 13, 2014 at 5:46 AM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
>> The arguments against large scale refactorings make sense. Doing them, i=
f at
>> all, during QA cycles or around releases sounds like a promising idea.
>>
>> Coupled with that, would it be useful to implement new rules outside of
>> these potential windows for refactoring in such a way that they report o=
n
>> style errors without failing the build?
>>
>> That way they work like a nag and encourage developers to fix style prob=
lems
>> in the course of working on their original patch. Coupled with a clear
>> policy to fix style only where code is being changed anyway, this could =
be a
>> helpful way to steadily fix problems related to new rules over time. The=
n,
>> when we get close to the "finish line", we can make a final patch to fix=
 the
>> remaining issues for a given rule and enforce it as part of the build.
>> Having the style report should also make it easier for committers to rev=
iew
>> style. We will have to do some work to show reports on new rules in a
>> digestible way, as they will probably be very large at first, but I thin=
k
>> that's a tractable problem.
>>
>> What do committers/reviewers think of that?
>>
>> As an aside, enforcing new style rules for new files only is an interest=
ing
>> idea, but you'd have to track that a file was added after the new rules =
were
>> enforced. Otherwise bad style will be allowed after the initial checkin =
of
>> that file. Also, enforcing style rules on changes may work in some (e.g.
>> space required  before "{") but is impossible in other (import ordering)
>> cases, as Reynold pointed out.
>>
>> Nick
>>
>>
>> 2014=EB=85=84 10=EC=9B=94 13=EC=9D=BC =EC=9B=94=EC=9A=94=EC=9D=BC, Matei=
 Zaharia<matei.zaharia@gmail.com>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=
=95=9C =EB=A9=94=EC=8B=9C=EC=A7=80:
>>
>>> I'm also against these huge reformattings. They slow down development a=
nd
>>> backporting for trivial reasons. Let's not do that at this point, the s=
tyle
>>> of the current code is quite consistent and we have plenty of other thi=
ngs
>>> to worry about. Instead, what you can do is as you edit a file when you=
're
>>> working on a feature, fix up style issues you see. Or, as Josh suggeste=
d,
>>> some way to make this apply only to new files would help.
>>>
>>> Matei
>>>
>>> On Oct 12, 2014, at 10:16 PM, Patrick Wendell <pwendell@gmail.com> wrot=
e:
>>>
>>> > Another big problem with these patches are that they make it almost
>>> > impossible to backport changes to older branches cleanly (there
>>> > becomes like 100% chance of a merge conflict).
>>> >
>>> > One proposal is to do this:
>>> > 1. We only consider new style rules at the end of a release cycle,
>>> > when there is the smallest chance of wanting to backport stuff.
>>> > 2. We require that they are submitted in individual patches with a (a=
)
>>> > new style rule and (b) the associated changes. Then we can also
>>> > evaluate on a case-by-case basis how large the change is for each
>>> > rule. For rules that require sweeping changes across the codebase,
>>> > personally I'd vote against them. For rules like import ordering that
>>> > won't cause too much pain on the diff (it's pretty easy to deal with
>>> > those conflicts) I'd be okay with it.
>>> >
>>> > If we went with this, we'd also have to warn people that we might not
>>> > accept new style rules if they are too costly to enforce. I'm guessin=
g
>>> > people will still contribute even with those expectations.
>>> >
>>> > - Patrick
>>> >
>>> > On Sun, Oct 12, 2014 at 9:39 PM, Reynold Xin <rxin@databricks.com>
>>> > wrote:
>>> >> I actually think we should just take the bite and follow through wit=
h
>>> >> the
>>> >> reformatting. Many rules are simply not possible to enforce only on
>>> >> deltas
>>> >> (e.g. import ordering).
>>> >>
>>> >> That said, maybe there are better windows to do this, e.g. during th=
e
>>> >> QA
>>> >> period.
>>> >>
>>> >> On Sun, Oct 12, 2014 at 9:37 PM, Josh Rosen <rosenville@gmail.com>
>>> >> wrote:
>>> >>
>>> >>> There are a number of open pull requests that aim to extend Spark's
>>> >>> automated style checks (see
>>> >>> https://issues.apache.org/jira/browse/SPARK-3849 for an umbrella
>>> >>> JIRA).
>>> >>> These fixes are mostly good, but I have some concerns about merging
>>> >>> these
>>> >>> patches.  Several of these patches make large reformatting changes =
in
>>> >>> nearly every file of Spark, which makes it more difficult to use `g=
it
>>> >>> blame` and has the potential to introduce merge conflicts with all
>>> >>> open PRs
>>> >>> and all backport patches.
>>> >>>
>>> >>> I feel that most of the value of automated style-checks comes from
>>> >>> allowing reviewers/committers to focus on the technical content of
>>> >>> pull
>>> >>> requests rather than their formatting.  My concern is that the
>>> >>> convenience
>>> >>> added by these new style rules will not outweigh the other overhead=
s
>>> >>> that
>>> >>> these reformatting patches will create for the committers.
>>> >>>
>>> >>> If possible, it would be great if we could extend the style checker=
 to
>>> >>> enforce the more stringent rules only for new code additions /
>>> >>> deletions.
>>> >>> If not, I don't think that we should proceed with the reformatting.
>>> >>> Others
>>> >>> might disagree, though, so I welcome comments / discussion.
>>> >>>
>>> >>> - Josh
>>> >
>>> > ---------------------------------------------------------------------
>>> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> > For additional commands, e-mail: dev-help@spark.apache.org
>>> >
>>>
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>



--=20
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9797-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 17:16:34 2014
Return-Path: <dev-return-9797-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 92F2317BF1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 17:16:34 +0000 (UTC)
Received: (qmail 82620 invoked by uid 500); 13 Oct 2014 17:16:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82540 invoked by uid 500); 13 Oct 2014 17:16:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82512 invoked by uid 99); 13 Oct 2014 17:16:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:16:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.181 as permitted sender)
Received: from [209.85.217.181] (HELO mail-lb0-f181.google.com) (209.85.217.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:16:29 +0000
Received: by mail-lb0-f181.google.com with SMTP id l4so6676645lbv.40
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 10:16:07 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=kXXAoo9ft/hNHoZNwFwRIk43q83iGT3H1fU5UCVa0ZY=;
        b=csVc/s6UxjisZ5LFNOd8oIjYbZjVHV1drkCYyLhh8NPQTtMzjAnWunnJ4ZSUoAkhOm
         YTSAqouG5uoqYt0wvne3WAWn7FoFJNt2yh1OJMmJ9OH1AZPJYWY41HOp5PH5zIdr4BWw
         inIRTzcel3KXRV6ZRSza7+0JaYhqzwNu0Qx/UGiHVIEBKj14fdTLoXdDrcdEze4+DQxz
         zFxlzChNkwwHIQXGnbjTD/lFYdu9E7cl8qlBfu7Rscjcu72qILExIRtIkmx3gPLx9iX6
         Kz+JCAOSZRGnolHPswdeRtTwrMgHbSNw59LPKuSzJeKeU+V5bGHbaqTOGRpxQh6ht27Q
         8eLA==
X-Gm-Message-State: ALoCoQl5w71/DoG1+2lBQwCEAhQUyx5aDHzKA/rWQaXjRCsiJK63ls4br7H1i+C6uRPwIEbMWyb7
X-Received: by 10.112.180.137 with SMTP id do9mr25214783lbc.63.1413220566944;
 Mon, 13 Oct 2014 10:16:06 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Mon, 13 Oct 2014 10:15:46 -0700 (PDT)
In-Reply-To: <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
 <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
 <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com> <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 13 Oct 2014 10:15:46 -0700
Message-ID: <CACdU-dTNrWoeosvggCERMnS8YwtvMgNLQK8DcWXaNAtcqmBWWw@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: Josh Rosen <rosenville@gmail.com>
Cc: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11c25c3ee1e5c40505510daa
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c25c3ee1e5c40505510daa
Content-Type: text/plain; charset=UTF-8

quick update:  we should be back up and running in the next ~60mins.

On Mon, Oct 13, 2014 at 7:54 AM, shane knapp <sknapp@berkeley.edu> wrote:

> Jenkins is in quiet mode and the move will be starting after i have my
> coffee.  :)
>
> On Sun, Oct 12, 2014 at 11:26 PM, Josh Rosen <rosenville@gmail.com> wrote:
>
>> Reminder: this Jenkins migration is happening tomorrow morning (Monday).
>>
>> On Fri, Oct 10, 2014 at 1:01 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> reminder:  this IS happening, first thing monday morning PDT.  :)
>>>
>>> On Wed, Oct 8, 2014 at 3:01 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>>
>>> > greetings!
>>> >
>>> > i've got some updates regarding our new jenkins infrastructure, as
>>> well as
>>> > the initial date and plan for rolling things out:
>>> >
>>> > *** current testing/build break whack-a-mole:
>>> > a lot of out of date artifacts are cached in the current jenkins, which
>>> > has caused a few builds during my testing to break due to dependency
>>> > resolution failure[1][2].
>>> >
>>> > bumping these versions can cause your builds to fail, due to public api
>>> > changes and the like.  consider yourself warned that some projects
>>> might
>>> > require some debugging...  :)
>>> >
>>> > tomorrow, i will be at databricks working w/@joshrosen to make sure
>>> that
>>> > the spark builds have any bugs hammered out.
>>> >
>>> > ***  deployment plan:
>>> > unless something completely horrible happens, THE NEW JENKINS WILL GO
>>> LIVE
>>> > ON MONDAY (october 13th).
>>> >
>>> > all jenkins infrastructure will be DOWN for the entirety of the day
>>> > (starting at ~8am).  this means no builds, period.  i'm hoping that the
>>> > downtime will be much shorter than this, but we'll have to see how
>>> > everything goes.
>>> >
>>> > all test/build history WILL BE PRESERVED.  i will be rsyncing the
>>> jenkins
>>> > jobs/ directory over, complete w/history as part of the deployment.
>>> >
>>> > once i'm feeling good about the state of things, i'll point the
>>> original
>>> > url to the new instances and send out an all clear.
>>> >
>>> > if you are a student at UC berkeley, you can log in to jenkins using
>>> your
>>> > LDAP login, and (by default) view but not change plans.  if you do not
>>> have
>>> > a UC berkeley LDAP login, you can still view plans anonymously.
>>> >
>>> > IF YOU ARE A PLAN ADMIN, THEN PLEASE REACH OUT, ASAP, PRIVATELY AND I
>>> WILL
>>> > SET UP ADMIN ACCESS TO YOUR BUILDS.
>>> >
>>> > ***  post deployment plan:
>>> > fix all of the things that break!
>>> >
>>> > i will be keeping a VERY close eye on the builds, checking for breaks,
>>> and
>>> > helping out where i can.  if the situation is dire, i can always roll
>>> back
>>> > to the old jenkins infra...  but i hope we never get to that point!  :)
>>> >
>>> > i'm hoping that things will go smoothly, but please be patient as i'm
>>> > certain we'll hit a few bumps in the road.
>>> >
>>> > please let me know if you guys have any
>>> comments/questions/concerns...  :)
>>> >
>>> > shane
>>> >
>>> > 1 - https://github.com/bigdatagenomics/bdg-services/pull/18
>>> > 2 - https://github.com/bigdatagenomics/avocado/pull/111
>>> >
>>>
>>
>>
>

--001a11c25c3ee1e5c40505510daa--

From dev-return-9798-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 17:17:29 2014
Return-Path: <dev-return-9798-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8F78817BFC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 17:17:29 +0000 (UTC)
Received: (qmail 86363 invoked by uid 500); 13 Oct 2014 17:17:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86293 invoked by uid 500); 13 Oct 2014 17:17:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86281 invoked by uid 99); 13 Oct 2014 17:17:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:17:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:17:01 +0000
Received: by mail-wi0-f178.google.com with SMTP id h11so4433307wiw.17
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 10:17:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=zUMFegXC5GX42eCQUeoyShgpFgHeea7pIQZ+snlycBE=;
        b=n/UWnbzFvO3eUWOxIY81DAOf3qOxOUJA9oh9BC8HrKFPA9YWPJdzWbZttN7rJ9ueX5
         jidFeioHKSPKyfF7hxiyrXnfjpG2HyJYaprxsoKxCTOztBSjiWLCZl4KZ0MHBS+NFdkg
         pZ8xT+05RSf5IdCRS7+EdvY1inY02s3/oHumYdxdbwfbpiA8i69L+wWk5wMpgr41MYcQ
         MachA5L74IHNowZ9OF3FDQ9XObF0tal5aAYDw21bn/vc9k5PXrWEzJelLzqxVpYh/a2e
         L2xaXSUAqcPiCVlmOe9l9Qih4OMZNVMynpkLzXhoMtz8k5o9J7DowRX93DZPb5bHbE+c
         /ExA==
X-Received: by 10.194.8.232 with SMTP id u8mr22928834wja.64.1413220621151;
 Mon, 13 Oct 2014 10:17:01 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 13 Oct 2014 10:16:21 -0700 (PDT)
In-Reply-To: <CABPQxstcdeK1ySXKHbOvgWwSzuAWxZvbW9h_r=uxFvKGR5Oc9w@mail.gmail.com>
References: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net>
 <CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com>
 <CABPQxssViFY129Bn9WF8yEvZGy63nJ-9BpMTKLNnVx825LZhcg@mail.gmail.com>
 <2760C3F7-35E9-4448-9C90-229FE2C852A0@gmail.com> <CAOhmDzf0kH2XrUoutn=81ihAAXx6u+VwJDc28M2AQqq_M+cAZg@mail.gmail.com>
 <CABPQxstcdeK1ySXKHbOvgWwSzuAWxZvbW9h_r=uxFvKGR5Oc9w@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 13 Oct 2014 13:16:21 -0400
Message-ID: <CAOhmDzexxOd0RTfPDZNGxovo2Gwjc8Ljuw-VFOKbM81ponQRpw@mail.gmail.com>
Subject: Re: Scalastyle improvements / large code reformatting
To: Patrick Wendell <pwendell@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, Reynold Xin <rxin@databricks.com>, 
	Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b5d348c1cf46f050551116e
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d348c1cf46f050551116e
Content-Type: text/plain; charset=UTF-8

On Mon, Oct 13, 2014 at 11:57 AM, Patrick Wendell <pwendell@gmail.com>
wrote:

> That would even work for imports as well,
> you'd just have a thing where if anyone modified some imports they
> would have to fix all the imports in that file. It's at least worth a
> try.
>

OK, that sounds like a fair compromise. I've updated the description on
SPARK-3849 <https://issues.apache.org/jira/browse/SPARK-3849> accordingly.

Nick

--047d7b5d348c1cf46f050551116e--

From dev-return-9799-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 17:28:18 2014
Return-Path: <dev-return-9799-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1BFB817C58
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 17:28:18 +0000 (UTC)
Received: (qmail 15984 invoked by uid 500); 13 Oct 2014 17:28:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15900 invoked by uid 500); 13 Oct 2014 17:28:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 15889 invoked by uid 99); 13 Oct 2014 17:28:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:28:16 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of eerlands@redhat.com designates 209.132.183.25 as permitted sender)
Received: from [209.132.183.25] (HELO mx4-phx2.redhat.com) (209.132.183.25)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:28:12 +0000
Received: from zmail12.collab.prod.int.phx2.redhat.com (zmail12.collab.prod.int.phx2.redhat.com [10.5.83.14])
	by mx4-phx2.redhat.com (8.13.8/8.13.8) with ESMTP id s9DHRlOQ028232;
	Mon, 13 Oct 2014 13:27:47 -0400
Date: Mon, 13 Oct 2014 13:27:47 -0400 (EDT)
From: Erik Erlandson <eje@redhat.com>
Reply-To: Erik Erlandson <eje@redhat.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Reynold Xin <rxin@databricks.com>,
        Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>
Message-ID: <960513449.2407051.1413221267083.JavaMail.zimbra@redhat.com>
In-Reply-To: <2760C3F7-35E9-4448-9C90-229FE2C852A0@gmail.com>
References: <etPan.543b56f0.6b8b4567.105@joshs-mbp.att.net> <CAPh_B=asx57KpwD0tSpGXA4LLt8n_H10tvztqqJgUqPsiMNgvw@mail.gmail.com> <CABPQxssViFY129Bn9WF8yEvZGy63nJ-9BpMTKLNnVx825LZhcg@mail.gmail.com> <2760C3F7-35E9-4448-9C90-229FE2C852A0@gmail.com>
Subject: Re: Scalastyle improvements / large code reformatting
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.7]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - GC36 (Linux)/8.0.6_GA_5922)
Thread-Topic: Scalastyle improvements / large code reformatting
Thread-Index: M9jctR/tuShYEdg3WAEAvfHizDOaHA==
X-Virus-Checked: Checked by ClamAV on apache.org



----- Original Message -----
> I'm also against these huge reformattings. They slow down development and
> backporting for trivial reasons. Let's not do that at this point, the style
> of the current code is quite consistent and we have plenty of other things
> to worry about. Instead, what you can do is as you edit a file when you're
> working on a feature, fix up style issues you see. Or, as Josh suggested,
> some way to make this apply only to new files would help.


+1, the benefit/cost ratio of wide-spread code churn just to alter formatting is close to zero.



> 
> Matei
> 
> On Oct 12, 2014, at 10:16 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> 
> > Another big problem with these patches are that they make it almost
> > impossible to backport changes to older branches cleanly (there
> > becomes like 100% chance of a merge conflict).
> > 
> > One proposal is to do this:
> > 1. We only consider new style rules at the end of a release cycle,
> > when there is the smallest chance of wanting to backport stuff.
> > 2. We require that they are submitted in individual patches with a (a)
> > new style rule and (b) the associated changes. Then we can also
> > evaluate on a case-by-case basis how large the change is for each
> > rule. For rules that require sweeping changes across the codebase,
> > personally I'd vote against them. For rules like import ordering that
> > won't cause too much pain on the diff (it's pretty easy to deal with
> > those conflicts) I'd be okay with it.
> > 
> > If we went with this, we'd also have to warn people that we might not
> > accept new style rules if they are too costly to enforce. I'm guessing
> > people will still contribute even with those expectations.
> > 
> > - Patrick
> > 
> > On Sun, Oct 12, 2014 at 9:39 PM, Reynold Xin <rxin@databricks.com> wrote:
> >> I actually think we should just take the bite and follow through with the
> >> reformatting. Many rules are simply not possible to enforce only on deltas
> >> (e.g. import ordering).
> >> 
> >> That said, maybe there are better windows to do this, e.g. during the QA
> >> period.
> >> 
> >> On Sun, Oct 12, 2014 at 9:37 PM, Josh Rosen <rosenville@gmail.com> wrote:
> >> 
> >>> There are a number of open pull requests that aim to extend Spark's
> >>> automated style checks (see
> >>> https://issues.apache.org/jira/browse/SPARK-3849 for an umbrella JIRA).
> >>> These fixes are mostly good, but I have some concerns about merging these
> >>> patches.  Several of these patches make large reformatting changes in
> >>> nearly every file of Spark, which makes it more difficult to use `git
> >>> blame` and has the potential to introduce merge conflicts with all open
> >>> PRs
> >>> and all backport patches.
> >>> 
> >>> I feel that most of the value of automated style-checks comes from
> >>> allowing reviewers/committers to focus on the technical content of pull
> >>> requests rather than their formatting.  My concern is that the
> >>> convenience
> >>> added by these new style rules will not outweigh the other overheads that
> >>> these reformatting patches will create for the committers.
> >>> 
> >>> If possible, it would be great if we could extend the style checker to
> >>> enforce the more stringent rules only for new code additions / deletions.
> >>> If not, I don't think that we should proceed with the reformatting.
> >>> Others
> >>> might disagree, though, so I welcome comments / discussion.
> >>> 
> >>> - Josh
> > 
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> > 
> 
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
> 
> 

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9800-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 17:35:52 2014
Return-Path: <dev-return-9800-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 95DFD17CAD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 17:35:52 +0000 (UTC)
Received: (qmail 35726 invoked by uid 500); 13 Oct 2014 17:35:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35662 invoked by uid 500); 13 Oct 2014 17:35:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35651 invoked by uid 99); 13 Oct 2014 17:35:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:35:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.170 as permitted sender)
Received: from [209.85.217.170] (HELO mail-lb0-f170.google.com) (209.85.217.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 17:35:25 +0000
Received: by mail-lb0-f170.google.com with SMTP id u10so6892913lbd.1
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 10:35:24 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=16FDFNcYW9oj4np1ANYbXjwAaTmhBafSFL1m5MuakVU=;
        b=kzdAkK7bnAKOKgA+9vFicH3VM3dgxQCSdkHWwTGD4RqOu2j+LPSsBj8HUNIaezhY2L
         vtiugdcNkD65I4jBxWqP3+dLSNncT5Cs3hjBrnsFWV3Cd9T1Qwq+cTMwh96iMgZjGktO
         JUcaCidVIq7Gk7aw2mlHWTFnAyvq0PfHNFcwUAGejMUgrBqYBCZKdVS1KZsEF6YR/GnS
         2IQPBvyjd2sAlAJKBTLaSF0FJDtDBvZVXqFUBN4H6iiWDH+0iK4e1GXXDgXrCmFVgkne
         fDVFPc2UMrWycqp5CgfXdxCh/JlriaQg5wz0vwPXCMthkgAiBsln93IcbtKq7deyc2Ik
         FxQA==
X-Gm-Message-State: ALoCoQk0ORLysRAfWfuDbFiGb61ViTLABHWIMo6rr21Ksf4552X1XgRaN4mZwMZwtLHR6hQ4JZe6
X-Received: by 10.113.6.163 with SMTP id cv3mr2078526lbd.75.1413221724183;
 Mon, 13 Oct 2014 10:35:24 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Mon, 13 Oct 2014 10:35:04 -0700 (PDT)
In-Reply-To: <CACdU-dTNrWoeosvggCERMnS8YwtvMgNLQK8DcWXaNAtcqmBWWw@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
 <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
 <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
 <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com> <CACdU-dTNrWoeosvggCERMnS8YwtvMgNLQK8DcWXaNAtcqmBWWw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 13 Oct 2014 10:35:04 -0700
Message-ID: <CACdU-dTk1bSnaNk37=AGVt_aqPBS0_pH571VxAXJg-_JDnanPQ@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: Josh Rosen <rosenville@gmail.com>
Cc: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11360c2adbedc60505515237
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11360c2adbedc60505515237
Content-Type: text/plain; charset=UTF-8

AND WE ARE LIIIIIIIVE!

https://amplab.cs.berkeley.edu/jenkins/

have at it, folks!

On Mon, Oct 13, 2014 at 10:15 AM, shane knapp <sknapp@berkeley.edu> wrote:

> quick update:  we should be back up and running in the next ~60mins.
>
> On Mon, Oct 13, 2014 at 7:54 AM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> Jenkins is in quiet mode and the move will be starting after i have my
>> coffee.  :)
>>
>> On Sun, Oct 12, 2014 at 11:26 PM, Josh Rosen <rosenville@gmail.com>
>> wrote:
>>
>>> Reminder: this Jenkins migration is happening tomorrow morning (Monday).
>>>
>>> On Fri, Oct 10, 2014 at 1:01 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>>
>>>> reminder:  this IS happening, first thing monday morning PDT.  :)
>>>>
>>>> On Wed, Oct 8, 2014 at 3:01 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>>
>>>> > greetings!
>>>> >
>>>> > i've got some updates regarding our new jenkins infrastructure, as
>>>> well as
>>>> > the initial date and plan for rolling things out:
>>>> >
>>>> > *** current testing/build break whack-a-mole:
>>>> > a lot of out of date artifacts are cached in the current jenkins,
>>>> which
>>>> > has caused a few builds during my testing to break due to dependency
>>>> > resolution failure[1][2].
>>>> >
>>>> > bumping these versions can cause your builds to fail, due to public
>>>> api
>>>> > changes and the like.  consider yourself warned that some projects
>>>> might
>>>> > require some debugging...  :)
>>>> >
>>>> > tomorrow, i will be at databricks working w/@joshrosen to make sure
>>>> that
>>>> > the spark builds have any bugs hammered out.
>>>> >
>>>> > ***  deployment plan:
>>>> > unless something completely horrible happens, THE NEW JENKINS WILL GO
>>>> LIVE
>>>> > ON MONDAY (october 13th).
>>>> >
>>>> > all jenkins infrastructure will be DOWN for the entirety of the day
>>>> > (starting at ~8am).  this means no builds, period.  i'm hoping that
>>>> the
>>>> > downtime will be much shorter than this, but we'll have to see how
>>>> > everything goes.
>>>> >
>>>> > all test/build history WILL BE PRESERVED.  i will be rsyncing the
>>>> jenkins
>>>> > jobs/ directory over, complete w/history as part of the deployment.
>>>> >
>>>> > once i'm feeling good about the state of things, i'll point the
>>>> original
>>>> > url to the new instances and send out an all clear.
>>>> >
>>>> > if you are a student at UC berkeley, you can log in to jenkins using
>>>> your
>>>> > LDAP login, and (by default) view but not change plans.  if you do
>>>> not have
>>>> > a UC berkeley LDAP login, you can still view plans anonymously.
>>>> >
>>>> > IF YOU ARE A PLAN ADMIN, THEN PLEASE REACH OUT, ASAP, PRIVATELY AND I
>>>> WILL
>>>> > SET UP ADMIN ACCESS TO YOUR BUILDS.
>>>> >
>>>> > ***  post deployment plan:
>>>> > fix all of the things that break!
>>>> >
>>>> > i will be keeping a VERY close eye on the builds, checking for
>>>> breaks, and
>>>> > helping out where i can.  if the situation is dire, i can always roll
>>>> back
>>>> > to the old jenkins infra...  but i hope we never get to that point!
>>>> :)
>>>> >
>>>> > i'm hoping that things will go smoothly, but please be patient as i'm
>>>> > certain we'll hit a few bumps in the road.
>>>> >
>>>> > please let me know if you guys have any
>>>> comments/questions/concerns...  :)
>>>> >
>>>> > shane
>>>> >
>>>> > 1 - https://github.com/bigdatagenomics/bdg-services/pull/18
>>>> > 2 - https://github.com/bigdatagenomics/avocado/pull/111
>>>> >
>>>>
>>>
>>>
>>
>

--001a11360c2adbedc60505515237--

From dev-return-9801-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 18:13:23 2014
Return-Path: <dev-return-9801-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B48AE17EC6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 18:13:23 +0000 (UTC)
Received: (qmail 60996 invoked by uid 500); 13 Oct 2014 18:13:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60913 invoked by uid 500); 13 Oct 2014 18:13:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60902 invoked by uid 99); 13 Oct 2014 18:13:22 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 18:13:22 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.218.48] (HELO mail-oi0-f48.google.com) (209.85.218.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 18:13:18 +0000
Received: by mail-oi0-f48.google.com with SMTP id g201so13902749oib.35
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 11:12:56 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=xTBiU14/0m5ijFjDnpf7L3UJXA15GyJ4/twhRKq7vpQ=;
        b=Oa6zpRpNvlW0ahZFhcIqEUS7E99GbS+kQ9E5Pr3S2G3NJXIsJWu5/H/GC4zQiny94g
         PecL+0pBUyEEhTqEvzMAsuqL/NKAfR/RNYxRQWJFHZ9hY/ib9rJr36bs24U8BwaLWEKn
         WZU3WoPrHKq128UuF4VZJVWMIVazIuFr3By1SvrT53gkuPLMbe7okT0MJW9+3rGAk4Uv
         C+v/pstel9qVbSueIoEtdZ0rtAvQ6zYRXOg4Qb790VPwQy++gzixMMQYTlrrHgSBmnuw
         2/4EzcyOukZYNbvbwRyUH4+vdGr/dwgNqkbWY+Q1nj3nlc5s411grR1lRG2YMbbOAkKM
         6j/Q==
X-Gm-Message-State: ALoCoQmeG+foTiVQJtxdhKyFmfH5pbFk7aaep5NbxHY5MfK5cnBAexQy9zryf+VTWy81NWev7JFu
MIME-Version: 1.0
X-Received: by 10.202.12.142 with SMTP id 136mr288796oim.131.1413223976326;
 Mon, 13 Oct 2014 11:12:56 -0700 (PDT)
Received: by 10.60.46.198 with HTTP; Mon, 13 Oct 2014 11:12:56 -0700 (PDT)
In-Reply-To: <CAMAsSdJhANFcnEaLpL-dLjRvxXEbyhqOjKhFWDt80+8J_SKNrg@mail.gmail.com>
References: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
	<0AA6CFCF-B93C-4CD2-B5B1-881A727780F0@gmail.com>
	<CAMAsSdK50QTOLV5_j4A_Bi337Deq1q7F4Aqf5y+ivDwS=19Efg@mail.gmail.com>
	<CAMAsSdJhANFcnEaLpL-dLjRvxXEbyhqOjKhFWDt80+8J_SKNrg@mail.gmail.com>
Date: Mon, 13 Oct 2014 11:12:56 -0700
Message-ID: <CAF7ADNokG6RKBXhyBs4-yXs2gysAvWvzkwcr9rJ1F3GBK63VrQ@mail.gmail.com>
Subject: Re: Decision forests don't work with non-trivial categorical features
From: Joseph Bradley <joseph@databricks.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Evan Sparks <evan.sparks@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d1cec18ea46050551d9bc
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d1cec18ea46050551d9bc
Content-Type: text/plain; charset=UTF-8

Hi Sean,

Sorry I didn't see this thread earlier!  (Thanks Ameet for pinging me.)

Short version: That exception should not be thrown, so there is a bug
somewhere.  The intended logic for handling high-arity categorical features
is about the best one can do, as far as I know.

Bug finding: For my checking purposes, which branch of Spark are you using,
and do you have the options being submitted to DecisionTree?

High-arity categorical features: As you have figured out, if you use a
categorical feature with just a few categories, it is treated as
"unordered" so that we explicitly consider all exponentially many ways to
split the categories into 2 groups.  If you use one with many categories,
then it is necessary to impose an order.  (The communication increases
linearly in the number of possible splits, so it would blow up if we
considered all exponentially many splits.)  This order is chosen separately
for each node, so it is not a uniform order imposed over the entire tree.
This actually means that it is not a heuristic for regression and binary
classification; i.e., it chooses the same split as if we had explicitly
considered all of the possible splits.  For multiclass classification, it
is a heuristic, but I don't know of a better solution.

I'll check the code, but if you can forward info about the bug, that would
be very helpful.

Thanks!
Joseph

On Mon, Oct 13, 2014 at 1:16 AM, Sean Owen <sowen@cloudera.com> wrote:

> Hm, no I don't think I'm quite right there. There's an issue but
> that's not quite it.
>
> So I have a categorical feature with 40 value, and 300 bins. The error
> I see in the end is:
>
> java.lang.IllegalArgumentException: requirement failed:
> DTStatsAggregator.getLeftRightFeatureOffsets is for unordered features
> only, but was called for ordered feature 4.
> at scala.Predef$.require(Predef.scala:233)
> at
> org.apache.spark.mllib.tree.impl.DTStatsAggregator.getLeftRightFeatureOffsets(DTStatsAggregator.scala:143)
> at
> org.apache.spark.mllib.tree.DecisionTree$.org$apache$spark$mllib$tree$DecisionTree$$mixedBinSeqOp(DecisionTree.scala:363)
> ...
>
> So this categorical is treated as an ordered feature because you would
> have to have a load of bins to match the condition in the code I
> quote. But something isn't expecting that. Is that much worth a JIRA?
>
> Hm, but what's the theory of giving meaning to the ordering of the
> arbitrary categorical values? is that what this is trying to do, or is
> it in fact ordering by some function of the target (average value for
> regression, average 1-vs-all entropy for classification)? I suppose I
> didn't expect to encounter logic like this.
>
> On Mon, Oct 13, 2014 at 9:04 AM, Sean Owen <sowen@cloudera.com> wrote:
> > I'm looking at this bit of code in DecisionTreeMetadata ...
> >
> > val maxCategoriesForUnorderedFeature =
> >   ((math.log(maxPossibleBins / 2 + 1) / math.log(2.0)) + 1).floor.toInt
> > strategy.categoricalFeaturesInfo.foreach { case (featureIndex,
> numCategories) =>
> >   // Decide if some categorical features should be treated as
> > unordered features,
> >   //  which require 2 * ((1 << numCategories - 1) - 1) bins.
> >   // We do this check with log values to prevent overflows in case
> > numCategories is large.
> >   // The next check is equivalent to: 2 * ((1 << numCategories - 1) -
> > 1) <= maxBins
> >   if (numCategories <= maxCategoriesForUnorderedFeature) {
> >     unorderedFeatures.add(featureIndex)
> >     numBins(featureIndex) = numUnorderedBins(numCategories)
> >   } else {
> >     numBins(featureIndex) = numCategories
> >   }
> > }
> >
> > So if I have a feature with 40 values and less than about a trillion
> > bins, it gets treated as a continuous feature, which is meaningless.
> > It shortly throws an exception though since other parts of the code
> > expect this to be a categorical feature.
> >
> > I think there's a bug here somewhere but wasn't sure whether it was
> > just 'not implemented' yet and so needs a better error message (and
> > should be implemented), or something else preventing this from working
> > as expected.
> >
> > I'll wait a beat to get more info and then if needed open a JIRA. Thanks
> all.
> >
> > On Mon, Oct 13, 2014 at 3:34 AM, Evan Sparks <evan.sparks@gmail.com>
> wrote:
> >> I was under the impression that we were using the usual sort by average
> response value heuristic when storing histogram bins (and searching for
> optimal splits) in the tree code.
> >>
> >> Maybe Manish or Joseph can clarify?
> >>
> >>> On Oct 12, 2014, at 2:50 PM, Sean Owen <sowen@cloudera.com> wrote:
> >>>
> >>> I'm having trouble getting decision forests to work with categorical
> >>> features. I have a dataset with a categorical feature with 40 values.
> >>> It seems to be treated as a continuous/numeric value by the
> >>> implementation.
> >>>
> >>> Digging deeper, I see there is some logic in the code that indicates
> >>> that categorical features over N values do not work unless the number
> >>> of bins is at least 2*((2^N - 1) - 1) bins. I understand this as the
> >>> naive brute force condition, wherein the decision tree will test all
> >>> possible splits of the categorical value.
> >>>
> >>> However, this gets unusable quickly as the number of bins should be
> >>> tens or hundreds at best, and this requirement rules out categorical
> >>> values over more than 10 or so features as a result. But, of course,
> >>> it's not unusual to have categorical features with high cardinality.
> >>> It's almost common.
> >>>
> >>> There are some pretty fine heuristics for selecting 'bins' over
> >>> categorical features when the number of bins is far fewer than the
> >>> complete, exhaustive set.
> >>>
> >>> Before I open a JIRA or continue, does anyone know what I am talking
> >>> about, am I mistaken? Is this a real limitation and is it worth
> >>> pursuing these heuristics? I can't figure out how to proceed with
> >>> decision forests in MLlib otherwise.
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>> For additional commands, e-mail: dev-help@spark.apache.org
> >>>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113d1cec18ea46050551d9bc--

From dev-return-9802-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 18:20:42 2014
Return-Path: <dev-return-9802-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AAAF717F0F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 18:20:42 +0000 (UTC)
Received: (qmail 74830 invoked by uid 500); 13 Oct 2014 18:20:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74750 invoked by uid 500); 13 Oct 2014 18:20:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74725 invoked by uid 99); 13 Oct 2014 18:20:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 18:20:41 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_BLACK
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.213.178 as permitted sender)
Received: from [209.85.213.178] (HELO mail-ig0-f178.google.com) (209.85.213.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 18:20:16 +0000
Received: by mail-ig0-f178.google.com with SMTP id h3so11526328igd.5
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 11:20:14 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=CEVM6JQGjWNy0XtDGTwGJ49VmOvRUcjpgOpR3wDDgVs=;
        b=bZ+xHNcyEkvpg4tLt4VJDlIosXfdecIxAeT3d/GP7yg47SPIPHF5KDWI37P+WKyDyt
         BwReW1vGta5ermkoJeOeNzy8Y2nOJrr4LAY6PHtH2U+lsrrpz0WmZjAtqGbwx8Eyqu5D
         1kIb2KqAQxK4j+pzKPB+2Y5gqxIJaFl2dZQeX6t+m/ErzzD6QbgxQTkr2lBt3h+n1yln
         kRkdmCrxBP6pBAIw/Ug5zLd1E5n+u379ZGZao9dZR+TQTQHIY7qq1skZUQOFodlJDZKa
         JCSa8cDWnLpSDy28fl9WAat1gP1k9Lg25l0mWWw3ujg4m06ePdQ+HtjusZ8HbzSw/SUG
         P/Kw==
X-Gm-Message-State: ALoCoQlNzEuQsx+bGD5zQ6l7feEr1efzxvuIRfAKefX5PgzF8NukAiXCLLBcIQ81LwpGNT3M+7Ak
X-Received: by 10.42.96.137 with SMTP id j9mr255664icn.88.1413224414563; Mon,
 13 Oct 2014 11:20:14 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Mon, 13 Oct 2014 11:19:54 -0700 (PDT)
In-Reply-To: <CAF7ADNokG6RKBXhyBs4-yXs2gysAvWvzkwcr9rJ1F3GBK63VrQ@mail.gmail.com>
References: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
 <0AA6CFCF-B93C-4CD2-B5B1-881A727780F0@gmail.com> <CAMAsSdK50QTOLV5_j4A_Bi337Deq1q7F4Aqf5y+ivDwS=19Efg@mail.gmail.com>
 <CAMAsSdJhANFcnEaLpL-dLjRvxXEbyhqOjKhFWDt80+8J_SKNrg@mail.gmail.com> <CAF7ADNokG6RKBXhyBs4-yXs2gysAvWvzkwcr9rJ1F3GBK63VrQ@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 13 Oct 2014 19:19:54 +0100
Message-ID: <CAMAsSdJzZE-zH+cGm9Lz9TJZ7kSWU4X6zcXZCSE1On00voDFcQ@mail.gmail.com>
Subject: Re: Decision forests don't work with non-trivial categorical features
To: Joseph Bradley <joseph@databricks.com>
Cc: Evan Sparks <evan.sparks@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Great, we'll confer then. I'm using master / 1.2.0-SNAPSHOT. I'll send
some details directly under separate cover.

On Mon, Oct 13, 2014 at 7:12 PM, Joseph Bradley <joseph@databricks.com> wrote:
> Hi Sean,
>
> Sorry I didn't see this thread earlier!  (Thanks Ameet for pinging me.)
>
> Short version: That exception should not be thrown, so there is a bug
> somewhere.  The intended logic for handling high-arity categorical features
> is about the best one can do, as far as I know.
>
> Bug finding: For my checking purposes, which branch of Spark are you using,
> and do you have the options being submitted to DecisionTree?
>
> High-arity categorical features: As you have figured out, if you use a
> categorical feature with just a few categories, it is treated as "unordered"
> so that we explicitly consider all exponentially many ways to split the
> categories into 2 groups.  If you use one with many categories, then it is
> necessary to impose an order.  (The communication increases linearly in the
> number of possible splits, so it would blow up if we considered all
> exponentially many splits.)  This order is chosen separately for each node,
> so it is not a uniform order imposed over the entire tree.  This actually
> means that it is not a heuristic for regression and binary classification;
> i.e., it chooses the same split as if we had explicitly considered all of
> the possible splits.  For multiclass classification, it is a heuristic, but
> I don't know of a better solution.
>
> I'll check the code, but if you can forward info about the bug, that would
> be very helpful.
>
> Thanks!
> Joseph
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9803-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 18:55:34 2014
Return-Path: <dev-return-9803-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EBC611729E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 18:55:34 +0000 (UTC)
Received: (qmail 79209 invoked by uid 500); 13 Oct 2014 18:55:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 79140 invoked by uid 500); 13 Oct 2014 18:55:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 79124 invoked by uid 99); 13 Oct 2014 18:55:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 18:55:32 +0000
X-ASF-Spam-Status: No, hits=5.7 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URIBL_BLACK
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.218.42] (HELO mail-oi0-f42.google.com) (209.85.218.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 18:55:06 +0000
Received: by mail-oi0-f42.google.com with SMTP id a141so14191266oig.29
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 11:55:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=1On/U+hOVmTnhfAKA48yxwmnfVIhVLeUC3C8uQM3nLU=;
        b=W9mDuSmnh1T36O+IGj4Xwl+c1eZZ0P/OexaO2OdHwSu4AiL454syddBT8c1r63H9rt
         nfGE6jKmsEfpmeCbdBc/VeskxFCPbmIVX4jqvuOmChOeEN/vT72+rZlxGUToUKmuKN88
         OVLKslKh4MzGJJaCVVbpS7sNHaudKKukGy3E1+hZ6x4w1hI/MY9OACmwC2IwYXyX2+ZC
         vJNIQktMAd3pV+7CLu5DOLLgM4l5mLaX544ysNjB7TG24At8KqjROkU4JF/9EzwX629F
         UlmwZDPuQHWZCBMTLaMs8WS7+CBSqIlAW+PmzsYYi9dRAbwTBpM0yBpNfP69Ugzs9mMW
         BkKg==
X-Gm-Message-State: ALoCoQlc5+i1nMi4yPMg7yDaDr+tooLoC//U2XfzRejfoSIhKazR7ksAMgV1n8yG+XicOoQ7qkYa
MIME-Version: 1.0
X-Received: by 10.202.223.133 with SMTP id w127mr288407oig.110.1413226504326;
 Mon, 13 Oct 2014 11:55:04 -0700 (PDT)
Received: by 10.60.46.198 with HTTP; Mon, 13 Oct 2014 11:55:04 -0700 (PDT)
In-Reply-To: <CAMAsSdJzZE-zH+cGm9Lz9TJZ7kSWU4X6zcXZCSE1On00voDFcQ@mail.gmail.com>
References: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
	<0AA6CFCF-B93C-4CD2-B5B1-881A727780F0@gmail.com>
	<CAMAsSdK50QTOLV5_j4A_Bi337Deq1q7F4Aqf5y+ivDwS=19Efg@mail.gmail.com>
	<CAMAsSdJhANFcnEaLpL-dLjRvxXEbyhqOjKhFWDt80+8J_SKNrg@mail.gmail.com>
	<CAF7ADNokG6RKBXhyBs4-yXs2gysAvWvzkwcr9rJ1F3GBK63VrQ@mail.gmail.com>
	<CAMAsSdJzZE-zH+cGm9Lz9TJZ7kSWU4X6zcXZCSE1On00voDFcQ@mail.gmail.com>
Date: Mon, 13 Oct 2014 11:55:04 -0700
Message-ID: <CAF7ADNqp3mf5wNkUqibTHc8d61FY6_4ax63VJwMzU0c4netgQg@mail.gmail.com>
Subject: Re: Decision forests don't work with non-trivial categorical features
From: Joseph Bradley <joseph@databricks.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Evan Sparks <evan.sparks@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113d4864c73b650505526f8b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113d4864c73b650505526f8b
Content-Type: text/plain; charset=UTF-8

I think this is the fix:

In this
file: mllib/src/main/scala/org/apache/spark/mllib/tree/impl/DTStatsAggregator.scala

methods "getFeatureOffset" and "getLeftRightFeatureOffsets" have sanity
checks ("require") which are correct for DecisionTree but not for
RandomForest.  You can remove those.  I've sent a PR with this and a few
other small fixes:

https://github.com/apache/spark/pull/2785

I hope this fixes the bug!

On Mon, Oct 13, 2014 at 11:19 AM, Sean Owen <sowen@cloudera.com> wrote:

> Great, we'll confer then. I'm using master / 1.2.0-SNAPSHOT. I'll send
> some details directly under separate cover.
>
> On Mon, Oct 13, 2014 at 7:12 PM, Joseph Bradley <joseph@databricks.com>
> wrote:
> > Hi Sean,
> >
> > Sorry I didn't see this thread earlier!  (Thanks Ameet for pinging me.)
> >
> > Short version: That exception should not be thrown, so there is a bug
> > somewhere.  The intended logic for handling high-arity categorical
> features
> > is about the best one can do, as far as I know.
> >
> > Bug finding: For my checking purposes, which branch of Spark are you
> using,
> > and do you have the options being submitted to DecisionTree?
> >
> > High-arity categorical features: As you have figured out, if you use a
> > categorical feature with just a few categories, it is treated as
> "unordered"
> > so that we explicitly consider all exponentially many ways to split the
> > categories into 2 groups.  If you use one with many categories, then it
> is
> > necessary to impose an order.  (The communication increases linearly in
> the
> > number of possible splits, so it would blow up if we considered all
> > exponentially many splits.)  This order is chosen separately for each
> node,
> > so it is not a uniform order imposed over the entire tree.  This actually
> > means that it is not a heuristic for regression and binary
> classification;
> > i.e., it chooses the same split as if we had explicitly considered all of
> > the possible splits.  For multiclass classification, it is a heuristic,
> but
> > I don't know of a better solution.
> >
> > I'll check the code, but if you can forward info about the bug, that
> would
> > be very helpful.
> >
> > Thanks!
> > Joseph
> >
>

--001a113d4864c73b650505526f8b--

From dev-return-9804-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 20:36:51 2014
Return-Path: <dev-return-9804-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 53C67176B8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 20:36:51 +0000 (UTC)
Received: (qmail 37238 invoked by uid 500); 13 Oct 2014 20:36:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37118 invoked by uid 500); 13 Oct 2014 20:36:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36193 invoked by uid 99); 13 Oct 2014 20:36:48 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 20:36:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jianshi.huang@gmail.com designates 209.85.215.52 as permitted sender)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 20:36:22 +0000
Received: by mail-la0-f52.google.com with SMTP id hz20so7486979lab.11
        for <multiple recipients>; Mon, 13 Oct 2014 13:36:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=ELIbxf6z6Xe+77KNNN4sbP4eUTDfJ1/xQJmZo72HVPw=;
        b=RkNoJf2JVl8nbMQ+UkGuvxgKqlKBb8qSOzUS2ut25Y2sLb0PwqLIU7HpruD6qzMGue
         pkBwrfDU9pzVuSmoNLLhmOKglE4U4+9GX/g5mgFvxxpE9zGR9HFnPIcW9tvVQdkSfgMe
         MUr1SjnLBzqvSOPbQV09pjRtadD+60KN0ArOlJBrF3/dCvn1xOfsqSqYg9Uig1wx1aGC
         qz5QNFzHA/lZp7pAxLcMxIpHigOx1BHsRRiDh/vBKwmkaD/SuAuH8H3tt+eUMHmHwJBF
         /05PXJCikVWN5f5NvuSzKxcolcr89tH0s7aTUICu9wHaVp10GIni5RHPyAdkGB4shLm4
         mSjQ==
X-Received: by 10.112.99.136 with SMTP id eq8mr803175lbb.57.1413232581497;
 Mon, 13 Oct 2014 13:36:21 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.161.208 with HTTP; Mon, 13 Oct 2014 13:36:01 -0700 (PDT)
In-Reply-To: <CACA1tWJGots4FNZvof0jp5DBSnGQRGDm3UTaOy7rmgCU4TDAAw@mail.gmail.com>
References: <CACA1tW+oBk3m4V7Paq9bQ_nQ_7G=FATC8CL=sPxDncSCYAubrw@mail.gmail.com>
 <CACA1tWJGots4FNZvof0jp5DBSnGQRGDm3UTaOy7rmgCU4TDAAw@mail.gmail.com>
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Tue, 14 Oct 2014 04:36:01 +0800
Message-ID: <CACA1tWKGkpEO-U4JmArM3=RwNDL498EFZuSH4vnhapSZVDu_HA@mail.gmail.com>
Subject: Re: SPARK-3106 fixed?
To: user <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11348fd4015b2c050553dad0
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11348fd4015b2c050553dad0
Content-Type: text/plain; charset=UTF-8

Turned out it was caused by this issue:
https://issues.apache.org/jira/browse/SPARK-3923

Set spark.akka.heartbeat.interval to 100 solved it.

Jianshi

On Mon, Oct 13, 2014 at 4:24 PM, Jianshi Huang <jianshi.huang@gmail.com>
wrote:

> Hmm... it failed again, just lasted a little bit longer.
>
> Jianshi
>
> On Mon, Oct 13, 2014 at 4:15 PM, Jianshi Huang <jianshi.huang@gmail.com>
> wrote:
>
>> https://issues.apache.org/jira/browse/SPARK-3106
>>
>> I'm having the saming errors described in SPARK-3106 (no other types of
>> errors confirmed), running a bunch sql queries on spark 1.2.0 built from
>> latest master HEAD.
>>
>> Any updates to this issue?
>>
>> My main task is to join a huge fact table with a dozen dim tables (using
>> HiveContext) and then map it to my class object. It failed a couple of
>> times and now I cached the intermediate table and currently it seems
>> working fine... no idea why until I found SPARK-3106
>>
>> Cheers,
>> --
>> Jianshi Huang
>>
>> LinkedIn: jianshi
>> Twitter: @jshuang
>> Github & Blog: http://huangjs.github.com/
>>
>
>
>
> --
> Jianshi Huang
>
> LinkedIn: jianshi
> Twitter: @jshuang
> Github & Blog: http://huangjs.github.com/
>



-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--001a11348fd4015b2c050553dad0--

From dev-return-9805-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 20:46:21 2014
Return-Path: <dev-return-9805-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 422BD17737
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 20:46:21 +0000 (UTC)
Received: (qmail 75280 invoked by uid 500); 13 Oct 2014 20:46:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75163 invoked by uid 500); 13 Oct 2014 20:46:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74189 invoked by uid 99); 13 Oct 2014 20:46:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 20:46:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jianshi.huang@gmail.com designates 209.85.217.169 as permitted sender)
Received: from [209.85.217.169] (HELO mail-lb0-f169.google.com) (209.85.217.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 20:45:53 +0000
Received: by mail-lb0-f169.google.com with SMTP id 10so7121559lbg.0
        for <multiple recipients>; Mon, 13 Oct 2014 13:45:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=VDmdg75QusyMUanvcuYeZ4GJIR90TKuBoJ5W6eAuohs=;
        b=irac9UZwCYibipo71XaSsxrpGvlaL6AUiG/IDaKO3M9DrFfshm68JhlAYUzvNH28T4
         Q+xflPOxnSNE0FOK9iatjuagBcCgR5xrctZkQ/nDvz++Q1HOzuzLOx3l3Vhoy3zbBiDP
         8n6e++44/SlE90iilRwU+FSExRPpWklllHuYiCm5/s8KFrvxJFoCf98fc80ICtpfPzYx
         5+C/0IW0xDl3PlqQaLCYat2s/CTKCbJctzEKYoom6YjjLcFnIHMVjt96KDq2OF6FgVu0
         HU+uwstU7YFVu6L2k/gaW1udGK5riO/rTztvu1t3y8g2UohCSqWNjBt1Hid0+AYlCUB3
         urNw==
X-Received: by 10.152.21.135 with SMTP id v7mr854172lae.65.1413233152931; Mon,
 13 Oct 2014 13:45:52 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.161.208 with HTTP; Mon, 13 Oct 2014 13:45:32 -0700 (PDT)
In-Reply-To: <CACA1tWKGkpEO-U4JmArM3=RwNDL498EFZuSH4vnhapSZVDu_HA@mail.gmail.com>
References: <CACA1tW+oBk3m4V7Paq9bQ_nQ_7G=FATC8CL=sPxDncSCYAubrw@mail.gmail.com>
 <CACA1tWJGots4FNZvof0jp5DBSnGQRGDm3UTaOy7rmgCU4TDAAw@mail.gmail.com> <CACA1tWKGkpEO-U4JmArM3=RwNDL498EFZuSH4vnhapSZVDu_HA@mail.gmail.com>
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Tue, 14 Oct 2014 04:45:32 +0800
Message-ID: <CACA1tWJzVL+Zti8TC3Aw1rqt5x2HV04dJuxM0D=T5OTv1xp0sQ@mail.gmail.com>
Subject: Re: SPARK-3106 fixed?
To: user <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158b3cc10c0ad050553fc43
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158b3cc10c0ad050553fc43
Content-Type: text/plain; charset=UTF-8

One thing made me very confused during debuggin is the error message. The
important one

  WARN ReliableDeliverySupervisor: Association with remote system
[akka.tcp://sparkDriver@xxx:50278] has failed, address is now gated for
[5000] ms. Reason is: [Disassociated].

is of Log Level WARN.

Jianshi


On Tue, Oct 14, 2014 at 4:36 AM, Jianshi Huang <jianshi.huang@gmail.com>
wrote:

> Turned out it was caused by this issue:
> https://issues.apache.org/jira/browse/SPARK-3923
>
> Set spark.akka.heartbeat.interval to 100 solved it.
>
> Jianshi
>
> On Mon, Oct 13, 2014 at 4:24 PM, Jianshi Huang <jianshi.huang@gmail.com>
> wrote:
>
>> Hmm... it failed again, just lasted a little bit longer.
>>
>> Jianshi
>>
>> On Mon, Oct 13, 2014 at 4:15 PM, Jianshi Huang <jianshi.huang@gmail.com>
>> wrote:
>>
>>> https://issues.apache.org/jira/browse/SPARK-3106
>>>
>>> I'm having the saming errors described in SPARK-3106 (no other types of
>>> errors confirmed), running a bunch sql queries on spark 1.2.0 built from
>>> latest master HEAD.
>>>
>>> Any updates to this issue?
>>>
>>> My main task is to join a huge fact table with a dozen dim tables (using
>>> HiveContext) and then map it to my class object. It failed a couple of
>>> times and now I cached the intermediate table and currently it seems
>>> working fine... no idea why until I found SPARK-3106
>>>
>>> Cheers,
>>> --
>>> Jianshi Huang
>>>
>>> LinkedIn: jianshi
>>> Twitter: @jshuang
>>> Github & Blog: http://huangjs.github.com/
>>>
>>
>>
>>
>> --
>> Jianshi Huang
>>
>> LinkedIn: jianshi
>> Twitter: @jshuang
>> Github & Blog: http://huangjs.github.com/
>>
>
>
>
> --
> Jianshi Huang
>
> LinkedIn: jianshi
> Twitter: @jshuang
> Github & Blog: http://huangjs.github.com/
>



-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--089e0158b3cc10c0ad050553fc43--

From dev-return-9806-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 21:30:09 2014
Return-Path: <dev-return-9806-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 026A917961
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 21:30:09 +0000 (UTC)
Received: (qmail 15731 invoked by uid 500); 13 Oct 2014 21:30:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15658 invoked by uid 500); 13 Oct 2014 21:30:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 15646 invoked by uid 99); 13 Oct 2014 21:30:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:30:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.44 as permitted sender)
Received: from [74.125.82.44] (HELO mail-wg0-f44.google.com) (74.125.82.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:29:39 +0000
Received: by mail-wg0-f44.google.com with SMTP id y10so9543688wgg.27
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 14:29:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=efRhRep3Bu+dCrCPFzmtbGrYrKmx247h+RVL7UY2p1U=;
        b=z0/vi2jnezGTRzA9wA+VtyrIzOMtKdgS1s4Wd7dBU4sz+WR7B0fuGQDE8DNL9imiKy
         IZJs+SxkiNQtHJgZYyNKIX4iM9ht4e/DSptBdibtvMgWG/GlPDIUv9+wlf+xH19y3CRC
         +WbLFrbdJCiU41OcAHiuBQarwlu+i0udqxSXtmukaQvxE7br9zsJxbKA2Wq0m+Dwb9dr
         m4ysUy27CxmAGpdhWcYeUSFoGmQpKn4fHyzsBDJjKWS9WnoCFKX36/+jUYHcX2mt0kwX
         YBr8BJ7HC6GRUYX4g7oVNQGkqmPjCTuf+gkMWEC/P97nNoYwRfBeYEwA37YdB1agR6DI
         NQBw==
X-Received: by 10.180.11.227 with SMTP id t3mr1412926wib.45.1413235778899;
 Mon, 13 Oct 2014 14:29:38 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 13 Oct 2014 14:28:58 -0700 (PDT)
In-Reply-To: <CACdU-dTk1bSnaNk37=AGVt_aqPBS0_pH571VxAXJg-_JDnanPQ@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
 <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
 <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
 <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com>
 <CACdU-dTNrWoeosvggCERMnS8YwtvMgNLQK8DcWXaNAtcqmBWWw@mail.gmail.com> <CACdU-dTk1bSnaNk37=AGVt_aqPBS0_pH571VxAXJg-_JDnanPQ@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 13 Oct 2014 17:28:58 -0400
Message-ID: <CAOhmDzeEB4_KFs5oNAVHfG9aomNfDKhjbjVFTBaA2_pdUNi93Q@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: shane knapp <sknapp@berkeley.edu>
Cc: Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>, 
	amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11c2400c95d40b0505549857
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2400c95d40b0505549857
Content-Type: text/plain; charset=UTF-8

Thanks for doing this work Shane.

So is Jenkins in the new datacenter now? Do you know if the problems with
checking out patches from GitHub should be resolved now? Here's an example
from the past hour
<https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21702/console>
.

Nick


On Mon, Oct 13, 2014 at 1:35 PM, shane knapp <sknapp@berkeley.edu> wrote:

> AND WE ARE LIIIIIIIVE!
>
> https://amplab.cs.berkeley.edu/jenkins/
>
> have at it, folks!
>
> On Mon, Oct 13, 2014 at 10:15 AM, shane knapp <sknapp@berkeley.edu> wrote:
>
> > quick update:  we should be back up and running in the next ~60mins.
> >
> > On Mon, Oct 13, 2014 at 7:54 AM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >
> >> Jenkins is in quiet mode and the move will be starting after i have my
> >> coffee.  :)
> >>
> >> On Sun, Oct 12, 2014 at 11:26 PM, Josh Rosen <rosenville@gmail.com>
> >> wrote:
> >>
> >>> Reminder: this Jenkins migration is happening tomorrow morning
> (Monday).
> >>>
> >>> On Fri, Oct 10, 2014 at 1:01 PM, shane knapp <sknapp@berkeley.edu>
> >>> wrote:
> >>>
> >>>> reminder:  this IS happening, first thing monday morning PDT.  :)
> >>>>
> >>>> On Wed, Oct 8, 2014 at 3:01 PM, shane knapp <sknapp@berkeley.edu>
> >>>> wrote:
> >>>>
> >>>> > greetings!
> >>>> >
> >>>> > i've got some updates regarding our new jenkins infrastructure, as
> >>>> well as
> >>>> > the initial date and plan for rolling things out:
> >>>> >
> >>>> > *** current testing/build break whack-a-mole:
> >>>> > a lot of out of date artifacts are cached in the current jenkins,
> >>>> which
> >>>> > has caused a few builds during my testing to break due to dependency
> >>>> > resolution failure[1][2].
> >>>> >
> >>>> > bumping these versions can cause your builds to fail, due to public
> >>>> api
> >>>> > changes and the like.  consider yourself warned that some projects
> >>>> might
> >>>> > require some debugging...  :)
> >>>> >
> >>>> > tomorrow, i will be at databricks working w/@joshrosen to make sure
> >>>> that
> >>>> > the spark builds have any bugs hammered out.
> >>>> >
> >>>> > ***  deployment plan:
> >>>> > unless something completely horrible happens, THE NEW JENKINS WILL
> GO
> >>>> LIVE
> >>>> > ON MONDAY (october 13th).
> >>>> >
> >>>> > all jenkins infrastructure will be DOWN for the entirety of the day
> >>>> > (starting at ~8am).  this means no builds, period.  i'm hoping that
> >>>> the
> >>>> > downtime will be much shorter than this, but we'll have to see how
> >>>> > everything goes.
> >>>> >
> >>>> > all test/build history WILL BE PRESERVED.  i will be rsyncing the
> >>>> jenkins
> >>>> > jobs/ directory over, complete w/history as part of the deployment.
> >>>> >
> >>>> > once i'm feeling good about the state of things, i'll point the
> >>>> original
> >>>> > url to the new instances and send out an all clear.
> >>>> >
> >>>> > if you are a student at UC berkeley, you can log in to jenkins using
> >>>> your
> >>>> > LDAP login, and (by default) view but not change plans.  if you do
> >>>> not have
> >>>> > a UC berkeley LDAP login, you can still view plans anonymously.
> >>>> >
> >>>> > IF YOU ARE A PLAN ADMIN, THEN PLEASE REACH OUT, ASAP, PRIVATELY AND
> I
> >>>> WILL
> >>>> > SET UP ADMIN ACCESS TO YOUR BUILDS.
> >>>> >
> >>>> > ***  post deployment plan:
> >>>> > fix all of the things that break!
> >>>> >
> >>>> > i will be keeping a VERY close eye on the builds, checking for
> >>>> breaks, and
> >>>> > helping out where i can.  if the situation is dire, i can always
> roll
> >>>> back
> >>>> > to the old jenkins infra...  but i hope we never get to that point!
> >>>> :)
> >>>> >
> >>>> > i'm hoping that things will go smoothly, but please be patient as
> i'm
> >>>> > certain we'll hit a few bumps in the road.
> >>>> >
> >>>> > please let me know if you guys have any
> >>>> comments/questions/concerns...  :)
> >>>> >
> >>>> > shane
> >>>> >
> >>>> > 1 - https://github.com/bigdatagenomics/bdg-services/pull/18
> >>>> > 2 - https://github.com/bigdatagenomics/avocado/pull/111
> >>>> >
> >>>>
> >>>
> >>>
> >>
> >
>

--001a11c2400c95d40b0505549857--

From dev-return-9807-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 21:37:14 2014
Return-Path: <dev-return-9807-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 53B39179B9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 21:37:14 +0000 (UTC)
Received: (qmail 35921 invoked by uid 500); 13 Oct 2014 21:37:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35793 invoked by uid 500); 13 Oct 2014 21:37:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34882 invoked by uid 99); 13 Oct 2014 21:37:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:37:12 +0000
X-ASF-Spam-Status: No, hits=2.8 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URIBL_BLACK
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.44 as permitted sender)
Received: from [209.85.220.44] (HELO mail-pa0-f44.google.com) (209.85.220.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:36:46 +0000
Received: by mail-pa0-f44.google.com with SMTP id et14so6519379pad.17
        for <multiple recipients>; Mon, 13 Oct 2014 14:36:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=nGgV43pTVlHwvi7itkRVn+FjKYMSTmX6WjFK19qjCcI=;
        b=qmFHucQo3O+OpxfOR9APgV+ykbGaW4bOlk9rx8UWmqhfPAN8dW5At7FARwGnNWPKKA
         89Xyo8VqK9MQv0NrxAk16LwzUGhRZsqCMmQAgu2803riR88bW3pXs0+1lGcc+uUPnyEg
         MSFEU17Qrq45kSAg2Ac6GLsu97vUXnNaic5VPSur601/JVMIDiJpalZph57S+yCFaijZ
         hRF65Q+rRaTBwkUnuITt4+O7PL1QpCa/fMna8w0KDLv5IKkTk7J9Xq0TlX5EkUOHWLi4
         ganMXcYsGTkm5PPn/mqdJQi+pC9nDsJ4ul6GbzcFPaPi6e+19PWyU3BjBjnwwcAGqdKy
         D5Tw==
X-Received: by 10.70.100.199 with SMTP id fa7mr1081926pdb.114.1413236204400;
        Mon, 13 Oct 2014 14:36:44 -0700 (PDT)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id u11sm12104502pbs.21.2014.10.13.14.36.43
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 13 Oct 2014 14:36:43 -0700 (PDT)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CAM-S9zTYKdhSdWaqUL-LuXCOrMDrERCY_kA87Wgb+KwJth3o=g@mail.gmail.com>
Date: Mon, 13 Oct 2014 14:36:41 -0700
Cc: dev@spark.apache.org,
 user@spark.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <2FAADD1E-810E-46A7-9BF9-F2C8BD2A3CCA@gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com> <CAM-S9zTYKdhSdWaqUL-LuXCOrMDrERCY_kA87Wgb+KwJth3o=g@mail.gmail.com>
To: Ilya Ganelin <ilganeli@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

The biggest scaling issue was supporting a large number of reduce tasks =
efficiently, which the JIRAs in that post handle. In particular, our =
current default shuffle (the hash-based one) has each map task open a =
separate file output stream for each reduce task, which wastes a lot of =
memory (since each stream has its own buffer).

A second thing that helped efficiency tremendously was Reynold's new =
network module (https://issues.apache.org/jira/browse/SPARK-2468). Doing =
I/O on 32 cores, 10 Gbps Ethernet and 8+ disks efficiently is not easy, =
as can be seen when you try to scale up other software.

Finally, with 30,000 tasks even sending info about every map's output =
size to each reducer was a problem, so Reynold has a patch that avoids =
that if the number of tasks is large.

Matei

On Oct 10, 2014, at 10:09 PM, Ilya Ganelin <ilganeli@gmail.com> wrote:

> Hi Matei - I read your post with great interest. Could you possibly =
comment in more depth on some of the issues you guys saw when scaling up =
spark and how you resolved them? I am interested specifically in =
spark-related problems. I'm working on scaling up spark to very large =
datasets and have been running into a variety of issues. Thanks in =
advance!
>=20
> On Oct 10, 2014 10:54 AM, "Matei Zaharia" <matei.zaharia@gmail.com> =
wrote:
> Hi folks,
>=20
> I interrupt your regularly scheduled user / dev list to bring you some =
pretty cool news for the project, which is that we've been able to use =
Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x =
faster on 10x fewer nodes. There's a detailed writeup at =
http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-so=
rt-record.html. Summary: while Hadoop MapReduce held last year's 100 TB =
world record by sorting 100 TB in 72 minutes on 2100 nodes, we sorted it =
in 23 minutes on 206 nodes; and we also scaled up to sort 1 PB in 234 =
minutes.
>=20
> I want to thank Reynold Xin for leading this effort over the past few =
weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali =
Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for =
providing the machines to make this possible. Finally, this result would =
of course not be possible without the many many other contributions, =
testing and feature requests from throughout the community.
>=20
> For an engine to scale from these multi-hour petabyte batch jobs down =
to 100-millisecond streaming and interactive queries is quite uncommon, =
and it's thanks to all of you folks that we are able to make this =
happen.
>=20
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9808-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 21:44:19 2014
Return-Path: <dev-return-9808-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1DE3517A06
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 21:44:19 +0000 (UTC)
Received: (qmail 63767 invoked by uid 500); 13 Oct 2014 21:44:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63690 invoked by uid 500); 13 Oct 2014 21:44:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63679 invoked by uid 99); 13 Oct 2014 21:44:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:44:18 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:43:53 +0000
Received: by mail-la0-f42.google.com with SMTP id mk6so7510328lab.1
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 14:43:51 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=c1hI3X7f/rBUq0g0qU/JAQLsZjnTatmoiGT8lJVGkqk=;
        b=ek3wpmS9nhD5gY9mPSDNw/Thppt/FwzkMxJfMqorGi5XX9VLJMNgLagfVIUVqh8S07
         Hv2mz38Z/UCH6au+Y5FbJs92XtZIF8UrosYhyeuD+KoOtTzC2HmEcAXQH729JbHXV+Pk
         Nw9bpPkV/6WoT2ETupVdsCxIsfMrTbH7psucw6ySrKpmgqEN/LLPYvOxoVyca4YGTOpK
         lvDRTk1qHoepUQVE0J5CU8lxd9HYYybByLdQ/f5p2k8Kc7iIX5c5N6rWSXCcGbcmm9vR
         l0w3u+H3PgoPNMGjwo0p0ub//6cC732JjRGKsmXl1krMZxYUwG3R+K8O+o8zWBS80f7P
         nTsA==
X-Gm-Message-State: ALoCoQlM6scGhkE52DYmnzO1Km8TunC8svkeYiIM9wHpcPWP29dECjzMy0U50TiugjtgAEP81x7G
X-Received: by 10.152.28.134 with SMTP id b6mr1323772lah.12.1413236631510;
 Mon, 13 Oct 2014 14:43:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Mon, 13 Oct 2014 14:43:30 -0700 (PDT)
In-Reply-To: <CAOhmDzeEB4_KFs5oNAVHfG9aomNfDKhjbjVFTBaA2_pdUNi93Q@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
 <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
 <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
 <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com>
 <CACdU-dTNrWoeosvggCERMnS8YwtvMgNLQK8DcWXaNAtcqmBWWw@mail.gmail.com>
 <CACdU-dTk1bSnaNk37=AGVt_aqPBS0_pH571VxAXJg-_JDnanPQ@mail.gmail.com> <CAOhmDzeEB4_KFs5oNAVHfG9aomNfDKhjbjVFTBaA2_pdUNi93Q@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 13 Oct 2014 14:43:30 -0700
Message-ID: <CACdU-dRj=9Eao-uuecOZsnyhsDMCeq40KsT1crFMX7S+x+OR8A@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>, 
	amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=089e0160a63867ad31050554cb19
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160a63867ad31050554cb19
Content-Type: text/plain; charset=UTF-8

On Mon, Oct 13, 2014 at 2:28 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> Thanks for doing this work Shane.
>
> So is Jenkins in the new datacenter now? Do you know if the problems with
> checking out patches from GitHub should be resolved now? Here's an
> example from the past hour
> <https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21702/console>
> .
>
>
> yeah, i just noticed that we're still having the checkout issues.  i was
really hoping that the better network would just make this go away...
 guess i'll be doing a deeper dive now.

i would just up the timeout, but that's not coming out for a little while
yet:
https://issues.jenkins-ci.org/browse/JENKINS-20387

(we are currently running the latest -- 2.2.7, and the timeout field is
coming in 2.3, whenever that is)

i'll try and strace/replicate it locally as well.

--089e0160a63867ad31050554cb19--

From dev-return-9809-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 21:49:11 2014
Return-Path: <dev-return-9809-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1214917A39
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 21:49:11 +0000 (UTC)
Received: (qmail 78631 invoked by uid 500); 13 Oct 2014 21:49:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 78557 invoked by uid 500); 13 Oct 2014 21:49:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 78545 invoked by uid 99); 13 Oct 2014 21:49:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:49:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:48:43 +0000
Received: by mail-wg0-f48.google.com with SMTP id k14so9511405wgh.31
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 14:48:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=zUZEJFfoYMbkkUT8z0tDvnEezeKPmMVOfp+vnKiuc/4=;
        b=PMj3T7bn4qvZ3NQNEza65fSqPgKMQoB5CsK3otScyuEL2O9WgZib0qk5AQZXIxkqJE
         pTQwR9KNIX6rZVgxT1dnojYxutn965r00obzuR8MMqOh3UBWXACDW62y8UioJXATVI4V
         8gKnopq4byFFXS7fDyur3zTzqJspQkSJdOTMkTGSiHDxwyibLAEoCuxRSaUqz0wdbBgt
         d2UHed4nAcyZI+6zdGcDHeOSUDfeRhGiiTJrS+uWeNoK8TUAeP2zFs3pG2aW7u0D3KFp
         o59/u1R0kAK8XKWl7fnu5PWwUXdiJeSCPLJLeE39YrKDQZ3Uvez9QQZp61JBaD2g835r
         TLXw==
X-Received: by 10.194.71.83 with SMTP id s19mr956697wju.29.1413236922931; Mon,
 13 Oct 2014 14:48:42 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 13 Oct 2014 14:48:02 -0700 (PDT)
In-Reply-To: <CACdU-dRj=9Eao-uuecOZsnyhsDMCeq40KsT1crFMX7S+x+OR8A@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
 <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
 <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
 <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com>
 <CACdU-dTNrWoeosvggCERMnS8YwtvMgNLQK8DcWXaNAtcqmBWWw@mail.gmail.com>
 <CACdU-dTk1bSnaNk37=AGVt_aqPBS0_pH571VxAXJg-_JDnanPQ@mail.gmail.com>
 <CAOhmDzeEB4_KFs5oNAVHfG9aomNfDKhjbjVFTBaA2_pdUNi93Q@mail.gmail.com> <CACdU-dRj=9Eao-uuecOZsnyhsDMCeq40KsT1crFMX7S+x+OR8A@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 13 Oct 2014 17:48:02 -0400
Message-ID: <CAOhmDzcXoZuQp+aQmqtYK+8B1eDNYjo+SqXdVfv0YhEbc1d-_A@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: shane knapp <sknapp@berkeley.edu>
Cc: Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>, 
	amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=047d7bfd0280c65f40050554dcd4
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfd0280c65f40050554dcd4
Content-Type: text/plain; charset=UTF-8

Ah, that sucks. Thank you for looking into this.

On Mon, Oct 13, 2014 at 5:43 PM, shane knapp <sknapp@berkeley.edu> wrote:

> On Mon, Oct 13, 2014 at 2:28 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Thanks for doing this work Shane.
>>
>> So is Jenkins in the new datacenter now? Do you know if the problems with
>> checking out patches from GitHub should be resolved now? Here's an
>> example from the past hour
>> <https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21702/console>
>> .
>>
>>
>> yeah, i just noticed that we're still having the checkout issues.  i was
> really hoping that the better network would just make this go away...
>  guess i'll be doing a deeper dive now.
>
> i would just up the timeout, but that's not coming out for a little while
> yet:
> https://issues.jenkins-ci.org/browse/JENKINS-20387
>
> (we are currently running the latest -- 2.2.7, and the timeout field is
> coming in 2.3, whenever that is)
>
> i'll try and strace/replicate it locally as well.
>
>

--047d7bfd0280c65f40050554dcd4--

From dev-return-9810-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 21:54:47 2014
Return-Path: <dev-return-9810-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B3C6517A6A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 21:54:47 +0000 (UTC)
Received: (qmail 95658 invoked by uid 500); 13 Oct 2014 21:54:46 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 95585 invoked by uid 500); 13 Oct 2014 21:54:46 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95574 invoked by uid 99); 13 Oct 2014 21:54:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:54:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.177 as permitted sender)
Received: from [209.85.217.177] (HELO mail-lb0-f177.google.com) (209.85.217.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:54:42 +0000
Received: by mail-lb0-f177.google.com with SMTP id w7so6997407lbi.8
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 14:54:21 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=ecaGKKrBrdPJRKkiZIhb1maCKs/3RIb+nTRRhyXuMLY=;
        b=QJyRTqbS5iGIcos34aJYoBwoiu813ckd3ZUFq+78Wri/AyfReAz3xhFVevPEirXg2z
         Op3SeNs1Jwp+JlM4fxVqwX91XkTQgmJFhr7ZFQFwJsRUje0xFKjY/YWXPAdHaa+JhYuT
         fKj/IMbwgFJ4ReveCrrNFJZg7ZE/OAZBom3t+KChLlYOSN7PVjWfO0nZVpOp+eSQ3gNW
         S2WClLV34X6WaiXegUwY3ppvGLusgDOnAHbo/+gzZuYnsUFcAxI/GHrbU/+xzlfxb74E
         QtoH/Tcx8iwsnsffSNC3bhLDD1IlWhj8e3I2sKpIW9VcfcPwM10mQa/lZkRgSyI4vLbv
         MoJg==
X-Gm-Message-State: ALoCoQngkKmMZvquCny45xZVEFNwhxqkqhiGfMdD8Bn9MT60Qyno92r3T22LCAcMcIlBXYQl+1Ri
X-Received: by 10.112.54.162 with SMTP id k2mr1086967lbp.63.1413237260712;
 Mon, 13 Oct 2014 14:54:20 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Mon, 13 Oct 2014 14:54:00 -0700 (PDT)
In-Reply-To: <CAOhmDzcXoZuQp+aQmqtYK+8B1eDNYjo+SqXdVfv0YhEbc1d-_A@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
 <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
 <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
 <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com>
 <CACdU-dTNrWoeosvggCERMnS8YwtvMgNLQK8DcWXaNAtcqmBWWw@mail.gmail.com>
 <CACdU-dTk1bSnaNk37=AGVt_aqPBS0_pH571VxAXJg-_JDnanPQ@mail.gmail.com>
 <CAOhmDzeEB4_KFs5oNAVHfG9aomNfDKhjbjVFTBaA2_pdUNi93Q@mail.gmail.com>
 <CACdU-dRj=9Eao-uuecOZsnyhsDMCeq40KsT1crFMX7S+x+OR8A@mail.gmail.com> <CAOhmDzcXoZuQp+aQmqtYK+8B1eDNYjo+SqXdVfv0YhEbc1d-_A@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 13 Oct 2014 14:54:00 -0700
Message-ID: <CACdU-dTh=pX1NsN56n5r5CLHKsG4sOOTsWHUs1xpJv3501TcGg@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>, 
	amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11c3eeeee88aba050554f0e4
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3eeeee88aba050554f0e4
Content-Type: text/plain; charset=UTF-8

ok, i found something that may help:
https://issues.jenkins-ci.org/browse/JENKINS-20445?focusedCommentId=195638&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-195638

i set this to 20 minutes...  let's see if that helps.

On Mon, Oct 13, 2014 at 2:48 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> Ah, that sucks. Thank you for looking into this.
>
> On Mon, Oct 13, 2014 at 5:43 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> On Mon, Oct 13, 2014 at 2:28 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> Thanks for doing this work Shane.
>>>
>>> So is Jenkins in the new datacenter now? Do you know if the problems
>>> with checking out patches from GitHub should be resolved now? Here's an
>>> example from the past hour
>>> <https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21702/console>
>>> .
>>>
>>>
>>> yeah, i just noticed that we're still having the checkout issues.  i was
>> really hoping that the better network would just make this go away...
>>  guess i'll be doing a deeper dive now.
>>
>> i would just up the timeout, but that's not coming out for a little while
>> yet:
>> https://issues.jenkins-ci.org/browse/JENKINS-20387
>>
>> (we are currently running the latest -- 2.2.7, and the timeout field is
>> coming in 2.3, whenever that is)
>>
>> i'll try and strace/replicate it locally as well.
>>
>>
>
>

--001a11c3eeeee88aba050554f0e4--

From dev-return-9811-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 21:56:39 2014
Return-Path: <dev-return-9811-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 47AF317A7F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 21:56:39 +0000 (UTC)
Received: (qmail 502 invoked by uid 500); 13 Oct 2014 21:56:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 416 invoked by uid 500); 13 Oct 2014 21:56:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 403 invoked by uid 99); 13 Oct 2014 21:56:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:56:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.173 as permitted sender)
Received: from [209.85.212.173] (HELO mail-wi0-f173.google.com) (209.85.212.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 21:56:34 +0000
Received: by mail-wi0-f173.google.com with SMTP id fb4so8543544wid.12
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 14:56:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=ZpsfS6t6+wXAUxxtYjais7LBsdAqtG5uzLvr6JY4qDw=;
        b=oPNDyleLdXdWpOOxaVhtKaTFwzx6MfVRdax+fi3jH5ssXAe/IZvYjn8s2Wze80+l9b
         Pqt8mDeW0ZQSXDS1Q68QZzYbJUI4OZNqL1uZnzUwUvfaDnsHVxe+fF0IPFaDgOhRDlVc
         kx5BqP1gzszPPsg5Tz/kMSvs+XVbc3MEJx/F0gorlyU5ubmyBTHmlqj/pZo1/j83NsFu
         4xdtgZ3dyGwe3n1q/MLuLLK3dAb37w/GPBIdF8qgfw4ZcE7MOK8Aue2ZS1/0uILlXwfn
         D4T7W9W5WU1xzHKH81qLbjhUP2Y8P9Tg8kuREb9YQ2/AzhHIGspSYdI0j2Lqc5xxqRTk
         Fmjg==
X-Received: by 10.180.11.227 with SMTP id t3mr1499548wib.45.1413237373116;
 Mon, 13 Oct 2014 14:56:13 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 13 Oct 2014 14:55:32 -0700 (PDT)
In-Reply-To: <CACdU-dTh=pX1NsN56n5r5CLHKsG4sOOTsWHUs1xpJv3501TcGg@mail.gmail.com>
References: <CACdU-dSS4iHqxB7p90ecLnUr+FCVQEkjqCo44Np3-83R5bGSbw@mail.gmail.com>
 <CACdU-dQ_nwMt1G3ZiQaWt6MQWhfeJ5aW1jpHUdMLyS3ECbYTxw@mail.gmail.com>
 <CAOEPXP55P3oyicwhuwMKwQ-Bu0aOAxa-A1P-yF1vKPCo6zL-0Q@mail.gmail.com>
 <CACdU-dQuLPvTmgeGGYxDQGhEmJ3VxOn_Km4oyBHMAbLT9A9=Jg@mail.gmail.com>
 <CACdU-dTNrWoeosvggCERMnS8YwtvMgNLQK8DcWXaNAtcqmBWWw@mail.gmail.com>
 <CACdU-dTk1bSnaNk37=AGVt_aqPBS0_pH571VxAXJg-_JDnanPQ@mail.gmail.com>
 <CAOhmDzeEB4_KFs5oNAVHfG9aomNfDKhjbjVFTBaA2_pdUNi93Q@mail.gmail.com>
 <CACdU-dRj=9Eao-uuecOZsnyhsDMCeq40KsT1crFMX7S+x+OR8A@mail.gmail.com>
 <CAOhmDzcXoZuQp+aQmqtYK+8B1eDNYjo+SqXdVfv0YhEbc1d-_A@mail.gmail.com> <CACdU-dTh=pX1NsN56n5r5CLHKsG4sOOTsWHUs1xpJv3501TcGg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 13 Oct 2014 17:55:32 -0400
Message-ID: <CAOhmDze1wmK06+hLdRJMsRtf-ZORtsX+r3VcA7u3k8sS1by4ig@mail.gmail.com>
Subject: Re: new jenkins update + tentative release date
To: shane knapp <sknapp@berkeley.edu>
Cc: Josh Rosen <rosenville@gmail.com>, dev <dev@spark.apache.org>, 
	amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=001a11c2400c9ba7ab050554f7e6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2400c9ba7ab050554f7e6
Content-Type: text/plain; charset=UTF-8

*fingers crossed*

On Mon, Oct 13, 2014 at 5:54 PM, shane knapp <sknapp@berkeley.edu> wrote:

> ok, i found something that may help:
>
> https://issues.jenkins-ci.org/browse/JENKINS-20445?focusedCommentId=195638&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-195638
>
> i set this to 20 minutes...  let's see if that helps.
>
> On Mon, Oct 13, 2014 at 2:48 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Ah, that sucks. Thank you for looking into this.
>>
>> On Mon, Oct 13, 2014 at 5:43 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> On Mon, Oct 13, 2014 at 2:28 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> Thanks for doing this work Shane.
>>>>
>>>> So is Jenkins in the new datacenter now? Do you know if the problems
>>>> with checking out patches from GitHub should be resolved now? Here's an
>>>> example from the past hour
>>>> <https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21702/console>
>>>> .
>>>>
>>>>
>>>> yeah, i just noticed that we're still having the checkout issues.  i
>>> was really hoping that the better network would just make this go away...
>>>  guess i'll be doing a deeper dive now.
>>>
>>> i would just up the timeout, but that's not coming out for a little
>>> while yet:
>>> https://issues.jenkins-ci.org/browse/JENKINS-20387
>>>
>>> (we are currently running the latest -- 2.2.7, and the timeout field is
>>> coming in 2.3, whenever that is)
>>>
>>> i'll try and strace/replicate it locally as well.
>>>
>>>
>>
>>
>

--001a11c2400c9ba7ab050554f7e6--

From dev-return-9812-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 22:56:40 2014
Return-Path: <dev-return-9812-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8BB1C17C68
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 22:56:40 +0000 (UTC)
Received: (qmail 38561 invoked by uid 500); 13 Oct 2014 22:56:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38489 invoked by uid 500); 13 Oct 2014 22:56:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 30920 invoked by uid 99); 13 Oct 2014 22:53:26 -0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ilganeli@gmail.com designates 209.85.213.176 as permitted sender)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=b9Y3d9J8mSN/phP0fm6p5AW4edV3exU0LCnf4WOVTIw=;
        b=wSYlUaR0H3IsrUVvLDZ991+vUd/G7mBmaf4SJXofUB/6F49vbt1mqj1iGu2JutoWc+
         aoqTE/SZjtjVYDtmXnLi1w800i8G+y/dqWMrcnXULGC+f2I9lsO6sJya0UPhAr430X1K
         GsHxatVmuHqKwGYN+zLchR3vtW4R1U18deq4tY98qito+AHh0DCdQTUNub+fcLpPMz/m
         PWWNt2mtlCz88OtWQtRVAIyJ4x6De+Ip+b4OqNLfgHwPVcQ/IPVQyS/BS5Mqw0sfFNt6
         BFMCEl8wQOs28lVnG3NQ8NZYRiUpNUhNMHaQ+FJtY6Di65pjdEE8oS3fZmA4uU2XLNMM
         tr7Q==
MIME-Version: 1.0
X-Received: by 10.51.16.37 with SMTP id ft5mr2726239igd.6.1413240778955; Mon,
 13 Oct 2014 15:52:58 -0700 (PDT)
In-Reply-To: <2FAADD1E-810E-46A7-9BF9-F2C8BD2A3CCA@gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
	<CAM-S9zTYKdhSdWaqUL-LuXCOrMDrERCY_kA87Wgb+KwJth3o=g@mail.gmail.com>
	<2FAADD1E-810E-46A7-9BF9-F2C8BD2A3CCA@gmail.com>
Date: Mon, 13 Oct 2014 18:52:58 -0400
Message-ID: <CAM-S9zQ4036C6QgDy4rXBKYe-KiNQRrRDrNGvMcOdL1TMMu8iA@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Ilya Ganelin <ilganeli@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: user <user@spark.apache.org>, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a113602409cbc99050555c23f
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113602409cbc99050555c23f
Content-Type: text/plain; charset=UTF-8

Thank you for the details! Would you mind speaking to what tools proved
most useful as far as identifying bottlenecks or bugs? Thanks again.
On Oct 13, 2014 5:36 PM, "Matei Zaharia" <matei.zaharia@gmail.com> wrote:

> The biggest scaling issue was supporting a large number of reduce tasks
> efficiently, which the JIRAs in that post handle. In particular, our
> current default shuffle (the hash-based one) has each map task open a
> separate file output stream for each reduce task, which wastes a lot of
> memory (since each stream has its own buffer).
>
> A second thing that helped efficiency tremendously was Reynold's new
> network module (https://issues.apache.org/jira/browse/SPARK-2468). Doing
> I/O on 32 cores, 10 Gbps Ethernet and 8+ disks efficiently is not easy, as
> can be seen when you try to scale up other software.
>
> Finally, with 30,000 tasks even sending info about every map's output size
> to each reducer was a problem, so Reynold has a patch that avoids that if
> the number of tasks is large.
>
> Matei
>
> On Oct 10, 2014, at 10:09 PM, Ilya Ganelin <ilganeli@gmail.com> wrote:
>
> > Hi Matei - I read your post with great interest. Could you possibly
> comment in more depth on some of the issues you guys saw when scaling up
> spark and how you resolved them? I am interested specifically in
> spark-related problems. I'm working on scaling up spark to very large
> datasets and have been running into a variety of issues. Thanks in advance!
> >
> > On Oct 10, 2014 10:54 AM, "Matei Zaharia" <matei.zaharia@gmail.com>
> wrote:
> > Hi folks,
> >
> > I interrupt your regularly scheduled user / dev list to bring you some
> pretty cool news for the project, which is that we've been able to use
> Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x
> faster on 10x fewer nodes. There's a detailed writeup at
> http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-record.html.
> Summary: while Hadoop MapReduce held last year's 100 TB world record by
> sorting 100 TB in 72 minutes on 2100 nodes, we sorted it in 23 minutes on
> 206 nodes; and we also scaled up to sort 1 PB in 234 minutes.
> >
> > I want to thank Reynold Xin for leading this effort over the past few
> weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali
> Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for
> providing the machines to make this possible. Finally, this result would of
> course not be possible without the many many other contributions, testing
> and feature requests from throughout the community.
> >
> > For an engine to scale from these multi-hour petabyte batch jobs down to
> 100-millisecond streaming and interactive queries is quite uncommon, and
> it's thanks to all of you folks that we are able to make this happen.
> >
> > Matei
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> > For additional commands, e-mail: user-help@spark.apache.org
> >
>
>

--001a113602409cbc99050555c23f--

From dev-return-9813-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 13 23:21:45 2014
Return-Path: <dev-return-9813-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9B5A417D26
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 13 Oct 2014 23:21:45 +0000 (UTC)
Received: (qmail 99123 invoked by uid 500); 13 Oct 2014 23:21:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99005 invoked by uid 500); 13 Oct 2014 23:21:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98086 invoked by uid 99); 13 Oct 2014 23:21:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 23:21:42 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ksankar42@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 13 Oct 2014 23:21:17 +0000
Received: by mail-pa0-f51.google.com with SMTP id lj1so6645876pab.38
        for <multiple recipients>; Mon, 13 Oct 2014 16:21:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Wy3OYR2ygtvbB1/CWyPJ1KiwLdrEC2p35EEuNrvUsJQ=;
        b=MD753PQVG0eIFFeo8tiojWLSheCdy5/rFBkGexbLv1Nf+qA6Kc6DA6dbUpDdxhmXtW
         dXG+okJrk/VoH7bgeA5cfVutlYNz9AxN8h3LqBOgxGFchXowKYDzXYPn7hKmNDsHF3+A
         IlxX16N3YUqYe/oKqEkvfg9urYu169e9UMzuqAQ7LrJQGsagTcM7B91jVIY4sE40yCCK
         EzFpvlYsMkwuLIeysD9qVZuCI6q2x2w7SdIVMGsxOvzy6eOTgMZ/yEKnCJF2OnAXagQt
         fQ/903IBDbI6H6iTPOvunsE3V4f0ZMqID9Q/y8iK3YbBFRrnpeKHv7fC4kyJF78uFRyP
         yivA==
MIME-Version: 1.0
X-Received: by 10.68.135.33 with SMTP id pp1mr1486936pbb.120.1413242475455;
 Mon, 13 Oct 2014 16:21:15 -0700 (PDT)
Received: by 10.70.30.1 with HTTP; Mon, 13 Oct 2014 16:21:15 -0700 (PDT)
In-Reply-To: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
References: <2FF6599B-D208-4903-8A87-C780EC6962BD@gmail.com>
Date: Mon, 13 Oct 2014 16:21:15 -0700
Message-ID: <CAOTBr2mw7Z_hoNPVi3a-_-FEJjRwh_P4VT5dO+ncSJJX3biZhQ@mail.gmail.com>
Subject: Re: Breaking the previous large-scale sort record with Spark
From: Krishna Sankar <ksankar42@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: user <user@spark.apache.org>, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=e89a8f234b71bb29c40505562746
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f234b71bb29c40505562746
Content-Type: text/plain; charset=UTF-8

Well done guys. MapReduce sort at that time was a good feat and Spark now
has raised the bar with the ability to sort a PB.
Like some of the folks in the list, a summary of what worked (and didn't)
as well as the monitoring practices would be good.
Cheers
<k/>
P.S: What are you folks planning next ?

On Fri, Oct 10, 2014 at 7:54 AM, Matei Zaharia <matei.zaharia@gmail.com>
wrote:

> Hi folks,
>
> I interrupt your regularly scheduled user / dev list to bring you some
> pretty cool news for the project, which is that we've been able to use
> Spark to break MapReduce's 100 TB and 1 PB sort records, sorting data 3x
> faster on 10x fewer nodes. There's a detailed writeup at
> http://databricks.com/blog/2014/10/10/spark-breaks-previous-large-scale-sort-record.html.
> Summary: while Hadoop MapReduce held last year's 100 TB world record by
> sorting 100 TB in 72 minutes on 2100 nodes, we sorted it in 23 minutes on
> 206 nodes; and we also scaled up to sort 1 PB in 234 minutes.
>
> I want to thank Reynold Xin for leading this effort over the past few
> weeks, along with Parviz Deyhim, Xiangrui Meng, Aaron Davidson and Ali
> Ghodsi. In addition, we'd really like to thank Amazon's EC2 team for
> providing the machines to make this possible. Finally, this result would of
> course not be possible without the many many other contributions, testing
> and feature requests from throughout the community.
>
> For an engine to scale from these multi-hour petabyte batch jobs down to
> 100-millisecond streaming and interactive queries is quite uncommon, and
> it's thanks to all of you folks that we are able to make this happen.
>
> Matei
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
>

--e89a8f234b71bb29c40505562746--

From dev-return-9814-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 14 05:53:59 2014
Return-Path: <dev-return-9814-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7C5E717804
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 14 Oct 2014 05:53:59 +0000 (UTC)
Received: (qmail 328 invoked by uid 500); 14 Oct 2014 05:53:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 275 invoked by uid 500); 14 Oct 2014 05:53:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99784 invoked by uid 99); 14 Oct 2014 05:53:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 14 Oct 2014 05:53:12 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of manish9ue@gmail.com designates 209.85.215.47 as permitted sender)
Received: from [209.85.215.47] (HELO mail-la0-f47.google.com) (209.85.215.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 14 Oct 2014 05:52:31 +0000
Received: by mail-la0-f47.google.com with SMTP id pv20so7741025lab.6
        for <dev@spark.apache.org>; Mon, 13 Oct 2014 22:52:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=agqTWKAZhgukF2ZHbbrPkcK1Gb0kYGz6sSHerfu69FE=;
        b=Tb7wCszCHZmAQ+JDYmFDSlO3RsRTDH5ncLLsmkmgou+zUnvyD8E/Vn0VYpXY63dES9
         X+sDhmbJSdmiJBHhRI1XYcDOlBwrFCuGvAy6QqvRaNKEPqnZ9R8cwjEodcF8CmN2139K
         JCSVAmFg+N8TMbIt/bjt82YfG9f0mHouOpp/My3QX3I8KmGFZfpU65cgGEKVISVveipy
         cMhAk1qZjwkHOYRZXCz0kWSXjYpLCpfHJGzTjOItqb124qT55tkaeYBbfCgqaHv+MJAN
         sn1OD0d7mMOJ1nXuhmVkFyyxtvgKv4QSuMvWOqLxC3380RJW16+sN20FjAc0aE4M8rzJ
         oPNg==
MIME-Version: 1.0
X-Received: by 10.152.116.50 with SMTP id jt18mr879179lab.86.1413265950662;
 Mon, 13 Oct 2014 22:52:30 -0700 (PDT)
Received: by 10.25.205.132 with HTTP; Mon, 13 Oct 2014 22:52:30 -0700 (PDT)
In-Reply-To: <CAF7ADNqp3mf5wNkUqibTHc8d61FY6_4ax63VJwMzU0c4netgQg@mail.gmail.com>
References: <CAMAsSdJTdKDFN8pJ_YeZ9j_oywkHU0DtHC1QMR6AQ2=Ay9+oYQ@mail.gmail.com>
	<0AA6CFCF-B93C-4CD2-B5B1-881A727780F0@gmail.com>
	<CAMAsSdK50QTOLV5_j4A_Bi337Deq1q7F4Aqf5y+ivDwS=19Efg@mail.gmail.com>
	<CAMAsSdJhANFcnEaLpL-dLjRvxXEbyhqOjKhFWDt80+8J_SKNrg@mail.gmail.com>
	<CAF7ADNokG6RKBXhyBs4-yXs2gysAvWvzkwcr9rJ1F3GBK63VrQ@mail.gmail.com>
	<CAMAsSdJzZE-zH+cGm9Lz9TJZ7kSWU4X6zcXZCSE1On00voDFcQ@mail.gmail.com>
	<CAF7ADNqp3mf5wNkUqibTHc8d61FY6_4ax63VJwMzU0c4netgQg@mail.gmail.com>
Date: Mon, 13 Oct 2014 22:52:30 -0700
Message-ID: <CAF4jm1Bs-UDmk2nTFFYDL7e+Q3kJAWxiAQJx4GAP=wZ1KHK8xg@mail.gmail.com>
Subject: Re: Decision forests don't work with non-trivial categorical features
From: Manish Amde <manish9ue@gmail.com>
To: Joseph Bradley <joseph@databricks.com>
Cc: Sean Owen <sowen@cloudera.com>, Evan Sparks <evan.sparks@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c363ecf6674405055b9e64
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c363ecf6674405055b9e64
Content-Type: text/plain; charset=UTF-8

Sean, sorry for missing out on the discussion.

Evan, you are correct, we are using the heuristic Sean suggested during the
multiclass PR for ordering high-arity categorical variables using the
impurity values for each categorical feature.

Joseph, thanks for fixing the bug which I think was a regression since we
added support for RFs. I don't think we have see this in 1.1.

-Manish

On Mon, Oct 13, 2014 at 11:55 AM, Joseph Bradley <joseph@databricks.com>
wrote:

> I think this is the fix:
>
> In this
> file:
> mllib/src/main/scala/org/apache/spark/mllib/tree/impl/DTStatsAggregator.scala
>
> methods "getFeatureOffset" and "getLeftRightFeatureOffsets" have sanity
> checks ("require") which are correct for DecisionTree but not for
> RandomForest.  You can remove those.  I've sent a PR with this and a few
> other small fixes:
>
> https://github.com/apache/spark/pull/2785
>
> I hope this fixes the bug!
>
> On Mon, Oct 13, 2014 at 11:19 AM, Sean Owen <sowen@cloudera.com> wrote:
>
> > Great, we'll confer then. I'm using master / 1.2.0-SNAPSHOT. I'll send
> > some details directly under separate cover.
> >
> > On Mon, Oct 13, 2014 at 7:12 PM, Joseph Bradley <joseph@databricks.com>
> > wrote:
> > > Hi Sean,
> > >
> > > Sorry I didn't see this thread earlier!  (Thanks Ameet for pinging me.)
> > >
> > > Short version: That exception should not be thrown, so there is a bug
> > > somewhere.  The intended logic for handling high-arity categorical
> > features
> > > is about the best one can do, as far as I know.
> > >
> > > Bug finding: For my checking purposes, which branch of Spark are you
> > using,
> > > and do you have the options being submitted to DecisionTree?
> > >
> > > High-arity categorical features: As you have figured out, if you use a
> > > categorical feature with just a few categories, it is treated as
> > "unordered"
> > > so that we explicitly consider all exponentially many ways to split the
> > > categories into 2 groups.  If you use one with many categories, then it
> > is
> > > necessary to impose an order.  (The communication increases linearly in
> > the
> > > number of possible splits, so it would blow up if we considered all
> > > exponentially many splits.)  This order is chosen separately for each
> > node,
> > > so it is not a uniform order imposed over the entire tree.  This
> actually
> > > means that it is not a heuristic for regression and binary
> > classification;
> > > i.e., it chooses the same split as if we had explicitly considered all
> of
> > > the possible splits.  For multiclass classification, it is a heuristic,
> > but
> > > I don't know of a better solution.
> > >
> > > I'll check the code, but if you can forward info about the bug, that
> > would
> > > be very helpful.
> > >
> > > Thanks!
> > > Joseph
> > >
> >
>

--001a11c363ecf6674405055b9e64--

From dev-return-9815-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 14 11:34:15 2014
Return-Path: <dev-return-9815-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1C384171E2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 14 Oct 2014 11:34:15 +0000 (UTC)
Received: (qmail 7518 invoked by uid 500); 14 Oct 2014 11:34:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7410 invoked by uid 500); 14 Oct 2014 11:34:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6374 invoked by uid 99); 14 Oct 2014 11:34:13 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 14 Oct 2014 11:34:13 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of learnings.chitturi@gmail.com designates 209.85.216.172 as permitted sender)
Received: from [209.85.216.172] (HELO mail-qc0-f172.google.com) (209.85.216.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 14 Oct 2014 11:34:07 +0000
Received: by mail-qc0-f172.google.com with SMTP id o8so6522440qcw.31
        for <multiple recipients>; Tue, 14 Oct 2014 04:33:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=j6ITEZtu8erhOcZb/jzFeyyb3W8iLhhNyhtjtKN2dFY=;
        b=KPQAcZpJ+mEGgxK6F+liEJ9Gf+YLsd124A6Nkz/uB0+0puzp5CfpZ1iPtPAZIS9by7
         0sXfmgi+gCu8rLAd+Oa6+/2B8JMmxKI/YlWl524JjE/zW6xq0EfEOwYuuoVX/9eoCXXa
         QhFbK0Oq3P+3gleAbiUU9GOcXqOwmWdpYTcW/8w8SPEkEMB8CPvOlkIUZD/ZA1XPdufX
         yUlCUeVAJZ/HFT0Tg1TNg8ff8ZTR9tq3RzimgL4DdRANDrouw/OtH9XLLsGq9ZqZDe/b
         adOftDhznWVSjcocZG3B4LYXgsf378P/o2aAFKDOFozGMHuoR1Snz5D/TbIAzT9npoPb
         YWuA==
MIME-Version: 1.0
X-Received: by 10.140.19.107 with SMTP id 98mr7169453qgg.37.1413286426962;
 Tue, 14 Oct 2014 04:33:46 -0700 (PDT)
Received: by 10.229.133.142 with HTTP; Tue, 14 Oct 2014 04:33:46 -0700 (PDT)
Date: Tue, 14 Oct 2014 17:03:46 +0530
Message-ID: <CABXsDPqPWdH8Oejs_+Tf4bzv3eDc5AEVKMtF82vmLsqTDDwCFw@mail.gmail.com>
Subject: Default spark.deploy.recoveryMode
From: Priya Ch <learnings.chitturi@gmail.com>
To: user@spark.apache.org, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11354e4e71efdf05056063a4
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11354e4e71efdf05056063a4
Content-Type: text/plain; charset=UTF-8

Hi Spark users/experts,

In Spark source code  (Master.scala & Worker.scala), when  registering the
worker with master, I see the usage of *persistenceEngine*. When we don't
specify spark.deploy.recovery mode explicitly, what is the default value
used ? This recovery mode is used to persists and restore the application &
worker details.

 I see when recovery mode not specified explicitly,
*BlackHolePersistenceEngine* being used. Am i right ?


Thanks,
Padma Ch

--001a11354e4e71efdf05056063a4--

From dev-return-9816-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 00:21:48 2014
Return-Path: <dev-return-9816-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C277917ECF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 00:21:48 +0000 (UTC)
Received: (qmail 82897 invoked by uid 500); 15 Oct 2014 00:21:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82813 invoked by uid 500); 15 Oct 2014 00:21:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82773 invoked by uid 99); 15 Oct 2014 00:21:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 00:21:47 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of jbeynon@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 00:21:22 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <jbeynon@gmail.com>)
	id 1XeCLB-0004V4-0h
	for dev@spark.incubator.apache.org; Tue, 14 Oct 2014 17:21:21 -0700
Date: Tue, 14 Oct 2014 17:21:21 -0700 (PDT)
From: Joseph Beynon <jbeynon@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1413332480984-8790.post@n3.nabble.com>
Subject: avro-mapred hadoop2 not in assembly jar
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

When building off of master it looks like the wrong version of the jar is
added to the assembly jar. The fix for SPARK-3039 added the "hadoop2"
classifier at compile time when using the hadoop2 profile, but in the
assembly stage I get:
    "[INFO] Including org.apache.avro:avro-mapred:jar:1.7.6 in the shaded
jar."
It's not clear if there are other dependencies that have classifiers being
added to the assembly. But when running with the current version I end up
with a common exception about TaskAttemptContext. After manually unjar-ing
the assembly and replacing the correct version of avro-mapred it works
correctly.
If I knew more about maven I'd try to help out with a PR to fix this.




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/avro-mapred-hadoop2-not-in-assembly-jar-tp8790.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9817-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 01:17:43 2014
Return-Path: <dev-return-9817-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9D8CF1722C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 01:17:43 +0000 (UTC)
Received: (qmail 85131 invoked by uid 500); 15 Oct 2014 01:17:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85065 invoked by uid 500); 15 Oct 2014 01:17:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85045 invoked by uid 99); 15 Oct 2014 01:17:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 01:17:42 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,HTML_OBFUSCATE_05_10,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matthew.c.cheah@gmail.com designates 209.85.223.172 as permitted sender)
Received: from [209.85.223.172] (HELO mail-ie0-f172.google.com) (209.85.223.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 01:17:15 +0000
Received: by mail-ie0-f172.google.com with SMTP id rl12so262285iec.17
        for <dev@spark.apache.org>; Tue, 14 Oct 2014 18:17:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=ZTYAgoxtv68aj4JdaUrHdNuVcR5bdh13/TIWxTvtv0g=;
        b=KX9Nuje+cjgLVpDX9DyX8Oa4YxErytIzidkJN3pxBDYM+5hsfRZqAKykCytYgXmrDy
         R8IsLgVxP0bYnQJc+Wfaj97ISuaqmefgq2jL3PvsOxi4eWja7XzlgudpQYIi/3OAH+zb
         PXPGiaau/KRzXUQ0VxTF2RReDOuhI/yy3rZw/aEbBxGy4vRq7UaOQ3QvIUyR7xBYYOnC
         DjqDFyaHMH3/HyhtiY8LdGKLsFcsXZz7AYgVRQPwFCsPMEki9AX0tO/RpuEilsdni7a4
         B3cQWaGfCQUzp7uT6o1c2+ak0bDlVTSgMfMevpx3ermgelUfQQ6G3LThM5BzU+J9vEEG
         L1ew==
MIME-Version: 1.0
X-Received: by 10.42.142.201 with SMTP id t9mr51928icu.60.1413335834488; Tue,
 14 Oct 2014 18:17:14 -0700 (PDT)
Received: by 10.64.23.39 with HTTP; Tue, 14 Oct 2014 18:17:14 -0700 (PDT)
Date: Tue, 14 Oct 2014 18:17:14 -0700
Message-ID: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
Subject: Unit testing Master-Worker Message Passing
From: Matthew Cheah <matthew.c.cheah@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=90e6ba6e84ca5cf4ff05056be401
X-Virus-Checked: Checked by ClamAV on apache.org

--90e6ba6e84ca5cf4ff05056be401
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi everyone,

I=E2=80=99m adding some new message passing between the Master and Worker a=
ctors in
order to address https://issues.apache.org/jira/browse/SPARK-3736 .

I was wondering if these kinds of interactions are tested in the automated
Jenkins test suite, and if so, where I could find some examples to help me
do the same.

Thanks!

-Matt Cheah

--90e6ba6e84ca5cf4ff05056be401--

From dev-return-9818-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 01:25:35 2014
Return-Path: <dev-return-9818-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B770217256
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 01:25:35 +0000 (UTC)
Received: (qmail 97167 invoked by uid 500); 15 Oct 2014 01:25:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97104 invoked by uid 500); 15 Oct 2014 01:25:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97091 invoked by uid 99); 15 Oct 2014 01:25:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 01:25:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.182 as permitted sender)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 01:25:28 +0000
Received: by mail-ie0-f182.google.com with SMTP id rp18so265926iec.27
        for <dev@spark.apache.org>; Tue, 14 Oct 2014 18:25:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=snGy8vmN4VB86A97WCRVGkJptDAWyKdVLRxuUI98Zd4=;
        b=qoWMP3sCZAid0VHgjITjQhjs6RP6LsrveMMhwvPV6CCI4cE5lv9HHUVPx1lwS0C7LC
         ogcO3vMu1g7EIx+CXFemUJ9t3qbQSqwpaImsFkhUXJ2eNg1IQoydtlUU68bDJ5CfC740
         pxUE4Acif0T8qVcK6500KCl1ryCEccYqq0S28iyWOobBdZSVSPYES6w9uLDZbNmgzmeg
         9t66X+b2mLCzCFaUUp5PIDLOMJdaT27S3t7cGI1fAuyOmJB5lQ059fPWuzNZunheJXZP
         v6p6Y5tv8nAJBIkT9y4zBNWK+ebmAM+BAI/W6g5D3Z/U5KdMO9qIrtQNrs76j1znGjsg
         X+HQ==
X-Received: by 10.107.40.136 with SMTP id o130mr6276210ioo.26.1413336307891;
        Tue, 14 Oct 2014 18:25:07 -0700 (PDT)
Received: from [192.168.2.12] (bas3-montreal42-1167938673.dsl.bell.ca. [69.157.84.113])
        by mx.google.com with ESMTPSA id f41sm1147489ioj.8.2014.10.14.18.25.07
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 14 Oct 2014 18:25:07 -0700 (PDT)
Date: Tue, 14 Oct 2014 21:40:45 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Matthew Cheah <matthew.c.cheah@gmail.com>
Cc: dev@spark.apache.org
Message-ID: <BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
In-Reply-To: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="543dd09d_e3e47a8_1fc"
X-Virus-Checked: Checked by ClamAV on apache.org

--543dd09d_e3e47a8_1fc
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

You can use akka testkit

Example:

https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c2673e=
41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcherSuit=
e.scala =20

-- =20
Nan Zhu


On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote:

> Hi everyone,
> =20
> I=E2=80=99m adding some new message passing between the Master and Work=
er actors in
> order to address https://issues.apache.org/jira/browse/SPARK-3736 .
> =20
> I was wondering if these kinds of interactions are tested in the automa=
ted
> Jenkins test suite, and if so, where I could find some examples to help=
 me
> do the same.
> =20
> Thanks=21
> =20
> -Matt Cheah =20


--543dd09d_e3e47a8_1fc--


From dev-return-9819-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 14:05:59 2014
Return-Path: <dev-return-9819-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0AE4410653
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 14:05:59 +0000 (UTC)
Received: (qmail 67274 invoked by uid 500); 15 Oct 2014 14:05:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67199 invoked by uid 500); 15 Oct 2014 14:05:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67187 invoked by uid 99); 15 Oct 2014 14:05:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 14:05:57 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of yuu.ishikawa+spark@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 14:05:53 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <yuu.ishikawa+spark@gmail.com>)
	id 1XePCn-00075L-E6
	for dev@spark.incubator.apache.org; Wed, 15 Oct 2014 07:05:33 -0700
Date: Wed, 15 Oct 2014 07:05:33 -0700 (PDT)
From: Yu Ishikawa <yuu.ishikawa+spark@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1413381933383-8793.post@n3.nabble.com>
Subject: [mllib] Share the simple benchmark result about the cast cost from
 Spark vector to Breeze vector
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

I wondered the cast cost from Spark Vectors to Breeze vector is high or low. 
So I benchmarked the simple operation about addition, multiplication and 
division of RDD[Vector] or RDD[BV[Double]]. I share the simple benchmark
result with you.

In conclusion, the cast cost was lower than I had expected. 
For more information, please read the below report, if you are interested in
it.
https://github.com/yu-iskw/benchmark-breeze-on-spark/blob/master/doc%2Fbenchmark-result.md

Best,
Yu Ishikawa



-----
-- Yu Ishikawa
--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/mllib-Share-the-simple-benchmark-result-about-the-cast-cost-from-Spark-vector-to-Breeze-vector-tp8793.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9820-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 18:04:32 2014
Return-Path: <dev-return-9820-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EA61717305
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 18:04:31 +0000 (UTC)
Received: (qmail 59993 invoked by uid 500); 15 Oct 2014 18:04:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 59909 invoked by uid 500); 15 Oct 2014 18:04:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 59897 invoked by uid 99); 15 Oct 2014 18:04:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 18:04:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matthew.c.cheah@gmail.com designates 209.85.223.181 as permitted sender)
Received: from [209.85.223.181] (HELO mail-ie0-f181.google.com) (209.85.223.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 18:04:05 +0000
Received: by mail-ie0-f181.google.com with SMTP id at20so1753816iec.40
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 11:04:03 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Wu243inxCMQHcaVtQOkEYmwTR0TxBtWut3OeravRTgU=;
        b=Lfg0u/EIGlLxxy50jZNd+7FkNumrvy3T+4CjtaG2X0Zxq+At1cfR8HDQTT7JLVJzTc
         tCHsu+nY18caypgkqsXsygw5bA8JSGzwyJ9TOZCUv7Jmz7+Y0ZDZuSQGAAI/vUNz/HhD
         9x62R8EKX6KqBBOo/mFvGOeutx1NqCTX7NtCKlTtsBlv1/xbOKwDEcHknnBULAQrFa/9
         TZ3oujBL9skavLiAbfDDTaiMfibhYoQmsC9aJfL3cU6dzFsnK//XBRpnP4/tK9DKjjZ2
         94Ckn62TS2vFDV6jQDlyh49oip79l4v4u/AuM4kqWSLAKoj/+FfWW9jlikorH7E8nTwJ
         zQnA==
MIME-Version: 1.0
X-Received: by 10.50.43.137 with SMTP id w9mr15845950igl.33.1413396243584;
 Wed, 15 Oct 2014 11:04:03 -0700 (PDT)
Received: by 10.64.23.39 with HTTP; Wed, 15 Oct 2014 11:04:03 -0700 (PDT)
In-Reply-To: <BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
	<BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
Date: Wed, 15 Oct 2014 11:04:03 -0700
Message-ID: <CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
From: Matthew Cheah <matthew.c.cheah@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=e89a8f8388f506c173050579f5a6
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f8388f506c173050579f5a6
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks, the example was helpful.

However, testing the Worker itself is a lot more complicated than
WorkerWatcher, since the Worker class is quite a bit more complex. Are
there any tests that inspect the Worker itself?

Thanks,

-Matt Cheah

On Tue, Oct 14, 2014 at 6:40 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

> You can use akka testkit
>
> Example:
>
>
> https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c2673e=
41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcherSuite.=
scala
>
> --
> Nan Zhu
>
> On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote:
>
> Hi everyone,
>
> I=E2=80=99m adding some new message passing between the Master and Worker=
 actors in
> order to address https://issues.apache.org/jira/browse/SPARK-3736 .
>
> I was wondering if these kinds of interactions are tested in the automate=
d
> Jenkins test suite, and if so, where I could find some examples to help m=
e
> do the same.
>
> Thanks!
>
> -Matt Cheah
>
>
>

--e89a8f8388f506c173050579f5a6--

From dev-return-9821-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 18:13:22 2014
Return-Path: <dev-return-9821-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7CDEB1738E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 18:13:22 +0000 (UTC)
Received: (qmail 83284 invoked by uid 500); 15 Oct 2014 18:13:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83215 invoked by uid 500); 15 Oct 2014 18:13:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83202 invoked by uid 99); 15 Oct 2014 18:13:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 18:13:19 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.213.174 as permitted sender)
Received: from [209.85.213.174] (HELO mail-ig0-f174.google.com) (209.85.213.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 18:12:52 +0000
Received: by mail-ig0-f174.google.com with SMTP id a13so17905854igq.13
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 11:12:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=EoosQFUJHdk9rOVtFgwbd0e8gioIony1pMlIEvEOMos=;
        b=hzhxzcUJW3LoHOLSat9iMWUlyuJm/5ZQn07QF3GqKZseJQ5OCDjCnskJYoINJeVEa7
         ikOGwKdhOWTVMfeNBcCObbRPqUyC6pvmMUfWqxHZDKBib408BgxOOA7KyR6OOu9uMWfS
         UufHcxB/TXXi3hoW8EoBTFXAlOgaSKl8p/GXa4azwOQJGeNhmPmtw7xd7HZKZ8wmzzLQ
         7whd7+mJabqQXj4413W6kuJaDpBUNIj3TgBLhGmIyr9nqLg90lx2ClXIy8LMxcYU31H6
         e3pHk1vuNpdP+acjUqlagRG6e3UfbTWGvbdPVd3JtYR7OIJl93eMzv9sQT7CcscOjAdm
         aO0w==
X-Received: by 10.50.4.35 with SMTP id h3mr15985019igh.37.1413396771215;
        Wed, 15 Oct 2014 11:12:51 -0700 (PDT)
Received: from [142.157.43.149] (wpa043149.Wireless.McGill.CA. [142.157.43.149])
        by mx.google.com with ESMTPSA id h8sm2100526ioh.35.2014.10.15.11.12.50
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Wed, 15 Oct 2014 11:12:50 -0700 (PDT)
Date: Wed, 15 Oct 2014 14:28:29 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Matthew Cheah <matthew.c.cheah@gmail.com>
Cc: dev@spark.apache.org
Message-ID: <8BDA8E51AD6244F0AB5B74ABAAD5B550@gmail.com>
In-Reply-To: <CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
 <BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
 <CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="543ebccd_661e3f1e_21e"
X-Virus-Checked: Checked by ClamAV on apache.org

--543ebccd_661e3f1e_21e
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I don=E2=80=99t think there are test cases for Worker itself =20


You can =20


val actorRef =3D TestActorRef=5BMaster=5D(Props(classOf=5BMaster=5D, ...)=
)(actorSystem) actorRef.underlyingActor.receive(Heartbeat)

and use expectMsg to test if Master can reply correct message  by assumin=
g Worker is absolutely correct

Then in another test case to test if Worker can send register message to =
Master after receiving Master=E2=80=99s =E2=80=9Cre-register=E2=80=9D ins=
truction, (in this test case assuming that the Master is absolutely right=
)

Best,

-- =20
Nan Zhu


On Wednesday, October 15, 2014 at 2:04 PM, Matthew Cheah wrote:

> Thanks, the example was helpful.
> =20
> However, testing the Worker itself is a lot more complicated than Worke=
rWatcher, since the Worker class is quite a bit more complex. Are there a=
ny tests that inspect the Worker itself=3F
> =20
> Thanks,
> =20
> -Matt Cheah
> =20
> On Tue, Oct 14, 2014 at 6:40 PM, Nan Zhu <zhunanmcgill=40gmail.com (mai=
lto:zhunanmcgill=40gmail.com)> wrote:
> > You can use akka testkit
> > =20
> > Example:
> > =20
> > https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c2=
673e41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcher=
Suite.scala =20
> > =20
> > -- =20
> > Nan Zhu
> > =20
> > =20
> > On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote:
> > =20
> > > Hi everyone,
> > > =20
> > > I=E2=80=99m adding some new message passing between the Master and =
Worker actors in
> > > order to address https://issues.apache.org/jira/browse/SPARK-3736 .=

> > > =20
> > > I was wondering if these kinds of interactions are tested in the au=
tomated
> > > Jenkins test suite, and if so, where I could find some examples to =
help me
> > > do the same.
> > > =20
> > > Thanks=21
> > > =20
> > > -Matt Cheah =20
> > =20
> =20


--543ebccd_661e3f1e_21e--


From dev-return-9822-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 20:38:34 2014
Return-Path: <dev-return-9822-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 751F2179A8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 20:38:34 +0000 (UTC)
Received: (qmail 86702 invoked by uid 500); 15 Oct 2014 20:38:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86648 invoked by uid 500); 15 Oct 2014 20:38:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86636 invoked by uid 99); 15 Oct 2014 20:38:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 20:38:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matthew.c.cheah@gmail.com designates 209.85.223.174 as permitted sender)
Received: from [209.85.223.174] (HELO mail-ie0-f174.google.com) (209.85.223.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 20:38:07 +0000
Received: by mail-ie0-f174.google.com with SMTP id tr6so2028354ieb.5
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 13:38:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=oyvv0hoi79E2qOJcGF//Hghncj2hsmZBg2spsJe4eDI=;
        b=YMrrvwaTHb95tJ2OkDqBFe+Xeq4R6C+bcA2j+8zdQJ9K+zxE7lR9tKsb7OjlRq73V/
         0X+6tXa8hfS6tLom5+YOg24pIClVQRp9OcHknbEq2DEmkSiqavd4pM6kfTLvuAqDgIeS
         oabNcfJO8WyDiu0f8gRce99WbsT46G7MGTVbgf4HQyxuzfeT0Q3AbN0fbQtmdCgWGPRB
         z0LqKpZauq395wcMKtPwyvUTxRYZALnJ4I0amg1dFEI2pJQA/Vl3h6muObM8jFSzEA+S
         7ifgl9g0P6YejKyGI6tlN2M2FqxcHWYWwVqYlseejpYB09Cfws7JNIQRcSPL5qdDwkve
         geDA==
MIME-Version: 1.0
X-Received: by 10.42.100.14 with SMTP id y14mr179927icn.64.1413405485786; Wed,
 15 Oct 2014 13:38:05 -0700 (PDT)
Received: by 10.64.23.39 with HTTP; Wed, 15 Oct 2014 13:38:05 -0700 (PDT)
In-Reply-To: <8BDA8E51AD6244F0AB5B74ABAAD5B550@gmail.com>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
	<BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
	<CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
	<8BDA8E51AD6244F0AB5B74ABAAD5B550@gmail.com>
Date: Wed, 15 Oct 2014 13:38:05 -0700
Message-ID: <CAHH8_OOBQ=U+CdMfXhmwk59QDyaex3xbD=pxw30h-miLvGCOoQ@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
From: Matthew Cheah <matthew.c.cheah@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=90e6ba6147b8e76cae05057c1b95
X-Virus-Checked: Checked by ClamAV on apache.org

--90e6ba6147b8e76cae05057c1b95
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

What's happening when I do this is that the Worker tries to get the Master
actor by calling context.actorSelection(), and the RegisterWorker message
gets sent to the dead letters mailbox instead of being picked up by
expectMsg. I'm new to Akka and I've tried various ways to registering a
"mock" master to no avail.

I would think there would be at least some kind of test for master - worker
message passing, no?

On Wed, Oct 15, 2014 at 11:28 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

> I don=E2=80=99t think there are test cases for Worker itself
>
>
> You can
>
>
> val actorRef =3D TestActorRef[Master](Props(classOf[Master], ...))(
> actorSystem) actorRef.underlyingActor.receive(Heartbeat)
>
> and use expectMsg to test if Master can reply correct message  by assumin=
g
> Worker is absolutely correct
>
> Then in another test case to test if Worker can send register message to
> Master after receiving Master=E2=80=99s =E2=80=9Cre-register=E2=80=9D ins=
truction, (in this test
> case assuming that the Master is absolutely right)
>
> Best,
>
> --
> Nan Zhu
>
> On Wednesday, October 15, 2014 at 2:04 PM, Matthew Cheah wrote:
>
> Thanks, the example was helpful.
>
> However, testing the Worker itself is a lot more complicated than
> WorkerWatcher, since the Worker class is quite a bit more complex. Are
> there any tests that inspect the Worker itself?
>
> Thanks,
>
> -Matt Cheah
>
> On Tue, Oct 14, 2014 at 6:40 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>
> You can use akka testkit
>
> Example:
>
>
> https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c2673e=
41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcherSuite.=
scala
>
> --
> Nan Zhu
>
> On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote:
>
> Hi everyone,
>
> I=E2=80=99m adding some new message passing between the Master and Worker=
 actors in
> order to address https://issues.apache.org/jira/browse/SPARK-3736 .
>
> I was wondering if these kinds of interactions are tested in the automate=
d
> Jenkins test suite, and if so, where I could find some examples to help m=
e
> do the same.
>
> Thanks!
>
> -Matt Cheah
>
>
>
>
>

--90e6ba6147b8e76cae05057c1b95--

From dev-return-9823-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 20:53:10 2014
Return-Path: <dev-return-9823-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 039B817A67
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 20:53:10 +0000 (UTC)
Received: (qmail 37670 invoked by uid 500); 15 Oct 2014 20:53:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 37601 invoked by uid 500); 15 Oct 2014 20:53:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 37588 invoked by uid 99); 15 Oct 2014 20:53:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 20:53:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 20:52:41 +0000
Received: by mail-lb0-f172.google.com with SMTP id b6so1738351lbj.31
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 13:52:40 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=PhmSyyn3zuDX89rAeu7wKDyQAXsYkOb6h9Zx9yuyFus=;
        b=mZlr27B5YKNZEL44YwddgDcQ3JXOacqXzKjNitVrEKfPDlMBgYr93JNJP/zgbA+tzr
         E+lnzcXulVcGSaQ6FOj4TWFsaZCzi0LZ306BVGDQ6NclWAXYGWThULVj4N3SN4+58L3t
         bJ3fLpEvArNiJEXJHoBX0Jvde+gaRvoXsSwuqMNpYPvefPlEWSsEqWG49RkGwCwNzVXn
         I9Px9sbJ3e98KHGDWHJC33UGVL/W1kVUFxBL+7r+cCBMTsLc7IkATcfH75I1C/gKON+d
         pznNWr28Y7t2Yl6Mk5pt8MgRw5uSjYJ8wrzpX13q9kd6NfIMrOtgf16M+mPdOLAliqmy
         iqfA==
X-Gm-Message-State: ALoCoQn2yj/+yKtkE7cm1xzFFoFIQxAeOhBSAXPkTlieN2BUSo7bLKNjQNLkcjHahXaUKpBw5y8V
X-Received: by 10.152.30.33 with SMTP id p1mr14764833lah.78.1413406360300;
 Wed, 15 Oct 2014 13:52:40 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Wed, 15 Oct 2014 13:52:20 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 15 Oct 2014 13:52:20 -0700
Message-ID: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
Subject: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160ad2a077bd205057c500b
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160ad2a077bd205057c500b
Content-Type: text/plain; charset=UTF-8

i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2) to see if
that helps w/the git fetch timeouts.

this will require a short downtime (~20 mins for builds to finish, ~20 mins
to downgrade), and will hopefully give us some insight in to wtf is going
on.

thanks for your patience...

shane

--089e0160ad2a077bd205057c500b--

From dev-return-9824-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 21:00:50 2014
Return-Path: <dev-return-9824-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B644517AAD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 21:00:50 +0000 (UTC)
Received: (qmail 55299 invoked by uid 500); 15 Oct 2014 21:00:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55222 invoked by uid 500); 15 Oct 2014 21:00:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55176 invoked by uid 99); 15 Oct 2014 21:00:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:00:44 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.176 as permitted sender)
Received: from [209.85.212.176] (HELO mail-wi0-f176.google.com) (209.85.212.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:00:19 +0000
Received: by mail-wi0-f176.google.com with SMTP id hi2so14052563wib.15
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 14:00:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=IBs4EcAXviIJWMMlkTKqs3zeZCQRj57mc4ri+QzBkVo=;
        b=oDA1JqJVz/Py1Uh7zTGOe80tR/QXY0I3WHcRVcwoWJ3lIDzrlPH1zBBN9+vmSX2yWY
         yY9qdGFq4HRsGK2p7UzKtvQOJV10sJF7zdammQuGv6hYTSArfELTLl7PuKmJhIn1qU/M
         cndPVknJ6F+vCHVCw2DJsdD2VRIP6v58xRRGB30RN4oExw5xHRDAkfbq/d3x5m2bf8P7
         pGgrCAXYVrYVf+/bnvR34wEP+AXz08syPBFIMezGmkmzzuqgW0ev12gc5qLBIdA+llf7
         gt1qMQpULTnDNHjsld4GnJ6lYvz2m12Ey+PZyv7jLvqHUfKaVz25URVfhhSvkdl+WpjI
         682Q==
X-Received: by 10.194.92.12 with SMTP id ci12mr14871293wjb.6.1413406818684;
 Wed, 15 Oct 2014 14:00:18 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Wed, 15 Oct 2014 13:59:38 -0700 (PDT)
In-Reply-To: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 15 Oct 2014 16:59:38 -0400
Message-ID: <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bfd08ba59d71705057c6bbc
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfd08ba59d71705057c6bbc
Content-Type: text/plain; charset=UTF-8

I support this effort. :thumbsup:

On Wed, Oct 15, 2014 at 4:52 PM, shane knapp <sknapp@berkeley.edu> wrote:

> i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2) to see if
> that helps w/the git fetch timeouts.
>
> this will require a short downtime (~20 mins for builds to finish, ~20 mins
> to downgrade), and will hopefully give us some insight in to wtf is going
> on.
>
> thanks for your patience...
>
> shane
>

--047d7bfd08ba59d71705057c6bbc--

From dev-return-9825-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 21:18:30 2014
Return-Path: <dev-return-9825-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BC5BC17B68
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 21:18:30 +0000 (UTC)
Received: (qmail 94262 invoked by uid 500); 15 Oct 2014 21:18:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 94192 invoked by uid 500); 15 Oct 2014 21:18:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 94180 invoked by uid 99); 15 Oct 2014 21:18:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:18:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of chester@alpinenow.com designates 209.85.215.43 as permitted sender)
Received: from [209.85.215.43] (HELO mail-la0-f43.google.com) (209.85.215.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:18:25 +0000
Received: by mail-la0-f43.google.com with SMTP id mc6so1852875lab.16
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 14:18:03 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=LdEN8PqddERFRfR30sULzSxFjuoYI1cus77Z7TzL1ps=;
        b=Bq+IkllmfKkDzznEGlLXNKA5vdy+OxmYrS+nhp2H126T2zHCUNr8iqxtVAHWSEma8Z
         I0O+uDcp2Q6JzHFQtjLYAHdT+fWKF9v5m0HaeUwOFsUyTrxJ5k5QeLQ87kt4LOG3d9UU
         KZYj/ZxvBDx/oNHoZqfXdyllsvr1F/pMg/BJfy2NIp3opCOVUdURsxJItQ1yHyq0uOPN
         hsbNjbQQ65C0dMv2PV/hkhisebncElkLiMyC0sHqpE3g89GA5uOir3/spmOW0COlweRj
         qU/G8AKp2hL+h9lwtFkVbqr77yp0B6AxvIKLhXeymcLfGREBtE44he1v3YlpCwSs/ew/
         Z1FA==
X-Gm-Message-State: ALoCoQmioc+mjbxm7v5Lg1QFxed4UxKbYcZ4JhsIs5A+ZDDTRjecDKci5YKvTgWDNLf9kN1tCToI
MIME-Version: 1.0
X-Received: by 10.112.73.35 with SMTP id i3mr15136494lbv.75.1413407883801;
 Wed, 15 Oct 2014 14:18:03 -0700 (PDT)
Received: by 10.25.217.143 with HTTP; Wed, 15 Oct 2014 14:18:03 -0700 (PDT)
In-Reply-To: <CAHH8_OOBQ=U+CdMfXhmwk59QDyaex3xbD=pxw30h-miLvGCOoQ@mail.gmail.com>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
	<BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
	<CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
	<8BDA8E51AD6244F0AB5B74ABAAD5B550@gmail.com>
	<CAHH8_OOBQ=U+CdMfXhmwk59QDyaex3xbD=pxw30h-miLvGCOoQ@mail.gmail.com>
Date: Wed, 15 Oct 2014 14:18:03 -0700
Message-ID: <CAPYnQ0XHg6LsqYEOqaJU0mjsyUKzpDzL_oY94YGVy4MwV1BgWw@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
From: Chester Chen <chester@alpinenow.com>
To: Matthew Cheah <matthew.c.cheah@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c340eed651cf05057caa30
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c340eed651cf05057caa30
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

You can call resolve method on ActorSelection.resolveOne() to see if the
actor is still there or the path is correct. The method returns a future
and you can wait for it with timeout. This way, you know the actor is live
or already dead or incorrect.

Another way, is to send Identify method to ActorSystem, if it returns with
correct identified message; then you can act on it, otherwise, ...

hope this helps

Chester

On Wed, Oct 15, 2014 at 1:38 PM, Matthew Cheah <matthew.c.cheah@gmail.com>
wrote:

> What's happening when I do this is that the Worker tries to get the Maste=
r
> actor by calling context.actorSelection(), and the RegisterWorker message
> gets sent to the dead letters mailbox instead of being picked up by
> expectMsg. I'm new to Akka and I've tried various ways to registering a
> "mock" master to no avail.
>
> I would think there would be at least some kind of test for master - work=
er
> message passing, no?
>
> On Wed, Oct 15, 2014 at 11:28 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>
> > I don=E2=80=99t think there are test cases for Worker itself
> >
> >
> > You can
> >
> >
> > val actorRef =3D TestActorRef[Master](Props(classOf[Master], ...))(
> > actorSystem) actorRef.underlyingActor.receive(Heartbeat)
> >
> > and use expectMsg to test if Master can reply correct message  by
> assuming
> > Worker is absolutely correct
> >
> > Then in another test case to test if Worker can send register message t=
o
> > Master after receiving Master=E2=80=99s =E2=80=9Cre-register=E2=80=9D i=
nstruction, (in this test
> > case assuming that the Master is absolutely right)
> >
> > Best,
> >
> > --
> > Nan Zhu
> >
> > On Wednesday, October 15, 2014 at 2:04 PM, Matthew Cheah wrote:
> >
> > Thanks, the example was helpful.
> >
> > However, testing the Worker itself is a lot more complicated than
> > WorkerWatcher, since the Worker class is quite a bit more complex. Are
> > there any tests that inspect the Worker itself?
> >
> > Thanks,
> >
> > -Matt Cheah
> >
> > On Tue, Oct 14, 2014 at 6:40 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote=
:
> >
> > You can use akka testkit
> >
> > Example:
> >
> >
> >
> https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c2673e=
41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcherSuite.=
scala
> >
> > --
> > Nan Zhu
> >
> > On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote:
> >
> > Hi everyone,
> >
> > I=E2=80=99m adding some new message passing between the Master and Work=
er actors
> in
> > order to address https://issues.apache.org/jira/browse/SPARK-3736 .
> >
> > I was wondering if these kinds of interactions are tested in the
> automated
> > Jenkins test suite, and if so, where I could find some examples to help
> me
> > do the same.
> >
> > Thanks!
> >
> > -Matt Cheah
> >
> >
> >
> >
> >
>

--001a11c340eed651cf05057caa30--

From dev-return-9826-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 21:20:31 2014
Return-Path: <dev-return-9826-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6228817B79
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 21:20:31 +0000 (UTC)
Received: (qmail 97636 invoked by uid 500); 15 Oct 2014 21:20:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97570 invoked by uid 500); 15 Oct 2014 21:20:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97558 invoked by uid 99); 15 Oct 2014 21:20:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:20:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.170 as permitted sender)
Received: from [209.85.217.170] (HELO mail-lb0-f170.google.com) (209.85.217.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:20:05 +0000
Received: by mail-lb0-f170.google.com with SMTP id u10so1795793lbd.1
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 14:20:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=7q3oEYMAr8o0tS3SIsL2Vj7EGqxwqVvqhic+iWW0Oww=;
        b=Fhu935Ck/h5EMHALcP6OBmCud4fqGCKTMjz54sLhSYS+NV2w9XFFWH5XOlAoVNGh/n
         7+3FNYgwXdLLORFo/NJpo0Iw3fW5WhXDOVFFcypHgYlFULjAODtzuDc84DTWrkD/Q1QV
         7q6rLT61bEishG4yEMwV+s78dmEcW1QeSKphfXQBQ+URZ5ZmKr0MD0m7r5u5zxDRYlcv
         Iyqn828VMm00PBr1GJDvHBXYxg8nbDsYEnCTonpAd2326wUZwDPIP1CIQtcd0RNpib8l
         zuWhBgx34dYKm8Tap3jFcK7NszZpcSH5v7aVkoIgI7rr56PXSGYTKJKunpfv1wLMRpu6
         fddA==
X-Gm-Message-State: ALoCoQnxggLqIe9ZltHKyf98AXfmRlFKxBoLm2ASYm1M4OUoTedjc6PvOPWmiwTuMfarwZh9dxj9
X-Received: by 10.112.28.75 with SMTP id z11mr14867507lbg.49.1413408004083;
 Wed, 15 Oct 2014 14:20:04 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Wed, 15 Oct 2014 14:19:43 -0700 (PDT)
In-Reply-To: <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 15 Oct 2014 14:19:43 -0700
Message-ID: <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: amp-infra <amp-infra@googlegroups.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133eca601a21f05057cb21b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133eca601a21f05057cb21b
Content-Type: text/plain; charset=UTF-8

ok, we're up and building...  :crossesfingersfortheumpteenthtime:

On Wed, Oct 15, 2014 at 1:59 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> I support this effort. :thumbsup:
>
> On Wed, Oct 15, 2014 at 4:52 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2) to see if
>> that helps w/the git fetch timeouts.
>>
>> this will require a short downtime (~20 mins for builds to finish, ~20
>> mins
>> to downgrade), and will hopefully give us some insight in to wtf is going
>> on.
>>
>> thanks for your patience...
>>
>> shane
>>
>
>  --
> You received this message because you are subscribed to the Google Groups
> "amp-infra" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to amp-infra+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/d/optout.
>

--001a1133eca601a21f05057cb21b--

From dev-return-9827-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 21:28:36 2014
Return-Path: <dev-return-9827-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5944E17BD5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 21:28:36 +0000 (UTC)
Received: (qmail 18186 invoked by uid 500); 15 Oct 2014 21:28:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18114 invoked by uid 500); 15 Oct 2014 21:28:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18103 invoked by uid 99); 15 Oct 2014 21:28:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:28:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:28:31 +0000
Received: by mail-lb0-f172.google.com with SMTP id b6so1782356lbj.31
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 14:28:09 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=VFq0o3iovyYZAISUVXZR7wp3FXQTBLFf/bATDz6sgWA=;
        b=HmrtgIhx2yR90Ueiwh3G8eT0wWHGHUnRpSwv9pnchJMbqGiuNYQbc3hLknHrFugeS4
         m0kprfCqlVfzOmLsfzOs6orU1CxUYRTqOGzMEoDGv0soranJkFtj9RaLkSyqW7H0pa6C
         vnUh8AEgY9eNn3fIn3rkDHCjTAoMv7zdQa2uH4z39kZt9MmEQnf0+3pLD2SWSTzs2DM8
         aDAjnJmxw9m48MI8B838i2mlZjEbVeDg/xQVRTL5UfFIjEIu6lKVnDeF8i3NLMpjqOPz
         otznm/os4edFqTPg0lWOqC+hPzsVMaeE9P3CMIZbE9dK/LPcQqHSXjtXnF3ZQ+Z5DKub
         rm0A==
X-Gm-Message-State: ALoCoQmppFWhqw1tfZFflHMcaecjINXJhKdTWpU7I/2nQmMxfeprhW0Xwc5sEoLEitbhnwQOu0Ik
X-Received: by 10.152.22.194 with SMTP id g2mr15123328laf.33.1413408489046;
 Wed, 15 Oct 2014 14:28:09 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Wed, 15 Oct 2014 14:27:48 -0700 (PDT)
In-Reply-To: <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com> <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 15 Oct 2014 14:27:48 -0700
Message-ID: <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: amp-infra <amp-infra@googlegroups.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158b61ce993e805057cce5f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158b61ce993e805057cce5f
Content-Type: text/plain; charset=UTF-8

four builds triggered....  and no timeouts.  :crossestoes:  :)

On Wed, Oct 15, 2014 at 2:19 PM, shane knapp <sknapp@berkeley.edu> wrote:

> ok, we're up and building...  :crossesfingersfortheumpteenthtime:
>
> On Wed, Oct 15, 2014 at 1:59 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> I support this effort. :thumbsup:
>>
>> On Wed, Oct 15, 2014 at 4:52 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>>> i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2) to see
>>> if
>>> that helps w/the git fetch timeouts.
>>>
>>> this will require a short downtime (~20 mins for builds to finish, ~20
>>> mins
>>> to downgrade), and will hopefully give us some insight in to wtf is going
>>> on.
>>>
>>> thanks for your patience...
>>>
>>> shane
>>>
>>
>>  --
>> You received this message because you are subscribed to the Google Groups
>> "amp-infra" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to amp-infra+unsubscribe@googlegroups.com.
>> For more options, visit https://groups.google.com/d/optout.
>>
>
>

--089e0158b61ce993e805057cce5f--

From dev-return-9828-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 21:39:23 2014
Return-Path: <dev-return-9828-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 103D117C56
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 21:39:23 +0000 (UTC)
Received: (qmail 43943 invoked by uid 500); 15 Oct 2014 21:39:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43870 invoked by uid 500); 15 Oct 2014 21:39:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43858 invoked by uid 99); 15 Oct 2014 21:39:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:39:21 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matthew.c.cheah@gmail.com designates 209.85.213.180 as permitted sender)
Received: from [209.85.213.180] (HELO mail-ig0-f180.google.com) (209.85.213.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:38:55 +0000
Received: by mail-ig0-f180.google.com with SMTP id uq10so2299240igb.7
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 14:38:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Fgt+4ybEaU6V3MoXmy6lhH1ybcH+yV1jZ2w1K69f3NM=;
        b=DU2YyOwjMxyyRP87l6M8TRjGsto8dWXjpjlGUHJN5zdvjBYnNx16uGXVC7EmgfKFXx
         ox9LmozIRCMjukWVydT+Xtjhe1RmZLRf/XxunHchuRsFCrYeuuAWvSpNTgYi8WD40byS
         SgnPxJeMq8xbaC5oybh5m29ZKoflg+C5q4LHwjQc24QjQXECQ57JafejK0nBeajNZjc6
         WiMvY5yEvB9BracaZAQIetKizULub2Ma9uPgjxYQao4+vNZWHafG0VHXEQqX69D89D7C
         5UfUWx4YBVBtDeGcJYLatitt0QhNfHN4QbmnV0Zjh/X4O3LUuxCvpTVhMcW4Db5n9Z0p
         YpmA==
MIME-Version: 1.0
X-Received: by 10.50.85.101 with SMTP id g5mr570511igz.40.1413409134279; Wed,
 15 Oct 2014 14:38:54 -0700 (PDT)
Received: by 10.64.23.39 with HTTP; Wed, 15 Oct 2014 14:38:54 -0700 (PDT)
In-Reply-To: <CAPYnQ0XHg6LsqYEOqaJU0mjsyUKzpDzL_oY94YGVy4MwV1BgWw@mail.gmail.com>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
	<BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
	<CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
	<8BDA8E51AD6244F0AB5B74ABAAD5B550@gmail.com>
	<CAHH8_OOBQ=U+CdMfXhmwk59QDyaex3xbD=pxw30h-miLvGCOoQ@mail.gmail.com>
	<CAPYnQ0XHg6LsqYEOqaJU0mjsyUKzpDzL_oY94YGVy4MwV1BgWw@mail.gmail.com>
Date: Wed, 15 Oct 2014 14:38:54 -0700
Message-ID: <CAHH8_OO-5HPL+PinU9zQ1iZQdXkAdsBH3T67K7o49DEkeNmW5Q@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
From: Matthew Cheah <matthew.c.cheah@gmail.com>
To: Chester Chen <chester@alpinenow.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0149c2485f022805057cf59f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0149c2485f022805057cf59f
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I think on a higher level I also want to ask why such unit testing has not
actually been done in this codebase. If it's not a common practice to test
message passing then I'm fine with leaving out the unit test, however I'm
more curious as to why such testing was not done before.

On Wed, Oct 15, 2014 at 2:18 PM, Chester Chen <chester@alpinenow.com> wrote=
:

> You can call resolve method on ActorSelection.resolveOne() to see if the
> actor is still there or the path is correct. The method returns a future
> and you can wait for it with timeout. This way, you know the actor is liv=
e
> or already dead or incorrect.
>
> Another way, is to send Identify method to ActorSystem, if it returns wit=
h
> correct identified message; then you can act on it, otherwise, ...
>
> hope this helps
>
> Chester
>
> On Wed, Oct 15, 2014 at 1:38 PM, Matthew Cheah <matthew.c.cheah@gmail.com=
>
> wrote:
>
>> What's happening when I do this is that the Worker tries to get the Mast=
er
>> actor by calling context.actorSelection(), and the RegisterWorker messag=
e
>> gets sent to the dead letters mailbox instead of being picked up by
>> expectMsg. I'm new to Akka and I've tried various ways to registering a
>> "mock" master to no avail.
>>
>> I would think there would be at least some kind of test for master -
>> worker
>> message passing, no?
>>
>> On Wed, Oct 15, 2014 at 11:28 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote=
:
>>
>> > I don=E2=80=99t think there are test cases for Worker itself
>> >
>> >
>> > You can
>> >
>> >
>> > val actorRef =3D TestActorRef[Master](Props(classOf[Master], ...))(
>> > actorSystem) actorRef.underlyingActor.receive(Heartbeat)
>>
>> >
>> > and use expectMsg to test if Master can reply correct message  by
>> assuming
>> > Worker is absolutely correct
>> >
>> > Then in another test case to test if Worker can send register message =
to
>> > Master after receiving Master=E2=80=99s =E2=80=9Cre-register=E2=80=9D =
instruction, (in this test
>> > case assuming that the Master is absolutely right)
>> >
>> > Best,
>> >
>> > --
>> > Nan Zhu
>> >
>> > On Wednesday, October 15, 2014 at 2:04 PM, Matthew Cheah wrote:
>> >
>> > Thanks, the example was helpful.
>> >
>> > However, testing the Worker itself is a lot more complicated than
>> > WorkerWatcher, since the Worker class is quite a bit more complex. Are
>> > there any tests that inspect the Worker itself?
>> >
>> > Thanks,
>> >
>> > -Matt Cheah
>> >
>> > On Tue, Oct 14, 2014 at 6:40 PM, Nan Zhu <zhunanmcgill@gmail.com>
>> wrote:
>> >
>> > You can use akka testkit
>> >
>> > Example:
>> >
>> >
>> >
>> https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c2673=
e41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcherSuite=
.scala
>> >
>> > --
>> > Nan Zhu
>> >
>> > On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote:
>> >
>> > Hi everyone,
>> >
>> > I=E2=80=99m adding some new message passing between the Master and Wor=
ker
>> actors in
>> > order to address https://issues.apache.org/jira/browse/SPARK-3736 .
>> >
>> > I was wondering if these kinds of interactions are tested in the
>> automated
>> > Jenkins test suite, and if so, where I could find some examples to hel=
p
>> me
>> > do the same.
>> >
>> > Thanks!
>> >
>> > -Matt Cheah
>> >
>> >
>> >
>> >
>> >
>>
>
>

--089e0149c2485f022805057cf59f--

From dev-return-9829-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 21:43:31 2014
Return-Path: <dev-return-9829-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 65E6517C9A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 21:43:31 +0000 (UTC)
Received: (qmail 53097 invoked by uid 500); 15 Oct 2014 21:43:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53027 invoked by uid 500); 15 Oct 2014 21:43:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53011 invoked by uid 99); 15 Oct 2014 21:43:30 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:43:30 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.192.181 as permitted sender)
Received: from [209.85.192.181] (HELO mail-pd0-f181.google.com) (209.85.192.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 21:43:03 +0000
Received: by mail-pd0-f181.google.com with SMTP id z10so1932150pdj.26
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 14:43:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=Esyn97H1igUdUXQmbaEka6898I9xrjCX/G13mt6DEKg=;
        b=L5ih8Avtl6vBmUTfcPFql9MoVcsJAmL3maOavl02bmBnmTGXE2NSXrLLWtjyM4Ffm3
         uhNhP3JWeBswT/Qcx+uy0JDQM66qLRLR6HY2SAZuVT4L+jZDw9BrbtsOKylx8jLGIWBx
         wx8PNTnzLbO4SQAuHKtZRgvVPZBL2GG/Utq9wgDc8/u92f6C/6gGAs1Vy1A4jBvILoIy
         aFY5txw7L9voC52xq5PxKDbFhJEZ5nrdXxcM2u/aucTfN/tPcMxrcdpFuEaB+Pkbb8vE
         mjGx+TOo3Rj5o57ymKeqRKS4iZDlDHI5ycY1xCyqKu0PE3grJb0ah9858CkumFbTAoPE
         g+Tw==
X-Received: by 10.66.251.194 with SMTP id zm2mr15521166pac.33.1413409382067;
        Wed, 15 Oct 2014 14:43:02 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id ms3sm18028700pdb.19.2014.10.15.14.42.58
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Wed, 15 Oct 2014 14:42:58 -0700 (PDT)
Date: Wed, 15 Oct 2014 14:42:57 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Chester Chen <chester@alpinenow.com>, Matthew Cheah
 <matthew.c.cheah@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <etPan.543eea61.3d1b58ba.3c30@joshs-mbp>
In-Reply-To: <CAHH8_OO-5HPL+PinU9zQ1iZQdXkAdsBH3T67K7o49DEkeNmW5Q@mail.gmail.com>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
 <BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
 <CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
 <8BDA8E51AD6244F0AB5B74ABAAD5B550@gmail.com>
 <CAHH8_OOBQ=U+CdMfXhmwk59QDyaex3xbD=pxw30h-miLvGCOoQ@mail.gmail.com>
 <CAPYnQ0XHg6LsqYEOqaJU0mjsyUKzpDzL_oY94YGVy4MwV1BgWw@mail.gmail.com>
 <CAHH8_OO-5HPL+PinU9zQ1iZQdXkAdsBH3T67K7o49DEkeNmW5Q@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
X-Mailer: Airmail Beta (269)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="543eea61_507ed7ab_3c30"
X-Virus-Checked: Checked by ClamAV on apache.org

--543eea61_507ed7ab_3c30
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

There are some end-to-end integration tests of Master <-> Worker fault-to=
lerance in=C2=A0https://github.com/apache/spark/blob/master/core/src/main=
/scala/org/apache/spark/deploy/=46aultToleranceTest.scala

I=E2=80=99ve actually been working to develop a more generalized Docker-b=
ased integration-testing framework for Spark in order to test Master <-> =
Worker interactions. =C2=A0I=E2=80=99d like to eventually clean up my cod=
e and release it publicly.
On October 15, 2014 at 2:39:22 PM, Matthew Cheah (matthew.c.cheah=40gmail=
.com) wrote:

I think on a higher level I also want to ask why such unit testing has no=
t =20
actually been done in this codebase. If it's not a common practice to tes=
t =20
message passing then I'm fine with leaving out the unit test, however I'm=
 =20
more curious as to why such testing was not done before. =20

On Wed, Oct 15, 2014 at 2:18 PM, Chester Chen <chester=40alpinenow.com> w=
rote: =20

> You can call resolve method on ActorSelection.resolveOne() to see if th=
e =20
> actor is still there or the path is correct. The method returns a futur=
e =20
> and you can wait for it with timeout. This way, you know the actor is l=
ive =20
> or already dead or incorrect. =20
> =20
> Another way, is to send Identify method to ActorSystem, if it returns w=
ith =20
> correct identified message; then you can act on it, otherwise, ... =20
> =20
> hope this helps =20
> =20
> Chester =20
> =20
> On Wed, Oct 15, 2014 at 1:38 PM, Matthew Cheah <matthew.c.cheah=40gmail=
.com> =20
> wrote: =20
> =20
>> What's happening when I do this is that the Worker tries to get the Ma=
ster =20
>> actor by calling context.actorSelection(), and the RegisterWorker mess=
age =20
>> gets sent to the dead letters mailbox instead of being picked up by =20
>> expectMsg. I'm new to Akka and I've tried various ways to registering =
a =20
>> =22mock=22 master to no avail. =20
>> =20
>> I would think there would be at least some kind of test for master - =20
>> worker =20
>> message passing, no=3F =20
>> =20
>> On Wed, Oct 15, 2014 at 11:28 AM, Nan Zhu <zhunanmcgill=40gmail.com> w=
rote: =20
>> =20
>> > I don=E2=80=99t think there are test cases for Worker itself =20
>> > =20
>> > =20
>> > You can =20
>> > =20
>> > =20
>> > val actorRef =3D TestActorRef=5BMaster=5D(Props(classOf=5BMaster=5D,=
 ...))( =20
>> > actorSystem) actorRef.underlyingActor.receive(Heartbeat) =20
>> =20
>> > =20
>> > and use expectMsg to test if Master can reply correct message by =20
>> assuming =20
>> > Worker is absolutely correct =20
>> > =20
>> > Then in another test case to test if Worker can send register messag=
e to =20
>> > Master after receiving Master=E2=80=99s =E2=80=9Cre-register=E2=80=9D=
 instruction, (in this test =20
>> > case assuming that the Master is absolutely right) =20
>> > =20
>> > Best, =20
>> > =20
>> > -- =20
>> > Nan Zhu =20
>> > =20
>> > On Wednesday, October 15, 2014 at 2:04 PM, Matthew Cheah wrote: =20
>> > =20
>> > Thanks, the example was helpful. =20
>> > =20
>> > However, testing the Worker itself is a lot more complicated than =20
>> > WorkerWatcher, since the Worker class is quite a bit more complex. A=
re =20
>> > there any tests that inspect the Worker itself=3F =20
>> > =20
>> > Thanks, =20
>> > =20
>> > -Matt Cheah =20
>> > =20
>> > On Tue, Oct 14, 2014 at 6:40 PM, Nan Zhu <zhunanmcgill=40gmail.com> =
=20
>> wrote: =20
>> > =20
>> > You can use akka testkit =20
>> > =20
>> > Example: =20
>> > =20
>> > =20
>> > =20
>> https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c26=
73e41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcherS=
uite.scala =20
>> > =20
>> > -- =20
>> > Nan Zhu =20
>> > =20
>> > On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote: =20
>> > =20
>> > Hi everyone, =20
>> > =20
>> > I=E2=80=99m adding some new message passing between the Master and W=
orker =20
>> actors in =20
>> > order to address https://issues.apache.org/jira/browse/SPARK-3736 . =
=20
>> > =20
>> > I was wondering if these kinds of interactions are tested in the =20
>> automated =20
>> > Jenkins test suite, and if so, where I could find some examples to h=
elp =20
>> me =20
>> > do the same. =20
>> > =20
>> > Thanks=21 =20
>> > =20
>> > -Matt Cheah =20
>> > =20
>> > =20
>> > =20
>> > =20
>> > =20
>> =20
> =20
> =20

--543eea61_507ed7ab_3c30--


From dev-return-9830-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 22:05:13 2014
Return-Path: <dev-return-9830-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7603117D81
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 22:05:13 +0000 (UTC)
Received: (qmail 12640 invoked by uid 500); 15 Oct 2014 22:05:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12573 invoked by uid 500); 15 Oct 2014 22:05:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12561 invoked by uid 99); 15 Oct 2014 22:05:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 22:05:09 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matthew.c.cheah@gmail.com designates 209.85.223.182 as permitted sender)
Received: from [209.85.223.182] (HELO mail-ie0-f182.google.com) (209.85.223.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 22:04:43 +0000
Received: by mail-ie0-f182.google.com with SMTP id rp18so2227194iec.27
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 15:04:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=8j5EWC/HMdhBKWjqco7rbThiTZsuTj/rvcndVZLoCrg=;
        b=tBR/+VyeX8pvgr2bkCEQuzq967Vu2MhBFaUYASKFN3QxXseI6R5y24H2QHT7skPMfM
         SYJgEyHqPfuOLrlrMP5qmR4AP0vCKlsa63TxlSCZgENGN7JN54Pz7iujwMjIvaLqstBw
         18lpdwgPvE7pxrnfsdvt4cvslM71y09hw/vRynubY8XWDvghUAurJjdxK5UTz3auFOJO
         ayfzOP9zW/d85SlBg8Ar8vhH+Kl/LGuJgUpFR2QO1enClLQntUpjWGIWGcUBLYcchbzl
         g/terezcSrrTwPYHJGI0QbRYhbxhTdLrLfcrn03Au6paJBbFf/H/eVS7J8xcBbJQSuUS
         c5Hw==
MIME-Version: 1.0
X-Received: by 10.107.168.39 with SMTP id r39mr5395327ioe.79.1413410682120;
 Wed, 15 Oct 2014 15:04:42 -0700 (PDT)
Received: by 10.64.23.39 with HTTP; Wed, 15 Oct 2014 15:04:42 -0700 (PDT)
In-Reply-To: <etPan.543eea61.3d1b58ba.3c30@joshs-mbp>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
	<BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
	<CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
	<8BDA8E51AD6244F0AB5B74ABAAD5B550@gmail.com>
	<CAHH8_OOBQ=U+CdMfXhmwk59QDyaex3xbD=pxw30h-miLvGCOoQ@mail.gmail.com>
	<CAPYnQ0XHg6LsqYEOqaJU0mjsyUKzpDzL_oY94YGVy4MwV1BgWw@mail.gmail.com>
	<CAHH8_OO-5HPL+PinU9zQ1iZQdXkAdsBH3T67K7o49DEkeNmW5Q@mail.gmail.com>
	<etPan.543eea61.3d1b58ba.3c30@joshs-mbp>
Date: Wed, 15 Oct 2014 15:04:42 -0700
Message-ID: <CAHH8_ONdGrb5PKwOfzkxrWzS52i5AZBjhvO9bb0s_pu10BCAmw@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
From: Matthew Cheah <matthew.c.cheah@gmail.com>
To: Josh Rosen <rosenville@gmail.com>
Cc: Chester Chen <chester@alpinenow.com>, Nan Zhu <zhunanmcgill@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11426966a1321905057d5176
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11426966a1321905057d5176
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks Josh! These tests seem to cover the cases I'm looking for already =
=3D).

What's interesting though is that we still ran into SPARK-3736 despite such
integration tests being in place to catch it - specifically, the case when
the master disconnects and reconnects, the workers should reconnect to the
master after the master restarts. Are the tests here run regularly, i.e.
Jenkins build or nightly build, and if so how did that test case pass while
SPARK-3736 apparently still exists?

At any rate, I think I'll submit my fix PR but with no particular extra
automated test written for it, since it seems like FaultToleranceTest
sufficiently covers what I need.

On Wed, Oct 15, 2014 at 2:42 PM, Josh Rosen <rosenville@gmail.com> wrote:

> There are some end-to-end integration tests of Master <-> Worker
> fault-tolerance in
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apach=
e/spark/deploy/FaultToleranceTest.scala
>
> I=E2=80=99ve actually been working to develop a more generalized Docker-b=
ased
> integration-testing framework for Spark in order to test Master <-> Worke=
r
> interactions.  I=E2=80=99d like to eventually clean up my code and releas=
e it
> publicly.
>
> On October 15, 2014 at 2:39:22 PM, Matthew Cheah (
> matthew.c.cheah@gmail.com) wrote:
>
> I think on a higher level I also want to ask why such unit testing has no=
t
> actually been done in this codebase. If it's not a common practice to tes=
t
> message passing then I'm fine with leaving out the unit test, however I'm
> more curious as to why such testing was not done before.
>
> On Wed, Oct 15, 2014 at 2:18 PM, Chester Chen <chester@alpinenow.com>
> wrote:
>
> > You can call resolve method on ActorSelection.resolveOne() to see if th=
e
> > actor is still there or the path is correct. The method returns a futur=
e
> > and you can wait for it with timeout. This way, you know the actor is
> live
> > or already dead or incorrect.
> >
> > Another way, is to send Identify method to ActorSystem, if it returns
> with
> > correct identified message; then you can act on it, otherwise, ...
> >
> > hope this helps
> >
> > Chester
> >
> > On Wed, Oct 15, 2014 at 1:38 PM, Matthew Cheah <
> matthew.c.cheah@gmail.com>
> > wrote:
> >
> >> What's happening when I do this is that the Worker tries to get the
> Master
> >> actor by calling context.actorSelection(), and the RegisterWorker
> message
> >> gets sent to the dead letters mailbox instead of being picked up by
> >> expectMsg. I'm new to Akka and I've tried various ways to registering =
a
> >> "mock" master to no avail.
> >>
> >> I would think there would be at least some kind of test for master -
> >> worker
> >> message passing, no?
> >>
> >> On Wed, Oct 15, 2014 at 11:28 AM, Nan Zhu <zhunanmcgill@gmail.com>
> wrote:
> >>
> >> > I don=E2=80=99t think there are test cases for Worker itself
> >> >
> >> >
> >> > You can
> >> >
> >> >
> >> > val actorRef =3D TestActorRef[Master](Props(classOf[Master], ...))(
> >> > actorSystem) actorRef.underlyingActor.receive(Heartbeat)
> >>
> >> >
> >> > and use expectMsg to test if Master can reply correct message by
> >> assuming
> >> > Worker is absolutely correct
> >> >
> >> > Then in another test case to test if Worker can send register messag=
e
> to
> >> > Master after receiving Master=E2=80=99s =E2=80=9Cre-register=E2=80=
=9D instruction, (in this
> test
> >> > case assuming that the Master is absolutely right)
> >> >
> >> > Best,
> >> >
> >> > --
> >> > Nan Zhu
> >> >
> >> > On Wednesday, October 15, 2014 at 2:04 PM, Matthew Cheah wrote:
> >> >
> >> > Thanks, the example was helpful.
> >> >
> >> > However, testing the Worker itself is a lot more complicated than
> >> > WorkerWatcher, since the Worker class is quite a bit more complex.
> Are
> >> > there any tests that inspect the Worker itself?
> >> >
> >> > Thanks,
> >> >
> >> > -Matt Cheah
> >> >
> >> > On Tue, Oct 14, 2014 at 6:40 PM, Nan Zhu <zhunanmcgill@gmail.com>
> >> wrote:
> >> >
> >> > You can use akka testkit
> >> >
> >> > Example:
> >> >
> >> >
> >> >
> >>
> https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c2673e=
41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcherSuite.=
scala
> >> >
> >> > --
> >> > Nan Zhu
> >> >
> >> > On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote:
> >> >
> >> > Hi everyone,
> >> >
> >> > I=E2=80=99m adding some new message passing between the Master and W=
orker
> >> actors in
> >> > order to address https://issues.apache.org/jira/browse/SPARK-3736 .
> >> >
> >> > I was wondering if these kinds of interactions are tested in the
> >> automated
> >> > Jenkins test suite, and if so, where I could find some examples to
> help
> >> me
> >> > do the same.
> >> >
> >> > Thanks!
> >> >
> >> > -Matt Cheah
> >> >
> >> >
> >> >
> >> >
> >> >
> >>
> >
> >
>
>

--001a11426966a1321905057d5176--

From dev-return-9831-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 22:10:59 2014
Return-Path: <dev-return-9831-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DDE2517DA9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 22:10:59 +0000 (UTC)
Received: (qmail 29794 invoked by uid 500); 15 Oct 2014 22:10:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29720 invoked by uid 500); 15 Oct 2014 22:10:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 29703 invoked by uid 99); 15 Oct 2014 22:10:58 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 22:10:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.50 as permitted sender)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 22:10:33 +0000
Received: by mail-la0-f50.google.com with SMTP id s18so1860832lam.23
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 15:10:32 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=DfI3KrbaqIoH2mRxpCE8UdUjTt3JSIsufeTooPbKLCs=;
        b=Y7gXnBHH0GuQ30HDZU53BCKYdbIsJWZ0ClHOT2y4UzfMtasReS83ea7zjuO2tNzlVC
         t5+vFe0ecqiyH4WU/8ADmAkzUoZR8/XwH2Ej9jXDi04xYOREEa6i1+kKbnzygVb6AEI8
         SBeVHHyAtfVnnSbeZmKEpSj9ceViBsI0027DC09/hKsUxlNY87y8gqDKaU0yTZyEX9W3
         hSfa5xxu1S9apkCLoOzcVydGMBH2pl+Hia0A8SOaShhzZBq69JZgstWvf0bqFulasLqy
         h7q+stRlQuc+2PwCShhoB++2VMNSD43OnDCvvZbvgGa3qbL6Mvc6APlkc1gW80gzOEyZ
         pDjQ==
X-Gm-Message-State: ALoCoQmMmQVYG03b+r/FwDKKT4QXLhaHJXXHbEK4tI1jBXrIOg2kzxcKeoAxMxgYRSr0JUYp/D47
X-Received: by 10.112.35.229 with SMTP id l5mr15397049lbj.60.1413411032198;
 Wed, 15 Oct 2014 15:10:32 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Wed, 15 Oct 2014 15:10:11 -0700 (PDT)
In-Reply-To: <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com> <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Wed, 15 Oct 2014 15:10:11 -0700
Message-ID: <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: amp-infra <amp-infra@googlegroups.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c36c407efed405057d66b3
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c36c407efed405057d66b3
Content-Type: text/plain; charset=UTF-8

ok, we've had about 10 spark pull request builds go through w/o any git
timeouts.  it seems that the git timeout issue might be licked.

i will be definitely be keeping an eye on this for the next few days.

thanks for being patient!

shane

On Wed, Oct 15, 2014 at 2:27 PM, shane knapp <sknapp@berkeley.edu> wrote:

> four builds triggered....  and no timeouts.  :crossestoes:  :)
>
> On Wed, Oct 15, 2014 at 2:19 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> ok, we're up and building...  :crossesfingersfortheumpteenthtime:
>>
>> On Wed, Oct 15, 2014 at 1:59 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> I support this effort. :thumbsup:
>>>
>>> On Wed, Oct 15, 2014 at 4:52 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>>
>>>> i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2) to see
>>>> if
>>>> that helps w/the git fetch timeouts.
>>>>
>>>> this will require a short downtime (~20 mins for builds to finish, ~20
>>>> mins
>>>> to downgrade), and will hopefully give us some insight in to wtf is
>>>> going
>>>> on.
>>>>
>>>> thanks for your patience...
>>>>
>>>> shane
>>>>
>>>
>>>  --
>>> You received this message because you are subscribed to the Google
>>> Groups "amp-infra" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to amp-infra+unsubscribe@googlegroups.com.
>>> For more options, visit https://groups.google.com/d/optout.
>>>
>>
>>
>

--001a11c36c407efed405057d66b3--

From dev-return-9832-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 15 23:57:31 2014
Return-Path: <dev-return-9832-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A1A4117259
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 15 Oct 2014 23:57:31 +0000 (UTC)
Received: (qmail 46236 invoked by uid 500); 15 Oct 2014 23:57:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46164 invoked by uid 500); 15 Oct 2014 23:57:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46152 invoked by uid 99); 15 Oct 2014 23:57:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 23:57:30 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.46 as permitted sender)
Received: from [209.85.215.46] (HELO mail-la0-f46.google.com) (209.85.215.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 15 Oct 2014 23:57:25 +0000
Received: by mail-la0-f46.google.com with SMTP id gi9so1973760lab.19
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 16:57:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=vgZb3i8+oyZDZycVkzkY3mAdY3avbpYOVYgwH4YRR7A=;
        b=OzYQnSpNKXPc3oAfnyqylt4RqDKDOM5cZA4zMbxKCNyhCGeW5gSfTjHTwZ3jXhl96n
         c6M4D2IUM1WoGDGLs1DgEHQCIsJKRSCvkrfR7jvUaPKBCGBl0KFuHzPyFW4OdM6FnVhJ
         kigbtMmgER130tYIgnn89lkECa/4ZDVJmBUCETqqlnVDm8KEJnVi703cojwWaCGT+25q
         xy0xxH714I7Xv3pmc56ZWgjkw01xkMVDcq3ua3aQIJf7jWVsyx/cQMDxj1Zqzn9uExzA
         Y3gb6S2EqVcgTQP36qvMzeHq0ZWcRrg2KKKL5Pdi5mYQeTk/wGg/1Reg4Bq3zjDAj42K
         yC6Q==
MIME-Version: 1.0
X-Received: by 10.112.148.161 with SMTP id tt1mr15947097lbb.67.1413417424510;
 Wed, 15 Oct 2014 16:57:04 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Wed, 15 Oct 2014 16:57:04 -0700 (PDT)
Date: Wed, 15 Oct 2014 16:57:04 -0700
Message-ID: <CA+B-+fxAC6B-1z2GSpib8TeOR_g8CXfkekzaeo+dKQ0ayXuebA@mail.gmail.com>
Subject: Issues with ALS positive definite
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a829a81e55d05057ee3a1
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a829a81e55d05057ee3a1
Content-Type: text/plain; charset=UTF-8

Hi,

If I take the Movielens data and run the default ALS with regularization as
0.0, I am hitting exception from LAPACK that the gram matrix is not
positive definite. This is on the master branch.

This is how I run it :

./bin/spark-submit --total-executor-cores 1 --master spark://
tusca09lmlvt00c.uswin.ad.vzwcorp.com:7077 --jars
/Users/v606014/.m2/repository/com/github/scopt/scopt_2.10/3.2.0/scopt_2.10-3.2.0.jar
--class org.apache.spark.examples.mllib.MovieLensALS
./examples/target/spark-examples_2.10-1.1.0-SNAPSHOT.jar --rank 20
--numIterations 20 --lambda 0.0 --kryo
hdfs://localhost:8020/sandbox/movielens/

Error from LAPACK:

WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 22,
tusca09lmlvt00c.uswin.ad.vzwcorp.com):
org.jblas.exceptions.LapackArgumentException: LAPACK DPOSV: Leading minor
of order i of A is not positive definite.

>From the maths it's not expected right ?

||r - wi'hj||^{2} has to be positive definite...

I think the tests are not running any 0.0 regularization tests otherwise we
should have caught it as well...

For the sparse coding NMF variant that I am running, I have to turn off L2
regularization when I run a L1 on products to extract sparse topics...

Thanks.

Deb

--047d7b3a829a81e55d05057ee3a1--

From dev-return-9833-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 00:01:50 2014
Return-Path: <dev-return-9833-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0772517283
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 00:01:50 +0000 (UTC)
Received: (qmail 49141 invoked by uid 500); 16 Oct 2014 00:01:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49060 invoked by uid 500); 16 Oct 2014 00:01:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49041 invoked by uid 99); 16 Oct 2014 00:01:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 00:01:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of liquanpei@gmail.com designates 209.85.212.180 as permitted sender)
Received: from [209.85.212.180] (HELO mail-wi0-f180.google.com) (209.85.212.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 00:01:44 +0000
Received: by mail-wi0-f180.google.com with SMTP id em10so3303300wid.7
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 17:01:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=emMOH8GpPaWsNifp4KpsdvbroJkaf7s9/r0LV+t7dM4=;
        b=JZ7ThxUFi+c+goKRXmcHX3XVTFAnddA9evZMwNrdkEr0WHNReU8zI10Ufkdb6+Bvhn
         T+nqYg4g89olL993oQmnDdfrlfd0jEUIzxSjmwmQFcT4WANpNJ2NlDqG8k9G5eIGxbtS
         nZxHOa3px6NMItAXQLCU110+CeQTr7vPM7jfjO1QUKRQkq0WaD5MdvcUKZaYPtd5SaQN
         dVxku8C60q7ETipxEHgvivh9bHUtbGkT/Y0zJtVlHqbxtxQmSuuE1lGifn5BU5ja1m3m
         zOj8oo3xHqASgxbFkvlYHGWCFGqKwMxJIuOabVLEpng/Ij5r3VmGcrOG4lJdHOJrS5LW
         UpPg==
MIME-Version: 1.0
X-Received: by 10.180.90.237 with SMTP id bz13mr16108306wib.50.1413417682935;
 Wed, 15 Oct 2014 17:01:22 -0700 (PDT)
Received: by 10.180.245.166 with HTTP; Wed, 15 Oct 2014 17:01:22 -0700 (PDT)
In-Reply-To: <CA+B-+fxAC6B-1z2GSpib8TeOR_g8CXfkekzaeo+dKQ0ayXuebA@mail.gmail.com>
References: <CA+B-+fxAC6B-1z2GSpib8TeOR_g8CXfkekzaeo+dKQ0ayXuebA@mail.gmail.com>
Date: Wed, 15 Oct 2014 17:01:22 -0700
Message-ID: <CAJmC80_aaf-D-26s=JSaX9XCpXHSfwk5Vc4vZh4_NBu8fdGc6Q@mail.gmail.com>
Subject: Re: Issues with ALS positive definite
From: Liquan Pei <liquanpei@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043c095ee9281505057ef249
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c095ee9281505057ef249
Content-Type: text/plain; charset=UTF-8

Hi Debaish,

I think ||r - wi'hj||^{2} is semi-positive definite.

Thanks,
Liquan

On Wed, Oct 15, 2014 at 4:57 PM, Debasish Das <debasish.das83@gmail.com>
wrote:

> Hi,
>
> If I take the Movielens data and run the default ALS with regularization as
> 0.0, I am hitting exception from LAPACK that the gram matrix is not
> positive definite. This is on the master branch.
>
> This is how I run it :
>
> ./bin/spark-submit --total-executor-cores 1 --master spark://
> tusca09lmlvt00c.uswin.ad.vzwcorp.com:7077 --jars
>
> /Users/v606014/.m2/repository/com/github/scopt/scopt_2.10/3.2.0/scopt_2.10-3.2.0.jar
> --class org.apache.spark.examples.mllib.MovieLensALS
> ./examples/target/spark-examples_2.10-1.1.0-SNAPSHOT.jar --rank 20
> --numIterations 20 --lambda 0.0 --kryo
> hdfs://localhost:8020/sandbox/movielens/
>
> Error from LAPACK:
>
> WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 22,
> tusca09lmlvt00c.uswin.ad.vzwcorp.com):
> org.jblas.exceptions.LapackArgumentException: LAPACK DPOSV: Leading minor
> of order i of A is not positive definite.
>
> From the maths it's not expected right ?
>
> ||r - wi'hj||^{2} has to be positive definite...
>
> I think the tests are not running any 0.0 regularization tests otherwise we
> should have caught it as well...
>
> For the sparse coding NMF variant that I am running, I have to turn off L2
> regularization when I run a L1 on products to extract sparse topics...
>
> Thanks.
>
> Deb
>



-- 
Liquan Pei
Department of Physics
University of Massachusetts Amherst

--f46d043c095ee9281505057ef249--

From dev-return-9834-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 00:06:01 2014
Return-Path: <dev-return-9834-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B0EC0172B6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 00:06:01 +0000 (UTC)
Received: (qmail 57039 invoked by uid 500); 16 Oct 2014 00:06:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56963 invoked by uid 500); 16 Oct 2014 00:06:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56948 invoked by uid 99); 16 Oct 2014 00:06:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 00:06:00 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.179 as permitted sender)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 00:05:34 +0000
Received: by mail-lb0-f179.google.com with SMTP id l4so1929429lbv.10
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 17:05:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=t6KGalT2KC76RaEoKhApGQuCKVBW5yN6Yeho/vGp30c=;
        b=xn2yk29nFpMqKNAEw2WaVZlBVE0AKOzf7y/VP+DWDzryfE1uYqoOkUUZzszEWvRest
         3KOIyxjUCek10B1PSls1Hnp0LGDRhEz87Mvm+QBNhCG5pF8ZGNbLEgjJ0tPe1W46VpoI
         ehdWuyIM5ap/iwATBGQNn+VAFwfHDCBtqPp83UVkYp+Jy/6O11oC0jZ05Gtpfd4YskuF
         jEW4Qbd1BwRSjjB6ahWggofv3noCX54+txTUzFXlx3JZcD4zNcKhqrdL7OnBigJUdeAE
         MGtpqYeDMb1+te09YVYfIMt2zgqpBO1Jo7QOgoxc2aS/uQpC/YWW6cLo0pkRn1LU2lAk
         l4Lw==
MIME-Version: 1.0
X-Received: by 10.112.28.75 with SMTP id z11mr15522666lbg.49.1413417933887;
 Wed, 15 Oct 2014 17:05:33 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Wed, 15 Oct 2014 17:05:33 -0700 (PDT)
In-Reply-To: <CAJmC80_aaf-D-26s=JSaX9XCpXHSfwk5Vc4vZh4_NBu8fdGc6Q@mail.gmail.com>
References: <CA+B-+fxAC6B-1z2GSpib8TeOR_g8CXfkekzaeo+dKQ0ayXuebA@mail.gmail.com>
	<CAJmC80_aaf-D-26s=JSaX9XCpXHSfwk5Vc4vZh4_NBu8fdGc6Q@mail.gmail.com>
Date: Wed, 15 Oct 2014 17:05:33 -0700
Message-ID: <CA+B-+fwsC_Zvqw_t9uyHc=P3-ie8ytQzJbBjcFEzFvY17p+DyA@mail.gmail.com>
Subject: Re: Issues with ALS positive definite
From: Debasish Das <debasish.das83@gmail.com>
To: Liquan Pei <liquanpei@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133eca6de5e4805057f0196
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133eca6de5e4805057f0196
Content-Type: text/plain; charset=UTF-8

But do you expect the mllib code to fail if I run with 0.0 regularization ?

I think ||r - wi'hj||^{2} is positive definite...It can become positive
semi definite only if there are dependent rows in the matrix...

@sean is that right ? We had this discussion before as well...


On Wed, Oct 15, 2014 at 5:01 PM, Liquan Pei <liquanpei@gmail.com> wrote:

> Hi Debaish,
>
> I think ||r - wi'hj||^{2} is semi-positive definite.
>
> Thanks,
> Liquan
>
> On Wed, Oct 15, 2014 at 4:57 PM, Debasish Das <debasish.das83@gmail.com>
> wrote:
>
>> Hi,
>>
>> If I take the Movielens data and run the default ALS with regularization
>> as
>> 0.0, I am hitting exception from LAPACK that the gram matrix is not
>> positive definite. This is on the master branch.
>>
>> This is how I run it :
>>
>> ./bin/spark-submit --total-executor-cores 1 --master spark://
>> tusca09lmlvt00c.uswin.ad.vzwcorp.com:7077 --jars
>>
>> /Users/v606014/.m2/repository/com/github/scopt/scopt_2.10/3.2.0/scopt_2.10-3.2.0.jar
>> --class org.apache.spark.examples.mllib.MovieLensALS
>> ./examples/target/spark-examples_2.10-1.1.0-SNAPSHOT.jar --rank 20
>> --numIterations 20 --lambda 0.0 --kryo
>> hdfs://localhost:8020/sandbox/movielens/
>>
>> Error from LAPACK:
>>
>> WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 22,
>> tusca09lmlvt00c.uswin.ad.vzwcorp.com):
>> org.jblas.exceptions.LapackArgumentException: LAPACK DPOSV: Leading minor
>> of order i of A is not positive definite.
>>
>> From the maths it's not expected right ?
>>
>> ||r - wi'hj||^{2} has to be positive definite...
>>
>> I think the tests are not running any 0.0 regularization tests otherwise
>> we
>> should have caught it as well...
>>
>> For the sparse coding NMF variant that I am running, I have to turn off L2
>> regularization when I run a L1 on products to extract sparse topics...
>>
>> Thanks.
>>
>> Deb
>>
>
>
>
> --
> Liquan Pei
> Department of Physics
> University of Massachusetts Amherst
>

--001a1133eca6de5e4805057f0196--

From dev-return-9835-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 02:06:29 2014
Return-Path: <dev-return-9835-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 11C821755E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 02:06:29 +0000 (UTC)
Received: (qmail 33346 invoked by uid 500); 16 Oct 2014 02:06:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33277 invoked by uid 500); 16 Oct 2014 02:06:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33265 invoked by uid 99); 16 Oct 2014 02:06:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 02:06:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.52 as permitted sender)
Received: from [74.125.82.52] (HELO mail-wg0-f52.google.com) (74.125.82.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 02:06:23 +0000
Received: by mail-wg0-f52.google.com with SMTP id a1so2620444wgh.11
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 19:06:03 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=FJMRPSlHqNvGlzLV39+GkP8hUBUvD+i3/FGTHmDenQw=;
        b=q66wL1HXRjbw2/CzjAneREB8DFDu62fD15pbPCweA+lu6QAKmi/+7YwWpyoE7MG2d5
         A3S3JhU9b5ycBMlXeREfn40dyabNBQJyTa1sOdGZicvwiVgx8b+937K5RSZ1tJn5jbJh
         6qQpcMKFg1Bfjc8yI9p6Kd3F5zrP+Z05RwpurATaRF0zNEJW1aOLu+/NAVLde4k11cV2
         ucszhf091S5meMLjAJLeReqs2AqGFfDOMbB2/Uyx9jW/1Lmd8n2DZSobMSF0N2a2ANAI
         T7RvE3O5Rq/uuCJD0mtAJk73OiPowTTksjQZRDIiEuYUYqITrfMnGOhrXFTsLNbFheuR
         mu3A==
X-Received: by 10.180.206.171 with SMTP id lp11mr15337944wic.33.1413425162920;
 Wed, 15 Oct 2014 19:06:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Wed, 15 Oct 2014 19:05:22 -0700 (PDT)
In-Reply-To: <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com> <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Wed, 15 Oct 2014 22:05:22 -0400
Message-ID: <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c380ccc0a90d050580b0c5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c380ccc0a90d050580b0c5
Content-Type: text/plain; charset=UTF-8

A quick scan through the Spark PR board <https://spark-prs.appspot.com/> shows
no recent failures related to this git checkout problem.

Looks promising!

Nick

On Wed, Oct 15, 2014 at 6:10 PM, shane knapp <sknapp@berkeley.edu> wrote:

> ok, we've had about 10 spark pull request builds go through w/o any git
> timeouts.  it seems that the git timeout issue might be licked.
>
> i will be definitely be keeping an eye on this for the next few days.
>
> thanks for being patient!
>
> shane
>
> On Wed, Oct 15, 2014 at 2:27 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
> > four builds triggered....  and no timeouts.  :crossestoes:  :)
> >
> > On Wed, Oct 15, 2014 at 2:19 PM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >
> >> ok, we're up and building...  :crossesfingersfortheumpteenthtime:
> >>
> >> On Wed, Oct 15, 2014 at 1:59 PM, Nicholas Chammas <
> >> nicholas.chammas@gmail.com> wrote:
> >>
> >>> I support this effort. :thumbsup:
> >>>
> >>> On Wed, Oct 15, 2014 at 4:52 PM, shane knapp <sknapp@berkeley.edu>
> >>> wrote:
> >>>
> >>>> i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2) to
> see
> >>>> if
> >>>> that helps w/the git fetch timeouts.
> >>>>
> >>>> this will require a short downtime (~20 mins for builds to finish, ~20
> >>>> mins
> >>>> to downgrade), and will hopefully give us some insight in to wtf is
> >>>> going
> >>>> on.
> >>>>
> >>>> thanks for your patience...
> >>>>
> >>>> shane
> >>>>
> >>>
> >>>  --
> >>> You received this message because you are subscribed to the Google
> >>> Groups "amp-infra" group.
> >>> To unsubscribe from this group and stop receiving emails from it, send
> >>> an email to amp-infra+unsubscribe@googlegroups.com.
> >>> For more options, visit https://groups.google.com/d/optout.
> >>>
> >>
> >>
> >
>

--001a11c380ccc0a90d050580b0c5--

From dev-return-9836-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 06:25:59 2014
Return-Path: <dev-return-9836-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0A0CB17ABC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 06:25:59 +0000 (UTC)
Received: (qmail 70628 invoked by uid 500); 16 Oct 2014 06:25:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 70559 invoked by uid 500); 16 Oct 2014 06:25:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 70547 invoked by uid 99); 16 Oct 2014 06:25:57 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 06:25:57 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of mengxr@gmail.com designates 209.85.223.171 as permitted sender)
Received: from [209.85.223.171] (HELO mail-ie0-f171.google.com) (209.85.223.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 06:25:32 +0000
Received: by mail-ie0-f171.google.com with SMTP id tr6so2796444ieb.2
        for <dev@spark.apache.org>; Wed, 15 Oct 2014 23:25:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=993sB8otlgBr0UQcuC/BOV7N+7hIHQxnXTikA0sPiA0=;
        b=Cz58KaQAvZwxIFz8CjpSCrYVJNObt+FIK7MrEHIiK4y2Xd/A3ffZxd7s5lSpZTI7WU
         G3+SKKhqp6dvFVze3TzZuedLFDkblyAPs7LoD376sU/CTO4YCuMA1WnSfet0qFlR3yF+
         YO7QrpQwBCypGciPtZZQ+XY2AaaraYH7ShFnDTqimEStJ1r/KqMdqIFuRRiLixOV2v0m
         UFhuONMqeePhL/S2cnw7p67g/TfEV0Lt9qYB1n7YZBw4kOgMwPDz/NbKUD6RRQnwC4Gu
         MtidWSYL8wfBcVwF+979T/wwQbbPAFV5zzsUQycf2ihxEJWLI5bhZ8v33qcleS+ntbQq
         l2/A==
MIME-Version: 1.0
X-Received: by 10.43.106.206 with SMTP id dv14mr2314352icc.6.1413440731160;
 Wed, 15 Oct 2014 23:25:31 -0700 (PDT)
Received: by 10.107.162.21 with HTTP; Wed, 15 Oct 2014 23:25:31 -0700 (PDT)
In-Reply-To: <CA+B-+fwsC_Zvqw_t9uyHc=P3-ie8ytQzJbBjcFEzFvY17p+DyA@mail.gmail.com>
References: <CA+B-+fxAC6B-1z2GSpib8TeOR_g8CXfkekzaeo+dKQ0ayXuebA@mail.gmail.com>
	<CAJmC80_aaf-D-26s=JSaX9XCpXHSfwk5Vc4vZh4_NBu8fdGc6Q@mail.gmail.com>
	<CA+B-+fwsC_Zvqw_t9uyHc=P3-ie8ytQzJbBjcFEzFvY17p+DyA@mail.gmail.com>
Date: Wed, 15 Oct 2014 23:25:31 -0700
Message-ID: <CAJgQjQ_jvnhfa3U0sQR8csPq-VYZWC7_pnr8tsvc1HkOTBtZzw@mail.gmail.com>
Subject: Re: Issues with ALS positive definite
From: Xiangrui Meng <mengxr@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: Liquan Pei <liquanpei@gmail.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Do not use lambda=0.0. Use a small number instead. Cholesky
factorization doesn't work on semi-positive systems with 0
eigenvalues. -Xiangrui

On Wed, Oct 15, 2014 at 5:05 PM, Debasish Das <debasish.das83@gmail.com> wrote:
> But do you expect the mllib code to fail if I run with 0.0 regularization ?
>
> I think ||r - wi'hj||^{2} is positive definite...It can become positive
> semi definite only if there are dependent rows in the matrix...
>
> @sean is that right ? We had this discussion before as well...
>
>
> On Wed, Oct 15, 2014 at 5:01 PM, Liquan Pei <liquanpei@gmail.com> wrote:
>
>> Hi Debaish,
>>
>> I think ||r - wi'hj||^{2} is semi-positive definite.
>>
>> Thanks,
>> Liquan
>>
>> On Wed, Oct 15, 2014 at 4:57 PM, Debasish Das <debasish.das83@gmail.com>
>> wrote:
>>
>>> Hi,
>>>
>>> If I take the Movielens data and run the default ALS with regularization
>>> as
>>> 0.0, I am hitting exception from LAPACK that the gram matrix is not
>>> positive definite. This is on the master branch.
>>>
>>> This is how I run it :
>>>
>>> ./bin/spark-submit --total-executor-cores 1 --master spark://
>>> tusca09lmlvt00c.uswin.ad.vzwcorp.com:7077 --jars
>>>
>>> /Users/v606014/.m2/repository/com/github/scopt/scopt_2.10/3.2.0/scopt_2.10-3.2.0.jar
>>> --class org.apache.spark.examples.mllib.MovieLensALS
>>> ./examples/target/spark-examples_2.10-1.1.0-SNAPSHOT.jar --rank 20
>>> --numIterations 20 --lambda 0.0 --kryo
>>> hdfs://localhost:8020/sandbox/movielens/
>>>
>>> Error from LAPACK:
>>>
>>> WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 22,
>>> tusca09lmlvt00c.uswin.ad.vzwcorp.com):
>>> org.jblas.exceptions.LapackArgumentException: LAPACK DPOSV: Leading minor
>>> of order i of A is not positive definite.
>>>
>>> From the maths it's not expected right ?
>>>
>>> ||r - wi'hj||^{2} has to be positive definite...
>>>
>>> I think the tests are not running any 0.0 regularization tests otherwise
>>> we
>>> should have caught it as well...
>>>
>>> For the sparse coding NMF variant that I am running, I have to turn off L2
>>> regularization when I run a L1 on products to extract sparse topics...
>>>
>>> Thanks.
>>>
>>> Deb
>>>
>>
>>
>>
>> --
>> Liquan Pei
>> Department of Physics
>> University of Massachusetts Amherst
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9837-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 11:19:41 2014
Return-Path: <dev-return-9837-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 37427173CB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 11:19:41 +0000 (UTC)
Received: (qmail 42671 invoked by uid 500); 16 Oct 2014 11:19:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42593 invoked by uid 500); 16 Oct 2014 11:19:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42582 invoked by uid 99); 16 Oct 2014 11:19:39 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 11:19:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.223.177 as permitted sender)
Received: from [209.85.223.177] (HELO mail-ie0-f177.google.com) (209.85.223.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 11:19:14 +0000
Received: by mail-ie0-f177.google.com with SMTP id rd18so3160715iec.36
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 04:19:12 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=ZV4Vkl3Sgc0I71rqOEqwEBEJFbaL+O/RnYfhYhUBtBk=;
        b=kATK/6JzVEg8Ef0bhZVRjZJTYJLyGAjnO3sHpjB4jR6fACojw5rzDYGsRw9NgsPXVs
         e6pFrInbEfTDN9Pl3Vs8hKbeA5dQcLq8hzgvDcPuhnErzMp0sVNNrNzh22A+CuOzmufw
         1h5GXuOK8Vbi7NGJIJp5THxOdMPkv7apHEwmBhk9OVGtpzSYnIXiOt/wynN8EP8qQBuz
         IYwJEEEs5/935qv/tWJ1rHJVlTuD68Q+G+sMZ0r3x8EhLYx1nd1FG9WALlhnz1znrf9F
         m1h12Pa6MzkMAJJqiaSlqLGWdwTl0hug7uY20VzhtNDNFNtxPv5l5jmu1saprQLEqpMP
         XXeA==
X-Gm-Message-State: ALoCoQlvzhu73igoHGC+Yxr63YnVXJ3ewUC8TUOnB1LMOS8U6A2/VbHr6iBJnQU/cWLXADao+StH
MIME-Version: 1.0
X-Received: by 10.42.96.137 with SMTP id j9mr1049725icn.88.1413458352718; Thu,
 16 Oct 2014 04:19:12 -0700 (PDT)
Received: by 10.107.12.158 with HTTP; Thu, 16 Oct 2014 04:19:12 -0700 (PDT)
Received: by 10.107.12.158 with HTTP; Thu, 16 Oct 2014 04:19:12 -0700 (PDT)
In-Reply-To: <CA+B-+fwsC_Zvqw_t9uyHc=P3-ie8ytQzJbBjcFEzFvY17p+DyA@mail.gmail.com>
References: <CA+B-+fxAC6B-1z2GSpib8TeOR_g8CXfkekzaeo+dKQ0ayXuebA@mail.gmail.com>
	<CAJmC80_aaf-D-26s=JSaX9XCpXHSfwk5Vc4vZh4_NBu8fdGc6Q@mail.gmail.com>
	<CA+B-+fwsC_Zvqw_t9uyHc=P3-ie8ytQzJbBjcFEzFvY17p+DyA@mail.gmail.com>
Date: Thu, 16 Oct 2014 07:19:12 -0400
Message-ID: <CAMAsSdKk4SyCYTrFuZmpQNA_rjBF8cN-QQyqsMKtaTghY_xCAw@mail.gmail.com>
Subject: Re: Issues with ALS positive definite
From: Sean Owen <sowen@cloudera.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=20cf3036392f04e6770505886bc1
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf3036392f04e6770505886bc1
Content-Type: text/plain; charset=UTF-8

It Gramian is at least positive semidefinite and will be definite if the
matrix is non singular, yes. That's usually but not always true.

The lambda*I matrix is positive definite, well, when lambda is positive.
Adding that makes it definite.

At least, lambda=0 could be rejected as invalid.

But this goes back to using the Cholesky decomposition. Why not use QR? It
doesn't require definite. It should be a little more accurate. On these
smallish dense matrices I don't think it is much slower. I have not
benchmarked that but I opted for QR in a different implementation and it
has worked fine.

Now I have to go hunt for how the QR decomposition is exposed in BLAS...
Looks like its GEQRF which JBLAS helpfully exposes. Debasish you could try
it for fun at least.
 On Oct 15, 2014 8:06 PM, "Debasish Das" <debasish.das83@gmail.com> wrote:

> But do you expect the mllib code to fail if I run with 0.0 regularization ?
>
> I think ||r - wi'hj||^{2} is positive definite...It can become positive
> semi definite only if there are dependent rows in the matrix...
>
> @sean is that right ? We had this discussion before as well...
>
>
> On Wed, Oct 15, 2014 at 5:01 PM, Liquan Pei <liquanpei@gmail.com> wrote:
>
> > Hi Debaish,
> >
> > I think ||r - wi'hj||^{2} is semi-positive definite.
> >
> > Thanks,
> > Liquan
> >
> > On Wed, Oct 15, 2014 at 4:57 PM, Debasish Das <debasish.das83@gmail.com>
> > wrote:
> >
> >> Hi,
> >>
> >> If I take the Movielens data and run the default ALS with regularization
> >> as
> >> 0.0, I am hitting exception from LAPACK that the gram matrix is not
> >> positive definite. This is on the master branch.
> >>
> >> This is how I run it :
> >>
> >> ./bin/spark-submit --total-executor-cores 1 --master spark://
> >> tusca09lmlvt00c.uswin.ad.vzwcorp.com:7077 --jars
> >>
> >>
> /Users/v606014/.m2/repository/com/github/scopt/scopt_2.10/3.2.0/scopt_2.10-3.2.0.jar
> >> --class org.apache.spark.examples.mllib.MovieLensALS
> >> ./examples/target/spark-examples_2.10-1.1.0-SNAPSHOT.jar --rank 20
> >> --numIterations 20 --lambda 0.0 --kryo
> >> hdfs://localhost:8020/sandbox/movielens/
> >>
> >> Error from LAPACK:
> >>
> >> WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 22,
> >> tusca09lmlvt00c.uswin.ad.vzwcorp.com):
> >> org.jblas.exceptions.LapackArgumentException: LAPACK DPOSV: Leading
> minor
> >> of order i of A is not positive definite.
> >>
> >> From the maths it's not expected right ?
> >>
> >> ||r - wi'hj||^{2} has to be positive definite...
> >>
> >> I think the tests are not running any 0.0 regularization tests otherwise
> >> we
> >> should have caught it as well...
> >>
> >> For the sparse coding NMF variant that I am running, I have to turn off
> L2
> >> regularization when I run a L1 on products to extract sparse topics...
> >>
> >> Thanks.
> >>
> >> Deb
> >>
> >
> >
> >
> > --
> > Liquan Pei
> > Department of Physics
> > University of Massachusetts Amherst
> >
>

--20cf3036392f04e6770505886bc1--

From dev-return-9838-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 15:35:02 2014
Return-Path: <dev-return-9838-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 884AC17BE2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 15:35:02 +0000 (UTC)
Received: (qmail 7721 invoked by uid 500); 16 Oct 2014 15:35:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 7644 invoked by uid 500); 16 Oct 2014 15:35:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 7632 invoked by uid 99); 16 Oct 2014 15:35:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 15:35:01 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 15:34:57 +0000
Received: by mail-lb0-f172.google.com with SMTP id b6so3015451lbj.17
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 08:34:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=hIvgjKNw6tc3CwScfCXxr7TDrj9JtRUVKUzlY/35T70=;
        b=h/DJQx7gEGXF2NkW/ytyCmy/oF4PztqU1DYDl/gOQsdm2sEX2UcV/l2o+PV51ynJsh
         rhF7iixNZxcPkRkY/Kv0jO79VJzE/aIuN07thr+qrAu2lTugg1nQEogwjytB908RnqSP
         WIr+BUiIBZSsEpgjPkKmPkGyl52G20iD35iWgH/DIfDn55iB03cCaGj3rOMgcC4iVYm9
         TWy4oH05ByyY6o4CcD4fLTKsAUaa16snU26tqyEm6K3XgnAEwkGQtLUZL6E6Ru+dREh/
         cVoAbUCQyqRVlsjJLIvhZ6BTOTbUNBWbix//T03V44rZhsm+ST5gmdO1hEZ5xCtWRnnq
         jymg==
MIME-Version: 1.0
X-Received: by 10.152.21.39 with SMTP id s7mr2605152lae.0.1413473676020; Thu,
 16 Oct 2014 08:34:36 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Thu, 16 Oct 2014 08:34:35 -0700 (PDT)
In-Reply-To: <CAMAsSdKk4SyCYTrFuZmpQNA_rjBF8cN-QQyqsMKtaTghY_xCAw@mail.gmail.com>
References: <CA+B-+fxAC6B-1z2GSpib8TeOR_g8CXfkekzaeo+dKQ0ayXuebA@mail.gmail.com>
	<CAJmC80_aaf-D-26s=JSaX9XCpXHSfwk5Vc4vZh4_NBu8fdGc6Q@mail.gmail.com>
	<CA+B-+fwsC_Zvqw_t9uyHc=P3-ie8ytQzJbBjcFEzFvY17p+DyA@mail.gmail.com>
	<CAMAsSdKk4SyCYTrFuZmpQNA_rjBF8cN-QQyqsMKtaTghY_xCAw@mail.gmail.com>
Date: Thu, 16 Oct 2014 08:34:35 -0700
Message-ID: <CA+B-+fxntSB_P=2Dead0ukxj9ONpq2Ei2jsXjY_A+TXJkZdygA@mail.gmail.com>
Subject: Re: Issues with ALS positive definite
From: Debasish Das <debasish.das83@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0141a22c5bd09305058bfc9d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0141a22c5bd09305058bfc9d
Content-Type: text/plain; charset=UTF-8

@xiangrui should we add this epsilon inside ALS code itself ? So that if
user by mistake put 0.0 as regularization, LAPACK failures does not show
up...

@sean For the proximal algorithms I am using Cholesky for L1 and LU for
equality and bound constraints (since the matrix is quasi definite)...I am
right now experimenting with the nesterov acceleration...I should
definitely use QR in place of LU...I am already BLAS solves from netlib
which is not in jblas so this should be fine as well...

Details are over here:

https://github.com/apache/spark/pull/2705


On Thu, Oct 16, 2014 at 4:19 AM, Sean Owen <sowen@cloudera.com> wrote:

> It Gramian is at least positive semidefinite and will be definite if the
> matrix is non singular, yes. That's usually but not always true.
>
> The lambda*I matrix is positive definite, well, when lambda is positive.
> Adding that makes it definite.
>
> At least, lambda=0 could be rejected as invalid.
>
> But this goes back to using the Cholesky decomposition. Why not use QR? It
> doesn't require definite. It should be a little more accurate. On these
> smallish dense matrices I don't think it is much slower. I have not
> benchmarked that but I opted for QR in a different implementation and it
> has worked fine.
>
> Now I have to go hunt for how the QR decomposition is exposed in BLAS...
> Looks like its GEQRF which JBLAS helpfully exposes. Debasish you could try
> it for fun at least.
>  On Oct 15, 2014 8:06 PM, "Debasish Das" <debasish.das83@gmail.com> wrote:
>
>> But do you expect the mllib code to fail if I run with 0.0 regularization
>> ?
>>
>> I think ||r - wi'hj||^{2} is positive definite...It can become positive
>> semi definite only if there are dependent rows in the matrix...
>>
>> @sean is that right ? We had this discussion before as well...
>>
>>
>> On Wed, Oct 15, 2014 at 5:01 PM, Liquan Pei <liquanpei@gmail.com> wrote:
>>
>> > Hi Debaish,
>> >
>> > I think ||r - wi'hj||^{2} is semi-positive definite.
>> >
>> > Thanks,
>> > Liquan
>> >
>> > On Wed, Oct 15, 2014 at 4:57 PM, Debasish Das <debasish.das83@gmail.com
>> >
>> > wrote:
>> >
>> >> Hi,
>> >>
>> >> If I take the Movielens data and run the default ALS with
>> regularization
>> >> as
>> >> 0.0, I am hitting exception from LAPACK that the gram matrix is not
>> >> positive definite. This is on the master branch.
>> >>
>> >> This is how I run it :
>> >>
>> >> ./bin/spark-submit --total-executor-cores 1 --master spark://
>> >> tusca09lmlvt00c.uswin.ad.vzwcorp.com:7077 --jars
>> >>
>> >>
>> /Users/v606014/.m2/repository/com/github/scopt/scopt_2.10/3.2.0/scopt_2.10-3.2.0.jar
>> >> --class org.apache.spark.examples.mllib.MovieLensALS
>> >> ./examples/target/spark-examples_2.10-1.1.0-SNAPSHOT.jar --rank 20
>> >> --numIterations 20 --lambda 0.0 --kryo
>> >> hdfs://localhost:8020/sandbox/movielens/
>> >>
>> >> Error from LAPACK:
>> >>
>> >> WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 22,
>> >> tusca09lmlvt00c.uswin.ad.vzwcorp.com):
>> >> org.jblas.exceptions.LapackArgumentException: LAPACK DPOSV: Leading
>> minor
>> >> of order i of A is not positive definite.
>> >>
>> >> From the maths it's not expected right ?
>> >>
>> >> ||r - wi'hj||^{2} has to be positive definite...
>> >>
>> >> I think the tests are not running any 0.0 regularization tests
>> otherwise
>> >> we
>> >> should have caught it as well...
>> >>
>> >> For the sparse coding NMF variant that I am running, I have to turn
>> off L2
>> >> regularization when I run a L1 on products to extract sparse topics...
>> >>
>> >> Thanks.
>> >>
>> >> Deb
>> >>
>> >
>> >
>> >
>> > --
>> > Liquan Pei
>> > Department of Physics
>> > University of Massachusetts Amherst
>> >
>>
>

--089e0141a22c5bd09305058bfc9d--

From dev-return-9839-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 15:45:24 2014
Return-Path: <dev-return-9839-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B54B217C3B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 15:45:24 +0000 (UTC)
Received: (qmail 36578 invoked by uid 500); 16 Oct 2014 15:45:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36508 invoked by uid 500); 16 Oct 2014 15:45:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36496 invoked by uid 99); 16 Oct 2014 15:45:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 15:45:23 +0000
X-ASF-Spam-Status: No, hits=1.8 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,WEIRD_PORT
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.169 as permitted sender)
Received: from [209.85.217.169] (HELO mail-lb0-f169.google.com) (209.85.217.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 15:44:58 +0000
Received: by mail-lb0-f169.google.com with SMTP id 10so3062196lbg.0
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 08:44:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=IM+QQDxQ5+OmR6xYAbbEjPqfO1pgG/lQdNkW7nC16IQ=;
        b=AeE7WFO9E1i3NG+d4wm6NOGW4eWSM2i5lU7E6SPlcQZNJ//VYTFonKe3nYiftbDMcS
         8jNPK/q4E+aGdTCV2kzHEspaWV8ed64vqfKwn2YMg4koHZWpuU2Hne3yluyqOrpZwbO8
         nTqAOGKZD74u82YTzWM0MgE5hZuvBit/+aQhdXidbFhN8f1gO+jyUZb7Zb+Az+C+Riv3
         h71N9VIIvxPeuES0FJ+7wGtI0mc76Y7Pq1SJYXWbtW9PsVpBfV91T41AUxeZiypvUnFg
         th5czGPNr0Jro/USrZL0hVl28ruZxiFRWtiLc8C0fFV0C4xEjszpWVdC2WotlK/i7c+H
         hg0w==
MIME-Version: 1.0
X-Received: by 10.112.147.199 with SMTP id tm7mr2548965lbb.92.1413474297430;
 Thu, 16 Oct 2014 08:44:57 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Thu, 16 Oct 2014 08:44:57 -0700 (PDT)
In-Reply-To: <CA+B-+fxntSB_P=2Dead0ukxj9ONpq2Ei2jsXjY_A+TXJkZdygA@mail.gmail.com>
References: <CA+B-+fxAC6B-1z2GSpib8TeOR_g8CXfkekzaeo+dKQ0ayXuebA@mail.gmail.com>
	<CAJmC80_aaf-D-26s=JSaX9XCpXHSfwk5Vc4vZh4_NBu8fdGc6Q@mail.gmail.com>
	<CA+B-+fwsC_Zvqw_t9uyHc=P3-ie8ytQzJbBjcFEzFvY17p+DyA@mail.gmail.com>
	<CAMAsSdKk4SyCYTrFuZmpQNA_rjBF8cN-QQyqsMKtaTghY_xCAw@mail.gmail.com>
	<CA+B-+fxntSB_P=2Dead0ukxj9ONpq2Ei2jsXjY_A+TXJkZdygA@mail.gmail.com>
Date: Thu, 16 Oct 2014 08:44:57 -0700
Message-ID: <CA+B-+fzXmxeSOmS7iTVPhg-cBHpBXNQDbHUAuURZnTNEc=uz5A@mail.gmail.com>
Subject: Re: Issues with ALS positive definite
From: Debasish Das <debasish.das83@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a893c65c9be05058c215e
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a893c65c9be05058c215e
Content-Type: text/plain; charset=UTF-8

Just checked, QR is exposed by netlib: import org.netlib.lapack.Dgeqrf

For the equality and bound version, I will use QR...it will be faster than
the LU that I am using through jblas.solveSymmetric...

On Thu, Oct 16, 2014 at 8:34 AM, Debasish Das <debasish.das83@gmail.com>
wrote:

> @xiangrui should we add this epsilon inside ALS code itself ? So that if
> user by mistake put 0.0 as regularization, LAPACK failures does not show
> up...
>
> @sean For the proximal algorithms I am using Cholesky for L1 and LU for
> equality and bound constraints (since the matrix is quasi definite)...I am
> right now experimenting with the nesterov acceleration...I should
> definitely use QR in place of LU...I am already BLAS solves from netlib
> which is not in jblas so this should be fine as well...
>
> Details are over here:
>
> https://github.com/apache/spark/pull/2705
>
>
> On Thu, Oct 16, 2014 at 4:19 AM, Sean Owen <sowen@cloudera.com> wrote:
>
>> It Gramian is at least positive semidefinite and will be definite if the
>> matrix is non singular, yes. That's usually but not always true.
>>
>> The lambda*I matrix is positive definite, well, when lambda is positive.
>> Adding that makes it definite.
>>
>> At least, lambda=0 could be rejected as invalid.
>>
>> But this goes back to using the Cholesky decomposition. Why not use QR?
>> It doesn't require definite. It should be a little more accurate. On these
>> smallish dense matrices I don't think it is much slower. I have not
>> benchmarked that but I opted for QR in a different implementation and it
>> has worked fine.
>>
>> Now I have to go hunt for how the QR decomposition is exposed in BLAS...
>> Looks like its GEQRF which JBLAS helpfully exposes. Debasish you could try
>> it for fun at least.
>>  On Oct 15, 2014 8:06 PM, "Debasish Das" <debasish.das83@gmail.com>
>> wrote:
>>
>>> But do you expect the mllib code to fail if I run with 0.0
>>> regularization ?
>>>
>>> I think ||r - wi'hj||^{2} is positive definite...It can become positive
>>> semi definite only if there are dependent rows in the matrix...
>>>
>>> @sean is that right ? We had this discussion before as well...
>>>
>>>
>>> On Wed, Oct 15, 2014 at 5:01 PM, Liquan Pei <liquanpei@gmail.com> wrote:
>>>
>>> > Hi Debaish,
>>> >
>>> > I think ||r - wi'hj||^{2} is semi-positive definite.
>>> >
>>> > Thanks,
>>> > Liquan
>>> >
>>> > On Wed, Oct 15, 2014 at 4:57 PM, Debasish Das <
>>> debasish.das83@gmail.com>
>>> > wrote:
>>> >
>>> >> Hi,
>>> >>
>>> >> If I take the Movielens data and run the default ALS with
>>> regularization
>>> >> as
>>> >> 0.0, I am hitting exception from LAPACK that the gram matrix is not
>>> >> positive definite. This is on the master branch.
>>> >>
>>> >> This is how I run it :
>>> >>
>>> >> ./bin/spark-submit --total-executor-cores 1 --master spark://
>>> >> tusca09lmlvt00c.uswin.ad.vzwcorp.com:7077 --jars
>>> >>
>>> >>
>>> /Users/v606014/.m2/repository/com/github/scopt/scopt_2.10/3.2.0/scopt_2.10-3.2.0.jar
>>> >> --class org.apache.spark.examples.mllib.MovieLensALS
>>> >> ./examples/target/spark-examples_2.10-1.1.0-SNAPSHOT.jar --rank 20
>>> >> --numIterations 20 --lambda 0.0 --kryo
>>> >> hdfs://localhost:8020/sandbox/movielens/
>>> >>
>>> >> Error from LAPACK:
>>> >>
>>> >> WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 22,
>>> >> tusca09lmlvt00c.uswin.ad.vzwcorp.com):
>>> >> org.jblas.exceptions.LapackArgumentException: LAPACK DPOSV: Leading
>>> minor
>>> >> of order i of A is not positive definite.
>>> >>
>>> >> From the maths it's not expected right ?
>>> >>
>>> >> ||r - wi'hj||^{2} has to be positive definite...
>>> >>
>>> >> I think the tests are not running any 0.0 regularization tests
>>> otherwise
>>> >> we
>>> >> should have caught it as well...
>>> >>
>>> >> For the sparse coding NMF variant that I am running, I have to turn
>>> off L2
>>> >> regularization when I run a L1 on products to extract sparse topics...
>>> >>
>>> >> Thanks.
>>> >>
>>> >> Deb
>>> >>
>>> >
>>> >
>>> >
>>> > --
>>> > Liquan Pei
>>> > Department of Physics
>>> > University of Massachusetts Amherst
>>> >
>>>
>>
>

--047d7b3a893c65c9be05058c215e--

From dev-return-9840-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 16:11:00 2014
Return-Path: <dev-return-9840-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C8CA617D49
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 16:11:00 +0000 (UTC)
Received: (qmail 2702 invoked by uid 500); 16 Oct 2014 16:10:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2632 invoked by uid 500); 16 Oct 2014 16:10:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2616 invoked by uid 99); 16 Oct 2014 16:10:59 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 16:10:59 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=SPF_HELO_PASS,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of Sean.McNamara@webtrends.com designates 216.64.169.22 as permitted sender)
Received: from [216.64.169.22] (HELO pdxmta01.webtrends.com) (216.64.169.22)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 16:10:54 +0000
Received: from pdxex1.webtrends.corp (Not Verified[10.61.2.220]) by pdxmta01.webtrends.com with MailMarshal (v7,2,3,6978) (using TLS: SSLv23)
	id <B543fedfc0000>; Thu, 16 Oct 2014 16:10:36 +0000
Received: from PDXEX2.WebTrends.corp ([172.27.3.221]) by pdxex1.webtrends.corp
 ([172.27.5.220]) with mapi id 14.03.0181.006; Thu, 16 Oct 2014 16:10:33 +0000
From: Sean McNamara <Sean.McNamara@Webtrends.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: accumulators
Thread-Topic: accumulators
Thread-Index: AQHP6Vu2+cZMCPLkiUaV2//jA9CYgw==
Date: Thu, 16 Oct 2014 16:10:32 +0000
Message-ID: <AAF43BA9-9046-44F9-8C96-0A21D0441740@webtrends.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.61.2.4]
Content-Type: text/plain; charset="Windows-1252"
Content-ID: <DB7DD7F476AA844AA3A74D996B922D05@WebTrends.com>
Content-Transfer-Encoding: quoted-printable
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

Accumulators on the stage info page show the rolling life time value of acc=
umulators as well as per task which is handy.  I think it would be useful t=
o add another field to the =93Accumulators=94 table that also shows the tot=
al for the stage you are looking at (basically just a merge of the accumula=
tors for tasks in that stage).  This would be useful for any job that is it=
erative (eg- basically every spark streaming job).

Does this idea make sense?


Separate but related question-  From the operational side I think it could =
be very useful to have an accumulators summary page.  For example we have a=
 spark streaming job with many different stages.  It is difficult to naviga=
te into each stage to pick out a trend.  An accumulators page that allowed =
one to filter by stage description and/or accumulator name would be very us=
eful.

Thoughts?


Thanks,

Sean=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9841-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 18:05:45 2014
Return-Path: <dev-return-9841-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 440861749F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 18:05:45 +0000 (UTC)
Received: (qmail 18838 invoked by uid 500); 16 Oct 2014 18:05:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18769 invoked by uid 500); 16 Oct 2014 18:05:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18758 invoked by uid 99); 16 Oct 2014 18:05:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 18:05:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.174 as permitted sender)
Received: from [209.85.217.174] (HELO mail-lb0-f174.google.com) (209.85.217.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 18:05:18 +0000
Received: by mail-lb0-f174.google.com with SMTP id p9so3298934lbv.33
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 11:05:16 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=8eBpBdJ8deMztA6AmVsN9xZJyCR9K7ZwAAppt1XZduw=;
        b=ESY9pvrFFjkP/EeSzizNs0Y0ckVPtOro5bBO3OAgWktTYUQ1MmbIw+wgjimG4g/L6W
         pIbEBbn22RqRT+fu2Vehano0XmqG2J4aUplFENNkW3PFxq59Z/uzeajZ7YybvWRZA8AE
         qpPs7LWlEIeoW+F7BW/8n1e5LffKp9GUzWTBXo2RbA0pyvb3Rlm8RDYo0wjgLHRKI9h9
         EHppg6QXIMETPkfPoWxVubQcxAj7hTg5RxRjSpxdLJm9SinY2FDRRKkV9Z5+JlYZWg/p
         8z5615wAfy/5w9nhSM+Is6knuO89HAYDSjatx9A+0EMYPq/xZvAtOfKLv2lI/LZzmfH7
         +acg==
X-Gm-Message-State: ALoCoQkZCLSq/V/m79yGcY/M1q5kFfUgiTN5pi7fSsbaR0ItaqkvB0qbc0iJZ8dm8MfhmMuGxfbX
X-Received: by 10.152.28.134 with SMTP id b6mr3595748lah.12.1413482716781;
 Thu, 16 Oct 2014 11:05:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Thu, 16 Oct 2014 11:04:56 -0700 (PDT)
In-Reply-To: <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com> <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 16 Oct 2014 11:04:56 -0700
Message-ID: <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160a6383af3ab05058e1723
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160a6383af3ab05058e1723
Content-Type: text/plain; charset=UTF-8

the bad news is that we've had a couple more failures due to timeouts, but
the good news is that the frequency that these happen has decreased
significantly (3 in the past ~18hr).

seems like the git plugin downgrade has helped relieve the problem, but
hasn't fixed it.  i'll be looking in to this more today.

On Wed, Oct 15, 2014 at 7:05 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> A quick scan through the Spark PR board <https://spark-prs.appspot.com/> shows
> no recent failures related to this git checkout problem.
>
> Looks promising!
>
> Nick
>
> On Wed, Oct 15, 2014 at 6:10 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> ok, we've had about 10 spark pull request builds go through w/o any git
>> timeouts.  it seems that the git timeout issue might be licked.
>>
>> i will be definitely be keeping an eye on this for the next few days.
>>
>> thanks for being patient!
>>
>> shane
>>
>> On Wed, Oct 15, 2014 at 2:27 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>
>> > four builds triggered....  and no timeouts.  :crossestoes:  :)
>> >
>> > On Wed, Oct 15, 2014 at 2:19 PM, shane knapp <sknapp@berkeley.edu>
>> wrote:
>> >
>> >> ok, we're up and building...  :crossesfingersfortheumpteenthtime:
>> >>
>> >> On Wed, Oct 15, 2014 at 1:59 PM, Nicholas Chammas <
>> >> nicholas.chammas@gmail.com> wrote:
>> >>
>> >>> I support this effort. :thumbsup:
>> >>>
>> >>> On Wed, Oct 15, 2014 at 4:52 PM, shane knapp <sknapp@berkeley.edu>
>> >>> wrote:
>> >>>
>> >>>> i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2) to
>> see
>> >>>> if
>> >>>> that helps w/the git fetch timeouts.
>> >>>>
>> >>>> this will require a short downtime (~20 mins for builds to finish,
>> ~20
>> >>>> mins
>> >>>> to downgrade), and will hopefully give us some insight in to wtf is
>> >>>> going
>> >>>> on.
>> >>>>
>> >>>> thanks for your patience...
>> >>>>
>> >>>> shane
>> >>>>
>> >>>
>> >>>  --
>> >>> You received this message because you are subscribed to the Google
>> >>> Groups "amp-infra" group.
>> >>> To unsubscribe from this group and stop receiving emails from it, send
>> >>> an email to amp-infra+unsubscribe@googlegroups.com.
>> >>> For more options, visit https://groups.google.com/d/optout.
>> >>>
>> >>
>> >>
>> >
>>
>
>

--089e0160a6383af3ab05058e1723--

From dev-return-9842-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 18:54:06 2014
Return-Path: <dev-return-9842-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 743B517647
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 18:54:06 +0000 (UTC)
Received: (qmail 47725 invoked by uid 500); 16 Oct 2014 18:54:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47650 invoked by uid 500); 16 Oct 2014 18:54:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47633 invoked by uid 99); 16 Oct 2014 18:54:04 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 18:54:04 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.220.47 as permitted sender)
Received: from [209.85.220.47] (HELO mail-pa0-f47.google.com) (209.85.220.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 18:53:37 +0000
Received: by mail-pa0-f47.google.com with SMTP id rd3so3973833pab.34
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 11:53:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=TVFfs4DCQRcsS8EXBVKpjIoKEMbj+f9Cv5KoCuEMNQE=;
        b=bdlgYmvJZeHNRAHwRafv3S5ntJ0qQTMEnrxggGf3Cef/9IPhbTFsAJU5sLBtuEeiar
         TmSzgF+gHuvh3xefyMwe9rWvk+em/LnTa5MnFOX+INGThqfZpGSQlFu8j5QwiHDZMMGT
         if3PlUds6jXZi/42e7tW2djZ5WaQDRYdsFWbQz0hL4+BlGgNF3reXSFRazIcA8GVnc5O
         +YcL0HJJ7p0HQF4tIXIcerSD5wc/Zjw6m+BdGolZpErc5dvFElAmprH1IeiCiku6Hkq4
         mTkZcn8FC8+J0JrtYsn5VlHJJiNUNQXE7vh/ppq1WWN1pbL7k5/XgCucaLZie7F0ALoo
         utTA==
X-Received: by 10.70.22.195 with SMTP id g3mr3179715pdf.37.1413485615745;
        Thu, 16 Oct 2014 11:53:35 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id rg6sm20469286pdb.20.2014.10.16.11.53.34
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Thu, 16 Oct 2014 11:53:35 -0700 (PDT)
Date: Thu, 16 Oct 2014 11:53:34 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Matthew Cheah <matthew.c.cheah@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, Chester Chen
 <chester@alpinenow.com>, "=?utf-8?Q?dev=40spark.apache.org?="
 <dev@spark.apache.org>
Message-ID: <etPan.5440142e.643c9869.109@joshs-mbp>
In-Reply-To: <CAHH8_ONdGrb5PKwOfzkxrWzS52i5AZBjhvO9bb0s_pu10BCAmw@mail.gmail.com>
References: <CAHH8_OOUkiCefoGj56pe_XEE0dvB5YMYk=TeiTEhURkFsBu1HA@mail.gmail.com>
 <BE0C0820BD164EDC8E03F9D06B188FC5@gmail.com>
 <CAHH8_OP9f34gp64wCMDUEbciM_J8iUrXmi1PnjJ2UONAev5TFA@mail.gmail.com>
 <8BDA8E51AD6244F0AB5B74ABAAD5B550@gmail.com>
 <CAHH8_OOBQ=U+CdMfXhmwk59QDyaex3xbD=pxw30h-miLvGCOoQ@mail.gmail.com>
 <CAPYnQ0XHg6LsqYEOqaJU0mjsyUKzpDzL_oY94YGVy4MwV1BgWw@mail.gmail.com>
 <CAHH8_OO-5HPL+PinU9zQ1iZQdXkAdsBH3T67K7o49DEkeNmW5Q@mail.gmail.com>
 <etPan.543eea61.3d1b58ba.3c30@joshs-mbp>
 <CAHH8_ONdGrb5PKwOfzkxrWzS52i5AZBjhvO9bb0s_pu10BCAmw@mail.gmail.com>
Subject: Re: Unit testing Master-Worker Message Passing
X-Mailer: Airmail Beta (269)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5440142e_66334873_109"
X-Virus-Checked: Checked by ClamAV on apache.org

--5440142e_66334873_109
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Hi Matt,

I=E2=80=99m not sure whether those tests will actually find this specific=
 issue. =C2=A0The tests that I linked to test Spark=E2=80=99s Zookeeper-b=
ased multi-master mode, whereas it sounds like you=E2=80=99re seeing this=
 issue in regular standalone cluster. =C2=A0In those tests, the workers d=
isconnect from the master because we've actually killed the master, where=
as it sounds like your workers are disconnecting due to intermittent netw=
ork issues and you=E2=80=99d like them to reconnect to the same=C2=A0mast=
er.

That =46aultToleranceSuite is not run automatically and I don=E2=80=99t t=
hink that it was designed for automatic use: for example, it doesn=E2=80=99=
t clean up Docker containers after failed tests, doesn=E2=80=99t use a fr=
amework like ScalaTest for structured test result reporting, etc. =C2=A0T=
he new framework that I=E2=80=99m working on will address these issues.

- Josh

On October 15, 2014 at 3:04:42 PM, Matthew Cheah (matthew.c.cheah=40gmail=
.com) wrote:

Thanks Josh=21 These tests seem to cover the cases I'm looking for alread=
y =3D).

What's interesting though is that we still ran into SPARK-3736 despite su=
ch integration tests being in place to catch it - specifically, the case =
when the master disconnects and reconnects, the workers should reconnect =
to the master after the master restarts. Are the tests here run regularly=
, i.e. Jenkins build or nightly build, and if so how did that test case p=
ass while SPARK-3736 apparently still exists=3F

At any rate, I think I'll submit my fix PR but with no particular extra a=
utomated test written for it, since it seems like =46aultToleranceTest su=
fficiently covers what I need.

On Wed, Oct 15, 2014 at 2:42 PM, Josh Rosen <rosenville=40gmail.com> wrot=
e:
There are some end-to-end integration tests of Master <-> Worker fault-to=
lerance in=C2=A0https://github.com/apache/spark/blob/master/core/src/main=
/scala/org/apache/spark/deploy/=46aultToleranceTest.scala

I=E2=80=99ve actually been working to develop a more generalized Docker-b=
ased integration-testing framework for Spark in order to test Master <-> =
Worker interactions.=C2=A0 I=E2=80=99d like to eventually clean up my cod=
e and release it publicly.

On October 15, 2014 at 2:39:22 PM, Matthew Cheah (matthew.c.cheah=40gmail=
.com) wrote:

I think on a higher level I also want to ask why such unit testing has no=
t
actually been done in this codebase. If it's not a common practice to tes=
t
message passing then I'm fine with leaving out the unit test, however I'm=

more curious as to why such testing was not done before.

On Wed, Oct 15, 2014 at 2:18 PM, Chester Chen <chester=40alpinenow.com> w=
rote:

> You can call resolve method on ActorSelection.resolveOne() to see if th=
e
> actor is still there or the path is correct. The method returns a futur=
e
> and you can wait for it with timeout. This way, you know the actor is l=
ive
> or already dead or incorrect.
>
> Another way, is to send Identify method to ActorSystem, if it returns w=
ith
> correct identified message; then you can act on it, otherwise, ...
>
> hope this helps
>
> Chester
>
> On Wed, Oct 15, 2014 at 1:38 PM, Matthew Cheah <matthew.c.cheah=40gmail=
.com>
> wrote:
>
>> What's happening when I do this is that the Worker tries to get the Ma=
ster
>> actor by calling context.actorSelection(), and the RegisterWorker mess=
age
>> gets sent to the dead letters mailbox instead of being picked up by
>> expectMsg. I'm new to Akka and I've tried various ways to registering =
a
>> =22mock=22 master to no avail.
>>
>> I would think there would be at least some kind of test for master -
>> worker
>> message passing, no=3F
>>
>> On Wed, Oct 15, 2014 at 11:28 AM, Nan Zhu <zhunanmcgill=40gmail.com> w=
rote:
>>
>> > I don=E2=80=99t think there are test cases for Worker itself
>> >
>> >
>> > You can
>> >
>> >
>> > val actorRef =3D TestActorRef=5BMaster=5D(Props(classOf=5BMaster=5D,=
 ...))(
>> > actorSystem) actorRef.underlyingActor.receive(Heartbeat)
>>
>> >
>> > and use expectMsg to test if Master can reply correct message by
>> assuming
>> > Worker is absolutely correct
>> >
>> > Then in another test case to test if Worker can send register messag=
e to
>> > Master after receiving Master=E2=80=99s =E2=80=9Cre-register=E2=80=9D=
 instruction, (in this test
>> > case assuming that the Master is absolutely right)
>> >
>> > Best,
>> >
>> > --
>> > Nan Zhu
>> >
>> > On Wednesday, October 15, 2014 at 2:04 PM, Matthew Cheah wrote:
>> >
>> > Thanks, the example was helpful.
>> >
>> > However, testing the Worker itself is a lot more complicated than
>> > WorkerWatcher, since the Worker class is quite a bit more complex. A=
re
>> > there any tests that inspect the Worker itself=3F
>> >
>> > Thanks,
>> >
>> > -Matt Cheah
>> >
>> > On Tue, Oct 14, 2014 at 6:40 PM, Nan Zhu <zhunanmcgill=40gmail.com>
>> wrote:
>> >
>> > You can use akka testkit
>> >
>> > Example:
>> >
>> >
>> >
>> https://github.com/apache/spark/blob/ef4ff00f87a4e8d38866f163f01741c26=
73e41da/core/src/test/scala/org/apache/spark/deploy/worker/WorkerWatcherS=
uite.scala
>> >
>> > --
>> > Nan Zhu
>> >
>> > On Tuesday, October 14, 2014 at 9:17 PM, Matthew Cheah wrote:
>> >
>> > Hi everyone,
>> >
>> > I=E2=80=99m adding some new message passing between the Master and W=
orker
>> actors in
>> > order to address https://issues.apache.org/jira/browse/SPARK-3736 .
>> >
>> > I was wondering if these kinds of interactions are tested in the
>> automated
>> > Jenkins test suite, and if so, where I could find some examples to h=
elp
>> me
>> > do the same.
>> >
>> > Thanks=21
>> >
>> > -Matt Cheah
>> >
>> >
>> >
>> >
>> >
>>
>
>


--5440142e_66334873_109--


From dev-return-9843-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 19:52:35 2014
Return-Path: <dev-return-9843-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9E33E17896
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 19:52:35 +0000 (UTC)
Received: (qmail 88873 invoked by uid 500); 16 Oct 2014 19:52:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88804 invoked by uid 500); 16 Oct 2014 19:52:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88782 invoked by uid 99); 16 Oct 2014 19:52:33 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 19:52:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 19:52:08 +0000
Received: by mail-wi0-f178.google.com with SMTP id h11so408764wiw.5
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 12:52:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=PkyUsvU1ONiPvQgpNeZ6L24M5zz6xoLB4+9HvReQgBI=;
        b=t+a0IGsFibdB7p2RnfQRmzkb5ZHbv9Zyadh4baXu9LS2ssBOmUuEDKw0KHyJoix8IB
         ve2KlOttdxbDNAstfBN36vLtLv2++8q9B0hMQuvUbF7u0jSROzqMjxTCimJvsn/fQQTV
         fD5D5haT8u8NzqrRB7G1gedYDpqEHBSsEjDkNM9/7h5IdYnmCo2fr6o3mZBjanOUjWSo
         Fy/6mTSNweyxYu1J06bR6BAAAiGbOFDta6L0rjNcMhs/KOZcAplh58jbhuggOtDkMhZo
         hke82JbUX9vQiz67jcWVYs+NzS5Bi9BHi3hvDP7RocskjZw3o+yl8iUH3iSEeWiN/BiZ
         t/TQ==
X-Received: by 10.194.2.8 with SMTP id 8mr4664595wjq.85.1413489127416; Thu, 16
 Oct 2014 12:52:07 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Thu, 16 Oct 2014 12:51:26 -0700 (PDT)
In-Reply-To: <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com> <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 16 Oct 2014 15:51:26 -0400
Message-ID: <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a89a455664205058f95c8
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a89a455664205058f95c8
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks for continuing to look into this, Shane.

One suggestion that Patrick brought up, if we have trouble getting to the
bottom of this, is doing the git checkout ourselves in the run-tests-jenkin=
s
script and cutting out the Jenkins git plugin entirely. That way we can
script retries and post friendlier messages about timeouts if they still
occur by ourselves.

Do you think that=E2=80=99s worth trying at some point?

Nick
=E2=80=8B

On Thu, Oct 16, 2014 at 2:04 PM, shane knapp <sknapp@berkeley.edu> wrote:

> the bad news is that we've had a couple more failures due to timeouts, bu=
t
> the good news is that the frequency that these happen has decreased
> significantly (3 in the past ~18hr).
>
> seems like the git plugin downgrade has helped relieve the problem, but
> hasn't fixed it.  i'll be looking in to this more today.
>
> On Wed, Oct 15, 2014 at 7:05 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> A quick scan through the Spark PR board <https://spark-prs.appspot.com/>=
 shows
>> no recent failures related to this git checkout problem.
>>
>> Looks promising!
>>
>> Nick
>>
>> On Wed, Oct 15, 2014 at 6:10 PM, shane knapp <sknapp@berkeley.edu> wrote=
:
>>
>>> ok, we've had about 10 spark pull request builds go through w/o any git
>>> timeouts.  it seems that the git timeout issue might be licked.
>>>
>>> i will be definitely be keeping an eye on this for the next few days.
>>>
>>> thanks for being patient!
>>>
>>> shane
>>>
>>> On Wed, Oct 15, 2014 at 2:27 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>>
>>> > four builds triggered....  and no timeouts.  :crossestoes:  :)
>>> >
>>> > On Wed, Oct 15, 2014 at 2:19 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>> >
>>> >> ok, we're up and building...  :crossesfingersfortheumpteenthtime:
>>> >>
>>> >> On Wed, Oct 15, 2014 at 1:59 PM, Nicholas Chammas <
>>> >> nicholas.chammas@gmail.com> wrote:
>>> >>
>>> >>> I support this effort. :thumbsup:
>>> >>>
>>> >>> On Wed, Oct 15, 2014 at 4:52 PM, shane knapp <sknapp@berkeley.edu>
>>> >>> wrote:
>>> >>>
>>> >>>> i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2) t=
o
>>> see
>>> >>>> if
>>> >>>> that helps w/the git fetch timeouts.
>>> >>>>
>>> >>>> this will require a short downtime (~20 mins for builds to finish,
>>> ~20
>>> >>>> mins
>>> >>>> to downgrade), and will hopefully give us some insight in to wtf i=
s
>>> >>>> going
>>> >>>> on.
>>> >>>>
>>> >>>> thanks for your patience...
>>> >>>>
>>> >>>> shane
>>> >>>>
>>> >>>
>>> >>>  --
>>> >>> You received this message because you are subscribed to the Google
>>> >>> Groups "amp-infra" group.
>>> >>> To unsubscribe from this group and stop receiving emails from it,
>>> send
>>> >>> an email to amp-infra+unsubscribe@googlegroups.com.
>>> >>> For more options, visit https://groups.google.com/d/optout.
>>> >>>
>>> >>
>>> >>
>>> >
>>>
>>
>>
>

--047d7b3a89a455664205058f95c8--

From dev-return-9844-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 19:56:39 2014
Return-Path: <dev-return-9844-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0591F178BB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 19:56:39 +0000 (UTC)
Received: (qmail 97469 invoked by uid 500); 16 Oct 2014 19:56:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97400 invoked by uid 500); 16 Oct 2014 19:56:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97388 invoked by uid 99); 16 Oct 2014 19:56:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 19:56:36 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 19:56:32 +0000
Received: by mail-la0-f51.google.com with SMTP id ge10so3511017lab.24
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 12:56:11 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=qKwoxMA54txxgNBEikGxXFsf+C+bm/WkVh+AtFGs+fE=;
        b=ODn325JLHuZ/sqc97ZQsWkZxL5mqiDBMZ2nsUsppYwaBavqJfVC/3NKpai5c/e5KWL
         gmgJ97xEqxsYhLds7nOBCUPXhr8DVrwrHXK3wRF6sf1K+APmGaSnIkfxZwRuSTyuUccs
         4vZwJXyjKGBsCMWVrc8ZCw1n9As5XyeUohnxILJa8NMrigiqdzQnsV4b/TG9cXywjkEn
         +JVwv9YCBvdhvDjdicbFmr2WoyBdV0WzAQnHibBgOTvSeQbAOIgphSKl3erWWZfewjqS
         aytECuyoUoSZb33bVJ2n/0J/3inoS3AcA/wndPXvdCLyWPvf6q8wArMfr2ix7vj2Clu1
         rpNQ==
X-Gm-Message-State: ALoCoQkygRV8gD4LcTX+vb4yr1Ip8iVD3FO//bLYtFkNDYt/Ri+L951X9iKwC6FNFzA2s0wha/5p
X-Received: by 10.152.22.194 with SMTP id g2mr3946790laf.33.1413489370565;
 Thu, 16 Oct 2014 12:56:10 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Thu, 16 Oct 2014 12:55:50 -0700 (PDT)
In-Reply-To: <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
 <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com> <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Thu, 16 Oct 2014 12:55:50 -0700
Message-ID: <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0158b61cd3a08505058fa334
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0158b61cd3a08505058fa334
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

yeah, at this point it might be worth trying.  :)

the absolutely irritating thing is that i am not seeing this happen w/any
other jobs other that the spark prb, nor does it seem to correlate w/time
of day, network or system load, or what slave it runs on.  nor are we
hitting our limit of connections on github.  i really, truly hate
non-deterministic failures.

i'm also going to write an email to support@github and see if they have any
insight in to this as well.

On Thu, Oct 16, 2014 at 12:51 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> Thanks for continuing to look into this, Shane.
>
> One suggestion that Patrick brought up, if we have trouble getting to the
> bottom of this, is doing the git checkout ourselves in the
> run-tests-jenkins script and cutting out the Jenkins git plugin entirely.
> That way we can script retries and post friendlier messages about timeout=
s
> if they still occur by ourselves.
>
> Do you think that=E2=80=99s worth trying at some point?
>
> Nick
> =E2=80=8B
>
> On Thu, Oct 16, 2014 at 2:04 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> the bad news is that we've had a couple more failures due to timeouts,
>> but the good news is that the frequency that these happen has decreased
>> significantly (3 in the past ~18hr).
>>
>> seems like the git plugin downgrade has helped relieve the problem, but
>> hasn't fixed it.  i'll be looking in to this more today.
>>
>> On Wed, Oct 15, 2014 at 7:05 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> A quick scan through the Spark PR board <https://spark-prs.appspot.com/=
> shows
>>> no recent failures related to this git checkout problem.
>>>
>>> Looks promising!
>>>
>>> Nick
>>>
>>> On Wed, Oct 15, 2014 at 6:10 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>>
>>>> ok, we've had about 10 spark pull request builds go through w/o any gi=
t
>>>> timeouts.  it seems that the git timeout issue might be licked.
>>>>
>>>> i will be definitely be keeping an eye on this for the next few days.
>>>>
>>>> thanks for being patient!
>>>>
>>>> shane
>>>>
>>>> On Wed, Oct 15, 2014 at 2:27 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>>
>>>> > four builds triggered....  and no timeouts.  :crossestoes:  :)
>>>> >
>>>> > On Wed, Oct 15, 2014 at 2:19 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>> >
>>>> >> ok, we're up and building...  :crossesfingersfortheumpteenthtime:
>>>> >>
>>>> >> On Wed, Oct 15, 2014 at 1:59 PM, Nicholas Chammas <
>>>> >> nicholas.chammas@gmail.com> wrote:
>>>> >>
>>>> >>> I support this effort. :thumbsup:
>>>> >>>
>>>> >>> On Wed, Oct 15, 2014 at 4:52 PM, shane knapp <sknapp@berkeley.edu>
>>>> >>> wrote:
>>>> >>>
>>>> >>>> i'm going to be downgrading our git plugin (from 2.2.7 to 2.2.2)
>>>> to see
>>>> >>>> if
>>>> >>>> that helps w/the git fetch timeouts.
>>>> >>>>
>>>> >>>> this will require a short downtime (~20 mins for builds to finish=
,
>>>> ~20
>>>> >>>> mins
>>>> >>>> to downgrade), and will hopefully give us some insight in to wtf =
is
>>>> >>>> going
>>>> >>>> on.
>>>> >>>>
>>>> >>>> thanks for your patience...
>>>> >>>>
>>>> >>>> shane
>>>> >>>>
>>>> >>>
>>>> >>>  --
>>>> >>> You received this message because you are subscribed to the Google
>>>> >>> Groups "amp-infra" group.
>>>> >>> To unsubscribe from this group and stop receiving emails from it,
>>>> send
>>>> >>> an email to amp-infra+unsubscribe@googlegroups.com.
>>>> >>> For more options, visit https://groups.google.com/d/optout.
>>>> >>>
>>>> >>
>>>> >>
>>>> >
>>>>
>>>
>>>
>>
>

--089e0158b61cd3a08505058fa334--

From dev-return-9845-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 16 20:05:50 2014
Return-Path: <dev-return-9845-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 236F7178FF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 16 Oct 2014 20:05:50 +0000 (UTC)
Received: (qmail 24316 invoked by uid 500); 16 Oct 2014 20:05:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 24243 invoked by uid 500); 16 Oct 2014 20:05:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24231 invoked by uid 99); 16 Oct 2014 20:05:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 20:05:48 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.48 as permitted sender)
Received: from [74.125.82.48] (HELO mail-wg0-f48.google.com) (74.125.82.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 16 Oct 2014 20:05:44 +0000
Received: by mail-wg0-f48.google.com with SMTP id k14so4539789wgh.19
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 13:05:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=4DJtdkPCIgJTGYXqrtIS3SpzCVE5McGgEcZvlK0kay0=;
        b=cft/4hErDaIKdICrkz3k2dY4+RrXDJMZxUFB3zmXpzi7qe+4s9PLzaRP0IThLgK8RD
         JzGgC1KQCuJ4P2wSiS46ZREoiQBZuKJA8LjvtZ7NR2RNbjjE4Zuzsc57KmcB1cQSzoyH
         cGQId0tQGYycdj2yCLTj8JWxSUso2+9Jki07FEH9WZ/E7TeqQsdUhnq1fDylf3aTwdjQ
         hSzb/eCOOOUGzTMrOmKp/0EtqKMDKi7UBl6xuxWbn6tdiR6xQrXwsrOjGyUnw7KoeD6P
         djmQtQf8zBS9fv4US6iJlYZJ08dzJb+Cp9GS1bwLhMw3wTdnl/FHeGpj0Ayou/M6Aa74
         QxnA==
X-Received: by 10.180.91.11 with SMTP id ca11mr23410588wib.45.1413489923829;
 Thu, 16 Oct 2014 13:05:23 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Thu, 16 Oct 2014 13:04:43 -0700 (PDT)
In-Reply-To: <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
 <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
 <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com> <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Thu, 16 Oct 2014 16:04:43 -0400
Message-ID: <CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043c7e76cdb37605058fc4d4
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c7e76cdb37605058fc4d4
Content-Type: text/plain; charset=UTF-8

On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu> wrote:

> i really, truly hate non-deterministic failures.


Amen bruddah.

--f46d043c7e76cdb37605058fc4d4--

From dev-return-9846-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 17 06:26:19 2014
Return-Path: <dev-return-9846-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 843A710B65
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 17 Oct 2014 06:26:19 +0000 (UTC)
Received: (qmail 50843 invoked by uid 500); 17 Oct 2014 06:26:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50770 invoked by uid 500); 17 Oct 2014 06:26:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50758 invoked by uid 99); 17 Oct 2014 06:26:18 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 06:26:18 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.53 as permitted sender)
Received: from [209.85.215.53] (HELO mail-la0-f53.google.com) (209.85.215.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 06:25:51 +0000
Received: by mail-la0-f53.google.com with SMTP id gq15so130211lab.26
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 23:25:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=Yt5jHUOLnyEzn3DUbpDCWPnVTmsLUC7ughUgfqujF60=;
        b=quztEGXyFroUOUiNafs5mwBJ1uYsEo+GvJ25t40VRYmTZPTuyF4rHM63WJSMIjKxsP
         rE416WVse3+lpNRtKla/YKlMrNYr2ac1CtENWf5xVEQtvWZ5izfMIeff1mD8X7lz0XUN
         4iz+rtxNdrFADUvWvLqUgltiN2lLDnSdpXG9SUZn+tdlL2iXA5IkTKujcGhfFF1K8Hoa
         ZoP9mgtSAlzx3og+2Nxui1UXFsVlmIlE63+SgheIkFGUIpNWT/WsHpqfoehbnV3R/0jK
         fNhb5MRD8krfMcWd5uR8lGFvayz73o2ym+R95XKL8ZG+uiVfQxTMeqNHeBbyf95xEevk
         WFgQ==
MIME-Version: 1.0
X-Received: by 10.112.200.9 with SMTP id jo9mr6444828lbc.82.1413527150771;
 Thu, 16 Oct 2014 23:25:50 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Thu, 16 Oct 2014 23:25:50 -0700 (PDT)
Date: Thu, 16 Oct 2014 23:25:50 -0700
Message-ID: <CA+B-+fyMLpXhqiFj+aojq_Gj1Qt0bW_Dpm7V=nXnCnda=_WZhA@mail.gmail.com>
Subject: NNLS bug
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c371c2b3c3bb0505986f87
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c371c2b3c3bb0505986f87
Content-Type: text/plain; charset=UTF-8

Hi,

I am validating the proximal algorithm for positive and bound constrained
ALS and I came across the bug detailed in the JIRA while running ALS with
NNLS:

https://issues.apache.org/jira/browse/SPARK-3987

ADMM based proximal algorithm came up with correct result...

Thanks.
Deb

--001a11c371c2b3c3bb0505986f87--

From dev-return-9847-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 17 06:54:07 2014
Return-Path: <dev-return-9847-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2EB6510C2E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 17 Oct 2014 06:54:07 +0000 (UTC)
Received: (qmail 5651 invoked by uid 500); 17 Oct 2014 06:54:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5584 invoked by uid 500); 17 Oct 2014 06:54:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5557 invoked by uid 99); 17 Oct 2014 06:54:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 06:54:05 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.223.180 as permitted sender)
Received: from [209.85.223.180] (HELO mail-ie0-f180.google.com) (209.85.223.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 06:53:59 +0000
Received: by mail-ie0-f180.google.com with SMTP id x19so186366ier.11
        for <dev@spark.apache.org>; Thu, 16 Oct 2014 23:53:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Hqyj3gzbAYNLJZ7q4VSPa89wMfq37EKo4ZDy0YAYc/Y=;
        b=s9Ff95m0xU2oRHq6Mm81viAzDZqrnzyFHqL8s9WEVogrLaj+UUBEthw3DT5QZgb6DX
         fOEdnIQtT9Mm9QFTZZvrkpI8/JeVKvhlE0c1KsRnCe2nNrrNXMsNODo8GFcpMc9EhMmy
         XbsufLpvwtrdaddrbwIKspTuPix+aYIV28d3aja9pPTG0hdcdXtDCoPlOf4Gs2M6jU46
         1uZ05f0ZZmZ86VmBGmGWWGOwZ43K4p8ceFKbaKOaEO5cv39xIeW8ho48L3ZHKKfs4bwR
         RvzXTxqjeUm2a8YQzxJyHjFWlO7yseHwVKpfHsHd5jKTIdrNSNzDztSZ96JaJ9Y3u1Sm
         SZkw==
MIME-Version: 1.0
X-Received: by 10.51.16.65 with SMTP id fu1mr10491114igd.18.1413528819183;
 Thu, 16 Oct 2014 23:53:39 -0700 (PDT)
Received: by 10.107.162.21 with HTTP; Thu, 16 Oct 2014 23:53:39 -0700 (PDT)
In-Reply-To: <CA+B-+fyMLpXhqiFj+aojq_Gj1Qt0bW_Dpm7V=nXnCnda=_WZhA@mail.gmail.com>
References: <CA+B-+fyMLpXhqiFj+aojq_Gj1Qt0bW_Dpm7V=nXnCnda=_WZhA@mail.gmail.com>
Date: Thu, 16 Oct 2014 23:53:39 -0700
Message-ID: <CAJgQjQ8nAukv3dgxC0k37R0f-EhO=GpwtJjPq4gYe8Qfc-W5fQ@mail.gmail.com>
Subject: Re: NNLS bug
From: Xiangrui Meng <mengxr@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks for reporting the bug! I will take a look. -Xiangrui

On Thu, Oct 16, 2014 at 11:25 PM, Debasish Das <debasish.das83@gmail.com> wrote:
> Hi,
>
> I am validating the proximal algorithm for positive and bound constrained
> ALS and I came across the bug detailed in the JIRA while running ALS with
> NNLS:
>
> https://issues.apache.org/jira/browse/SPARK-3987
>
> ADMM based proximal algorithm came up with correct result...
>
> Thanks.
> Deb

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9848-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 17 19:13:33 2014
Return-Path: <dev-return-9848-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DFA171791F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 17 Oct 2014 19:13:33 +0000 (UTC)
Received: (qmail 28782 invoked by uid 500); 17 Oct 2014 19:13:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28712 invoked by uid 500); 17 Oct 2014 19:13:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28700 invoked by uid 99); 17 Oct 2014 19:13:32 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 19:13:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.44 as permitted sender)
Received: from [74.125.82.44] (HELO mail-wg0-f44.google.com) (74.125.82.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 19:13:07 +0000
Received: by mail-wg0-f44.google.com with SMTP id y10so1559212wgg.3
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 12:13:06 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=irPuv1LM/w9LLJc9vjKLykgA2TgcvjxKCc3pBtVGqa8=;
        b=qMHJzycmkotiWqB+q5mIL2Ye0C28bIvWk17517FqLTWZNe5eygxo2+1Bi9WZ96SebV
         NFgKuxBlJMZKfxIqquPh4tLETRJICy8IaQHx+Cw4G28Iaeo56m+WjbISa41vVe2bMojj
         XEJ9lGDmAi9SZLgo+msUkuk0+fHAiuBM41NLrFWgUY4o+s6p1jN2BtRKwcs9trNSrYkL
         jcN+wgs5wsEfuHKLVDLXy43vuWxXItizZOc1d/VY7bJdu2LV4KnaD5P/mMwpu61D4KRD
         AyP9Y0MxZGnqklFagexcppS0GFrpufmfUnyAHbQixbHbyCKtboQ0idGyz5XvMBnjK+6s
         sZPw==
MIME-Version: 1.0
X-Received: by 10.194.92.12 with SMTP id ci12mr12666179wjb.6.1413573186826;
 Fri, 17 Oct 2014 12:13:06 -0700 (PDT)
Received: by 10.180.99.70 with HTTP; Fri, 17 Oct 2014 12:13:06 -0700 (PDT)
Date: Fri, 17 Oct 2014 15:13:06 -0400
Message-ID: <CAOhmDzf7mZ7oZSOye=zMwT_bmYapTK3f8YDG6Yf_fUTMGQxxgg@mail.gmail.com>
Subject: Using Docker to Parallelize Tests
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bfd08baaa39bf0505a32757
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bfd08baaa39bf0505a32757
Content-Type: text/plain; charset=UTF-8

https://news.ycombinator.com/item?id=8471812

The parent thread has lots of interesting use cases for Docker, and the
linked comment seems most relevant to our testing predicament.

I might look into this after I finish something presentable with Packer and
our EC2 scripts, but if anyone else is interested, by all means...

Nick

--047d7bfd08baaa39bf0505a32757--

From dev-return-9849-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 17 21:31:30 2014
Return-Path: <dev-return-9849-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7275017E36
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 17 Oct 2014 21:31:30 +0000 (UTC)
Received: (qmail 57816 invoked by uid 500); 17 Oct 2014 21:31:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57738 invoked by uid 500); 17 Oct 2014 21:31:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57727 invoked by uid 99); 17 Oct 2014 21:31:29 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 21:31:29 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.213.173] (HELO mail-ig0-f173.google.com) (209.85.213.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 21:31:25 +0000
Received: by mail-ig0-f173.google.com with SMTP id h18so2359614igc.12
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 14:31:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:date:from:to:message-id:in-reply-to:references
         :subject:mime-version:content-type;
        bh=UfT4pR2m+yGtj6kiQUk67B78MCcRwAWWeCrAr5ZWufU=;
        b=byfFp5rl2GyoNDMcK2NXLUGAYpn+rYOJ8LSyWv+vhiJW7M6Hot4J059M1zG0lWpfrN
         jVDioR7DZzrjxOU47zx8/RTzx32MDZSQ/i69YjScp8DWT5CYFdto1IRpsjvqO1NGzsMp
         acKQhFDbhyhvHUh8pDs3A4gSCNFNvRwvfC3njOGSzaEmk1XWa0t3UE3rlTBNCawJfAkq
         /k6ZHg9J5iiZvgTL/B5eGShqnEnLCEumE3eaGF7Pp9tBJ+OGCPIdqeJb6TTaKzkr3YSt
         SlslusQnHRDKKofo0bpT8NaEkIsY+z/lCYZhGpMBcUJHwM4Inr8emoc9+00McYIj32Cd
         ljjw==
X-Gm-Message-State: ALoCoQmQyZgWjsRLd0urMvZhqbOJWdtAm3fEQhWe3ZbbgFv9v/oUZjzxTIUplYugvc1zO3zJxHWD
X-Received: by 10.107.128.34 with SMTP id b34mr4669666iod.85.1413581464068;
        Fri, 17 Oct 2014 14:31:04 -0700 (PDT)
Received: from rxin-mbp.local ([2600:1001:b102:778:bae8:56ff:fe47:4f4])
        by mx.google.com with ESMTPSA id a192sm1122566ioa.34.2014.10.17.14.31.02
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Fri, 17 Oct 2014 14:31:03 -0700 (PDT)
Date: Fri, 17 Oct 2014 17:31:01 -0400
From: Reynold Xin <rxin@databricks.com>
To: Sean McNamara <sean.mcnamara@webtrends.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <etPan.54418a95.238e1f29.302c@rxin-mbp.local>
In-Reply-To: <AAF43BA9-9046-44F9-8C96-0A21D0441740@webtrends.com>
References: <AAF43BA9-9046-44F9-8C96-0A21D0441740@webtrends.com>
Subject: Re: accumulators
X-Mailer: Airmail Beta (269)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="54418a95_46e87ccd_302c"
X-Virus-Checked: Checked by ClamAV on apache.org

--54418a95_46e87ccd_302c
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

It certainly makes sense for a single streaming job. But it is definitely=
 non-trivial to make this useful to all Spark programs. If I were to have=
 a long running SParkContext and submit a wide variety of jobs to it, thi=
s would make the list of accumulators very, very large. Maybe the solutio=
n is to have pagination of these and always sort them by the last update =
time.

--=C2=A0
Reynold Xin


On October 16, 2014 at 12:11:00 PM, Sean McNamara (sean.mcnamara=40webtre=
nds.com) wrote:

Accumulators on the stage info page show the rolling life time value of a=
ccumulators as well as per task which is handy. I think it would be usefu=
l to add another field to the =E2=80=9CAccumulators=E2=80=9D table that a=
lso shows the total for the stage you are looking at (basically just a me=
rge of the accumulators for tasks in that stage). This would be useful fo=
r any job that is iterative (eg- basically every spark streaming job). =20

Does this idea make sense=3F =20


Separate but related question- =46rom the operational side I think it cou=
ld be very useful to have an accumulators summary page. =46or example we =
have a spark streaming job with many different stages. It is difficult to=
 navigate into each stage to pick out a trend. An accumulators page that =
allowed one to filter by stage description and/or accumulator name would =
be very useful. =20

Thoughts=3F =20


Thanks, =20

Sean =20
--------------------------------------------------------------------- =20
To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
=46or additional commands, e-mail: dev-help=40spark.apache.org =20


--54418a95_46e87ccd_302c--


From dev-return-9850-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 17 22:23:47 2014
Return-Path: <dev-return-9850-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BF2B318000
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 17 Oct 2014 22:23:47 +0000 (UTC)
Received: (qmail 91252 invoked by uid 500); 17 Oct 2014 22:23:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91184 invoked by uid 500); 17 Oct 2014 22:23:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91172 invoked by uid 99); 17 Oct 2014 22:23:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 22:23:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of freeman.jeremy@gmail.com designates 209.85.220.45 as permitted sender)
Received: from [209.85.220.45] (HELO mail-pa0-f45.google.com) (209.85.220.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 22:23:21 +0000
Received: by mail-pa0-f45.google.com with SMTP id rd3so1592246pab.18
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 15:23:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:content-type:subject:message-id:date:to:mime-version;
        bh=Gt5nXdtY9SFPkdEG/cWIOk77XFWyXKJ0zAQ5iBW8Dlc=;
        b=hGfNRFFfZruX/vjophUfAZzVDDrfNsxcAF8eNQVvd49sZ92emeyEA0BQzQt4XBQi+F
         uYaYWlsk9tB0wv9cMx8MSAnmdt3aXAOz40gr/hD8lC6S2RIotgb0lZqJwGUOpYuoUTDG
         Uheq1JfJwwFAITMbSUuo68jxd2c/A9Ud4yR/pHemQYlIrVGMXxD/nb1tOfiNuCNV6tNF
         FYXtjDhGF19js1uoMf+0+6VLLXKj5Ld4opTucA6RRoyBJP8Z5nCuKspdQpe5W1ktPUD6
         FvdLPstVZqHPaETB4EWAjbulGS9Eu73y1+UrNzBnaJhL8N4cb6cKfca+BxQ6VVcOhMrA
         1O0A==
X-Received: by 10.68.129.103 with SMTP id nv7mr11492571pbb.56.1413584599445;
        Fri, 17 Oct 2014 15:23:19 -0700 (PDT)
Received: from [172.20.10.5] (mobile-166-171-248-114.mycingular.net. [166.171.248.114])
        by mx.google.com with ESMTPSA id al4sm2440112pbc.19.2014.10.17.15.23.17
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 17 Oct 2014 15:23:18 -0700 (PDT)
From: Jeremy Freeman <freeman.jeremy@gmail.com>
Content-Type: multipart/alternative; boundary="Apple-Mail=_5A27A52E-D5F7-4BB0-9201-5B0AFCB4DC46"
Subject: sampling broken in PySpark with recent NumPy
Message-Id: <3DB010C1-F424-4650-AB42-38E3FFDB9EED@gmail.com>
Date: Fri, 17 Oct 2014 18:23:15 -0400
To: dev@spark.apache.org
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_5A27A52E-D5F7-4BB0-9201-5B0AFCB4DC46
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=windows-1252

Hi all,

I found a significant bug in PySpark's sampling methods, due to a recent =
NumPy change (as of v1.9). I created a JIRA =
(https://issues.apache.org/jira/browse/SPARK-3995), but wanted to share =
here as well in case anyone hits it.

Steps to reproduce are:

> foo =3D sc.parallelize(range(1000),5)
> foo.takeSample(False, 10)

Which returns:

> PythonException: Traceback (most recent call last):
>   File =
"/Users/freemanj11/code/spark-1.1.0-bin-hadoop1/python/pyspark/worker.py",=
 line 79, in main
>     serializer.dump_stream(func(split_index, iterator), outfile)
>   File =
"/Users/freemanj11/code/spark-1.1.0-bin-hadoop1/python/pyspark/serializers=
.py", line 196, in dump_stream
>     self.serializer.dump_stream(self._batched(iterator), stream)
>   File =
"/Users/freemanj11/code/spark-1.1.0-bin-hadoop1/python/pyspark/serializers=
.py", line 127, in dump_stream
>     for obj in iterator:
>   File =
"/Users/freemanj11/code/spark-1.1.0-bin-hadoop1/python/pyspark/serializers=
.py", line 185, in _batched
>     for item in iterator:
>   File =
"/Users/freemanj11/code/spark-1.1.0-bin-hadoop1/python/pyspark/rddsampler.=
py", line 116, in func
>     if self.getUniformSample(split) <=3D self._fraction:
>   File =
"/Users/freemanj11/code/spark-1.1.0-bin-hadoop1/python/pyspark/rddsampler.=
py", line 58, in getUniformSample
>     self.initRandomGenerator(split)
>   File =
"/Users/freemanj11/code/spark-1.1.0-bin-hadoop1/python/pyspark/rddsampler.=
py", line 44, in initRandomGenerator
>     self._random =3D numpy.random.RandomState(self._seed)
>   File "mtrand.pyx", line 610, in mtrand.RandomState.__init__ =
(numpy/random/mtrand/mtrand.c:7397)
>   File "mtrand.pyx", line 646, in mtrand.RandomState.seed =
(numpy/random/mtrand/mtrand.c:7697)
> ValueError: Seed must be between 0 and 4294967295

The problem is that NumPy used to silently truncate random seeds larger =
than 2 ** 32, but now throws an error (due to this patch: =
https://github.com/numpy/numpy/commit/6b1a1205eac6fe5d162f16155d500765e8bc=
a53c). And this reliably breaks our sampling. I=92ll put a PR in shortly =
with the fix.

=97 Jeremy

-------------------------
jeremyfreeman.net
@thefreemanlab


--Apple-Mail=_5A27A52E-D5F7-4BB0-9201-5B0AFCB4DC46--

From dev-return-9851-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 17 23:44:54 2014
Return-Path: <dev-return-9851-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6681417414
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 17 Oct 2014 23:44:54 +0000 (UTC)
Received: (qmail 43028 invoked by uid 500); 17 Oct 2014 23:44:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42953 invoked by uid 500); 17 Oct 2014 23:44:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42942 invoked by uid 99); 17 Oct 2014 23:44:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 23:44:53 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.45 as permitted sender)
Received: from [209.85.215.45] (HELO mail-la0-f45.google.com) (209.85.215.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 23:44:48 +0000
Received: by mail-la0-f45.google.com with SMTP id q1so1491110lam.4
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 16:44:27 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=2G9bS8NSZvLrcmzbSmQ2uyqwOUPbQ/RMVpyQqeorS28=;
        b=jcp2phXEwMgqoNXAhL3JhXLbQI/Iw2PM9ci7q/N3xHGfCm4GP/pUTWiZxz/kuOg9d7
         R9KsAgVtI491zV6Rm4uOuCvyL3vxHzyNfSHKvN9nGcsoPQspV8S7EybrGc5lcgSLSJRt
         H2wGZAUM71Xn/YBBmLitciyv350IpFEmIENOcoPgLSdSibxuCq9LYNnjWB87KG+/5vOM
         S8pHnfRaYfDREyS45cZfMilhOwxIA4DURcNi0aUrwDBRTEY7/0/sVcwMDu7iopc/hWr6
         qlNVn95kiYXBU1GiQD4Stmoi29nIhS515cMkjcA9G5Xskj8o/sBIVhHIKmohxNjPS85/
         B55Q==
X-Gm-Message-State: ALoCoQnpGEfSf3ecevp3DU9AX2BqGqXP5ZDUqoysVL5Fbzd5wclYn58sw47l9QKq1YHOKj2J1vH8
X-Received: by 10.152.206.36 with SMTP id ll4mr12181696lac.64.1413589466685;
 Fri, 17 Oct 2014 16:44:26 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Fri, 17 Oct 2014 16:44:06 -0700 (PDT)
In-Reply-To: <CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
 <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
 <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
 <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com> <CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 17 Oct 2014 16:44:06 -0700
Message-ID: <CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133b742052f880505a6f2a0
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133b742052f880505a6f2a0
Content-Type: text/plain; charset=UTF-8

quick update:

here are some stats i scraped over the past week of ALL pull request
builder projects and timeout failures.  due to the large number of spark
ghprb jobs, i don't have great records earlier than oct 7th.  the data is
current up until ~230pm today:

spark and new spark ghprb total builds vs git fetch timeouts:
$ for x in 10-{09..17}; do passed=$(grep $x SORTED.passed | grep -i spark |
wc -l); failed=$(grep $x SORTED | grep -i spark | wc -l); let
total=passed+failed; fail_percent=$(echo "scale=2; $failed/$total" | bc |
sed "s/^\.//g"); line="$x -- total builds: $total\tp/f:
 $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
10-09 -- total builds: 140 p/f: 92/48 fail%: 34%
10-10 -- total builds: 65 p/f: 59/6 fail%: 09%
10-11 -- total builds: 29 p/f: 29/0 fail%: 0%
10-12 -- total builds: 24 p/f: 21/3 fail%: 12%
10-13 -- total builds: 39 p/f: 35/4 fail%: 10%
10-14 -- total builds: 7 p/f: 5/2 fail%: 28%
10-15 -- total builds: 37 p/f: 34/3 fail%: 08%
10-16 -- total builds: 71 p/f: 59/12 fail%: 16%
10-17 -- total builds: 26 p/f: 20/6 fail%: 23%

all other ghprb builds vs git fetch timeouts:
$ for x in 10-{09..17}; do passed=$(grep $x SORTED.passed | grep -vi spark
| wc -l); failed=$(grep $x SORTED | grep -vi spark | wc -l); let
total=passed+failed; fail_percent=$(echo "scale=2; $failed/$total" | bc |
sed "s/^\.//g"); line="$x -- total builds: $total\tp/f:
 $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
10-09 -- total builds: 16 p/f: 16/0 fail%: 0%
10-10 -- total builds: 46 p/f: 40/6 fail%: 13%
10-11 -- total builds: 4 p/f: 4/0 fail%: 0%
10-12 -- total builds: 2 p/f: 2/0 fail%: 0%
10-13 -- total builds: 2 p/f: 2/0 fail%: 0%
10-14 -- total builds: 10 p/f: 10/0 fail%: 0%
10-15 -- total builds: 5 p/f: 5/0 fail%: 0%
10-16 -- total builds: 5 p/f: 5/0 fail%: 0%
10-17 -- total builds: 0 p/f: 0/0 fail%: 0%

note:  the 15th was the day i rolled back to the earlier version of the git
plugin.  it doesn't seem to have helped much, so i'll probably bring us
back up to the latest version soon.
also note:  rocking some floating point math on the CLI!  ;)

i also compared the distribution of git timeout failures vs time of day,
and there appears to be no correlation.  the failures are pretty evenly
distributed over each hour of the day.

we could be hitting the rate limit due to the ghprb hitting github a couple
of times for each build, but we're averaging ~10-20 builds per hour (a
build hits github 2-4 times, from what i can tell).  i'll have to look more
in to this on monday, but suffice to say we may need to move from
unauthorized https fetches to authorized requests.  this means retrofitting
all of our jobs.  yay!  fun!  :)

another option is to have local mirrors of all of the repos.  the problem
w/this is that there might be a window where changes haven't made it to the
local mirror and tests run against it.  more fun stuff to think about...

now that i have some stats, and a list of all of the times/dates of the
failures, i will be drafting my email to github and firing that off later
today or first thing monday.

have a great weekend everyone!

shane, who spent way too much time on the CLI and is ready for some beer.

On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> i really, truly hate non-deterministic failures.
>
>
> Amen bruddah.
>

--001a1133b742052f880505a6f2a0--

From dev-return-9852-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 17 23:53:15 2014
Return-Path: <dev-return-9852-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B8F3F1744D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 17 Oct 2014 23:53:15 +0000 (UTC)
Received: (qmail 62118 invoked by uid 500); 17 Oct 2014 23:53:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62047 invoked by uid 500); 17 Oct 2014 23:53:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62032 invoked by uid 99); 17 Oct 2014 23:53:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 23:53:14 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.45 as permitted sender)
Received: from [74.125.82.45] (HELO mail-wg0-f45.google.com) (74.125.82.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 17 Oct 2014 23:52:48 +0000
Received: by mail-wg0-f45.google.com with SMTP id m15so1936405wgh.16
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 16:52:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=8QMI7uj/1xAE6zQk+pO6/VIMaSY+rqlUxglMowxjcRE=;
        b=QDS7jJ71ifUZ5ky27L7/kHy0AGP1pMKvkEunhgETqCUbS8ABvPXI6NjG3ROc8eP0rB
         6xJIszfuJf0U5HXL+010Wvl97J/mc/ecfumXsqByzgva5VWHrJ0L4KAWwK+qr4YqBmfu
         AKW2Si2mDfjHt0L6ie+vVUgxkue7kSgfyjoQHGeox8xUzqGVIRpFwH7ThPTRgftVcIFw
         SrAIkPJkxHw5CbPmgvvlfEH4orbVpnsH38wTB5lpAQf2mPJc4JW9fv68aTROvDJHC8Wb
         YulKPPZzsHDsva0mB6+fq7UnZyCesdjynv78Ppye5ewIHN8oarZMRHUGqsOJtf6M/IFr
         C4Hw==
MIME-Version: 1.0
X-Received: by 10.194.103.74 with SMTP id fu10mr14839618wjb.0.1413589967858;
 Fri, 17 Oct 2014 16:52:47 -0700 (PDT)
Received: by 10.180.99.70 with HTTP; Fri, 17 Oct 2014 16:52:47 -0700 (PDT)
In-Reply-To: <CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
	<CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
	<CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
	<CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
	<CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
	<CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
	<CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
	<CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
	<CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
	<CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
	<CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
Date: Fri, 17 Oct 2014 19:52:47 -0400
Message-ID: <CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: shane knapp <sknapp@berkeley.edu>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e010d7fb8e470610505a70fd7
X-Virus-Checked: Checked by ClamAV on apache.org

--089e010d7fb8e470610505a70fd7
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Wow, thanks for this deep dive Shane. Is there a way to check if we are
getting hit by rate limiting directly, or do we need to contact GitHub for
that?

2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, shane kn=
app<sknapp@berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =EB=
=A9=94=EC=8B=9C=EC=A7=80:

> quick update:
>
> here are some stats i scraped over the past week of ALL pull request
> builder projects and timeout failures.  due to the large number of spark
> ghprb jobs, i don't have great records earlier than oct 7th.  the data is
> current up until ~230pm today:
>
> spark and new spark ghprb total builds vs git fetch timeouts:
> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -i spa=
rk
> | wc -l); failed=3D$(grep $x SORTED | grep -i spark | wc -l); let
> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$total" =
| bc |
> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>  $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34%
> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09%
> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0%
> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12%
> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10%
> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28%
> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08%
> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16%
> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23%
>
> all other ghprb builds vs git fetch timeouts:
> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -vi sp=
ark
> | wc -l); failed=3D$(grep $x SORTED | grep -vi spark | wc -l); let
> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$total" =
| bc |
> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>  $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0%
> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13%
> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0%
> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0%
> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0%
> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0%
> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0%
> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0%
> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0%
>
> note:  the 15th was the day i rolled back to the earlier version of the
> git plugin.  it doesn't seem to have helped much, so i'll probably bring =
us
> back up to the latest version soon.
> also note:  rocking some floating point math on the CLI!  ;)
>
> i also compared the distribution of git timeout failures vs time of day,
> and there appears to be no correlation.  the failures are pretty evenly
> distributed over each hour of the day.
>
> we could be hitting the rate limit due to the ghprb hitting github a
> couple of times for each build, but we're averaging ~10-20 builds per hou=
r
> (a build hits github 2-4 times, from what i can tell).  i'll have to look
> more in to this on monday, but suffice to say we may need to move from
> unauthorized https fetches to authorized requests.  this means retrofitti=
ng
> all of our jobs.  yay!  fun!  :)
>
> another option is to have local mirrors of all of the repos.  the problem
> w/this is that there might be a window where changes haven't made it to t=
he
> local mirror and tests run against it.  more fun stuff to think about...
>
> now that i have some stats, and a list of all of the times/dates of the
> failures, i will be drafting my email to github and firing that off later
> today or first thing monday.
>
> have a great weekend everyone!
>
> shane, who spent way too much time on the CLI and is ready for some beer.
>
> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com
> <javascript:_e(%7B%7D,'cvml','nicholas.chammas@gmail.com');>> wrote:
>
>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu
>> <javascript:_e(%7B%7D,'cvml','sknapp@berkeley.edu');>> wrote:
>>
>>> i really, truly hate non-deterministic failures.
>>
>>
>> Amen bruddah.
>>
>
>

--089e010d7fb8e470610505a70fd7--

From dev-return-9853-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 00:00:56 2014
Return-Path: <dev-return-9853-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6543017482
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 00:00:56 +0000 (UTC)
Received: (qmail 75191 invoked by uid 500); 18 Oct 2014 00:00:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75131 invoked by uid 500); 18 Oct 2014 00:00:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75120 invoked by uid 99); 18 Oct 2014 00:00:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 00:00:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.41 as permitted sender)
Received: from [209.85.215.41] (HELO mail-la0-f41.google.com) (209.85.215.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 00:00:50 +0000
Received: by mail-la0-f41.google.com with SMTP id pn19so1494105lab.14
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 17:00:28 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=xh/MphmtSaXhsM8mCjnZUtQ86+L8BsAJb3Eyb2kiZCY=;
        b=f7mzwsY0aSg3DIv4hro75vN+8jIsUPZSH+TGXcKzv3VeopsQA0FKj1LNV3ymBe/xgn
         CVUQU1n7QFkuLE7YSdEkmOkoaHRRIZfV8Rbe8QpX9BHp+Gu7k1YJo6ZCncNh4LdbsPp7
         KjqhYO10oE0mI8WAggTtgJ6MOWVLz5P1dJcjGtwQl6OqAl17gqkMARNuATqk4ezatgtK
         84jqjcnXcqAnvBc73whjPZ0h7eJi2CYq6gjuRunTIdNqKeym8XoLI0Hx5WoLQG3OQkfC
         yBMIgOaD1Br5yaUzQd1TU/oHQ2UuN6AQS3huT88A7B6/Anp+5/tCwahtHBy9lr4dWPMK
         W6jQ==
X-Gm-Message-State: ALoCoQn3OnbEcbgGJpweD4FpNAAeC4sJO81ES9D7V1te7jQehX0cYvLv4iD8aoAYLl6h9IqjHMGV
X-Received: by 10.112.222.195 with SMTP id qo3mr12175813lbc.29.1413590428510;
 Fri, 17 Oct 2014 17:00:28 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Fri, 17 Oct 2014 17:00:08 -0700 (PDT)
In-Reply-To: <CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
 <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
 <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
 <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
 <CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
 <CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
 <CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com> <CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 17 Oct 2014 17:00:08 -0700
Message-ID: <CACdU-dSea+ETt6hipNzVHtaiAN4Wd_VpSNkwJaZrALfy8X8nQA@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133ade6597b640505a72ba2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133ade6597b640505a72ba2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

actually, nvm, you have to be run that command from our servers to affect
our limit.  run it all you want from your own machines!  :P

On Fri, Oct 17, 2014 at 4:59 PM, shane knapp <sknapp@berkeley.edu> wrote:

> yep, and i will tell you guys ONLY if you promise to NOT try this
> yourselves...  checking the rate limit also counts as a hit and increment=
s
> our numbers:
>
> # curl -i https://api.github.com/users/whatever 2> /dev/null | egrep
> ^X-Rate
> X-RateLimit-Limit: 60
> X-RateLimit-Remaining: 51
> X-RateLimit-Reset: 1413590269
>
> (yes, that is the exact url that they recommended on the github site lol)
>
> so, earlier today, we had a spark build fail w/a git timeout at 10:57am,
> but there were only ~7 builds run that hour, so that points to us NOT
> hitting the rate limit...  at least for this fail.  whee!
>
> is it beer-thirty yet?
>
> shane
>
>
>
> On Fri, Oct 17, 2014 at 4:52 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> Wow, thanks for this deep dive Shane. Is there a way to check if we are
>> getting hit by rate limiting directly, or do we need to contact GitHub
>> for that?
>>
>> 2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, shane=
 knapp<sknapp@berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =
=EB=A9=94=EC=8B=9C=EC=A7=80:
>>
>> quick update:
>>>
>>> here are some stats i scraped over the past week of ALL pull request
>>> builder projects and timeout failures.  due to the large number of spar=
k
>>> ghprb jobs, i don't have great records earlier than oct 7th.  the data =
is
>>> current up until ~230pm today:
>>>
>>> spark and new spark ghprb total builds vs git fetch timeouts:
>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -i
>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -i spark | wc -l); let
>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$total=
" | bc |
>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>>  $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>>> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34%
>>> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09%
>>> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0%
>>> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12%
>>> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10%
>>> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28%
>>> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08%
>>> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16%
>>> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23%
>>>
>>> all other ghprb builds vs git fetch timeouts:
>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -vi
>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -vi spark | wc -l); le=
t
>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$total=
" | bc |
>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>>  $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>>> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0%
>>> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13%
>>> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0%
>>> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0%
>>> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0%
>>> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0%
>>> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0%
>>> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0%
>>> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0%
>>>
>>> note:  the 15th was the day i rolled back to the earlier version of the
>>> git plugin.  it doesn't seem to have helped much, so i'll probably brin=
g us
>>> back up to the latest version soon.
>>> also note:  rocking some floating point math on the CLI!  ;)
>>>
>>> i also compared the distribution of git timeout failures vs time of day=
,
>>> and there appears to be no correlation.  the failures are pretty evenly
>>> distributed over each hour of the day.
>>>
>>> we could be hitting the rate limit due to the ghprb hitting github a
>>> couple of times for each build, but we're averaging ~10-20 builds per h=
our
>>> (a build hits github 2-4 times, from what i can tell).  i'll have to lo=
ok
>>> more in to this on monday, but suffice to say we may need to move from
>>> unauthorized https fetches to authorized requests.  this means retrofit=
ting
>>> all of our jobs.  yay!  fun!  :)
>>>
>>> another option is to have local mirrors of all of the repos.  the
>>> problem w/this is that there might be a window where changes haven't ma=
de
>>> it to the local mirror and tests run against it.  more fun stuff to thi=
nk
>>> about...
>>>
>>> now that i have some stats, and a list of all of the times/dates of the
>>> failures, i will be drafting my email to github and firing that off lat=
er
>>> today or first thing monday.
>>>
>>> have a great weekend everyone!
>>>
>>> shane, who spent way too much time on the CLI and is ready for some bee=
r.
>>>
>>> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu>
>>>> wrote:
>>>>
>>>>> i really, truly hate non-deterministic failures.
>>>>
>>>>
>>>> Amen bruddah.
>>>>
>>>
>>>
>

--001a1133ade6597b640505a72ba2--

From dev-return-9854-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 00:01:30 2014
Return-Path: <dev-return-9854-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 73C0317485
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 00:01:30 +0000 (UTC)
Received: (qmail 76827 invoked by uid 500); 18 Oct 2014 00:01:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76751 invoked by uid 500); 18 Oct 2014 00:01:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76734 invoked by uid 99); 18 Oct 2014 00:01:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 00:01:29 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.220.182] (HELO mail-vc0-f182.google.com) (209.85.220.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 00:01:03 +0000
Received: by mail-vc0-f182.google.com with SMTP id la4so1384978vcb.27
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 17:01:02 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=HQU204RPctcoOOCoKSAOgoWhPoBK1dGmfMmvyoB9MxI=;
        b=IsaMdqLglZOFYtm4VkuPaL2Z9Xco0x6JLZRc4JyvYxtpPPjmU2ZGtUATBrOfHDGUaa
         KK/WkjSEkH8o+8dhmLCUCs6fd30DA4jshCLBQFjHydenhsldUntfJLsafzJU469jL7FO
         ngTCnBB8+un8wWK9PFYu7kMvMI7O1DkEQWlGBafD3GOdtzipiaFQMkLFHZEisP/wK+7b
         kafiXc9K0HD7vMJ6VzEaZw0Ff/btUMIqKGvj7D1b+8meiFvHVyQYx0yCqU8hX9l5lQae
         pOak1TdqhxVdFLnhAvMHHaEJc51ElB187WCOpQO4O+Tn7QzrgxYfaiFigoGibF4qmJLF
         DUyw==
X-Gm-Message-State: ALoCoQkKq+2m1OrhfSwbB8dHrz1VfJqgbgQtDISUD0EFpiFmnP/4r1aAa8HH19hpWA+0MyRWLysP
X-Received: by 10.53.5.132 with SMTP id cm4mr2896931vdd.50.1413590461867;
        Fri, 17 Oct 2014 17:01:01 -0700 (PDT)
Received: from mail-vc0-f170.google.com (mail-vc0-f170.google.com. [209.85.220.170])
        by mx.google.com with ESMTPSA id br2sm498141vdc.10.2014.10.17.17.01.00
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 17 Oct 2014 17:01:00 -0700 (PDT)
Received: by mail-vc0-f170.google.com with SMTP id hy10so1367895vcb.1
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 17:01:00 -0700 (PDT)
X-Received: by 10.52.111.33 with SMTP id if1mr3203607vdb.47.1413590460560;
 Fri, 17 Oct 2014 17:01:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.220.84.129 with HTTP; Fri, 17 Oct 2014 17:00:40 -0700 (PDT)
From: Andrew Ash <andrew@andrewash.com>
Date: Fri, 17 Oct 2014 17:00:40 -0700
Message-ID: <CA+-p3AFb3SygzTgAsxbq8q=mJ5hGNNYrpXo7kFyoGP3rMRnM1Q@mail.gmail.com>
Subject: Raise Java dependency from 6 to 7
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=bcaec548a485427cdb0505a72d1b
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec548a485427cdb0505a72d1b
Content-Type: text/plain; charset=UTF-8

Hi Spark devs,

I've heard a few times that keeping support for Java 6 is a priority for
Apache Spark.  Given that Java 6 has been publicly EOL'd since Feb 2013
<http://www.oracle.com/technetwork/java/eol-135779.html> and the last
public update was Apr 2013
<https://en.wikipedia.org/wiki/Java_version_history#Java_6_updates>, why
are we still maintaing support for 6?  The only people using it now must be
paying for the extended support to continue receiving security fixes.

Bumping the lower bound of Java versions up to Java 7 would allow us to
upgrade from Jetty 8 to 9, which is currently a conflict with the
Dropwizard framework and a personal pain point.

Java 6 vs 7 for Spark links:
Try with resources
<https://github.com/apache/spark/pull/2575/files#r18152125> for
SparkContext et al
Upgrade to Jetty 9
<https://github.com/apache/spark/pull/167#issuecomment-54544494>
Warn when not compiling with Java6
<https://github.com/apache/spark/pull/859>


Who are the people out there that still need Java 6 support?

Thanks!
Andrew

--bcaec548a485427cdb0505a72d1b--

From dev-return-9855-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 00:06:02 2014
Return-Path: <dev-return-9855-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 89F52174A8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 00:06:02 +0000 (UTC)
Received: (qmail 90177 invoked by uid 500); 18 Oct 2014 00:06:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90102 invoked by uid 500); 18 Oct 2014 00:06:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90091 invoked by uid 99); 18 Oct 2014 00:06:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 00:06:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.49 as permitted sender)
Received: from [209.85.215.49] (HELO mail-la0-f49.google.com) (209.85.215.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 00:05:34 +0000
Received: by mail-la0-f49.google.com with SMTP id q1so1477333lam.22
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 17:05:33 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=pIFVw6I0/qQUBfb5Pnxmo7LzXLciBlYvnDPgF9BxVxI=;
        b=YACLrdXkxKyvAxe/XS7px9Az3COgHzDWe5ix8fvu6D1tMpgkVvmvOs1lkjuvTV7HH5
         CwtO2rYp+3VMFLEOvVgAAfAbRiBgIIXtBPNIIUkh7hUpanuE2dU8FozUsz2Ce4NuIHeW
         6LlR7N+v4dw9P9iLq3/05ApeEBspxaQZkwYi0ss8C57DpUgFpGDepL6D3DM/qZF9izq6
         4wuZjXTTxEnoe1FV+SHhqcythZeZqLUchs7+p/qEdo4x7CvSdoKqeroYoKqpynNi/EYm
         E9xSJjkeWWIfJXsJ7P9uiQJPojXZQOZzXaxHG+iTkTtx6Ef8UIVlIeN65BmqfQQ+C1a+
         HTTQ==
X-Gm-Message-State: ALoCoQleswp7huAyEAI8hWA37SsOxYc/CR2fxNQ+oOUXWfMRkAJhmFH/G+Y+w+fwvwhGYLeQVnWY
X-Received: by 10.152.44.233 with SMTP id h9mr11859887lam.73.1413590376622;
 Fri, 17 Oct 2014 16:59:36 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.11 with HTTP; Fri, 17 Oct 2014 16:59:15 -0700 (PDT)
In-Reply-To: <CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
 <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
 <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
 <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
 <CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
 <CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com> <CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 17 Oct 2014 16:59:15 -0700
Message-ID: <CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160b3ba41b3370505a7282c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160b3ba41b3370505a7282c
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

yep, and i will tell you guys ONLY if you promise to NOT try this
yourselves...  checking the rate limit also counts as a hit and increments
our numbers:

# curl -i https://api.github.com/users/whatever 2> /dev/null | egrep ^X-Rat=
e
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 51
X-RateLimit-Reset: 1413590269

(yes, that is the exact url that they recommended on the github site lol)

so, earlier today, we had a spark build fail w/a git timeout at 10:57am,
but there were only ~7 builds run that hour, so that points to us NOT
hitting the rate limit...  at least for this fail.  whee!

is it beer-thirty yet?

shane



On Fri, Oct 17, 2014 at 4:52 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> Wow, thanks for this deep dive Shane. Is there a way to check if we are
> getting hit by rate limiting directly, or do we need to contact GitHub
> for that?
>
> 2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, shane =
knapp<sknapp@berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =
=EB=A9=94=EC=8B=9C=EC=A7=80:
>
> quick update:
>>
>> here are some stats i scraped over the past week of ALL pull request
>> builder projects and timeout failures.  due to the large number of spark
>> ghprb jobs, i don't have great records earlier than oct 7th.  the data i=
s
>> current up until ~230pm today:
>>
>> spark and new spark ghprb total builds vs git fetch timeouts:
>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -i sp=
ark
>> | wc -l); failed=3D$(grep $x SORTED | grep -i spark | wc -l); let
>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$total"=
 | bc |
>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>  $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34%
>> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09%
>> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0%
>> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12%
>> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10%
>> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28%
>> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08%
>> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16%
>> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23%
>>
>> all other ghprb builds vs git fetch timeouts:
>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -vi
>> spark | wc -l); failed=3D$(grep $x SORTED | grep -vi spark | wc -l); let
>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$total"=
 | bc |
>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>  $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0%
>> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13%
>> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0%
>> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0%
>> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0%
>> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0%
>> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0%
>> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0%
>> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0%
>>
>> note:  the 15th was the day i rolled back to the earlier version of the
>> git plugin.  it doesn't seem to have helped much, so i'll probably bring=
 us
>> back up to the latest version soon.
>> also note:  rocking some floating point math on the CLI!  ;)
>>
>> i also compared the distribution of git timeout failures vs time of day,
>> and there appears to be no correlation.  the failures are pretty evenly
>> distributed over each hour of the day.
>>
>> we could be hitting the rate limit due to the ghprb hitting github a
>> couple of times for each build, but we're averaging ~10-20 builds per ho=
ur
>> (a build hits github 2-4 times, from what i can tell).  i'll have to loo=
k
>> more in to this on monday, but suffice to say we may need to move from
>> unauthorized https fetches to authorized requests.  this means retrofitt=
ing
>> all of our jobs.  yay!  fun!  :)
>>
>> another option is to have local mirrors of all of the repos.  the proble=
m
>> w/this is that there might be a window where changes haven't made it to =
the
>> local mirror and tests run against it.  more fun stuff to think about...
>>
>> now that i have some stats, and a list of all of the times/dates of the
>> failures, i will be drafting my email to github and firing that off late=
r
>> today or first thing monday.
>>
>> have a great weekend everyone!
>>
>> shane, who spent way too much time on the CLI and is ready for some beer=
.
>>
>> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu>
>>> wrote:
>>>
>>>> i really, truly hate non-deterministic failures.
>>>
>>>
>>> Amen bruddah.
>>>
>>
>>

--089e0160b3ba41b3370505a7282c--

From dev-return-9856-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 00:26:57 2014
Return-Path: <dev-return-9856-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2BBB0174F4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 00:26:57 +0000 (UTC)
Received: (qmail 15636 invoked by uid 500); 18 Oct 2014 00:26:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15568 invoked by uid 500); 18 Oct 2014 00:26:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 15557 invoked by uid 99); 18 Oct 2014 00:26:55 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 00:26:55 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 00:26:51 +0000
Received: by mail-la0-f54.google.com with SMTP id gm9so1536838lab.13
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 17:26:29 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=6fLIirB4CBw98Wwstu5SuAn/YiPupIgV5oVKXZTuGrc=;
        b=TTPoL5Ux5hx5ed2D3yDAqji7uhVofyhn+Z8/Ev6jzfg/jNj8DGSPst7ku3/sI8yZ7C
         tYN2Pr8zgFfBajoCsH3rgaRaJoaP419+KGj8OMtI09ue/WA7JMbyzPoZ3ctOidur8nKi
         L1KE2CD4EK8d7LnUpzJsQOiFf70M9MMEHVzA+RA9+nVMhQma+hAVclh2WNbvqLJ/jr2w
         qmsVzUmytlTU8R5vK5ZK6vllBVwqECggTJkIbXIA1qgBUB8ANV7gDQwIVix/g4fbt+KW
         NNOobNnwtLuRyvHHWAw78LukuZ8Su9yx2LRVxRWWmcfLj0P27ir7+Aj3fUF093fYbw3j
         LQQQ==
X-Gm-Message-State: ALoCoQn64UyMx89EFTrxDsVZetnM6lBSFAQAz/nxLK6+gh+z7ygZRrLRSdaTCP0YRaPkMSJb9rgn
MIME-Version: 1.0
X-Received: by 10.152.22.74 with SMTP id b10mr12133804laf.16.1413591989334;
 Fri, 17 Oct 2014 17:26:29 -0700 (PDT)
Received: by 10.25.162.65 with HTTP; Fri, 17 Oct 2014 17:26:29 -0700 (PDT)
In-Reply-To: <CACdU-dSea+ETt6hipNzVHtaiAN4Wd_VpSNkwJaZrALfy8X8nQA@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
	<CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
	<CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
	<CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
	<CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
	<CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
	<CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
	<CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
	<CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
	<CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
	<CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
	<CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
	<CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
	<CACdU-dSea+ETt6hipNzVHtaiAN4Wd_VpSNkwJaZrALfy8X8nQA@mail.gmail.com>
Date: Fri, 17 Oct 2014 17:26:29 -0700
Message-ID: <CA+2Pv=jYG3gTu4yxtanaGp4_uBeyb+Q_yX97kaMG0BpZ2OL3DA@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
From: Davies Liu <davies@databricks.com>
To: shane knapp <sknapp@berkeley.edu>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, amp-infra <amp-infra@googlegroups.com>, 
	dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

One finding is that all the timeout happened with this command:

git fetch --tags --progress https://github.com/apache/spark.git
+refs/pull/*:refs/remotes/origin/pr/*

I'm thinking that maybe this may be a expensive call, we could try to
use a more cheap one:

git fetch --tags --progress https://github.com/apache/spark.git
+refs/pull/XXX/*:refs/remotes/origin/pr/XXX/*

XXX is the PullRequestID,

The configuration support parameters [1], so we could put this in :

+refs/pull//${ghprbPullId}/*:refs/remotes/origin/pr/${ghprbPullId}/*

I have not tested this yet, could you give this a try?

Davies


[1] https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder=
+plugin

On Fri, Oct 17, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu> wrote:
> actually, nvm, you have to be run that command from our servers to affect
> our limit.  run it all you want from your own machines!  :P
>
> On Fri, Oct 17, 2014 at 4:59 PM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> yep, and i will tell you guys ONLY if you promise to NOT try this
>> yourselves...  checking the rate limit also counts as a hit and incremen=
ts
>> our numbers:
>>
>> # curl -i https://api.github.com/users/whatever 2> /dev/null | egrep
>> ^X-Rate
>> X-RateLimit-Limit: 60
>> X-RateLimit-Remaining: 51
>> X-RateLimit-Reset: 1413590269
>>
>> (yes, that is the exact url that they recommended on the github site lol=
)
>>
>> so, earlier today, we had a spark build fail w/a git timeout at 10:57am,
>> but there were only ~7 builds run that hour, so that points to us NOT
>> hitting the rate limit...  at least for this fail.  whee!
>>
>> is it beer-thirty yet?
>>
>> shane
>>
>>
>>
>> On Fri, Oct 17, 2014 at 4:52 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> Wow, thanks for this deep dive Shane. Is there a way to check if we are
>>> getting hit by rate limiting directly, or do we need to contact GitHub
>>> for that?
>>>
>>> 2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, shan=
e knapp<sknapp@berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =
=EB=A9=94=EC=8B=9C=EC=A7=80:
>>>
>>> quick update:
>>>>
>>>> here are some stats i scraped over the past week of ALL pull request
>>>> builder projects and timeout failures.  due to the large number of spa=
rk
>>>> ghprb jobs, i don't have great records earlier than oct 7th.  the data=
 is
>>>> current up until ~230pm today:
>>>>
>>>> spark and new spark ghprb total builds vs git fetch timeouts:
>>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -i
>>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -i spark | wc -l); le=
t
>>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$tota=
l" | bc |
>>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>>>  $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>>>> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34%
>>>> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09%
>>>> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0%
>>>> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12%
>>>> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10%
>>>> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28%
>>>> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08%
>>>> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16%
>>>> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23%
>>>>
>>>> all other ghprb builds vs git fetch timeouts:
>>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -vi
>>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -vi spark | wc -l); l=
et
>>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$tota=
l" | bc |
>>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>>>  $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>>>> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0%
>>>> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13%
>>>> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0%
>>>> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0%
>>>> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0%
>>>> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0%
>>>> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0%
>>>> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0%
>>>> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0%
>>>>
>>>> note:  the 15th was the day i rolled back to the earlier version of th=
e
>>>> git plugin.  it doesn't seem to have helped much, so i'll probably bri=
ng us
>>>> back up to the latest version soon.
>>>> also note:  rocking some floating point math on the CLI!  ;)
>>>>
>>>> i also compared the distribution of git timeout failures vs time of da=
y,
>>>> and there appears to be no correlation.  the failures are pretty evenl=
y
>>>> distributed over each hour of the day.
>>>>
>>>> we could be hitting the rate limit due to the ghprb hitting github a
>>>> couple of times for each build, but we're averaging ~10-20 builds per =
hour
>>>> (a build hits github 2-4 times, from what i can tell).  i'll have to l=
ook
>>>> more in to this on monday, but suffice to say we may need to move from
>>>> unauthorized https fetches to authorized requests.  this means retrofi=
tting
>>>> all of our jobs.  yay!  fun!  :)
>>>>
>>>> another option is to have local mirrors of all of the repos.  the
>>>> problem w/this is that there might be a window where changes haven't m=
ade
>>>> it to the local mirror and tests run against it.  more fun stuff to th=
ink
>>>> about...
>>>>
>>>> now that i have some stats, and a list of all of the times/dates of th=
e
>>>> failures, i will be drafting my email to github and firing that off la=
ter
>>>> today or first thing monday.
>>>>
>>>> have a great weekend everyone!
>>>>
>>>> shane, who spent way too much time on the CLI and is ready for some be=
er.
>>>>
>>>> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu>
>>>>> wrote:
>>>>>
>>>>>> i really, truly hate non-deterministic failures.
>>>>>
>>>>>
>>>>> Amen bruddah.
>>>>>
>>>>
>>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9857-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 01:17:34 2014
Return-Path: <dev-return-9857-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EAB89175D4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 01:17:34 +0000 (UTC)
Received: (qmail 90056 invoked by uid 500); 18 Oct 2014 01:17:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89917 invoked by uid 500); 18 Oct 2014 01:17:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89890 invoked by uid 99); 18 Oct 2014 01:17:33 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 01:17:33 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.220.49 as permitted sender)
Received: from [209.85.220.49] (HELO mail-pa0-f49.google.com) (209.85.220.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 01:17:29 +0000
Received: by mail-pa0-f49.google.com with SMTP id hz1so1765628pad.36
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 18:17:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=SrRstZypda/MIeHCTG5AaoFf+yFnDV4o4P+kYad5gfQ=;
        b=PMFw67gl+n4ivnKDmIYJb6R9w5Pttz2kwBjFAAzUcTuH8pR3bFzQiip3RY8GyKVUym
         N0O0bw4uubTr9WMTohDX5AEx7XKjxeApcbXZPMdIgf9fQ2OAw2koxAfsXy1bxTNIUYrg
         7TqkwMuR26a/ZSBaDGYKX4XTD5hi7GtogzBjBtQd74QQ/eYMSLwWOb4DdnotaqDqTkvn
         W0U2bH45ypA7SzX9MzEvxVZGwwEr4zyIxaORyuPY9xo9fKJQc0bUmTcqHGqzG8cf+VG5
         wXVSulYkLWYhUeaeZ451w9rdXtj80Tnnlb5egjP7ubIYmIj48/lr675i2MtyYqOTkbSG
         WUKg==
X-Received: by 10.70.3.2 with SMTP id 2mr12201721pdy.9.1413595029031;
        Fri, 17 Oct 2014 18:17:09 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id dx10sm2631790pab.38.2014.10.17.18.17.08
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Fri, 17 Oct 2014 18:17:08 -0700 (PDT)
Date: Fri, 17 Oct 2014 18:17:07 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Davies Liu <davies@databricks.com>, shane knapp
 <sknapp@berkeley.edu>
Cc: dev <dev@spark.apache.org>, Nicholas Chammas
 <nicholas.chammas@gmail.com>, amp-infra <amp-infra@googlegroups.com>
Message-ID: <etPan.5441bf93.643c9869.107@joshs-mbp>
In-Reply-To: <CA+2Pv=jYG3gTu4yxtanaGp4_uBeyb+Q_yX97kaMG0BpZ2OL3DA@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
 <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
 <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
 <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
 <CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
 <CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
 <CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
 <CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
 <CACdU-dSea+ETt6hipNzVHtaiAN4Wd_VpSNkwJaZrALfy8X8nQA@mail.gmail.com>
 <CA+2Pv=jYG3gTu4yxtanaGp4_uBeyb+Q_yX97kaMG0BpZ2OL3DA@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of
 the git fetch timeouts
X-Mailer: Airmail Beta (269)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5441bf93_66334873_107"
X-Virus-Checked: Checked by ClamAV on apache.org

--5441bf93_66334873_107
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

=46YI, I edited the Spark Pull Request Builder job to try this out. =C2=A0=
Let=E2=80=99s see if it works (I=E2=80=99ll be around to revert if it doe=
sn=E2=80=99t).

On October 17, 2014 at 5:26:56 PM, Davies Liu (davies=40databricks.com) w=
rote:

One finding is that all the timeout happened with this command: =20

git fetch --tags --progress https://github.com/apache/spark.git =20
+refs/pull/*:refs/remotes/origin/pr/* =20

I'm thinking that maybe this may be a expensive call, we could try to =20
use a more cheap one: =20

git fetch --tags --progress https://github.com/apache/spark.git =20
+refs/pull/XXX/*:refs/remotes/origin/pr/XXX/* =20

XXX is the PullRequestID, =20

The configuration support parameters =5B1=5D, so we could put this in : =20

+refs/pull//=24=7BghprbPullId=7D/*:refs/remotes/origin/pr/=24=7BghprbPull=
Id=7D/* =20

I have not tested this yet, could you give this a try=3F =20

Davies =20


=5B1=5D https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+b=
uilder+plugin =20

On =46ri, Oct 17, 2014 at 5:00 PM, shane knapp <sknapp=40berkeley.edu> wr=
ote: =20
> actually, nvm, you have to be run that command from our servers to affe=
ct =20
> our limit. run it all you want from your own machines=21 :P =20
> =20
> On =46ri, Oct 17, 2014 at 4:59 PM, shane knapp <sknapp=40berkeley.edu> =
wrote: =20
> =20
>> yep, and i will tell you guys ONLY if you promise to NOT try this =20
>> yourselves... checking the rate limit also counts as a hit and increme=
nts =20
>> our numbers: =20
>> =20
>> =23 curl -i https://api.github.com/users/whatever 2> /dev/null =7C egr=
ep =20
>> =5EX-Rate =20
>> X-RateLimit-Limit: 60 =20
>> X-RateLimit-Remaining: 51 =20
>> X-RateLimit-Reset: 1413590269 =20
>> =20
>> (yes, that is the exact url that they recommended on the github site l=
ol) =20
>> =20
>> so, earlier today, we had a spark build fail w/a git timeout at 10:57a=
m, =20
>> but there were only =7E7 builds run that hour, so that points to us NO=
T =20
>> hitting the rate limit... at least for this fail. whee=21 =20
>> =20
>> is it beer-thirty yet=3F =20
>> =20
>> shane =20
>> =20
>> =20
>> =20
>> On =46ri, Oct 17, 2014 at 4:52 PM, Nicholas Chammas < =20
>> nicholas.chammas=40gmail.com> wrote: =20
>> =20
>>> Wow, thanks for this deep dive Shane. Is there a way to check if we a=
re =20
>>> getting hit by rate limiting directly, or do we need to contact GitHu=
b =20
>>> for that=3F =20
>>> =20
>>> 2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, sh=
ane knapp<sknapp=40berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=
=9C =EB=A9=94=EC=8B=9C=EC=A7=80: =20
>>> =20
>>> quick update: =20
>>>> =20
>>>> here are some stats i scraped over the past week of ALL pull request=
 =20
>>>> builder projects and timeout failures. due to the large number of sp=
ark =20
>>>> ghprb jobs, i don't have great records earlier than oct 7th. the dat=
a is =20
>>>> current up until =7E230pm today: =20
>>>> =20
>>>> spark and new spark ghprb total builds vs git fetch timeouts: =20
>>>> =24 for x in 10-=7B09..17=7D; do passed=3D=24(grep =24x SORTED.passe=
d =7C grep -i =20
>>>> spark =7C wc -l); failed=3D=24(grep =24x SORTED =7C grep -i spark =7C=
 wc -l); let =20
>>>> total=3Dpassed+failed; fail=5Fpercent=3D=24(echo =22scale=3D2; =24fa=
iled/=24total=22 =7C bc =7C =20
>>>> sed =22s/=5E=5C.//g=22); line=3D=22=24x -- total builds: =24total=5C=
tp/f: =20
>>>> =24passed/=24failed=5Ctfail%: =24fail=5Fpercent%=22; echo -e =24line=
; done =20
>>>> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34% =20
>>>> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09% =20
>>>> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0% =20
>>>> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12% =20
>>>> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10% =20
>>>> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28% =20
>>>> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08% =20
>>>> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16% =20
>>>> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23% =20
>>>> =20
>>>> all other ghprb builds vs git fetch timeouts: =20
>>>> =24 for x in 10-=7B09..17=7D; do passed=3D=24(grep =24x SORTED.passe=
d =7C grep -vi =20
>>>> spark =7C wc -l); failed=3D=24(grep =24x SORTED =7C grep -vi spark =7C=
 wc -l); let =20
>>>> total=3Dpassed+failed; fail=5Fpercent=3D=24(echo =22scale=3D2; =24fa=
iled/=24total=22 =7C bc =7C =20
>>>> sed =22s/=5E=5C.//g=22); line=3D=22=24x -- total builds: =24total=5C=
tp/f: =20
>>>> =24passed/=24failed=5Ctfail%: =24fail=5Fpercent%=22; echo -e =24line=
; done =20
>>>> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0% =20
>>>> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13% =20
>>>> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0% =20
>>>> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0% =20
>>>> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0% =20
>>>> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0% =20
>>>> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0% =20
>>>> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0% =20
>>>> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0% =20
>>>> =20
>>>> note: the 15th was the day i rolled back to the earlier version of t=
he =20
>>>> git plugin. it doesn't seem to have helped much, so i'll probably br=
ing us =20
>>>> back up to the latest version soon. =20
>>>> also note: rocking some floating point math on the CLI=21 ;) =20
>>>> =20
>>>> i also compared the distribution of git timeout failures vs time of =
day, =20
>>>> and there appears to be no correlation. the failures are pretty even=
ly =20
>>>> distributed over each hour of the day. =20
>>>> =20
>>>> we could be hitting the rate limit due to the ghprb hitting github a=
 =20
>>>> couple of times for each build, but we're averaging =7E10-20 builds =
per hour =20
>>>> (a build hits github 2-4 times, from what i can tell). i'll have to =
look =20
>>>> more in to this on monday, but suffice to say we may need to move fr=
om =20
>>>> unauthorized https fetches to authorized requests. this means retrof=
itting =20
>>>> all of our jobs. yay=21 fun=21 :) =20
>>>> =20
>>>> another option is to have local mirrors of all of the repos. the =20
>>>> problem w/this is that there might be a window where changes haven't=
 made =20
>>>> it to the local mirror and tests run against it. more fun stuff to t=
hink =20
>>>> about... =20
>>>> =20
>>>> now that i have some stats, and a list of all of the times/dates of =
the =20
>>>> failures, i will be drafting my email to github and firing that off =
later =20
>>>> today or first thing monday. =20
>>>> =20
>>>> have a great weekend everyone=21 =20
>>>> =20
>>>> shane, who spent way too much time on the CLI and is ready for some =
beer. =20
>>>> =20
>>>> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas < =20
>>>> nicholas.chammas=40gmail.com> wrote: =20
>>>> =20
>>>>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp=40berkeley.edu=
> =20
>>>>> wrote: =20
>>>>> =20
>>>>>> i really, truly hate non-deterministic failures. =20
>>>>> =20
>>>>> =20
>>>>> Amen bruddah. =20
>>>>> =20
>>>> =20
>>>> =20
>> =20

--------------------------------------------------------------------- =20
To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
=46or additional commands, e-mail: dev-help=40spark.apache.org =20


--5441bf93_66334873_107--


From dev-return-9858-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 05:32:00 2014
Return-Path: <dev-return-9858-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5C7251793D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 05:32:00 +0000 (UTC)
Received: (qmail 80707 invoked by uid 500); 18 Oct 2014 05:31:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80637 invoked by uid 500); 18 Oct 2014 05:31:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80625 invoked by uid 99); 18 Oct 2014 05:31:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 05:31:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of fairizazizi@gmail.com designates 209.85.212.174 as permitted sender)
Received: from [209.85.212.174] (HELO mail-wi0-f174.google.com) (209.85.212.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 05:31:51 +0000
Received: by mail-wi0-f174.google.com with SMTP id h11so3877617wiw.7
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 22:31:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:from:date:message-id
         :subject:to:cc:content-type;
        bh=dasjwqHMiGWbUdGKYchsLgZUpL0HVy4srZkY876MQow=;
        b=nPB2PCj0rP/Y95LM7Kh4NV2bcKY6DvdMdiPxXW7o4HnzG3NjxubqF41XdWtOuJ1YA6
         p7Bu+ScetlmQJO3W0oC/4HAWMAD72aEAKtJM+CsFEa8WhK0zrjudxdtPaaZmhUd4t6Nl
         SCZ6Tro04HJsH/M+dKqSGDdgGTs9I/da7+CB8ampID4/GhSwG4InZBhQ6NWv02yj1lUu
         cPPqbS3ctge0LyoCzoLEONFwqMNYnEzPsqwhLuAnUENPuaHjSdg9n1SqPymTdHKzGgg5
         W6JyXgZBpQaLgXdVEeQTHX1+olLGRyiUbUREPAGGIizfdB45vl+zD6VGwqFt5xIJbpPW
         Xlbw==
X-Received: by 10.180.108.43 with SMTP id hh11mr3666966wib.80.1413610289846;
 Fri, 17 Oct 2014 22:31:29 -0700 (PDT)
MIME-Version: 1.0
Sender: fairizazizi@gmail.com
Received: by 10.194.63.68 with HTTP; Fri, 17 Oct 2014 22:31:09 -0700 (PDT)
In-Reply-To: <54377E35.6050209@uninett.no>
References: <CAAHrQ0nP+kV3dyEfpF8mY2bHQeUtC5sThAVOhsyFBw10=SxrTg@mail.gmail.com>
 <54323A64.2090205@uninett.no> <CAFx0iW_nwv4iUJ-YgARek4z+N0VXEiyQe-EVaAkiqKnfxtsHbg@mail.gmail.com>
 <CAFx0iW95PruH47=Y44a+5mzeVJQO+njw8u41qkkceMdioH2=DA@mail.gmail.com>
 <543249BB.505@uninett.no> <CADtDQQLVZBVnV0VE5g_kKA6GOPuqs8HQy4E2a_7BcotOgfQpXg@mail.gmail.com>
 <CAFx0iW8WuKFBWdjW7wEpKVt4JdfuXfxpWmpOU36AoaUP-y+haw@mail.gmail.com>
 <CAAHrQ0kc4V-B357hMX2OEDsauxnpniTDPbf9ycx+9oh6qVKXiw@mail.gmail.com>
 <CADtDQQJzkWAW-AZ2zQEYqXy02QnpZ-rHTuf9fYZc5MS3SAgv4w@mail.gmail.com>
 <CAAHrQ0=_XLNuGs+E_SB4eGs54xU=M70-uD+vd5NzZ=3-c-KGyA@mail.gmail.com>
 <CADtDQQJc97mU+P4WV3WwRPi5SohRmn=u5ZdSqJrfLjFgkM1KaA@mail.gmail.com>
 <CAAHrQ0kkg-AgMN2_TVPfCf+XPOYHfc30Py8TvO5QvNbB1=Q2Fw@mail.gmail.com> <54377E35.6050209@uninett.no>
From: Fairiz Azizi <coderfi@gmail.com>
Date: Fri, 17 Oct 2014 22:31:09 -0700
X-Google-Sender-Auth: 3eYJdlDbMFOlJKf6y3EqGjYNo8c
Message-ID: <CAAHrQ0kJxQFJmcutUV=c59F0E20ch39-BuqfGJXJix9AtOeZsg@mail.gmail.com>
Subject: Re: Spark on Mesos 0.20
To: Gurvinder Singh <gurvinder.singh@uninett.no>
Cc: RJ Nowling <rnowling@gmail.com>, Timothy Chen <tnachen@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122950a2d5f130505abcb6b
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122950a2d5f130505abcb6b
Content-Type: text/plain; charset=UTF-8

Hello,

Sorry for the delay (again), we were busy upgrading our cluster from MAPR
3.0.x to Mapr 3.1.1.26113.GA

I updated my builds to include referencing the native hadoop libraries by
this distribution as well as installing SNAPPY (I no longer see the 'unable
to load native hadoop libraries' and also see that it loads the SNAPPY
library).

I ran the example against a directory of ApacheLog files containing about
4.4GB, and things seem to work fine.

time MASTER="mesos://xxxxxxxx*:5050*" /opt/spark/current/bin/run-example
LogQuery "maprfs:///user/hive/warehouse/apachelog/dt=20141017/16"

14/10/18 05:23:21 INFO scheduler.DAGScheduler: Stage 0 (collect at
LogQuery.scala:80) finished in 1.704 s
14/10/18 05:23:21 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0,
whose tasks have all completed, from pool default
14/10/18 05:23:21 INFO spark.SparkContext: Job finished: collect at
LogQuery.scala:80, took 40.533904277 s
(null,null,null) bytes=0 n=16682940

real 0m51.393s
user 0m19.130s
sys 0m4.120s

So this combination of software seems to work fine for me!

Spark 1.1.0
Mesos 0.20.1
MAPR 3.1.1.26113.GA
spark-1.1.0-bin-mapr3.tgz

Note: one thing you might try is increasing your spark.executor.memory
setting
Mine was set to 8GB in the spark-defaults.conf file.

Hope this helps,
Fi


Fairiz "Fi" Azizi

On Thu, Oct 9, 2014 at 11:35 PM, Gurvinder Singh <gurvinder.singh@uninett.no
> wrote:

> On 10/10/2014 06:11 AM, Fairiz Azizi wrote:
> > Hello,
> >
> > Sorry for the late reply.
> >
> > When I tried the LogQuery example this time, things now seem to be fine!
> >
> > ...
> >
> > 14/10/10 04:01:21 INFO scheduler.DAGScheduler: Stage 0 (collect at
> > LogQuery.scala:80) finished in 0.429 s
> >
> > 14/10/10 04:01:21 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0,
> > whose tasks have all completed, from pool defa
> >
> > 14/10/10 04:01:21 INFO spark.SparkContext: Job finished: collect at
> > LogQuery.scala:80, took 12.802743914 s
> >
> > (10.10.10.10,"FRED",GET http://images.com/2013/Generic.jpg HTTP/1.1)
> > bytes=621       n=2
> >
> >
> > Not sure if this is the correct response for that example.
> >
> > Our mesos/spark builds have since been updated since I last wrote.
> >
> > Possibly, the JDK version was updated to 1.7.0_67
> >
> > If you are using an older JDK, maybe try updating that?
> I have tested on current JDK 7 and now I am running JDK 8, the problem
> still exist. Can you run logquery on data of size say 100+ GB, so that
> you have more map tasks. As we start to see the issue on larger tasks.
>
> - Gurvinder
> >
> >
> > - Fi
> >
> >
> >
> > Fairiz "Fi" Azizi
> >
> > On Wed, Oct 8, 2014 at 7:54 AM, RJ Nowling <rnowling@gmail.com
> > <mailto:rnowling@gmail.com>> wrote:
> >
> >     Yep!  That's the example I was talking about.
> >
> >     Is an error message printed when it hangs? I get :
> >
> >     14/09/30 13:23:14 ERROR BlockManagerMasterActor: Got two different
> block manager registrations on 20140930-131734-1723727882-5050-1895-1
> >
> >
> >
> >     On Tue, Oct 7, 2014 at 8:36 PM, Fairiz Azizi <coderfi@gmail.com
> >     <mailto:coderfi@gmail.com>> wrote:
> >
> >         Sure, could you point me to the example?
> >
> >         The only thing I could find was
> >
> https://github.com/apache/spark/blob/master/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala
> >
> >         So do you mean running it like:
> >            MASTER="mesos://xxxxxxx_:5050_" ./run-example LogQuery
> >
> >         I tried that and I can see the job run and the tasks complete on
> >         the slave nodes, but the client process seems to hang forever,
> >         it's probably a different problem. BTW, only a dozen or so tasks
> >         kick off.
> >
> >         I actually haven't done much with Scala and Spark (it's been all
> >         python).
> >
> >         Fi
> >
> >
> >
> >         Fairiz "Fi" Azizi
> >
> >         On Tue, Oct 7, 2014 at 6:29 AM, RJ Nowling <rnowling@gmail.com
> >         <mailto:rnowling@gmail.com>> wrote:
> >
> >             I was able to reproduce it on a small 4 node cluster (1
> >             mesos master and 3 mesos slaves) with relatively low-end
> >             specs.  As I said, I just ran the log query examples with
> >             the fine-grained mesos mode.
> >
> >             Spark 1.1.0 and mesos 0.20.1.
> >
> >             Fairiz, could you try running the logquery example included
> >             with Spark and see what you get?
> >
> >             Thanks!
> >
> >             On Mon, Oct 6, 2014 at 8:07 PM, Fairiz Azizi
> >             <coderfi@gmail.com <mailto:coderfi@gmail.com>> wrote:
> >
> >                 That's what great about Spark, the community is so
> >                 active! :)
> >
> >                 I compiled Mesos 0.20.1 from the source tarball.
> >
> >                 Using the Mapr3 Spark 1.1.0 distribution from the Spark
> >                 downloads page  (spark-1.1.0-bin-mapr3.tgz).
> >
> >                 I see no problems for the workloads we are trying.
> >
> >                 However, the cluster is small (less than 100 cores
> >                 across 3 nodes).
> >
> >                 The workloads reads in just a few gigabytes from HDFS,
> >                 via an ipython notebook spark shell.
> >
> >                 thanks,
> >                 Fi
> >
> >
> >
> >                 Fairiz "Fi" Azizi
> >
> >                 On Mon, Oct 6, 2014 at 9:20 AM, Timothy Chen
> >                 <tnachen@gmail.com <mailto:tnachen@gmail.com>> wrote:
> >
> >                     Ok I created SPARK-3817 to track this, will try to
> >                     repro it as well.
> >
> >                     Tim
> >
> >                     On Mon, Oct 6, 2014 at 6:08 AM, RJ Nowling
> >                     <rnowling@gmail.com <mailto:rnowling@gmail.com>>
> wrote:
> >                     > I've recently run into this issue as well. I get
> >                     it from running Spark
> >                     > examples such as log query.  Maybe that'll help
> >                     reproduce the issue.
> >                     >
> >                     >
> >                     > On Monday, October 6, 2014, Gurvinder Singh
> >                     <gurvinder.singh@uninett.no
> >                     <mailto:gurvinder.singh@uninett.no>>
> >                     > wrote:
> >                     >>
> >                     >> The issue does not occur if the task at hand has
> >                     small number of map
> >                     >> tasks. I have a task which has 978 map tasks and
> >                     I see this error as
> >                     >>
> >                     >> 14/10/06 09:34:40 ERROR BlockManagerMasterActor:
> >                     Got two different block
> >                     >> manager registrations on
> >                     20140711-081617-711206558-5050-2543-5
> >                     >>
> >                     >> Here is the log from the mesos-slave where this
> >                     container was running.
> >                     >>
> >                     >> http://pastebin.com/Q1Cuzm6Q
> >                     >>
> >                     >> If you look for the code from where error
> >                     produced by spark, you will
> >                     >> see that it simply exit and saying in comments
> >                     "this should never
> >                     >> happen, lets just quit" :-)
> >                     >>
> >                     >> - Gurvinder
> >                     >> On 10/06/2014 09:30 AM, Timothy Chen wrote:
> >                     >> > (Hit enter too soon...)
> >                     >> >
> >                     >> > What is your setup and steps to repro this?
> >                     >> >
> >                     >> > Tim
> >                     >> >
> >                     >> > On Mon, Oct 6, 2014 at 12:30 AM, Timothy Chen
> >                     <tnachen@gmail.com <mailto:tnachen@gmail.com>>
> wrote:
> >                     >> >> Hi Gurvinder,
> >                     >> >>
> >                     >> >> I tried fine grain mode before and didn't get
> >                     into that problem.
> >                     >> >>
> >                     >> >>
> >                     >> >> On Sun, Oct 5, 2014 at 11:44 PM, Gurvinder
> Singh
> >                     >> >> <gurvinder.singh@uninett.no
> >                     <mailto:gurvinder.singh@uninett.no>> wrote:
> >                     >> >>> On 10/06/2014 08:19 AM, Fairiz Azizi wrote:
> >                     >> >>>> The Spark online docs indicate that Spark is
> >                     compatible with Mesos
> >                     >> >>>> 0.18.1
> >                     >> >>>>
> >                     >> >>>> I've gotten it to work just fine on 0.18.1
> >                     and 0.18.2
> >                     >> >>>>
> >                     >> >>>> Has anyone tried Spark on a newer version of
> >                     Mesos, i.e. Mesos
> >                     >> >>>> v0.20.0?
> >                     >> >>>>
> >                     >> >>>> -Fi
> >                     >> >>>>
> >                     >> >>> Yeah we are using Spark 1.1.0 with Mesos
> >                     0.20.1. It runs fine in
> >                     >> >>> coarse
> >                     >> >>> mode, in fine grain mode there is an issue
> >                     with blockmanager names
> >                     >> >>> conflict. I have been waiting for it to be
> >                     fixed but it is still
> >                     >> >>> there.
> >                     >> >>>
> >                     >> >>> -Gurvinder
> >                     >> >>>
> >                     >> >>>
> >
>  ---------------------------------------------------------------------
> >                     >> >>> To unsubscribe, e-mail:
> >                     dev-unsubscribe@spark.apache.org
> >                     <mailto:dev-unsubscribe@spark.apache.org>
> >                     >> >>> For additional commands, e-mail:
> >                     dev-help@spark.apache.org
> >                     <mailto:dev-help@spark.apache.org>
> >                     >> >>>
> >                     >>
> >                     >>
> >                     >>
> >
>  ---------------------------------------------------------------------
> >                     >> To unsubscribe, e-mail:
> >                     dev-unsubscribe@spark.apache.org
> >                     <mailto:dev-unsubscribe@spark.apache.org>
> >                     >> For additional commands, e-mail:
> >                     dev-help@spark.apache.org
> >                     <mailto:dev-help@spark.apache.org>
> >                     >>
> >                     >
> >                     >
> >                     > --
> >                     > em rnowling@gmail.com <mailto:rnowling@gmail.com>
> >                     > c 954.496.2314 <tel:954.496.2314>
> >
> >
> >
> >
> >
> >             --
> >             em rnowling@gmail.com <mailto:rnowling@gmail.com>
> >             c 954.496.2314 <tel:954.496.2314>
> >
> >
> >
> >
> >
> >     --
> >     em rnowling@gmail.com <mailto:rnowling@gmail.com>
> >     c 954.496.2314 <tel:954.496.2314>
> >
> >
>
>

--089e0122950a2d5f130505abcb6b--

From dev-return-9859-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 06:03:40 2014
Return-Path: <dev-return-9859-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 23A2217A32
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 06:03:40 +0000 (UTC)
Received: (qmail 18144 invoked by uid 500); 18 Oct 2014 06:03:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18072 invoked by uid 500); 18 Oct 2014 06:03:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18056 invoked by uid 99); 18 Oct 2014 06:03:38 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 06:03:38 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 06:03:35 +0000
Received: by mail-la0-f52.google.com with SMTP id hz20so1715195lab.11
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 23:03:13 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=hpInfGts1siTHEh8rkHHSJcWn5HuKDvpgI+XKYK67Oo=;
        b=McSGSzjQYOrNx8akopX6PCx5c8+umZLTZFTuRgvyHES5WKYSjU/1OlT1bG5aOYKDqK
         DF5hNU9WtpyxqlOZ/X0bDFYTiAZSWpc6PLuD3m0ptInh35r809SPUQ5jntk4A0cgPGcT
         hIRaRavmRtEwX3yZDhcQ0qK5A7KjVfQOx6a02lDAEu96sAJr/U+B9uYsjm28pmM6Xo6u
         kEKv8mMM8rHCBfZfs4jkzXN1TqbJVIFTQefnUJoL9j509DvBW8cpBtehe22VDt1tzO30
         lZ24Cdh632nHlKUUsVWMmk1tRQjQ99lYvhScqirOWZ50ghaA2W3KbuvU2P9NUCtqPuoQ
         GBPQ==
X-Gm-Message-State: ALoCoQnsoLAaWfv81OFJqMmSyPEwTrExA6qc0OLMvTWCFO+7Lmyqkv6S3Tv1ztPJDKo4WgL7FBMm
MIME-Version: 1.0
X-Received: by 10.112.247.43 with SMTP id yb11mr13284914lbc.51.1413612193616;
 Fri, 17 Oct 2014 23:03:13 -0700 (PDT)
Received: by 10.25.162.65 with HTTP; Fri, 17 Oct 2014 23:03:13 -0700 (PDT)
In-Reply-To: <etPan.5441bf93.643c9869.107@joshs-mbp>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
	<CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
	<CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
	<CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
	<CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
	<CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
	<CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
	<CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
	<CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
	<CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
	<CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
	<CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
	<CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
	<CACdU-dSea+ETt6hipNzVHtaiAN4Wd_VpSNkwJaZrALfy8X8nQA@mail.gmail.com>
	<CA+2Pv=jYG3gTu4yxtanaGp4_uBeyb+Q_yX97kaMG0BpZ2OL3DA@mail.gmail.com>
	<etPan.5441bf93.643c9869.107@joshs-mbp>
Date: Fri, 17 Oct 2014 23:03:13 -0700
Message-ID: <CA+2Pv=iv=qJAycXYk5pHq8+Jf9qcd=tEEDp63djnano3A1c6bw@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
From: Davies Liu <davies@databricks.com>
To: Josh Rosen <rosenville@gmail.com>
Cc: shane knapp <sknapp@berkeley.edu>, dev <dev@spark.apache.org>, 
	Nicholas Chammas <nicholas.chammas@gmail.com>, amp-infra <amp-infra@googlegroups.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

How can we know the changes has been applied? I had checked several
recent builds, they all use the original configs.

Davies

On Fri, Oct 17, 2014 at 6:17 PM, Josh Rosen <rosenville@gmail.com> wrote:
> FYI, I edited the Spark Pull Request Builder job to try this out.  Let=E2=
=80=99s see
> if it works (I=E2=80=99ll be around to revert if it doesn=E2=80=99t).
>
> On October 17, 2014 at 5:26:56 PM, Davies Liu (davies@databricks.com) wro=
te:
>
> One finding is that all the timeout happened with this command:
>
> git fetch --tags --progress https://github.com/apache/spark.git
> +refs/pull/*:refs/remotes/origin/pr/*
>
> I'm thinking that maybe this may be a expensive call, we could try to
> use a more cheap one:
>
> git fetch --tags --progress https://github.com/apache/spark.git
> +refs/pull/XXX/*:refs/remotes/origin/pr/XXX/*
>
> XXX is the PullRequestID,
>
> The configuration support parameters [1], so we could put this in :
>
> +refs/pull//${ghprbPullId}/*:refs/remotes/origin/pr/${ghprbPullId}/*
>
> I have not tested this yet, could you give this a try?
>
> Davies
>
>
> [1]
> https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder+p=
lugin
>
> On Fri, Oct 17, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu> wrote:
>> actually, nvm, you have to be run that command from our servers to affec=
t
>> our limit. run it all you want from your own machines! :P
>>
>> On Fri, Oct 17, 2014 at 4:59 PM, shane knapp <sknapp@berkeley.edu> wrote=
:
>>
>>> yep, and i will tell you guys ONLY if you promise to NOT try this
>>> yourselves... checking the rate limit also counts as a hit and incremen=
ts
>>> our numbers:
>>>
>>> # curl -i https://api.github.com/users/whatever 2> /dev/null | egrep
>>> ^X-Rate
>>> X-RateLimit-Limit: 60
>>> X-RateLimit-Remaining: 51
>>> X-RateLimit-Reset: 1413590269
>>>
>>> (yes, that is the exact url that they recommended on the github site lo=
l)
>>>
>>> so, earlier today, we had a spark build fail w/a git timeout at 10:57am=
,
>>> but there were only ~7 builds run that hour, so that points to us NOT
>>> hitting the rate limit... at least for this fail. whee!
>>>
>>> is it beer-thirty yet?
>>>
>>> shane
>>>
>>>
>>>
>>> On Fri, Oct 17, 2014 at 4:52 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> Wow, thanks for this deep dive Shane. Is there a way to check if we ar=
e
>>>> getting hit by rate limiting directly, or do we need to contact GitHub
>>>> for that?
>>>>
>>>> 2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, sha=
ne knapp<sknapp@berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C=
 =EB=A9=94=EC=8B=9C=EC=A7=80:
>>>>
>>>> quick update:
>>>>>
>>>>> here are some stats i scraped over the past week of ALL pull request
>>>>> builder projects and timeout failures. due to the large number of spa=
rk
>>>>> ghprb jobs, i don't have great records earlier than oct 7th. the data
>>>>> is
>>>>> current up until ~230pm today:
>>>>>
>>>>> spark and new spark ghprb total builds vs git fetch timeouts:
>>>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -i
>>>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -i spark | wc -l); l=
et
>>>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$tot=
al" | bc
>>>>> |
>>>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>>>> $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>>>>> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34%
>>>>> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09%
>>>>> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0%
>>>>> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12%
>>>>> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10%
>>>>> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28%
>>>>> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08%
>>>>> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16%
>>>>> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23%
>>>>>
>>>>> all other ghprb builds vs git fetch timeouts:
>>>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -v=
i
>>>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -vi spark | wc -l); =
let
>>>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$tot=
al" | bc
>>>>> |
>>>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>>>> $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>>>>> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0%
>>>>> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13%
>>>>> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0%
>>>>> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0%
>>>>> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0%
>>>>> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0%
>>>>> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0%
>>>>> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0%
>>>>> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0%
>>>>>
>>>>> note: the 15th was the day i rolled back to the earlier version of th=
e
>>>>> git plugin. it doesn't seem to have helped much, so i'll probably bri=
ng
>>>>> us
>>>>> back up to the latest version soon.
>>>>> also note: rocking some floating point math on the CLI! ;)
>>>>>
>>>>> i also compared the distribution of git timeout failures vs time of
>>>>> day,
>>>>> and there appears to be no correlation. the failures are pretty evenl=
y
>>>>> distributed over each hour of the day.
>>>>>
>>>>> we could be hitting the rate limit due to the ghprb hitting github a
>>>>> couple of times for each build, but we're averaging ~10-20 builds per
>>>>> hour
>>>>> (a build hits github 2-4 times, from what i can tell). i'll have to
>>>>> look
>>>>> more in to this on monday, but suffice to say we may need to move fro=
m
>>>>> unauthorized https fetches to authorized requests. this means
>>>>> retrofitting
>>>>> all of our jobs. yay! fun! :)
>>>>>
>>>>> another option is to have local mirrors of all of the repos. the
>>>>> problem w/this is that there might be a window where changes haven't
>>>>> made
>>>>> it to the local mirror and tests run against it. more fun stuff to
>>>>> think
>>>>> about...
>>>>>
>>>>> now that i have some stats, and a list of all of the times/dates of t=
he
>>>>> failures, i will be drafting my email to github and firing that off
>>>>> later
>>>>> today or first thing monday.
>>>>>
>>>>> have a great weekend everyone!
>>>>>
>>>>> shane, who spent way too much time on the CLI and is ready for some
>>>>> beer.
>>>>>
>>>>> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas <
>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>
>>>>>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu>
>>>>>> wrote:
>>>>>>
>>>>>>> i really, truly hate non-deterministic failures.
>>>>>>
>>>>>>
>>>>>> Amen bruddah.
>>>>>>
>>>>>
>>>>>
>>>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9860-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 06:06:29 2014
Return-Path: <dev-return-9860-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A7FFF17A41
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 06:06:29 +0000 (UTC)
Received: (qmail 20711 invoked by uid 500); 18 Oct 2014 06:06:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20631 invoked by uid 500); 18 Oct 2014 06:06:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20619 invoked by uid 99); 18 Oct 2014 06:06:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 06:06:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.192.178 as permitted sender)
Received: from [209.85.192.178] (HELO mail-pd0-f178.google.com) (209.85.192.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 06:06:24 +0000
Received: by mail-pd0-f178.google.com with SMTP id y10so1962358pdj.9
        for <dev@spark.apache.org>; Fri, 17 Oct 2014 23:06:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=Cg4SKcqYDp6+qEUd/omJDXCutM9DNM/6p5hcSSruNBk=;
        b=ZpWlJZqYZggMNVSoOQDi8wPz3ql+Aoa0GScQq6/cfsVN4FjPF4b4Oio/5iLud/GKg6
         XidSRkXt4SgXgEa1usc9IuIqTwsX9yQ7YrGEXxn3wqiAn8RQ4b/UOgvlHMZLp0bxfEjD
         orhsvUpDeIYl4aJilIhG52V9OUgUbYtufryP81hEAbGMSvzVN/WQUwznxSdW3aIoK9H1
         yzXxxoWeIrVOdW4D/1ESP/xvmlmm1UL+D97OBETYcXjnF0zBz57ABSJ5Raj7t+o0SR0/
         qBzCt5XPZYdXKzc+cWbN/rRbhyeF7ZPU3PdSs5Irh5h1qh2+7Ehwj+sGIEa0qQL0HSK1
         hrzg==
X-Received: by 10.68.255.195 with SMTP id as3mr13594126pbd.38.1413612364215;
        Fri, 17 Oct 2014 23:06:04 -0700 (PDT)
Received: from joshs-mbp.att.net ([2602:306:cdd1:b10:899f:28b9:79fe:749])
        by mx.google.com with ESMTPSA id y1sm3114513pdg.47.2014.10.17.23.06.03
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Fri, 17 Oct 2014 23:06:03 -0700 (PDT)
Date: Fri, 17 Oct 2014 23:06:02 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Davies Liu <davies@databricks.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, amp-infra
 <amp-infra@googlegroups.com>, shane knapp <sknapp@berkeley.edu>, dev
 <dev@spark.apache.org>
Message-ID: <etPan.5442034a.74b0dc51.107@joshs-mbp.att.net>
In-Reply-To: <CA+2Pv=iv=qJAycXYk5pHq8+Jf9qcd=tEEDp63djnano3A1c6bw@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
 <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
 <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
 <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
 <CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
 <CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
 <CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
 <CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
 <CACdU-dSea+ETt6hipNzVHtaiAN4Wd_VpSNkwJaZrALfy8X8nQA@mail.gmail.com>
 <CA+2Pv=jYG3gTu4yxtanaGp4_uBeyb+Q_yX97kaMG0BpZ2OL3DA@mail.gmail.com>
 <etPan.5441bf93.643c9869.107@joshs-mbp>
 <CA+2Pv=iv=qJAycXYk5pHq8+Jf9qcd=tEEDp63djnano3A1c6bw@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of
 the git fetch timeouts
X-Mailer: Airmail Beta (269)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5442034a_19495cff_107"
X-Virus-Checked: Checked by ClamAV on apache.org

--5442034a_19495cff_107
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I think that the fix was applied. =C2=A0Take a look at=C2=A0https://ampla=
b.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21874/console=46ull=


Here, I see a fetch command that mentions this specific PR branch rather =
than the wildcard that we had before:

 > git fetch --tags --progress https://github.com/apache/spark.git +refs/=
pull/2840/*:refs/remotes/origin/pr/2840/* =23 timeout=3D15

Do you have an example of a Spark PRB build that=E2=80=99s still failing =
with the old fetch failure=3F

- Josh
On October 17, 2014 at 11:03:14 PM, Davies Liu (davies=40databricks.com) =
wrote:

How can we know the changes has been applied=3F I had checked several =20
recent builds, they all use the original configs. =20

Davies =20

On =46ri, Oct 17, 2014 at 6:17 PM, Josh Rosen <rosenville=40gmail.com> wr=
ote: =20
> =46YI, I edited the Spark Pull Request Builder job to try this out. Let=
=E2=80=99s see =20
> if it works (I=E2=80=99ll be around to revert if it doesn=E2=80=99t). =20
> =20
> On October 17, 2014 at 5:26:56 PM, Davies Liu (davies=40databricks.com)=
 wrote: =20
> =20
> One finding is that all the timeout happened with this command: =20
> =20
> git fetch --tags --progress https://github.com/apache/spark.git =20
> +refs/pull/*:refs/remotes/origin/pr/* =20
> =20
> I'm thinking that maybe this may be a expensive call, we could try to =20
> use a more cheap one: =20
> =20
> git fetch --tags --progress https://github.com/apache/spark.git =20
> +refs/pull/XXX/*:refs/remotes/origin/pr/XXX/* =20
> =20
> XXX is the PullRequestID, =20
> =20
> The configuration support parameters =5B1=5D, so we could put this in :=
 =20
> =20
> +refs/pull//=24=7BghprbPullId=7D/*:refs/remotes/origin/pr/=24=7BghprbPu=
llId=7D/* =20
> =20
> I have not tested this yet, could you give this a try=3F =20
> =20
> Davies =20
> =20
> =20
> =5B1=5D =20
> https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder=
+plugin =20
> =20
> On =46ri, Oct 17, 2014 at 5:00 PM, shane knapp <sknapp=40berkeley.edu> =
wrote: =20
>> actually, nvm, you have to be run that command from our servers to aff=
ect =20
>> our limit. run it all you want from your own machines=21 :P =20
>> =20
>> On =46ri, Oct 17, 2014 at 4:59 PM, shane knapp <sknapp=40berkeley.edu>=
 wrote: =20
>> =20
>>> yep, and i will tell you guys ONLY if you promise to NOT try this =20
>>> yourselves... checking the rate limit also counts as a hit and increm=
ents =20
>>> our numbers: =20
>>> =20
>>> =23 curl -i https://api.github.com/users/whatever 2> /dev/null =7C eg=
rep =20
>>> =5EX-Rate =20
>>> X-RateLimit-Limit: 60 =20
>>> X-RateLimit-Remaining: 51 =20
>>> X-RateLimit-Reset: 1413590269 =20
>>> =20
>>> (yes, that is the exact url that they recommended on the github site =
lol) =20
>>> =20
>>> so, earlier today, we had a spark build fail w/a git timeout at 10:57=
am, =20
>>> but there were only =7E7 builds run that hour, so that points to us N=
OT =20
>>> hitting the rate limit... at least for this fail. whee=21 =20
>>> =20
>>> is it beer-thirty yet=3F =20
>>> =20
>>> shane =20
>>> =20
>>> =20
>>> =20
>>> On =46ri, Oct 17, 2014 at 4:52 PM, Nicholas Chammas < =20
>>> nicholas.chammas=40gmail.com> wrote: =20
>>> =20
>>>> Wow, thanks for this deep dive Shane. Is there a way to check if we =
are =20
>>>> getting hit by rate limiting directly, or do we need to contact GitH=
ub =20
>>>> for that=3F =20
>>>> =20
>>>> 2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, s=
hane knapp<sknapp=40berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=
=95=9C =EB=A9=94=EC=8B=9C=EC=A7=80: =20
>>>> =20
>>>> quick update: =20
>>>>> =20
>>>>> here are some stats i scraped over the past week of ALL pull reques=
t =20
>>>>> builder projects and timeout failures. due to the large number of s=
park =20
>>>>> ghprb jobs, i don't have great records earlier than oct 7th. the da=
ta =20
>>>>> is =20
>>>>> current up until =7E230pm today: =20
>>>>> =20
>>>>> spark and new spark ghprb total builds vs git fetch timeouts: =20
>>>>> =24 for x in 10-=7B09..17=7D; do passed=3D=24(grep =24x SORTED.pass=
ed =7C grep -i =20
>>>>> spark =7C wc -l); failed=3D=24(grep =24x SORTED =7C grep -i spark =7C=
 wc -l); let =20
>>>>> total=3Dpassed+failed; fail=5Fpercent=3D=24(echo =22scale=3D2; =24f=
ailed/=24total=22 =7C bc =20
>>>>> =7C =20
>>>>> sed =22s/=5E=5C.//g=22); line=3D=22=24x -- total builds: =24total=5C=
tp/f: =20
>>>>> =24passed/=24failed=5Ctfail%: =24fail=5Fpercent%=22; echo -e =24lin=
e; done =20
>>>>> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34% =20
>>>>> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09% =20
>>>>> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0% =20
>>>>> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12% =20
>>>>> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10% =20
>>>>> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28% =20
>>>>> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08% =20
>>>>> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16% =20
>>>>> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23% =20
>>>>> =20
>>>>> all other ghprb builds vs git fetch timeouts: =20
>>>>> =24 for x in 10-=7B09..17=7D; do passed=3D=24(grep =24x SORTED.pass=
ed =7C grep -vi =20
>>>>> spark =7C wc -l); failed=3D=24(grep =24x SORTED =7C grep -vi spark =
=7C wc -l); let =20
>>>>> total=3Dpassed+failed; fail=5Fpercent=3D=24(echo =22scale=3D2; =24f=
ailed/=24total=22 =7C bc =20
>>>>> =7C =20
>>>>> sed =22s/=5E=5C.//g=22); line=3D=22=24x -- total builds: =24total=5C=
tp/f: =20
>>>>> =24passed/=24failed=5Ctfail%: =24fail=5Fpercent%=22; echo -e =24lin=
e; done =20
>>>>> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0% =20
>>>>> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13% =20
>>>>> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0% =20
>>>>> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0% =20
>>>>> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0% =20
>>>>> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0% =20
>>>>> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0% =20
>>>>> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0% =20
>>>>> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0% =20
>>>>> =20
>>>>> note: the 15th was the day i rolled back to the earlier version of =
the =20
>>>>> git plugin. it doesn't seem to have helped much, so i'll probably b=
ring =20
>>>>> us =20
>>>>> back up to the latest version soon. =20
>>>>> also note: rocking some floating point math on the CLI=21 ;) =20
>>>>> =20
>>>>> i also compared the distribution of git timeout failures vs time of=
 =20
>>>>> day, =20
>>>>> and there appears to be no correlation. the failures are pretty eve=
nly =20
>>>>> distributed over each hour of the day. =20
>>>>> =20
>>>>> we could be hitting the rate limit due to the ghprb hitting github =
a =20
>>>>> couple of times for each build, but we're averaging =7E10-20 builds=
 per =20
>>>>> hour =20
>>>>> (a build hits github 2-4 times, from what i can tell). i'll have to=
 =20
>>>>> look =20
>>>>> more in to this on monday, but suffice to say we may need to move f=
rom =20
>>>>> unauthorized https fetches to authorized requests. this means =20
>>>>> retrofitting =20
>>>>> all of our jobs. yay=21 fun=21 :) =20
>>>>> =20
>>>>> another option is to have local mirrors of all of the repos. the =20
>>>>> problem w/this is that there might be a window where changes haven'=
t =20
>>>>> made =20
>>>>> it to the local mirror and tests run against it. more fun stuff to =
=20
>>>>> think =20
>>>>> about... =20
>>>>> =20
>>>>> now that i have some stats, and a list of all of the times/dates of=
 the =20
>>>>> failures, i will be drafting my email to github and firing that off=
 =20
>>>>> later =20
>>>>> today or first thing monday. =20
>>>>> =20
>>>>> have a great weekend everyone=21 =20
>>>>> =20
>>>>> shane, who spent way too much time on the CLI and is ready for some=
 =20
>>>>> beer. =20
>>>>> =20
>>>>> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas < =20
>>>>> nicholas.chammas=40gmail.com> wrote: =20
>>>>> =20
>>>>>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp=40berkeley.ed=
u> =20
>>>>>> wrote: =20
>>>>>> =20
>>>>>>> i really, truly hate non-deterministic failures. =20
>>>>>> =20
>>>>>> =20
>>>>>> Amen bruddah. =20
>>>>>> =20
>>>>> =20
>>>>> =20
>>> =20
> =20
> --------------------------------------------------------------------- =20
> To unsubscribe, e-mail: dev-unsubscribe=40spark.apache.org =20
> =46or additional commands, e-mail: dev-help=40spark.apache.org =20
> =20

--5442034a_19495cff_107--


From dev-return-9861-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 07:44:53 2014
Return-Path: <dev-return-9861-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7889317B56
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 07:44:53 +0000 (UTC)
Received: (qmail 80921 invoked by uid 500); 18 Oct 2014 07:44:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80843 invoked by uid 500); 18 Oct 2014 07:44:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80832 invoked by uid 99); 18 Oct 2014 07:44:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 07:44:52 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 07:44:26 +0000
Received: by mail-la0-f54.google.com with SMTP id gm9so1761375lab.27
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 00:44:25 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=cpmfv0rOEjN6V6Zx5uC3Jk4Zgs5gGKEbiMKaHobh3tI=;
        b=fgcmzy/a8XvjrBxmwazqWc99y7eDKBVmvDoo38DA304FwJt/53b5ARDJ6Vmzcek03L
         eF47X6cFtseIepDqEi+m51u6fRupR2HiBDpLd9p+8EE2Wp2jpR1eSFBB7tLA85sajvVh
         qCN/ps7sRJfrCfb2VWVlA1HEm9G1US3wvDIN3zqwoqqRGIL+h4l67zydkg9wP8RSMul/
         l+TjeIi2fPKITkIVfzkK44Tm7bV2gP12MZdzlJCY7IPW9uDMulOoIvftzh9Cpfb4zLRd
         3ltWStjJ/FE1SIQFVcPv4UL2SO5L7oT8fYLreVuISDqy75zuxVj5A/Xyx1IYrQ/5dwgD
         AUxw==
X-Gm-Message-State: ALoCoQk1KlWUrnWQd3SK5P/IyufYAB7vkufTwyPJ94ko60Mjbv4/sWMU2fPrVg6FZfin7IVK90bU
MIME-Version: 1.0
X-Received: by 10.152.20.132 with SMTP id n4mr13917205lae.50.1413618265505;
 Sat, 18 Oct 2014 00:44:25 -0700 (PDT)
Received: by 10.25.162.65 with HTTP; Sat, 18 Oct 2014 00:44:25 -0700 (PDT)
In-Reply-To: <etPan.5442034a.74b0dc51.107@joshs-mbp.att.net>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
	<CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
	<CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
	<CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
	<CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
	<CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
	<CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
	<CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
	<CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
	<CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
	<CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
	<CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
	<CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
	<CACdU-dSea+ETt6hipNzVHtaiAN4Wd_VpSNkwJaZrALfy8X8nQA@mail.gmail.com>
	<CA+2Pv=jYG3gTu4yxtanaGp4_uBeyb+Q_yX97kaMG0BpZ2OL3DA@mail.gmail.com>
	<etPan.5441bf93.643c9869.107@joshs-mbp>
	<CA+2Pv=iv=qJAycXYk5pHq8+Jf9qcd=tEEDp63djnano3A1c6bw@mail.gmail.com>
	<etPan.5442034a.74b0dc51.107@joshs-mbp.att.net>
Date: Sat, 18 Oct 2014 00:44:25 -0700
Message-ID: <CA+2Pv=i5gsx2zrOXc31biM=1M7gb5FJeO95jeCgHLQQPc2DXbQ@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
From: Davies Liu <davies@databricks.com>
To: Josh Rosen <rosenville@gmail.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, amp-infra <amp-infra@googlegroups.com>, 
	shane knapp <sknapp@berkeley.edu>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Cool, the recent 4 build had used the new configs, thanks!

Let's run more builds.

Davies

On Fri, Oct 17, 2014 at 11:06 PM, Josh Rosen <rosenville@gmail.com> wrote:
> I think that the fix was applied.  Take a look at
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21874/=
consoleFull
>
> Here, I see a fetch command that mentions this specific PR branch rather
> than the wildcard that we had before:
>
>  > git fetch --tags --progress https://github.com/apache/spark.git
> +refs/pull/2840/*:refs/remotes/origin/pr/2840/* # timeout=3D15
>
>
> Do you have an example of a Spark PRB build that=E2=80=99s still failing =
with the
> old fetch failure?
>
> - Josh
>
> On October 17, 2014 at 11:03:14 PM, Davies Liu (davies@databricks.com)
> wrote:
>
> How can we know the changes has been applied? I had checked several
> recent builds, they all use the original configs.
>
> Davies
>
> On Fri, Oct 17, 2014 at 6:17 PM, Josh Rosen <rosenville@gmail.com> wrote:
>> FYI, I edited the Spark Pull Request Builder job to try this out. Let=E2=
=80=99s
>> see
>> if it works (I=E2=80=99ll be around to revert if it doesn=E2=80=99t).
>>
>> On October 17, 2014 at 5:26:56 PM, Davies Liu (davies@databricks.com)
>> wrote:
>>
>> One finding is that all the timeout happened with this command:
>>
>> git fetch --tags --progress https://github.com/apache/spark.git
>> +refs/pull/*:refs/remotes/origin/pr/*
>>
>> I'm thinking that maybe this may be a expensive call, we could try to
>> use a more cheap one:
>>
>> git fetch --tags --progress https://github.com/apache/spark.git
>> +refs/pull/XXX/*:refs/remotes/origin/pr/XXX/*
>>
>> XXX is the PullRequestID,
>>
>> The configuration support parameters [1], so we could put this in :
>>
>> +refs/pull//${ghprbPullId}/*:refs/remotes/origin/pr/${ghprbPullId}/*
>>
>> I have not tested this yet, could you give this a try?
>>
>> Davies
>>
>>
>> [1]
>>
>> https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder+=
plugin
>>
>> On Fri, Oct 17, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu> wrote=
:
>>> actually, nvm, you have to be run that command from our servers to affe=
ct
>>> our limit. run it all you want from your own machines! :P
>>>
>>> On Fri, Oct 17, 2014 at 4:59 PM, shane knapp <sknapp@berkeley.edu> wrot=
e:
>>>
>>>> yep, and i will tell you guys ONLY if you promise to NOT try this
>>>> yourselves... checking the rate limit also counts as a hit and
>>>> increments
>>>> our numbers:
>>>>
>>>> # curl -i https://api.github.com/users/whatever 2> /dev/null | egrep
>>>> ^X-Rate
>>>> X-RateLimit-Limit: 60
>>>> X-RateLimit-Remaining: 51
>>>> X-RateLimit-Reset: 1413590269
>>>>
>>>> (yes, that is the exact url that they recommended on the github site
>>>> lol)
>>>>
>>>> so, earlier today, we had a spark build fail w/a git timeout at 10:57a=
m,
>>>> but there were only ~7 builds run that hour, so that points to us NOT
>>>> hitting the rate limit... at least for this fail. whee!
>>>>
>>>> is it beer-thirty yet?
>>>>
>>>> shane
>>>>
>>>>
>>>>
>>>> On Fri, Oct 17, 2014 at 4:52 PM, Nicholas Chammas <
>>>> nicholas.chammas@gmail.com> wrote:
>>>>
>>>>> Wow, thanks for this deep dive Shane. Is there a way to check if we a=
re
>>>>> getting hit by rate limiting directly, or do we need to contact GitHu=
b
>>>>> for that?
>>>>>
>>>>> 2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, sh=
ane knapp<sknapp@berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=
=9C =EB=A9=94=EC=8B=9C=EC=A7=80:
>>>>>
>>>>> quick update:
>>>>>>
>>>>>> here are some stats i scraped over the past week of ALL pull request
>>>>>> builder projects and timeout failures. due to the large number of
>>>>>> spark
>>>>>> ghprb jobs, i don't have great records earlier than oct 7th. the dat=
a
>>>>>> is
>>>>>> current up until ~230pm today:
>>>>>>
>>>>>> spark and new spark ghprb total builds vs git fetch timeouts:
>>>>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -=
i
>>>>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -i spark | wc -l); =
let
>>>>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$to=
tal" |
>>>>>> bc
>>>>>> |
>>>>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>>>>> $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>>>>>> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34%
>>>>>> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09%
>>>>>> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0%
>>>>>> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12%
>>>>>> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10%
>>>>>> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28%
>>>>>> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08%
>>>>>> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16%
>>>>>> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23%
>>>>>>
>>>>>> all other ghprb builds vs git fetch timeouts:
>>>>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep -=
vi
>>>>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -vi spark | wc -l);=
 let
>>>>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$to=
tal" |
>>>>>> bc
>>>>>> |
>>>>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
>>>>>> $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
>>>>>> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0%
>>>>>> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13%
>>>>>> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0%
>>>>>> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0%
>>>>>> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0%
>>>>>> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0%
>>>>>> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0%
>>>>>> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0%
>>>>>> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0%
>>>>>>
>>>>>> note: the 15th was the day i rolled back to the earlier version of t=
he
>>>>>> git plugin. it doesn't seem to have helped much, so i'll probably
>>>>>> bring
>>>>>> us
>>>>>> back up to the latest version soon.
>>>>>> also note: rocking some floating point math on the CLI! ;)
>>>>>>
>>>>>> i also compared the distribution of git timeout failures vs time of
>>>>>> day,
>>>>>> and there appears to be no correlation. the failures are pretty even=
ly
>>>>>> distributed over each hour of the day.
>>>>>>
>>>>>> we could be hitting the rate limit due to the ghprb hitting github a
>>>>>> couple of times for each build, but we're averaging ~10-20 builds pe=
r
>>>>>> hour
>>>>>> (a build hits github 2-4 times, from what i can tell). i'll have to
>>>>>> look
>>>>>> more in to this on monday, but suffice to say we may need to move fr=
om
>>>>>> unauthorized https fetches to authorized requests. this means
>>>>>> retrofitting
>>>>>> all of our jobs. yay! fun! :)
>>>>>>
>>>>>> another option is to have local mirrors of all of the repos. the
>>>>>> problem w/this is that there might be a window where changes haven't
>>>>>> made
>>>>>> it to the local mirror and tests run against it. more fun stuff to
>>>>>> think
>>>>>> about...
>>>>>>
>>>>>> now that i have some stats, and a list of all of the times/dates of
>>>>>> the
>>>>>> failures, i will be drafting my email to github and firing that off
>>>>>> later
>>>>>> today or first thing monday.
>>>>>>
>>>>>> have a great weekend everyone!
>>>>>>
>>>>>> shane, who spent way too much time on the CLI and is ready for some
>>>>>> beer.
>>>>>>
>>>>>> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas <
>>>>>> nicholas.chammas@gmail.com> wrote:
>>>>>>
>>>>>>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> i really, truly hate non-deterministic failures.
>>>>>>>
>>>>>>>
>>>>>>> Amen bruddah.
>>>>>>>
>>>>>>
>>>>>>
>>>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9862-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 15:47:17 2014
Return-Path: <dev-return-9862-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 430911743D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 15:47:17 +0000 (UTC)
Received: (qmail 53543 invoked by uid 500); 18 Oct 2014 15:47:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53478 invoked by uid 500); 18 Oct 2014 15:47:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53453 invoked by uid 99); 18 Oct 2014 15:47:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 15:47:15 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.54 as permitted sender)
Received: from [209.85.215.54] (HELO mail-la0-f54.google.com) (209.85.215.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 15:47:09 +0000
Received: by mail-la0-f54.google.com with SMTP id gm9so2064487lab.27
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 08:46:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=XCIlfYY/i6/h0Ka5+QeQu3YPifkSP7YaM5mGPVPzhW0=;
        b=HNXP4z0o1QF0zAU0zdMM3UTLdUHYv6g+tHNb+dzICxC3ztGskEivOysg+HJY73Ai9/
         hEx+vp5/83D4/LvKN6Vz0zoN9iFbCFvIGMzfOKRqRXVU0kmA1RBzPn69MxDLf1+PdEr3
         8385DdGq5W2jO1zaJnqQcStc6Pnwq4afGUk0+NYw+WVbmwOqUy2NBCbv9iKDzyqTiLf3
         iIEB3A15QHV1RCoETGEEvKF2DWQuXcbVGCYvo2EapSU+K79axVWvigh1hwKJMur4ewPL
         fPUN+4aTne/lwoxmuWGNvXNT2YgW56XH1at3gmGXuzp3pBKWUvRR1e8ZjFVMDI+ygpk3
         aTAA==
MIME-Version: 1.0
X-Received: by 10.153.4.44 with SMTP id cb12mr16195483lad.10.1413647208238;
 Sat, 18 Oct 2014 08:46:48 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Sat, 18 Oct 2014 08:46:48 -0700 (PDT)
Date: Sat, 18 Oct 2014 08:46:48 -0700
Message-ID: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
Subject: Oryx + Spark mllib
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133afa0af554d0505b4639a
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133afa0af554d0505b4639a
Content-Type: text/plain; charset=UTF-8

Hi,

Is someone working on a project on integrating Oryx model serving layer
with Spark ? Models will be built using either Streaming data / Batch data
in HDFS and cross validated with mllib APIs but the model serving layer
will give API endpoints like Oryx
and read the models may be from hdfs/impala/SparkSQL

One of the requirement is that the API layer should be scalable and
elastic...as requests grow we should be able to add more nodes...using play
and akka clustering module...

If there is a ongoing project on github please point to it...

Is there a plan of adding model serving and experimentation layer to mllib ?

Thanks.
Deb

--001a1133afa0af554d0505b4639a--

From dev-return-9863-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 16:06:59 2014
Return-Path: <dev-return-9863-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 56D6C174B1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 16:06:59 +0000 (UTC)
Received: (qmail 73615 invoked by uid 500); 18 Oct 2014 16:06:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73540 invoked by uid 500); 18 Oct 2014 16:06:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73528 invoked by uid 99); 18 Oct 2014 16:06:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 16:06:57 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rajiv.abraham@gmail.com designates 209.85.215.53 as permitted sender)
Received: from [209.85.215.53] (HELO mail-la0-f53.google.com) (209.85.215.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 16:06:53 +0000
Received: by mail-la0-f53.google.com with SMTP id gq15so2094984lab.12
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 09:06:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=09t97lQFq3WYddOHVIMCMaGPrWAyBxElua4Mp8G6hkA=;
        b=1FIlDJOs2T+GeBVIoTYjWyl2zvXZi4b4dnFgBTkSjbgFIvyDFMCUW0jzVfmNr2d943
         Mcarx5Be2SbmvLjLt3Ote6sIQK7mB5R5XbXq6y/iEa4kDaUpdvGHe59tTwBuLW8U9Fls
         w7R7Kd6nBiOrCj+Pno4ehwOGsJBroHcVnXhRXOINSAJ+X7TOimkCZ2s1YZoMh1PoWUqe
         u62/5uGF6tc8NYnhX+6DSxykPEGD82pQL0mo7FGquPkWyhl9x99O6qpJ30X+u9kFWbVT
         R8Ub1MvylMGF1yBbbwV2+AljUkUITY+CXr3HeT5jT6qjHptUfrVN+ak8p0uqp106gVHh
         eXmA==
X-Received: by 10.152.20.132 with SMTP id n4mr16148338lae.50.1413648392163;
 Sat, 18 Oct 2014 09:06:32 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.58.133 with HTTP; Sat, 18 Oct 2014 09:06:01 -0700 (PDT)
In-Reply-To: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
References: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
From: Rajiv Abraham <rajiv.abraham@gmail.com>
Date: Sat, 18 Oct 2014 12:06:01 -0400
Message-ID: <CADnDY-XvR1+HTAfi3JRN8Dae2ms9UftVgDBXJFK2OwxSUySC-A@mail.gmail.com>
Subject: Re: Oryx + Spark mllib
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01493b904098e80505b4aa72
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01493b904098e80505b4aa72
Content-Type: text/plain; charset=UTF-8

Oryx 2 seems to be geared for Spark

https://github.com/OryxProject/oryx

2014-10-18 11:46 GMT-04:00 Debasish Das <debasish.das83@gmail.com>:

> Hi,
>
> Is someone working on a project on integrating Oryx model serving layer
> with Spark ? Models will be built using either Streaming data / Batch data
> in HDFS and cross validated with mllib APIs but the model serving layer
> will give API endpoints like Oryx
> and read the models may be from hdfs/impala/SparkSQL
>
> One of the requirement is that the API layer should be scalable and
> elastic...as requests grow we should be able to add more nodes...using play
> and akka clustering module...
>
> If there is a ongoing project on github please point to it...
>
> Is there a plan of adding model serving and experimentation layer to mllib
> ?
>
> Thanks.
> Deb
>



-- 
Take care,
Rajiv

--089e01493b904098e80505b4aa72--

From dev-return-9864-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 20:48:48 2014
Return-Path: <dev-return-9864-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A2548179B0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 20:48:48 +0000 (UTC)
Received: (qmail 86381 invoked by uid 500); 18 Oct 2014 20:48:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 86298 invoked by uid 500); 18 Oct 2014 20:48:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86287 invoked by uid 99); 18 Oct 2014 20:48:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 20:48:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of Saurabh.Wadhawan@guavus.com designates 204.232.241.167 as permitted sender)
Received: from [204.232.241.167] (HELO mx1.guavus.com) (204.232.241.167)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 20:48:40 +0000
Received: from MX3.guavus.com ([192.168.11.2]) by mx1.guavus.com
 ([204.232.241.167]) with mapi id 14.03.0174.001; Sat, 18 Oct 2014 13:46:50
 -0700
From: Saurabh Wadhawan <Saurabh.Wadhawan@guavus.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Joining the spark dev community
Thread-Topic: Joining the spark dev community
Thread-Index: AQHP6xSjUYWLkyKcFkiccLtfBLQKoQ==
Date: Sat, 18 Oct 2014 20:46:49 +0000
Message-ID: <D730DBF4-1D7E-4005-9195-3CE890C683B3@guavus.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [122.161.178.235]
Content-Type: multipart/alternative;
	boundary="_000_D730DBF41D7E400591953CE890C683B3guavuscom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D730DBF41D7E400591953CE890C683B3guavuscom_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

How can I become a spark contributor.
What's the good path that I can follow to become an active code submitter f=
or spark from a newbie.

Regards
- Saurabh


--_000_D730DBF41D7E400591953CE890C683B3guavuscom_--

From dev-return-9865-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 18 23:37:48 2014
Return-Path: <dev-return-9865-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 85CD217CA0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 18 Oct 2014 23:37:48 +0000 (UTC)
Received: (qmail 2104 invoked by uid 500); 18 Oct 2014 23:37:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2020 invoked by uid 500); 18 Oct 2014 23:37:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2009 invoked by uid 99); 18 Oct 2014 23:37:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 23:37:47 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 18 Oct 2014 23:37:21 +0000
Received: by mail-wi0-f182.google.com with SMTP id n3so3713309wiv.3
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 16:37:20 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=RmIXNOKI00MhUHLqNI0+PZW9qHlFiWuSPhw1rtTQhTE=;
        b=Q1czEF85nixgfpVuBo8Dke4LIxk2mkdJnEiSOHjBA6R32m6fK/1+mobREoqbK/IQUk
         xCwb8SxH1Va6J+H1mhn1osGReFf8WepRGWQnVOYpYKM+FvCbwFAzrD4+SoEN5YkfthX8
         ltB0FxceaSJsC8TpYmkA/vRoXe63r3OQsXUKQuz/PaFwY5OmUq761uXULyzZQdVQKLgy
         etUoCv0Ght4oKpDtN7rZIwXUeKl560FT9ekIcSVC5D8NU58NYUcjO/dHY8RsJRlNaDYB
         unCck1jBLbPPqlVuYHHpGm7oAngP/Mddnuf0iGR+EniBlS7rRvKEXuDUgWLblp0reMKo
         LYqw==
X-Gm-Message-State: ALoCoQmMOwMtpAzF+/1yMY+Lkk3qrdEu9P1xahxpSr2v/A4ZlmqNtDtfgCNz3bNUkkV+gZTn3hpx
MIME-Version: 1.0
X-Received: by 10.180.186.175 with SMTP id fl15mr9161078wic.38.1413675440758;
 Sat, 18 Oct 2014 16:37:20 -0700 (PDT)
Received: by 10.217.116.69 with HTTP; Sat, 18 Oct 2014 16:37:20 -0700 (PDT)
X-Originating-IP: [172.56.34.172]
Received: by 10.217.116.69 with HTTP; Sat, 18 Oct 2014 16:37:20 -0700 (PDT)
In-Reply-To: <CA+-p3AFb3SygzTgAsxbq8q=mJ5hGNNYrpXo7kFyoGP3rMRnM1Q@mail.gmail.com>
References: <CA+-p3AFb3SygzTgAsxbq8q=mJ5hGNNYrpXo7kFyoGP3rMRnM1Q@mail.gmail.com>
Date: Sat, 18 Oct 2014 19:37:20 -0400
Message-ID: <CANx3uAjzxPKOKdiv2M+ff=LcW+5A893iOA337RGyTGjLy38fiw@mail.gmail.com>
Subject: Re: Raise Java dependency from 6 to 7
From: Koert Kuipers <koert@tresata.com>
To: Andrew Ash <andrew@andrewash.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11339a6479b3c60505baf62e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11339a6479b3c60505baf62e
Content-Type: text/plain; charset=UTF-8

my experience is that there are still a lot of java 6 clusters out there.
also distros that bundle spark still support java 6
On Oct 17, 2014 8:01 PM, "Andrew Ash" <andrew@andrewash.com> wrote:

> Hi Spark devs,
>
> I've heard a few times that keeping support for Java 6 is a priority for
> Apache Spark.  Given that Java 6 has been publicly EOL'd since Feb 2013
> <http://www.oracle.com/technetwork/java/eol-135779.html> and the last
> public update was Apr 2013
> <https://en.wikipedia.org/wiki/Java_version_history#Java_6_updates>, why
> are we still maintaing support for 6?  The only people using it now must be
> paying for the extended support to continue receiving security fixes.
>
> Bumping the lower bound of Java versions up to Java 7 would allow us to
> upgrade from Jetty 8 to 9, which is currently a conflict with the
> Dropwizard framework and a personal pain point.
>
> Java 6 vs 7 for Spark links:
> Try with resources
> <https://github.com/apache/spark/pull/2575/files#r18152125> for
> SparkContext et al
> Upgrade to Jetty 9
> <https://github.com/apache/spark/pull/167#issuecomment-54544494>
> Warn when not compiling with Java6
> <https://github.com/apache/spark/pull/859>
>
>
> Who are the people out there that still need Java 6 support?
>
> Thanks!
> Andrew
>

--001a11339a6479b3c60505baf62e--

From dev-return-9866-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 00:44:39 2014
Return-Path: <dev-return-9866-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 60B4D17D35
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 00:44:38 +0000 (UTC)
Received: (qmail 31791 invoked by uid 500); 19 Oct 2014 00:44:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31720 invoked by uid 500); 19 Oct 2014 00:44:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31700 invoked by uid 99); 19 Oct 2014 00:44:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 00:44:36 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.41 as permitted sender)
Received: from [209.85.220.41] (HELO mail-pa0-f41.google.com) (209.85.220.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 00:44:32 +0000
Received: by mail-pa0-f41.google.com with SMTP id eu11so2981936pac.0
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 17:44:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=Ex1EzlnardpQE154WhkJVlz3TY4NYqeD818KBvV1iUQ=;
        b=pVuBs3XFBKcEiZ0eFoZXXZqr1Mxw0bU9buyHANkOAYZS87jqiz2w3du43UMnyu9N+9
         NMkoPrwPAZ3N0hsc6SoQwC9VPYaGXBeuaMqspkOB0iTkF610WK8lZd+3PnCDROmqAiD5
         UqYUGZHwNr1ARvUsHAHO3ANOVbTptgG59BBcBudZzvbLaW4K9wVwyFmDhlqmST59ymST
         ATh986VBs29g+MlwlOvqX/s8xqlHM2c9nvmHjiVUA/m7t1ibNRCU2j/Hoaoue4FRyF9R
         5o0wdYBRp7NeEU7yJUTB/GEiK0OvGohoQGx/G/RMu22PyPNczLq0v6Vy3BgySWKxLoXa
         WeLw==
X-Received: by 10.70.128.176 with SMTP id np16mr387850pdb.118.1413679451448;
        Sat, 18 Oct 2014 17:44:11 -0700 (PDT)
Received: from [192.168.1.106] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id ne9sm5131379pbc.87.2014.10.18.17.44.10
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 18 Oct 2014 17:44:10 -0700 (PDT)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 8.0 \(1990.1\))
Subject: Re: Raise Java dependency from 6 to 7
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CANx3uAjzxPKOKdiv2M+ff=LcW+5A893iOA337RGyTGjLy38fiw@mail.gmail.com>
Date: Sat, 18 Oct 2014 17:44:09 -0700
Cc: Andrew Ash <andrew@andrewash.com>,
 dev <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <4605E6C0-E375-455B-91CE-A1423140E8DD@gmail.com>
References: <CA+-p3AFb3SygzTgAsxbq8q=mJ5hGNNYrpXo7kFyoGP3rMRnM1Q@mail.gmail.com> <CANx3uAjzxPKOKdiv2M+ff=LcW+5A893iOA337RGyTGjLy38fiw@mail.gmail.com>
To: Koert Kuipers <koert@tresata.com>
X-Mailer: Apple Mail (2.1990.1)
X-Virus-Checked: Checked by ClamAV on apache.org

I'd also wait a bit until these are gone. Jetty is unfortunately a much =
hairier topic by the way, because the Hadoop libraries also depend on =
Jetty. I think it will be hard to update. However, a patch that shades =
Jetty might be nice to have, if that doesn't require shading a lot of =
other stuff.

Matei

> On Oct 18, 2014, at 4:37 PM, Koert Kuipers <koert@tresata.com> wrote:
>=20
> my experience is that there are still a lot of java 6 clusters out =
there.
> also distros that bundle spark still support java 6
> On Oct 17, 2014 8:01 PM, "Andrew Ash" <andrew@andrewash.com> wrote:
>=20
>> Hi Spark devs,
>>=20
>> I've heard a few times that keeping support for Java 6 is a priority =
for
>> Apache Spark.  Given that Java 6 has been publicly EOL'd since Feb =
2013
>> <http://www.oracle.com/technetwork/java/eol-135779.html> and the last
>> public update was Apr 2013
>> <https://en.wikipedia.org/wiki/Java_version_history#Java_6_updates>, =
why
>> are we still maintaing support for 6?  The only people using it now =
must be
>> paying for the extended support to continue receiving security fixes.
>>=20
>> Bumping the lower bound of Java versions up to Java 7 would allow us =
to
>> upgrade from Jetty 8 to 9, which is currently a conflict with the
>> Dropwizard framework and a personal pain point.
>>=20
>> Java 6 vs 7 for Spark links:
>> Try with resources
>> <https://github.com/apache/spark/pull/2575/files#r18152125> for
>> SparkContext et al
>> Upgrade to Jetty 9
>> <https://github.com/apache/spark/pull/167#issuecomment-54544494>
>> Warn when not compiling with Java6
>> <https://github.com/apache/spark/pull/859>
>>=20
>>=20
>> Who are the people out there that still need Java 6 support?
>>=20
>> Thanks!
>> Andrew
>>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9867-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 01:20:43 2014
Return-Path: <dev-return-9867-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 662D617D89
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 01:20:42 +0000 (UTC)
Received: (qmail 52077 invoked by uid 500); 19 Oct 2014 01:20:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 52003 invoked by uid 500); 19 Oct 2014 01:20:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51992 invoked by uid 99); 19 Oct 2014 01:20:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 01:20:37 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.216.178 as permitted sender)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 01:20:33 +0000
Received: by mail-qc0-f178.google.com with SMTP id c9so2221477qcz.37
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 18:20:13 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=2cd3/+7iICUvUXd0p40zS/m03F9KuZJPQfbuGY0huWo=;
        b=UZS2470lYyYWdp26D/FgAgzFq52wo0DV54yMcdpeEE81/8gPJ5KTPVds7rA5yUihw3
         YEPwNUFg1usJ6j2SGc5uM9wv1qdsmRcrf7NSOyD6xqC/rSt4Efa5XtfRDogrX8zIf0Cz
         TjTlLcQp+fexDSrdlCHPWI8IRtmg+HFv+wT1jp9T5kR9/duJ3iupUiUnqGpn2M5K71nA
         UzvHhJlJg1lNbrUi+6fDp1Z83Ay6OxkLUXJ4TGN06qkvl99h1R7r07Hhs+b7vGLWHtRq
         TxRKpFX6bIqAFOwveS34kKbtU3SU381cmsko1TAjPfR7EcMpKfwT13SmZoZGa9IWRE/s
         /Jrg==
X-Gm-Message-State: ALoCoQkvc2aVVyOcqGMEV4v5PoAnl6Pu1JNgS+cg89XfiRI7gUSymGKHxQC4kZjQ3M2XMU/dKzRr
MIME-Version: 1.0
X-Received: by 10.224.46.8 with SMTP id h8mr23865326qaf.85.1413681613153; Sat,
 18 Oct 2014 18:20:13 -0700 (PDT)
Received: by 10.229.8.68 with HTTP; Sat, 18 Oct 2014 18:20:13 -0700 (PDT)
In-Reply-To: <4605E6C0-E375-455B-91CE-A1423140E8DD@gmail.com>
References: <CA+-p3AFb3SygzTgAsxbq8q=mJ5hGNNYrpXo7kFyoGP3rMRnM1Q@mail.gmail.com>
	<CANx3uAjzxPKOKdiv2M+ff=LcW+5A893iOA337RGyTGjLy38fiw@mail.gmail.com>
	<4605E6C0-E375-455B-91CE-A1423140E8DD@gmail.com>
Date: Sat, 18 Oct 2014 18:20:13 -0700
Message-ID: <CAAOnQ7uVg0HWvspba9tsbo_hKHw8uLjPi2-GqCsUhxJHp-=Hvw@mail.gmail.com>
Subject: Re: Raise Java dependency from 6 to 7
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: Koert Kuipers <koert@tresata.com>, Andrew Ash <andrew@andrewash.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Hadoop, for better or worse, depends on an ancient version of Jetty
(6), that is even on a different package. So Spark (or anyone trying
to use a newer Jetty) is lucky on that front...

IIRC Hadoop is planning to move to Java 7-only starting with 2.7. Java
7 is also supposed to be EOL some time next year, so a plan to move to
Java 7 and, eventually, Java 8 would be nice.

On Sat, Oct 18, 2014 at 5:44 PM, Matei Zaharia <matei.zaharia@gmail.com> wr=
ote:
> I'd also wait a bit until these are gone. Jetty is unfortunately a much h=
airier topic by the way, because the Hadoop libraries also depend on Jetty.=
 I think it will be hard to update. However, a patch that shades Jetty migh=
t be nice to have, if that doesn't require shading a lot of other stuff.
>
> Matei
>
>> On Oct 18, 2014, at 4:37 PM, Koert Kuipers <koert@tresata.com> wrote:
>>
>> my experience is that there are still a lot of java 6 clusters out there=
.
>> also distros that bundle spark still support java 6
>> On Oct 17, 2014 8:01 PM, "Andrew Ash" <andrew@andrewash.com> wrote:
>>
>>> Hi Spark devs,
>>>
>>> I've heard a few times that keeping support for Java 6 is a priority fo=
r
>>> Apache Spark.  Given that Java 6 has been publicly EOL'd since Feb 2013
>>> <http://www.oracle.com/technetwork/java/eol-135779.html> and the last
>>> public update was Apr 2013
>>> <https://en.wikipedia.org/wiki/Java_version_history#Java_6_updates>, wh=
y
>>> are we still maintaing support for 6?  The only people using it now mus=
t be
>>> paying for the extended support to continue receiving security fixes.
>>>
>>> Bumping the lower bound of Java versions up to Java 7 would allow us to
>>> upgrade from Jetty 8 to 9, which is currently a conflict with the
>>> Dropwizard framework and a personal pain point.
>>>
>>> Java 6 vs 7 for Spark links:
>>> Try with resources
>>> <https://github.com/apache/spark/pull/2575/files#r18152125> for
>>> SparkContext et al
>>> Upgrade to Jetty 9
>>> <https://github.com/apache/spark/pull/167#issuecomment-54544494>
>>> Warn when not compiling with Java6
>>> <https://github.com/apache/spark/pull/859>
>>>
>>>
>>> Who are the people out there that still need Java 6 support?
>>>
>>> Thanks!
>>> Andrew
>>>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>



--=20
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9868-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 04:52:45 2014
Return-Path: <dev-return-9868-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6CB1817EF6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 04:52:45 +0000 (UTC)
Received: (qmail 30713 invoked by uid 500); 19 Oct 2014 04:52:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30644 invoked by uid 500); 19 Oct 2014 04:52:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30630 invoked by uid 99); 19 Oct 2014 04:52:43 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 04:52:43 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.192.180 as permitted sender)
Received: from [209.85.192.180] (HELO mail-pd0-f180.google.com) (209.85.192.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 04:52:18 +0000
Received: by mail-pd0-f180.google.com with SMTP id fp1so2962952pdb.25
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 21:52:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:content-type:content-transfer-encoding:subject:message-id:date
         :to:mime-version;
        bh=kEECnGIBlpQYvdasO1JPKme5o1R0farwOpOsI0WYs4E=;
        b=Dgc/bYiGBWhFJos9J1akFzSIJB+soc17vFI5xecc3ylsnhXCr10q9UE/24HArml+5z
         y4k3YBgbsFD2C5avOI8C9Ph0Pjy4uJQOPAoXafplhGT9dUAiziSj9sMxQJKiEV9fsNPo
         OeoerZ2pR3V8fDAQhTaJ8fw/FbmVkh2Awv0IAgorudDkE7BpPNBusRpHpXy+XQVFmHMi
         RysRhnj8ozg+6fTu9LJfnkP/TSu9iNbCOlGSYGrkLOcpiC5R+7BTnnNQFlQnUwhbO5cK
         8VKzn48Kd2OC1IYIEmbjiqAY6tffioFUuoHv1zWhDWDk9W3d3zQvQlJK49sVyzD0ksXT
         h7Eg==
X-Received: by 10.70.128.11 with SMTP id nk11mr18661757pdb.113.1413694336177;
        Sat, 18 Oct 2014 21:52:16 -0700 (PDT)
Received: from [192.168.1.106] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id tv4sm5610674pab.28.2014.10.18.21.52.15
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 18 Oct 2014 21:52:15 -0700 (PDT)
From: Matei Zaharia <matei.zaharia@gmail.com>
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable
Subject: Submissions open for Spark Summit East 2015
Message-Id: <D0ADA066-72C3-4CC9-B102-825EBCFA7A5A@gmail.com>
Date: Sat, 18 Oct 2014 21:52:13 -0700
To: user@spark.incubator.apache.org,
 dev <dev@spark.apache.org>
Mime-Version: 1.0 (Mac OS X Mail 8.0 \(1990.1\))
X-Mailer: Apple Mail (2.1990.1)
X-Virus-Checked: Checked by ClamAV on apache.org

After successful events in the past two years, the Spark Summit =
conference has expanded for 2015, offering both an event in New York on =
March 18-19 and one in San Francisco on June 15-17. The conference is a =
great chance to meet people from throughout the Spark community and see =
the latest news, tips and use cases.

Submissions are now open for Spark Summit East 2015, to be held in New =
York on March 18-19. If you=E2=80=99d like to give a talk on use cases, =
neat applications, or ongoing Spark development, submit your talk online =
today at http://prevalentdesignevents.com/sparksummit2015/east/speaker/. =
Submissions will be open until December 6th, 2014.

If you missed this year=E2=80=99s Spark Summit, you can still find =
videos from all talks online at http://spark-summit.org/2014.

Hope to see you there,

Matei=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9869-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 05:10:52 2014
Return-Path: <dev-return-9869-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1729317F27
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 05:10:52 +0000 (UTC)
Received: (qmail 40987 invoked by uid 500); 19 Oct 2014 05:10:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40915 invoked by uid 500); 19 Oct 2014 05:10:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40904 invoked by uid 99); 19 Oct 2014 05:10:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 05:10:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.213.182 as permitted sender)
Received: from [209.85.213.182] (HELO mail-ig0-f182.google.com) (209.85.213.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 05:10:25 +0000
Received: by mail-ig0-f182.google.com with SMTP id hn15so2929891igb.9
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 22:10:23 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=MAJvaLbZIYgO7m0QVL2lpDRibP8b/dhyCl3tedRr7LI=;
        b=mQy4k4HaqLMlHswhbtBz8+faWvd40gs/5ICU1Ck1ZguGUXQAEfCsDgynyCyM31cg75
         ofhBM6W0pqz/1wcNoylfzVYIzkA1usFfwmB4dUg/KlpkYJ62XMfLmouA5/sOR2Sjz5Hd
         ptf3wnOUbzKisWRHvvhB9u4AodsYJph50vaK2nhmVCACuRgPbWv+/D0M6r/1Vu2dzwBd
         dh8+nFum4zVCt/Fe6fOiJjNKFrDRS2sGOPjSGCcoL1zHFlbs2JqzNoKrvUdnuKH/vXdd
         d5PZXuIdgt2oud/l+rKYC4dCk0VLBPD2B8w0srI9gHp2VaBfE1iabDL1YGm7dSsaC6o8
         TllA==
X-Gm-Message-State: ALoCoQlXqDJQlkS9bP/KbGoKm3ZkgF6lM81cKapd9rXxhl8rHMxll7ZuzlxyEQBIT+6fZITsl1Vv
MIME-Version: 1.0
X-Received: by 10.43.140.132 with SMTP id ja4mr19221554icc.40.1413695423758;
 Sat, 18 Oct 2014 22:10:23 -0700 (PDT)
Received: by 10.107.12.158 with HTTP; Sat, 18 Oct 2014 22:10:23 -0700 (PDT)
Received: by 10.107.12.158 with HTTP; Sat, 18 Oct 2014 22:10:23 -0700 (PDT)
In-Reply-To: <CADnDY-XvR1+HTAfi3JRN8Dae2ms9UftVgDBXJFK2OwxSUySC-A@mail.gmail.com>
References: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
	<CADnDY-XvR1+HTAfi3JRN8Dae2ms9UftVgDBXJFK2OwxSUySC-A@mail.gmail.com>
Date: Sun, 19 Oct 2014 01:10:23 -0400
Message-ID: <CAMAsSdK9SYnAf-B+Oa_uNjfkCtMAgywcC+pD=e3A+RvJ3Z_jOg@mail.gmail.com>
Subject: Re: Oryx + Spark mllib
From: Sean Owen <sowen@cloudera.com>
To: Rajiv Abraham <rajiv.abraham@gmail.com>
Cc: dev@spark.apache.org, Debasish Das <debasish.das83@gmail.com>
Content-Type: multipart/alternative; boundary=001a11c3634e8de1500505bf9d1b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3634e8de1500505bf9d1b
Content-Type: text/plain; charset=UTF-8

Yes, that is exactly what the next 2.x version does. Still in progress but
the recommender app and framework are code - complete. It is not even
specific to MLlib and could plug in other model build functions.

The current 1.x version will not use MLlib. Neither uses Play but is
intended to scale just by adding web servers however you usually do.

See graphflow too.
On Oct 18, 2014 5:06 PM, "Rajiv Abraham" <rajiv.abraham@gmail.com> wrote:

> Oryx 2 seems to be geared for Spark
>
> https://github.com/OryxProject/oryx
>
> 2014-10-18 11:46 GMT-04:00 Debasish Das <debasish.das83@gmail.com>:
>
> > Hi,
> >
> > Is someone working on a project on integrating Oryx model serving layer
> > with Spark ? Models will be built using either Streaming data / Batch
> data
> > in HDFS and cross validated with mllib APIs but the model serving layer
> > will give API endpoints like Oryx
> > and read the models may be from hdfs/impala/SparkSQL
> >
> > One of the requirement is that the API layer should be scalable and
> > elastic...as requests grow we should be able to add more nodes...using
> play
> > and akka clustering module...
> >
> > If there is a ongoing project on github please point to it...
> >
> > Is there a plan of adding model serving and experimentation layer to
> mllib
> > ?
> >
> > Thanks.
> > Deb
> >
>
>
>
> --
> Take care,
> Rajiv
>

--001a11c3634e8de1500505bf9d1b--

From dev-return-9870-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 06:23:01 2014
Return-Path: <dev-return-9870-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6DE3417FEC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 06:23:01 +0000 (UTC)
Received: (qmail 67854 invoked by uid 500); 19 Oct 2014 06:23:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67779 invoked by uid 500); 19 Oct 2014 06:23:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67766 invoked by uid 99); 19 Oct 2014 06:22:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 06:22:59 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nick.pentreath@gmail.com designates 209.85.214.174 as permitted sender)
Received: from [209.85.214.174] (HELO mail-ob0-f174.google.com) (209.85.214.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 06:22:34 +0000
Received: by mail-ob0-f174.google.com with SMTP id wp18so2428814obc.33
        for <dev@spark.apache.org>; Sat, 18 Oct 2014 23:22:32 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=sVw9n+ZOrWIGoto0CYks3VkWYakUE7cRQGYsTDdkyDM=;
        b=SyC6ZtqYOQamwjB6q0+ScJyKoKX7LxhLRbz7PtqaO/rowvCKYrV3F42S1nF+ZvDrfN
         klpM2/IZrNCgEKo3iDyGp53OJxDV+2IycgOHWcNMY1JdfVY/9nBRb4MHqALp2lEqKEqN
         fUkaK9w4rygnLxWoYoZEzJg7aflDFRcD3aOzxcKhlbvlz0Zowf6J8o2dJx8eJEL2TJhG
         2fDwBhNYWFbGCnKx4Ua2X11rdJeZjqBk+ZT6i7WyGfPDysNsxocKIt547dvOYNb0HwAv
         pVnH3M2AJQifzBHZbOtSDWKTWEralxrUejh4kRtdIsbJG07S4fQ8wM8sqhvIk8RReXVx
         mFRQ==
MIME-Version: 1.0
X-Received: by 10.202.185.138 with SMTP id j132mr15176098oif.25.1413699752657;
 Sat, 18 Oct 2014 23:22:32 -0700 (PDT)
Received: by 10.182.107.196 with HTTP; Sat, 18 Oct 2014 23:22:32 -0700 (PDT)
In-Reply-To: <CAMAsSdK9SYnAf-B+Oa_uNjfkCtMAgywcC+pD=e3A+RvJ3Z_jOg@mail.gmail.com>
References: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
	<CADnDY-XvR1+HTAfi3JRN8Dae2ms9UftVgDBXJFK2OwxSUySC-A@mail.gmail.com>
	<CAMAsSdK9SYnAf-B+Oa_uNjfkCtMAgywcC+pD=e3A+RvJ3Z_jOg@mail.gmail.com>
Date: Sun, 19 Oct 2014 08:22:32 +0200
Message-ID: <CALD+6GOjq5D_BX+0BXNp60vYv1_aNpo-kb2ZJwNJ9BM-ruCThw@mail.gmail.com>
Subject: Re: Oryx + Spark mllib
From: Nick Pentreath <nick.pentreath@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Rajiv Abraham <rajiv.abraham@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	Debasish Das <debasish.das83@gmail.com>
Content-Type: multipart/alternative; boundary=001a113cc732938a7f0505c09fb0
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113cc732938a7f0505c09fb0
Content-Type: text/plain; charset=UTF-8

We've built a model server internally, based on Scalatra and Akka
Clustering. Our use case is more geared towards serving possibly thousands
of smaller models.

It's actually very basic, just reads models from S3 as strings (!!) (uses
HDFS FileSystem so can read from local, HDFS, S3) and uses Breeze for
linear algebra. (Technically it is also not dependent on Spark, it could be
reading models generated by any computation layer).

It's designed to allow scaling via cluster sharding, by adding nodes (but
could also support a load-balanced approach). Not using persistent actors
as doing a model reload on node failure is not a disaster as we have
multiple levels of fallback.

Currently it is a bit specific to our setup (and only focused on
recommendation models for now), but could with some work be made generic.
I'm certainly considering if we can find the time to make it a releasable
project.

One major difference to Oryx is that it only handles the model loading and
vector computations, not the filtering-related and other things that come
as part of a recommender system (that is done elsewhere in our system). It
also does not handle the ingesting of data at all.

On Sun, Oct 19, 2014 at 7:10 AM, Sean Owen <sowen@cloudera.com> wrote:

> Yes, that is exactly what the next 2.x version does. Still in progress but
> the recommender app and framework are code - complete. It is not even
> specific to MLlib and could plug in other model build functions.
>
> The current 1.x version will not use MLlib. Neither uses Play but is
> intended to scale just by adding web servers however you usually do.
>
> See graphflow too.
> On Oct 18, 2014 5:06 PM, "Rajiv Abraham" <rajiv.abraham@gmail.com> wrote:
>
> > Oryx 2 seems to be geared for Spark
> >
> > https://github.com/OryxProject/oryx
> >
> > 2014-10-18 11:46 GMT-04:00 Debasish Das <debasish.das83@gmail.com>:
> >
> > > Hi,
> > >
> > > Is someone working on a project on integrating Oryx model serving layer
> > > with Spark ? Models will be built using either Streaming data / Batch
> > data
> > > in HDFS and cross validated with mllib APIs but the model serving layer
> > > will give API endpoints like Oryx
> > > and read the models may be from hdfs/impala/SparkSQL
> > >
> > > One of the requirement is that the API layer should be scalable and
> > > elastic...as requests grow we should be able to add more nodes...using
> > play
> > > and akka clustering module...
> > >
> > > If there is a ongoing project on github please point to it...
> > >
> > > Is there a plan of adding model serving and experimentation layer to
> > mllib
> > > ?
> > >
> > > Thanks.
> > > Deb
> > >
> >
> >
> >
> > --
> > Take care,
> > Rajiv
> >
>

--001a113cc732938a7f0505c09fb0--

From dev-return-9871-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 15:29:52 2014
Return-Path: <dev-return-9871-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A97A0178CF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 15:29:52 +0000 (UTC)
Received: (qmail 90065 invoked by uid 500); 19 Oct 2014 15:29:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 89998 invoked by uid 500); 19 Oct 2014 15:29:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 89986 invoked by uid 99); 19 Oct 2014 15:29:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 15:29:51 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.48 as permitted sender)
Received: from [209.85.215.48] (HELO mail-la0-f48.google.com) (209.85.215.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 15:29:24 +0000
Received: by mail-la0-f48.google.com with SMTP id gi9so2791035lab.35
        for <dev@spark.apache.org>; Sun, 19 Oct 2014 08:29:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=yVB6Qyisi8anSUVtj3we2C2ZuBaIgXUmru2FIBjHI1s=;
        b=qynGZZKJ8G5a7wHv+G+LFczbUDvoFyrQuvQEycVbdctZQYmaCwH1/3ruH0R2M2eZEF
         KmTjswjC/1pUdAqFonEABhbIL9s4/XLTuMtQx6mNQrOC9XNEEcSgADaEJplx+OZJnIg1
         SuD++N0EPyDYF/gg2SRYue49p0Px72wfTWPCucNTRbPw4CBFNV/LHQphxFmkDF3lmaSf
         NPItMvckwwZy69uTLVMc0J8sPX70aVFoPQ5PZwmL1Re+/3xyNLWabyiWhHYpKuiU7dN6
         njyYMe1yR3/HM0Ms1e8sONRtsBlGguj4Sf9I30jFL2Vw/JiukdAgBpWBSqdfSS6ump19
         1Umg==
MIME-Version: 1.0
X-Received: by 10.152.88.105 with SMTP id bf9mr21829310lab.30.1413732563760;
 Sun, 19 Oct 2014 08:29:23 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Sun, 19 Oct 2014 08:29:23 -0700 (PDT)
In-Reply-To: <CALD+6GOjq5D_BX+0BXNp60vYv1_aNpo-kb2ZJwNJ9BM-ruCThw@mail.gmail.com>
References: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
	<CADnDY-XvR1+HTAfi3JRN8Dae2ms9UftVgDBXJFK2OwxSUySC-A@mail.gmail.com>
	<CAMAsSdK9SYnAf-B+Oa_uNjfkCtMAgywcC+pD=e3A+RvJ3Z_jOg@mail.gmail.com>
	<CALD+6GOjq5D_BX+0BXNp60vYv1_aNpo-kb2ZJwNJ9BM-ruCThw@mail.gmail.com>
Date: Sun, 19 Oct 2014 08:29:23 -0700
Message-ID: <CA+B-+fwiPzeBd=igo1yCnADtaN4U80s5Pr4wvtXqMWm7Xm1=uA@mail.gmail.com>
Subject: Re: Oryx + Spark mllib
From: Debasish Das <debasish.das83@gmail.com>
To: Nick Pentreath <nick.pentreath@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>, Rajiv Abraham <rajiv.abraham@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c36722453bbb0505c843da
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c36722453bbb0505c843da
Content-Type: text/plain; charset=UTF-8

Hi Nick,

Any specific reason of choosing scalatra and not play/spray (now that they
are getting integrated) ?

Sean,

Would you be interested in a play and akka clustering based module in oryx2
and see how it compares against the servlets ? I am interested to
understand the scalability....

Thanks.
Deb

On Sat, Oct 18, 2014 at 11:22 PM, Nick Pentreath <nick.pentreath@gmail.com>
wrote:

> We've built a model server internally, based on Scalatra and Akka
> Clustering. Our use case is more geared towards serving possibly thousands
> of smaller models.
>
> It's actually very basic, just reads models from S3 as strings (!!) (uses
> HDFS FileSystem so can read from local, HDFS, S3) and uses Breeze for
> linear algebra. (Technically it is also not dependent on Spark, it could be
> reading models generated by any computation layer).
>
> It's designed to allow scaling via cluster sharding, by adding nodes (but
> could also support a load-balanced approach). Not using persistent actors
> as doing a model reload on node failure is not a disaster as we have
> multiple levels of fallback.
>
> Currently it is a bit specific to our setup (and only focused on
> recommendation models for now), but could with some work be made generic.
> I'm certainly considering if we can find the time to make it a releasable
> project.
>
> One major difference to Oryx is that it only handles the model loading and
> vector computations, not the filtering-related and other things that come
> as part of a recommender system (that is done elsewhere in our system). It
> also does not handle the ingesting of data at all.
>
> On Sun, Oct 19, 2014 at 7:10 AM, Sean Owen <sowen@cloudera.com> wrote:
>
>> Yes, that is exactly what the next 2.x version does. Still in progress but
>> the recommender app and framework are code - complete. It is not even
>> specific to MLlib and could plug in other model build functions.
>>
>> The current 1.x version will not use MLlib. Neither uses Play but is
>> intended to scale just by adding web servers however you usually do.
>>
>> See graphflow too.
>> On Oct 18, 2014 5:06 PM, "Rajiv Abraham" <rajiv.abraham@gmail.com> wrote:
>>
>> > Oryx 2 seems to be geared for Spark
>> >
>> > https://github.com/OryxProject/oryx
>> >
>> > 2014-10-18 11:46 GMT-04:00 Debasish Das <debasish.das83@gmail.com>:
>> >
>> > > Hi,
>> > >
>> > > Is someone working on a project on integrating Oryx model serving
>> layer
>> > > with Spark ? Models will be built using either Streaming data / Batch
>> > data
>> > > in HDFS and cross validated with mllib APIs but the model serving
>> layer
>> > > will give API endpoints like Oryx
>> > > and read the models may be from hdfs/impala/SparkSQL
>> > >
>> > > One of the requirement is that the API layer should be scalable and
>> > > elastic...as requests grow we should be able to add more nodes...using
>> > play
>> > > and akka clustering module...
>> > >
>> > > If there is a ongoing project on github please point to it...
>> > >
>> > > Is there a plan of adding model serving and experimentation layer to
>> > mllib
>> > > ?
>> > >
>> > > Thanks.
>> > > Deb
>> > >
>> >
>> >
>> >
>> > --
>> > Take care,
>> > Rajiv
>> >
>>
>
>

--001a11c36722453bbb0505c843da--

From dev-return-9872-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 15:38:39 2014
Return-Path: <dev-return-9872-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 029A5178E6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 15:38:39 +0000 (UTC)
Received: (qmail 97127 invoked by uid 500); 19 Oct 2014 15:38:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 97066 invoked by uid 500); 19 Oct 2014 15:38:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 97054 invoked by uid 99); 19 Oct 2014 15:38:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 15:38:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 209.85.218.53 as permitted sender)
Received: from [209.85.218.53] (HELO mail-oi0-f53.google.com) (209.85.218.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 15:38:33 +0000
Received: by mail-oi0-f53.google.com with SMTP id v63so2543126oia.26
        for <dev@spark.apache.org>; Sun, 19 Oct 2014 08:38:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=0ykeSp2aP/gB3byOD008Oqw6+DsCxboHsQZdpokD3CY=;
        b=W0/9GXzFOtY+wCJvAxG1K1yBr/4ZRtIujRLabplduByynv5sgpgJWN0OkCMnxVxvn2
         MvdQlJRb9vs2ahEuvTPnrPKbcLhmjPWBV4YJwI2nVYvGkXWaMtITnM7ByBoSzbLdT2FE
         JmB0cxp7fgbzupf3btTYyXVSkw2Oh9HkQPTeoqEEpHGlvp8UEd/lMaJVf6GGHf92Z90N
         u/0xTifgJmK2EOSJJsIB04n12nZx+asdTqa/0eAz2iN3EB0AkvcDNM63dYAnk6rIsxnq
         PS15sjiNB9bk6I7KUmOFmEhl0gCKTE1osEehOtVZKFzM1sIknnRNf3fgBqIDR+rnYT3C
         ll3w==
MIME-Version: 1.0
X-Received: by 10.60.133.140 with SMTP id pc12mr1122886oeb.64.1413733092894;
 Sun, 19 Oct 2014 08:38:12 -0700 (PDT)
Received: by 10.182.107.196 with HTTP; Sun, 19 Oct 2014 08:38:12 -0700 (PDT)
In-Reply-To: <CA+B-+fwiPzeBd=igo1yCnADtaN4U80s5Pr4wvtXqMWm7Xm1=uA@mail.gmail.com>
References: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
	<CADnDY-XvR1+HTAfi3JRN8Dae2ms9UftVgDBXJFK2OwxSUySC-A@mail.gmail.com>
	<CAMAsSdK9SYnAf-B+Oa_uNjfkCtMAgywcC+pD=e3A+RvJ3Z_jOg@mail.gmail.com>
	<CALD+6GOjq5D_BX+0BXNp60vYv1_aNpo-kb2ZJwNJ9BM-ruCThw@mail.gmail.com>
	<CA+B-+fwiPzeBd=igo1yCnADtaN4U80s5Pr4wvtXqMWm7Xm1=uA@mail.gmail.com>
Date: Sun, 19 Oct 2014 17:38:12 +0200
Message-ID: <CALD+6GMTS5Z1XMjmFbVS+1VGzY=oQwwRENa7kZJT0WAJXPOvig@mail.gmail.com>
Subject: Re: Oryx + Spark mllib
From: Nick Pentreath <nick.pentreath@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: Sean Owen <sowen@cloudera.com>, Rajiv Abraham <rajiv.abraham@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b47288ecf2e010505c86271
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b47288ecf2e010505c86271
Content-Type: text/plain; charset=UTF-8

Well, when I started development ~2 years ago, Scalatra just appealed more,
being more lightweight (I didn't need MVC just barebones REST endpoints),
and I still find its API / DSL much nicer to work with. Also, the swagger
API docs integration was important to me. So it's more familiarity than any
other reason.

If I were to build a model server from scratch perhaps Spray/Akka HTTP
would be the better way to go purely for integration purposes.

Having said that I think Scalatra is great and performant, so it's not a
no-brainer either way.

On Sun, Oct 19, 2014 at 5:29 PM, Debasish Das <debasish.das83@gmail.com>
wrote:

> Hi Nick,
>
> Any specific reason of choosing scalatra and not play/spray (now that they
> are getting integrated) ?
>
> Sean,
>
> Would you be interested in a play and akka clustering based module in
> oryx2 and see how it compares against the servlets ? I am interested to
> understand the scalability....
>
> Thanks.
> Deb
>
> On Sat, Oct 18, 2014 at 11:22 PM, Nick Pentreath <nick.pentreath@gmail.com
> > wrote:
>
>> We've built a model server internally, based on Scalatra and Akka
>> Clustering. Our use case is more geared towards serving possibly thousands
>> of smaller models.
>>
>> It's actually very basic, just reads models from S3 as strings (!!) (uses
>> HDFS FileSystem so can read from local, HDFS, S3) and uses Breeze for
>> linear algebra. (Technically it is also not dependent on Spark, it could be
>> reading models generated by any computation layer).
>>
>> It's designed to allow scaling via cluster sharding, by adding nodes (but
>> could also support a load-balanced approach). Not using persistent actors
>> as doing a model reload on node failure is not a disaster as we have
>> multiple levels of fallback.
>>
>> Currently it is a bit specific to our setup (and only focused on
>> recommendation models for now), but could with some work be made generic.
>> I'm certainly considering if we can find the time to make it a releasable
>> project.
>>
>> One major difference to Oryx is that it only handles the model loading
>> and vector computations, not the filtering-related and other things that
>> come as part of a recommender system (that is done elsewhere in our
>> system). It also does not handle the ingesting of data at all.
>>
>> On Sun, Oct 19, 2014 at 7:10 AM, Sean Owen <sowen@cloudera.com> wrote:
>>
>>> Yes, that is exactly what the next 2.x version does. Still in progress
>>> but
>>> the recommender app and framework are code - complete. It is not even
>>> specific to MLlib and could plug in other model build functions.
>>>
>>> The current 1.x version will not use MLlib. Neither uses Play but is
>>> intended to scale just by adding web servers however you usually do.
>>>
>>> See graphflow too.
>>> On Oct 18, 2014 5:06 PM, "Rajiv Abraham" <rajiv.abraham@gmail.com>
>>> wrote:
>>>
>>> > Oryx 2 seems to be geared for Spark
>>> >
>>> > https://github.com/OryxProject/oryx
>>> >
>>> > 2014-10-18 11:46 GMT-04:00 Debasish Das <debasish.das83@gmail.com>:
>>> >
>>> > > Hi,
>>> > >
>>> > > Is someone working on a project on integrating Oryx model serving
>>> layer
>>> > > with Spark ? Models will be built using either Streaming data / Batch
>>> > data
>>> > > in HDFS and cross validated with mllib APIs but the model serving
>>> layer
>>> > > will give API endpoints like Oryx
>>> > > and read the models may be from hdfs/impala/SparkSQL
>>> > >
>>> > > One of the requirement is that the API layer should be scalable and
>>> > > elastic...as requests grow we should be able to add more
>>> nodes...using
>>> > play
>>> > > and akka clustering module...
>>> > >
>>> > > If there is a ongoing project on github please point to it...
>>> > >
>>> > > Is there a plan of adding model serving and experimentation layer to
>>> > mllib
>>> > > ?
>>> > >
>>> > > Thanks.
>>> > > Deb
>>> > >
>>> >
>>> >
>>> >
>>> > --
>>> > Take care,
>>> > Rajiv
>>> >
>>>
>>
>>
>

--047d7b47288ecf2e010505c86271--

From dev-return-9873-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 15:47:23 2014
Return-Path: <dev-return-9873-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4C7A1178F8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 15:47:22 +0000 (UTC)
Received: (qmail 2838 invoked by uid 500); 19 Oct 2014 15:47:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2769 invoked by uid 500); 19 Oct 2014 15:47:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2757 invoked by uid 99); 19 Oct 2014 15:47:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 15:47:20 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.223.178 as permitted sender)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 15:46:53 +0000
Received: by mail-ie0-f178.google.com with SMTP id rl12so3266755iec.23
        for <dev@spark.apache.org>; Sun, 19 Oct 2014 08:46:52 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=cnjvp9576esyvhLuM3iT+qLQ6o/VrrekhqNAUvnn5lI=;
        b=Tod2kZH8rEZnx9VpM/VkcK5R9PHf3OHvSZA02mddhSFXCFP10v5XHaI0gVoYkVQqnv
         mHkDM14SqL20TUQw2bLjJ9yHF9/KvApNeUI4S+7vIs+zBUulM9GOuKyKPfWSNs6vRRLy
         Tcf880xk3XN68JXWxeNyQx+g8zPgwZ4Tw7CMNI37hr/QsVi/2qfRlAAw5e+cCazq9Ipe
         EPtHZTJ/Qkc+8ah6nBohrXYRF7qD22ajSM9eQzF4ybjpMf+AurOZ9j3oB3miVt1xJzwZ
         OEPAXDfR9pTjo9NrX+9w4QM8tzFsMTuB13g9VdV4hmFf+7k1BXbi2skXdFeH41Yeg0kE
         8CAw==
X-Gm-Message-State: ALoCoQkZGpgNgopc1vOjMk4A9C4CUKU1K0pdU4o7RcDLm0RXvR6pA+DhEWMySoxnbeY8BbNxMHMm
X-Received: by 10.42.96.137 with SMTP id j9mr1919456icn.88.1413733612298; Sun,
 19 Oct 2014 08:46:52 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Sun, 19 Oct 2014 08:46:31 -0700 (PDT)
In-Reply-To: <CA+B-+fwiPzeBd=igo1yCnADtaN4U80s5Pr4wvtXqMWm7Xm1=uA@mail.gmail.com>
References: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
 <CADnDY-XvR1+HTAfi3JRN8Dae2ms9UftVgDBXJFK2OwxSUySC-A@mail.gmail.com>
 <CAMAsSdK9SYnAf-B+Oa_uNjfkCtMAgywcC+pD=e3A+RvJ3Z_jOg@mail.gmail.com>
 <CALD+6GOjq5D_BX+0BXNp60vYv1_aNpo-kb2ZJwNJ9BM-ruCThw@mail.gmail.com> <CA+B-+fwiPzeBd=igo1yCnADtaN4U80s5Pr4wvtXqMWm7Xm1=uA@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Sun, 19 Oct 2014 11:46:31 -0400
Message-ID: <CAMAsSdLktDYipBYp96mkbqeAPrU6uEHbnFAYu8zOfnn3oOMZXA@mail.gmail.com>
Subject: Re: Oryx + Spark mllib
To: Debasish Das <debasish.das83@gmail.com>
Cc: Nick Pentreath <nick.pentreath@gmail.com>, Rajiv Abraham <rajiv.abraham@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Briefly, re: Oryx2, since the intent is for users to write their own
serving apps, I though JAX-RS would be more familiar to more
developers. I don't know how hard/easy REST APIs are in JAX-RS vs
anything else but I suspect it's not much different.

The interesting design decision that impacts scale is: do you
distribute scoring of each request across a cluster? the servlet-based
design does not and does everything in-core, in-memory.

Pros: Dead simple architecture. Hard to beat for low latency. Anything
more complex is big overkill for most models (RDF, k-means) -- except
recommenders.

Cons: For recommenders, harder to scale since everything is in-memory.
And that's a big "but".

On Sun, Oct 19, 2014 at 11:29 AM, Debasish Das <debasish.das83@gmail.com> wrote:
> Would you be interested in a play and akka clustering based module in oryx2
> and see how it compares against the servlets ? I am interested to understand
> the scalability....

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9874-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 16:35:05 2014
Return-Path: <dev-return-9874-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3236F1797D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 16:35:04 +0000 (UTC)
Received: (qmail 32703 invoked by uid 500); 19 Oct 2014 16:35:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32633 invoked by uid 500); 19 Oct 2014 16:35:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32613 invoked by uid 99); 19 Oct 2014 16:35:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 16:35:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nick.pentreath@gmail.com designates 209.85.214.172 as permitted sender)
Received: from [209.85.214.172] (HELO mail-ob0-f172.google.com) (209.85.214.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 16:34:34 +0000
Received: by mail-ob0-f172.google.com with SMTP id vb8so2753110obc.17
        for <dev@spark.apache.org>; Sun, 19 Oct 2014 09:34:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=KJKO2ZdZ1e/VdCH0L9+PBP1lPgh9l7L3SY5+wUJb0qs=;
        b=DMNKiUqP6GHH7+Igri6UuWnIFuWYWAfsfVBzJPtYLtmrUt/KNzgS3vtwBQY7Ch3DCg
         XOYx+SYaCQzdU/qbhnn+LDHFcuGuhAcoVKD1RGkmRV8q146Q3T1rAfHzfHonvQ7YJoAT
         EEJ5LcTQP3AtWpcy/WStLx6Snges51TYGLFbP8NTBFjAKp9Wz51v6eMXgVPkJxer53IQ
         9FpWo5pU8nS2QBnvVV7hH9Vtp1gyds1Daejzrv/1do1A8Kr3PSbCLWqZNaDvFrDl+r5E
         7faclk/Mg1R9eSiPzqK5iNZPrQeBApzCb7G2yDCwOm3whGFV1jhoVmNcA4aB9IalQJRu
         yJuQ==
MIME-Version: 1.0
X-Received: by 10.182.81.10 with SMTP id v10mr443100obx.72.1413736472914; Sun,
 19 Oct 2014 09:34:32 -0700 (PDT)
Received: by 10.182.107.196 with HTTP; Sun, 19 Oct 2014 09:34:32 -0700 (PDT)
In-Reply-To: <CAMAsSdLktDYipBYp96mkbqeAPrU6uEHbnFAYu8zOfnn3oOMZXA@mail.gmail.com>
References: <CA+B-+fwjO9Zdv1tGHQbZG18oc1vzvFzFfVX6gQtSGJJYYDDCVQ@mail.gmail.com>
	<CADnDY-XvR1+HTAfi3JRN8Dae2ms9UftVgDBXJFK2OwxSUySC-A@mail.gmail.com>
	<CAMAsSdK9SYnAf-B+Oa_uNjfkCtMAgywcC+pD=e3A+RvJ3Z_jOg@mail.gmail.com>
	<CALD+6GOjq5D_BX+0BXNp60vYv1_aNpo-kb2ZJwNJ9BM-ruCThw@mail.gmail.com>
	<CA+B-+fwiPzeBd=igo1yCnADtaN4U80s5Pr4wvtXqMWm7Xm1=uA@mail.gmail.com>
	<CAMAsSdLktDYipBYp96mkbqeAPrU6uEHbnFAYu8zOfnn3oOMZXA@mail.gmail.com>
Date: Sun, 19 Oct 2014 18:34:32 +0200
Message-ID: <CALD+6GMO7EekYUvAA=11DL80EjHXz_06KKJANTx3ivJhzZRNJw@mail.gmail.com>
Subject: Re: Oryx + Spark mllib
From: Nick Pentreath <nick.pentreath@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Debasish Das <debasish.das83@gmail.com>, Rajiv Abraham <rajiv.abraham@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b2e431046387b0505c92cde
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b2e431046387b0505c92cde
Content-Type: text/plain; charset=UTF-8

The shared-nothing load-balanced server architecture works for all but the
most massive models - and even then a few big EC2 r3 instances should do
the trick.

One nice thing about Akka (and especially the new HTTP) is fault tolerance,
recovery and potential for persistence.

For us arguably the sharding is somewhat overkill initially, but does allow
easy scaling in future where conceivably all models may not fit into single
machine memory.

On Sun, Oct 19, 2014 at 5:46 PM, Sean Owen <sowen@cloudera.com> wrote:

> Briefly, re: Oryx2, since the intent is for users to write their own
> serving apps, I though JAX-RS would be more familiar to more
> developers. I don't know how hard/easy REST APIs are in JAX-RS vs
> anything else but I suspect it's not much different.
>
> The interesting design decision that impacts scale is: do you
> distribute scoring of each request across a cluster? the servlet-based
> design does not and does everything in-core, in-memory.
>
> Pros: Dead simple architecture. Hard to beat for low latency. Anything
> more complex is big overkill for most models (RDF, k-means) -- except
> recommenders.
>
> Cons: For recommenders, harder to scale since everything is in-memory.
> And that's a big "but".
>
> On Sun, Oct 19, 2014 at 11:29 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > Would you be interested in a play and akka clustering based module in
> oryx2
> > and see how it compares against the servlets ? I am interested to
> understand
> > the scalability....
>

--047d7b2e431046387b0505c92cde--

From dev-return-9875-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 16:48:59 2014
Return-Path: <dev-return-9875-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EFAFD179AB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 16:48:59 +0000 (UTC)
Received: (qmail 46385 invoked by uid 500); 19 Oct 2014 16:48:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46313 invoked by uid 500); 19 Oct 2014 16:48:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46301 invoked by uid 99); 19 Oct 2014 16:48:58 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 16:48:58 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of cjnolet@gmail.com designates 209.85.223.179 as permitted sender)
Received: from [209.85.223.179] (HELO mail-ie0-f179.google.com) (209.85.223.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 16:48:54 +0000
Received: by mail-ie0-f179.google.com with SMTP id ar1so3295181iec.24
        for <dev@spark.apache.org>; Sun, 19 Oct 2014 09:48:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=8DAmGMIC/DU2WtkmWscHPK6G9MOV4wdBYGc3N5DLttQ=;
        b=Wxf3YWbTvSHneeLOvbkKnFDyax7kCme1QrwMIekWg31lBEE15jKan9Px+rTqp/93Pr
         LUGvlrkM3OfNdW1aw+bX+XT98ez5/FeSZjgGad92baPXNeQPyVbzy5RJ7u9qxDDcskEX
         VvwX9nQq6JR+JbixqjW+zLI+cTQzqUnGqYyJiZQ6VACdFrLl5SFPNnTTEt2PXKFIaMPZ
         +N+UhmynNPX/woY7ITWt6D003AZUo+eeaHAZjXZnbPhHIxpA/Ajv6ZPWRfrfXM3QRFuP
         Mfeklw6u+pKC4F8A7NVd9rugEAposQbYf6lXcFOiEIJ+XFcltaKHIk7gwdOp50Kn6HDV
         kRgA==
X-Received: by 10.50.73.137 with SMTP id l9mr7721595igv.26.1413737314118; Sun,
 19 Oct 2014 09:48:34 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.65.14.133 with HTTP; Sun, 19 Oct 2014 09:48:13 -0700 (PDT)
In-Reply-To: <CAAOnQ7uVg0HWvspba9tsbo_hKHw8uLjPi2-GqCsUhxJHp-=Hvw@mail.gmail.com>
References: <CA+-p3AFb3SygzTgAsxbq8q=mJ5hGNNYrpXo7kFyoGP3rMRnM1Q@mail.gmail.com>
 <CANx3uAjzxPKOKdiv2M+ff=LcW+5A893iOA337RGyTGjLy38fiw@mail.gmail.com>
 <4605E6C0-E375-455B-91CE-A1423140E8DD@gmail.com> <CAAOnQ7uVg0HWvspba9tsbo_hKHw8uLjPi2-GqCsUhxJHp-=Hvw@mail.gmail.com>
From: Corey Nolet <cjnolet@gmail.com>
Date: Sun, 19 Oct 2014 12:48:13 -0400
Message-ID: <CAOHP_tG6u0LXwGgSYno8E_0NH7-wuShMKpBy8A6xkR4tReXa3A@mail.gmail.com>
Subject: Re: Raise Java dependency from 6 to 7
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, Koert Kuipers <koert@tresata.com>, 
	Andrew Ash <andrew@andrewash.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013a226869f22b0505c95e7c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013a226869f22b0505c95e7c
Content-Type: text/plain; charset=UTF-8

A concrete plan and a definite version upon which the upgrade would be
applied sounds like it would benefit the community. If you plan far enough
out (as Hadoop has done) and give the community enough of a notice, I can't
see it being a problem as they would have ample time upgrade.



On Sat, Oct 18, 2014 at 9:20 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:

> Hadoop, for better or worse, depends on an ancient version of Jetty
> (6), that is even on a different package. So Spark (or anyone trying
> to use a newer Jetty) is lucky on that front...
>
> IIRC Hadoop is planning to move to Java 7-only starting with 2.7. Java
> 7 is also supposed to be EOL some time next year, so a plan to move to
> Java 7 and, eventually, Java 8 would be nice.
>
> On Sat, Oct 18, 2014 at 5:44 PM, Matei Zaharia <matei.zaharia@gmail.com>
> wrote:
> > I'd also wait a bit until these are gone. Jetty is unfortunately a much
> hairier topic by the way, because the Hadoop libraries also depend on
> Jetty. I think it will be hard to update. However, a patch that shades
> Jetty might be nice to have, if that doesn't require shading a lot of other
> stuff.
> >
> > Matei
> >
> >> On Oct 18, 2014, at 4:37 PM, Koert Kuipers <koert@tresata.com> wrote:
> >>
> >> my experience is that there are still a lot of java 6 clusters out
> there.
> >> also distros that bundle spark still support java 6
> >> On Oct 17, 2014 8:01 PM, "Andrew Ash" <andrew@andrewash.com> wrote:
> >>
> >>> Hi Spark devs,
> >>>
> >>> I've heard a few times that keeping support for Java 6 is a priority
> for
> >>> Apache Spark.  Given that Java 6 has been publicly EOL'd since Feb 2013
> >>> <http://www.oracle.com/technetwork/java/eol-135779.html> and the last
> >>> public update was Apr 2013
> >>> <https://en.wikipedia.org/wiki/Java_version_history#Java_6_updates>,
> why
> >>> are we still maintaing support for 6?  The only people using it now
> must be
> >>> paying for the extended support to continue receiving security fixes.
> >>>
> >>> Bumping the lower bound of Java versions up to Java 7 would allow us to
> >>> upgrade from Jetty 8 to 9, which is currently a conflict with the
> >>> Dropwizard framework and a personal pain point.
> >>>
> >>> Java 6 vs 7 for Spark links:
> >>> Try with resources
> >>> <https://github.com/apache/spark/pull/2575/files#r18152125> for
> >>> SparkContext et al
> >>> Upgrade to Jetty 9
> >>> <https://github.com/apache/spark/pull/167#issuecomment-54544494>
> >>> Warn when not compiling with Java6
> >>> <https://github.com/apache/spark/pull/859>
> >>>
> >>>
> >>> Who are the people out there that still need Java 6 support?
> >>>
> >>> Thanks!
> >>> Andrew
> >>>
> >
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
>
>
> --
> Marcelo
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e013a226869f22b0505c95e7c--

From dev-return-9876-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 19 20:13:52 2014
Return-Path: <dev-return-9876-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 729B617D27
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 19 Oct 2014 20:13:51 +0000 (UTC)
Received: (qmail 8549 invoked by uid 500); 19 Oct 2014 20:13:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8481 invoked by uid 500); 19 Oct 2014 20:13:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8469 invoked by uid 99); 19 Oct 2014 20:13:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 20:13:49 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 19 Oct 2014 20:13:44 +0000
Received: by mail-pa0-f54.google.com with SMTP id ey11so3843490pad.27
        for <dev@spark.apache.org>; Sun, 19 Oct 2014 13:13:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date
         :content-transfer-encoding:message-id:references:to;
        bh=7TrPjnulbypwTzom1WB4aWzkjm+YZF29Q1noe3PZrtg=;
        b=sfRNuFGz402Lxp2reLHpQ6JTLNUJn/lWK4mo99ljkJTUL740Xq63rg+FtsakZ2b0sJ
         iPUMQodYUhNjlUfaTLR+wFWQwFG7FxnI/B024P/fp4oJXHi7oJl42X1mfcGcFsJ9z1nM
         FmYA2gASEP6DGqeXvO2Uo12B7z6/MJ7ohovZoo7+rpKGToFBXhOuL0+ZDWMi/EPH/+BQ
         9RsFxLVm2AtgWlGPclAAl1eXOiCaQTTLkZxgLmhaybI6p8YDDJCbwZaJBspa/BenvUq3
         aGHq7C7M/eNmYZvMhcfGb1lLplw43I3v7qUxaBbao+sDBWlO1+/e4aLCdSjm1VF47Nt5
         6myA==
X-Received: by 10.70.125.225 with SMTP id mt1mr23021220pdb.49.1413749604267;
        Sun, 19 Oct 2014 13:13:24 -0700 (PDT)
Received: from [192.168.1.106] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id nd6sm7235796pbc.28.2014.10.19.13.13.22
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 19 Oct 2014 13:13:23 -0700 (PDT)
Content-Type: text/plain; charset=utf-8
Mime-Version: 1.0 (Mac OS X Mail 8.0 \(1990.1\))
Subject: Re: Submissions open for Spark Summit East 2015
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <D0ADA066-72C3-4CC9-B102-825EBCFA7A5A@gmail.com>
Date: Sun, 19 Oct 2014 13:13:22 -0700
Content-Transfer-Encoding: quoted-printable
Message-Id: <59B001C8-D253-4503-8E79-20D3CA0BD65D@gmail.com>
References: <D0ADA066-72C3-4CC9-B102-825EBCFA7A5A@gmail.com>
To: user@spark.incubator.apache.org,
 dev <dev@spark.apache.org>
X-Mailer: Apple Mail (2.1990.1)
X-Virus-Checked: Checked by ClamAV on apache.org

BTW several people asked about registration and student passes. =
Registration will open in a few weeks, and like in previous Spark =
Summits, I expect there to be a special pass for students.

Matei

> On Oct 18, 2014, at 9:52 PM, Matei Zaharia <matei.zaharia@gmail.com> =
wrote:
>=20
> After successful events in the past two years, the Spark Summit =
conference has expanded for 2015, offering both an event in New York on =
March 18-19 and one in San Francisco on June 15-17. The conference is a =
great chance to meet people from throughout the Spark community and see =
the latest news, tips and use cases.
>=20
> Submissions are now open for Spark Summit East 2015, to be held in New =
York on March 18-19. If you=E2=80=99d like to give a talk on use cases, =
neat applications, or ongoing Spark development, submit your talk online =
today at http://prevalentdesignevents.com/sparksummit2015/east/speaker/. =
Submissions will be open until December 6th, 2014.
>=20
> If you missed this year=E2=80=99s Spark Summit, you can still find =
videos from all talks online at http://spark-summit.org/2014.
>=20
> Hope to see you there,
>=20
> Matei


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9877-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 02:21:34 2014
Return-Path: <dev-return-9877-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 176A5173E3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 02:21:34 +0000 (UTC)
Received: (qmail 74150 invoked by uid 500); 20 Oct 2014 02:21:33 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74074 invoked by uid 500); 20 Oct 2014 02:21:33 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74059 invoked by uid 99); 20 Oct 2014 02:21:32 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 02:21:32 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.46 as permitted sender)
Received: from [209.85.220.46] (HELO mail-pa0-f46.google.com) (209.85.220.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 02:21:28 +0000
Received: by mail-pa0-f46.google.com with SMTP id fa1so4196628pad.33
        for <dev@spark.apache.org>; Sun, 19 Oct 2014 19:21:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=rjbv4AwYNafXigr+voDr/axrv0v+shwJgH5tVE5RnGE=;
        b=uN79TR9ww4O3WhUITrqS2v2A0mYXtjAPrBFgF/s4Dtf1Wyux74hAQF93IlGF2TAZ2L
         6K/pNWkcWMzxwig+c3pEyxXpn32B8iz5LR/GOZGLBYFz4ipa7gMNi6oVyIeA9cXSWt8Z
         q09omN7OdJPcTD8fMC3O+/Gjp7h6ikn5CPLJJa+rryxezE4Q8sGHYSW2Z4QDCiMiPRe0
         sKRmyKLBZ45yjlBAlEKdVjA0SY3OukorzzQn9xRzQ/H6Gj5DK6XH7jUuO7Za0IFxKGip
         2dYxStrS3Pq0MW5KuGk6Ey3msBSb/Q9zLD6ElhC59WrmvWJ4KJKHjLZz3JDo1mxne985
         G3qw==
X-Received: by 10.66.119.70 with SMTP id ks6mr24597330pab.74.1413771668349;
        Sun, 19 Oct 2014 19:21:08 -0700 (PDT)
Received: from [192.168.1.106] (c-50-174-127-216.hsd1.ca.comcast.net. [50.174.127.216])
        by mx.google.com with ESMTPSA id c10sm5180991pdj.77.2014.10.19.19.21.07
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 19 Oct 2014 19:21:07 -0700 (PDT)
Content-Type: multipart/alternative; boundary="Apple-Mail=_972D024E-9D83-478B-8165-41E3709A9F8E"
Mime-Version: 1.0 (Mac OS X Mail 8.0 \(1990.1\))
Subject: Re: Raise Java dependency from 6 to 7
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CAOHP_tG6u0LXwGgSYno8E_0NH7-wuShMKpBy8A6xkR4tReXa3A@mail.gmail.com>
Date: Sun, 19 Oct 2014 19:21:06 -0700
Cc: Marcelo Vanzin <vanzin@cloudera.com>,
 Koert Kuipers <koert@tresata.com>,
 Andrew Ash <andrew@andrewash.com>,
 dev <dev@spark.apache.org>
Message-Id: <43DCEC53-385F-44C9-B677-4FC7F0F5F2BC@gmail.com>
References: <CA+-p3AFb3SygzTgAsxbq8q=mJ5hGNNYrpXo7kFyoGP3rMRnM1Q@mail.gmail.com> <CANx3uAjzxPKOKdiv2M+ff=LcW+5A893iOA337RGyTGjLy38fiw@mail.gmail.com> <4605E6C0-E375-455B-91CE-A1423140E8DD@gmail.com> <CAAOnQ7uVg0HWvspba9tsbo_hKHw8uLjPi2-GqCsUhxJHp-=Hvw@mail.gmail.com> <CAOHP_tG6u0LXwGgSYno8E_0NH7-wuShMKpBy8A6xkR4tReXa3A@mail.gmail.com>
To: Corey Nolet <cjnolet@gmail.com>
X-Mailer: Apple Mail (2.1990.1)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_972D024E-9D83-478B-8165-41E3709A9F8E
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=us-ascii

So from my point of view, I'd do it maybe 1-2 years after all the major =
Hadoop vendors have stopped supporting Java 6. We're not there yet, but =
we will be soon. The reason is that the cost of staying on Java 6 is =
much smaller to us (as developers) than the cost of fragmenting the =
Spark community by having a big chunk of users unable to upgrade past a =
certain version of Spark (or requiring them to use a modified =
third-party version, which is a similar thing). There's very little =
stuff in Java 7 or 8 that would make the project much better if we =
dropped support for 6 -- this Jetty issue might be one, but we can =
certainly work around it.

We've done a lot of stuff to reach the broadest set of users, including =
pushing back the versions of Python and NumPy we support, and in my =
experience it's been well worth it. In surveys I've seen the majority of =
users (something like 75%) updating to each new Spark release within a =
few months of it coming out, which is awesome for keeping the community =
healthy.

Matei


> On Oct 19, 2014, at 9:48 AM, Corey Nolet <cjnolet@gmail.com> wrote:
>=20
> A concrete plan and a definite version upon which the upgrade would be =
applied sounds like it would benefit the community. If you plan far =
enough out (as Hadoop has done) and give the community enough of a =
notice, I can't see it being a problem as they would have ample time =
upgrade.=20
>=20
>=20
>=20
> On Sat, Oct 18, 2014 at 9:20 PM, Marcelo Vanzin <vanzin@cloudera.com =
<mailto:vanzin@cloudera.com>> wrote:
> Hadoop, for better or worse, depends on an ancient version of Jetty
> (6), that is even on a different package. So Spark (or anyone trying
> to use a newer Jetty) is lucky on that front...
>=20
> IIRC Hadoop is planning to move to Java 7-only starting with 2.7. Java
> 7 is also supposed to be EOL some time next year, so a plan to move to
> Java 7 and, eventually, Java 8 would be nice.
>=20
> On Sat, Oct 18, 2014 at 5:44 PM, Matei Zaharia =
<matei.zaharia@gmail.com <mailto:matei.zaharia@gmail.com>> wrote:
> > I'd also wait a bit until these are gone. Jetty is unfortunately a =
much hairier topic by the way, because the Hadoop libraries also depend =
on Jetty. I think it will be hard to update. However, a patch that =
shades Jetty might be nice to have, if that doesn't require shading a =
lot of other stuff.
> >
> > Matei
> >
> >> On Oct 18, 2014, at 4:37 PM, Koert Kuipers <koert@tresata.com =
<mailto:koert@tresata.com>> wrote:
> >>
> >> my experience is that there are still a lot of java 6 clusters out =
there.
> >> also distros that bundle spark still support java 6
> >> On Oct 17, 2014 8:01 PM, "Andrew Ash" <andrew@andrewash.com =
<mailto:andrew@andrewash.com>> wrote:
> >>
> >>> Hi Spark devs,
> >>>
> >>> I've heard a few times that keeping support for Java 6 is a =
priority for
> >>> Apache Spark.  Given that Java 6 has been publicly EOL'd since Feb =
2013
> >>> <http://www.oracle.com/technetwork/java/eol-135779.html =
<http://www.oracle.com/technetwork/java/eol-135779.html>> and the last
> >>> public update was Apr 2013
> >>> <https://en.wikipedia.org/wiki/Java_version_history#Java_6_updates =
<https://en.wikipedia.org/wiki/Java_version_history#Java_6_updates>>, =
why
> >>> are we still maintaing support for 6?  The only people using it =
now must be
> >>> paying for the extended support to continue receiving security =
fixes.
> >>>
> >>> Bumping the lower bound of Java versions up to Java 7 would allow =
us to
> >>> upgrade from Jetty 8 to 9, which is currently a conflict with the
> >>> Dropwizard framework and a personal pain point.
> >>>
> >>> Java 6 vs 7 for Spark links:
> >>> Try with resources
> >>> <https://github.com/apache/spark/pull/2575/files#r18152125 =
<https://github.com/apache/spark/pull/2575/files#r18152125>> for
> >>> SparkContext et al
> >>> Upgrade to Jetty 9
> >>> <https://github.com/apache/spark/pull/167#issuecomment-54544494 =
<https://github.com/apache/spark/pull/167#issuecomment-54544494>>
> >>> Warn when not compiling with Java6
> >>> <https://github.com/apache/spark/pull/859 =
<https://github.com/apache/spark/pull/859>>
> >>>
> >>>
> >>> Who are the people out there that still need Java 6 support?
> >>>
> >>> Thanks!
> >>> Andrew
> >>>
> >
> >
> > =
---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org =
<mailto:dev-unsubscribe@spark.apache.org>
> > For additional commands, e-mail: dev-help@spark.apache.org =
<mailto:dev-help@spark.apache.org>
> >
>=20
>=20
>=20
> --
> Marcelo
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org =
<mailto:dev-unsubscribe@spark.apache.org>
> For additional commands, e-mail: dev-help@spark.apache.org =
<mailto:dev-help@spark.apache.org>
>=20
>=20


--Apple-Mail=_972D024E-9D83-478B-8165-41E3709A9F8E--

From dev-return-9878-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 05:28:13 2014
Return-Path: <dev-return-9878-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CA79917663
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 05:28:13 +0000 (UTC)
Received: (qmail 55206 invoked by uid 500); 20 Oct 2014 05:28:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55125 invoked by uid 500); 20 Oct 2014 05:28:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55107 invoked by uid 99); 20 Oct 2014 05:28:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 05:28:11 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of henry.saputra@gmail.com designates 209.85.217.181 as permitted sender)
Received: from [209.85.217.181] (HELO mail-lb0-f181.google.com) (209.85.217.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 05:28:07 +0000
Received: by mail-lb0-f181.google.com with SMTP id l4so3196516lbv.26
        for <dev@spark.apache.org>; Sun, 19 Oct 2014 22:27:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=pd3hyzANWlAvS83ZyJF6cVZnUBwjJacHUBj4sJcciho=;
        b=iQ/O/xi1se/QHx2WVP6N7QAwSct3mzPjCCUn6NTakT5ttr0256RgdPlN9NstfQlyah
         SjezktCfR31RHIH2Y9GGCecUJwnRCvHCo0++1/ekzwZZilX9xq2yNmVofuNCpMhc3q31
         lmJyjravG66qq7nc5Rnp4JS9vjTamIFnMO2Ltz9VWkCLxtojepWWSs4B93tsNDf0armI
         UvGkxD7cO9FtC/ytTq8S/zMvMmOXcyL6H6hkC258LDVSr5rWpHp6MdKdajCE9WTHLRrE
         o1PPRL5lIak9d8Iip8WdJMRL84LNALB2LYN8ImFc4EL59OaSdzmCn/tYQ3ajCQ4DwLsD
         dDpw==
MIME-Version: 1.0
X-Received: by 10.112.140.8 with SMTP id rc8mr24585679lbb.2.1413782865641;
 Sun, 19 Oct 2014 22:27:45 -0700 (PDT)
Received: by 10.25.31.75 with HTTP; Sun, 19 Oct 2014 22:27:45 -0700 (PDT)
In-Reply-To: <D730DBF4-1D7E-4005-9195-3CE890C683B3@guavus.com>
References: <D730DBF4-1D7E-4005-9195-3CE890C683B3@guavus.com>
Date: Sun, 19 Oct 2014 22:27:45 -0700
Message-ID: <CALuGr6Y9mXAQLnNWx3r5b--T2m3bBK7v2OmVyN2DYvHhOMVdtQ@mail.gmail.com>
Subject: Re: Joining the spark dev community
From: Henry Saputra <henry.saputra@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Saurabh,

Good way to start is to use Spark with your applications and file
issues you might have found and maybe provide patch for those or
existing ones.

Please take a look at Spark's how to contribute page [1] to help you
get started.

Hope this helps.

- Henry


[1] https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark

On Sat, Oct 18, 2014 at 1:46 PM, Saurabh Wadhawan
<Saurabh.Wadhawan@guavus.com> wrote:
> How can I become a spark contributor.
> What's the good path that I can follow to become an active code submitter for spark from a newbie.
>
> Regards
> - Saurabh
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9879-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 14:17:53 2014
Return-Path: <dev-return-9879-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 28537173DA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 14:17:53 +0000 (UTC)
Received: (qmail 83750 invoked by uid 500); 20 Oct 2014 14:17:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83675 invoked by uid 500); 20 Oct 2014 14:17:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83663 invoked by uid 99); 20 Oct 2014 14:17:51 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 14:17:51 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HK_RANDOM_ENVFROM,HK_RANDOM_FROM,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of huaiyin.thu@gmail.com designates 209.85.215.45 as permitted sender)
Received: from [209.85.215.45] (HELO mail-la0-f45.google.com) (209.85.215.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 14:17:26 +0000
Received: by mail-la0-f45.google.com with SMTP id q1so4053592lam.18
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 07:17:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=Ssux1GZoohsWltsP98mJCDkJ+fj+wBjfP+MlNUjiJWY=;
        b=Nm6NZQ9BYVyKlZ7Ofq9ax67l7CdQsiWw4mnXNgzuW1JwGN2HMsAyo3bWdTfoOCX9ck
         /x+cePXL3GtbUt2bN1MQ/2ZnffqHb+Qfi0Dl6iaFHE834sQpldT/Dg6IIFRjuZlx8hwy
         dvE4Wp+mRRt1O5fSTAy5e05AQNdH8iMM3PemQBM38wD/IqpndxwN2h0nQLV41q3Cs+Y3
         kZv/sF03lJdBf+4xHPYnDPoN1dd8LWZfJAKxUOnBZK8r/tO8NHKyp9zfQN6weyGY5PEj
         6Bv6EOc00Yf+9vcULqPof+ujSnJfxQtXT2Bob1tz+SdVpOneLEcgNPK29kIZHINWqcHW
         y8bw==
X-Received: by 10.153.7.107 with SMTP id db11mr27889043lad.35.1413814645211;
 Mon, 20 Oct 2014 07:17:25 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.56.75 with HTTP; Mon, 20 Oct 2014 07:17:04 -0700 (PDT)
From: Yin Huai <huaiyin.thu@gmail.com>
Date: Mon, 20 Oct 2014 10:17:04 -0400
Message-ID: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
Subject: Get attempt number in a closure
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a113456a0b4dab80505db5fd2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113456a0b4dab80505db5fd2
Content-Type: text/plain; charset=UTF-8

Hello,

Is there any way to get the attempt number in a closure? Seems
TaskContext.attemptId actually returns the taskId of a task (see this
<https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L181>
 and this
<https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/Task.scala#L47>).
It looks like a bug.

Thanks,

Yin

--001a113456a0b4dab80505db5fd2--

From dev-return-9880-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 17:58:31 2014
Return-Path: <dev-return-9880-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A0B6917C00
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 17:58:31 +0000 (UTC)
Received: (qmail 82488 invoked by uid 500); 20 Oct 2014 17:58:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82397 invoked by uid 500); 20 Oct 2014 17:58:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82381 invoked by uid 99); 20 Oct 2014 17:58:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 17:58:30 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.181] (HELO mail-qc0-f181.google.com) (209.85.216.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 17:58:25 +0000
Received: by mail-qc0-f181.google.com with SMTP id r5so4089416qcx.40
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 10:58:04 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=t5n8uVtsWMi0nF4aAJOCq33L0CETq+SBzqEFjZZsfEs=;
        b=Lq6BsV+wjR7Yf3m8bAjeJqb6F8yU/1PrpJKf8WnS2uwhglI5qnuT/KaueuppGI0Ute
         qX8znkmn72Vt8qFLB0ldu2+x+61M2K+pi/YjbxpGe/yhsJM277R6fPgeLy5V0w3gqB8Z
         E58ZBFYZNhLp9aq8rMm9PLQhGW3v3rduiX+TGfJ/hjf117+cPNIjboeBNDKBPs9LgBPJ
         XV9KXPpE0yqWqJBe4el5fWjhbVrvlkFX4qrMIo5W6PcANbOXRSTqJYgluFpNaI1DKOUO
         M0zAlxiCe0rxKK1xvS4y7es15u64qGlwJgIe6lufy/iF5sURXFENWLkpd6/aQbRrVult
         Ip1A==
X-Gm-Message-State: ALoCoQldCgBX+zVAdDAgEKU2bqwDjpqZaoauzVVeGoN0fLkgIRBmPtWL9d51TCXXCafQ+XSASXYf
X-Received: by 10.224.79.146 with SMTP id p18mr36802853qak.67.1413827884565;
 Mon, 20 Oct 2014 10:58:04 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.47.8 with HTTP; Mon, 20 Oct 2014 10:57:42 -0700 (PDT)
In-Reply-To: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
References: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 20 Oct 2014 10:57:42 -0700
Message-ID: <CAPh_B=ZbfXMA21EiTiRx1bV4_t_+GuK9OoCKg493M_Kr72Y2WQ@mail.gmail.com>
Subject: Re: Get attempt number in a closure
To: Yin Huai <huaiyin.thu@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bf0e070d560230505de7487
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bf0e070d560230505de7487
Content-Type: text/plain; charset=UTF-8

I also ran into this earlier. It is a bug. Do you want to file a jira?

I think part of the problem is that we don't actually have the attempt id
on the executors. If we do, that's great. If not, we'd need to propagate
that over.

On Mon, Oct 20, 2014 at 7:17 AM, Yin Huai <huaiyin.thu@gmail.com> wrote:

> Hello,
>
> Is there any way to get the attempt number in a closure? Seems
> TaskContext.attemptId actually returns the taskId of a task (see this
> <
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L181
> >
>  and this
> <
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/Task.scala#L47
> >).
> It looks like a bug.
>
> Thanks,
>
> Yin
>

--047d7bf0e070d560230505de7487--

From dev-return-9881-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 19:39:18 2014
Return-Path: <dev-return-9881-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CA71917226
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 19:39:18 +0000 (UTC)
Received: (qmail 45643 invoked by uid 500); 20 Oct 2014 19:39:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45570 invoked by uid 500); 20 Oct 2014 19:39:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45558 invoked by uid 99); 20 Oct 2014 19:39:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 19:39:17 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HK_RANDOM_ENVFROM,HK_RANDOM_FROM,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of huaiyin.thu@gmail.com designates 209.85.215.50 as permitted sender)
Received: from [209.85.215.50] (HELO mail-la0-f50.google.com) (209.85.215.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 19:38:52 +0000
Received: by mail-la0-f50.google.com with SMTP id s18so4595657lam.37
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 12:38:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=xJ0hWopA1iABIGA375N0L4tSdCpq58gMLBZ4DmUSLsw=;
        b=Zk8Grohl8ulgXGrgqFKOvfUlXHdQST9Q9gsqqXc7x7gXfLc/CT0Vp68KS6wNKTCcbw
         bLqNnI4U/5OtNVWd4CLqkXBRekHocPJR5l5waOk79xOJXych+yrKa/p4DLJtGm52xm2z
         YbEmh3DrDzJVZKd2V8Hpgx/ZVLilRE100RGIxlz+QjatS3DfcGufH4RIumu8d4fTxlWt
         N6+MClX1A9x6+vo+3M3Emc6d4hNqDlkxeGm2XlrppIBQw0t0B9jR/YEIoQkxnpVhQn0Y
         D16Cv51RaYSvPLFsqVOFMzSP5m+RlsilUqXOEn0ZNgey/BIQNlMQ6Pj0eMbq+QFZggU+
         TUdQ==
X-Received: by 10.112.172.231 with SMTP id bf7mr2917343lbc.100.1413833931662;
 Mon, 20 Oct 2014 12:38:51 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.56.75 with HTTP; Mon, 20 Oct 2014 12:38:31 -0700 (PDT)
In-Reply-To: <CAPh_B=ZbfXMA21EiTiRx1bV4_t_+GuK9OoCKg493M_Kr72Y2WQ@mail.gmail.com>
References: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
 <CAPh_B=ZbfXMA21EiTiRx1bV4_t_+GuK9OoCKg493M_Kr72Y2WQ@mail.gmail.com>
From: Yin Huai <huaiyin.thu@gmail.com>
Date: Mon, 20 Oct 2014 15:38:31 -0400
Message-ID: <CAOSFW132zn483rBFLiC1W1ydiKrfShBo1Qs4m-B-7ffiJCuwOQ@mail.gmail.com>
Subject: Re: Get attempt number in a closure
To: Reynold Xin <rxin@databricks.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c38bc644aa7e0505dfdd3f
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c38bc644aa7e0505dfdd3f
Content-Type: text/plain; charset=UTF-8

Yeah, seems we need to pass the attempt id to executors through
TaskDescription. I have created
https://issues.apache.org/jira/browse/SPARK-4014.

On Mon, Oct 20, 2014 at 1:57 PM, Reynold Xin <rxin@databricks.com> wrote:

> I also ran into this earlier. It is a bug. Do you want to file a jira?
>
> I think part of the problem is that we don't actually have the attempt id
> on the executors. If we do, that's great. If not, we'd need to propagate
> that over.
>
> On Mon, Oct 20, 2014 at 7:17 AM, Yin Huai <huaiyin.thu@gmail.com> wrote:
>
>> Hello,
>>
>> Is there any way to get the attempt number in a closure? Seems
>> TaskContext.attemptId actually returns the taskId of a task (see this
>> <
>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L181
>> >
>>  and this
>> <
>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/Task.scala#L47
>> >).
>> It looks like a bug.
>>
>> Thanks,
>>
>> Yin
>>
>
>

--001a11c38bc644aa7e0505dfdd3f--

From dev-return-9882-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 20:29:59 2014
Return-Path: <dev-return-9882-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 26C3717453
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 20:29:59 +0000 (UTC)
Received: (qmail 63800 invoked by uid 500); 20 Oct 2014 20:29:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63725 invoked by uid 500); 20 Oct 2014 20:29:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63713 invoked by uid 99); 20 Oct 2014 20:29:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 20:29:57 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 20:29:53 +0000
Received: by mail-ob0-f175.google.com with SMTP id wn1so4499273obc.6
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 13:29:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=z/joGD93SLaLC5mJO/mf3JQ2uksYgE7Lcf2J3lo6CF8=;
        b=FMS5t+9vJVmfIFeeLO2Dc3Ek/5vF0RDZnyGcgcQVAqztRvRRczCDXoQbWbbCV35dHx
         dZ+La+whMfVJ+tXU8/bRVF/UuRxzYSi5gdqjbws5qU2T+DYb7NiKgqidbCWZdYiWEH2F
         C9rBAvp4HnPGuYJMztTPMsikt9nRrgpAVLvJnp8p41WgTB3FjaIsnSEiEDRB+pr9hpQD
         Qp7LXqKXhcQE1/1funbVo4nCCXoMtvcyq9iF9xs4b2wUbOcDW9VQJnPURXvtJ1FTA8w2
         b6aXbgfpM1nzRk0eFvjyqxIEDXLBCLg+Z69AObUkf6X7Gcyleg/V81NJEvV5pBcMAEmK
         7RNQ==
MIME-Version: 1.0
X-Received: by 10.202.98.195 with SMTP id w186mr2572825oib.104.1413836973262;
 Mon, 20 Oct 2014 13:29:33 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Mon, 20 Oct 2014 13:29:33 -0700 (PDT)
In-Reply-To: <CAOSFW132zn483rBFLiC1W1ydiKrfShBo1Qs4m-B-7ffiJCuwOQ@mail.gmail.com>
References: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
	<CAPh_B=ZbfXMA21EiTiRx1bV4_t_+GuK9OoCKg493M_Kr72Y2WQ@mail.gmail.com>
	<CAOSFW132zn483rBFLiC1W1ydiKrfShBo1Qs4m-B-7ffiJCuwOQ@mail.gmail.com>
Date: Mon, 20 Oct 2014 13:29:33 -0700
Message-ID: <CABPQxstu+qLf=42biCOVTYNritcNcCQ2rxnQEafL8vRKJ6+44A@mail.gmail.com>
Subject: Re: Get attempt number in a closure
From: Patrick Wendell <pwendell@gmail.com>
To: Yin Huai <huaiyin.thu@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

There is a deeper issue here which is AFAIK we don't even store a
notion of attempt inside of Spark, we just use a new taskId with the
same index.

On Mon, Oct 20, 2014 at 12:38 PM, Yin Huai <huaiyin.thu@gmail.com> wrote:
> Yeah, seems we need to pass the attempt id to executors through
> TaskDescription. I have created
> https://issues.apache.org/jira/browse/SPARK-4014.
>
> On Mon, Oct 20, 2014 at 1:57 PM, Reynold Xin <rxin@databricks.com> wrote:
>
>> I also ran into this earlier. It is a bug. Do you want to file a jira?
>>
>> I think part of the problem is that we don't actually have the attempt id
>> on the executors. If we do, that's great. If not, we'd need to propagate
>> that over.
>>
>> On Mon, Oct 20, 2014 at 7:17 AM, Yin Huai <huaiyin.thu@gmail.com> wrote:
>>
>>> Hello,
>>>
>>> Is there any way to get the attempt number in a closure? Seems
>>> TaskContext.attemptId actually returns the taskId of a task (see this
>>> <
>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L181
>>> >
>>>  and this
>>> <
>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/Task.scala#L47
>>> >).
>>> It looks like a bug.
>>>
>>> Thanks,
>>>
>>> Yin
>>>
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9883-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 20:46:07 2014
Return-Path: <dev-return-9883-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4FC7B174B7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 20:46:07 +0000 (UTC)
Received: (qmail 96261 invoked by uid 500); 20 Oct 2014 20:46:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96180 invoked by uid 500); 20 Oct 2014 20:46:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96169 invoked by uid 99); 20 Oct 2014 20:46:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 20:46:05 +0000
X-ASF-Spam-Status: No, hits=0.9 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_SOFTFAIL
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of keo@eecs.berkeley.edu does not designate 169.229.218.143 as permitted sender)
Received: from [169.229.218.143] (HELO cm02fe.IST.Berkeley.EDU) (169.229.218.143)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 20:45:40 +0000
Received: from mail-yh0-f51.google.com ([209.85.213.51])
	by cm02fe.ist.berkeley.edu with esmtpsa (TLSv1:RC4-SHA:128)
	(Exim 4.76)
	(auth plain:keo@eecs.berkeley.edu)
	(envelope-from <keo@eecs.berkeley.edu>)
	id 1XgJpg-0006lw-7y
	for dev@spark.apache.org; Mon, 20 Oct 2014 13:45:37 -0700
Received: by mail-yh0-f51.google.com with SMTP id t59so3945734yho.24
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 13:45:35 -0700 (PDT)
MIME-Version: 1.0
X-Received: by 10.236.230.105 with SMTP id i99mr42833173yhq.72.1413837935582;
 Mon, 20 Oct 2014 13:45:35 -0700 (PDT)
Received: by 10.170.136.72 with HTTP; Mon, 20 Oct 2014 13:45:35 -0700 (PDT)
In-Reply-To: <CABPQxstu+qLf=42biCOVTYNritcNcCQ2rxnQEafL8vRKJ6+44A@mail.gmail.com>
References: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
	<CAPh_B=ZbfXMA21EiTiRx1bV4_t_+GuK9OoCKg493M_Kr72Y2WQ@mail.gmail.com>
	<CAOSFW132zn483rBFLiC1W1ydiKrfShBo1Qs4m-B-7ffiJCuwOQ@mail.gmail.com>
	<CABPQxstu+qLf=42biCOVTYNritcNcCQ2rxnQEafL8vRKJ6+44A@mail.gmail.com>
Date: Mon, 20 Oct 2014 13:45:35 -0700
Message-ID: <CAKJXNjFFUsQYoz40z=rfgJJmmaRegX=w+N7B1DN3MUco6uEaww@mail.gmail.com>
Subject: Re: Get attempt number in a closure
From: Kay Ousterhout <keo@eecs.berkeley.edu>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Yin Huai <huaiyin.thu@gmail.com>, Reynold Xin <rxin@databricks.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160d102eba9990505e0cb6f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160d102eba9990505e0cb6f
Content-Type: text/plain; charset=UTF-8

Are you guys sure this is a bug?  In the task scheduler, we keep two
identifiers for each task: the "index", which uniquely identifiers the
computation+partition, and the "taskId" which is unique across all tasks
for that Spark context (See
https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/TaskSetManager.scala#L439).
If multiple attempts of one task are run, they will have the same index,
but different taskIds.  Historically, we have used "taskId" and
"taskAttemptId" interchangeably (which arose from naming in Mesos, which
uses similar naming).

This was complicated when Mr. Xin added the "attempt" field to TaskInfo,
which we show in the UI.  This field uniquely identifies attempts for a
particular task, but is not unique across different task indexes (it always
starts at 0 for a given task).  I'm guessing the right fix is to rename
Task.taskAttemptId to Task.taskId to resolve this inconsistency -- does
that sound right to you Reynold?

-Kay

On Mon, Oct 20, 2014 at 1:29 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> There is a deeper issue here which is AFAIK we don't even store a
> notion of attempt inside of Spark, we just use a new taskId with the
> same index.
>
> On Mon, Oct 20, 2014 at 12:38 PM, Yin Huai <huaiyin.thu@gmail.com> wrote:
> > Yeah, seems we need to pass the attempt id to executors through
> > TaskDescription. I have created
> > https://issues.apache.org/jira/browse/SPARK-4014.
> >
> > On Mon, Oct 20, 2014 at 1:57 PM, Reynold Xin <rxin@databricks.com>
> wrote:
> >
> >> I also ran into this earlier. It is a bug. Do you want to file a jira?
> >>
> >> I think part of the problem is that we don't actually have the attempt
> id
> >> on the executors. If we do, that's great. If not, we'd need to propagate
> >> that over.
> >>
> >> On Mon, Oct 20, 2014 at 7:17 AM, Yin Huai <huaiyin.thu@gmail.com>
> wrote:
> >>
> >>> Hello,
> >>>
> >>> Is there any way to get the attempt number in a closure? Seems
> >>> TaskContext.attemptId actually returns the taskId of a task (see this
> >>> <
> >>>
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L181
> >>> >
> >>>  and this
> >>> <
> >>>
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/Task.scala#L47
> >>> >).
> >>> It looks like a bug.
> >>>
> >>> Thanks,
> >>>
> >>> Yin
> >>>
> >>
> >>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e0160d102eba9990505e0cb6f--

From dev-return-9884-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 20:48:28 2014
Return-Path: <dev-return-9884-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 35C32174C0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 20:48:28 +0000 (UTC)
Received: (qmail 99239 invoked by uid 500); 20 Oct 2014 20:48:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 99164 invoked by uid 500); 20 Oct 2014 20:48:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 99153 invoked by uid 99); 20 Oct 2014 20:48:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 20:48:25 +0000
X-ASF-Spam-Status: No, hits=0.9 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_SOFTFAIL
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of keo@eecs.berkeley.edu does not designate 169.229.218.147 as permitted sender)
Received: from [169.229.218.147] (HELO cm06fe.IST.Berkeley.EDU) (169.229.218.147)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 20:47:59 +0000
Received: from mail-yh0-f47.google.com ([209.85.213.47])
	by cm06fe.ist.berkeley.edu with esmtpsa (TLSv1:RC4-SHA:128)
	(Exim 4.76)
	(auth plain:keo@eecs.berkeley.edu)
	(envelope-from <keo@eecs.berkeley.edu>)
	id 1XgJrv-00034O-MB
	for dev@spark.apache.org; Mon, 20 Oct 2014 13:47:57 -0700
Received: by mail-yh0-f47.google.com with SMTP id c41so3977509yho.6
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 13:47:55 -0700 (PDT)
MIME-Version: 1.0
X-Received: by 10.236.1.228 with SMTP id 64mr6442yhd.51.1413838075097; Mon, 20
 Oct 2014 13:47:55 -0700 (PDT)
Received: by 10.170.136.72 with HTTP; Mon, 20 Oct 2014 13:47:54 -0700 (PDT)
In-Reply-To: <CAKJXNjFFUsQYoz40z=rfgJJmmaRegX=w+N7B1DN3MUco6uEaww@mail.gmail.com>
References: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
	<CAPh_B=ZbfXMA21EiTiRx1bV4_t_+GuK9OoCKg493M_Kr72Y2WQ@mail.gmail.com>
	<CAOSFW132zn483rBFLiC1W1ydiKrfShBo1Qs4m-B-7ffiJCuwOQ@mail.gmail.com>
	<CABPQxstu+qLf=42biCOVTYNritcNcCQ2rxnQEafL8vRKJ6+44A@mail.gmail.com>
	<CAKJXNjFFUsQYoz40z=rfgJJmmaRegX=w+N7B1DN3MUco6uEaww@mail.gmail.com>
Date: Mon, 20 Oct 2014 13:47:54 -0700
Message-ID: <CAKJXNjEdZ8wZyEVyJpzH5D4sg914XpGEHhD6WSVfyr5U1Fv2hw@mail.gmail.com>
Subject: Re: Get attempt number in a closure
From: Kay Ousterhout <keo@eecs.berkeley.edu>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Yin Huai <huaiyin.thu@gmail.com>, Reynold Xin <rxin@databricks.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0112cec23c79f30505e0d45e
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0112cec23c79f30505e0d45e
Content-Type: text/plain; charset=UTF-8

Sorry to clarify, there are two issues here:

(1) attemptId has different meanings in the codebase
(2) we currently don't propagate the 0-based per-task attempt identifier to
the executors.

(1) should definitely be fixed.  It sounds like Yin's original email was
requesting that we add (2).

On Mon, Oct 20, 2014 at 1:45 PM, Kay Ousterhout <keo@eecs.berkeley.edu>
wrote:

> Are you guys sure this is a bug?  In the task scheduler, we keep two
> identifiers for each task: the "index", which uniquely identifiers the
> computation+partition, and the "taskId" which is unique across all tasks
> for that Spark context (See
> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/TaskSetManager.scala#L439).
> If multiple attempts of one task are run, they will have the same index,
> but different taskIds.  Historically, we have used "taskId" and
> "taskAttemptId" interchangeably (which arose from naming in Mesos, which
> uses similar naming).
>
> This was complicated when Mr. Xin added the "attempt" field to TaskInfo,
> which we show in the UI.  This field uniquely identifies attempts for a
> particular task, but is not unique across different task indexes (it always
> starts at 0 for a given task).  I'm guessing the right fix is to rename
> Task.taskAttemptId to Task.taskId to resolve this inconsistency -- does
> that sound right to you Reynold?
>
> -Kay
>
> On Mon, Oct 20, 2014 at 1:29 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
>> There is a deeper issue here which is AFAIK we don't even store a
>> notion of attempt inside of Spark, we just use a new taskId with the
>> same index.
>>
>> On Mon, Oct 20, 2014 at 12:38 PM, Yin Huai <huaiyin.thu@gmail.com> wrote:
>> > Yeah, seems we need to pass the attempt id to executors through
>> > TaskDescription. I have created
>> > https://issues.apache.org/jira/browse/SPARK-4014.
>> >
>> > On Mon, Oct 20, 2014 at 1:57 PM, Reynold Xin <rxin@databricks.com>
>> wrote:
>> >
>> >> I also ran into this earlier. It is a bug. Do you want to file a jira?
>> >>
>> >> I think part of the problem is that we don't actually have the attempt
>> id
>> >> on the executors. If we do, that's great. If not, we'd need to
>> propagate
>> >> that over.
>> >>
>> >> On Mon, Oct 20, 2014 at 7:17 AM, Yin Huai <huaiyin.thu@gmail.com>
>> wrote:
>> >>
>> >>> Hello,
>> >>>
>> >>> Is there any way to get the attempt number in a closure? Seems
>> >>> TaskContext.attemptId actually returns the taskId of a task (see this
>> >>> <
>> >>>
>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L181
>> >>> >
>> >>>  and this
>> >>> <
>> >>>
>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/Task.scala#L47
>> >>> >).
>> >>> It looks like a bug.
>> >>>
>> >>> Thanks,
>> >>>
>> >>> Yin
>> >>>
>> >>
>> >>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>

--089e0112cec23c79f30505e0d45e--

From dev-return-9885-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 20:57:46 2014
Return-Path: <dev-return-9885-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 692721750A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 20:57:46 +0000 (UTC)
Received: (qmail 30969 invoked by uid 500); 20 Oct 2014 20:57:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30901 invoked by uid 500); 20 Oct 2014 20:57:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30890 invoked by uid 99); 20 Oct 2014 20:57:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 20:57:44 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.192.41] (HELO mail-qg0-f41.google.com) (209.85.192.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 20:57:19 +0000
Received: by mail-qg0-f41.google.com with SMTP id a108so4121056qge.0
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 13:57:17 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=5mPRd/hxmVXgNHsxVDbBdaYZNEDBJTNM5mUJVgWHCxw=;
        b=a1Auwrysz9cefNvgkWqRaz1BC2v51GIuxyBT3Ma97hXAFTwt17GNiD2gtg5srx6cDs
         nbBi4zNCcqLvHJipikKMUuQEi3BHMk4MmENLonPamEQFHuRvpiollONo+UKOkPAVDNpV
         qI5bKHMeHhCoaHdc6TxdzBob+HcteZkG5ER0CC6XcjfLVD1mpK3PGm7MdoOq3hCdYsTU
         oxb7wMRB5K0fNSyU8c87yZ9D5dqnw1CvNpOnC/GZ2LIz6XF+PZPBCxNmjrF+xWKNhoQZ
         YxWHG3dmwUzp41BhaEykOWwtBypAjUpF3U22bjqT1GrJQQ6Bk7btpVH9Y4n613ZegWCs
         r8RA==
X-Gm-Message-State: ALoCoQmZYpGpkYjfvEeCvgoEnYb/xU4zMxXdm2kNUJZmC1ysYcJ2AZzxBGeri2hbTquz6D1cvm8O
X-Received: by 10.140.100.242 with SMTP id s105mr25612773qge.44.1413838636854;
 Mon, 20 Oct 2014 13:57:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.47.8 with HTTP; Mon, 20 Oct 2014 13:56:56 -0700 (PDT)
In-Reply-To: <CAKJXNjEdZ8wZyEVyJpzH5D4sg914XpGEHhD6WSVfyr5U1Fv2hw@mail.gmail.com>
References: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
 <CAPh_B=ZbfXMA21EiTiRx1bV4_t_+GuK9OoCKg493M_Kr72Y2WQ@mail.gmail.com>
 <CAOSFW132zn483rBFLiC1W1ydiKrfShBo1Qs4m-B-7ffiJCuwOQ@mail.gmail.com>
 <CABPQxstu+qLf=42biCOVTYNritcNcCQ2rxnQEafL8vRKJ6+44A@mail.gmail.com>
 <CAKJXNjFFUsQYoz40z=rfgJJmmaRegX=w+N7B1DN3MUco6uEaww@mail.gmail.com> <CAKJXNjEdZ8wZyEVyJpzH5D4sg914XpGEHhD6WSVfyr5U1Fv2hw@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 20 Oct 2014 13:56:56 -0700
Message-ID: <CAPh_B=a5cGZuwGhSkV3idVB6u=xwZ8fkaQAmakq4sX+OLGLM0g@mail.gmail.com>
Subject: Re: Get attempt number in a closure
To: Kay Ousterhout <keo@eecs.berkeley.edu>
Cc: Patrick Wendell <pwendell@gmail.com>, Yin Huai <huaiyin.thu@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c16798b864b60505e0f5b7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c16798b864b60505e0f5b7
Content-Type: text/plain; charset=UTF-8

Yes, as I understand it this is for (2).

Imagine a use case in which I want to save some output. In order to make
this atomic, the program uses part_[index]_[attempt].dat, and once it
finishes writing, it renames this to part_[index].dat.

Right now [attempt] is just the TID, which could show up like (assuming
this is not the first stage):

part_0_1000
part_1_1001
part_0_1002 (some retry)
...

This is fairly confusing. The natural thing to expect is

part_0_0
part_1_0
part_0_1
...



On Mon, Oct 20, 2014 at 1:47 PM, Kay Ousterhout <keo@eecs.berkeley.edu>
wrote:

> Sorry to clarify, there are two issues here:
>
> (1) attemptId has different meanings in the codebase
> (2) we currently don't propagate the 0-based per-task attempt identifier
> to the executors.
>
> (1) should definitely be fixed.  It sounds like Yin's original email was
> requesting that we add (2).
>
> On Mon, Oct 20, 2014 at 1:45 PM, Kay Ousterhout <keo@eecs.berkeley.edu>
> wrote:
>
>> Are you guys sure this is a bug?  In the task scheduler, we keep two
>> identifiers for each task: the "index", which uniquely identifiers the
>> computation+partition, and the "taskId" which is unique across all tasks
>> for that Spark context (See
>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/TaskSetManager.scala#L439).
>> If multiple attempts of one task are run, they will have the same index,
>> but different taskIds.  Historically, we have used "taskId" and
>> "taskAttemptId" interchangeably (which arose from naming in Mesos, which
>> uses similar naming).
>>
>> This was complicated when Mr. Xin added the "attempt" field to TaskInfo,
>> which we show in the UI.  This field uniquely identifies attempts for a
>> particular task, but is not unique across different task indexes (it always
>> starts at 0 for a given task).  I'm guessing the right fix is to rename
>> Task.taskAttemptId to Task.taskId to resolve this inconsistency -- does
>> that sound right to you Reynold?
>>
>> -Kay
>>
>> On Mon, Oct 20, 2014 at 1:29 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>>> There is a deeper issue here which is AFAIK we don't even store a
>>> notion of attempt inside of Spark, we just use a new taskId with the
>>> same index.
>>>
>>> On Mon, Oct 20, 2014 at 12:38 PM, Yin Huai <huaiyin.thu@gmail.com>
>>> wrote:
>>> > Yeah, seems we need to pass the attempt id to executors through
>>> > TaskDescription. I have created
>>> > https://issues.apache.org/jira/browse/SPARK-4014.
>>> >
>>> > On Mon, Oct 20, 2014 at 1:57 PM, Reynold Xin <rxin@databricks.com>
>>> wrote:
>>> >
>>> >> I also ran into this earlier. It is a bug. Do you want to file a jira?
>>> >>
>>> >> I think part of the problem is that we don't actually have the
>>> attempt id
>>> >> on the executors. If we do, that's great. If not, we'd need to
>>> propagate
>>> >> that over.
>>> >>
>>> >> On Mon, Oct 20, 2014 at 7:17 AM, Yin Huai <huaiyin.thu@gmail.com>
>>> wrote:
>>> >>
>>> >>> Hello,
>>> >>>
>>> >>> Is there any way to get the attempt number in a closure? Seems
>>> >>> TaskContext.attemptId actually returns the taskId of a task (see this
>>> >>> <
>>> >>>
>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L181
>>> >>> >
>>> >>>  and this
>>> >>> <
>>> >>>
>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/Task.scala#L47
>>> >>> >).
>>> >>> It looks like a bug.
>>> >>>
>>> >>> Thanks,
>>> >>>
>>> >>> Yin
>>> >>>
>>> >>
>>> >>
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>
>>
>

--001a11c16798b864b60505e0f5b7--

From dev-return-9886-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 21:14:43 2014
Return-Path: <dev-return-9886-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7FE9A17588
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 21:14:43 +0000 (UTC)
Received: (qmail 68524 invoked by uid 500); 20 Oct 2014 21:14:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68454 invoked by uid 500); 20 Oct 2014 21:14:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68438 invoked by uid 99); 20 Oct 2014 21:14:41 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 21:14:41 +0000
X-ASF-Spam-Status: No, hits=3.1 required=10.0
	tests=HK_RANDOM_ENVFROM,HK_RANDOM_FROM,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of huaiyin.thu@gmail.com designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 21:14:16 +0000
Received: by mail-la0-f42.google.com with SMTP id gf13so5253924lab.15
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 14:14:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=EeOuVTJsIKcymV+vm3qrc2JWpS0C5NJ19BC/bJMmmk4=;
        b=NpH3QfL0wqn19oUn4dpQqR6XrR9w7HcnVkgGqoWv+MV2YBSBtOSyb+gNmqfgPBuZ0Y
         9svfABaHJtXuQrMKXUMsYbywXhDAb7L0mcjR17XgK/S4dl2g9wtZha0Ewnkr/BNJwz2l
         g9leZlVpaapokgjB1pYGm9HOmZq3UxUGYw7aEC96Q+KA6+mKYRaK+gB+MY7Nzoz4cqiF
         6Hh1pOrvuSBlEj40On6D0wWlKR5ISzrhCBBKRtvI/TvuuQ/ZeWPBt8aePNpI/YZjF3KX
         bUVrMxC14jeeOAhM12tAz0UvoZ+Zy5UW562JXPLVgyIGP/qIFuAidUQ6PlKi8puk7njU
         Df9w==
X-Received: by 10.112.198.226 with SMTP id jf2mr11834978lbc.84.1413839655345;
 Mon, 20 Oct 2014 14:14:15 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.56.75 with HTTP; Mon, 20 Oct 2014 14:13:55 -0700 (PDT)
In-Reply-To: <CAPh_B=a5cGZuwGhSkV3idVB6u=xwZ8fkaQAmakq4sX+OLGLM0g@mail.gmail.com>
References: <CAOSFW11szJfgbo2SuacwVFkOaA12EkKNqtdHi5EHXU1AcKMbxw@mail.gmail.com>
 <CAPh_B=ZbfXMA21EiTiRx1bV4_t_+GuK9OoCKg493M_Kr72Y2WQ@mail.gmail.com>
 <CAOSFW132zn483rBFLiC1W1ydiKrfShBo1Qs4m-B-7ffiJCuwOQ@mail.gmail.com>
 <CABPQxstu+qLf=42biCOVTYNritcNcCQ2rxnQEafL8vRKJ6+44A@mail.gmail.com>
 <CAKJXNjFFUsQYoz40z=rfgJJmmaRegX=w+N7B1DN3MUco6uEaww@mail.gmail.com>
 <CAKJXNjEdZ8wZyEVyJpzH5D4sg914XpGEHhD6WSVfyr5U1Fv2hw@mail.gmail.com> <CAPh_B=a5cGZuwGhSkV3idVB6u=xwZ8fkaQAmakq4sX+OLGLM0g@mail.gmail.com>
From: Yin Huai <huaiyin.thu@gmail.com>
Date: Mon, 20 Oct 2014 17:13:55 -0400
Message-ID: <CAOSFW13j+t3XsWRMxTKJY5gF=foY0Dokhm2j3OUrnrY_4NAfYw@mail.gmail.com>
Subject: Re: Get attempt number in a closure
To: Reynold Xin <rxin@databricks.com>
Cc: Kay Ousterhout <keo@eecs.berkeley.edu>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c341ca6d26a50505e132fd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c341ca6d26a50505e132fd
Content-Type: text/plain; charset=UTF-8

Yes, it is for (2). I was confused because the doc of TaskContext.attemptId
(release 1.1)
<http://spark.apache.org/docs/1.1.0/api/scala/index.html#org.apache.spark.TaskContext>
is
"the number of attempts to execute this task". Seems the per-task attempt
id used to populate "attempt" field in the UI is maintained by
TaskSetManager and its value is assigned in resourceOffer.

On Mon, Oct 20, 2014 at 4:56 PM, Reynold Xin <rxin@databricks.com> wrote:

> Yes, as I understand it this is for (2).
>
> Imagine a use case in which I want to save some output. In order to make
> this atomic, the program uses part_[index]_[attempt].dat, and once it
> finishes writing, it renames this to part_[index].dat.
>
> Right now [attempt] is just the TID, which could show up like (assuming
> this is not the first stage):
>
> part_0_1000
> part_1_1001
> part_0_1002 (some retry)
> ...
>
> This is fairly confusing. The natural thing to expect is
>
> part_0_0
> part_1_0
> part_0_1
> ...
>
>
>
> On Mon, Oct 20, 2014 at 1:47 PM, Kay Ousterhout <keo@eecs.berkeley.edu>
> wrote:
>
>> Sorry to clarify, there are two issues here:
>>
>> (1) attemptId has different meanings in the codebase
>> (2) we currently don't propagate the 0-based per-task attempt identifier
>> to the executors.
>>
>> (1) should definitely be fixed.  It sounds like Yin's original email was
>> requesting that we add (2).
>>
>> On Mon, Oct 20, 2014 at 1:45 PM, Kay Ousterhout <keo@eecs.berkeley.edu>
>> wrote:
>>
>>> Are you guys sure this is a bug?  In the task scheduler, we keep two
>>> identifiers for each task: the "index", which uniquely identifiers the
>>> computation+partition, and the "taskId" which is unique across all tasks
>>> for that Spark context (See
>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/TaskSetManager.scala#L439).
>>> If multiple attempts of one task are run, they will have the same index,
>>> but different taskIds.  Historically, we have used "taskId" and
>>> "taskAttemptId" interchangeably (which arose from naming in Mesos, which
>>> uses similar naming).
>>>
>>> This was complicated when Mr. Xin added the "attempt" field to TaskInfo,
>>> which we show in the UI.  This field uniquely identifies attempts for a
>>> particular task, but is not unique across different task indexes (it always
>>> starts at 0 for a given task).  I'm guessing the right fix is to rename
>>> Task.taskAttemptId to Task.taskId to resolve this inconsistency -- does
>>> that sound right to you Reynold?
>>>
>>> -Kay
>>>
>>> On Mon, Oct 20, 2014 at 1:29 PM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>
>>>> There is a deeper issue here which is AFAIK we don't even store a
>>>> notion of attempt inside of Spark, we just use a new taskId with the
>>>> same index.
>>>>
>>>> On Mon, Oct 20, 2014 at 12:38 PM, Yin Huai <huaiyin.thu@gmail.com>
>>>> wrote:
>>>> > Yeah, seems we need to pass the attempt id to executors through
>>>> > TaskDescription. I have created
>>>> > https://issues.apache.org/jira/browse/SPARK-4014.
>>>> >
>>>> > On Mon, Oct 20, 2014 at 1:57 PM, Reynold Xin <rxin@databricks.com>
>>>> wrote:
>>>> >
>>>> >> I also ran into this earlier. It is a bug. Do you want to file a
>>>> jira?
>>>> >>
>>>> >> I think part of the problem is that we don't actually have the
>>>> attempt id
>>>> >> on the executors. If we do, that's great. If not, we'd need to
>>>> propagate
>>>> >> that over.
>>>> >>
>>>> >> On Mon, Oct 20, 2014 at 7:17 AM, Yin Huai <huaiyin.thu@gmail.com>
>>>> wrote:
>>>> >>
>>>> >>> Hello,
>>>> >>>
>>>> >>> Is there any way to get the attempt number in a closure? Seems
>>>> >>> TaskContext.attemptId actually returns the taskId of a task (see
>>>> this
>>>> >>> <
>>>> >>>
>>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L181
>>>> >>> >
>>>> >>>  and this
>>>> >>> <
>>>> >>>
>>>> https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/Task.scala#L47
>>>> >>> >).
>>>> >>> It looks like a bug.
>>>> >>>
>>>> >>> Thanks,
>>>> >>>
>>>> >>> Yin
>>>> >>>
>>>> >>
>>>> >>
>>>>
>>>> ---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>
>>>>
>>>
>>
>

--001a11c341ca6d26a50505e132fd--

From dev-return-9887-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 22:52:10 2014
Return-Path: <dev-return-9887-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 179C71785C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 22:52:10 +0000 (UTC)
Received: (qmail 65100 invoked by uid 500); 20 Oct 2014 22:52:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 65039 invoked by uid 500); 20 Oct 2014 22:52:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 65027 invoked by uid 99); 20 Oct 2014 22:52:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 22:52:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.174 as permitted sender)
Received: from [209.85.223.174] (HELO mail-ie0-f174.google.com) (209.85.223.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 22:52:04 +0000
Received: by mail-ie0-f174.google.com with SMTP id tr6so27293ieb.19
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 15:51:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=rcKTbxOxzL/7mo2XdyheUBYpspWGqYjLuh11mzfdOjc=;
        b=GNOnpWBxdAzMYMpdPSTqGjZLDG61BEIKWIJg0uTlp1bN4Tw2VIIJt+s9CPylUsHZe7
         WPYefJZDKuf9SdatURIC77Ogmnhu6M2WCafkflLE6jxu7MFdoVmqTJgAn3LVesxdAplg
         bce8dTjWWy/LQY/T8mNFrtmaH5qmsCsaWSWgAMpjCE7cqO1rkPyHuWuuOXZT6R4Gmh7a
         +Nc4MnV8EUXPXP/5K9N3tAw/GmikBGQRl3UptMq1iwJM6IK66ITGdSRYzTcn7puLBTht
         KNLGlGNtS7+FI0TRqUJQiVhkGpqA4mod6i4w9ID5mSmFrBDCb9eEDI75oMuXQnnUit3a
         Ig5Q==
MIME-Version: 1.0
X-Received: by 10.50.3.36 with SMTP id 4mr21961639igz.20.1413845504370; Mon,
 20 Oct 2014 15:51:44 -0700 (PDT)
Received: by 10.107.11.38 with HTTP; Mon, 20 Oct 2014 15:51:44 -0700 (PDT)
Date: Mon, 20 Oct 2014 18:51:44 -0400
Message-ID: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
Subject: something wrong with Jenkins or something untested merged?
From: Nan Zhu <zhunanmcgill@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0122a4800e2f860505e28fb1
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0122a4800e2f860505e28fb1
Content-Type: text/plain; charset=UTF-8

Hi,

I just submitted a patch https://github.com/apache/spark/pull/2864/files
with one line change

but the Jenkins told me it's failed to compile on the unrelated files?

https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console


Best,

Nan

--089e0122a4800e2f860505e28fb1--

From dev-return-9888-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 23:45:02 2014
Return-Path: <dev-return-9888-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 754EA17ACA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 23:45:02 +0000 (UTC)
Received: (qmail 87093 invoked by uid 500); 20 Oct 2014 23:45:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 87017 invoked by uid 500); 20 Oct 2014 23:45:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 86990 invoked by uid 99); 20 Oct 2014 23:45:01 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 23:45:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.42 as permitted sender)
Received: from [74.125.82.42] (HELO mail-wg0-f42.google.com) (74.125.82.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 23:44:56 +0000
Received: by mail-wg0-f42.google.com with SMTP id z12so90570wgg.1
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 16:44:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=ERqowqo5IPbSf5fvi6M4a+VgSLDX8uKZL1vSLkYRwJM=;
        b=HB/BZ8hNDL4dMHesHDv2gUdLJzlwcxIKERFddMsxVtR6/KYhs7Yd+40ijT4VnTVabo
         hvAqIrq4GY1dKqTQdTxi5pG8YjeXdN6Pz2Wvm/bu+awvgv0bU/um5M183hQoaDjYoX4D
         338rmYJ+VCL1OFN5cVq7o88GZpwQX6F8+gOFjg/nlhmmYcbw1akDZpU34ulcBgRlIIEs
         AeDNYMxZr8LCREntumV5LynnTrwPsZWKeK8Kltw+wGHF+m28TirAkgpH2hGKzCNete/A
         HVhxDX54FTL/Ygfubv0JTe61rmt0dkjVKxutkzr8NKVRzDJ0cDBvkMr5smrGVOFW6Dn8
         VMGg==
X-Received: by 10.181.27.161 with SMTP id jh1mr23570358wid.75.1413848675654;
 Mon, 20 Oct 2014 16:44:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 20 Oct 2014 16:43:55 -0700 (PDT)
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 20 Oct 2014 19:43:55 -0400
Message-ID: <CAOhmDzerXLg1x8RWY3rDOwiZ9TmwH7+x8YDOGDA4LZDGBcsNkw@mail.gmail.com>
Subject: Building and Running Spark on OS X
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1136cbe01423240505e34c66
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1136cbe01423240505e34c66
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

If one were to put together a short but comprehensive guide to setting up
Spark to run locally on OS X, would it look like this?

# Install Maven. On OS X, we suggest using Homebrew.
brew install maven
# Set some important Java and Maven environment variables.export
JAVA_HOME=3D$(/usr/libexec/java_home)export MAVEN_OPTS=3D"-Xmx512m
-XX:MaxPermSize=3D128m"
# Go to where you downloaded the Spark source.cd ./spark
# Build, configure slaves, and startup Spark.
mvn -DskipTests clean packageecho "localhost" > ./conf/slaves
./sbin/start-all.sh
# Rock 'n' Roll.
./bin/pyspark
# Cleanup when you're done.
./sbin/stop-all.sh

Nick
=E2=80=8B

--001a1136cbe01423240505e34c66--

From dev-return-9889-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 23:57:01 2014
Return-Path: <dev-return-9889-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B617F17B33
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 23:57:01 +0000 (UTC)
Received: (qmail 17488 invoked by uid 500); 20 Oct 2014 23:57:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17421 invoked by uid 500); 20 Oct 2014 23:57:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17018 invoked by uid 99); 20 Oct 2014 23:57:00 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 23:57:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of yuzhihong@gmail.com designates 209.85.213.41 as permitted sender)
Received: from [209.85.213.41] (HELO mail-yh0-f41.google.com) (209.85.213.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 23:56:35 +0000
Received: by mail-yh0-f41.google.com with SMTP id i57so159194yha.28
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 16:56:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=N06NPzUPyXvsiJ1h3Eeuy6j3C+jg0RQ67zm82c892AY=;
        b=enR+e6uRg/9igk3g6cUmK+BwdVxF95bJClpFCK+KT8BlrjMyAt3nxp0ey5Vj68JdAn
         AnDcyKHGSs/h6Lm95JWn1pCXNb0E8JPWt3RJExFzuR1dW/nV/8q2EQW0X7/t+FfWY+bm
         u+Kk38Qly3LRxqigjOqETvpv7nBKkEt/8TKobs+KrNPp65iqEheQiBchqmE4QBHALeKM
         85nRlEDcaUapneri2aUCsIx7gY6by6Pt1FCDbz4uIeJpIkgBdIuV9EU8ZTThaHlxIQXl
         /1kaNfRs7lvxrDfqP98nOBbeqDHoJqQ7cL46Phy4DZ1eGeVxwcQ2D2fCpl/G7cl1OW6s
         QNkQ==
MIME-Version: 1.0
X-Received: by 10.236.210.108 with SMTP id t72mr9597122yho.116.1413849394355;
 Mon, 20 Oct 2014 16:56:34 -0700 (PDT)
Received: by 10.170.180.7 with HTTP; Mon, 20 Oct 2014 16:56:34 -0700 (PDT)
In-Reply-To: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
Date: Mon, 20 Oct 2014 16:56:34 -0700
Message-ID: <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
From: Ted Yu <yuzhihong@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160a414eaa68d0505e37607
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160a414eaa68d0505e37607
Content-Type: text/plain; charset=UTF-8

I performed build on latest master branch but didn't get compilation error.

FYI

On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

> Hi,
>
> I just submitted a patch https://github.com/apache/spark/pull/2864/files
> with one line change
>
> but the Jenkins told me it's failed to compile on the unrelated files?
>
>
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>
>
> Best,
>
> Nan
>

--089e0160a414eaa68d0505e37607--

From dev-return-9890-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 20 23:58:31 2014
Return-Path: <dev-return-9890-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3634417B46
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 20 Oct 2014 23:58:31 +0000 (UTC)
Received: (qmail 22380 invoked by uid 500); 20 Oct 2014 23:58:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22304 invoked by uid 500); 20 Oct 2014 23:58:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22286 invoked by uid 99); 20 Oct 2014 23:58:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 23:58:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.216.178 as permitted sender)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 20 Oct 2014 23:58:04 +0000
Received: by mail-qc0-f178.google.com with SMTP id c9so77814qcz.37
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 16:58:03 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=BNVmLdT8hRU5COQZ0BL0y2vIWFn5q8qOqHzVONpJT9g=;
        b=KKCJ807b8arsnJp3lKPzfjyDPBoFqKDFn2VRacLT+AM4mFtNx5Q6ugwagywKOlYXdT
         VvxBz0IL+pYK7mRLPWGxzGV/aqhwxIOm8Vzz93bghc8LAy452T9jKsRLWSwzQJjdowab
         WEUYrCmSpleA0O2q71N0fjZltGkxloK1pjZ0pw6sD05ndA/V/TeVP4tHTJ1QP2j7c+FX
         lPJh5QkrPE6nJ5MWqJnQkf7pDdLfxQvWQOb3nbnSeuTYOxQb6hkSBCHSkm9iMbaad3Cl
         9NpP7U2FTfcJM0H9PfPiTribvILGY0Mkhc85AOjwfTbAJKIR79NpqbC1Kzutg8rwUn6U
         V+qQ==
X-Received: by 10.140.109.53 with SMTP id k50mr38838617qgf.83.1413849482918;
        Mon, 20 Oct 2014 16:58:02 -0700 (PDT)
Received: from [192.168.2.13] (bas3-montreal42-1167938673.dsl.bell.ca. [69.157.84.113])
        by mx.google.com with ESMTPSA id j1sm9247078qao.38.2014.10.20.16.58.02
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Mon, 20 Oct 2014 16:58:02 -0700 (PDT)
Date: Mon, 20 Oct 2014 20:11:55 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Ted Yu <yuzhihong@gmail.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <AFBB584B386748008FF81312D2A24C39@gmail.com>
In-Reply-To: <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5445a4cb_5bd062c2_221"
X-Virus-Checked: Checked by ClamAV on apache.org

--5445a4cb_5bd062c2_221
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline

yes, I can compile locally, too 

but it seems that Jenkins is not happy now...https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/ 

All failed to compile

Best, 

-- 
Nan Zhu


On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:

> I performed build on latest master branch but didn't get compilation error.
> 
> FYI
> 
> On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com (mailto:zhunanmcgill@gmail.com)> wrote:
> > Hi,
> > 
> > I just submitted a patch https://github.com/apache/spark/pull/2864/files
> > with one line change
> > 
> > but the Jenkins told me it's failed to compile on the unrelated files?
> > 
> > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
> > 
> > 
> > Best,
> > 
> > Nan
> 


--5445a4cb_5bd062c2_221--


From dev-return-9891-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:01:10 2014
Return-Path: <dev-return-9891-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3AD7817B76
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:01:10 +0000 (UTC)
Received: (qmail 32165 invoked by uid 500); 21 Oct 2014 00:01:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32094 invoked by uid 500); 21 Oct 2014 00:01:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32081 invoked by uid 99); 21 Oct 2014 00:01:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:01:08 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:01:03 +0000
Received: by mail-qc0-f178.google.com with SMTP id c9so85948qcz.23
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:00:41 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=rI2cyUarlJOahKEBRCkjvqnYWjhc3kDJMg4Nbstn1Yo=;
        b=VeeqZngxcQixpnzBkaYZAL1lFJOkHAw7QWkFiAB9zeiH7yQi/zNIim5tIP0zMiggxn
         NYspjkiymPclHHL83VawXM3o/fb8qUB80glVlIKlid71h5yKqA4WaFIkzwjrnaz+VF4l
         jrs88Fjw29yd/dUE4scyBQAD6PNg2Vgqn44TrLMtHFeqRQAYyZXH5A+9vYxv5cUI8OXf
         bq2VOFUPE/Hu4pRsc8FAwBl9fI+0CrHmTHjzRtxNVDMuCTQiZw7K4dh547THB+rHwfAM
         39pInaQhxrsCSqADO4avWZyqmsGokaTpNmF26QNiaobL0LKB9o7O/FTHGbDfWK6VnAR2
         aoYw==
X-Gm-Message-State: ALoCoQm2gwtPEN962fu6FaFRX3/wr7/0D/Gn/IRn1imehwmNrkzxUbatw2mr101j53Q7FG/eaKW4
X-Received: by 10.140.102.169 with SMTP id w38mr15078228qge.95.1413849641628;
 Mon, 20 Oct 2014 17:00:41 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.47.8 with HTTP; Mon, 20 Oct 2014 17:00:21 -0700 (PDT)
In-Reply-To: <CAOhmDzerXLg1x8RWY3rDOwiZ9TmwH7+x8YDOGDA4LZDGBcsNkw@mail.gmail.com>
References: <CAOhmDzerXLg1x8RWY3rDOwiZ9TmwH7+x8YDOGDA4LZDGBcsNkw@mail.gmail.com>
From: Reynold Xin <rxin@databricks.com>
Date: Mon, 20 Oct 2014 17:00:21 -0700
Message-ID: <CAPh_B=bomHWCCdkaNnEJFQ348_h0kVSHWk+EOob+P1zVxfrxkQ@mail.gmail.com>
Subject: Re: Building and Running Spark on OS X
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c16c78a7eaa70505e3850d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c16c78a7eaa70505e3850d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I usually use SBT on Mac and that one doesn't require any setup ...


On Mon, Oct 20, 2014 at 4:43 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> If one were to put together a short but comprehensive guide to setting up
> Spark to run locally on OS X, would it look like this?
>
> # Install Maven. On OS X, we suggest using Homebrew.
> brew install maven
> # Set some important Java and Maven environment variables.export
> JAVA_HOME=3D$(/usr/libexec/java_home)export MAVEN_OPTS=3D"-Xmx512m
> -XX:MaxPermSize=3D128m"
> # Go to where you downloaded the Spark source.cd ./spark
> # Build, configure slaves, and startup Spark.
> mvn -DskipTests clean packageecho "localhost" > ./conf/slaves
> ./sbin/start-all.sh
> # Rock 'n' Roll.
> ./bin/pyspark
> # Cleanup when you're done.
> ./sbin/stop-all.sh
>
> Nick
> =E2=80=8B
>

--001a11c16c78a7eaa70505e3850d--

From dev-return-9892-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:05:12 2014
Return-Path: <dev-return-9892-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5977E17B96
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:05:12 +0000 (UTC)
Received: (qmail 41574 invoked by uid 500); 21 Oct 2014 00:05:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 41504 invoked by uid 500); 21 Oct 2014 00:05:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 41479 invoked by uid 99); 21 Oct 2014 00:05:10 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:05:10 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.50 as permitted sender)
Received: from [74.125.82.50] (HELO mail-wg0-f50.google.com) (74.125.82.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:04:46 +0000
Received: by mail-wg0-f50.google.com with SMTP id a1so93064wgh.33
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:04:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=FhNxnn1v1b0s497JjoLPWi7hTjLLN639TTeQ1swheds=;
        b=OBJHqtVpgCVus0DCgQEwre930Ol7jF2ohn5FQD7FURHfHo+kLrU9ZRrOmTVfshFvRp
         vr1CNifzMQWXs96HhcZhh9sAtabxUnGBQAAgnSrWioCbcjkd6/y3E1zskvog7HK5jZ/v
         iUXNCm32+2+uAuGmVY4VCq0HYfgwjqHqkXhM+q2dbF5OZwCkyI6q9jGdEiAJDFpmqSZE
         +Y2YGt/52lXx+UwQPBXhnOvhkRHdQNtnyzftxq4Mr1FGck3uaF6hzs1Ty021KCa/cdpH
         KB68uZwndsRTQavbX8pDGRlKLyPqvSd3ShbdNThjPJAamZCNjwHwsIWICc9VaDJ5aXwC
         csOQ==
X-Received: by 10.180.11.227 with SMTP id t3mr24309898wib.45.1413849885417;
 Mon, 20 Oct 2014 17:04:45 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 20 Oct 2014 17:04:05 -0700 (PDT)
In-Reply-To: <CAPh_B=bomHWCCdkaNnEJFQ348_h0kVSHWk+EOob+P1zVxfrxkQ@mail.gmail.com>
References: <CAOhmDzerXLg1x8RWY3rDOwiZ9TmwH7+x8YDOGDA4LZDGBcsNkw@mail.gmail.com>
 <CAPh_B=bomHWCCdkaNnEJFQ348_h0kVSHWk+EOob+P1zVxfrxkQ@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 20 Oct 2014 20:04:05 -0400
Message-ID: <CAOhmDzeUNhuCr41B7KRPTEwMn4cga_2TNpZrWqQB8REekokxzg@mail.gmail.com>
Subject: Re: Building and Running Spark on OS X
To: Reynold Xin <rxin@databricks.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2400c2fa6d70505e394b9
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2400c2fa6d70505e394b9
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Yeah, I would use sbt too, but I thought if I wanted to publish a little
reference page for OS X users then I probably should use the =E2=80=9Coffic=
ial
<https://github.com/apache/spark#building-spark>=E2=80=9C build instruction=
s.

Nick
=E2=80=8B

On Mon, Oct 20, 2014 at 8:00 PM, Reynold Xin <rxin@databricks.com> wrote:

> I usually use SBT on Mac and that one doesn't require any setup ...
>
>
> On Mon, Oct 20, 2014 at 4:43 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>
>> If one were to put together a short but comprehensive guide to setting u=
p
>> Spark to run locally on OS X, would it look like this?
>>
>> # Install Maven. On OS X, we suggest using Homebrew.
>> brew install maven
>> # Set some important Java and Maven environment variables.export
>> JAVA_HOME=3D$(/usr/libexec/java_home)export MAVEN_OPTS=3D"-Xmx512m
>> -XX:MaxPermSize=3D128m"
>> # Go to where you downloaded the Spark source.cd ./spark
>> # Build, configure slaves, and startup Spark.
>> mvn -DskipTests clean packageecho "localhost" > ./conf/slaves
>> ./sbin/start-all.sh
>> # Rock 'n' Roll.
>> ./bin/pyspark
>> # Cleanup when you're done.
>> ./sbin/stop-all.sh
>>
>> Nick
>> =E2=80=8B
>>
>
>

--001a11c2400c2fa6d70505e394b9--

From dev-return-9893-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:08:20 2014
Return-Path: <dev-return-9893-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F3F5917BBD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:08:19 +0000 (UTC)
Received: (qmail 53748 invoked by uid 500); 21 Oct 2014 00:08:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53676 invoked by uid 500); 21 Oct 2014 00:08:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53659 invoked by uid 99); 21 Oct 2014 00:08:18 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:08:18 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of denny.g.lee@gmail.com designates 209.85.192.171 as permitted sender)
Received: from [209.85.192.171] (HELO mail-pd0-f171.google.com) (209.85.192.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:08:14 +0000
Received: by mail-pd0-f171.google.com with SMTP id ft15so136981pdb.2
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:07:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=nIxK4rsLdwO/nUl12GmjPj6sL1bqDDO64VBdpI6ViJE=;
        b=vCSLqmcYoeWWz+o8ZmsphJdhqYY+rHNGCbh4O3SBgshqNmjAEGsRr4kYun+XCZKI5v
         t5b3BmEDQULyGPz6DY1ivFCVWBwvU0GQoz1xu8tayoNjwISxPCox59SdYzcymeaA7GjY
         EgoYoWZJxlYEtrEv4hltupWqODexlyVsQi56R7zcU2+SiROrj7Gh0MsWZtukUWryhriF
         T0+t5gb6LPNRStRZhK6FtkKcGKAFa5H75qmUjG6QcEI+Sj6/bUg/PNiqkIM20JVvoraN
         Jar1T+UnannRagMr/UlZfTXpovoJcyN06Lb/q9+pKXPcGht+5F+4zzLR0qjtgPpjOUzw
         rMOw==
X-Received: by 10.70.10.195 with SMTP id k3mr16059624pdb.41.1413850074394;
        Mon, 20 Oct 2014 17:07:54 -0700 (PDT)
Received: from ?IPv6:2601:8:9880:5e8:95ab:e930:c03b:f4d9? ([2601:8:9880:5e8:95ab:e930:c03b:f4d9])
        by mx.google.com with ESMTPSA id x15sm10094379pbt.91.2014.10.20.17.07.53
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 20 Oct 2014 17:07:53 -0700 (PDT)
Content-Type: text/plain;
	charset=utf-8
Mime-Version: 1.0 (1.0)
Subject: Re: Building and Running Spark on OS X
From: Denny Lee <denny.g.lee@gmail.com>
X-Mailer: iPhone Mail (12B411)
In-Reply-To: <CAPh_B=bomHWCCdkaNnEJFQ348_h0kVSHWk+EOob+P1zVxfrxkQ@mail.gmail.com>
Date: Mon, 20 Oct 2014 17:07:52 -0700
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>,
 dev <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <BC6307A6-01C3-4B7C-A426-E28C6CA48FC8@gmail.com>
References: <CAOhmDzerXLg1x8RWY3rDOwiZ9TmwH7+x8YDOGDA4LZDGBcsNkw@mail.gmail.com> <CAPh_B=bomHWCCdkaNnEJFQ348_h0kVSHWk+EOob+P1zVxfrxkQ@mail.gmail.com>
To: Reynold Xin <rxin@databricks.com>
X-Virus-Checked: Checked by ClamAV on apache.org

+1=20
huge fan of sbt with OSX


> On Oct 20, 2014, at 17:00, Reynold Xin <rxin@databricks.com> wrote:
>=20
> I usually use SBT on Mac and that one doesn't require any setup ...
>=20
>=20
> On Mon, Oct 20, 2014 at 4:43 PM, Nicholas Chammas <
> nicholas.chammas@gmail.com> wrote:
>=20
>> If one were to put together a short but comprehensive guide to setting up=

>> Spark to run locally on OS X, would it look like this?
>>=20
>> # Install Maven. On OS X, we suggest using Homebrew.
>> brew install maven
>> # Set some important Java and Maven environment variables.export
>> JAVA_HOME=3D$(/usr/libexec/java_home)export MAVEN_OPTS=3D"-Xmx512m
>> -XX:MaxPermSize=3D128m"
>> # Go to where you downloaded the Spark source.cd ./spark
>> # Build, configure slaves, and startup Spark.
>> mvn -DskipTests clean packageecho "localhost" > ./conf/slaves
>> ./sbin/start-all.sh
>> # Rock 'n' Roll.
>> ./bin/pyspark
>> # Cleanup when you're done.
>> ./sbin/stop-all.sh
>>=20
>> Nick
>> =E2=80=8B
>>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9894-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:09:24 2014
Return-Path: <dev-return-9894-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3922317BCE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:09:24 +0000 (UTC)
Received: (qmail 57674 invoked by uid 500); 21 Oct 2014 00:09:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57603 invoked by uid 500); 21 Oct 2014 00:09:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57583 invoked by uid 99); 21 Oct 2014 00:09:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:09:23 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.177 as permitted sender)
Received: from [209.85.217.177] (HELO mail-lb0-f177.google.com) (209.85.217.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:08:57 +0000
Received: by mail-lb0-f177.google.com with SMTP id w7so89205lbi.8
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:08:56 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=q4jya7hHBMKUHRlfVsHiIL5qx/D78RZr+1ricmSoPMY=;
        b=U153nZXifDXPGyguGsqAkj/SuuMZoYa7T73bEHENJQcfAeQGHkyy+ACoOUlrgYF1IQ
         X+3kmQvujKy4FCWYAbOQLgsCGCKNsHZTEcGh99akT/IQcNupjqZrP1RzYvTg0UIrLeXL
         xhBQh7H3ewV3eKEXWPYLbWf2ASUXBAawe2Xx2F57RBwYwRcU6bmhyViXUdtAM4NSQ35x
         1FTvx/KKuxJuEZsz67/SeXHJOfqbHOxqDUAEsg9TsjRjt3i6i9E6jDbypWf3T/Qbpr9a
         9NH9KRou4pPNxgCSlhAK1aM5nYWP4GAJ1UwrVRh87yaSpIctcMOandQE7eGB2TYQrUE5
         WqPQ==
X-Gm-Message-State: ALoCoQlT2Ngblez2TKrqylbij8fyNu6Kg75hyGFz3bQw68550h1dETi06WVdnv/r3P05mSBfF0m8
X-Received: by 10.112.150.136 with SMTP id ui8mr18221629lbb.60.1413850136718;
 Mon, 20 Oct 2014 17:08:56 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.16 with HTTP; Mon, 20 Oct 2014 17:08:36 -0700 (PDT)
In-Reply-To: <AFBB584B386748008FF81312D2A24C39@gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com> <AFBB584B386748008FF81312D2A24C39@gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 20 Oct 2014 17:08:36 -0700
Message-ID: <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Ted Yu <yuzhihong@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a8c802a3bc40505e3a3c9
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a8c802a3bc40505e3a3c9
Content-Type: text/plain; charset=UTF-8

hmm, strange.  i'll take a look.

On Mon, Oct 20, 2014 at 5:11 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

> yes, I can compile locally, too
>
> but it seems that Jenkins is not happy now...
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
>
> All failed to compile
>
> Best,
>
> --
> Nan Zhu
>
>
> On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:
>
> > I performed build on latest master branch but didn't get compilation
> error.
> >
> > FYI
> >
> > On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com
> (mailto:zhunanmcgill@gmail.com)> wrote:
> > > Hi,
> > >
> > > I just submitted a patch
> https://github.com/apache/spark/pull/2864/files
> > > with one line change
> > >
> > > but the Jenkins told me it's failed to compile on the unrelated files?
> > >
> > >
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
> > >
> > >
> > > Best,
> > >
> > > Nan
> >
>
>

--047d7b3a8c802a3bc40505e3a3c9--

From dev-return-9895-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:16:31 2014
Return-Path: <dev-return-9895-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C4BE217C27
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:16:31 +0000 (UTC)
Received: (qmail 77801 invoked by uid 500); 21 Oct 2014 00:16:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77720 invoked by uid 500); 21 Oct 2014 00:16:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77704 invoked by uid 99); 21 Oct 2014 00:16:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:16:30 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.223.176 as permitted sender)
Received: from [209.85.223.176] (HELO mail-ie0-f176.google.com) (209.85.223.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:16:26 +0000
Received: by mail-ie0-f176.google.com with SMTP id rp18so128333iec.21
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:16:06 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type:content-transfer-encoding;
        bh=bcTOcwrfHQN2O8AUu5NNRbzUbQHGL61wpQruWG1z5r8=;
        b=cQhQmfMC7oJcx6MfGPbUgkJgexFuHwEMrO80TUMyUkLOPWj80U/yrxWeeWRZVK5fRq
         44t4UrlURAFsqP0wZVg2Zyyg++6LfXmEU3u+taeylYmgycrvTJW8O07mtyK52TihcMwq
         GG8kABz7ZDl3oy9xWxnDtLTxU/cf/SS21q3nFyZPD+B+N1nwzQpy4EA/xQ1yGQ4MkvE7
         dFaN8qMUpynz8Gk3nGDEVQUks49/iaclMPkX+uwK10q9XuXKzutSGlUhjVHfHO/TiEmh
         6pErjt7C+IL/hOpb59ZKl1O+qXXLzwfXs6cRxRvmKB6E7rZE/N/PkEsk5agyXT5EsZ0H
         c64w==
X-Gm-Message-State: ALoCoQlOvefBZAoAE+kfpSlRs1KqHj4eRLwAaJFsc8bWGLg78UtbqvLZUx5GMug1WgpJoPslyAdC
X-Received: by 10.50.119.195 with SMTP id kw3mr22006440igb.5.1413850566037;
 Mon, 20 Oct 2014 17:16:06 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Mon, 20 Oct 2014 17:15:45 -0700 (PDT)
In-Reply-To: <CAOhmDzeUNhuCr41B7KRPTEwMn4cga_2TNpZrWqQB8REekokxzg@mail.gmail.com>
References: <CAOhmDzerXLg1x8RWY3rDOwiZ9TmwH7+x8YDOGDA4LZDGBcsNkw@mail.gmail.com>
 <CAPh_B=bomHWCCdkaNnEJFQ348_h0kVSHWk+EOob+P1zVxfrxkQ@mail.gmail.com> <CAOhmDzeUNhuCr41B7KRPTEwMn4cga_2TNpZrWqQB8REekokxzg@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 20 Oct 2014 20:15:45 -0400
Message-ID: <CAMAsSd+wsSY6ZHw+ZCDbn374DS_pwddDu4UHm8iFP6rr_KL8iw@mail.gmail.com>
Subject: Re: Building and Running Spark on OS X
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Maven is at least built in to OS X (well, with dev tools). You don't
even have to brew install it. Surely SBT isn't in the dev tools even?
I recall I had to install it. I'd be surprised to hear it required
zero setup.

On Mon, Oct 20, 2014 at 8:04 PM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> Yeah, I would use sbt too, but I thought if I wanted to publish a little
> reference page for OS X users then I probably should use the =E2=80=9Coff=
icial
> <https://github.com/apache/spark#building-spark>=E2=80=9C build instructi=
ons.
>
> Nick
>
>
> On Mon, Oct 20, 2014 at 8:00 PM, Reynold Xin <rxin@databricks.com> wrote:
>
>> I usually use SBT on Mac and that one doesn't require any setup ...
>>
>>
>> On Mon, Oct 20, 2014 at 4:43 PM, Nicholas Chammas <
>> nicholas.chammas@gmail.com> wrote:
>>
>>> If one were to put together a short but comprehensive guide to setting =
up
>>> Spark to run locally on OS X, would it look like this?
>>>
>>> # Install Maven. On OS X, we suggest using Homebrew.
>>> brew install maven
>>> # Set some important Java and Maven environment variables.export
>>> JAVA_HOME=3D$(/usr/libexec/java_home)export MAVEN_OPTS=3D"-Xmx512m
>>> -XX:MaxPermSize=3D128m"
>>> # Go to where you downloaded the Spark source.cd ./spark
>>> # Build, configure slaves, and startup Spark.
>>> mvn -DskipTests clean packageecho "localhost" > ./conf/slaves
>>> ./sbin/start-all.sh
>>> # Rock 'n' Roll.
>>> ./bin/pyspark
>>> # Cleanup when you're done.
>>> ./sbin/stop-all.sh
>>>
>>> Nick
>>>
>>>
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9896-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:16:51 2014
Return-Path: <dev-return-9896-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F0D1C17C2F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:16:50 +0000 (UTC)
Received: (qmail 80600 invoked by uid 500); 21 Oct 2014 00:16:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80525 invoked by uid 500); 21 Oct 2014 00:16:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80513 invoked by uid 99); 21 Oct 2014 00:16:49 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:16:49 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.179 as permitted sender)
Received: from [209.85.214.179] (HELO mail-ob0-f179.google.com) (209.85.214.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:16:45 +0000
Received: by mail-ob0-f179.google.com with SMTP id wp4so99598obc.38
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:16:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=Yj29GYJ+meU/lUHixAUwLhTbQXHii8GpxxW9HpldfY4=;
        b=sTKVOgpQpA42NMM5gKx+ciFLK5NfUjqloJbj/gMI7VDDuMfC3y9Wa2qQFXSZ5BMpup
         OgkA94GHclxRkJQO1UoSO0UPGtRIzpEhEbtDPezArqgyLCDTWFzhiy8tp7em+mE8eSMY
         abuy+gSUPYTU2Ud9YY2iPl7nsANXzvQ6DUPyv7+N3b+Fa6edEghjIoT97PUWBnVqmsD+
         VwjDzjwZS93v2kJHfC6V8sOY2pDIqCSiFc0PFVrXGJ5frwb7zlEMjnNIMxjaL+DEetX9
         Gc2+oRbmnB4QlxyHrhV8c3Q7bdj9NJusTqHzZ93xgV8UVB/UhnCdgn0it/DFd+KZvzcv
         SFZw==
MIME-Version: 1.0
X-Received: by 10.202.130.139 with SMTP id e133mr24689541oid.35.1413850585181;
 Mon, 20 Oct 2014 17:16:25 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Mon, 20 Oct 2014 17:16:25 -0700 (PDT)
In-Reply-To: <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
	<CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
	<AFBB584B386748008FF81312D2A24C39@gmail.com>
	<CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
Date: Mon, 20 Oct 2014 17:16:25 -0700
Message-ID: <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
From: Patrick Wendell <pwendell@gmail.com>
To: shane knapp <sknapp@berkeley.edu>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

The failure is in the Kinesis compoent, can you reproduce this if you
build with -Pkinesis-asl?

- Patrick

On Mon, Oct 20, 2014 at 5:08 PM, shane knapp <sknapp@berkeley.edu> wrote:
> hmm, strange.  i'll take a look.
>
> On Mon, Oct 20, 2014 at 5:11 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>
>> yes, I can compile locally, too
>>
>> but it seems that Jenkins is not happy now...
>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
>>
>> All failed to compile
>>
>> Best,
>>
>> --
>> Nan Zhu
>>
>>
>> On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:
>>
>> > I performed build on latest master branch but didn't get compilation
>> error.
>> >
>> > FYI
>> >
>> > On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com
>> (mailto:zhunanmcgill@gmail.com)> wrote:
>> > > Hi,
>> > >
>> > > I just submitted a patch
>> https://github.com/apache/spark/pull/2864/files
>> > > with one line change
>> > >
>> > > but the Jenkins told me it's failed to compile on the unrelated files?
>> > >
>> > >
>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>> > >
>> > >
>> > > Best,
>> > >
>> > > Nan
>> >
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9897-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:20:33 2014
Return-Path: <dev-return-9897-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1A87317C51
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:20:33 +0000 (UTC)
Received: (qmail 88516 invoked by uid 500); 21 Oct 2014 00:20:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88441 invoked by uid 500); 21 Oct 2014 00:20:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88429 invoked by uid 99); 21 Oct 2014 00:20:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:20:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.180 as permitted sender)
Received: from [209.85.212.180] (HELO mail-wi0-f180.google.com) (209.85.212.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:20:28 +0000
Received: by mail-wi0-f180.google.com with SMTP id em10so394414wid.7
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:20:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=XXCJb6nY0jgTna7SaxwtXSXSAtX5hHK9ozrjUH7C/ec=;
        b=TuRNzmcibnKFgnyyn/uGn3uFaTt0qPCW3BJ7ck+dpEBGPE5iZ+140lA/6SkiD7lE9R
         ywJqvoRnGbfI5WaSd9xsPkT1P/aOzs8Jbeh1fs/Wl/jVndQVrxo5Su+kxtnE+YcfLUTd
         NhqVv0N7Z9ynqHxX3Lzvf3l4kCJfG45cGXQ4rSD+SUMsFcum/UM3aydjzBX2lmxFonRk
         buVPKAXBQH08ZAPBp4T6psSddQJ1O56CS/SdqPtwZBbelwQfgYsy5LbRQNRkSVY/0r8D
         4vX3wzfYLtbmll/64fKAxcny61NF+PH3N+sEBF6f5/SoislVYrrQXa83LzgZue9QRTBD
         h+8g==
X-Received: by 10.180.206.171 with SMTP id lp11mr23658469wic.33.1413850807095;
 Mon, 20 Oct 2014 17:20:07 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 20 Oct 2014 17:19:26 -0700 (PDT)
In-Reply-To: <CAMAsSd+wsSY6ZHw+ZCDbn374DS_pwddDu4UHm8iFP6rr_KL8iw@mail.gmail.com>
References: <CAOhmDzerXLg1x8RWY3rDOwiZ9TmwH7+x8YDOGDA4LZDGBcsNkw@mail.gmail.com>
 <CAPh_B=bomHWCCdkaNnEJFQ348_h0kVSHWk+EOob+P1zVxfrxkQ@mail.gmail.com>
 <CAOhmDzeUNhuCr41B7KRPTEwMn4cga_2TNpZrWqQB8REekokxzg@mail.gmail.com> <CAMAsSd+wsSY6ZHw+ZCDbn374DS_pwddDu4UHm8iFP6rr_KL8iw@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 20 Oct 2014 20:19:26 -0400
Message-ID: <CAOhmDzfVrBzrQ3ZrhO7Dome6rQhR9GBWFHdyeSs0wVOjqUozWA@mail.gmail.com>
Subject: Re: Building and Running Spark on OS X
To: Sean Owen <sowen@cloudera.com>
Cc: Reynold Xin <rxin@databricks.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c380cc1f57160505e3cbc5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c380cc1f57160505e3cbc5
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I think starting in Mavericks, Maven is no longer included by default
<http://stackoverflow.com/questions/19678594/maven-not-found-in-mac-osx-mav=
ericks>
.

On Mon, Oct 20, 2014 at 8:15 PM, Sean Owen <sowen@cloudera.com> wrote:

> Maven is at least built in to OS X (well, with dev tools). You don't
> even have to brew install it. Surely SBT isn't in the dev tools even?
> I recall I had to install it. I'd be surprised to hear it required
> zero setup.
>
> On Mon, Oct 20, 2014 at 8:04 PM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
> > Yeah, I would use sbt too, but I thought if I wanted to publish a littl=
e
> > reference page for OS X users then I probably should use the =E2=80=9Co=
fficial
> > <https://github.com/apache/spark#building-spark>=E2=80=9C build instruc=
tions.
> >
> > Nick
> >
> >
> > On Mon, Oct 20, 2014 at 8:00 PM, Reynold Xin <rxin@databricks.com>
> wrote:
> >
> >> I usually use SBT on Mac and that one doesn't require any setup ...
> >>
> >>
> >> On Mon, Oct 20, 2014 at 4:43 PM, Nicholas Chammas <
> >> nicholas.chammas@gmail.com> wrote:
> >>
> >>> If one were to put together a short but comprehensive guide to settin=
g
> up
> >>> Spark to run locally on OS X, would it look like this?
> >>>
> >>> # Install Maven. On OS X, we suggest using Homebrew.
> >>> brew install maven
> >>> # Set some important Java and Maven environment variables.export
> >>> JAVA_HOME=3D$(/usr/libexec/java_home)export MAVEN_OPTS=3D"-Xmx512m
> >>> -XX:MaxPermSize=3D128m"
> >>> # Go to where you downloaded the Spark source.cd ./spark
> >>> # Build, configure slaves, and startup Spark.
> >>> mvn -DskipTests clean packageecho "localhost" > ./conf/slaves
> >>> ./sbin/start-all.sh
> >>> # Rock 'n' Roll.
> >>> ./bin/pyspark
> >>> # Cleanup when you're done.
> >>> ./sbin/stop-all.sh
> >>>
> >>> Nick
> >>>
> >>>
> >>
> >>
>

--001a11c380cc1f57160505e3cbc5--

From dev-return-9898-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:21:09 2014
Return-Path: <dev-return-9898-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6A0C917C57
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:21:09 +0000 (UTC)
Received: (qmail 90639 invoked by uid 500); 21 Oct 2014 00:21:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90569 invoked by uid 500); 21 Oct 2014 00:21:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90557 invoked by uid 99); 21 Oct 2014 00:21:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:21:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hshreedharan@cloudera.com designates 209.85.216.46 as permitted sender)
Received: from [209.85.216.46] (HELO mail-qa0-f46.google.com) (209.85.216.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:20:43 +0000
Received: by mail-qa0-f46.google.com with SMTP id w8so92199qac.33
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:20:42 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:date:mime-version:message-id:in-reply-to
         :references:from:to:cc:subject:content-type;
        bh=sbK3caJvd+/Nfxeu5DhB+WT9/DaQHgRs2y3sHIHm6U8=;
        b=dSEyS+BY5hSZ6L1geC3xMGUwjKv710H40sYCpzO3XQfOL4PBYtM6r+Z5pJMuufJYMe
         PZAOrKw8BWkCo3GT6vD9wIra22Zodiwhex7J5LGgnetgba5mGwRrJfHSr1X4gOdgFlha
         spjDKKtvP+6CzHxF2tOObKZV7YBNnp7740LLuV5a3EZ0uYeLfe7iEaiy4CZgzb5U3Hzk
         t/Wok8moz2HcEOHyX2OLP0xdrZcbSBVjU92FkEywE/AIneolYa8ZkyBit6TyRnmXPSjn
         Urd76yJaCoBNVmcAtDYxhwzG7Eh0Z4rbfUT2vXYanl/JbPi72hejquIvrqACYIsuUL6g
         Tc4A==
X-Gm-Message-State: ALoCoQlTAR2yr/LCRqXEPYIdXckKb+gRE+GIkTFxEGj0jt5UFZTpKIo7aw9As5Ob01Fa99aGi+Ls
X-Received: by 10.229.40.71 with SMTP id j7mr40645622qce.21.1413850841969;
        Mon, 20 Oct 2014 17:20:41 -0700 (PDT)
Received: from hedwig-6.prd.orcali.com (ec2-54-85-253-252.compute-1.amazonaws.com. [54.85.253.252])
        by mx.google.com with ESMTPSA id u3sm9304355qat.27.2014.10.20.17.20.41
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 20 Oct 2014 17:20:41 -0700 (PDT)
Date: Mon, 20 Oct 2014 17:20:41 -0700 (PDT)
X-Google-Original-Date: Tue, 21 Oct 2014 00:20:41 GMT
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Message-Id: <1413850841116.1cbbe293@Nodemailer>
In-Reply-To: <CAMAsSd+wsSY6ZHw+ZCDbn374DS_pwddDu4UHm8iFP6rr_KL8iw@mail.gmail.com>
References: <CAMAsSd+wsSY6ZHw+ZCDbn374DS_pwddDu4UHm8iFP6rr_KL8iw@mail.gmail.com>
X-Orchestra-Oid: 4EC2B291-FE23-4E36-B099-67DF1AC88D9B
X-Orchestra-Sig: 33def738e33dbf5579fa91524f37a375c6b538a9
X-Orchestra-Thrid: TEB56D109-7104-46FE-9747-57A7D6EE5D69_1482527817243830246
X-Orchestra-Thrid-Sig: 4d535fcf1b041909a2b3b65ebe5f325a2cddeaff
X-Orchestra-Account: d9fec3db2e40d383d9a27139d7f821bb94417284
From: "Hari Shreedharan" <hshreedharan@cloudera.com>
To: "Sean Owen" <sowen@cloudera.com>
Cc: "Nicholas Chammas" <nicholas.chammas@gmail.com>, "dev"
 <dev@spark.apache.org>, "Reynold Xin" <rxin@databricks.com>
Subject: Re: Building and Running Spark on OS X
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1413850841506"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1413850841506
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

The sbt executable that is in the spark repo can be used to build sbt =
without any other set up (it will download the sbt jars etc).


Thanks,
Hari

On Mon, Oct 20, 2014 at 5:16 PM, Sean Owen <sowen@cloudera.com> wrote:

> Maven is at least built in to OS X (well, with dev tools). You don't
> even have to brew install it. Surely SBT isn't in the dev tools even=3F
> I recall I had to install it. I'd be surprised to hear it required
> zero setup.
> On Mon, Oct 20, 2014 at 8:04 PM, Nicholas Chammas
> <nicholas.chammas@gmail.com> wrote:
>> Yeah, I would use sbt too, but I thought if I wanted to publish a =
little
>> reference page for OS X users then I probably should use the =
=E2=80=9Cofficial
>> <https://github.com/apache/spark#building-spark>=E2=80=9C build =
instructions.
>>
>> Nick
>>
>>
>> On Mon, Oct 20, 2014 at 8:00 PM, Reynold Xin <rxin@databricks.com> =
wrote:
>>
>>> I usually use SBT on Mac and that one doesn't require any setup ...
>>>
>>>
>>> On Mon, Oct 20, 2014 at 4:43 PM, Nicholas Chammas <
>>> nicholas.chammas@gmail.com> wrote:
>>>
>>>> If one were to put together a short but comprehensive guide to setting=
 up
>>>> Spark to run locally on OS X, would it look like this=3F
>>>>
>>>> # Install Maven. On OS X, we suggest using Homebrew.
>>>> brew install maven
>>>> # Set some important Java and Maven environment variables.export
>>>> JAVA=5FHOME=3D$(/usr/libexec/java=5Fhome)export =
MAVEN=5FOPTS=3D=22-Xmx512m
>>>> -XX:MaxPermSize=3D128m=22
>>>> # Go to where you downloaded the Spark source.cd ./spark
>>>> # Build, configure slaves, and startup Spark.
>>>> mvn -DskipTests clean packageecho =22localhost=22 > ./conf/slaves
>>>> ./sbin/start-all.sh
>>>> # Rock 'n' Roll.
>>>> ./bin/pyspark
>>>> # Cleanup when you're done.
>>>> ./sbin/stop-all.sh
>>>>
>>>> Nick
>>>>
>>>>
>>>
>>>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.=
org
------Nodemailer-0.5.0-?=_1-1413850841506--

From dev-return-9899-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:26:04 2014
Return-Path: <dev-return-9899-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 41D9F17C80
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:26:04 +0000 (UTC)
Received: (qmail 6380 invoked by uid 500); 21 Oct 2014 00:26:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6289 invoked by uid 500); 21 Oct 2014 00:26:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6272 invoked by uid 99); 21 Oct 2014 00:26:03 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:26:03 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.213.171 as permitted sender)
Received: from [209.85.213.171] (HELO mail-ig0-f171.google.com) (209.85.213.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:25:37 +0000
Received: by mail-ig0-f171.google.com with SMTP id h15so333327igd.10
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:25:36 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=7IvNSIH6WBB2und4lHf6mRt7lSRTgs3PAvqsLcJOVuU=;
        b=FmiRdCS0ObHG2lZ2ye+5k6Y6lkoi11FHKzrLqr6TB9JotbaYvwcLHnQw/68WyvO11C
         ACbxj5BqIlD7rClEmASD690UL3axqfiCRRBR+2/Virh6O5rccsVn7yIoEJr8IARwGWJn
         HR2sOJi/Sg3QsSoWnceFKziROdzx4zZTjhrUsz7a/slGU9Z333QfCjHXOrz1uSFwT0eC
         zbnFx+c/mSZ9U6YS3wZcQBf+wrQfZb+6ac+ckYLKqDi9srnEdi8vDeepZTr5rpizBGhF
         vgGbwmZqfEl9WJgANPt+O0rkEY0VOiBad1Y7+kIwXJGaVhAey45azQW2ZfDUGH1h2C/t
         EL2Q==
X-Gm-Message-State: ALoCoQmkkKhMCcBmFTTpssZdGSdML0iR6iAcuHVaMO+ol5T/2KmT2yvUAWKfoME1F93bFUdnyzc4
X-Received: by 10.50.61.137 with SMTP id p9mr22322974igr.34.1413851136805;
 Mon, 20 Oct 2014 17:25:36 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Mon, 20 Oct 2014 17:25:16 -0700 (PDT)
In-Reply-To: <1413850841116.1cbbe293@Nodemailer>
References: <CAMAsSd+wsSY6ZHw+ZCDbn374DS_pwddDu4UHm8iFP6rr_KL8iw@mail.gmail.com>
 <1413850841116.1cbbe293@Nodemailer>
From: Sean Owen <sowen@cloudera.com>
Date: Mon, 20 Oct 2014 20:25:16 -0400
Message-ID: <CAMAsSdKWHh3Z+PBHUqhvmgY-mmLO-BUS8p5hLgquk5H812V0=g@mail.gmail.com>
Subject: Re: Building and Running Spark on OS X
To: Hari Shreedharan <hshreedharan@cloudera.com>
Cc: Nicholas Chammas <nicholas.chammas@gmail.com>, dev <dev@spark.apache.org>, 
	Reynold Xin <rxin@databricks.com>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Oh right, we're talking about the bundled sbt of course.
And I didn't know Maven wasn't installed anymore!

On Mon, Oct 20, 2014 at 8:20 PM, Hari Shreedharan
<hshreedharan@cloudera.com> wrote:
> The sbt executable that is in the spark repo can be used to build sbt
> without any other set up (it will download the sbt jars etc).
>
> Thanks,
> Hari
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9900-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:29:44 2014
Return-Path: <dev-return-9900-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8B68317C94
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:29:44 +0000 (UTC)
Received: (qmail 14956 invoked by uid 500); 21 Oct 2014 00:29:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 14882 invoked by uid 500); 21 Oct 2014 00:29:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 14870 invoked by uid 99); 21 Oct 2014 00:29:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:29:43 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.44 as permitted sender)
Received: from [209.85.215.44] (HELO mail-la0-f44.google.com) (209.85.215.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:29:39 +0000
Received: by mail-la0-f44.google.com with SMTP id hs14so112919lab.3
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:29:17 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=wobepckJg/n1e1hDKyF8nfg4XEUd85R6YY3gODb7bMc=;
        b=fijfXfMayWKRXAksgbjhqaFRw0eV1fkLVYX02IMyDylEWFiTEbBt7n6mJh6O6W1yGW
         0iZLEqrByIz0css0olysMOapveRpMSNPRsodrUX9s/7lboBtMAWVrn86hgjTx3E2Ylxd
         cMuUKcdRvPJyknGd0+2M7g1xU8nxQ+RMvJq4DfOauW+0jWGRzvMjCmbWAJrBAjZmdJj4
         aJOAnhNzcNEJzF0z0FdSx5Hy7fQIuv2S/lYew1CZ0qYID4sUen6EvrOu7qyWFtt7S3Aq
         1dpBmVcMocwla4JwcYFwqWT2CvHvXrHGH0IAaCptbgn4TUOQ6SoY1Gq3A0/Zdby2XoI+
         /gyA==
X-Gm-Message-State: ALoCoQkRR+13KPj5L55JmOoguTAcjL5Ce8wV1m+NBmgcaY+KN4zbWCR/jAOsQFyusSpNn9G4Srj4
X-Received: by 10.112.130.41 with SMTP id ob9mr30257094lbb.74.1413851357519;
 Mon, 20 Oct 2014 17:29:17 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.16 with HTTP; Mon, 20 Oct 2014 17:28:57 -0700 (PDT)
In-Reply-To: <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com> <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 20 Oct 2014 17:28:57 -0700
Message-ID: <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
To: Patrick Wendell <pwendell@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b342ba6ee2f980505e3ebaa
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b342ba6ee2f980505e3ebaa
Content-Type: text/plain; charset=UTF-8

ok, so earlier today i installed a 2nd JDK within jenkins (7u71), which
fixed the SparkR build but apparently made Spark itself quite unhappy.  i
removed that JDK, triggered a build (
https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
and it compiled kinesis w/o dying a fiery death.

apparently 7u71 is stricter when compiling.  sad times.

sorry about that!

shane


On Mon, Oct 20, 2014 at 5:16 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> The failure is in the Kinesis compoent, can you reproduce this if you
> build with -Pkinesis-asl?
>
> - Patrick
>
> On Mon, Oct 20, 2014 at 5:08 PM, shane knapp <sknapp@berkeley.edu> wrote:
> > hmm, strange.  i'll take a look.
> >
> > On Mon, Oct 20, 2014 at 5:11 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
> >
> >> yes, I can compile locally, too
> >>
> >> but it seems that Jenkins is not happy now...
> >> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
> >>
> >> All failed to compile
> >>
> >> Best,
> >>
> >> --
> >> Nan Zhu
> >>
> >>
> >> On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:
> >>
> >> > I performed build on latest master branch but didn't get compilation
> >> error.
> >> >
> >> > FYI
> >> >
> >> > On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com
> >> (mailto:zhunanmcgill@gmail.com)> wrote:
> >> > > Hi,
> >> > >
> >> > > I just submitted a patch
> >> https://github.com/apache/spark/pull/2864/files
> >> > > with one line change
> >> > >
> >> > > but the Jenkins told me it's failed to compile on the unrelated
> files?
> >> > >
> >> > >
> >>
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
> >> > >
> >> > >
> >> > > Best,
> >> > >
> >> > > Nan
> >> >
> >>
> >>
>

--047d7b342ba6ee2f980505e3ebaa--

From dev-return-9901-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:29:55 2014
Return-Path: <dev-return-9901-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D353B17C96
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:29:55 +0000 (UTC)
Received: (qmail 16381 invoked by uid 500); 21 Oct 2014 00:29:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16313 invoked by uid 500); 21 Oct 2014 00:29:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16301 invoked by uid 99); 21 Oct 2014 00:29:54 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:29:54 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.45 as permitted sender)
Received: from [74.125.82.45] (HELO mail-wg0-f45.google.com) (74.125.82.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:29:29 +0000
Received: by mail-wg0-f45.google.com with SMTP id m15so133082wgh.4
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:29:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=DiXtA65yt8bJFOhinxcCefKp9PNZYB6FuIKhY3dScAw=;
        b=mTISGvEQN71yH18424zpmKQnM02QnjHm5uvTGviD63DDGmKxT12GmQeorusk8FUq29
         GDsJ/NmM5A0O4b6b/WoAwffNxWH/8WEmsVJMoh+plQsRBPgGNw/agtGddO9LGerDHAMw
         x3pVCq8VbjUp5n8Gz3XupSTvT7kTkv5i8L9gU+xGzBB1fROksGW50UfzsGjiwHqOMxD4
         lYAtLpJi96qVyWCtr/b0mY87cx9APJplfE7bcVUlvib6u69joMjDpF+jun3zZdrDdjM0
         velnzX4bs1rRlfx1Zod5eizzn86fPypdliMUSlmAo36k4xic257dOvauzr9AHGlfdxX8
         FIVA==
X-Received: by 10.181.8.72 with SMTP id di8mr29686152wid.1.1413851368494; Mon,
 20 Oct 2014 17:29:28 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.99.70 with HTTP; Mon, 20 Oct 2014 17:28:48 -0700 (PDT)
In-Reply-To: <CAMAsSdKWHh3Z+PBHUqhvmgY-mmLO-BUS8p5hLgquk5H812V0=g@mail.gmail.com>
References: <CAMAsSd+wsSY6ZHw+ZCDbn374DS_pwddDu4UHm8iFP6rr_KL8iw@mail.gmail.com>
 <1413850841116.1cbbe293@Nodemailer> <CAMAsSdKWHh3Z+PBHUqhvmgY-mmLO-BUS8p5hLgquk5H812V0=g@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Mon, 20 Oct 2014 20:28:48 -0400
Message-ID: <CAOhmDzc8E3UxSmjjNGzsTJpxFvJ8GV2gzU-2YGHsi0XGsKCFhg@mail.gmail.com>
Subject: Re: Building and Running Spark on OS X
To: Sean Owen <sowen@cloudera.com>
Cc: Hari Shreedharan <hshreedharan@cloudera.com>, dev <dev@spark.apache.org>, 
	Reynold Xin <rxin@databricks.com>
Content-Type: multipart/alternative; boundary=001a1134cdee959bc40505e3ec2e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1134cdee959bc40505e3ec2e
Content-Type: text/plain; charset=UTF-8

So back to my original question... :)

If we wanted to post this guide to the user list or to a gist for easy
reference, would we rather have Maven or SBT listed? And is there anything
else about the steps that should be modified?

Nick

On Mon, Oct 20, 2014 at 8:25 PM, Sean Owen <sowen@cloudera.com> wrote:

> Oh right, we're talking about the bundled sbt of course.
> And I didn't know Maven wasn't installed anymore!
>
> On Mon, Oct 20, 2014 at 8:20 PM, Hari Shreedharan
> <hshreedharan@cloudera.com> wrote:
> > The sbt executable that is in the spark repo can be used to build sbt
> > without any other set up (it will download the sbt jars etc).
> >
> > Thanks,
> > Hari
> >
>

--001a1134cdee959bc40505e3ec2e--

From dev-return-9902-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:33:01 2014
Return-Path: <dev-return-9902-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 734BC17CAA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:33:01 +0000 (UTC)
Received: (qmail 22649 invoked by uid 500); 21 Oct 2014 00:33:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22572 invoked by uid 500); 21 Oct 2014 00:33:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22536 invoked by uid 99); 21 Oct 2014 00:33:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:33:00 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.49 as permitted sender)
Received: from [209.85.218.49] (HELO mail-oi0-f49.google.com) (209.85.218.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:32:56 +0000
Received: by mail-oi0-f49.google.com with SMTP id a3so112923oib.22
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:32:35 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=jGwwCJ/LsM3IVQXkRXqIOFqaw8/XFwEzDHtWpMlfkR4=;
        b=GH0oLiEIf1dGuBBQsud40UObxms2/Rq5XWwbeia0p7by7shIXSZB/0iVWi4GNeBxLF
         gBMkvwINb/5hdgFrDA7ZiSrcpX9L6wrTIy0hoGAz6uX+6VrAuzLpqCgcQFTGxSLkFBTH
         /m9p1qRx1NVk74+laJ5u3OAU4IYGXslI/ueg6gWjjKeSmB0anBKUUbL1vOwTq9JQ+ytf
         iAWnSp0bqoxQb/b3Zo528GFsCZuVSV/lGeldjkecgrFvHJ3xlCi3g4as7+e9M1GST56D
         kuO05ptG4Z+5qCVczip2lxUnC2dWfxxID4fawYslJPxLqB6fsS9gmiSS8fbpZ0U81da8
         V2VQ==
MIME-Version: 1.0
X-Received: by 10.60.78.106 with SMTP id a10mr26112167oex.21.1413851555670;
 Mon, 20 Oct 2014 17:32:35 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Mon, 20 Oct 2014 17:32:35 -0700 (PDT)
In-Reply-To: <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
	<CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
	<AFBB584B386748008FF81312D2A24C39@gmail.com>
	<CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
	<CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
	<CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
Date: Mon, 20 Oct 2014 17:32:35 -0700
Message-ID: <CABPQxst=iAvB_cOsJUytHXe3X2vCQS7H39P_B+C-7KWy8CgTjA@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
From: Patrick Wendell <pwendell@gmail.com>
To: shane knapp <sknapp@berkeley.edu>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks Shane - we should fix the source code issues in the Kinesis
code that made stricter Java compilers reject it.

- Patrick

On Mon, Oct 20, 2014 at 5:28 PM, shane knapp <sknapp@berkeley.edu> wrote:
> ok, so earlier today i installed a 2nd JDK within jenkins (7u71), which
> fixed the SparkR build but apparently made Spark itself quite unhappy.  i
> removed that JDK, triggered a build
> (https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
> and it compiled kinesis w/o dying a fiery death.
>
> apparently 7u71 is stricter when compiling.  sad times.
>
> sorry about that!
>
> shane
>
>
> On Mon, Oct 20, 2014 at 5:16 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>
>> The failure is in the Kinesis compoent, can you reproduce this if you
>> build with -Pkinesis-asl?
>>
>> - Patrick
>>
>> On Mon, Oct 20, 2014 at 5:08 PM, shane knapp <sknapp@berkeley.edu> wrote:
>> > hmm, strange.  i'll take a look.
>> >
>> > On Mon, Oct 20, 2014 at 5:11 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>> >
>> >> yes, I can compile locally, too
>> >>
>> >> but it seems that Jenkins is not happy now...
>> >> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
>> >>
>> >> All failed to compile
>> >>
>> >> Best,
>> >>
>> >> --
>> >> Nan Zhu
>> >>
>> >>
>> >> On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:
>> >>
>> >> > I performed build on latest master branch but didn't get compilation
>> >> error.
>> >> >
>> >> > FYI
>> >> >
>> >> > On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com
>> >> (mailto:zhunanmcgill@gmail.com)> wrote:
>> >> > > Hi,
>> >> > >
>> >> > > I just submitted a patch
>> >> https://github.com/apache/spark/pull/2864/files
>> >> > > with one line change
>> >> > >
>> >> > > but the Jenkins told me it's failed to compile on the unrelated
>> >> > > files?
>> >> > >
>> >> > >
>> >>
>> >> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>> >> > >
>> >> > >
>> >> > > Best,
>> >> > >
>> >> > > Nan
>> >> >
>> >>
>> >>
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9903-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:35:41 2014
Return-Path: <dev-return-9903-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2EBD517CB4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:35:41 +0000 (UTC)
Received: (qmail 27819 invoked by uid 500); 21 Oct 2014 00:35:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27746 invoked by uid 500); 21 Oct 2014 00:35:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27734 invoked by uid 99); 21 Oct 2014 00:35:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:35:39 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.50 as permitted sender)
Received: from [209.85.218.50] (HELO mail-oi0-f50.google.com) (209.85.218.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:35:35 +0000
Received: by mail-oi0-f50.google.com with SMTP id i138so111881oig.37
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:35:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=qosZ12vlul2pWGYm08bEvn7eUgUk5BhYF3izBwpfhDU=;
        b=g9bWdfdfAeUH74L6sLshKL8IME+7f+28tk4EJpazOUEoCKQwHtPRsk7Bqm9ZqwUJQy
         ZB2sR3wpkCYxv6UjWkRvog+RlVNg3wX9AjzaFz+Yj2Nks09WT31lzdHaURpfItj3ezEi
         LRmBIsiRlQF7h69fxfPqx3F0JbsPdWH8JRqroKNb+JWwslV+R6PoLALAWFcqO9IPmOAR
         t1qMNXclSQ6yKY6lcexJ0O1ULWHA9VZn99K8aFgKbqC781V+CVLb3rZUmH0pbcWb88D+
         PQQoOiWOkDgD8jjRdGQahYTN4kT96n3T4B+23USoqgrO3WCi/91101Zrg7e4kPBhcFhn
         rJfg==
MIME-Version: 1.0
X-Received: by 10.202.168.80 with SMTP id r77mr10719508oie.26.1413851715423;
 Mon, 20 Oct 2014 17:35:15 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Mon, 20 Oct 2014 17:35:15 -0700 (PDT)
In-Reply-To: <CABPQxst=iAvB_cOsJUytHXe3X2vCQS7H39P_B+C-7KWy8CgTjA@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
	<CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
	<AFBB584B386748008FF81312D2A24C39@gmail.com>
	<CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
	<CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
	<CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
	<CABPQxst=iAvB_cOsJUytHXe3X2vCQS7H39P_B+C-7KWy8CgTjA@mail.gmail.com>
Date: Mon, 20 Oct 2014 17:35:15 -0700
Message-ID: <CABPQxstHmnnU1JH4LyXtAC+OC9fOjcAdMYzPKfRi1vT1Rq=8zQ@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
From: Patrick Wendell <pwendell@gmail.com>
To: shane knapp <sknapp@berkeley.edu>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I created an issue to fix this:

https://issues.apache.org/jira/browse/SPARK-4021

On Mon, Oct 20, 2014 at 5:32 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Thanks Shane - we should fix the source code issues in the Kinesis
> code that made stricter Java compilers reject it.
>
> - Patrick
>
> On Mon, Oct 20, 2014 at 5:28 PM, shane knapp <sknapp@berkeley.edu> wrote:
>> ok, so earlier today i installed a 2nd JDK within jenkins (7u71), which
>> fixed the SparkR build but apparently made Spark itself quite unhappy.  i
>> removed that JDK, triggered a build
>> (https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
>> and it compiled kinesis w/o dying a fiery death.
>>
>> apparently 7u71 is stricter when compiling.  sad times.
>>
>> sorry about that!
>>
>> shane
>>
>>
>> On Mon, Oct 20, 2014 at 5:16 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>>
>>> The failure is in the Kinesis compoent, can you reproduce this if you
>>> build with -Pkinesis-asl?
>>>
>>> - Patrick
>>>
>>> On Mon, Oct 20, 2014 at 5:08 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>> > hmm, strange.  i'll take a look.
>>> >
>>> > On Mon, Oct 20, 2014 at 5:11 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>>> >
>>> >> yes, I can compile locally, too
>>> >>
>>> >> but it seems that Jenkins is not happy now...
>>> >> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
>>> >>
>>> >> All failed to compile
>>> >>
>>> >> Best,
>>> >>
>>> >> --
>>> >> Nan Zhu
>>> >>
>>> >>
>>> >> On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:
>>> >>
>>> >> > I performed build on latest master branch but didn't get compilation
>>> >> error.
>>> >> >
>>> >> > FYI
>>> >> >
>>> >> > On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com
>>> >> (mailto:zhunanmcgill@gmail.com)> wrote:
>>> >> > > Hi,
>>> >> > >
>>> >> > > I just submitted a patch
>>> >> https://github.com/apache/spark/pull/2864/files
>>> >> > > with one line change
>>> >> > >
>>> >> > > but the Jenkins told me it's failed to compile on the unrelated
>>> >> > > files?
>>> >> > >
>>> >> > >
>>> >>
>>> >> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>>> >> > >
>>> >> > >
>>> >> > > Best,
>>> >> > >
>>> >> > > Nan
>>> >> >
>>> >>
>>> >>
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9904-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:37:54 2014
Return-Path: <dev-return-9904-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9273117CC8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:37:54 +0000 (UTC)
Received: (qmail 32517 invoked by uid 500); 21 Oct 2014 00:37:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32445 invoked by uid 500); 21 Oct 2014 00:37:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32433 invoked by uid 99); 21 Oct 2014 00:37:53 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:37:53 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.44 as permitted sender)
Received: from [209.85.215.44] (HELO mail-la0-f44.google.com) (209.85.215.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:37:49 +0000
Received: by mail-la0-f44.google.com with SMTP id hs14so106274lab.31
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:37:27 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=Byo4kHLUBKoF/SmslTKGHb6LEEBnlbtlYLQuA1MBmLE=;
        b=mBpLs+3izm54hl8oYLuQ9UTwaqz8TKeR++Y16a9XlNrZpRW9KkiB9E3hmc4hsVOgGF
         23DEr3uC2+9GFkVOuy3Wndqo0hXJID/OQ8jWLj4tzxh6NA3Jv2n7JrvkiNO+DNgT7kfA
         JIp0PJwPlrx81XYFdgRrvr+45CTKBBWEq+NFi2n8S0xNR5+JQHpguzXD9NnxUcRcNAuu
         2VU1mZwEk5fWhvn/3kiPB7fJgOZUG9YawkK6rOBEZxLw62zgFqMVbNo9NDAG0igdA26d
         yKgGWDy29p2bBwC3KO1Th0UECnZL66c33tMdelyDtwxMKHm/DzaOgT5Td4DQn+8zWDKK
         +0qA==
X-Gm-Message-State: ALoCoQmMhObygu9Y/QcB8zouEppfpV4ZSYXSplYZDy4IwSizGYUxoXpyG5rfVt9DjL/hnCx8s9Iy
X-Received: by 10.112.97.135 with SMTP id ea7mr31090482lbb.46.1413851847711;
 Mon, 20 Oct 2014 17:37:27 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.15.16 with HTTP; Mon, 20 Oct 2014 17:37:06 -0700 (PDT)
In-Reply-To: <CABPQxstHmnnU1JH4LyXtAC+OC9fOjcAdMYzPKfRi1vT1Rq=8zQ@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com> <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <CABPQxst=iAvB_cOsJUytHXe3X2vCQS7H39P_B+C-7KWy8CgTjA@mail.gmail.com> <CABPQxstHmnnU1JH4LyXtAC+OC9fOjcAdMYzPKfRi1vT1Rq=8zQ@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 20 Oct 2014 17:37:06 -0700
Message-ID: <CACdU-dSH2Cof8mqV6G+yRAUuGhjfBv8HAtRv7Bt57MiKtqT8JQ@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
To: Patrick Wendell <pwendell@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133cede25ec300505e409e8
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133cede25ec300505e409e8
Content-Type: text/plain; charset=UTF-8

thanks, patrick!

:)

On Mon, Oct 20, 2014 at 5:35 PM, Patrick Wendell <pwendell@gmail.com> wrote:

> I created an issue to fix this:
>
> https://issues.apache.org/jira/browse/SPARK-4021
>
> On Mon, Oct 20, 2014 at 5:32 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Thanks Shane - we should fix the source code issues in the Kinesis
> > code that made stricter Java compilers reject it.
> >
> > - Patrick
> >
> > On Mon, Oct 20, 2014 at 5:28 PM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >> ok, so earlier today i installed a 2nd JDK within jenkins (7u71), which
> >> fixed the SparkR build but apparently made Spark itself quite unhappy.
> i
> >> removed that JDK, triggered a build
> >> (
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console
> ),
> >> and it compiled kinesis w/o dying a fiery death.
> >>
> >> apparently 7u71 is stricter when compiling.  sad times.
> >>
> >> sorry about that!
> >>
> >> shane
> >>
> >>
> >> On Mon, Oct 20, 2014 at 5:16 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >>>
> >>> The failure is in the Kinesis compoent, can you reproduce this if you
> >>> build with -Pkinesis-asl?
> >>>
> >>> - Patrick
> >>>
> >>> On Mon, Oct 20, 2014 at 5:08 PM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >>> > hmm, strange.  i'll take a look.
> >>> >
> >>> > On Mon, Oct 20, 2014 at 5:11 PM, Nan Zhu <zhunanmcgill@gmail.com>
> wrote:
> >>> >
> >>> >> yes, I can compile locally, too
> >>> >>
> >>> >> but it seems that Jenkins is not happy now...
> >>> >> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
> >>> >>
> >>> >> All failed to compile
> >>> >>
> >>> >> Best,
> >>> >>
> >>> >> --
> >>> >> Nan Zhu
> >>> >>
> >>> >>
> >>> >> On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:
> >>> >>
> >>> >> > I performed build on latest master branch but didn't get
> compilation
> >>> >> error.
> >>> >> >
> >>> >> > FYI
> >>> >> >
> >>> >> > On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com
> >>> >> (mailto:zhunanmcgill@gmail.com)> wrote:
> >>> >> > > Hi,
> >>> >> > >
> >>> >> > > I just submitted a patch
> >>> >> https://github.com/apache/spark/pull/2864/files
> >>> >> > > with one line change
> >>> >> > >
> >>> >> > > but the Jenkins told me it's failed to compile on the unrelated
> >>> >> > > files?
> >>> >> > >
> >>> >> > >
> >>> >>
> >>> >>
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
> >>> >> > >
> >>> >> > >
> >>> >> > > Best,
> >>> >> > >
> >>> >> > > Nan
> >>> >> >
> >>> >>
> >>> >>
> >>
> >>
>

--001a1133cede25ec300505e409e8--

From dev-return-9905-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 00:42:51 2014
Return-Path: <dev-return-9905-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CDACA17CFA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 00:42:51 +0000 (UTC)
Received: (qmail 43519 invoked by uid 500); 21 Oct 2014 00:42:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43447 invoked by uid 500); 21 Oct 2014 00:42:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43428 invoked by uid 99); 21 Oct 2014 00:42:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:42:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of freeman.jeremy@gmail.com designates 209.85.216.43 as permitted sender)
Received: from [209.85.216.43] (HELO mail-qa0-f43.google.com) (209.85.216.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 00:42:46 +0000
Received: by mail-qa0-f43.google.com with SMTP id j7so118818qaq.16
        for <dev@spark.apache.org>; Mon, 20 Oct 2014 17:42:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to;
        bh=FIA4VqJZd5rIXZ6p85H6jlDIDIgi6JKyr7CgC64x658=;
        b=VOQbngcO4TDrl2SpJcMItGd7rjmAoFlfy/iPNxThP7N7tIWoYNqU09WXWFNTNm/aNi
         U+L8Uioqt+hIZRYmbxEuxHLGlGxpS8qjMvuotLc/19cWxeNfTjImR+5dEBo86G3qFLk8
         QxTBN5QW+pyn+9WubWt/XL38fENLp4kJxcLHgKsQbvwQFV+IyhCwvfmbcEZT9nmAR5/v
         bAiNalySXEQ817FGTH8kc9D2kMXrg9QChITCXE+mRk445x/5VgsZbCoH1kjcZICy3lnc
         rSGit6PMvIpu9hJAW8xHVR1v230fnGk3Zq0QhUz7a+OzQ2AtfRxNkCNLmdeZAe8L1Z6v
         JBZg==
X-Received: by 10.224.66.7 with SMTP id l7mr40612707qai.71.1413852145353;
        Mon, 20 Oct 2014 17:42:25 -0700 (PDT)
Received: from solaire.home (pool-71-171-84-41.clppva.fios.verizon.net. [71.171.84.41])
        by mx.google.com with ESMTPSA id s10sm9359457qac.14.2014.10.20.17.42.23
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Mon, 20 Oct 2014 17:42:24 -0700 (PDT)
Content-Type: multipart/alternative; boundary="Apple-Mail=_FB7F6EB2-4CDC-4A0F-969C-CC79F4565B53"
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: Building and Running Spark on OS X
From: Jeremy Freeman <freeman.jeremy@gmail.com>
In-Reply-To: <CAOhmDzc8E3UxSmjjNGzsTJpxFvJ8GV2gzU-2YGHsi0XGsKCFhg@mail.gmail.com>
Date: Mon, 20 Oct 2014 20:42:22 -0400
Cc: Sean Owen <sowen@cloudera.com>,
 Hari Shreedharan <hshreedharan@cloudera.com>,
 dev <dev@spark.apache.org>,
 Reynold Xin <rxin@databricks.com>
Message-Id: <B1FB9930-EB76-4189-B0C4-E899CFFC17E3@gmail.com>
References: <CAMAsSd+wsSY6ZHw+ZCDbn374DS_pwddDu4UHm8iFP6rr_KL8iw@mail.gmail.com> <1413850841116.1cbbe293@Nodemailer> <CAMAsSdKWHh3Z+PBHUqhvmgY-mmLO-BUS8p5hLgquk5H812V0=g@mail.gmail.com> <CAOhmDzc8E3UxSmjjNGzsTJpxFvJ8GV2gzU-2YGHsi0XGsKCFhg@mail.gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail=_FB7F6EB2-4CDC-4A0F-969C-CC79F4565B53
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=windows-1252

I also prefer sbt on Mac.

You might want to add checking for / getting Python 2.6+ (though most =
modern Macs should have it), and maybe numpy as an optional dependency. =
I often just point people to Anaconda.

=97 Jeremy

-------------------------
jeremyfreeman.net
@thefreemanlab

On Oct 20, 2014, at 8:28 PM, Nicholas Chammas =
<nicholas.chammas@gmail.com> wrote:

> So back to my original question... :)
>=20
> If we wanted to post this guide to the user list or to a gist for easy
> reference, would we rather have Maven or SBT listed? And is there =
anything
> else about the steps that should be modified?
>=20
> Nick
>=20
> On Mon, Oct 20, 2014 at 8:25 PM, Sean Owen <sowen@cloudera.com> wrote:
>=20
>> Oh right, we're talking about the bundled sbt of course.
>> And I didn't know Maven wasn't installed anymore!
>>=20
>> On Mon, Oct 20, 2014 at 8:20 PM, Hari Shreedharan
>> <hshreedharan@cloudera.com> wrote:
>>> The sbt executable that is in the spark repo can be used to build =
sbt
>>> without any other set up (it will download the sbt jars etc).
>>>=20
>>> Thanks,
>>> Hari
>>>=20
>>=20


--Apple-Mail=_FB7F6EB2-4CDC-4A0F-969C-CC79F4565B53--

From dev-return-9906-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 11:42:42 2014
Return-Path: <dev-return-9906-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0935017277
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 11:42:42 +0000 (UTC)
Received: (qmail 44982 invoked by uid 500); 21 Oct 2014 11:42:41 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 44904 invoked by uid 500); 21 Oct 2014 11:42:41 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 44888 invoked by uid 99); 21 Oct 2014 11:42:40 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 11:42:40 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.223.175 as permitted sender)
Received: from [209.85.223.175] (HELO mail-ie0-f175.google.com) (209.85.223.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 11:42:14 +0000
Received: by mail-ie0-f175.google.com with SMTP id at20so978714iec.34
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 04:41:28 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=yyc9KRqNx9FM3woNwSh7uB00Su2G4hgnBWWnRC7bRfQ=;
        b=mb7Yz/qC8cqWMyzU+d2xnJrNArZnMq6VSGDksrqfrMTaGpaX4eFvlReI+71gOawN36
         b2JHvitYlhCVgQCSP7xLLsRHuYeW7npF/Sff/fikef87iE/caIupHOYt/1qjeWAQ+iFb
         lfu7sDn+DOdSuFzLHN/mh6BWmzU8l+s3MIRNxsQMZeb26wuRLS5ibvSc+D5u/EDjMhQI
         IdB3XOQ9nZSpixGp5Kcu0Q+ddIAcZmhzrfr+Y5TmD7sGElGmOmJg506ZkrRhEIvZIUxu
         47cMdi6S/YwOhlA6Z4WG75AFE30qOyEJjTkoZXE6kVLxgXD9iMjxOIQw+TXU2gtdn+AR
         dkCQ==
X-Gm-Message-State: ALoCoQmqYU+QLOCCad8FyOPqBCcrH2AGG4PkyblKRUZKjifK3LehlLbLc3QKA+PuRIdV6pAlpNh5
X-Received: by 10.50.41.34 with SMTP id c2mr25620889igl.5.1413891687800; Tue,
 21 Oct 2014 04:41:27 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Tue, 21 Oct 2014 04:41:07 -0700 (PDT)
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 21 Oct 2014 07:41:07 -0400
Message-ID: <CAMAsSd+5oxJLnOj32QuZczJBkbBFszCksVDP1qP6gfXapg_42g@mail.gmail.com>
Subject: Easy win: SBT plugin config expert to help on SPARK-3359?
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

This one can be resolved, I think, with a bit of help from someone who
understands SBT + plugin config:

https://issues.apache.org/jira/browse/SPARK-3359

Just a matter of figuring out how to set a property on the plugin.
This would make Java 8 javadoc work much more nicely. Minor but
useful!

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9907-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 12:32:05 2014
Return-Path: <dev-return-9907-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5C5A417409
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 12:32:05 +0000 (UTC)
Received: (qmail 22718 invoked by uid 500); 21 Oct 2014 12:32:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22642 invoked by uid 500); 21 Oct 2014 12:32:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22627 invoked by uid 99); 21 Oct 2014 12:32:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 12:32:03 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.44 as permitted sender)
Received: from [209.85.220.44] (HELO mail-pa0-f44.google.com) (209.85.220.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 12:31:59 +0000
Received: by mail-pa0-f44.google.com with SMTP id et14so1312806pad.17
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 05:30:53 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type;
        bh=fqLmW8hemGgpjWXcO/bPVxL8Ys99x0cHdfCBboqtj1k=;
        b=xYrMWyeK/e4E6glSsmcp+nbjlbgqCb0cxrrgU+zzUPCBb2uPfB4r0xiIdExh6mORDW
         7IdMWdx2UipxgWWY1KcMOYB/i9RSNHEpuG0yy4ECfUKQxJO/l/HvK9wyrkcX+QHKHAgZ
         vfQNVLN/dAClNiUsM2US1/5z74HYzjzFXOci+LZPapRV+hP0uOcUbxk93SyknHY5WnSi
         RSow1Q0V3SlyBBrlh1YxtpC5qdH8nGx0Gbqp7NSBQBlNq0B12p03r38It+pvQcbJ8lVm
         eh0YVhA9m9ogR/A+QefWxRy6gKjoagAHmGr+7+K0JCz3xg1RrJu2u1z4ApT1Wu7DTthA
         CRYA==
X-Received: by 10.70.140.4 with SMTP id rc4mr35062909pdb.108.1413894653693;
        Tue, 21 Oct 2014 05:30:53 -0700 (PDT)
Received: from lian-laptop.local ([60.166.130.27])
        by mx.google.com with ESMTPSA id hm1sm11823758pdb.84.2014.10.21.05.30.47
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 21 Oct 2014 05:30:52 -0700 (PDT)
Message-ID: <544651F3.1050006@gmail.com>
Date: Tue, 21 Oct 2014 20:30:43 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: shane knapp <sknapp@berkeley.edu>, 
 Patrick Wendell <pwendell@gmail.com>
CC: Nan Zhu <zhunanmcgill@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: something wrong with Jenkins or something untested merged?
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com> <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com> <AFBB584B386748008FF81312D2A24C39@gmail.com> <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com> <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com> <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
In-Reply-To: <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
Content-Type: multipart/alternative;
 boundary="------------000006070700070801010906"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------000006070700070801010906
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

Hm, seems that 7u71 comes back again. Observed similar Kinesis 
compilation error just now: 
https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBuilder/410/consoleFull

Checked Jenkins slave nodes, saw /usr/java/latest points to jdk1.7.0_71. 
However, /usr/bin/javac -version says:

    Eclipse Java Compiler 0.894_R34x, 3.4.2 release, Copyright IBM Corp
    2000, 2008. All rights reserved.

Which JDK is actually used by Jenkins?

Cheng

On 10/21/14 8:28 AM, shane knapp wrote:

> ok, so earlier today i installed a 2nd JDK within jenkins (7u71), which
> fixed the SparkR build but apparently made Spark itself quite unhappy.  i
> removed that JDK, triggered a build (
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
> and it compiled kinesis w/o dying a fiery death.
>
> apparently 7u71 is stricter when compiling.  sad times.
>
> sorry about that!
>
> shane
>
>
> On Mon, Oct 20, 2014 at 5:16 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>
>> The failure is in the Kinesis compoent, can you reproduce this if you
>> build with -Pkinesis-asl?
>>
>> - Patrick
>>
>> On Mon, Oct 20, 2014 at 5:08 PM, shane knapp <sknapp@berkeley.edu> wrote:
>>> hmm, strange.  i'll take a look.
>>>
>>> On Mon, Oct 20, 2014 at 5:11 PM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>>>
>>>> yes, I can compile locally, too
>>>>
>>>> but it seems that Jenkins is not happy now...
>>>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
>>>>
>>>> All failed to compile
>>>>
>>>> Best,
>>>>
>>>> --
>>>> Nan Zhu
>>>>
>>>>
>>>> On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:
>>>>
>>>>> I performed build on latest master branch but didn't get compilation
>>>> error.
>>>>> FYI
>>>>>
>>>>> On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com
>>>> (mailto:zhunanmcgill@gmail.com)> wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I just submitted a patch
>>>> https://github.com/apache/spark/pull/2864/files
>>>>>> with one line change
>>>>>>
>>>>>> but the Jenkins told me it's failed to compile on the unrelated
>> files?
>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>>>>>> Best,
>>>>>>
>>>>>> Nan



--------------000006070700070801010906--

From dev-return-9908-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 13:19:57 2014
Return-Path: <dev-return-9908-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 157D61754E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 13:19:57 +0000 (UTC)
Received: (qmail 23813 invoked by uid 500); 21 Oct 2014 13:19:54 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23735 invoked by uid 500); 21 Oct 2014 13:19:54 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23215 invoked by uid 99); 21 Oct 2014 13:19:54 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 13:19:54 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.216.49 as permitted sender)
Received: from [209.85.216.49] (HELO mail-qa0-f49.google.com) (209.85.216.49)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 13:19:49 +0000
Received: by mail-qa0-f49.google.com with SMTP id f12so769544qad.8
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 06:19:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=1Fs49Csvhq7k3Q/td9oL/RN4r83/X1LNfazt3o+DtJA=;
        b=Yl26oPxrHU6RDB951d7QFMNeTCqtxz6K3NKjOlYDC+a33XhI7n0G5rfKHdDVapzPNo
         EvB4HAxlIIbrYQAeyMZQHpfNqfRPZ8karY/hWdAGu9U/iuswP60MwJtJ8ljU0nT2fGTA
         ezlb7XwyxiliElGjHhn7O17GWsAQR+88So2n5ATacBGifuMlkAW1Lt/VitBwTBD3yr71
         FDakWMpWryY5M7zbtAhPNBe72diE1PjFove+4nxkTDDf8k0PZe2hRB3QgB9Rzn1bvyhP
         gJT6LbYa9QPp/tZUCjbQ8psRYmJL2MUO1vXNQ1SNdSUWHxLp20xDYJQZg5udCxUzAkia
         HjJg==
X-Received: by 10.224.47.2 with SMTP id l2mr30948948qaf.28.1413897562771;
        Tue, 21 Oct 2014 06:19:22 -0700 (PDT)
Received: from [192.168.1.146] (MTRLPQ02-1177746539.sdsl.bell.ca. [70.50.252.107])
        by mx.google.com with ESMTPSA id 94sm5101229qgg.33.2014.10.21.06.19.21
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 21 Oct 2014 06:19:22 -0700 (PDT)
Date: Tue, 21 Oct 2014 09:33:14 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: shane knapp <sknapp@berkeley.edu>, Patrick Wendell
 <pwendell@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
In-Reply-To: <544651F3.1050006@gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com>
 <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <544651F3.1050006@gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5446609a_721da317_221"
X-Virus-Checked: Checked by ClamAV on apache.org

--5446609a_721da317_221
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

just curious=E2=80=A6what is this =E2=80=9CNewSparkPullRequestBuilder=E2=80=
=9D=3F =20

Best, =20

-- =20
Nan Zhu


On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:

> =20
> Hm, seems that 7u71 comes back again. Observed similar Kinesis compilat=
ion error just now: https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPu=
llRequestBuilder/410/console=46ull
> =20
> =20
> Checked Jenkins slave nodes, saw /usr/java/latest points to jdk1.7.0=5F=
71. However, /usr/bin/javac -version says:
> =20
> > =20
> > Eclipse Java Compiler 0.894=5FR34x, 3.4.2 release, Copyright IBM Corp=
 2000, 2008. All rights reserved.
> > =20
> =20
> =20
> Which JDK is actually used by Jenkins=3F
> =20
> =20
> Cheng
> =20
> =20
> On 10/21/14 8:28 AM, shane knapp wrote:
> =20
> =20
> =20
> =20
> =20
> > ok, so earlier today i installed a 2nd JDK within jenkins (7u71), whi=
ch fixed the SparkR build but apparently made Spark itself quite unhappy.=
 i removed that JDK, triggered a build ( https://amplab.cs.berkeley.edu/j=
enkins/job/SparkPullRequestBuilder/21943/console), and it compiled kinesi=
s w/o dying a fiery death. apparently 7u71 is stricter when compiling. sa=
d times. sorry about that=21 shane On Mon, Oct 20, 2014 at 5:16 PM, Patri=
ck Wendell <pwendell=40gmail.com> (mailto:pwendell=40gmail.com) wrote: =20
> > > The failure is in the Kinesis compoent, can you reproduce this if y=
ou build with -Pkinesis-asl=3F - Patrick On Mon, Oct 20, 2014 at 5:08 PM,=
 shane knapp <sknapp=40berkeley.edu> (mailto:sknapp=40berkeley.edu) wrote=
: =20
> > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at 5:11 PM, =
Nan Zhu <zhunanmcgill=40gmail.com> (mailto:zhunanmcgill=40gmail.com) wrot=
e: =20
> > > > > yes, I can compile locally, too but it seems that Jenkins is no=
t happy now... https://amplab.cs.berkeley.edu/jenkins/job/SparkPullReques=
tBuilder/ All failed to compile Best, -- Nan Zhu On Monday, October 20, 2=
014 at 7:56 PM, Ted Yu wrote: =20
> > > > > > I performed build on latest master branch but didn't get comp=
ilation =20
> > > > > > =20
> > > > > =20
> > > > > error. =20
> > > > > > =46YI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill=40=
gmail.com (mailto:zhunanmcgill=40gmail.com) =20
> > > > > > =20
> > > > > =20
> > > > > (mailto:zhunanmcgill=40gmail.com)> wrote: =20
> > > > > > > Hi, I just submitted a patch =20
> > > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > https://github.com/apache/spark/pull/2864/files =20
> > > > > > > with one line change but the Jenkins told me it's failed to=
 compile on the unrelated =20
> > > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > =20
> > > > =20
> > > > =20
> > > =20
> > > files=3F =20
> > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > =20
> > > =20
> > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/=
21935/console =20
> > > > > > > Best, Nan =20
> > > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > =20
> > > =20
> > > =20
> > > =20
> > =20
> > =20
> > =20
> =20
> =20
> =20
> =20
> =20
> =20
> =E2=80=8B
> =20
> =20
> =20



--5446609a_721da317_221--


From dev-return-9909-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 13:23:25 2014
Return-Path: <dev-return-9909-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3A89917563
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 13:23:25 +0000 (UTC)
Received: (qmail 32505 invoked by uid 500); 21 Oct 2014 13:23:23 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32435 invoked by uid 500); 21 Oct 2014 13:23:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32423 invoked by uid 99); 21 Oct 2014 13:23:22 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 13:23:22 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.42 as permitted sender)
Received: from [209.85.220.42] (HELO mail-pa0-f42.google.com) (209.85.220.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 13:22:56 +0000
Received: by mail-pa0-f42.google.com with SMTP id bj1so1411716pad.29
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 06:22:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type;
        bh=fHMs81x4ugqYHoQ1LMwn3fzo2daoY1LMA2f10vqFSQA=;
        b=apLR8MxwFJhJHUey9wRpXCDCg7kfJY81o5uebqDiujj6bufel+V/jkaeXzEtxlCf+A
         p5dbgX05VSk+nr5FyrwBjuisWOTKZiCoyADxdNghBqoQgygm67x1V6Eb8m44HEnC+cqt
         ouM5s3jb8V4iSIKtOsqa4tPKO3BK6ouB+r3aNyP/8tcSVds9V+YXSCAbM0w9JnRsBJhX
         5TyzD5CIllZhq0wPc+uFxQQ3B3YzlYxYRu4jhNjOJj7wuQL/1fJoMple1hJcUKfEFeql
         PKe3kPPfeY026WmGMd5yRa0S3xKy/7XfqCKjF0MnFbfCgCQe26WteGeGewnm2hs2Stq4
         qXDw==
X-Received: by 10.70.36.3 with SMTP id m3mr34770315pdj.53.1413897774606;
        Tue, 21 Oct 2014 06:22:54 -0700 (PDT)
Received: from lian-laptop.local ([60.166.130.27])
        by mx.google.com with ESMTPSA id rf5sm11987462pdb.16.2014.10.21.06.22.44
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 21 Oct 2014 06:22:53 -0700 (PDT)
Message-ID: <54465E1D.1000301@gmail.com>
Date: Tue, 21 Oct 2014 21:22:37 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.1.2
MIME-Version: 1.0
To: Nan Zhu <zhunanmcgill@gmail.com>
CC: shane knapp <sknapp@berkeley.edu>, 
 Patrick Wendell <pwendell@gmail.com>,
 Ted Yu <yuzhihong@gmail.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: something wrong with Jenkins or something untested merged?
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com> <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com> <AFBB584B386748008FF81312D2A24C39@gmail.com> <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com> <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com> <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com> <544651F3.1050006@gmail.com> <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
In-Reply-To: <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
Content-Type: multipart/alternative;
 boundary="------------020701040400090306020604"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------020701040400090306020604
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

It's a new pull request builder written by Josh, integrated into our 
state-of-the-art PR dashboard :)

On 10/21/14 9:33 PM, Nan Zhu wrote:
> just curiouswhat is this NewSparkPullRequestBuilder?
>
> Best,
>
> -- 
> Nan Zhu
>
> On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:
>
>> Hm, seems that 7u71 comes back again. Observed similar Kinesis 
>> compilation error just now: 
>> https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBuilder/410/consoleFull
>>
>> Checked Jenkins slave nodes, saw /usr/java/latest points to 
>> jdk1.7.0_71. However, /usr/bin/javac -version says:
>>
>>     Eclipse Java Compiler 0.894_R34x, 3.4.2 release, Copyright IBM
>>     Corp 2000, 2008. All rights reserved.
>>
>> Which JDK is actually used by Jenkins?
>>
>> Cheng
>>
>> On 10/21/14 8:28 AM, shane knapp wrote:
>>
>>> ok, so earlier today i installed a 2nd JDK within jenkins (7u71), which
>>> fixed the SparkR build but apparently made Spark itself quite unhappy.  i
>>> removed that JDK, triggered a build (
>>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
>>> and it compiled kinesis w/o dying a fiery death.
>>>
>>> apparently 7u71 is stricter when compiling.  sad times.
>>>
>>> sorry about that!
>>>
>>> shane
>>>
>>>
>>> On Mon, Oct 20, 2014 at 5:16 PM, Patrick Wendell<pwendell@gmail.com>  <mailto:pwendell@gmail.com>  wrote:
>>>
>>>> The failure is in the Kinesis compoent, can you reproduce this if you
>>>> build with -Pkinesis-asl?
>>>>
>>>> - Patrick
>>>>
>>>> On Mon, Oct 20, 2014 at 5:08 PM, shane knapp<sknapp@berkeley.edu>  <mailto:sknapp@berkeley.edu>  wrote:
>>>>> hmm, strange.  i'll take a look.
>>>>>
>>>>> On Mon, Oct 20, 2014 at 5:11 PM, Nan Zhu<zhunanmcgill@gmail.com>  <mailto:zhunanmcgill@gmail.com>  wrote:
>>>>>
>>>>>> yes, I can compile locally, too
>>>>>>
>>>>>> but it seems that Jenkins is not happy now...
>>>>>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/
>>>>>>
>>>>>> All failed to compile
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> --
>>>>>> Nan Zhu
>>>>>>
>>>>>>
>>>>>> On Monday, October 20, 2014 at 7:56 PM, Ted Yu wrote:
>>>>>>
>>>>>>> I performed build on latest master branch but didn't get compilation
>>>>>> error.
>>>>>>> FYI
>>>>>>>
>>>>>>> On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgill@gmail.com  <mailto:zhunanmcgill@gmail.com>
>>>>>> (mailto:zhunanmcgill@gmail.com)> wrote:
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I just submitted a patch
>>>>>> https://github.com/apache/spark/pull/2864/files
>>>>>>>> with one line change
>>>>>>>>
>>>>>>>> but the Jenkins told me it's failed to compile on the unrelated
>>>> files?
>>>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>>>>>>>> Best,
>>>>>>>>
>>>>>>>> Nan
>> 
>


--------------020701040400090306020604--

From dev-return-9910-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 13:26:29 2014
Return-Path: <dev-return-9910-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 932F21756D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 13:26:29 +0000 (UTC)
Received: (qmail 35767 invoked by uid 500); 21 Oct 2014 13:26:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35698 invoked by uid 500); 21 Oct 2014 13:26:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35686 invoked by uid 99); 21 Oct 2014 13:26:27 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 13:26:27 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.192.41 as permitted sender)
Received: from [209.85.192.41] (HELO mail-qg0-f41.google.com) (209.85.192.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 13:26:23 +0000
Received: by mail-qg0-f41.google.com with SMTP id a108so834057qge.0
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 06:25:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=lWG7ohBCtBOny4VI+cEWeu9tppIm9iouNc+IB0dWwaU=;
        b=sfK+Iai+IEFodd4mhOrpMkiaFz8vnApwgqruFR6ClOrOonWPJnlZq744BxJNi8YqR9
         W03jQfO9ELJwN9r9Rm/n0dMW/i9EZI0LW+Z4jje5RbvL/HAW3t8y0b35uw5MwZydbvVS
         Rad0y09/mhwVdTY0+F5E0zCMo59NNFBCo75F3egBu4i7jv9drP6hcryNpJ4JtfCCdhUl
         BBAojBpFySk4R/XSEpSCML7a6iTe0fp8gal7tLiWPxkkg7XCuQP/6JKoiFrkd/Dk5KRM
         SI1j7rIVJHN8dbLMnlJga/u/u1WGKtn+9ancs2HIgu2U0tqhhDu/BDXA0CHlvw9Cs3D4
         ldVg==
X-Received: by 10.224.168.8 with SMTP id s8mr13508036qay.102.1413897917751;
        Tue, 21 Oct 2014 06:25:17 -0700 (PDT)
Received: from [192.168.1.146] (MTRLPQ02-1177746539.sdsl.bell.ca. [70.50.252.107])
        by mx.google.com with ESMTPSA id d68sm10667014qga.17.2014.10.21.06.25.16
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 21 Oct 2014 06:25:17 -0700 (PDT)
Date: Tue, 21 Oct 2014 09:39:11 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: shane knapp <sknapp@berkeley.edu>, Patrick Wendell
 <pwendell@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
In-Reply-To: <54465E1D.1000301@gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com>
 <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <544651F3.1050006@gmail.com> <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
 <54465E1D.1000301@gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="544661ff_189a769b_221"
X-Virus-Checked: Checked by ClamAV on apache.org

--544661ff_189a769b_221
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

seems that all PRs built by NewSparkPRBuilder suffers from 7u71, while Sp=
arkPRBuilder is working fine

Best, =20

-- =20
Nan Zhu


On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote:

> It's a new pull request builder written by Josh, integrated into our st=
ate-of-the-art PR dashboard :)
> =20
> On 10/21/14 9:33 PM, Nan Zhu wrote:
> > just curious=E2=80=A6what is this =E2=80=9CNewSparkPullRequestBuilder=
=E2=80=9D=3F =20
> > =20
> > Best, =20
> > =20
> > --  =20
> > Nan Zhu
> > =20
> > =20
> > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:
> > =20
> > > =20
> > > Hm, seems that 7u71 comes back again. Observed similar Kinesis comp=
ilation error just now: https://amplab.cs.berkeley.edu/jenkins/job/NewSpa=
rkPullRequestBuilder/410/console=46ull
> > > =20
> > > =20
> > > Checked Jenkins slave nodes, saw /usr/java/latest points to jdk1.7.=
0=5F71. However, /usr/bin/javac -version says:
> > > =20
> > > > =20
> > > > Eclipse Java Compiler 0.894=5FR34x, 3.4.2 release, Copyright IBM =
Corp 2000, 2008. All rights reserved.
> > > > =20
> > > =20
> > > =20
> > > Which JDK is actually used by Jenkins=3F
> > > =20
> > > =20
> > > Cheng
> > > =20
> > > =20
> > > On 10/21/14 8:28 AM, shane knapp wrote:
> > > =20
> > > > ok, so earlier today i installed a 2nd JDK within jenkins (7u71),=
 which fixed the SparkR build but apparently made Spark itself quite unha=
ppy. i removed that JDK, triggered a build ( https://amplab.cs.berkeley.e=
du/jenkins/job/SparkPullRequestBuilder/21943/console), and it compiled ki=
nesis w/o dying a fiery death. apparently 7u71 is stricter when compiling=
. sad times. sorry about that=21 shane On Mon, Oct 20, 2014 at 5:16 PM, P=
atrick Wendell <pwendell=40gmail.com> (mailto:pwendell=40gmail.com) wrote=
: =20
> > > > > The failure is in the Kinesis compoent, can you reproduce this =
if you build with -Pkinesis-asl=3F - Patrick On Mon, Oct 20, 2014 at 5:08=
 PM, shane knapp <sknapp=40berkeley.edu> (mailto:sknapp=40berkeley.edu) w=
rote: =20
> > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at 5:11 =
PM, Nan Zhu <zhunanmcgill=40gmail.com> (mailto:zhunanmcgill=40gmail.com) =
wrote: =20
> > > > > > > yes, I can compile locally, too but it seems that Jenkins i=
s not happy now... https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRe=
questBuilder/ All failed to compile Best, -- Nan Zhu On Monday, October 2=
0, 2014 at 7:56 PM, Ted Yu wrote: =20
> > > > > > > > I performed build on latest master branch but didn't get =
compilation =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > > error. =20
> > > > > > > > =46YI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcg=
ill=40gmail.com (mailto:zhunanmcgill=40gmail.com) =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > > (mailto:zhunanmcgill=40gmail.com)> wrote: =20
> > > > > > > > > Hi, I just submitted a patch =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > > https://github.com/apache/spark/pull/2864/files =20
> > > > > > > > > with one line change but the Jenkins told me it's faile=
d to compile on the unrelated =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > files=3F =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuil=
der/21935/console =20
> > > > > > > > > Best, Nan =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > =20
> > > > =20
> > > > =20
> > > =20
> > > =20
> > > =E2=80=8B
> > > =20
> > > =20
> > > =20
> > > =20
> > =20
> > =20
> =20


--544661ff_189a769b_221--


From dev-return-9911-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 13:35:39 2014
Return-Path: <dev-return-9911-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CE524175B0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 13:35:39 +0000 (UTC)
Received: (qmail 64544 invoked by uid 500); 21 Oct 2014 13:35:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 64424 invoked by uid 500); 21 Oct 2014 13:35:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63731 invoked by uid 99); 21 Oct 2014 13:35:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 13:35:37 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.192.43 as permitted sender)
Received: from [209.85.192.43] (HELO mail-qg0-f43.google.com) (209.85.192.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 13:35:32 +0000
Received: by mail-qg0-f43.google.com with SMTP id j107so840114qga.30
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 06:34:27 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=e5/4outNzFovDKRfbfxp0iT1KbOt9iqOmXJ+7ybH1sk=;
        b=SiDj25eoN4Jjj4DobTNkoev5FXgO3VbKvEBR642wPS8eYOsgIMEXSVehvA3HZPsD8P
         I1JWmxMiOeTuSy6j4UnqaIFfK6EBFi1oBHHUMNW1vwsoti3QC3Zu4z0CUEF5e8LRZiPh
         ciQprwjr+B6pDIasCuaicJBToJZYJ9Y03i/HNt9iuX9itRKEfdmTA4LXtFVcJlxGfnG1
         8sEqot6dBDvD6xYbtPJjV4fFWz/axO0p5+9ZJCtuyyXR3HFouXnENHQoXIV4+RWbSHHM
         f6V9cXFn2VskTBhHDIctjqBTU4837JRWLxl2xvROECct5J+TDxipWKay4ipW2mNFqNzn
         ullg==
X-Received: by 10.229.124.9 with SMTP id s9mr45922616qcr.15.1413898465795;
        Tue, 21 Oct 2014 06:34:25 -0700 (PDT)
Received: from [192.168.1.146] ([70.50.252.107])
        by mx.google.com with ESMTPSA id n46sm10694499qgn.9.2014.10.21.06.34.24
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Tue, 21 Oct 2014 06:34:25 -0700 (PDT)
Date: Tue, 21 Oct 2014 09:48:15 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: shane knapp <sknapp@berkeley.edu>, Patrick Wendell
 <pwendell@gmail.com>, Ted Yu <yuzhihong@gmail.com>, 
 "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>
Message-ID: <F851301989FB43DFA027184738D534EE@gmail.com>
In-Reply-To: <06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com>
 <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <544651F3.1050006@gmail.com> <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
 <54465E1D.1000301@gmail.com> <06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5446641f_5c482a97_221"
X-Virus-Checked: Checked by ClamAV on apache.org

--5446641f_5c482a97_221
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

weird=E2=80=A6..two buildings (one triggered by New, one triggered by Old=
) were executed in the same node, amp-jenkins-slave-01, one compiles, one=
 not=E2=80=A6

Best, =20

-- =20
Nan Zhu


On Tuesday, October 21, 2014 at 9:39 AM, Nan Zhu wrote:

> seems that all PRs built by NewSparkPRBuilder suffers from 7u71, while =
SparkPRBuilder is working fine
> =20
> Best, =20
> =20
> -- =20
> Nan Zhu
> =20
> =20
> On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote:
> =20
> > It's a new pull request builder written by Josh, integrated into our =
state-of-the-art PR dashboard :)
> > =20
> > On 10/21/14 9:33 PM, Nan Zhu wrote:
> > > just curious=E2=80=A6what is this =E2=80=9CNewSparkPullRequestBuild=
er=E2=80=9D=3F =20
> > > =20
> > > Best, =20
> > > =20
> > > --  =20
> > > Nan Zhu
> > > =20
> > > =20
> > > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:
> > > =20
> > > > =20
> > > > Hm, seems that 7u71 comes back again. Observed similar Kinesis co=
mpilation error just now: https://amplab.cs.berkeley.edu/jenkins/job/NewS=
parkPullRequestBuilder/410/console=46ull
> > > > =20
> > > > =20
> > > > Checked Jenkins slave nodes, saw /usr/java/latest points to jdk1.=
7.0=5F71. However, /usr/bin/javac -version says:
> > > > =20
> > > > > =20
> > > > > Eclipse Java Compiler 0.894=5FR34x, 3.4.2 release, Copyright IB=
M Corp 2000, 2008. All rights reserved.
> > > > > =20
> > > > =20
> > > > =20
> > > > Which JDK is actually used by Jenkins=3F
> > > > =20
> > > > =20
> > > > Cheng
> > > > =20
> > > > =20
> > > > On 10/21/14 8:28 AM, shane knapp wrote:
> > > > =20
> > > > > ok, so earlier today i installed a 2nd JDK within jenkins (7u71=
), which fixed the SparkR build but apparently made Spark itself quite un=
happy. i removed that JDK, triggered a build ( https://amplab.cs.berkeley=
.edu/jenkins/job/SparkPullRequestBuilder/21943/console), and it compiled =
kinesis w/o dying a fiery death. apparently 7u71 is stricter when compili=
ng. sad times. sorry about that=21 shane On Mon, Oct 20, 2014 at 5:16 PM,=
 Patrick Wendell <pwendell=40gmail.com> (mailto:pwendell=40gmail.com) wro=
te: =20
> > > > > > The failure is in the Kinesis compoent, can you reproduce thi=
s if you build with -Pkinesis-asl=3F - Patrick On Mon, Oct 20, 2014 at 5:=
08 PM, shane knapp <sknapp=40berkeley.edu> (mailto:sknapp=40berkeley.edu)=
 wrote: =20
> > > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at 5:1=
1 PM, Nan Zhu <zhunanmcgill=40gmail.com> (mailto:zhunanmcgill=40gmail.com=
) wrote: =20
> > > > > > > > yes, I can compile locally, too but it seems that Jenkins=
 is not happy now... https://amplab.cs.berkeley.edu/jenkins/job/SparkPull=
RequestBuilder/ All failed to compile Best, -- Nan Zhu On Monday, October=
 20, 2014 at 7:56 PM, Ted Yu wrote: =20
> > > > > > > > > I performed build on latest master branch but didn't ge=
t compilation =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > error. =20
> > > > > > > > > =46YI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanm=
cgill=40gmail.com (mailto:zhunanmcgill=40gmail.com) =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > (mailto:zhunanmcgill=40gmail.com)> wrote: =20
> > > > > > > > > > Hi, I just submitted a patch =20
> > > > > > > > > > =20
> > > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > https://github.com/apache/spark/pull/2864/files =20
> > > > > > > > > > with one line change but the Jenkins told me it's fai=
led to compile on the unrelated =20
> > > > > > > > > > =20
> > > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > > files=3F =20
> > > > > > > > > > =20
> > > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBu=
ilder/21935/console =20
> > > > > > > > > > Best, Nan =20
> > > > > > > > > > =20
> > > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > =20
> > > > =20
> > > > =E2=80=8B
> > > > =20
> > > > =20
> > > > =20
> > > > =20
> > > =20
> > > =20
> > =20
> =20


--5446641f_5c482a97_221--


From dev-return-9912-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 16:26:27 2014
Return-Path: <dev-return-9912-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3391D17C3D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 16:26:27 +0000 (UTC)
Received: (qmail 10810 invoked by uid 500); 21 Oct 2014 16:26:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10734 invoked by uid 500); 21 Oct 2014 16:26:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 94303 invoked by uid 99); 21 Oct 2014 09:23:29 -0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Date: Tue, 21 Oct 2014 02:23:00 -0700 (PDT)
From: Ashutosh <ashutosh.trivedi@iiitb.org>
To: dev@spark.incubator.apache.org
Message-ID: <1413883380883-8880.post@n3.nabble.com>
Subject: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,
I am new to Apache Spark (any open source project). I want to contribute to
it. I found that MLlib has no algorithm for outlier detection yet.  By
literature review I found the algorithm Attribute Value Frequency (AVF) is
promising. Here is the link  DOI: 10.1109/ICTAI.2007.125

By following the process I figured out that, I have to open a new feature
request at JIRA (https://issues.apache.org/jira/browse/SPARK). Also, I have
checked that no other issue is opened on "outlier detection".

I want to know is it the right way to go? What project owners have in mind
about outlier detection? Also is anybody working on parallel K nearest
neighbour?

Apart from opening up the feature request then pull request from git, How to
provide the test cases? 

Suggestions and guidance are welcome.

Thanks,
Ashutosh 



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9913-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 16:41:11 2014
Return-Path: <dev-return-9913-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D83C417CC7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 16:41:11 +0000 (UTC)
Received: (qmail 48629 invoked by uid 500); 21 Oct 2014 16:41:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48556 invoked by uid 500); 21 Oct 2014 16:41:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48544 invoked by uid 99); 21 Oct 2014 16:41:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 16:41:10 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.223.175 as permitted sender)
Received: from [209.85.223.175] (HELO mail-ie0-f175.google.com) (209.85.223.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 16:41:06 +0000
Received: by mail-ie0-f175.google.com with SMTP id at20so1611873iec.20
        for <dev@spark.incubator.apache.org>; Tue, 21 Oct 2014 09:40:00 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=eMxMnrc1+oHq7DXy0M995nRuXQ8DbYUb41YQMYeBL8k=;
        b=pWCWAxGfsY6Oe6dcJMXZ1dajlGhTOB11NLMvZkEXHuZH3FIGfPFUBFZJ/jgWVzPM4/
         orhkt7JB+dH0vT5Buila44qFH6IdYUhaRSCNV/cHDoRbHyNwKhKuRfY6qOArawpHGLh5
         SBU6raItVj2VuSPI4betUecjb5f0SrnThI4N/LG3fF+ZwxVyd3bAID8DFflHl7jnZUIy
         Mpva2WQNs3oby8vpSTjejhdZw2fhm8KdG5bcnNINlTMI3CqY67uOCSJ4rkYs+/0wqV+w
         mKWBvL3f9Bq9zH4CNZHa4QciPVC6+4pMfNUy1PocetXXpIEzqU6eaM22eUN0pUDoyg8E
         2C3A==
MIME-Version: 1.0
X-Received: by 10.107.11.210 with SMTP id 79mr37858438iol.18.1413909600495;
 Tue, 21 Oct 2014 09:40:00 -0700 (PDT)
Received: by 10.107.162.21 with HTTP; Tue, 21 Oct 2014 09:40:00 -0700 (PDT)
In-Reply-To: <1413883380883-8880.post@n3.nabble.com>
References: <1413883380883-8880.post@n3.nabble.com>
Date: Tue, 21 Oct 2014 09:40:00 -0700
Message-ID: <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
From: Xiangrui Meng <mengxr@gmail.com>
To: Ashutosh <ashutosh.trivedi@iiitb.org>
Cc: dev <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Ashutosh,

The process you described is correct, with details documented in
https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
. There is no outlier detection algorithm in MLlib. Before you start
coding, please open an JIRA and let's discuss which algorithms are
appropriate to include, because there are many outlier detection
algorithms. I'm not sure which one is general enough and easy to
implement in parallel. For example, I'm not familiar with the
algorithm you mentioned, while the one I'm familiar with is based on
leverage scores: http://en.wikipedia.org/wiki/Leverage_(statistics)

Best,
Xiangrui

On Tue, Oct 21, 2014 at 2:23 AM, Ashutosh <ashutosh.trivedi@iiitb.org> wrote:
> Hi,
> I am new to Apache Spark (any open source project). I want to contribute to
> it. I found that MLlib has no algorithm for outlier detection yet.  By
> literature review I found the algorithm Attribute Value Frequency (AVF) is
> promising. Here is the link  DOI: 10.1109/ICTAI.2007.125
>
> By following the process I figured out that, I have to open a new feature
> request at JIRA (https://issues.apache.org/jira/browse/SPARK). Also, I have
> checked that no other issue is opened on "outlier detection".
>
> I want to know is it the right way to go? What project owners have in mind
> about outlier detection? Also is anybody working on parallel K nearest
> neighbour?
>
> Apart from opening up the feature request then pull request from git, How to
> provide the test cases?
>
> Suggestions and guidance are welcome.
>
> Thanks,
> Ashutosh
>
>
>
> --
> View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9914-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 17:05:50 2014
Return-Path: <dev-return-9914-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 46BF417DA2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 17:05:50 +0000 (UTC)
Received: (qmail 21048 invoked by uid 500); 21 Oct 2014 17:05:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20976 invoked by uid 500); 21 Oct 2014 17:05:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20963 invoked by uid 99); 21 Oct 2014 17:05:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 17:05:47 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.220.45 as permitted sender)
Received: from [209.85.220.45] (HELO mail-pa0-f45.google.com) (209.85.220.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 17:05:43 +0000
Received: by mail-pa0-f45.google.com with SMTP id lj1so1803283pab.18
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 10:05:23 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=H7WuH9qFyk8bq5N0GJ/dcBeSRGDD6zHhQAtkYilsoEI=;
        b=ss025aVwA1fcCvD/MhCk29MDDcTqPgDXd8kCnmvafJeVjkl1rTw577H8Rfkw/sdjAO
         30TidXBq6+g1jBr7nSOQLoHJK6XyMPDfLpOWdcZaDc2mY86faggmp+VHU3U/xEf5SKnx
         6KfKRU7LtB0tyA352fwA/Uj6sCTNUTt3dUt76z/cZppBU0VTqJU3RHtCkrnXnnlYS+vP
         uvsOb5rMI7Rl6rBifs8sBqekua8JwfQe64OMS68iFo7cJUZq/rISDFagjW8Z04xu9M/a
         NGpmOeog2Bcq+mciaCvQle3UlMm+ZxqXNyMD38FeIPif+mmP32IjwybxfEEKcQE31SUP
         r5VA==
X-Received: by 10.70.100.6 with SMTP id eu6mr17079416pdb.120.1413911123045;
        Tue, 21 Oct 2014 10:05:23 -0700 (PDT)
Received: from joshs-mbp.att.net ([2602:306:cdd1:b10:21f5:cd91:af9e:de91])
        by mx.google.com with ESMTPSA id tc5sm12272153pbc.51.2014.10.21.10.05.18
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Tue, 21 Oct 2014 10:05:19 -0700 (PDT)
Date: Tue, 21 Oct 2014 10:05:17 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>, Cheng Lian
 <lian.cs.zju@gmail.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, Ted Yu
 <yuzhihong@gmail.com>, shane knapp <sknapp@berkeley.edu>, Patrick
 Wendell <pwendell@gmail.com>
Message-ID: <etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
In-Reply-To: <F851301989FB43DFA027184738D534EE@gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com>
 <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <544651F3.1050006@gmail.com> <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
 <54465E1D.1000301@gmail.com> <06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
 <F851301989FB43DFA027184738D534EE@gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
X-Mailer: Airmail Beta (269)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="5446924e_554365fc_107"
X-Virus-Checked: Checked by ClamAV on apache.org

--5446924e_554365fc_107
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

I find it concerning that there=E2=80=99s a JDK version that breaks out b=
uild, since we=E2=80=99re supposed to support Java 7. =C2=A0Is 7u71 an up=
grade or downgrade from the JDK that we used before=3F =C2=A0Is there an =
easy way to fix our build so that it compiles with 7u71=E2=80=99s stricte=
r settings=3F

I=E2=80=99m not sure why the =E2=80=9CNew=E2=80=9D PRB is failing here. =C2=
=A0It was originally created as a clone of the main pull request builder =
job. I checked the configuration history and confirmed that there aren=E2=
=80=99t any settings that we=E2=80=99ve forgotten to copy over (e.g. thei=
r configurations haven=E2=80=99t diverged), so I=E2=80=99m not sure what=E2=
=80=99s causing this.

- Josh

On October 21, 2014 at 6:35:39 AM, Nan Zhu (zhunanmcgill=40gmail.com) wro=
te:
weird=E2=80=A6..two buildings (one triggered by New, one triggered by Old=
) were executed in the same node, amp-jenkins-slave-01, one compiles, one=
 not=E2=80=A6 =20

Best, =20

-- =20
Nan Zhu =20


On Tuesday, October 21, 2014 at 9:39 AM, Nan Zhu wrote: =20

> seems that all PRs built by NewSparkPRBuilder suffers from 7u71, while =
SparkPRBuilder is working fine =20
> =20
> Best, =20
> =20
> -- =20
> Nan Zhu =20
> =20
> =20
> On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote: =20
> =20
> > It's a new pull request builder written by Josh, integrated into our =
state-of-the-art PR dashboard :) =20
> > =20
> > On 10/21/14 9:33 PM, Nan Zhu wrote: =20
> > > just curious=E2=80=A6what is this =E2=80=9CNewSparkPullRequestBuild=
er=E2=80=9D=3F =20
> > > =20
> > > Best, =20
> > > =20
> > > -- =20
> > > Nan Zhu =20
> > > =20
> > > =20
> > > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote: =20
> > > =20
> > > > =20
> > > > Hm, seems that 7u71 comes back again. Observed similar Kinesis co=
mpilation error just now: https://amplab.cs.berkeley.edu/jenkins/job/NewS=
parkPullRequestBuilder/410/console=46ull =20
> > > > =20
> > > > =20
> > > > Checked Jenkins slave nodes, saw /usr/java/latest points to jdk1.=
7.0=5F71. However, /usr/bin/javac -version says: =20
> > > > =20
> > > > > =20
> > > > > Eclipse Java Compiler 0.894=5FR34x, 3.4.2 release, Copyright IB=
M Corp 2000, 2008. All rights reserved. =20
> > > > > =20
> > > > =20
> > > > =20
> > > > Which JDK is actually used by Jenkins=3F =20
> > > > =20
> > > > =20
> > > > Cheng =20
> > > > =20
> > > > =20
> > > > On 10/21/14 8:28 AM, shane knapp wrote: =20
> > > > =20
> > > > > ok, so earlier today i installed a 2nd JDK within jenkins (7u71=
), which fixed the SparkR build but apparently made Spark itself quite un=
happy. i removed that JDK, triggered a build ( https://amplab.cs.berkeley=
.edu/jenkins/job/SparkPullRequestBuilder/21943/console), and it compiled =
kinesis w/o dying a fiery death. apparently 7u71 is stricter when compili=
ng. sad times. sorry about that=21 shane On Mon, Oct 20, 2014 at 5:16 PM,=
 Patrick Wendell <pwendell=40gmail.com> (mailto:pwendell=40gmail.com) wro=
te: =20
> > > > > > The failure is in the Kinesis compoent, can you reproduce thi=
s if you build with -Pkinesis-asl=3F - Patrick On Mon, Oct 20, 2014 at 5:=
08 PM, shane knapp <sknapp=40berkeley.edu> (mailto:sknapp=40berkeley.edu)=
 wrote: =20
> > > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at 5:1=
1 PM, Nan Zhu <zhunanmcgill=40gmail.com> (mailto:zhunanmcgill=40gmail.com=
) wrote: =20
> > > > > > > > yes, I can compile locally, too but it seems that Jenkins=
 is not happy now... https://amplab.cs.berkeley.edu/jenkins/job/SparkPull=
RequestBuilder/ All failed to compile Best, -- Nan Zhu On Monday, October=
 20, 2014 at 7:56 PM, Ted Yu wrote: =20
> > > > > > > > > I performed build on latest master branch but didn't ge=
t compilation =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > error. =20
> > > > > > > > > =46YI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanm=
cgill=40gmail.com (mailto:zhunanmcgill=40gmail.com) =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > (mailto:zhunanmcgill=40gmail.com)> wrote: =20
> > > > > > > > > > Hi, I just submitted a patch =20
> > > > > > > > > > =20
> > > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > https://github.com/apache/spark/pull/2864/files =20
> > > > > > > > > > with one line change but the Jenkins told me it's fai=
led to compile on the unrelated =20
> > > > > > > > > > =20
> > > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > > files=3F =20
> > > > > > > > > > =20
> > > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBu=
ilder/21935/console =20
> > > > > > > > > > Best, Nan =20
> > > > > > > > > > =20
> > > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > > =20
> > > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > > > =20
> > > > > =20
> > > > > =20
> > > > > =20
> > > > =20
> > > > =20
> > > > =E2=80=8B =20
> > > > =20
> > > > =20
> > > > =20
> > > > =20
> > > =20
> > > =20
> > =20
> =20


--5446924e_554365fc_107--


From dev-return-9915-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 17:09:26 2014
Return-Path: <dev-return-9915-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6618A17DC9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 17:09:26 +0000 (UTC)
Received: (qmail 29732 invoked by uid 500); 21 Oct 2014 17:09:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29664 invoked by uid 500); 21 Oct 2014 17:09:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 29652 invoked by uid 99); 21 Oct 2014 17:09:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 17:09:24 +0000
X-ASF-Spam-Status: No, hits=0.3 required=10.0
	tests=FREEMAIL_REPLY,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 17:08:59 +0000
Received: by mail-ob0-f175.google.com with SMTP id wn1so1392293obc.20
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 10:08:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=uq/7XGztl1LrR62iF2mTqLNoZ4+9hfIjlgopeBTManM=;
        b=jYQ13eFYsUrc2FAUN48RSqxPKT6wkIJr9o/gCu8UnS+QpZ40DtZln0I1nEQd7tiB2q
         84OunWl69aTy5jF+yvUcKYrgC1Av3TVoxRSa/7mQCt8pYgWq3BFsHeyA3SIgIhedUUa0
         C4KJKDZUiVXUXnz5C76AlD3xCpnOwMkrEFO0yFQIaUJTXbuOtEwmJl1f0Cz/D8AN7uN/
         b6/GayOh6ZWB24twXQGJfrvlkFKXE4T65UpIXQOA0XAPXxa6zE5tIrD4ifcgYXhJHA6+
         BeVAA/dw5+ndN5W4S4Ef0rgMOX9z1WPFNeIDqra6V8J3Nq/klLmcvFrh+u1CohxZcuj0
         XGfw==
MIME-Version: 1.0
X-Received: by 10.60.62.178 with SMTP id z18mr3283533oer.68.1413911338110;
 Tue, 21 Oct 2014 10:08:58 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Tue, 21 Oct 2014 10:08:58 -0700 (PDT)
In-Reply-To: <etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
	<CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
	<AFBB584B386748008FF81312D2A24C39@gmail.com>
	<CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
	<CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
	<CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
	<544651F3.1050006@gmail.com>
	<702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
	<54465E1D.1000301@gmail.com>
	<06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
	<F851301989FB43DFA027184738D534EE@gmail.com>
	<etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
Date: Tue, 21 Oct 2014 10:08:58 -0700
Message-ID: <CABPQxsta-2uRFtwLXP1SVSWvANFf9fVjyN5tfO_=SXonhNMy0g@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
From: Patrick Wendell <pwendell@gmail.com>
To: Josh Rosen <rosenville@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, Cheng Lian <lian.cs.zju@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Ted Yu <yuzhihong@gmail.com>, 
	shane knapp <sknapp@berkeley.edu>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Josh - the errors that broke our build indicated that JDK5 was being
used. Somehow the upgrade caused our build to use a much older Java
version. See the JIRA for more details.

On Tue, Oct 21, 2014 at 10:05 AM, Josh Rosen <rosenville@gmail.com> wrote:
> I find it concerning that there's a JDK version that breaks out build, since
> we're supposed to support Java 7.  Is 7u71 an upgrade or downgrade from the
> JDK that we used before?  Is there an easy way to fix our build so that it
> compiles with 7u71's stricter settings?
>
> I'm not sure why the "New" PRB is failing here.  It was originally created
> as a clone of the main pull request builder job. I checked the configuration
> history and confirmed that there aren't any settings that we've forgotten to
> copy over (e.g. their configurations haven't diverged), so I'm not sure
> what's causing this.
>
> - Josh
>
> On October 21, 2014 at 6:35:39 AM, Nan Zhu (zhunanmcgill@gmail.com) wrote:
>
> weird.....two buildings (one triggered by New, one triggered by Old) were
> executed in the same node, amp-jenkins-slave-01, one compiles, one not...
>
> Best,
>
> --
> Nan Zhu
>
>
> On Tuesday, October 21, 2014 at 9:39 AM, Nan Zhu wrote:
>
>> seems that all PRs built by NewSparkPRBuilder suffers from 7u71, while
>> SparkPRBuilder is working fine
>>
>> Best,
>>
>> --
>> Nan Zhu
>>
>>
>> On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote:
>>
>> > It's a new pull request builder written by Josh, integrated into our
>> > state-of-the-art PR dashboard :)
>> >
>> > On 10/21/14 9:33 PM, Nan Zhu wrote:
>> > > just curious...what is this "NewSparkPullRequestBuilder"?
>> > >
>> > > Best,
>> > >
>> > > --
>> > > Nan Zhu
>> > >
>> > >
>> > > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:
>> > >
>> > > >
>> > > > Hm, seems that 7u71 comes back again. Observed similar Kinesis
>> > > > compilation error just now:
>> > > > https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBuilder/410/consoleFull
>> > > >
>> > > >
>> > > > Checked Jenkins slave nodes, saw /usr/java/latest points to
>> > > > jdk1.7.0_71. However, /usr/bin/javac -version says:
>> > > >
>> > > > >
>> > > > > Eclipse Java Compiler 0.894_R34x, 3.4.2 release, Copyright IBM
>> > > > > Corp 2000, 2008. All rights reserved.
>> > > > >
>> > > >
>> > > >
>> > > > Which JDK is actually used by Jenkins?
>> > > >
>> > > >
>> > > > Cheng
>> > > >
>> > > >
>> > > > On 10/21/14 8:28 AM, shane knapp wrote:
>> > > >
>> > > > > ok, so earlier today i installed a 2nd JDK within jenkins (7u71),
>> > > > > which fixed the SparkR build but apparently made Spark itself quite unhappy.
>> > > > > i removed that JDK, triggered a build (
>> > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
>> > > > > and it compiled kinesis w/o dying a fiery death. apparently 7u71 is stricter
>> > > > > when compiling. sad times. sorry about that! shane On Mon, Oct 20, 2014 at
>> > > > > 5:16 PM, Patrick Wendell <pwendell@gmail.com> (mailto:pwendell@gmail.com)
>> > > > > wrote:
>> > > > > > The failure is in the Kinesis compoent, can you reproduce this
>> > > > > > if you build with -Pkinesis-asl? - Patrick On Mon, Oct 20, 2014 at 5:08 PM,
>> > > > > > shane knapp <sknapp@berkeley.edu> (mailto:sknapp@berkeley.edu) wrote:
>> > > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at 5:11
>> > > > > > > PM, Nan Zhu <zhunanmcgill@gmail.com> (mailto:zhunanmcgill@gmail.com) wrote:
>> > > > > > > > yes, I can compile locally, too but it seems that Jenkins is
>> > > > > > > > not happy now...
>> > > > > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/ All
>> > > > > > > > failed to compile Best, -- Nan Zhu On Monday, October 20, 2014 at 7:56 PM,
>> > > > > > > > Ted Yu wrote:
>> > > > > > > > > I performed build on latest master branch but didn't get
>> > > > > > > > > compilation
>> > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > > error.
>> > > > > > > > > FYI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu
>> > > > > > > > > <zhunanmcgill@gmail.com (mailto:zhunanmcgill@gmail.com)
>> > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > > (mailto:zhunanmcgill@gmail.com)> wrote:
>> > > > > > > > > > Hi, I just submitted a patch
>> > > > > > > > > >
>> > > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > > https://github.com/apache/spark/pull/2864/files
>> > > > > > > > > > with one line change but the Jenkins told me it's failed
>> > > > > > > > > > to compile on the unrelated
>> > > > > > > > > >
>> > > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > >
>> > > > > > >
>> > > > > > >
>> > > > > >
>> > > > > > files?
>> > > > > > > > > >
>> > > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > >
>> > > > > >
>> > > > > >
>> > > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>> > > > > > > > > > Best, Nan
>> > > > > > > > > >
>> > > > > > > > > >
>> > > > > > > > >
>> > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > >
>> > > > > >
>> > > > > >
>> > > > > >
>> > > > >
>> > > > >
>> > > > >
>> > > >
>> > > >
>> > > >
>> > > >
>> > > >
>> > > >
>> > > >
>> > >
>> > >
>> >
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9916-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 17:11:09 2014
Return-Path: <dev-return-9916-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 41A5A17DD2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 17:11:09 +0000 (UTC)
Received: (qmail 33133 invoked by uid 500); 21 Oct 2014 17:11:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 33079 invoked by uid 500); 21 Oct 2014 17:11:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 33066 invoked by uid 99); 21 Oct 2014 17:11:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 17:11:07 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.213.174 as permitted sender)
Received: from [209.85.213.174] (HELO mail-ig0-f174.google.com) (209.85.213.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 17:11:03 +0000
Received: by mail-ig0-f174.google.com with SMTP id a13so1769490igq.1
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 10:09:58 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type:content-transfer-encoding;
        bh=q7VeBEG+qV+IwNQjKtfyqCc/Glvc0Jq8s7p8gbwv1DM=;
        b=bwK8PRKCQy/Wchw72V7YF7TLkMoSqWPIms7mwY0KfRdD9xScMPM1FAa96mmJ9T+kHv
         yjYEcaHOmnzBcDtKFPNUwlUvKcRoiOG4FH4PijHBvoWWsBINdJ1VWmnS2rCINjbDw2C3
         YTwLdx0FzViBQFYGheQhL6cwxew6BeEby8JsvM/SIETV0Llm7Pk1+7I5gi5xRk25LhYt
         n7p39ADblSZgicgm7qrHTYQ5DKnRy8nDDxhuQvEyaxjRFVsZ4QSWfvP6LPop/s8QOT5R
         mEV8MVRR6pPVwWyE3ZbtlcjGeGXhL+QMZRGEH4wwTlMXy5gdQhEdZkhEF2CaLaJX8RQk
         EeIQ==
X-Gm-Message-State: ALoCoQlYI4qlSY1SOr6Rgh+5dk3vmhWQyi+M1mE81lgHWWrmI6ow60L+BA5kdvSLjAAyb1ihYuzz
X-Received: by 10.107.167.66 with SMTP id q63mr38311448ioe.23.1413911397923;
 Tue, 21 Oct 2014 10:09:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Tue, 21 Oct 2014 10:09:37 -0700 (PDT)
In-Reply-To: <etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com> <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <544651F3.1050006@gmail.com> <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
 <54465E1D.1000301@gmail.com> <06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
 <F851301989FB43DFA027184738D534EE@gmail.com> <etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 21 Oct 2014 13:09:37 -0400
Message-ID: <CAMAsSd+9WS9jcZv6Bd92BR3rDy3JGLHoom_drGGab0+z3PiZCg@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
To: Josh Rosen <rosenville@gmail.com>
Cc: Nan Zhu <zhunanmcgill@gmail.com>, Cheng Lian <lian.cs.zju@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Ted Yu <yuzhihong@gmail.com>, 
	shane knapp <sknapp@berkeley.edu>, Patrick Wendell <pwendell@gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Given the nature of the error, I would be really, really shocked if
Java 7u71 were actually being used in the failing build, so no I do
not thing the problem has to do with 7u71 per se.

As I'd expect I see no changes to javac in this update from 7u65, and
no chatter about crazy javac regressions.

It is complaining that @Override doesn't apply to implemented
interface methods. This is allowed in Java 6+. Either something is
really using Java 5 -- or some new config has kicked in setting
-source=3D1.5. (Something also seems to have enabled -Xlint:all or
similar.)

Given Shane's finding about the Eclipse compiler apparently being
invoked, I think that's the problem, or it's of that form.

On Tue, Oct 21, 2014 at 1:05 PM, Josh Rosen <rosenville@gmail.com> wrote:
> I find it concerning that there=E2=80=99s a JDK version that breaks out b=
uild, since we=E2=80=99re supposed to support Java 7.  Is 7u71 an upgrade o=
r downgrade from the JDK that we used before?  Is there an easy way to fix =
our build so that it compiles with 7u71=E2=80=99s stricter settings?
>
> I=E2=80=99m not sure why the =E2=80=9CNew=E2=80=9D PRB is failing here.  =
It was originally created as a clone of the main pull request builder job. =
I checked the configuration history and confirmed that there aren=E2=80=99t=
 any settings that we=E2=80=99ve forgotten to copy over (e.g. their configu=
rations haven=E2=80=99t diverged), so I=E2=80=99m not sure what=E2=80=99s c=
ausing this.
>
> - Josh
>
> On October 21, 2014 at 6:35:39 AM, Nan Zhu (zhunanmcgill@gmail.com) wrote=
:
> weird=E2=80=A6..two buildings (one triggered by New, one triggered by Old=
) were executed in the same node, amp-jenkins-slave-01, one compiles, one n=
ot=E2=80=A6
>
> Best,
>
> --
> Nan Zhu
>
>
> On Tuesday, October 21, 2014 at 9:39 AM, Nan Zhu wrote:
>
>> seems that all PRs built by NewSparkPRBuilder suffers from 7u71, while S=
parkPRBuilder is working fine
>>
>> Best,
>>
>> --
>> Nan Zhu
>>
>>
>> On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote:
>>
>> > It's a new pull request builder written by Josh, integrated into our s=
tate-of-the-art PR dashboard :)
>> >
>> > On 10/21/14 9:33 PM, Nan Zhu wrote:
>> > > just curious=E2=80=A6what is this =E2=80=9CNewSparkPullRequestBuilde=
r=E2=80=9D?
>> > >
>> > > Best,
>> > >
>> > > --
>> > > Nan Zhu
>> > >
>> > >
>> > > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:
>> > >
>> > > >
>> > > > Hm, seems that 7u71 comes back again. Observed similar Kinesis com=
pilation error just now: https://amplab.cs.berkeley.edu/jenkins/job/NewSpar=
kPullRequestBuilder/410/consoleFull
>> > > >
>> > > >
>> > > > Checked Jenkins slave nodes, saw /usr/java/latest points to jdk1.7=
.0_71. However, /usr/bin/javac -version says:
>> > > >
>> > > > >
>> > > > > Eclipse Java Compiler 0.894_R34x, 3.4.2 release, Copyright IBM C=
orp 2000, 2008. All rights reserved.
>> > > > >
>> > > >
>> > > >
>> > > > Which JDK is actually used by Jenkins?
>> > > >
>> > > >
>> > > > Cheng
>> > > >
>> > > >
>> > > > On 10/21/14 8:28 AM, shane knapp wrote:
>> > > >
>> > > > > ok, so earlier today i installed a 2nd JDK within jenkins (7u71)=
, which fixed the SparkR build but apparently made Spark itself quite unhap=
py. i removed that JDK, triggered a build ( https://amplab.cs.berkeley.edu/=
jenkins/job/SparkPullRequestBuilder/21943/console), and it compiled kinesis=
 w/o dying a fiery death. apparently 7u71 is stricter when compiling. sad t=
imes. sorry about that! shane On Mon, Oct 20, 2014 at 5:16 PM, Patrick Wend=
ell <pwendell@gmail.com> (mailto:pwendell@gmail.com) wrote:
>> > > > > > The failure is in the Kinesis compoent, can you reproduce this=
 if you build with -Pkinesis-asl? - Patrick On Mon, Oct 20, 2014 at 5:08 PM=
, shane knapp <sknapp@berkeley.edu> (mailto:sknapp@berkeley.edu) wrote:
>> > > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at 5:11=
 PM, Nan Zhu <zhunanmcgill@gmail.com> (mailto:zhunanmcgill@gmail.com) wrote=
:
>> > > > > > > > yes, I can compile locally, too but it seems that Jenkins =
is not happy now... https://amplab.cs.berkeley.edu/jenkins/job/SparkPullReq=
uestBuilder/ All failed to compile Best, -- Nan Zhu On Monday, October 20, =
2014 at 7:56 PM, Ted Yu wrote:
>> > > > > > > > > I performed build on latest master branch but didn't get=
 compilation
>> > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > > error.
>> > > > > > > > > FYI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu <zhunanmcgi=
ll@gmail.com (mailto:zhunanmcgill@gmail.com)
>> > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > > (mailto:zhunanmcgill@gmail.com)> wrote:
>> > > > > > > > > > Hi, I just submitted a patch
>> > > > > > > > > >
>> > > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > > https://github.com/apache/spark/pull/2864/files
>> > > > > > > > > > with one line change but the Jenkins told me it's fail=
ed to compile on the unrelated
>> > > > > > > > > >
>> > > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > >
>> > > > > > >
>> > > > > > >
>> > > > > >
>> > > > > > files?
>> > > > > > > > > >
>> > > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > >
>> > > > > >
>> > > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBui=
lder/21935/console
>> > > > > > > > > > Best, Nan
>> > > > > > > > > >
>> > > > > > > > > >
>> > > > > > > > >
>> > > > > > > > >
>> > > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > > >
>> > > > > > >
>> > > > > >
>> > > > > >
>> > > > > >
>> > > > >
>> > > > >
>> > > > >
>> > > >
>> > > >
>> > > >
>> > > >
>> > > >
>> > > >
>> > > >
>> > >
>> > >
>> >
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9917-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 17:12:19 2014
Return-Path: <dev-return-9917-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8470217DD5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 17:12:19 +0000 (UTC)
Received: (qmail 36511 invoked by uid 500); 21 Oct 2014 17:12:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 36428 invoked by uid 500); 21 Oct 2014 17:12:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 36416 invoked by uid 99); 21 Oct 2014 17:12:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 17:12:17 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rosenville@gmail.com designates 209.85.192.172 as permitted sender)
Received: from [209.85.192.172] (HELO mail-pd0-f172.google.com) (209.85.192.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 17:11:51 +0000
Received: by mail-pd0-f172.google.com with SMTP id ft15so1725498pdb.31
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 10:11:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=WLeBfYIMOGK3N1QLvOWmkkUPIFMkg1iTrGMu1I2u6tI=;
        b=Tk9yTyD4pWKE5WRCy4cDrnq7SuAyDwACn+vDoWnj8FhlvEwDhKlVIJDYfJ6LrpsmVz
         yqUdlVpOXCdDou7S2n613cHtAa+duywr3jeYOmR9AdjbM8ZY2P6WpoB36M6MghQAx0Iy
         2i3jhSHcanRh9X98Vt1yllFq/Lfb5cyhDLnebDx7GKCyByehNpm/zgnPHUKT9hWY52dg
         JjCAAzY2lUYwMQM0I4wKh+fZ39OeTESf3v+8zqGpXekXmWTkjyPIT/CmxBCFV3LM2ODL
         UjkuOMMV49dWJcchvOdYWxjWxjMeQpi95KuNzNijkspbnwskznwLCQJuUpnu4r1BlGoR
         vHjw==
X-Received: by 10.70.7.195 with SMTP id l3mr37148134pda.39.1413911464819;
        Tue, 21 Oct 2014 10:11:04 -0700 (PDT)
Received: from joshs-mbp.att.net ([2602:306:cdd1:b10:21f5:cd91:af9e:de91])
        by mx.google.com with ESMTPSA id fv4sm12284842pbd.47.2014.10.21.10.11.03
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Tue, 21 Oct 2014 10:11:03 -0700 (PDT)
Date: Tue, 21 Oct 2014 10:11:02 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: "=?utf-8?Q?dev=40spark.apache.org?=" <dev@spark.apache.org>, shane
 knapp <sknapp@berkeley.edu>, Ted Yu <yuzhihong@gmail.com>, Nan Zhu
 <zhunanmcgill@gmail.com>, Cheng Lian <lian.cs.zju@gmail.com>
Message-ID: <etPan.544693a6.2b422e4.107@joshs-mbp.att.net>
In-Reply-To: <CABPQxsta-2uRFtwLXP1SVSWvANFf9fVjyN5tfO_=SXonhNMy0g@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com>
 <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <544651F3.1050006@gmail.com> <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
 <54465E1D.1000301@gmail.com> <06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
 <F851301989FB43DFA027184738D534EE@gmail.com>
 <etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
 <CABPQxsta-2uRFtwLXP1SVSWvANFf9fVjyN5tfO_=SXonhNMy0g@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
X-Mailer: Airmail Beta (269)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="544693a6_435e4f85_107"
X-Virus-Checked: Checked by ClamAV on apache.org

--544693a6_435e4f85_107
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Ah, that makes sense. =C2=A0I had forgotten that there was a JIRA for thi=
s:

https://issues.apache.org/jira/browse/SPARK-4021 =C2=A0

On October 21, 2014 at 10:08:58 AM, Patrick Wendell (pwendell=40gmail.com=
) wrote:

Josh - the errors that broke our build indicated that JDK5 was being =20
used. Somehow the upgrade caused our build to use a much older Java =20
version. See the JIRA for more details. =20

On Tue, Oct 21, 2014 at 10:05 AM, Josh Rosen <rosenville=40gmail.com> wro=
te: =20
> I find it concerning that there's a JDK version that breaks out build, =
since =20
> we're supposed to support Java 7. Is 7u71 an upgrade or downgrade from =
the =20
> JDK that we used before=3F Is there an easy way to fix our build so tha=
t it =20
> compiles with 7u71's stricter settings=3F =20
> =20
> I'm not sure why the =22New=22 PRB is failing here. It was originally c=
reated =20
> as a clone of the main pull request builder job. I checked the configur=
ation =20
> history and confirmed that there aren't any settings that we've forgott=
en to =20
> copy over (e.g. their configurations haven't diverged), so I'm not sure=
 =20
> what's causing this. =20
> =20
> - Josh =20
> =20
> On October 21, 2014 at 6:35:39 AM, Nan Zhu (zhunanmcgill=40gmail.com) w=
rote: =20
> =20
> weird.....two buildings (one triggered by New, one triggered by Old) we=
re =20
> executed in the same node, amp-jenkins-slave-01, one compiles, one not.=
.. =20
> =20
> Best, =20
> =20
> -- =20
> Nan Zhu =20
> =20
> =20
> On Tuesday, October 21, 2014 at 9:39 AM, Nan Zhu wrote: =20
> =20
>> seems that all PRs built by NewSparkPRBuilder suffers from 7u71, while=
 =20
>> SparkPRBuilder is working fine =20
>> =20
>> Best, =20
>> =20
>> -- =20
>> Nan Zhu =20
>> =20
>> =20
>> On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote: =20
>> =20
>> > It's a new pull request builder written by Josh, integrated into our=
 =20
>> > state-of-the-art PR dashboard :) =20
>> > =20
>> > On 10/21/14 9:33 PM, Nan Zhu wrote: =20
>> > > just curious...what is this =22NewSparkPullRequestBuilder=22=3F =20
>> > > =20
>> > > Best, =20
>> > > =20
>> > > -- =20
>> > > Nan Zhu =20
>> > > =20
>> > > =20
>> > > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote: =20
>> > > =20
>> > > > =20
>> > > > Hm, seems that 7u71 comes back again. Observed similar Kinesis =20
>> > > > compilation error just now: =20
>> > > > https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBu=
ilder/410/console=46ull =20
>> > > > =20
>> > > > =20
>> > > > Checked Jenkins slave nodes, saw /usr/java/latest points to =20
>> > > > jdk1.7.0=5F71. However, /usr/bin/javac -version says: =20
>> > > > =20
>> > > > > =20
>> > > > > Eclipse Java Compiler 0.894=5FR34x, 3.4.2 release, Copyright I=
BM =20
>> > > > > Corp 2000, 2008. All rights reserved. =20
>> > > > > =20
>> > > > =20
>> > > > =20
>> > > > Which JDK is actually used by Jenkins=3F =20
>> > > > =20
>> > > > =20
>> > > > Cheng =20
>> > > > =20
>> > > > =20
>> > > > On 10/21/14 8:28 AM, shane knapp wrote: =20
>> > > > =20
>> > > > > ok, so earlier today i installed a 2nd JDK within jenkins (7u7=
1), =20
>> > > > > which fixed the SparkR build but apparently made Spark itself =
quite unhappy. =20
>> > > > > i removed that JDK, triggered a build ( =20
>> > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBui=
lder/21943/console), =20
>> > > > > and it compiled kinesis w/o dying a fiery death. apparently 7u=
71 is stricter =20
>> > > > > when compiling. sad times. sorry about that=21 shane On Mon, O=
ct 20, 2014 at =20
>> > > > > 5:16 PM, Patrick Wendell <pwendell=40gmail.com> (mailto:pwende=
ll=40gmail.com) =20
>> > > > > wrote: =20
>> > > > > > The failure is in the Kinesis compoent, can you reproduce th=
is =20
>> > > > > > if you build with -Pkinesis-asl=3F - Patrick On Mon, Oct 20,=
 2014 at 5:08 PM, =20
>> > > > > > shane knapp <sknapp=40berkeley.edu> (mailto:sknapp=40berkele=
y.edu) wrote: =20
>> > > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at 5:=
11 =20
>> > > > > > > PM, Nan Zhu <zhunanmcgill=40gmail.com> (mailto:zhunanmcgil=
l=40gmail.com) wrote: =20
>> > > > > > > > yes, I can compile locally, too but it seems that Jenkin=
s is =20
>> > > > > > > > not happy now... =20
>> > > > > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequ=
estBuilder/ All =20
>> > > > > > > > failed to compile Best, -- Nan Zhu On Monday, October 20=
, 2014 at 7:56 PM, =20
>> > > > > > > > Ted Yu wrote: =20
>> > > > > > > > > I performed build on latest master branch but didn't g=
et =20
>> > > > > > > > > compilation =20
>> > > > > > > > > =20
>> > > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > error. =20
>> > > > > > > > > =46YI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu =20
>> > > > > > > > > <zhunanmcgill=40gmail.com (mailto:zhunanmcgill=40gmail=
.com) =20
>> > > > > > > > > =20
>> > > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > (mailto:zhunanmcgill=40gmail.com)> wrote: =20
>> > > > > > > > > > Hi, I just submitted a patch =20
>> > > > > > > > > > =20
>> > > > > > > > > > =20
>> > > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > https://github.com/apache/spark/pull/2864/files =20
>> > > > > > > > > > with one line change but the Jenkins told me it's fa=
iled =20
>> > > > > > > > > > to compile on the unrelated =20
>> > > > > > > > > > =20
>> > > > > > > > > > =20
>> > > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > =20
>> > > > > > > =20
>> > > > > > > =20
>> > > > > > =20
>> > > > > > files=3F =20
>> > > > > > > > > > =20
>> > > > > > > > > > =20
>> > > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > =20
>> > > > > > =20
>> > > > > > =20
>> > > > > > https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestB=
uilder/21935/console =20
>> > > > > > > > > > Best, Nan =20
>> > > > > > > > > > =20
>> > > > > > > > > > =20
>> > > > > > > > > =20
>> > > > > > > > > =20
>> > > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > > =20
>> > > > > > > =20
>> > > > > > =20
>> > > > > > =20
>> > > > > > =20
>> > > > > =20
>> > > > > =20
>> > > > > =20
>> > > > =20
>> > > > =20
>> > > > =20
>> > > > =20
>> > > > =20
>> > > > =20
>> > > > =20
>> > > =20
>> > > =20
>> > =20
>> =20
> =20

--544693a6_435e4f85_107--


From dev-return-9918-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 18:08:20 2014
Return-Path: <dev-return-9918-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 937FB1739B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 18:08:20 +0000 (UTC)
Received: (qmail 38804 invoked by uid 500); 21 Oct 2014 18:08:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38736 invoked by uid 500); 21 Oct 2014 18:08:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 38723 invoked by uid 99); 21 Oct 2014 18:08:19 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 18:08:19 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.223.171 as permitted sender)
Received: from [209.85.223.171] (HELO mail-ie0-f171.google.com) (209.85.223.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 18:08:15 +0000
Received: by mail-ie0-f171.google.com with SMTP id x19so1195711ier.2
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 11:07:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=SAaOMQtIxWg0LG1mwv0GI0DP0WlWADm0YEY43ZEggO4=;
        b=dM2KIGO4fo6hNuO4slCUl0kclZ52Q/XDTkKePSWHbHyegAz8lM4781DY6ht7gSCfZ2
         /enlOWymsOnLYZYEdfSoGqJCMj/fmz+g9szhsd+7U/3jdvc7C4E/+hfJG275hJcX/T6L
         x+vYtGmXZ8YuCl1i3sPd+gNhjQ3jJKC1By7ixAwvwFjSx9I9PI6UT4/+J+AyFbBgq3kg
         RpRHeJ+GRzcStwXq8YXfxxRQDD/u+k0cvG5/5NAygO03FaW1LfEaCWAJEOM9RFKuz0Na
         EiMUFIF97+GAEgff5geHjxtFefDzYHQdZdmZ/lxln7j1jY2sKLirnu5ag8xvGCPaxZaA
         gRCw==
MIME-Version: 1.0
X-Received: by 10.107.19.203 with SMTP id 72mr38319944iot.27.1413914874504;
 Tue, 21 Oct 2014 11:07:54 -0700 (PDT)
Received: by 10.107.11.38 with HTTP; Tue, 21 Oct 2014 11:07:54 -0700 (PDT)
In-Reply-To: <etPan.544693a6.2b422e4.107@joshs-mbp.att.net>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
	<CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
	<AFBB584B386748008FF81312D2A24C39@gmail.com>
	<CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
	<CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
	<CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
	<544651F3.1050006@gmail.com>
	<702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
	<54465E1D.1000301@gmail.com>
	<06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
	<F851301989FB43DFA027184738D534EE@gmail.com>
	<etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
	<CABPQxsta-2uRFtwLXP1SVSWvANFf9fVjyN5tfO_=SXonhNMy0g@mail.gmail.com>
	<etPan.544693a6.2b422e4.107@joshs-mbp.att.net>
Date: Tue, 21 Oct 2014 14:07:54 -0400
Message-ID: <CAMtqZec3L5dtD9GQc-UqcE6fmOD7ye3zyHvwWdekP7iNgpZYOA@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Josh Rosen <rosenville@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	shane knapp <sknapp@berkeley.edu>, Ted Yu <yuzhihong@gmail.com>, 
	Cheng Lian <lian.cs.zju@gmail.com>
Content-Type: multipart/alternative; boundary=001a113f8264d693fc0505f2b549
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113f8264d693fc0505f2b549
Content-Type: text/plain; charset=UTF-8

I agree with Sean

I just compiled spark core successfully with 7u71 in Mac OS X

On Tue, Oct 21, 2014 at 1:11 PM, Josh Rosen <rosenville@gmail.com> wrote:

> Ah, that makes sense.  I had forgotten that there was a JIRA for this:
>
> https://issues.apache.org/jira/browse/SPARK-4021
>
> On October 21, 2014 at 10:08:58 AM, Patrick Wendell (pwendell@gmail.com)
> wrote:
>
> Josh - the errors that broke our build indicated that JDK5 was being
> used. Somehow the upgrade caused our build to use a much older Java
> version. See the JIRA for more details.
>
> On Tue, Oct 21, 2014 at 10:05 AM, Josh Rosen <rosenville@gmail.com>
> wrote:
> > I find it concerning that there's a JDK version that breaks out build,
> since
> > we're supposed to support Java 7. Is 7u71 an upgrade or downgrade from
> the
> > JDK that we used before? Is there an easy way to fix our build so that
> it
> > compiles with 7u71's stricter settings?
> >
> > I'm not sure why the "New" PRB is failing here. It was originally
> created
> > as a clone of the main pull request builder job. I checked the
> configuration
> > history and confirmed that there aren't any settings that we've
> forgotten to
> > copy over (e.g. their configurations haven't diverged), so I'm not sure
> > what's causing this.
> >
> > - Josh
> >
> > On October 21, 2014 at 6:35:39 AM, Nan Zhu (zhunanmcgill@gmail.com)
> wrote:
> >
> > weird.....two buildings (one triggered by New, one triggered by Old)
> were
> > executed in the same node, amp-jenkins-slave-01, one compiles, one
> not...
> >
> > Best,
> >
> > --
> > Nan Zhu
> >
> >
> > On Tuesday, October 21, 2014 at 9:39 AM, Nan Zhu wrote:
> >
> >> seems that all PRs built by NewSparkPRBuilder suffers from 7u71, while
> >> SparkPRBuilder is working fine
> >>
> >> Best,
> >>
> >> --
> >> Nan Zhu
> >>
> >>
> >> On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote:
> >>
> >> > It's a new pull request builder written by Josh, integrated into our
> >> > state-of-the-art PR dashboard :)
> >> >
> >> > On 10/21/14 9:33 PM, Nan Zhu wrote:
> >> > > just curious...what is this "NewSparkPullRequestBuilder"?
> >> > >
> >> > > Best,
> >> > >
> >> > > --
> >> > > Nan Zhu
> >> > >
> >> > >
> >> > > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:
> >> > >
> >> > > >
> >> > > > Hm, seems that 7u71 comes back again. Observed similar Kinesis
> >> > > > compilation error just now:
> >> > > >
> https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBuilder/410/consoleFull
> >> > > >
> >> > > >
> >> > > > Checked Jenkins slave nodes, saw /usr/java/latest points to
> >> > > > jdk1.7.0_71. However, /usr/bin/javac -version says:
> >> > > >
> >> > > > >
> >> > > > > Eclipse Java Compiler 0.894_R34x, 3.4.2 release, Copyright IBM
> >> > > > > Corp 2000, 2008. All rights reserved.
> >> > > > >
> >> > > >
> >> > > >
> >> > > > Which JDK is actually used by Jenkins?
> >> > > >
> >> > > >
> >> > > > Cheng
> >> > > >
> >> > > >
> >> > > > On 10/21/14 8:28 AM, shane knapp wrote:
> >> > > >
> >> > > > > ok, so earlier today i installed a 2nd JDK within jenkins
> (7u71),
> >> > > > > which fixed the SparkR build but apparently made Spark itself
> quite unhappy.
> >> > > > > i removed that JDK, triggered a build (
> >> > > > >
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
>
> >> > > > > and it compiled kinesis w/o dying a fiery death. apparently
> 7u71 is stricter
> >> > > > > when compiling. sad times. sorry about that! shane On Mon, Oct
> 20, 2014 at
> >> > > > > 5:16 PM, Patrick Wendell <pwendell@gmail.com> (mailto:
> pwendell@gmail.com)
> >> > > > > wrote:
> >> > > > > > The failure is in the Kinesis compoent, can you reproduce
> this
> >> > > > > > if you build with -Pkinesis-asl? - Patrick On Mon, Oct 20,
> 2014 at 5:08 PM,
> >> > > > > > shane knapp <sknapp@berkeley.edu> (mailto:sknapp@berkeley.edu)
> wrote:
> >> > > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at
> 5:11
> >> > > > > > > PM, Nan Zhu <zhunanmcgill@gmail.com> (mailto:
> zhunanmcgill@gmail.com) wrote:
> >> > > > > > > > yes, I can compile locally, too but it seems that Jenkins
> is
> >> > > > > > > > not happy now...
> >> > > > > > > >
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/ All
> >> > > > > > > > failed to compile Best, -- Nan Zhu On Monday, October 20,
> 2014 at 7:56 PM,
> >> > > > > > > > Ted Yu wrote:
> >> > > > > > > > > I performed build on latest master branch but didn't
> get
> >> > > > > > > > > compilation
> >> > > > > > > > >
> >> > > > > > > > >
> >> > > > > > > >
> >> > > > > > > > error.
> >> > > > > > > > > FYI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu
> >> > > > > > > > > <zhunanmcgill@gmail.com (mailto:zhunanmcgill@gmail.com)
>
> >> > > > > > > > >
> >> > > > > > > > >
> >> > > > > > > >
> >> > > > > > > > (mailto:zhunanmcgill@gmail.com)> wrote:
> >> > > > > > > > > > Hi, I just submitted a patch
> >> > > > > > > > > >
> >> > > > > > > > > >
> >> > > > > > > > >
> >> > > > > > > >
> >> > > > > > > > https://github.com/apache/spark/pull/2864/files
> >> > > > > > > > > > with one line change but the Jenkins told me it's
> failed
> >> > > > > > > > > > to compile on the unrelated
> >> > > > > > > > > >
> >> > > > > > > > > >
> >> > > > > > > > >
> >> > > > > > > >
> >> > > > > > > >
> >> > > > > > > >
> >> > > > > > >
> >> > > > > > >
> >> > > > > > >
> >> > > > > >
> >> > > > > > files?
> >> > > > > > > > > >
> >> > > > > > > > > >
> >> > > > > > > > >
> >> > > > > > > >
> >> > > > > > > >
> >> > > > > > > >
> >> > > > > > >
> >> > > > > >
> >> > > > > >
> >> > > > > >
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
> >> > > > > > > > > > Best, Nan
> >> > > > > > > > > >
> >> > > > > > > > > >
> >> > > > > > > > >
> >> > > > > > > > >
> >> > > > > > > > >
> >> > > > > > > >
> >> > > > > > > >
> >> > > > > > > >
> >> > > > > > >
> >> > > > > >
> >> > > > > >
> >> > > > > >
> >> > > > >
> >> > > > >
> >> > > > >
> >> > > >
> >> > > >
> >> > > >
> >> > > >
> >> > > >
> >> > > >
> >> > > >
> >> > >
> >> > >
> >> >
> >>
> >
>
>

--001a113f8264d693fc0505f2b549--

From dev-return-9919-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 18:52:27 2014
Return-Path: <dev-return-9919-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 72DCC17593
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 18:52:27 +0000 (UTC)
Received: (qmail 49675 invoked by uid 500); 21 Oct 2014 18:52:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49610 invoked by uid 500); 21 Oct 2014 18:52:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49599 invoked by uid 99); 21 Oct 2014 18:52:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 18:52:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.53 as permitted sender)
Received: from [209.85.215.53] (HELO mail-la0-f53.google.com) (209.85.215.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 18:51:59 +0000
Received: by mail-la0-f53.google.com with SMTP id gq15so1568303lab.40
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 11:51:58 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=+mzYHiS4FrEl/azhVXSpb9bkNhXog3QkGgh1SxKIvhM=;
        b=lcIFHRoQRSi3q8UGl5UMqnXrBbtOZMklbibSV6vaOyRng8qhlFaoPquc2TyNrkbnYt
         bK7CC7iIIkRZTI7Ch+euEKeeZ1mxM0i/gFEq3KcLnFnUTbnahAy5Plb+O5XUAVokiQ7p
         Kh6IrYfi1Bkda+nZLDDj7LR+7stRx7BD9q46L0/L9hHeMkuvChywMKH2Bbus/jczxAfH
         Wyr9AORnpyxb0uqBaLVempCI3nE/vZjSynuQW3qxdFC5ID4A8M22fqrlp4dBWe3Q/SWo
         6APYYyGKYFxomtYDrzbNRHqm4Tf2h46h59IWlkzP6mSQL+ay22/j4fwBNxWTM6dpW7gd
         Yx6A==
X-Gm-Message-State: ALoCoQn7g+ZX84cJ80l3geBl1wlHfXg6BjLCN8vVYZ2Hb5n3rM1AmWlFPWnbawDQygVzG/K4paEX
X-Received: by 10.112.54.162 with SMTP id k2mr36632232lbp.63.1413917517946;
 Tue, 21 Oct 2014 11:51:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.24.14 with HTTP; Tue, 21 Oct 2014 11:51:37 -0700 (PDT)
In-Reply-To: <CAMtqZec3L5dtD9GQc-UqcE6fmOD7ye3zyHvwWdekP7iNgpZYOA@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com> <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <544651F3.1050006@gmail.com> <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
 <54465E1D.1000301@gmail.com> <06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
 <F851301989FB43DFA027184738D534EE@gmail.com> <etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
 <CABPQxsta-2uRFtwLXP1SVSWvANFf9fVjyN5tfO_=SXonhNMy0g@mail.gmail.com>
 <etPan.544693a6.2b422e4.107@joshs-mbp.att.net> <CAMtqZec3L5dtD9GQc-UqcE6fmOD7ye3zyHvwWdekP7iNgpZYOA@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 21 Oct 2014 11:51:37 -0700
Message-ID: <CACdU-dTbGDbuiHAmWXJ1EfpwWi-OW-6X6R24Ht6ueDCG3L3g1A@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Josh Rosen <rosenville@gmail.com>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Ted Yu <yuzhihong@gmail.com>, 
	Cheng Lian <lian.cs.zju@gmail.com>
Content-Type: multipart/alternative; boundary=001a11c3eeee6631c70505f35365
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3eeee6631c70505f35365
Content-Type: text/plain; charset=UTF-8

i'm currently in a meeting and will be starting to do some tests in ~1 hour
or so.

On Tue, Oct 21, 2014 at 11:07 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

> I agree with Sean
>
> I just compiled spark core successfully with 7u71 in Mac OS X
>
> On Tue, Oct 21, 2014 at 1:11 PM, Josh Rosen <rosenville@gmail.com> wrote:
>
>> Ah, that makes sense.  I had forgotten that there was a JIRA for this:
>>
>> https://issues.apache.org/jira/browse/SPARK-4021
>>
>> On October 21, 2014 at 10:08:58 AM, Patrick Wendell (pwendell@gmail.com)
>> wrote:
>>
>> Josh - the errors that broke our build indicated that JDK5 was being
>> used. Somehow the upgrade caused our build to use a much older Java
>> version. See the JIRA for more details.
>>
>> On Tue, Oct 21, 2014 at 10:05 AM, Josh Rosen <rosenville@gmail.com>
>> wrote:
>> > I find it concerning that there's a JDK version that breaks out build,
>> since
>> > we're supposed to support Java 7. Is 7u71 an upgrade or downgrade from
>> the
>> > JDK that we used before? Is there an easy way to fix our build so that
>> it
>> > compiles with 7u71's stricter settings?
>> >
>> > I'm not sure why the "New" PRB is failing here. It was originally
>> created
>> > as a clone of the main pull request builder job. I checked the
>> configuration
>> > history and confirmed that there aren't any settings that we've
>> forgotten to
>> > copy over (e.g. their configurations haven't diverged), so I'm not sure
>> > what's causing this.
>> >
>> > - Josh
>> >
>> > On October 21, 2014 at 6:35:39 AM, Nan Zhu (zhunanmcgill@gmail.com)
>> wrote:
>> >
>> > weird.....two buildings (one triggered by New, one triggered by Old)
>> were
>> > executed in the same node, amp-jenkins-slave-01, one compiles, one
>> not...
>> >
>> > Best,
>> >
>> > --
>> > Nan Zhu
>> >
>> >
>> > On Tuesday, October 21, 2014 at 9:39 AM, Nan Zhu wrote:
>> >
>> >> seems that all PRs built by NewSparkPRBuilder suffers from 7u71, while
>> >> SparkPRBuilder is working fine
>> >>
>> >> Best,
>> >>
>> >> --
>> >> Nan Zhu
>> >>
>> >>
>> >> On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote:
>> >>
>> >> > It's a new pull request builder written by Josh, integrated into our
>> >> > state-of-the-art PR dashboard :)
>> >> >
>> >> > On 10/21/14 9:33 PM, Nan Zhu wrote:
>> >> > > just curious...what is this "NewSparkPullRequestBuilder"?
>> >> > >
>> >> > > Best,
>> >> > >
>> >> > > --
>> >> > > Nan Zhu
>> >> > >
>> >> > >
>> >> > > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:
>> >> > >
>> >> > > >
>> >> > > > Hm, seems that 7u71 comes back again. Observed similar Kinesis
>> >> > > > compilation error just now:
>> >> > > >
>> https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBuilder/410/consoleFull
>> >> > > >
>> >> > > >
>> >> > > > Checked Jenkins slave nodes, saw /usr/java/latest points to
>> >> > > > jdk1.7.0_71. However, /usr/bin/javac -version says:
>> >> > > >
>> >> > > > >
>> >> > > > > Eclipse Java Compiler 0.894_R34x, 3.4.2 release, Copyright IBM
>> >> > > > > Corp 2000, 2008. All rights reserved.
>> >> > > > >
>> >> > > >
>> >> > > >
>> >> > > > Which JDK is actually used by Jenkins?
>> >> > > >
>> >> > > >
>> >> > > > Cheng
>> >> > > >
>> >> > > >
>> >> > > > On 10/21/14 8:28 AM, shane knapp wrote:
>> >> > > >
>> >> > > > > ok, so earlier today i installed a 2nd JDK within jenkins
>> (7u71),
>> >> > > > > which fixed the SparkR build but apparently made Spark itself
>> quite unhappy.
>> >> > > > > i removed that JDK, triggered a build (
>> >> > > > >
>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
>>
>> >> > > > > and it compiled kinesis w/o dying a fiery death. apparently
>> 7u71 is stricter
>> >> > > > > when compiling. sad times. sorry about that! shane On Mon, Oct
>> 20, 2014 at
>> >> > > > > 5:16 PM, Patrick Wendell <pwendell@gmail.com> (mailto:
>> pwendell@gmail.com)
>> >> > > > > wrote:
>> >> > > > > > The failure is in the Kinesis compoent, can you reproduce
>> this
>> >> > > > > > if you build with -Pkinesis-asl? - Patrick On Mon, Oct 20,
>> 2014 at 5:08 PM,
>> >> > > > > > shane knapp <sknapp@berkeley.edu> (mailto:
>> sknapp@berkeley.edu) wrote:
>> >> > > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at
>> 5:11
>> >> > > > > > > PM, Nan Zhu <zhunanmcgill@gmail.com> (mailto:
>> zhunanmcgill@gmail.com) wrote:
>> >> > > > > > > > yes, I can compile locally, too but it seems that
>> Jenkins is
>> >> > > > > > > > not happy now...
>> >> > > > > > > >
>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/ All
>> >> > > > > > > > failed to compile Best, -- Nan Zhu On Monday, October
>> 20, 2014 at 7:56 PM,
>> >> > > > > > > > Ted Yu wrote:
>> >> > > > > > > > > I performed build on latest master branch but didn't
>> get
>> >> > > > > > > > > compilation
>> >> > > > > > > > >
>> >> > > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > > error.
>> >> > > > > > > > > FYI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu
>> >> > > > > > > > > <zhunanmcgill@gmail.com (mailto:zhunanmcgill@gmail.com)
>>
>> >> > > > > > > > >
>> >> > > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > > (mailto:zhunanmcgill@gmail.com)> wrote:
>> >> > > > > > > > > > Hi, I just submitted a patch
>> >> > > > > > > > > >
>> >> > > > > > > > > >
>> >> > > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > > https://github.com/apache/spark/pull/2864/files
>> >> > > > > > > > > > with one line change but the Jenkins told me it's
>> failed
>> >> > > > > > > > > > to compile on the unrelated
>> >> > > > > > > > > >
>> >> > > > > > > > > >
>> >> > > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > >
>> >> > > > > > >
>> >> > > > > > >
>> >> > > > > > >
>> >> > > > > >
>> >> > > > > > files?
>> >> > > > > > > > > >
>> >> > > > > > > > > >
>> >> > > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > >
>> >> > > > > > >
>> >> > > > > >
>> >> > > > > >
>> >> > > > > >
>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>> >> > > > > > > > > > Best, Nan
>> >> > > > > > > > > >
>> >> > > > > > > > > >
>> >> > > > > > > > >
>> >> > > > > > > > >
>> >> > > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > >
>> >> > > > > > > >
>> >> > > > > > >
>> >> > > > > >
>> >> > > > > >
>> >> > > > > >
>> >> > > > >
>> >> > > > >
>> >> > > > >
>> >> > > >
>> >> > > >
>> >> > > >
>> >> > > >
>> >> > > >
>> >> > > >
>> >> > > >
>> >> > >
>> >> > >
>> >> >
>> >>
>> >
>>
>>
>

--001a11c3eeee6631c70505f35365--

From dev-return-9920-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 19:41:37 2014
Return-Path: <dev-return-9920-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 63D7B17759
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 19:41:37 +0000 (UTC)
Received: (qmail 84159 invoked by uid 500); 21 Oct 2014 19:41:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84092 invoked by uid 500); 21 Oct 2014 19:41:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83747 invoked by uid 99); 21 Oct 2014 19:41:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 19:41:35 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 19:41:31 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <ashutosh.trivedi@iiitb.org>)
	id 1XgfIs-0006Dj-7S
	for dev@spark.incubator.apache.org; Tue, 21 Oct 2014 12:41:10 -0700
Date: Tue, 21 Oct 2014 12:41:10 -0700 (PDT)
From: Ashutosh <ashutosh.trivedi@iiitb.org>
To: dev@spark.incubator.apache.org
Message-ID: <1413920470217-8894.post@n3.nabble.com>
In-Reply-To: <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com>
References: <1413883380883-8880.post@n3.nabble.com> <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Xiangrui,

Thanks for the reply. AVF is not so difficult to implement in parallel. It
just calculate the frequency of each attribute and calculate the overall
'score' of the datapoint. Low score points are considered outlier. One
advantage of it is that it does not calculate distance, so in that sense it
is general.

I have to look at the one you pointed out. It calculates Hat matrix and I am
not sure about calculating Hat matrix in parallel, but Mahalanobis Distance
can be implemented. http://en.wikipedia.org/wiki/Mahalanobis_distance 

I have Opened the JIRA.
 https://issues.apache.org/jira/browse/SPARK-4038
Lets discuss it over there.

Regards,
Ashutosh



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p8894.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9921-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 20:53:22 2014
Return-Path: <dev-return-9921-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4BC3C17B11
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 20:53:22 +0000 (UTC)
Received: (qmail 47764 invoked by uid 500); 21 Oct 2014 20:53:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47692 invoked by uid 500); 21 Oct 2014 20:53:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47671 invoked by uid 99); 21 Oct 2014 20:53:20 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 20:53:20 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id A673B43C6D
	for <dev@spark.apache.org>; Tue, 21 Oct 2014 20:53:40 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id 9B30B43C70; Tue, 21 Oct 2014 20:53:40 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: *
X-Spam-Status: No, score=1.5 required=10.0 tests=HTML_MESSAGE,
	RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,RCVD_IN_MSPIKE_WL,SPF_PASS,URIBL_BLOCKED
	autolearn=disabled version=3.4.0
Received: from mail-lb0-f180.google.com (mail-lb0-f180.google.com [209.85.217.180])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id 029C643C6D
	for <dev@spark.apache.org>; Tue, 21 Oct 2014 20:53:38 +0000 (UTC)
Received: by mail-lb0-f180.google.com with SMTP id n15so1705007lbi.25
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 13:53:11 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=S8GrtXDlbd/zESum2xOuBXmRMonTmAsjcOxOidbhX0k=;
        b=YEyHplSfa5kmSs1H/YYIwsgnC+UwVlesP8MHK7RhJfL/ERM7UxblmyvROKtF8dKRwd
         h8/V7tnCtB52FA3jpFts95V47gr3WW/kbesDV0tCSpIx2BcMheZdDNt/w42bbg7dOgjm
         2JB1byyRbVpjp4h86haHYDIk6JvHojYI+443g11ZHrOCBp+onSNaewZjUgPIOL4028jp
         cgl2A0cEr2oOawUPazJOghEEgUd/5dgN9vj3zKjwkAvq2qsTIwS3i/sxWJk8j3xW8AUe
         vSv/sWkG3CsSp7DmRNMWV8oYEeb5KM+H1si+yNGEvsXG/JjR4cDY039Yl8dEHm46eYch
         rQWQ==
X-Gm-Message-State: ALoCoQl9ZB04UY9oo/9HAeEkUakk8AKZN5mVvLCl1kpn3THYlUT7/9HYydJksWrZjY5JqPwF9F/j
X-Received: by 10.112.28.75 with SMTP id z11mr36834151lbg.49.1413924791046;
 Tue, 21 Oct 2014 13:53:11 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.24.14 with HTTP; Tue, 21 Oct 2014 13:52:50 -0700 (PDT)
In-Reply-To: <CACdU-dTbGDbuiHAmWXJ1EfpwWi-OW-6X6R24Ht6ueDCG3L3g1A@mail.gmail.com>
References: <CAMtqZediVtz8YhuHiL2UYDtaN5tCc0impAyawb6b0Hbv8tDdJw@mail.gmail.com>
 <CALte62yYnT+7G9fZ6ZVyP_Wu05pB7AYiqBHq_J0S3nb9Acpbiw@mail.gmail.com>
 <AFBB584B386748008FF81312D2A24C39@gmail.com> <CACdU-dT0C2y73HS44YTGoHSOSwXz-hR4dOE_5f3rP_Pt+4rjog@mail.gmail.com>
 <CABPQxsu88mYzws7+3tcohOzUdMafmpyKDXOJ4gbCvgxtyRcaCg@mail.gmail.com>
 <CACdU-dTnVo+JLtRjk4pU_L76qZiNKurz2NAJbe6GsKcHDpLtYw@mail.gmail.com>
 <544651F3.1050006@gmail.com> <702DB4FBA22C4BA18B03FC41036B35AE@gmail.com>
 <54465E1D.1000301@gmail.com> <06C2D754E3B04AE49D7DA12A98F952AC@gmail.com>
 <F851301989FB43DFA027184738D534EE@gmail.com> <etPan.5446924e.2fa7e8e1.107@joshs-mbp.att.net>
 <CABPQxsta-2uRFtwLXP1SVSWvANFf9fVjyN5tfO_=SXonhNMy0g@mail.gmail.com>
 <etPan.544693a6.2b422e4.107@joshs-mbp.att.net> <CAMtqZec3L5dtD9GQc-UqcE6fmOD7ye3zyHvwWdekP7iNgpZYOA@mail.gmail.com>
 <CACdU-dTbGDbuiHAmWXJ1EfpwWi-OW-6X6R24Ht6ueDCG3L3g1A@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 21 Oct 2014 13:52:50 -0700
Message-ID: <CACdU-dRUpCdL8=QfRwxvTUzMWj-DAh_dGWko7wRx5cynifJ64A@mail.gmail.com>
Subject: Re: something wrong with Jenkins or something untested merged?
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Josh Rosen <rosenville@gmail.com>, Patrick Wendell <pwendell@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, Ted Yu <yuzhihong@gmail.com>, 
	Cheng Lian <lian.cs.zju@gmail.com>
Content-Type: multipart/alternative; boundary=001a1133eca6e8dd6b0505f50447
X-Virus-Scanned: ClamAV using ClamSMTP

--001a1133eca6e8dd6b0505f50447
Content-Type: text/plain; charset=UTF-8

ok, i did some testing and found out what's happening.

https://issues.apache.org/jira/browse/SPARK-4021

here's the TL;DR:
jenkins ignores what JDKs are installed via the web interface when there's
more than one defined, and falls back to whatever is default on the slave
the test is run on.  in this case, it's openjdk 7u65...  and spark
compilation fails.  i've removed the 2nd JDK (7u71) from jenkins, and
everything is back to normal.

On Tue, Oct 21, 2014 at 11:51 AM, shane knapp <sknapp@berkeley.edu> wrote:

> i'm currently in a meeting and will be starting to do some tests in ~1
> hour or so.
>
> On Tue, Oct 21, 2014 at 11:07 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:
>
>> I agree with Sean
>>
>> I just compiled spark core successfully with 7u71 in Mac OS X
>>
>> On Tue, Oct 21, 2014 at 1:11 PM, Josh Rosen <rosenville@gmail.com> wrote:
>>
>>> Ah, that makes sense.  I had forgotten that there was a JIRA for this:
>>>
>>> https://issues.apache.org/jira/browse/SPARK-4021
>>>
>>> On October 21, 2014 at 10:08:58 AM, Patrick Wendell (pwendell@gmail.com)
>>> wrote:
>>>
>>> Josh - the errors that broke our build indicated that JDK5 was being
>>> used. Somehow the upgrade caused our build to use a much older Java
>>> version. See the JIRA for more details.
>>>
>>> On Tue, Oct 21, 2014 at 10:05 AM, Josh Rosen <rosenville@gmail.com>
>>> wrote:
>>> > I find it concerning that there's a JDK version that breaks out build,
>>> since
>>> > we're supposed to support Java 7. Is 7u71 an upgrade or downgrade from
>>> the
>>> > JDK that we used before? Is there an easy way to fix our build so that
>>> it
>>> > compiles with 7u71's stricter settings?
>>> >
>>> > I'm not sure why the "New" PRB is failing here. It was originally
>>> created
>>> > as a clone of the main pull request builder job. I checked the
>>> configuration
>>> > history and confirmed that there aren't any settings that we've
>>> forgotten to
>>> > copy over (e.g. their configurations haven't diverged), so I'm not
>>> sure
>>> > what's causing this.
>>> >
>>> > - Josh
>>> >
>>> > On October 21, 2014 at 6:35:39 AM, Nan Zhu (zhunanmcgill@gmail.com)
>>> wrote:
>>> >
>>> > weird.....two buildings (one triggered by New, one triggered by Old)
>>> were
>>> > executed in the same node, amp-jenkins-slave-01, one compiles, one
>>> not...
>>> >
>>> > Best,
>>> >
>>> > --
>>> > Nan Zhu
>>> >
>>> >
>>> > On Tuesday, October 21, 2014 at 9:39 AM, Nan Zhu wrote:
>>> >
>>> >> seems that all PRs built by NewSparkPRBuilder suffers from 7u71,
>>> while
>>> >> SparkPRBuilder is working fine
>>> >>
>>> >> Best,
>>> >>
>>> >> --
>>> >> Nan Zhu
>>> >>
>>> >>
>>> >> On Tuesday, October 21, 2014 at 9:22 AM, Cheng Lian wrote:
>>> >>
>>> >> > It's a new pull request builder written by Josh, integrated into
>>> our
>>> >> > state-of-the-art PR dashboard :)
>>> >> >
>>> >> > On 10/21/14 9:33 PM, Nan Zhu wrote:
>>> >> > > just curious...what is this "NewSparkPullRequestBuilder"?
>>> >> > >
>>> >> > > Best,
>>> >> > >
>>> >> > > --
>>> >> > > Nan Zhu
>>> >> > >
>>> >> > >
>>> >> > > On Tuesday, October 21, 2014 at 8:30 AM, Cheng Lian wrote:
>>> >> > >
>>> >> > > >
>>> >> > > > Hm, seems that 7u71 comes back again. Observed similar Kinesis
>>> >> > > > compilation error just now:
>>> >> > > >
>>> https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBuilder/410/consoleFull
>>> >> > > >
>>> >> > > >
>>> >> > > > Checked Jenkins slave nodes, saw /usr/java/latest points to
>>> >> > > > jdk1.7.0_71. However, /usr/bin/javac -version says:
>>> >> > > >
>>> >> > > > >
>>> >> > > > > Eclipse Java Compiler 0.894_R34x, 3.4.2 release, Copyright
>>> IBM
>>> >> > > > > Corp 2000, 2008. All rights reserved.
>>> >> > > > >
>>> >> > > >
>>> >> > > >
>>> >> > > > Which JDK is actually used by Jenkins?
>>> >> > > >
>>> >> > > >
>>> >> > > > Cheng
>>> >> > > >
>>> >> > > >
>>> >> > > > On 10/21/14 8:28 AM, shane knapp wrote:
>>> >> > > >
>>> >> > > > > ok, so earlier today i installed a 2nd JDK within jenkins
>>> (7u71),
>>> >> > > > > which fixed the SparkR build but apparently made Spark itself
>>> quite unhappy.
>>> >> > > > > i removed that JDK, triggered a build (
>>> >> > > > >
>>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21943/console),
>>>
>>> >> > > > > and it compiled kinesis w/o dying a fiery death. apparently
>>> 7u71 is stricter
>>> >> > > > > when compiling. sad times. sorry about that! shane On Mon,
>>> Oct 20, 2014 at
>>> >> > > > > 5:16 PM, Patrick Wendell <pwendell@gmail.com> (mailto:
>>> pwendell@gmail.com)
>>> >> > > > > wrote:
>>> >> > > > > > The failure is in the Kinesis compoent, can you reproduce
>>> this
>>> >> > > > > > if you build with -Pkinesis-asl? - Patrick On Mon, Oct 20,
>>> 2014 at 5:08 PM,
>>> >> > > > > > shane knapp <sknapp@berkeley.edu> (mailto:
>>> sknapp@berkeley.edu) wrote:
>>> >> > > > > > > hmm, strange. i'll take a look. On Mon, Oct 20, 2014 at
>>> 5:11
>>> >> > > > > > > PM, Nan Zhu <zhunanmcgill@gmail.com> (mailto:
>>> zhunanmcgill@gmail.com) wrote:
>>> >> > > > > > > > yes, I can compile locally, too but it seems that
>>> Jenkins is
>>> >> > > > > > > > not happy now...
>>> >> > > > > > > >
>>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/ All
>>> >> > > > > > > > failed to compile Best, -- Nan Zhu On Monday, October
>>> 20, 2014 at 7:56 PM,
>>> >> > > > > > > > Ted Yu wrote:
>>> >> > > > > > > > > I performed build on latest master branch but didn't
>>> get
>>> >> > > > > > > > > compilation
>>> >> > > > > > > > >
>>> >> > > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > > error.
>>> >> > > > > > > > > FYI On Mon, Oct 20, 2014 at 3:51 PM, Nan Zhu
>>> >> > > > > > > > > <zhunanmcgill@gmail.com (mailto:
>>> zhunanmcgill@gmail.com)
>>> >> > > > > > > > >
>>> >> > > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > > (mailto:zhunanmcgill@gmail.com)> wrote:
>>> >> > > > > > > > > > Hi, I just submitted a patch
>>> >> > > > > > > > > >
>>> >> > > > > > > > > >
>>> >> > > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > > https://github.com/apache/spark/pull/2864/files
>>> >> > > > > > > > > > with one line change but the Jenkins told me it's
>>> failed
>>> >> > > > > > > > > > to compile on the unrelated
>>> >> > > > > > > > > >
>>> >> > > > > > > > > >
>>> >> > > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > >
>>> >> > > > > > >
>>> >> > > > > > >
>>> >> > > > > >
>>> >> > > > > > files?
>>> >> > > > > > > > > >
>>> >> > > > > > > > > >
>>> >> > > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > >
>>> >> > > > > >
>>> >> > > > > >
>>> >> > > > > >
>>> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21935/console
>>> >> > > > > > > > > > Best, Nan
>>> >> > > > > > > > > >
>>> >> > > > > > > > > >
>>> >> > > > > > > > >
>>> >> > > > > > > > >
>>> >> > > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > > >
>>> >> > > > > > >
>>> >> > > > > >
>>> >> > > > > >
>>> >> > > > > >
>>> >> > > > >
>>> >> > > > >
>>> >> > > > >
>>> >> > > >
>>> >> > > >
>>> >> > > >
>>> >> > > >
>>> >> > > >
>>> >> > > >
>>> >> > > >
>>> >> > >
>>> >> > >
>>> >> >
>>> >>
>>> >
>>>
>>>
>>
>

--001a1133eca6e8dd6b0505f50447--

From dev-return-9922-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 21 21:20:12 2014
Return-Path: <dev-return-9922-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EE4D117BFB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 21 Oct 2014 21:20:12 +0000 (UTC)
Received: (qmail 21783 invoked by uid 500); 21 Oct 2014 21:20:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21706 invoked by uid 500); 21 Oct 2014 21:20:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21690 invoked by uid 99); 21 Oct 2014 21:20:11 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 21:20:11 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.52 as permitted sender)
Received: from [209.85.215.52] (HELO mail-la0-f52.google.com) (209.85.215.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 21 Oct 2014 21:20:07 +0000
Received: by mail-la0-f52.google.com with SMTP id hz20so1858893lab.11
        for <dev@spark.apache.org>; Tue, 21 Oct 2014 14:19:45 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=pRZKc3V4qO57+sFmPAOn0/4f1rO65xhRS7bZDCVVXTU=;
        b=eSGxe3jLIjTvM/HwwMAb5itM9G75sildXCEdHx3MGTO6WMF8THc/0LXeMF2LcJx6XJ
         QLMqAjmAEF58+1+UAODNT0ymAvXjtSyd6rZoYtzR5eGjJsN7E9ML4mur1wD8QN5pX/px
         i7RsmyIxT5qIuxovTsn9jMq0hysK1hNG1Y8I9uoJ9FQCHoqKnR2TMdhnRJwdjyz3DGzk
         3ffqC3txmkQiftGuCG+uLjpFAJatUuIYnnoGYcPqvXuc1/EEfgzQ0myL4WJM0LttBb48
         smdAcmrxiiq+A4bQw8/+fEzCExxaJUjPZLm1t2/pakxiyHqaYEoqpT9aWDzZ7hMAtENb
         o9tA==
X-Gm-Message-State: ALoCoQk4H692fVp2vmv5CL1tqFEWHYAbKd7W/FRX2ZC1FVepdKFlewZbhpcdcPQdT528SznCh4/R
X-Received: by 10.112.28.75 with SMTP id z11mr36938125lbg.49.1413926385610;
 Tue, 21 Oct 2014 14:19:45 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.24.14 with HTTP; Tue, 21 Oct 2014 14:19:25 -0700 (PDT)
In-Reply-To: <CA+2Pv=i5gsx2zrOXc31biM=1M7gb5FJeO95jeCgHLQQPc2DXbQ@mail.gmail.com>
References: <CACdU-dTFr8k8Z54ZGcMgJ=PAEomq9QnbZ+O5cW8g+uSM1nnW+w@mail.gmail.com>
 <CAOhmDzd3eMmJt0h4OfUDJPyCXXUxzis1u=TJ9WNTg-4wfek9rw@mail.gmail.com>
 <CACdU-dSU=6uoqSMLTL0P6MRb4Fx=5D2jCx5m67Yw_XRRA1NDkA@mail.gmail.com>
 <CACdU-dSWZw1+wTMVicz+W5hmry5+Jo=u8zA_RsmTiD8crsn6hA@mail.gmail.com>
 <CACdU-dTtDddcGZBQ7QKJVE-GoK8g_hjinY5iF8wXf8W3f0PN+g@mail.gmail.com>
 <CAOhmDzfK+GmQC_rUrpn22jzxm9y5BMR5fzHNiPodHzdTBLs_Tw@mail.gmail.com>
 <CACdU-dRLb_D6vM9fWGBWWG=0yc2k4JvWvV5For-4mQPBiNrUVg@mail.gmail.com>
 <CAOhmDzf=L5JvQO65x0SOeSLLdun6W2WqwmFzp-QRHBrQaAYY8w@mail.gmail.com>
 <CACdU-dTai_mrqf8jB2K+RRTUO+APU7R9je6KE89_wYF3xMYUew@mail.gmail.com>
 <CAOhmDze_MF1qMxPCV_FbLxFqRPgcioELwqzyTKbPwnXAhT3PZg@mail.gmail.com>
 <CACdU-dSEdZB2GyBeUJ9OD0oRNZ2YfgRf+05jnhfm7mzU-s9Lkw@mail.gmail.com>
 <CAOhmDzeZjHfS04qGH7aQODKcdCQS22-MqdpvdDbRYyZah1O+2A@mail.gmail.com>
 <CACdU-dTzOBc_PSi8E=sMTvFxZXzst6E9Bgfg_KFmoNALT=xsBw@mail.gmail.com>
 <CACdU-dSea+ETt6hipNzVHtaiAN4Wd_VpSNkwJaZrALfy8X8nQA@mail.gmail.com>
 <CA+2Pv=jYG3gTu4yxtanaGp4_uBeyb+Q_yX97kaMG0BpZ2OL3DA@mail.gmail.com>
 <etPan.5441bf93.643c9869.107@joshs-mbp> <CA+2Pv=iv=qJAycXYk5pHq8+Jf9qcd=tEEDp63djnano3A1c6bw@mail.gmail.com>
 <etPan.5442034a.74b0dc51.107@joshs-mbp.att.net> <CA+2Pv=i5gsx2zrOXc31biM=1M7gb5FJeO95jeCgHLQQPc2DXbQ@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 21 Oct 2014 14:19:25 -0700
Message-ID: <CACdU-dSa_TQUZV9dJZb06CjVf-KS06vtHZvJ8ZNpsE2+0KGSZg@mail.gmail.com>
Subject: Re: short jenkins downtime -- trying to get to the bottom of the git
 fetch timeouts
To: Davies Liu <davies@databricks.com>
Cc: Josh Rosen <rosenville@gmail.com>, Nicholas Chammas <nicholas.chammas@gmail.com>, 
	amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133eca6f3f79d0505f563b2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133eca6f3f79d0505f563b2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

i've seen a few more builds fail w/timeouts and it appears that we're
definitely NOT hitting any rate limiting.

https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/22005/co=
nsole

[jenkins@amp-jenkins-slave-01 ~]$ curl -i -H "Authorization: token
<REDACTED>" https://api.github.com | grep Rate
X-RateLimit-Limit: 5000
X-RateLimit-Remaining: 4997
X-RateLimit-Reset: 1413929848
Access-Control-Expose-Headers: ETag, Link, X-GitHub-OTP, X-RateLimit-Limit,
X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes,
X-Accepted-OAuth-Scopes, X-Poll-Interval

On Sat, Oct 18, 2014 at 12:44 AM, Davies Liu <davies@databricks.com> wrote:

> Cool, the recent 4 build had used the new configs, thanks!
>
> Let's run more builds.
>
> Davies
>
> On Fri, Oct 17, 2014 at 11:06 PM, Josh Rosen <rosenville@gmail.com> wrote=
:
> > I think that the fix was applied.  Take a look at
> >
> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/21874/=
consoleFull
> >
> > Here, I see a fetch command that mentions this specific PR branch rathe=
r
> > than the wildcard that we had before:
> >
> >  > git fetch --tags --progress https://github.com/apache/spark.git
> > +refs/pull/2840/*:refs/remotes/origin/pr/2840/* # timeout=3D15
> >
> >
> > Do you have an example of a Spark PRB build that=E2=80=99s still failin=
g with the
> > old fetch failure?
> >
> > - Josh
> >
> > On October 17, 2014 at 11:03:14 PM, Davies Liu (davies@databricks.com)
> > wrote:
> >
> > How can we know the changes has been applied? I had checked several
> > recent builds, they all use the original configs.
> >
> > Davies
> >
> > On Fri, Oct 17, 2014 at 6:17 PM, Josh Rosen <rosenville@gmail.com>
> wrote:
> >> FYI, I edited the Spark Pull Request Builder job to try this out. Let=
=E2=80=99s
> >> see
> >> if it works (I=E2=80=99ll be around to revert if it doesn=E2=80=99t).
> >>
> >> On October 17, 2014 at 5:26:56 PM, Davies Liu (davies@databricks.com)
> >> wrote:
> >>
> >> One finding is that all the timeout happened with this command:
> >>
> >> git fetch --tags --progress https://github.com/apache/spark.git
> >> +refs/pull/*:refs/remotes/origin/pr/*
> >>
> >> I'm thinking that maybe this may be a expensive call, we could try to
> >> use a more cheap one:
> >>
> >> git fetch --tags --progress https://github.com/apache/spark.git
> >> +refs/pull/XXX/*:refs/remotes/origin/pr/XXX/*
> >>
> >> XXX is the PullRequestID,
> >>
> >> The configuration support parameters [1], so we could put this in :
> >>
> >> +refs/pull//${ghprbPullId}/*:refs/remotes/origin/pr/${ghprbPullId}/*
> >>
> >> I have not tested this yet, could you give this a try?
> >>
> >> Davies
> >>
> >>
> >> [1]
> >>
> >>
> https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder+p=
lugin
> >>
> >> On Fri, Oct 17, 2014 at 5:00 PM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >>> actually, nvm, you have to be run that command from our servers to
> affect
> >>> our limit. run it all you want from your own machines! :P
> >>>
> >>> On Fri, Oct 17, 2014 at 4:59 PM, shane knapp <sknapp@berkeley.edu>
> wrote:
> >>>
> >>>> yep, and i will tell you guys ONLY if you promise to NOT try this
> >>>> yourselves... checking the rate limit also counts as a hit and
> >>>> increments
> >>>> our numbers:
> >>>>
> >>>> # curl -i https://api.github.com/users/whatever 2> /dev/null | egrep
> >>>> ^X-Rate
> >>>> X-RateLimit-Limit: 60
> >>>> X-RateLimit-Remaining: 51
> >>>> X-RateLimit-Reset: 1413590269
> >>>>
> >>>> (yes, that is the exact url that they recommended on the github site
> >>>> lol)
> >>>>
> >>>> so, earlier today, we had a spark build fail w/a git timeout at
> 10:57am,
> >>>> but there were only ~7 builds run that hour, so that points to us NO=
T
> >>>> hitting the rate limit... at least for this fail. whee!
> >>>>
> >>>> is it beer-thirty yet?
> >>>>
> >>>> shane
> >>>>
> >>>>
> >>>>
> >>>> On Fri, Oct 17, 2014 at 4:52 PM, Nicholas Chammas <
> >>>> nicholas.chammas@gmail.com> wrote:
> >>>>
> >>>>> Wow, thanks for this deep dive Shane. Is there a way to check if we
> are
> >>>>> getting hit by rate limiting directly, or do we need to contact
> GitHub
> >>>>> for that?
> >>>>>
> >>>>> 2014=EB=85=84 10=EC=9B=94 17=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, =
shane knapp<sknapp@berkeley.edu>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=
=9C =EB=A9=94=EC=8B=9C=EC=A7=80:
> >>>>>
> >>>>> quick update:
> >>>>>>
> >>>>>> here are some stats i scraped over the past week of ALL pull reque=
st
> >>>>>> builder projects and timeout failures. due to the large number of
> >>>>>> spark
> >>>>>> ghprb jobs, i don't have great records earlier than oct 7th. the
> data
> >>>>>> is
> >>>>>> current up until ~230pm today:
> >>>>>>
> >>>>>> spark and new spark ghprb total builds vs git fetch timeouts:
> >>>>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep=
 -i
> >>>>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -i spark | wc -l)=
;
> let
> >>>>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$=
total" |
> >>>>>> bc
> >>>>>> |
> >>>>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
> >>>>>> $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
> >>>>>> 10-09 -- total builds: 140 p/f: 92/48 fail%: 34%
> >>>>>> 10-10 -- total builds: 65 p/f: 59/6 fail%: 09%
> >>>>>> 10-11 -- total builds: 29 p/f: 29/0 fail%: 0%
> >>>>>> 10-12 -- total builds: 24 p/f: 21/3 fail%: 12%
> >>>>>> 10-13 -- total builds: 39 p/f: 35/4 fail%: 10%
> >>>>>> 10-14 -- total builds: 7 p/f: 5/2 fail%: 28%
> >>>>>> 10-15 -- total builds: 37 p/f: 34/3 fail%: 08%
> >>>>>> 10-16 -- total builds: 71 p/f: 59/12 fail%: 16%
> >>>>>> 10-17 -- total builds: 26 p/f: 20/6 fail%: 23%
> >>>>>>
> >>>>>> all other ghprb builds vs git fetch timeouts:
> >>>>>> $ for x in 10-{09..17}; do passed=3D$(grep $x SORTED.passed | grep=
 -vi
> >>>>>> spark | wc -l); failed=3D$(grep $x SORTED | grep -vi spark | wc -l=
);
> let
> >>>>>> total=3Dpassed+failed; fail_percent=3D$(echo "scale=3D2; $failed/$=
total" |
> >>>>>> bc
> >>>>>> |
> >>>>>> sed "s/^\.//g"); line=3D"$x -- total builds: $total\tp/f:
> >>>>>> $passed/$failed\tfail%: $fail_percent%"; echo -e $line; done
> >>>>>> 10-09 -- total builds: 16 p/f: 16/0 fail%: 0%
> >>>>>> 10-10 -- total builds: 46 p/f: 40/6 fail%: 13%
> >>>>>> 10-11 -- total builds: 4 p/f: 4/0 fail%: 0%
> >>>>>> 10-12 -- total builds: 2 p/f: 2/0 fail%: 0%
> >>>>>> 10-13 -- total builds: 2 p/f: 2/0 fail%: 0%
> >>>>>> 10-14 -- total builds: 10 p/f: 10/0 fail%: 0%
> >>>>>> 10-15 -- total builds: 5 p/f: 5/0 fail%: 0%
> >>>>>> 10-16 -- total builds: 5 p/f: 5/0 fail%: 0%
> >>>>>> 10-17 -- total builds: 0 p/f: 0/0 fail%: 0%
> >>>>>>
> >>>>>> note: the 15th was the day i rolled back to the earlier version of
> the
> >>>>>> git plugin. it doesn't seem to have helped much, so i'll probably
> >>>>>> bring
> >>>>>> us
> >>>>>> back up to the latest version soon.
> >>>>>> also note: rocking some floating point math on the CLI! ;)
> >>>>>>
> >>>>>> i also compared the distribution of git timeout failures vs time o=
f
> >>>>>> day,
> >>>>>> and there appears to be no correlation. the failures are pretty
> evenly
> >>>>>> distributed over each hour of the day.
> >>>>>>
> >>>>>> we could be hitting the rate limit due to the ghprb hitting github=
 a
> >>>>>> couple of times for each build, but we're averaging ~10-20 builds
> per
> >>>>>> hour
> >>>>>> (a build hits github 2-4 times, from what i can tell). i'll have t=
o
> >>>>>> look
> >>>>>> more in to this on monday, but suffice to say we may need to move
> from
> >>>>>> unauthorized https fetches to authorized requests. this means
> >>>>>> retrofitting
> >>>>>> all of our jobs. yay! fun! :)
> >>>>>>
> >>>>>> another option is to have local mirrors of all of the repos. the
> >>>>>> problem w/this is that there might be a window where changes haven=
't
> >>>>>> made
> >>>>>> it to the local mirror and tests run against it. more fun stuff to
> >>>>>> think
> >>>>>> about...
> >>>>>>
> >>>>>> now that i have some stats, and a list of all of the times/dates o=
f
> >>>>>> the
> >>>>>> failures, i will be drafting my email to github and firing that of=
f
> >>>>>> later
> >>>>>> today or first thing monday.
> >>>>>>
> >>>>>> have a great weekend everyone!
> >>>>>>
> >>>>>> shane, who spent way too much time on the CLI and is ready for som=
e
> >>>>>> beer.
> >>>>>>
> >>>>>> On Thu, Oct 16, 2014 at 1:04 PM, Nicholas Chammas <
> >>>>>> nicholas.chammas@gmail.com> wrote:
> >>>>>>
> >>>>>>> On Thu, Oct 16, 2014 at 3:55 PM, shane knapp <sknapp@berkeley.edu=
>
> >>>>>>> wrote:
> >>>>>>>
> >>>>>>>> i really, truly hate non-deterministic failures.
> >>>>>>>
> >>>>>>>
> >>>>>>> Amen bruddah.
> >>>>>>>
> >>>>>>
> >>>>>>
> >>>>
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
>

--001a1133eca6f3f79d0505f563b2--

From dev-return-9923-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 11:00:14 2014
Return-Path: <dev-return-9923-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DE1021766D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 11:00:13 +0000 (UTC)
Received: (qmail 67115 invoked by uid 500); 22 Oct 2014 11:00:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 67044 invoked by uid 500); 22 Oct 2014 11:00:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 67032 invoked by uid 99); 22 Oct 2014 11:00:12 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 11:00:12 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id 6024C42DFB
	for <dev@spark.apache.org>; Wed, 22 Oct 2014 11:00:33 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id 556F9435BE; Wed, 22 Oct 2014 11:00:33 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-0.7 required=10.0 tests=DKIM_SIGNED,DKIM_VALID,
	DKIM_VALID_AU,RCVD_IN_DNSWL_BLOCKED,RCVD_IN_MSPIKE_H2,SPF_PASS
	autolearn=disabled version=3.4.0
Received: from mail-pd0-f178.google.com (mail-pd0-f178.google.com [209.85.192.178])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id EEB0B42DFB
	for <dev@spark.apache.org>; Wed, 22 Oct 2014 11:00:32 +0000 (UTC)
Received: by mail-pd0-f178.google.com with SMTP id y10so3265205pdj.23
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 04:00:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject
         :content-type:content-transfer-encoding;
        bh=jM0TCedg5l+kND1F0wfAghTyjmSgdT8G+zuQ9HDfCCM=;
        b=nEJ7FuXepR/s6ecMNY+dojrQ0yXwT0ix4bdLFZjmDl2lz9v1iWEGfsZPjWczV7REGP
         g11CD7EgpCRXywRGlwIMXH4tEnCnO9zjOkECYCpp2Ey2MTuIrX07ul7Y8X0TeVtTEs71
         yLIxuj7SIRPEQClNDQghZcMSnL8ojK92CfLFVfB3pckXpFl5yy1JGqD8KJ+nSPo0ivwK
         lefj0YPcPJ+0t1kZkooyHRgQGGN/V3swjbTLU9Jz2XcAIZubQK8tdl7Qjc87tFjh4zdk
         W9Xl/gH2pSP3rKZOLyKjzpP1WOiTTchmBQ2S1a6Us+H0RhMedi5LEpkF8QK6dBOUkmpu
         HeGg==
X-Received: by 10.68.221.69 with SMTP id qc5mr824492pbc.159.1413975610084;
        Wed, 22 Oct 2014 04:00:10 -0700 (PDT)
Received: from [172.16.36.2] (104.128.83.4.16clouds.com. [104.128.83.4])
        by mx.google.com with ESMTPSA id fk10sm1761699pab.29.2014.10.22.04.00.08
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Wed, 22 Oct 2014 04:00:09 -0700 (PDT)
Message-ID: <54478E38.4030507@gmail.com>
Date: Wed, 22 Oct 2014 19:00:08 +0800
From: Theodore Si <sjyzhxw@gmail.com>
User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64; rv:31.0) Gecko/20100101 Thunderbird/31.2.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Which part of the code deals with communication?
Content-Type: text/plain; charset=gbk; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Scanned: ClamAV using ClamSMTP

Hi all,

Workers will exchange data in between, right?

What classes are in charge of these actions?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9924-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 13:26:41 2014
Return-Path: <dev-return-9924-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 890A0179C4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 13:26:41 +0000 (UTC)
Received: (qmail 40772 invoked by uid 500); 22 Oct 2014 13:26:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40704 invoked by uid 500); 22 Oct 2014 13:26:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40692 invoked by uid 99); 22 Oct 2014 13:26:40 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 13:26:40 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of awasthi.manoj@gmail.com designates 209.85.220.54 as permitted sender)
Received: from [209.85.220.54] (HELO mail-pa0-f54.google.com) (209.85.220.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 13:26:34 +0000
Received: by mail-pa0-f54.google.com with SMTP id rd3so3010039pab.27
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 06:26:14 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=yzTk6U9Oj63wD9vDiiLf6X3PSc0J2EeH7zWtFNqOAVI=;
        b=E/bVcrs+AvFVB/IyGjUr+WiEWWv+NiKol18fevQwajB86Eqc/tWsjNAPLQCIH2h+9b
         Xk5ZUTqoyFXeHF2GJ9ODU6I4w550DkwquDjhI1s4GqB1NtIJZfj1ThB/ToY7wRbaw0fW
         lkwsn5JLUVwNMrc0JiEuBcoi9OzQiEIS3p5Z8RNXHccaEhXdoyHZ1HQNMlDbVBKC/Hqj
         7eJ7FQ8kIpWRrOf3gmbLWAN9l0CWoWVYrTEoNreuuVBPEM3WCCSISb1/JrApSq1RM6a6
         VFpkrwhJJkdmV8mS6DaqpYdEsylHCmQ71cytEZ3+Vp6+jkMToorN3Q8aAV+SjEVjxJi5
         PwYg==
MIME-Version: 1.0
X-Received: by 10.66.140.76 with SMTP id re12mr1609098pab.147.1413984374217;
 Wed, 22 Oct 2014 06:26:14 -0700 (PDT)
Received: by 10.70.102.101 with HTTP; Wed, 22 Oct 2014 06:26:14 -0700 (PDT)
Date: Wed, 22 Oct 2014 18:56:14 +0530
Message-ID: <CAJ0+auypqrkONwC_aWBfbBq8qnSyP=YD9CQUu2bmCxuZ+GwCtg@mail.gmail.com>
Subject: Graphx connectComponents API
From: Manoj Awasthi <awasthi.manoj@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11331dfa57e1ac050602e424
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11331dfa57e1ac050602e424
Content-Type: text/plain; charset=UTF-8

Hi Guys,

I am trying something very basic. I am using GraphX to load a graph from an
edge list file which is like this:

*220 224*
*400 401*
*220 221*

So it has following nodes (just for the sake of understanding - bear with
me for drawing):

*220 => 224          400 => 401 *
* ||*

* v 221*

Clearly, there are two "connected components" in this graph (please CMIIW).
Following is my code:


*val graph = GraphLoader.edgeListFile(sc, inputFile)*

*val componentLowestVertexGraph = graph.connectedComponents*
*componentLowestVertexGraph.vertices.collect.foreach(x => {*
*      println(x._1) // print node id's*
*  })*

gives me following result:

*224*
*401*
*220*
*221*
*400*

Per the documentation of connectedComponents:

*return a graph with the vertex value containing the lowest vertex id in
the connected component containing that vertex.*

So I was expecting to get two vertices returned for above cases.

Can some one point out if I am missing something?

Manoj

--001a11331dfa57e1ac050602e424--

From dev-return-9925-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 13:36:22 2014
Return-Path: <dev-return-9925-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 063D4179F5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 13:36:22 +0000 (UTC)
Received: (qmail 61365 invoked by uid 500); 22 Oct 2014 13:36:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61277 invoked by uid 500); 22 Oct 2014 13:36:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61255 invoked by uid 99); 22 Oct 2014 13:36:20 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 13:36:20 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id A090043C84
	for <dev@spark.apache.org>; Wed, 22 Oct 2014 13:36:41 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id 955E443C86; Wed, 22 Oct 2014 13:36:41 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: **
X-Spam-Status: No, score=2.1 required=10.0 tests=DKIM_SIGNED,DKIM_VALID,
	DKIM_VALID_AU,HTML_MESSAGE,RCVD_IN_DNSWL_BLOCKED,RCVD_IN_MSPIKE_H3,
	RCVD_IN_MSPIKE_WL,SPF_PASS autolearn=disabled version=3.4.0
Received: from mail-pa0-f54.google.com (mail-pa0-f54.google.com [209.85.220.54])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id 48EBE43C84
	for <dev@spark.apache.org>; Wed, 22 Oct 2014 13:36:41 +0000 (UTC)
Received: by mail-pa0-f54.google.com with SMTP id rd3so3012619pab.13
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 06:36:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=7jqbMYiQ47DBRqDQL6ly/Q7npFQkBtKXuABf9unnxvc=;
        b=HGK14x8R1zxN8L68BgCLPQmeD46m0M+EdCW8oGFC4hT8XNKEivpevojna8hyBMPwhG
         upInpPKFC+wcRNRk+oTAaW4gWg1lvn3/z6y3JR2lL5IJJxPGy63+i7zMlkAg76JtOO7D
         SufcoBZxDY59T8UZ5kgfdAALNZ6ZMakBibkZb1gL6Khmj0Tzhn1Rq49HbNJNis/mXDF6
         oN1kszFZYd52rGxCCygJdoT13Wd4AToUEE24oPE8cL7rWmmlxUiLqXNehKucOrNhuVFB
         IhrqTXtXTuo+1pYqDFn9axMC/zHlZEX+4bjul8VFL4R8oZpEnkTV9V0vsJGILIC7RvZ6
         cT1A==
MIME-Version: 1.0
X-Received: by 10.70.44.193 with SMTP id g1mr2977802pdm.10.1413984978035; Wed,
 22 Oct 2014 06:36:18 -0700 (PDT)
Received: by 10.70.102.101 with HTTP; Wed, 22 Oct 2014 06:36:17 -0700 (PDT)
In-Reply-To: <CAJ0+auypqrkONwC_aWBfbBq8qnSyP=YD9CQUu2bmCxuZ+GwCtg@mail.gmail.com>
References: <CAJ0+auypqrkONwC_aWBfbBq8qnSyP=YD9CQUu2bmCxuZ+GwCtg@mail.gmail.com>
Date: Wed, 22 Oct 2014 19:06:17 +0530
Message-ID: <CAJ0+auxSTXHxi_uTD45KMq9qn-AfiMccU0ki6+ibfTobQbnjcQ@mail.gmail.com>
Subject: Re: Graphx connectComponents API
From: Manoj Awasthi <awasthi.manoj@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=047d7bfe93c8556b510506030851
X-Virus-Scanned: ClamAV using ClamSMTP

--047d7bfe93c8556b510506030851
Content-Type: text/plain; charset=UTF-8

Well - resolved.

The problem was in my understanding. It returns the graph with vertex
"data" set to the connected components.

Thanks.

On Wed, Oct 22, 2014 at 6:56 PM, Manoj Awasthi <awasthi.manoj@gmail.com>
wrote:

> Hi Guys,
>
> I am trying something very basic. I am using GraphX to load a graph from
> an edge list file which is like this:
>
> *220 224*
> *400 401*
> *220 221*
>
> So it has following nodes (just for the sake of understanding - bear with
> me for drawing):
>
> *220 => 224          400 => 401 *
> * ||*
>
> * v 221*
>
> Clearly, there are two "connected components" in this graph (please
> CMIIW). Following is my code:
>
>
> *val graph = GraphLoader.edgeListFile(sc, inputFile)*
>
> *val componentLowestVertexGraph = graph.connectedComponents*
> *componentLowestVertexGraph.vertices.collect.foreach(x => {*
> *      println(x._1) // print node id's            <========== HERE IT
> SHOULD BE ._2 *
> *  })*
>
> gives me following result:
>
> *224*
> *401*
> *220*
> *221*
> *400*
>
> Per the documentation of connectedComponents:
>
> *return a graph with the vertex value containing the lowest vertex id in
> the connected component containing that vertex.*
>
> So I was expecting to get two vertices returned for above cases.
>
> Can some one point out if I am missing something?
>
> Manoj
>

--047d7bfe93c8556b510506030851--

From dev-return-9926-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 16:06:10 2014
Return-Path: <dev-return-9926-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EE43E171B6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 16:06:09 +0000 (UTC)
Received: (qmail 83475 invoked by uid 500); 22 Oct 2014 16:06:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83403 invoked by uid 500); 22 Oct 2014 16:06:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83386 invoked by uid 99); 22 Oct 2014 16:06:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 16:06:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of holden.karau@gmail.com designates 209.85.212.176 as permitted sender)
Received: from [209.85.212.176] (HELO mail-wi0-f176.google.com) (209.85.212.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 16:05:43 +0000
Received: by mail-wi0-f176.google.com with SMTP id n3so1333723wiv.15
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 09:05:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=Cw4Tm4iwnvSgTVYyW6DoLzaCHi5/focHkMOXAxsTx5Y=;
        b=f2d1GwCLYohKWtre2NYc3jVmJ2LY4fIhja+pMoCtmHsyYhCIAq70Klse9kD5VW6kiK
         WX3pR+jHMDBCRHLXeNfmFbi7a4YvEkiEUt+tESMFnJR44AU+JTAc12HQtQHiZiNO+jTZ
         NypAc2G1KiCwPegQRdSc0xzwGnYhO1HnnTOCbfqF0Cnjh1asPF2YEEsauqyFfUFQPcx3
         Snx7WbZ/1Z+1xCfSKiqNSpT6jSlSvQtvmUgMfxNbp90Cdm1zbGcXOLQ7eVgYFY8P+61R
         h0wT4jS/58oy2JBE3u+Quho4Y9q8/9oEgiaR1qw1leVHJFqaXC6Pm+nDFtQkb3jOwDb9
         dzzQ==
MIME-Version: 1.0
X-Received: by 10.180.100.136 with SMTP id ey8mr6660194wib.83.1413993942741;
 Wed, 22 Oct 2014 09:05:42 -0700 (PDT)
Sender: holden.karau@gmail.com
Received: by 10.194.6.65 with HTTP; Wed, 22 Oct 2014 09:05:42 -0700 (PDT)
In-Reply-To: <CAMAsSd+5oxJLnOj32QuZczJBkbBFszCksVDP1qP6gfXapg_42g@mail.gmail.com>
References: <CAMAsSd+5oxJLnOj32QuZczJBkbBFszCksVDP1qP6gfXapg_42g@mail.gmail.com>
Date: Wed, 22 Oct 2014 09:05:42 -0700
X-Google-Sender-Auth: JKRKq2hxdKFN82ZTgSNzLONvCOU
Message-ID: <CAJLcJd9cPAR+hPeE5yj-COss=2ByVBbtUENNX=55+mV5AQHpGA@mail.gmail.com>
Subject: Re: Easy win: SBT plugin config expert to help on SPARK-3359?
From: Holden Karau <holden@pigscanfly.ca>
To: Sean Owen <sowen@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d0444ec99abf8a90506051e17
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d0444ec99abf8a90506051e17
Content-Type: text/plain; charset=UTF-8

Hi Sean,

I've pushed a PR for this https://github.com/apache/spark/pull/2893 :)

Cheers,

Holden :)

On Tue, Oct 21, 2014 at 4:41 AM, Sean Owen <sowen@cloudera.com> wrote:

> This one can be resolved, I think, with a bit of help from someone who
> understands SBT + plugin config:
>
> https://issues.apache.org/jira/browse/SPARK-3359
>
> Just a matter of figuring out how to set a property on the plugin.
> This would make Java 8 javadoc work much more nicely. Minor but
> useful!
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 
Cell : 425-233-8271

--f46d0444ec99abf8a90506051e17--

From dev-return-9927-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 16:52:49 2014
Return-Path: <dev-return-9927-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5B4D6173E4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 16:52:49 +0000 (UTC)
Received: (qmail 40962 invoked by uid 500); 22 Oct 2014 16:52:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40896 invoked by uid 500); 22 Oct 2014 16:52:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40877 invoked by uid 99); 22 Oct 2014 16:52:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 16:52:47 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of bbejeck@gmail.com designates 209.85.213.175 as permitted sender)
Received: from [209.85.213.175] (HELO mail-ig0-f175.google.com) (209.85.213.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 16:52:20 +0000
Received: by mail-ig0-f175.google.com with SMTP id uq10so1286380igb.8
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 09:52:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=1YyL9XUsfu9/zI2UD43SkxKZQ4/kwFk2FkkaErRP5fY=;
        b=Hsd9/McQPKBE+64ZVPaKYICuCZxflfu9+AKX8sRLUAGChVLoDpVqPD3BX2+xBjyrU2
         QUBx/Ki/fR9IApi5WzbI8jscUSO3imZhHXDMRS68JDe3oTprEajmxTQukK7fNuCB/OXi
         ZXaOvhRbKoh/ApyDv50s0RqPV/fyteoX8Fhd+hbDCJOYhN5OZxkFR77RDofZnkml66bU
         7snMIiSo/Ub+HuOisklZ3sp6uzM/aKdCNQ6FBc5s6ctLpc0b1YnGN2axn0cBOz3oZYvx
         CKNgpYLC/21bVtw3lQAO0GxSqyxiWphmkBHkW4oRRWEIWX9dbKLE3v4CbkHeuiXpj8s1
         aH8g==
MIME-Version: 1.0
X-Received: by 10.42.94.131 with SMTP id b3mr2553073icn.92.1413996739472; Wed,
 22 Oct 2014 09:52:19 -0700 (PDT)
Received: by 10.64.242.196 with HTTP; Wed, 22 Oct 2014 09:52:19 -0700 (PDT)
Date: Wed, 22 Oct 2014 12:52:19 -0400
Message-ID: <CAF7WS+pCsscu=1Wmjvsqt+9+_dtUSsxr1LZJupKg7FhwfYyASg@mail.gmail.com>
Subject: SPARK-3299 jira task question
From: Bill Bejeck <bbejeck@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=485b397dd2935eb246050605c5da
X-Virus-Checked: Checked by ClamAV on apache.org

--485b397dd2935eb246050605c5da
Content-Type: text/plain; charset=UTF-8

Since this task involves making changes to some of core functionality, I
figured it's best if I share my intents for completing this task.

This change is a little more involved as it requires modifying the Catalog
trait.
My current plan is to add an abstract method to the Catalog trait and have
any objects extending Catalog override a 'listTables' method.
The SQLContext object uses an instance of SimpleCatalog for any table
operations. Any additional public method defined to list the tables will
delegate to the SimpleCatalog instance. This approach follows the pattern
used for registering tables with the SQLContext.

Any feedback is appreciated.

Thanks,
Bill

--485b397dd2935eb246050605c5da--

From dev-return-9928-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 17:24:59 2014
Return-Path: <dev-return-9928-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 28DB3175DB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 17:24:59 +0000 (UTC)
Received: (qmail 71450 invoked by uid 500); 22 Oct 2014 17:24:58 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71383 invoked by uid 500); 22 Oct 2014 17:24:58 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71367 invoked by uid 99); 22 Oct 2014 17:24:57 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 17:24:57 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id C5ADA435BE
	for <dev@spark.apache.org>; Wed, 22 Oct 2014 17:25:19 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id BA992435AE; Wed, 22 Oct 2014 17:25:19 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-0.8 required=10.0 tests=DKIM_SIGNED,DKIM_VALID,
	DKIM_VALID_AU,RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,RCVD_IN_MSPIKE_WL,SPF_PASS,
	URIBL_BLOCKED autolearn=disabled version=3.4.0
Received: from mail-ob0-f169.google.com (mail-ob0-f169.google.com [209.85.214.169])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id 649A9435BE
	for <dev@spark.apache.org>; Wed, 22 Oct 2014 17:25:19 +0000 (UTC)
Received: by mail-ob0-f169.google.com with SMTP id m8so3358739obr.0
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 10:24:11 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=vH6HgofadD0uNU6TJglxagkqw46U99GJhulhKEHcNyI=;
        b=D8Kj9pxjumEzX0iiKRI+l6Pa63UNZ+3dVs2TtqQNfqYbzxuA1LWQsgtm8lrAGkiYZD
         0sArrzEFbPerr0qKrFen1fBPf9uChA+YOoWad9ECYeSs3y8+2Tw0cs8/GmBoPy4mBFDj
         fALUnKyXK6HZKXeNh5LfJSHarbQb3lmcTItOAlPZlIuaM3EALnqc4HjTSNBqHsHHYtT9
         vJhop8Q6scJk6sxb98YhRSh+sFaUDIbetApR6mptfqpwK0wlWsZyBaM2GdiqV5wpA32X
         MMzCBDeeQMWWKhAWh6z+Q3R0ti7V0Z3fpmEzvl4wf4vurA9fTr8YeRVRJCinKEoUDXHf
         264Q==
MIME-Version: 1.0
X-Received: by 10.202.88.66 with SMTP id m63mr34551991oib.11.1413998651221;
 Wed, 22 Oct 2014 10:24:11 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Wed, 22 Oct 2014 10:24:11 -0700 (PDT)
In-Reply-To: <54478E38.4030507@gmail.com>
References: <54478E38.4030507@gmail.com>
Date: Wed, 22 Oct 2014 10:24:11 -0700
Message-ID: <CABPQxstHUw+kF12DDvy7LXkOPm99G_5iQbGnoDJH_3UNeVFVtw@mail.gmail.com>
Subject: Re: Which part of the code deals with communication?
From: Patrick Wendell <pwendell@gmail.com>
To: Theodore Si <sjyzhxw@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Scanned: ClamAV using ClamSMTP

The best documentation about communication interfaces is the
SecurityManager doc written by Tom Graves. With this as a starting
point I'd recommend digging through the code for each component.

https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SecurityManager.scala#L59

On Wed, Oct 22, 2014 at 4:00 AM, Theodore Si <sjyzhxw@gmail.com> wrote:
> Hi all,
>
> Workers will exchange data in between, right?
>
> What classes are in charge of these actions?
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9929-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 18:47:53 2014
Return-Path: <dev-return-9929-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5B86F17977
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 18:47:53 +0000 (UTC)
Received: (qmail 35220 invoked by uid 500); 22 Oct 2014 18:47:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35151 invoked by uid 500); 22 Oct 2014 18:47:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34027 invoked by uid 99); 22 Oct 2014 18:47:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 18:47:49 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of ashwinshankar77@gmail.com designates 209.85.192.47 as permitted sender)
Received: from [209.85.192.47] (HELO mail-qg0-f47.google.com) (209.85.192.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 18:47:22 +0000
Received: by mail-qg0-f47.google.com with SMTP id i50so2957008qgf.6
        for <multiple recipients>; Wed, 22 Oct 2014 11:47:21 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=fTtbvmFbNqvQkVFxqaLrjhipIYItiQTFCLleTFvQgKg=;
        b=CQor6lPhQegSe0fKxL8VwzX0066hwDhLO9MNcd9DgAfaTuTj1YACxnSGtwQkP8IzuU
         Nmp68icWvmwe+4hswogtMjtMj1xwOecghXDJ32DchX7t6j/QiZS0kS0a9AtmWmHyFpZ7
         rUm9KI1UNFbxSFU+/qlqiiSoJaWD020sfH0w69CXMQmiLwqctVtJcnwW2gwp03trbM94
         2FroruHVWx3Ps8DS8Qt8Pzfha64w/y0o9sTm79nCKlnMtp8AxqYwVdaNqcik7VLYqtL9
         PB/ZuNlJpyYsrVy/Wvuk2MkWdjrc//rch0yLtW2iRRMLdN6Ax7XRfZiCQQjtjav9741H
         MY7A==
MIME-Version: 1.0
X-Received: by 10.140.48.41 with SMTP id n38mr55951898qga.1.1414003641171;
 Wed, 22 Oct 2014 11:47:21 -0700 (PDT)
Received: by 10.140.93.34 with HTTP; Wed, 22 Oct 2014 11:47:21 -0700 (PDT)
Date: Wed, 22 Oct 2014 11:47:21 -0700
Message-ID: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
Subject: Multitenancy in Spark - within/across spark context
From: Ashwin Shankar <ashwinshankar77@gmail.com>
To: dev@spark.apache.org, user@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11352550be46db050607601d
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11352550be46db050607601d
Content-Type: text/plain; charset=UTF-8

Hi Spark devs/users,
One of the things we are investigating here at Netflix is if Spark would
suit us for our ETL needs, and one of requirements is multi tenancy.
I did read the official doc
<http://spark.apache.org/docs/latest/job-scheduling.html> and the book, but
I'm still not clear on certain things.

Here are my questions :
1. *Sharing spark context* : How exactly multiple users can share the
cluster using same spark
    context ? UserA wants to run AppA, UserB wants to run AppB. How do they
talk to same
    context ? How exactly are each of their jobs scheduled and run in same
context?
    Is preemption supported in this scenario ? How are user names passed on
to the spark context ?

2. *Different spark context in YARN*: assuming I have a YARN cluster with
queues and preemption
    configured. Are there problems if executors/containers of a spark app
are preempted to allow a
    high priority spark app to execute ? Would the preempted app get stuck
or would it continue to
    make progress? How are user names passed on from spark to yarn(say I'm
using nested user
    queues feature in fair scheduler) ?

3. Sharing RDDs in 1 and 2 above ?

4. Anything else about user/job isolation ?

I know I'm asking a lot of questions. Thanks in advance :) !

-- 
Thanks,
Ashwin
Netflix

--001a11352550be46db050607601d--

From dev-return-9930-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 19:08:51 2014
Return-Path: <dev-return-9930-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A095B17A1D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 19:08:51 +0000 (UTC)
Received: (qmail 88537 invoked by uid 500); 22 Oct 2014 19:08:50 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88448 invoked by uid 500); 22 Oct 2014 19:08:50 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88435 invoked by uid 99); 22 Oct 2014 19:08:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 19:08:50 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vanzin@cloudera.com designates 209.85.216.178 as permitted sender)
Received: from [209.85.216.178] (HELO mail-qc0-f178.google.com) (209.85.216.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 19:08:24 +0000
Received: by mail-qc0-f178.google.com with SMTP id b13so2081425qcw.23
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 12:07:46 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=UI92IzmxKGM/1AUk3TKogJ3KUTohx8eRN6K1AUbHf0E=;
        b=Uvr9bSBg1W5thYDSRa8Y53f58/l+H0EzGOPjYl73FBK3YbHfS7HAb/W2F3GKVuvJzX
         xJE/uUaDB4J7XAVMe0t+V0eYzhPPrWzdQ94UYwkyWsKOjZOiQRpcuTmtaA5E1CN2ULss
         BSDxlz0n7MjlCPsnjQ6AuSktY4Tj2JR5deh+rS64U6ZnMIMZx1OYf0NbIqrkKUYaeAC9
         zuz0DneTSDj05wYF4t29TVlsBiiitti21nvNp0F5Y7IbNfQ4ahho0wIX3AZVI6dl4yON
         loT00SA40+JJpUuesmH9a3ZdTkWsaqYDaI+e58yCmhW4nz9P68TbKopTkB337DTxIcyq
         O6mg==
X-Gm-Message-State: ALoCoQkWlIbd4GwIx7XQZ43kAHQnlDgsvCYSv/kJaTFzsq8gTP9Bgc6sGSgkvy/AvW7OJbLoppEp
MIME-Version: 1.0
X-Received: by 10.224.1.200 with SMTP id 8mr195974qag.54.1414004864979; Wed,
 22 Oct 2014 12:07:44 -0700 (PDT)
Received: by 10.229.8.68 with HTTP; Wed, 22 Oct 2014 12:07:44 -0700 (PDT)
In-Reply-To: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
References: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
Date: Wed, 22 Oct 2014 12:07:44 -0700
Message-ID: <CAAOnQ7tkPYTKwAx=6J_pz1=TXC0TE57JvUZ=UJbg5+2fvDr4Vg@mail.gmail.com>
Subject: Re: Multitenancy in Spark - within/across spark context
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Ashwin Shankar <ashwinshankar77@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Ashwin,

Let me try to answer to the best of my knowledge.

On Wed, Oct 22, 2014 at 11:47 AM, Ashwin Shankar
<ashwinshankar77@gmail.com> wrote:
> Here are my questions :
> 1. Sharing spark context : How exactly multiple users can share the cluster
> using same spark
>     context ?

That's not something you might want to do usually. In general, a
SparkContext maps to a user application, so each user would submit
their own job which would create its own SparkContext.

If you want to go outside of Spark, there are project which allow you
to manage SparkContext instances outside of applications and
potentially share them, such as
https://github.com/spark-jobserver/spark-jobserver. But be sure you
actually need it - since you haven't really explained the use case,
it's not very clear.

> 2. Different spark context in YARN: assuming I have a YARN cluster with
> queues and preemption
>     configured. Are there problems if executors/containers of a spark app
> are preempted to allow a
>     high priority spark app to execute ?

As far as I understand, this will cause executors to be killed, which
means that Spark will start retrying tasks to rebuild the data that
was held by those executors when needed. Yarn mode does have a
configurable upper limit on the number of executor failures, so if
your jobs keeps getting preempted it will eventually fail (unless you
tweak the settings).

I don't recall whether Yarn has an API to cleanly allow clients to
stop executors when preempted, but even if it does, I don't think
that's supported in Spark at the moment.

> How are user names passed on from spark to yarn(say I'm
> using nested user queues feature in fair scheduler) ?

Spark will try to run the job as the requesting user; if you're not
using Kerberos, that means the process themselves will be run as
whatever user runs the Yarn daemons, but the Spark app will be run
inside a "UserGroupInformation.doAs()" call as the requesting user. So
technically nested queues should work as expected.

> 3. Sharing RDDs in 1 and 2 above ?

I'll assume you don't mean actually sharing RDDs in the same context,
but between different SparkContext instances. You might (big might
here) be able to checkpoint an RDD from one context and load it from
another context; that's actually like some HA-like features for Spark
drivers are being addressed.

The job server I mentioned before, which allows different apps to
share the same Spark context, has a feature to share RDDs by name,
also, without having to resort to checkpointing.

Hope this helps!

-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9931-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 21:19:09 2014
Return-Path: <dev-return-9931-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B02EE17F1D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 21:19:09 +0000 (UTC)
Received: (qmail 19925 invoked by uid 500); 22 Oct 2014 21:19:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19811 invoked by uid 500); 22 Oct 2014 21:19:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18739 invoked by uid 99); 22 Oct 2014 21:19:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 21:19:07 +0000
X-ASF-Spam-Status: No, hits=1.7 required=5.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of ashwinshankar77@gmail.com designates 209.85.192.52 as permitted sender)
Received: from [209.85.192.52] (HELO mail-qg0-f52.google.com) (209.85.192.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 21:19:03 +0000
Received: by mail-qg0-f52.google.com with SMTP id q108so3111398qgd.25
        for <multiple recipients>; Wed, 22 Oct 2014 14:17:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=FTGU9Q/e1ab/+hDnlsz7uQimGp5fY2aOtdvvhBM5/B8=;
        b=Br0VMzxpgXbt6JkJjjhPPt104VJTAeuLxRBrzj0Fa+hbGWnnURojP7cguYJ2zGeKB2
         1I1XiKLzfHGWpnAlcHcRL/rGJ/HnwJbNfTChOtRlC3iYLk6zgoSm7ewNbrzC9274gKxc
         TtCzhf+PPcEl0iFw5JOUR7dvlAtgY04UDxrhfy7bvAKPbjSzw+MH2EvaXTbT1Y7wskuq
         y4xY/J4HJqVgB5chJ1j2fIIWgcyjOG4+UkV0V/LOEzaxcpmkWR9jZ/ng7/0mSYLE/K/i
         CicDWipDMSLKVyBP0Wid6KHcna5xXYhx5d/7k1+bqmeAGrt7d5w+Vmh88fYQh98s+WYN
         smmw==
MIME-Version: 1.0
X-Received: by 10.140.89.232 with SMTP id v95mr893744qgd.85.1414012675906;
 Wed, 22 Oct 2014 14:17:55 -0700 (PDT)
Received: by 10.140.93.34 with HTTP; Wed, 22 Oct 2014 14:17:55 -0700 (PDT)
In-Reply-To: <CAAOnQ7tkPYTKwAx=6J_pz1=TXC0TE57JvUZ=UJbg5+2fvDr4Vg@mail.gmail.com>
References: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
	<CAAOnQ7tkPYTKwAx=6J_pz1=TXC0TE57JvUZ=UJbg5+2fvDr4Vg@mail.gmail.com>
Date: Wed, 22 Oct 2014 14:17:55 -0700
Message-ID: <CAHwrdDF4nkXyg2X4U6CtgkAcrc=PKxkEr+6W4J4e=cow-kfoiQ@mail.gmail.com>
Subject: Re: Multitenancy in Spark - within/across spark context
From: Ashwin Shankar <ashwinshankar77@gmail.com>
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c11c204165040506097b8b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c11c204165040506097b8b
Content-Type: text/plain; charset=UTF-8

Thanks Marcelo, that was helpful ! I had some follow up questions :

That's not something you might want to do usually. In general, a
> SparkContext maps to a user application

My question was basically this. In this
<http://spark.apache.org/docs/latest/job-scheduling.html> page in the
official doc, under  "Scheduling within an application" section, it talks
about multiuser and fair sharing within an app. How does multiuser within
an application work(how users connect to an app,run their stuff) ? When
would I want to use this ?

As far as I understand, this will cause executors to be killed, which
> means that Spark will start retrying tasks to rebuild the data that
> was held by those executors when needed.

I basically wanted to find out if there were any "gotchas" related to
preemption on Spark. Things like say half of an application's executors got
preempted say while doing reduceByKey, will the application progress with
the remaining resources/fair share ?

I'm new to spark, sry if I'm asking something very obvious :).

Thanks,
Ashwin

On Wed, Oct 22, 2014 at 12:07 PM, Marcelo Vanzin <vanzin@cloudera.com>
wrote:

> Hi Ashwin,
>
> Let me try to answer to the best of my knowledge.
>
> On Wed, Oct 22, 2014 at 11:47 AM, Ashwin Shankar
> <ashwinshankar77@gmail.com> wrote:
> > Here are my questions :
> > 1. Sharing spark context : How exactly multiple users can share the
> cluster
> > using same spark
> >     context ?
>
> That's not something you might want to do usually. In general, a
> SparkContext maps to a user application, so each user would submit
> their own job which would create its own SparkContext.
>
> If you want to go outside of Spark, there are project which allow you
> to manage SparkContext instances outside of applications and
> potentially share them, such as
> https://github.com/spark-jobserver/spark-jobserver. But be sure you
> actually need it - since you haven't really explained the use case,
> it's not very clear.
>
> > 2. Different spark context in YARN: assuming I have a YARN cluster with
> > queues and preemption
> >     configured. Are there problems if executors/containers of a spark app
> > are preempted to allow a
> >     high priority spark app to execute ?
>
> As far as I understand, this will cause executors to be killed, which
> means that Spark will start retrying tasks to rebuild the data that
> was held by those executors when needed. Yarn mode does have a
> configurable upper limit on the number of executor failures, so if
> your jobs keeps getting preempted it will eventually fail (unless you
> tweak the settings).
>
> I don't recall whether Yarn has an API to cleanly allow clients to
> stop executors when preempted, but even if it does, I don't think
> that's supported in Spark at the moment.
>
> > How are user names passed on from spark to yarn(say I'm
> > using nested user queues feature in fair scheduler) ?
>
> Spark will try to run the job as the requesting user; if you're not
> using Kerberos, that means the process themselves will be run as
> whatever user runs the Yarn daemons, but the Spark app will be run
> inside a "UserGroupInformation.doAs()" call as the requesting user. So
> technically nested queues should work as expected.
>
> > 3. Sharing RDDs in 1 and 2 above ?
>
> I'll assume you don't mean actually sharing RDDs in the same context,
> but between different SparkContext instances. You might (big might
> here) be able to checkpoint an RDD from one context and load it from
> another context; that's actually like some HA-like features for Spark
> drivers are being addressed.
>
> The job server I mentioned before, which allows different apps to
> share the same Spark context, has a feature to share RDDs by name,
> also, without having to resort to checkpointing.
>
> Hope this helps!
>
> --
> Marcelo
>



-- 
Thanks,
Ashwin

--001a11c11c204165040506097b8b--

From dev-return-9932-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 21:23:36 2014
Return-Path: <dev-return-9932-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 64A2717F3C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 21:23:36 +0000 (UTC)
Received: (qmail 32429 invoked by uid 500); 22 Oct 2014 21:23:35 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32324 invoked by uid 500); 22 Oct 2014 21:23:35 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31485 invoked by uid 99); 22 Oct 2014 21:23:34 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 21:23:34 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sadhan.sood@gmail.com designates 209.85.217.173 as permitted sender)
Received: from [209.85.217.173] (HELO mail-lb0-f173.google.com) (209.85.217.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 21:23:29 +0000
Received: by mail-lb0-f173.google.com with SMTP id 10so3566321lbg.4
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 14:23:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=betajS4bO5IdF3o20wJxGhvHAKsnh1wHqyjYRVZG7Kk=;
        b=OdpcfYZKd0C8J2fYmTFj/lB3PyMP4uydnpBb00wPJOvRX85c1PmhR8U6d0rWrgKgvA
         P5ZlkRaBrhN3spFRGkdGqHjqnW81njY9eKu8vnW+/UjJabrgKSoMsJrMabqoStDmqY3D
         hXKR2EM68K0CVyqWiGRVMpenZe7qnAjR0aENd7ZDtjEDFGlrMma46MW9RjrVk6d1y9dI
         jSUlfC8ACLils52KTb0rP/klSFI5nSp5q56W7qxuUFV2MARBN5RPSDXGhjHd3uMD9ZIh
         FI0jm3BXChGj7DK+RT5Q+m673pMibGoOtUUgJAb5edkN85uVgLMlwYFVcdshwUENXkoN
         977Q==
X-Received: by 10.112.200.34 with SMTP id jp2mr660504lbc.1.1414012987556; Wed,
 22 Oct 2014 14:23:07 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.10.3 with HTTP; Wed, 22 Oct 2014 14:22:47 -0700 (PDT)
From: Sadhan Sood <sadhan.sood@gmail.com>
Date: Wed, 22 Oct 2014 17:22:47 -0400
Message-ID: <CALQwjuiLNXMVtyHxQ3M7doKars+qwuB=a3MFs=cvKE6bHgSLdw@mail.gmail.com>
Subject: Sharing spark context across multiple spark sql cli initializations
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c3749ed4ca770506098db7
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3749ed4ca770506098db7
Content-Type: text/plain; charset=UTF-8

We want to run multiple instances of spark sql cli on our yarn cluster.
Each instance of the cli is to be used by a different user. This would be
non-optimal if each user brings up a different cli given how spark works on
yarn by running executor processes (and hence consuming resources) on
worker nodes for the lifetime of the application. Imagine each user trying
to cache a table in memory when there is limited memory across the
cluster.  The right way seems like to use the same spark context shared
across multiple initializations and running just one spark sql application.
Is my understanding correct about resource usage on yarn for spark-sql? Is
there a way to do the sharing of spark context currently ? Seem like it
needs some kind of thrift interface hooked into the cli driver.

*Apologies if you have already seen this on user group*

--001a11c3749ed4ca770506098db7--

From dev-return-9933-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 21:24:50 2014
Return-Path: <dev-return-9933-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 689DC17F4A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 21:24:50 +0000 (UTC)
Received: (qmail 35168 invoked by uid 500); 22 Oct 2014 21:24:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35089 invoked by uid 500); 22 Oct 2014 21:24:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 7900 invoked by uid 99); 22 Oct 2014 19:19:34 -0000
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: *
X-Spam-Status: No, score=1.4 required=10.0 tests=DKIM_SIGNED,DKIM_VALID,
	DKIM_VALID_AU,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,
	RCVD_IN_MSPIKE_WL,SPF_PASS autolearn=disabled version=3.4.0
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :content-type;
        bh=nIST8GPq1e7ki9ugAdmjTui1Cw2ZrdwcLqDUVhlecqU=;
        b=fKuHV99nedWhqNXC1YecNk+PEiRppPZS8wq6csVMJGfPdx9bvkaNLEQjA4YneKFIj4
         4P4FPHgQb+fmSo4mR/YFMnRmkqCR/aKrWhIPDiadGJoUM6G+GZ3VxZedSbCU1+5CUB7s
         J0ZZcsG26Xy2n55SyxmWJOGM7xNdTiTjz/glNks9RtmL+pXLfBuUKXqCyey9lmkWUu1w
         spTbYUQwoT6C0Tdu3LKQIul7yBQMpYzfqi4GmxSwpfA3dIBg9luFdWTcPloDQL4u9En7
         8TZgogiD0jZUY39pVpRy8Bk0YZj6g7jMzuXXSZBzI5kJt9gpK7iaX0w+fUYQrVMFyxnX
         lRAg==
X-Received: by 10.112.134.39 with SMTP id ph7mr36795lbb.45.1414005526255; Wed,
 22 Oct 2014 12:18:46 -0700 (PDT)
MIME-Version: 1.0
In-Reply-To: <CALQwjuiE3FcSKWgcKeKLbqwZAsqamn-4pE02f76X0FY+HqAToQ@mail.gmail.com>
References: <CALQwjuiE3FcSKWgcKeKLbqwZAsqamn-4pE02f76X0FY+HqAToQ@mail.gmail.com>
From: Sadhan Sood <sadhan.sood@gmail.com>
Date: Wed, 22 Oct 2014 15:18:26 -0400
Message-ID: <CALQwjuiPU9qFX_N7EnBocavuxpy3s0JsT2OL3nEY=VRwee=jWA@mail.gmail.com>
Subject: Fwd: Sharing spark context across multiple spark sql cli initializations
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=047d7b3441841a6064050607d183
X-Virus-Scanned: ClamAV using ClamSMTP

--047d7b3441841a6064050607d183
Content-Type: text/plain; charset=UTF-8

We want to run multiple instances of spark sql cli on our yarn cluster.
Each instance of the cli is to be used by a different user. This looks
non-optimal if each user brings up a different cli given how spark works on
yarn by running executor processes (and hence consuming resources) on
worker nodes for the lifetime of the application. So, the right way seems
like to use the same spark context shared across multiple initializations
and running just one spark sql application. Is the understanding correct ?
Is there a way to do it currently ? Seem like it needs some kind of thrift
interface hooked into the cli driver.

--047d7b3441841a6064050607d183--

From dev-return-9934-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 21:37:15 2014
Return-Path: <dev-return-9934-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1188D17FD4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 21:37:15 +0000 (UTC)
Received: (qmail 76504 invoked by uid 500); 22 Oct 2014 21:37:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76440 invoked by uid 500); 22 Oct 2014 21:37:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76428 invoked by uid 99); 22 Oct 2014 21:37:13 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 21:37:13 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vanzin@cloudera.com designates 209.85.216.51 as permitted sender)
Received: from [209.85.216.51] (HELO mail-qa0-f51.google.com) (209.85.216.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 21:36:46 +0000
Received: by mail-qa0-f51.google.com with SMTP id k15so3055765qaq.38
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 14:36:00 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=rkBIlBifqNdc7Zgl7aHz+SRpusWPvQlr9RzYhkVxSXA=;
        b=aBJRIk+Cxf9BMMo9+VpbmOkrvW/uLhI+HiSglDPRUkg9u3mm8ol4lDYvekrMuZ1uTs
         P5BEHaZKxJThFRfgG7u6B3vAfpuFiEd1nJ4LhpnQ+amNWQCvM3JRjcp/boA4+rzftSJp
         qaPG/PWsCCAWerE3Y0lR75yTBlR/RIBfQfNpiIf4VRE1goaVzQ9gt+H54Aow+zgvKY0o
         Rp7vwMpmfD6LdDIg0nQEcn1wZzEBGU6z5dOCBCwPK2o5pEqd/gfnWA/jF1Fg9Yk0/Bl3
         sWXHPzmggX4NviisH5pDIG505U7JhnU+uNqosb307PFzqFclQl1DQc+QCiBk+VgLjfrm
         jcIQ==
X-Gm-Message-State: ALoCoQlmiTKQ0az0+FxNFHWSsWdbTxrvx37RE5ZKn2XNlcJMHcIwfnSbPqT9i6HIJXDylnY1mAfB
MIME-Version: 1.0
X-Received: by 10.224.62.20 with SMTP id v20mr1125334qah.87.1414013760750;
 Wed, 22 Oct 2014 14:36:00 -0700 (PDT)
Received: by 10.229.8.68 with HTTP; Wed, 22 Oct 2014 14:36:00 -0700 (PDT)
In-Reply-To: <CAHwrdDF4nkXyg2X4U6CtgkAcrc=PKxkEr+6W4J4e=cow-kfoiQ@mail.gmail.com>
References: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
	<CAAOnQ7tkPYTKwAx=6J_pz1=TXC0TE57JvUZ=UJbg5+2fvDr4Vg@mail.gmail.com>
	<CAHwrdDF4nkXyg2X4U6CtgkAcrc=PKxkEr+6W4J4e=cow-kfoiQ@mail.gmail.com>
Date: Wed, 22 Oct 2014 14:36:00 -0700
Message-ID: <CAAOnQ7sL_rusQqWthLARKCoWep9Yj4jGGJk8xGOcVSrqPqT-9w@mail.gmail.com>
Subject: Re: Multitenancy in Spark - within/across spark context
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Ashwin Shankar <ashwinshankar77@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Oct 22, 2014 at 2:17 PM, Ashwin Shankar
<ashwinshankar77@gmail.com> wrote:
>> That's not something you might want to do usually. In general, a
>> SparkContext maps to a user application
>
> My question was basically this. In this page in the official doc, under
> "Scheduling within an application" section, it talks about multiuser and
> fair sharing within an app. How does multiuser within an application
> work(how users connect to an app,run their stuff) ? When would I want to use
> this ?

I see. The way I read that page is that Spark supports all those
scheduling options; but Spark doesn't give you the means to actually
be able to submit jobs from different users to a running SparkContext
hosted on a different process. For that, you'll need something like
the job server that I referenced before, or write your own framework
for supporting that.

Personally, I'd use the information on that page when dealing with
concurrent jobs in the same SparkContext, but still restricted to the
same user. I'd avoid trying to create any application where a single
SparkContext is trying to be shared by multiple users in any way.

>> As far as I understand, this will cause executors to be killed, which
>> means that Spark will start retrying tasks to rebuild the data that
>> was held by those executors when needed.
>
> I basically wanted to find out if there were any "gotchas" related to
> preemption on Spark. Things like say half of an application's executors got
> preempted say while doing reduceByKey, will the application progress with
> the remaining resources/fair share ?

Jobs should still make progress as long as at least one executor is
available. The gotcha would be the one I mentioned, where Spark will
fail your job after "x" executors failed, which might be a common
occurrence when preemption is enabled. That being said, it's a
configurable option, so you can set "x" to a very large value and your
job should keep on chugging along.

The options you'd want to take a look at are: spark.task.maxFailures
and spark.yarn.max.executor.failures

-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9935-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 22 23:13:49 2014
Return-Path: <dev-return-9935-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 96AC717528
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 22 Oct 2014 23:13:49 +0000 (UTC)
Received: (qmail 1811 invoked by uid 500); 22 Oct 2014 23:13:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 1741 invoked by uid 500); 22 Oct 2014 23:13:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 1730 invoked by uid 99); 22 Oct 2014 23:13:48 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 23:13:48 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of skacanski@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 22 Oct 2014 23:13:43 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <skacanski@gmail.com>)
	id 1Xh55l-0002Ql-LH
	for dev@spark.incubator.apache.org; Wed, 22 Oct 2014 16:13:21 -0700
Date: Wed, 22 Oct 2014 16:13:21 -0700 (PDT)
From: catchmonster <skacanski@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1414019601641-8911.post@n3.nabble.com>
Subject: Development testing code
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,
If developing in python, what is preffered way to do unit testing?
Do I use pyunit framework or I need to go with scalaTest?




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Development-testing-code-tp8911.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9936-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 00:55:06 2014
Return-Path: <dev-return-9936-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B03CC17940
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 00:55:06 +0000 (UTC)
Received: (qmail 10367 invoked by uid 500); 23 Oct 2014 00:55:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10294 invoked by uid 500); 23 Oct 2014 00:55:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10282 invoked by uid 99); 23 Oct 2014 00:55:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 00:55:05 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of holden.karau@gmail.com designates 209.85.212.182 as permitted sender)
Received: from [209.85.212.182] (HELO mail-wi0-f182.google.com) (209.85.212.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 00:54:39 +0000
Received: by mail-wi0-f182.google.com with SMTP id bs8so648314wib.3
        for <dev@spark.incubator.apache.org>; Wed, 22 Oct 2014 17:54:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:sender:in-reply-to:references:date:message-id:subject
         :from:to:cc:content-type;
        bh=hn7tpXooeaGd4W6nX5r66nQxHbILN3KATlL7DWtH3ws=;
        b=crxx1r8nqfKW5xMPPoyzzPAtqEFxnTahQhf7dVpwjUjw2Da3dcir8sv9vzImGTtR00
         OwEHBwyW09ygcFeTK9wyyAal10LTNFLWfo+SOAqk73oZwuCKwMRKh67b+998H8rYzV23
         3bN9r1QhIHVse0+1W1QD0nAN+qOTvZcEDASisk4QhQa9rqgfEVKPIQRSmNk+QvjtzCCZ
         IXlX5rh8FP2fqNNxqQ+om1Eq9LELkgNUcbu8RJbiw1Sy6kwYpEPj18s4240T6xcg+7Tn
         tQ5z6Pt40422lOOL6nnehw813mFDfLVSbMc6WLYDeTucXqlr0IRDj9IBXPyl0ee80U0S
         5VtQ==
MIME-Version: 1.0
X-Received: by 10.180.73.103 with SMTP id k7mr41185154wiv.83.1414025678989;
 Wed, 22 Oct 2014 17:54:38 -0700 (PDT)
Sender: holden.karau@gmail.com
Received: by 10.194.120.1 with HTTP; Wed, 22 Oct 2014 17:54:38 -0700 (PDT)
In-Reply-To: <1414019601641-8911.post@n3.nabble.com>
References: <1414019601641-8911.post@n3.nabble.com>
Date: Wed, 22 Oct 2014 17:54:38 -0700
X-Google-Sender-Auth: p38a8ADSdEWiPvaACDQzEIWcec0
Message-ID: <CAJLcJd_mahK--k-1UHt=3TPB1-oOQNXejnYdBdbppRGpUt5Y4w@mail.gmail.com>
Subject: Re: Development testing code
From: Holden Karau <holden@pigscanfly.ca>
To: catchmonster <skacanski@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=f46d043c815e4caf2305060c8251
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d043c815e4caf2305060c8251
Content-Type: text/plain; charset=UTF-8

Hi,

Many tests in pyspark are implemented as doctests and the python
unittesting framework is also used for additional tests.

Cheers,

Holden :)

On Wed, Oct 22, 2014 at 4:13 PM, catchmonster <skacanski@gmail.com> wrote:

> Hi,
> If developing in python, what is preffered way to do unit testing?
> Do I use pyunit framework or I need to go with scalaTest?
>
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/Development-testing-code-tp8911.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>


-- 
Cell : 425-233-8271

--f46d043c815e4caf2305060c8251--

From dev-return-9937-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 06:34:52 2014
Return-Path: <dev-return-9937-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5A65D172E1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 06:34:52 +0000 (UTC)
Received: (qmail 80832 invoked by uid 500); 23 Oct 2014 06:34:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 80747 invoked by uid 500); 23 Oct 2014 06:34:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 80717 invoked by uid 99); 23 Oct 2014 06:34:50 -0000
Received: from ec2-54-191-145-13.us-west-2.compute.amazonaws.com (HELO mx1-us-west.apache.org) (54.191.145.13)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 06:34:50 +0000
Received: from mx1-us-west.apache.org (localhost [127.0.0.1])
	by mx1-us-west.apache.org (ASF Mail Server at mx1-us-west.apache.org) with ESMTP id 1596125D60
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 06:34:50 +0000 (UTC)
Received: by mx1-us-west.apache.org (ASF Mail Server at mx1-us-west.apache.org, from userid 114)
	id 0A8FB261F5; Thu, 23 Oct 2014 06:34:50 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-west.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-1.2 required=10.0 tests=RCVD_IN_DNSWL_LOW,
	RCVD_IN_MSPIKE_H2,SPF_PASS,T_DKIM_INVALID autolearn=disabled version=3.4.0
Received: from mail-ig0-f176.google.com (mail-ig0-f176.google.com [209.85.213.176])
	by mx1-us-west.apache.org (ASF Mail Server at mx1-us-west.apache.org) with ESMTPS id 7B91D25D60
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 06:34:49 +0000 (UTC)
Received: by mail-ig0-f176.google.com with SMTP id hn18so2344243igb.3
        for <dev@spark.apache.org>; Wed, 22 Oct 2014 23:34:43 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=ir4O9R+WoaACpDy1YNhKHBfQefA+nWHy/xoelaLgg3Y=;
        b=tHaHZhE8Fx6VwPc3+EU3V7YtLVymGtryN6PWYnJFJlk6zWo+wHO0YB035dnm/sQ4DK
         J+mdq2bJMtvP+LqA3DSG3A1lFrhwGM8pYROz3s7gXQflkpn5E3ffFu+g/EnSuSN08V6a
         2igQq7TGfYyyDkCc4kWYrB/4GStomVmRWHAOlmwn+R9Rdw+ER5M9A73lKss9CEUTVWJ1
         DpoqYs1KilWYRk7k7crJEH/UMjxb+orjiVyHf95aoZRnyABOdU17kU4B/RIRQfWqXFov
         IWSvqg64+qCzJpQIXni6GPyPrABZqpRA39OtNJKSfJkWJ7YeveniVJnobtsue9J7fqCf
         koqA==
MIME-Version: 1.0
X-Received: by 10.50.93.6 with SMTP id cq6mr10505374igb.7.1414046083408; Wed,
 22 Oct 2014 23:34:43 -0700 (PDT)
Received: by 10.64.106.5 with HTTP; Wed, 22 Oct 2014 23:34:43 -0700 (PDT)
Date: Thu, 23 Oct 2014 12:04:43 +0530
Message-ID: <CACKkDGHRxZdAEX3P2E18juc50tYj_JF+aNyaMaGS2KyoMgBn7w@mail.gmail.com>
Subject: Exception while running unit tests that makes use of local-cluster mode
From: Varadharajan Mukundan <srinathsmn@gmail.com>
To: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Scanned: ClamAV using ClamSMTP

Hi All,

When i try to run unit tests that makes use of local-cluster mode (Ex:
"Accessing HttpBroadcast variables in a local cluster" in
BroadcastSuite.scala), its failing with the below exception. I'm using
java version "1.8.0_05" and scala version  2.10. I tried to look into
the jenkins build report and its passing over there. Please let me
know how i can resolve this issue.

Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times,
most recent failure: Lost task 0.3 in stage 0.0 (TID 6,
192.168.43.112): java.lang.ClassNotFoundException:
org.apache.spark.broadcast.BroadcastSuite$$anonfun$3$$anonfun$19
        java.net.URLClassLoader$1.run(URLClassLoader.java:372)
        java.net.URLClassLoader$1.run(URLClassLoader.java:361)
        java.security.AccessController.doPrivileged(Native Method)
        java.net.URLClassLoader.findClass(URLClassLoader.java:360)
        java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        java.lang.Class.forName0(Native Method)
        java.lang.Class.forName(Class.java:340)
        org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:59)
        java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1613)
        java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1518)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1774)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:57)
        org.apache.spark.scheduler.Task.run(Task.scala:56)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        java.lang.Thread.run(Thread.java:745)
Driver stacktrace:
org.apache.spark.SparkException: Job aborted due to stage failure:
Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3
in stage 0.0 (TID 6, 192.168.43.112):
java.lang.ClassNotFoundException:
org.apache.spark.broadcast.BroadcastSuite$$anonfun$3$$anonfun$19
        java.net.URLClassLoader$1.run(URLClassLoader.java:372)
        java.net.URLClassLoader$1.run(URLClassLoader.java:361)
        java.security.AccessController.doPrivileged(Native Method)
        java.net.URLClassLoader.findClass(URLClassLoader.java:360)
        java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        java.lang.Class.forName0(Native Method)
        java.lang.Class.forName(Class.java:340)
        org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:59)
        java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1613)
        java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1518)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1774)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1993)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1918)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:57)
        org.apache.spark.scheduler.Task.run(Task.scala:56)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        java.lang.Thread.run(Thread.java:745)
Driver stacktrace:
at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1191)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1180)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1179)
at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1179)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:694)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:694)
at scala.Option.foreach(Option.scala:236)
at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:694)
at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1397)
at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
at org.apache.spark.scheduler.DAGSchedulerEventProcessActor.aroundReceive(DAGScheduler.scala:1352)
at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
at akka.actor.ActorCell.invoke(ActorCell.scala:487)
at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
at akka.dispatch.Mailbox.run(Mailbox.scala:220)
at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)


Process finished with exit code 0
.

-- 
Thanks,
M. Varadharajan

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9938-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 09:57:50 2014
Return-Path: <dev-return-9938-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D2B9F178F3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 09:57:50 +0000 (UTC)
Received: (qmail 57613 invoked by uid 500); 23 Oct 2014 09:57:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57533 invoked by uid 500); 23 Oct 2014 09:57:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56519 invoked by uid 99); 23 Oct 2014 09:57:47 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 09:57:47 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id AF8EE43866;
	Thu, 23 Oct 2014 09:57:46 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id A4AE443869; Thu, 23 Oct 2014 09:57:46 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: *
X-Spam-Status: No, score=1.4 required=10.0 tests=DKIM_SIGNED,DKIM_VALID,
	DKIM_VALID_AU,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,
	RCVD_IN_MSPIKE_WL,SPF_PASS,URIBL_BLOCKED autolearn=disabled version=3.4.0
Received: from mail-lb0-f182.google.com (mail-lb0-f182.google.com [209.85.217.182])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id CE7CA43866;
	Thu, 23 Oct 2014 09:57:45 +0000 (UTC)
Received: by mail-lb0-f182.google.com with SMTP id z11so512404lbi.41
        for <multiple recipients>; Thu, 23 Oct 2014 02:56:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=O1FrlJhL17wT3TCqTsfFZfCWBxOtfb/Ye+voSeeKXsw=;
        b=hYfOjsia85J53Bq9MtMZRFyjUVep27nJeBG2kmC0Cflt9b3IDnJk7OWb4Cm6E4uZS1
         G+v6umStKJNEGfcTj0kTrEtI9icv60TqVqr5yiA2bJ6n/vEvcLXVjQ2Nr1XGMD+y39Sl
         VbEvLuQefP1uEEM2Zn/F6f4lCliwuRuRhma71QsWB4c+JpDTDQ+8yfa8F7YionyjLOvV
         Lx7Hi0apCyzI/D2jvvVYxXwgD52OfZUIVN+lZ+HOVxQQ3W5KmMv0Ay4+keKJ7hDXdl3g
         MT46IvDn6HJtQ9frnkiXh3rX3G6W20oNveWHayn7sobgqKxYjGyqQSPxktrK4/aDW7Qd
         rYdA==
X-Received: by 10.152.5.38 with SMTP id p6mr3892582lap.44.1414058219401; Thu,
 23 Oct 2014 02:56:59 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.210.1 with HTTP; Thu, 23 Oct 2014 02:56:39 -0700 (PDT)
In-Reply-To: <CAAOnQ7sL_rusQqWthLARKCoWep9Yj4jGGJk8xGOcVSrqPqT-9w@mail.gmail.com>
References: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
 <CAAOnQ7tkPYTKwAx=6J_pz1=TXC0TE57JvUZ=UJbg5+2fvDr4Vg@mail.gmail.com>
 <CAHwrdDF4nkXyg2X4U6CtgkAcrc=PKxkEr+6W4J4e=cow-kfoiQ@mail.gmail.com> <CAAOnQ7sL_rusQqWthLARKCoWep9Yj4jGGJk8xGOcVSrqPqT-9w@mail.gmail.com>
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Thu, 23 Oct 2014 17:56:39 +0800
Message-ID: <CACA1tWLEy1R8Wud6HZVvDJ1j=QTnwAnwx9KDViRxH1U+kHb9hw@mail.gmail.com>
Subject: Re: Multitenancy in Spark - within/across spark context
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: Ashwin Shankar <ashwinshankar77@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01419acedbf88c0506141508
X-Virus-Scanned: ClamAV using ClamSMTP

--089e01419acedbf88c0506141508
Content-Type: text/plain; charset=UTF-8

Upvote for the multitanency requirement.

I'm also building a data analytic platform and there'll be multiple users
running queries and computations simultaneously. One of the paint point is
control of resource size. Users don't really know how much nodes they need,
they always use as much as possible... The result is lots of wasted
resource in our Yarn cluster.

A way to 1) allow multiple spark context to share the same resource or 2)
add dynamic resource management for Yarn mode is very much wanted.

Jianshi

On Thu, Oct 23, 2014 at 5:36 AM, Marcelo Vanzin <vanzin@cloudera.com> wrote:

> On Wed, Oct 22, 2014 at 2:17 PM, Ashwin Shankar
> <ashwinshankar77@gmail.com> wrote:
> >> That's not something you might want to do usually. In general, a
> >> SparkContext maps to a user application
> >
> > My question was basically this. In this page in the official doc, under
> > "Scheduling within an application" section, it talks about multiuser and
> > fair sharing within an app. How does multiuser within an application
> > work(how users connect to an app,run their stuff) ? When would I want to
> use
> > this ?
>
> I see. The way I read that page is that Spark supports all those
> scheduling options; but Spark doesn't give you the means to actually
> be able to submit jobs from different users to a running SparkContext
> hosted on a different process. For that, you'll need something like
> the job server that I referenced before, or write your own framework
> for supporting that.
>
> Personally, I'd use the information on that page when dealing with
> concurrent jobs in the same SparkContext, but still restricted to the
> same user. I'd avoid trying to create any application where a single
> SparkContext is trying to be shared by multiple users in any way.
>
> >> As far as I understand, this will cause executors to be killed, which
> >> means that Spark will start retrying tasks to rebuild the data that
> >> was held by those executors when needed.
> >
> > I basically wanted to find out if there were any "gotchas" related to
> > preemption on Spark. Things like say half of an application's executors
> got
> > preempted say while doing reduceByKey, will the application progress with
> > the remaining resources/fair share ?
>
> Jobs should still make progress as long as at least one executor is
> available. The gotcha would be the one I mentioned, where Spark will
> fail your job after "x" executors failed, which might be a common
> occurrence when preemption is enabled. That being said, it's a
> configurable option, so you can set "x" to a very large value and your
> job should keep on chugging along.
>
> The options you'd want to take a look at are: spark.task.maxFailures
> and spark.yarn.max.executor.failures
>
> --
> Marcelo
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> For additional commands, e-mail: user-help@spark.apache.org
>
>


-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--089e01419acedbf88c0506141508--

From dev-return-9939-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 09:58:58 2014
Return-Path: <dev-return-9939-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F04EF178F9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 09:58:57 +0000 (UTC)
Received: (qmail 62939 invoked by uid 500); 23 Oct 2014 09:58:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62856 invoked by uid 500); 23 Oct 2014 09:58:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62823 invoked by uid 99); 23 Oct 2014 09:58:56 -0000
Received: from ec2-54-76-25-247.eu-west-1.compute.amazonaws.com (HELO mx1-eu-west.apache.org) (54.76.25.247)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 09:58:56 +0000
Received: from mx1-eu-west.apache.org (localhost [127.0.0.1])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTP id 5B0C726E6D
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 09:58:55 +0000 (UTC)
Received: by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org, from userid 113)
	id 505972016B; Thu, 23 Oct 2014 09:58:55 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-eu-west.apache.org
X-Spam-Level: *
X-Spam-Status: No, score=1.5 required=10.0 tests=HTML_MESSAGE,
	RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,RCVD_IN_MSPIKE_WL,SPF_PASS,T_DKIM_INVALID,
	URIBL_BLOCKED autolearn=disabled version=3.4.0
Received: from mail-wi0-f174.google.com (mail-wi0-f174.google.com [209.85.212.174])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTPS id 6C65B26E78
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 09:58:53 +0000 (UTC)
Received: by mail-wi0-f174.google.com with SMTP id q5so250598wiv.1
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 02:58:47 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=5/CH3u1dPftyOxjUoi+O2DG74PRRtrjuoBfrnRAmo1o=;
        b=hKgGsbPwdjIgOKN8VlMQh6eIZ4QDPENRnIupRrznFTAhXcaavu+IybtL0bKRCp0PM3
         pT2qkFYh5whn5w0VchUtyAM8JkdxvlQEbHTEmuZ5z3tpL63cPAILxu+Ph9QKpIUL3wVD
         FYw0J5vvmdgvZdi4ZOmqvVf5S1WB5P7Y2MUhwRqZnnsvmjhPrJf05YZM+/hxb1emxJIM
         WJNpXzVarN8eYKuAgGxCV5/ZC4YmdY4AwfTFkY+NM5GLvmqXrk5AChf8cOS2+s8SZSyz
         YTz4wP/4S3lGkF8R59zNc/F5Q4ohxgU8pM5HcGW+aX5evUGUg4xYxjzJ9FU5ZP1851Md
         plNQ==
MIME-Version: 1.0
X-Received: by 10.181.11.131 with SMTP id ei3mr11698884wid.24.1414058327200;
 Thu, 23 Oct 2014 02:58:47 -0700 (PDT)
Received: by 10.194.37.225 with HTTP; Thu, 23 Oct 2014 02:58:47 -0700 (PDT)
Date: Thu, 23 Oct 2014 05:58:47 -0400
Message-ID: <CADtDQQJPbtofBi=HTDbnD3fgFOX+vTCKnU=fOgor55ZDsCDwpQ@mail.gmail.com>
Subject: PR for Hierarchical Clustering Needs Review
From: RJ Nowling <rnowling@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=f46d043c80ba48dabe0506141cce
X-Virus-Scanned: ClamAV using ClamSMTP

--f46d043c80ba48dabe0506141cce
Content-Type: text/plain; charset=UTF-8

Hi all,

A few months ago, I collected feedback on what the community was looking
for in clustering methods.  A number of the community members requested a
divisive hierarchical clustering method.

Yu Ishikawa has stepped up to implement such a method.  I've been working
with him to communicate what I heard the community request and to review
and improve his code.

You can find the JIRA here:
https://issues.apache.org/jira/browse/SPARK-2429

He has now submitted a PR:
https://github.com/apache/spark/pull/2906

I was hoping Xiangrui, other committers, and community members would be
willing to take a look?  It's quite a large patch so it'll need extra
attention.

Thank you,
RJ

-- 
em rnowling@gmail.com
c 954.496.2314

--f46d043c80ba48dabe0506141cce--

From dev-return-9940-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 10:36:12 2014
Return-Path: <dev-return-9940-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7FA30179E9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 10:36:12 +0000 (UTC)
Received: (qmail 17823 invoked by uid 500); 23 Oct 2014 10:36:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17747 invoked by uid 500); 23 Oct 2014 10:36:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17717 invoked by uid 99); 23 Oct 2014 10:36:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 10:36:05 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (athena.apache.org: transitioning domain of thubregtsen@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 10:36:01 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <thubregtsen@gmail.com>)
	id 1XhFk3-0003vB-JY
	for dev@spark.incubator.apache.org; Thu, 23 Oct 2014 03:35:39 -0700
Date: Thu, 23 Oct 2014 03:35:39 -0700 (PDT)
From: Tom Hubregtsen <thubregtsen@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1414060539494-8916.post@n3.nabble.com>
Subject: Memory
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi all,

I would like to validate my understanding of memory regions in Spark. Any
comments on my description below would be appreciated!

Execution is split up into stages, based on wide dependencies between RDDs
and actions such as save. All transformations involving narrow dependencies
before this wide dependency (or action) are pipelined. When Spark uses HDFS,
input data is loaded into memory according to the partitioning used in the
HDFS. As Spark has three regions (general, shuffle and storage), and this
does not yet involve an explicit cache nor a shuffle, I'll assume it goes
into general. During the pipelined execution of transformations with narrow
dependencies, it stays here, using the same partitioning, until we reach a
wide dependency (or an action). It then acquires memory from the shuffle
region, and spills to disk when there is no sufficient amount of memory
available. The result is passed in an iterator (located in the general
space) and the shuffle region is freed.

Only when an RDD is explicitly cached, it moves from the general region into
the storage region. This will guarantee availability for future use, but
also save space from the general region.

Question 1: Is this correct?
Question 2: How big is the general region?
Example: When I tell Spark I have 4GB, but my system actually has 16. I see
that the parameters shuffle and storage are defined (default: 20% and 60%),
but it does not seem that the general area is bounded by this. Will spark
use:
Shuffle: 0.2*4=0.8
Storage: 0.6*4=2.4
General: 1-(0.2+0.6)*4=0.8
Or
Shuffle: max(0.2*4)=max(0.8) //As we acquire from a counter, and not
actually divided memory regions
Storage: max(0.6*4)=max(2.4)
General: 16-actualUsage(shuffle+storage) or 4-actualUsage(shuffle+storage)



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Memory-tp8916.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9941-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 12:48:45 2014
Return-Path: <dev-return-9941-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 92A4D17D45
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 12:48:45 +0000 (UTC)
Received: (qmail 40194 invoked by uid 500); 23 Oct 2014 12:48:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40127 invoked by uid 500); 23 Oct 2014 12:48:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40107 invoked by uid 99); 23 Oct 2014 12:48:43 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 12:48:43 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id 55A6B4385C
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 12:48:43 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id 4AA3443864; Thu, 23 Oct 2014 12:48:43 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-1.3 required=10.0 tests=DKIM_SIGNED,DKIM_VALID,
	DKIM_VALID_AU,RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H2,SPF_PASS autolearn=disabled
	version=3.4.0
Received: from mail-ie0-f182.google.com (mail-ie0-f182.google.com [209.85.223.182])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id E518B43858
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 12:48:42 +0000 (UTC)
Received: by mail-ie0-f182.google.com with SMTP id rd18so321302iec.41
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 05:47:56 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :content-type;
        bh=bpmyE42FUVEgjQAEkrPbEMyhcKospYPMsOgKGwSqyAw=;
        b=nIXfEDHpGQr1c1vLWJZJWPNvA7FyRn+WKyaRb6n7l0VjK3mDzbm0xGGwsjsdOYsfIA
         Vk2QtnPR5q6LGEe0p09WKwmZQiUN8VzhgQuKfuLygfNcqFpn9QNhCEwUXixYJDwZEFK6
         H23qyIZqIc+Y9hCoB6GVuRmPYC0y9fb/4JHo8qEom2hJ0VZrgvmlQNmqu/CF64lMhm+l
         ZSkTAHVJqdwS9tlxC6PL6kbs4bp5PnDjgPuB1PxZLDl4ZMrRh4yBPl38RyOpPQkGXxY8
         BRVXeZxKNHUF0UfZS35ZS0KtP+rwwCk6Xl+0MHyNzhyD8eWE+XWcK81hPYYQFVRxJOMf
         gheg==
MIME-Version: 1.0
X-Received: by 10.50.43.200 with SMTP id y8mr41580515igl.7.1414068476837; Thu,
 23 Oct 2014 05:47:56 -0700 (PDT)
Received: by 10.64.106.5 with HTTP; Thu, 23 Oct 2014 05:47:56 -0700 (PDT)
In-Reply-To: <CACKkDGHRxZdAEX3P2E18juc50tYj_JF+aNyaMaGS2KyoMgBn7w@mail.gmail.com>
References: <CACKkDGHRxZdAEX3P2E18juc50tYj_JF+aNyaMaGS2KyoMgBn7w@mail.gmail.com>
Date: Thu, 23 Oct 2014 18:17:56 +0530
Message-ID: <CACKkDGH3=Zrn9th1uuAkuaRg6Sc6JDJ7cbkVOvp==Yh3pNQ_XQ@mail.gmail.com>
Subject: Re: Exception while running unit tests that makes use of
 local-cluster mode
From: Varadharajan Mukundan <srinathsmn@gmail.com>
To: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Scanned: ClamAV using ClamSMTP

Hi All,

I just figured it out that it fails whenever its run from Intellij. I
think it relates to the classpath issues mentioned in
https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-ScalaTestIssues
.

-- 
Thanks,
M. Varadharajan

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9942-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 14:37:58 2014
Return-Path: <dev-return-9942-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DEF6517361
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 14:37:58 +0000 (UTC)
Received: (qmail 23746 invoked by uid 500); 23 Oct 2014 14:37:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23669 invoked by uid 500); 23 Oct 2014 14:37:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23647 invoked by uid 99); 23 Oct 2014 14:37:57 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 14:37:57 +0000
X-ASF-Spam-Status: No, hits=-0.0 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [209.85.220.44] (HELO mail-pa0-f44.google.com) (209.85.220.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 14:37:52 +0000
Received: by mail-pa0-f44.google.com with SMTP id et14so1171490pad.31
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 07:37:30 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:content-type:mime-version:subject:from
         :in-reply-to:date:cc:content-transfer-encoding:message-id:references
         :to;
        bh=IaVnpz+NKMdFZ9DSarNNWqxok2xNeRclC2Egp9FsbYw=;
        b=RM3vKW0Mk6E6xiNbIcUFf6zfOyoD9h0ipi3CX6RDZxwM0t0B7fbzn67/DxXpdI+PlF
         kSPJb2ZSonTlT51OkMQy7XgaJbxEWXNKippV5XsUcDyLAzVCAVPEPA9tH/qRrOMRco3R
         cSyvlQzuZ3/fLi4u/oaOSUNPdM1LOJA9MS1iOIaf3pYsQI/Lhn/pDu2/LXkdY+srXdMZ
         D747eW35AfiYANaxdfT0TTSArWVenz5plzdwq9/omaPH6kisqIK56JY/FtqBtVuzM3Lf
         lBzKVuOmgfzGmwSrcEBg4tSdzYB3SJBVPzgm90yN+ZzpwVqf18dbd/3wq2YVr0qvtcqp
         1Fpg==
X-Gm-Message-State: ALoCoQmH4YxOtqRSPE2X3bYSa5d8kkC0Jj73KbwXfDSQyilQYeEs2HEPOdE/r95V2SuVwvtx6+Y4
X-Received: by 10.70.140.4 with SMTP id rc4mr5539992pdb.108.1414075049739;
        Thu, 23 Oct 2014 07:37:29 -0700 (PDT)
Received: from [192.168.0.14] (cpe-23-242-90-138.socal.res.rr.com. [23.242.90.138])
        by mx.google.com with ESMTPSA id q1sm1698810pdq.67.2014.10.23.07.37.28
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 23 Oct 2014 07:37:29 -0700 (PDT)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 8.0 \(1990.1\))
Subject: Re: reading/writing parquet decimal type
From: Michael Allman <michael@videoamp.com>
In-Reply-To: <90908724-1C31-4075-9B9C-014470B240DC@gmail.com>
Date: Thu, 23 Oct 2014 07:37:27 -0700
Cc: dev@spark.apache.org
Content-Transfer-Encoding: quoted-printable
Message-Id: <BA619D45-4BFC-4633-AAC1-BE2EB0D7F0EE@videoamp.com>
References: <6D485596-9181-44B5-AF05-CFB44E22902F@videoamp.com> <2089C711-2427-4BB5-90CB-32F2E5123DD3@gmail.com> <0ED145D3-33D8-48DB-943F-7BA69924B036@videoamp.com> <90908724-1C31-4075-9B9C-014470B240DC@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
X-Mailer: Apple Mail (2.1990.1)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Matei,

Another thing occurred to me. Will the binary format you're writing sort =
the data in numeric order? Or would the decimals have to be decoded for =
comparison?

Cheers,

Michael


> On Oct 12, 2014, at 10:48 PM, Matei Zaharia <matei.zaharia@gmail.com> =
wrote:
>=20
> The fixed-length binary type can hold fewer bytes than an int64, =
though many encodings of int64 can probably do the right thing. We can =
look into supporting multiple ways to do this -- the spec does say that =
you should at least be able to read int32s and int64s.
>=20
> Matei
>=20
> On Oct 12, 2014, at 8:20 PM, Michael Allman <michael@videoamp.com> =
wrote:
>=20
>> Hi Matei,
>>=20
>> Thanks, I can see you've been hard at work on this! I examined your =
patch and do have a question. It appears you're limiting the precision =
of decimals written to parquet to those that will fit in a long, yet =
you're writing the values as a parquet binary type. Why not write them =
using the int64 parquet type instead?
>>=20
>> Cheers,
>>=20
>> Michael
>>=20
>> On Oct 12, 2014, at 3:32 PM, Matei Zaharia <matei.zaharia@gmail.com> =
wrote:
>>=20
>>> Hi Michael,
>>>=20
>>> I've been working on this in my repo: =
https://github.com/mateiz/spark/tree/decimal. I'll make some pull =
requests with these features soon, but meanwhile you can try this =
branch. See https://github.com/mateiz/spark/compare/decimal for the =
individual commits that went into it. It has exactly the precision stuff =
you need, plus some optimizations for working on decimals.
>>>=20
>>> Matei
>>>=20
>>> On Oct 12, 2014, at 1:51 PM, Michael Allman <michael@videoamp.com> =
wrote:
>>>=20
>>>> Hello,
>>>>=20
>>>> I'm interested in reading/writing parquet SchemaRDDs that support =
the Parquet Decimal converted type. The first thing I did was update the =
Spark parquet dependency to version 1.5.0, as this version introduced =
support for decimals in parquet. However, conversion between the =
catalyst decimal type and the parquet decimal type is complicated by the =
fact that the catalyst type does not specify a decimal precision and =
scale but the parquet type requires them.
>>>>=20
>>>> I'm wondering if perhaps we could add an optional precision and =
scale to the catalyst decimal type? The catalyst decimal type would have =
unspecified precision and scale by default for backwards compatibility, =
but users who want to serialize a SchemaRDD with decimal(s) to parquet =
would have to narrow their decimal type(s) by specifying a precision and =
scale.
>>>>=20
>>>> Thoughts?
>>>>=20
>>>> Michael
>>>> =
---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>=20
>>>=20
>>=20
>=20


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9943-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 14:43:22 2014
Return-Path: <dev-return-9943-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CC5E1173A0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 14:43:22 +0000 (UTC)
Received: (qmail 42927 invoked by uid 500); 23 Oct 2014 14:43:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42865 invoked by uid 500); 23 Oct 2014 14:43:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42854 invoked by uid 99); 23 Oct 2014 14:43:20 -0000
Received: from ec2-54-76-25-247.eu-west-1.compute.amazonaws.com (HELO mx1-eu-west.apache.org) (54.76.25.247)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 14:43:20 +0000
Received: from mx1-eu-west.apache.org (localhost [127.0.0.1])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTP id F369F26E3C
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 14:43:19 +0000 (UTC)
Received: by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org, from userid 113)
	id E875326E53; Thu, 23 Oct 2014 14:43:19 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-eu-west.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-0.7 required=10.0 tests=RCVD_IN_DNSWL_LOW,
	RCVD_IN_MSPIKE_H3,RCVD_IN_MSPIKE_WL autolearn=disabled version=3.4.0
Received: from mail-pa0-f52.google.com (mail-pa0-f52.google.com [209.85.220.52])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTPS id 6C23726E3C
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 14:43:19 +0000 (UTC)
Received: by mail-pa0-f52.google.com with SMTP id fb1so1189759pad.11
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 07:43:12 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:from:content-type:content-transfer-encoding
         :subject:message-id:date:to:mime-version;
        bh=KX6hHvk09isydbl/1HjVgiuyyEy7jclTC0TvRWR0Efs=;
        b=PJbPyKjosAH/6Jt8knq0p+iSBFHsDN871tADQ6fLnB2Dt3XtAB3c3tGdKvT6xa44pQ
         YYgF+opQTrzdvBfSNjmoPHEWh7AR8YOLvGs01p1NhLEXc0BhKAP9NZcYOa0Pf8igRQun
         kq98iObJOsJo1ODFSshQvbsJGsRHtaxJfCw/m+Qzd71iJXimx3bq774aTmphrl0lsTkR
         8XW/ipOlf3HVUJzRfs0bTpAUSZ7E3v/qLMh9tcr6K5IIsGKYiMZnf1EhIyryvhgvC1Yh
         GFHwWi2H+DIxlInTeHCdnPDWqyyv4kYLhf3VKlsU+DqWNL2hTyYZZZvQqIj0v/v6xNnf
         L+Zg==
X-Gm-Message-State: ALoCoQlU5NHEmI9fEIDKmD4rodRxRQxyoKsu3sgR/BI5ZfTNABxMqeke7jbMGkZ0TshUL6tGBenI
X-Received: by 10.70.140.34 with SMTP id rd2mr4220554pdb.146.1414075391940;
        Thu, 23 Oct 2014 07:43:11 -0700 (PDT)
Received: from [192.168.0.14] (cpe-23-242-90-138.socal.res.rr.com. [23.242.90.138])
        by mx.google.com with ESMTPSA id ah2sm1747027pad.10.2014.10.23.07.43.11
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 23 Oct 2014 07:43:11 -0700 (PDT)
From: Michael Allman <michael@videoamp.com>
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Subject: Receiver/DStream storage level
Message-Id: <0BD00F55-9163-4B48-A340-938265F9D635@videoamp.com>
Date: Thu, 23 Oct 2014 07:43:10 -0700
To: dev@spark.apache.org
Mime-Version: 1.0 (Mac OS X Mail 8.0 \(1990.1\))
X-Mailer: Apple Mail (2.1990.1)
X-Virus-Scanned: ClamAV using ClamSMTP

I'm implementing a custom ReceiverInputDStream and I'm not sure how to =
initialize the Receiver with the storage level. The storage level is set =
on the DStream, but there doesn't seem to be a way to pass it to the =
Receiver. At the same time, setting the storage level separately on the =
Receiver seems to introduce potential confusion as the storage level of =
the DStream can be set separately. Is this desired behavior---to have =
distinct DStream and Receiver storage levels? Perhaps I'm missing =
something? Also, the storageLevel property of the Receiver[T] class is =
undocumented.

Cheers,

Michael=

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9944-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 17:07:07 2014
Return-Path: <dev-return-9944-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9727D179CE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 17:07:07 +0000 (UTC)
Received: (qmail 22354 invoked by uid 500); 23 Oct 2014 17:07:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 22288 invoked by uid 500); 23 Oct 2014 17:07:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 22272 invoked by uid 99); 23 Oct 2014 17:07:06 -0000
Received: from ec2-54-76-25-247.eu-west-1.compute.amazonaws.com (HELO mx1-eu-west.apache.org) (54.76.25.247)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 17:07:06 +0000
Received: from mx1-eu-west.apache.org (localhost [127.0.0.1])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTP id 7C43426E40
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 17:07:05 +0000 (UTC)
Received: by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org, from userid 113)
	id 714B926E53; Thu, 23 Oct 2014 17:07:05 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-eu-west.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-1.2 required=10.0 tests=RCVD_IN_DNSWL_LOW,
	RCVD_IN_MSPIKE_H2,SPF_PASS,URIBL_BLOCKED autolearn=disabled version=3.4.0
Received: from mail-qg0-f41.google.com (mail-qg0-f41.google.com [209.85.192.41])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTPS id 1EB9926E40
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 17:07:03 +0000 (UTC)
Received: by mail-qg0-f41.google.com with SMTP id a108so989660qge.28
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 10:06:53 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=D+WNJI3PBPkFp3+curNZ4FwNcXlkhASf4aimnlO8RXs=;
        b=R8grYLub8J69v0d478lCmZA5W5RWI2n6lZz/+5JZnGQXaR30zSYaITbcgmPstux/Bw
         wk1B2LJxz0dWCcp5oLa7Cqvy5uNldTQrsDfp9sKk0VBnt1QULBrqjK80HSMvblwbaDld
         sWxOzIaXrqPyJcDOfOKUnJvfm7X1zmfMEt/kpIsqNdTl5OQotm/D7A5gZkJR9bEYQ5Ug
         vMyBVuDoQspgkOQ3sMid9X9SIPYMVbKEyOOkk2m8TaZ9/pnHOLtmdLS/OCHvtMd8rkWZ
         V2D5AkoXganFwXL7rYOP+A1nHTje2k9UMAahsrXsC84F28C7IMCMPOLHCHahXqUmj0NS
         5LVw==
X-Gm-Message-State: ALoCoQlbtJdkvOT9I7iJ84Vwru2FH/s6nt6ijbNNmu4gvWHmPlNxYvBb2klJg2SDx+BswVNiWEBt
MIME-Version: 1.0
X-Received: by 10.140.84.179 with SMTP id l48mr9148975qgd.24.1414084013791;
 Thu, 23 Oct 2014 10:06:53 -0700 (PDT)
Received: by 10.229.8.68 with HTTP; Thu, 23 Oct 2014 10:06:53 -0700 (PDT)
In-Reply-To: <CACA1tWLEy1R8Wud6HZVvDJ1j=QTnwAnwx9KDViRxH1U+kHb9hw@mail.gmail.com>
References: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
	<CAAOnQ7tkPYTKwAx=6J_pz1=TXC0TE57JvUZ=UJbg5+2fvDr4Vg@mail.gmail.com>
	<CAHwrdDF4nkXyg2X4U6CtgkAcrc=PKxkEr+6W4J4e=cow-kfoiQ@mail.gmail.com>
	<CAAOnQ7sL_rusQqWthLARKCoWep9Yj4jGGJk8xGOcVSrqPqT-9w@mail.gmail.com>
	<CACA1tWLEy1R8Wud6HZVvDJ1j=QTnwAnwx9KDViRxH1U+kHb9hw@mail.gmail.com>
Date: Thu, 23 Oct 2014 10:06:53 -0700
Message-ID: <CAAOnQ7t_e77Kw5iVgRGeSJeBWb70c5b=1Vm23H_5CqgBX=vy+Q@mail.gmail.com>
Subject: Re: Multitenancy in Spark - within/across spark context
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Jianshi Huang <jianshi.huang@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Scanned: ClamAV using ClamSMTP

You may want to take a look at https://issues.apache.org/jira/browse/SPARK-3174.

On Thu, Oct 23, 2014 at 2:56 AM, Jianshi Huang <jianshi.huang@gmail.com> wrote:
> Upvote for the multitanency requirement.
>
> I'm also building a data analytic platform and there'll be multiple users
> running queries and computations simultaneously. One of the paint point is
> control of resource size. Users don't really know how much nodes they need,
> they always use as much as possible... The result is lots of wasted resource
> in our Yarn cluster.
>
> A way to 1) allow multiple spark context to share the same resource or 2)
> add dynamic resource management for Yarn mode is very much wanted.
>
> Jianshi
>
> On Thu, Oct 23, 2014 at 5:36 AM, Marcelo Vanzin <vanzin@cloudera.com> wrote:
>>
>> On Wed, Oct 22, 2014 at 2:17 PM, Ashwin Shankar
>> <ashwinshankar77@gmail.com> wrote:
>> >> That's not something you might want to do usually. In general, a
>> >> SparkContext maps to a user application
>> >
>> > My question was basically this. In this page in the official doc, under
>> > "Scheduling within an application" section, it talks about multiuser and
>> > fair sharing within an app. How does multiuser within an application
>> > work(how users connect to an app,run their stuff) ? When would I want to
>> > use
>> > this ?
>>
>> I see. The way I read that page is that Spark supports all those
>> scheduling options; but Spark doesn't give you the means to actually
>> be able to submit jobs from different users to a running SparkContext
>> hosted on a different process. For that, you'll need something like
>> the job server that I referenced before, or write your own framework
>> for supporting that.
>>
>> Personally, I'd use the information on that page when dealing with
>> concurrent jobs in the same SparkContext, but still restricted to the
>> same user. I'd avoid trying to create any application where a single
>> SparkContext is trying to be shared by multiple users in any way.
>>
>> >> As far as I understand, this will cause executors to be killed, which
>> >> means that Spark will start retrying tasks to rebuild the data that
>> >> was held by those executors when needed.
>> >
>> > I basically wanted to find out if there were any "gotchas" related to
>> > preemption on Spark. Things like say half of an application's executors
>> > got
>> > preempted say while doing reduceByKey, will the application progress
>> > with
>> > the remaining resources/fair share ?
>>
>> Jobs should still make progress as long as at least one executor is
>> available. The gotcha would be the one I mentioned, where Spark will
>> fail your job after "x" executors failed, which might be a common
>> occurrence when preemption is enabled. That being said, it's a
>> configurable option, so you can set "x" to a very large value and your
>> job should keep on chugging along.
>>
>> The options you'd want to take a look at are: spark.task.maxFailures
>> and spark.yarn.max.executor.failures
>>
>> --
>> Marcelo
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
>> For additional commands, e-mail: user-help@spark.apache.org
>>
>
>
>
> --
> Jianshi Huang
>
> LinkedIn: jianshi
> Twitter: @jshuang
> Github & Blog: http://huangjs.github.com/



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9945-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 18:04:13 2014
Return-Path: <dev-return-9945-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 848E717CA8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 18:04:13 +0000 (UTC)
Received: (qmail 15816 invoked by uid 500); 23 Oct 2014 18:04:12 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15745 invoked by uid 500); 23 Oct 2014 18:04:12 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 15734 invoked by uid 99); 23 Oct 2014 18:04:12 -0000
Received: from ec2-54-76-25-247.eu-west-1.compute.amazonaws.com (HELO mx1-eu-west.apache.org) (54.76.25.247)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 18:04:12 +0000
Received: from mx1-eu-west.apache.org (localhost [127.0.0.1])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTP id 6DA0E20185
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 18:04:11 +0000 (UTC)
Received: by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org, from userid 113)
	id 634BB26E0E; Thu, 23 Oct 2014 18:04:11 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-eu-west.apache.org
X-Spam-Level: *
X-Spam-Status: No, score=1.5 required=10.0 tests=HTML_MESSAGE,
	RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,RCVD_IN_MSPIKE_WL autolearn=disabled
	version=3.4.0
Received: from mail-wi0-f171.google.com (mail-wi0-f171.google.com [209.85.212.171])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTPS id 7114C20185
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 18:04:10 +0000 (UTC)
Received: by mail-wi0-f171.google.com with SMTP id em10so4850294wid.16
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 11:03:24 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=cNSga8gqE2uD9tiSAKqZcF7369KkNNyc3zXoTjhSRzs=;
        b=EFzRtnmzrwO2yC6K3A2DX8CrfUL4h82R7uRptu9yBYnVN4kngbyQzrz9+UFdCu+Zub
         JS+OCdjH6aDhf7tzSecJ+XczmCmH4oC4NoFqNfgmqO35AyqAbanhh8kJG1xFSZGj7fRa
         vlmqbExpCcBne5NnrmVFryD7AbqDtwB2sxiBEb1UlVpHZgKwkzBaTleEAF79e2zI+Ykd
         JZtwpoEPShXVB0JwpRSAFhlGB7PisE4gJy0bH0mQ/oUc9QEKSODF1CBOskzOFAZFi/t9
         dTZ1spoxyEx7N+KI3IbQbZLr4Zj2xLhQjarg15xXtl6ybIi8IgscDWpKsS6JBpiKZoqN
         bPNg==
X-Gm-Message-State: ALoCoQkhC6b2NL4EoAsjVK5Kh1gWR78Tdr3Y9ecXHDKipvjfu8xuNFntGeESO9LVJQiYC1rRiF7v
MIME-Version: 1.0
X-Received: by 10.194.122.71 with SMTP id lq7mr7421607wjb.66.1414087404300;
 Thu, 23 Oct 2014 11:03:24 -0700 (PDT)
Received: by 10.217.116.69 with HTTP; Thu, 23 Oct 2014 11:03:24 -0700 (PDT)
X-Originating-IP: [204.148.13.62]
Date: Thu, 23 Oct 2014 14:03:24 -0400
Message-ID: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
Subject: scalastyle annoys me a little bit
From: Koert Kuipers <koert@tresata.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e012297506a458405061ae157
X-Virus-Scanned: ClamAV using ClamSMTP

--089e012297506a458405061ae157
Content-Type: text/plain; charset=UTF-8

100 max width seems very restrictive to me.

even the most restrictive environment i have for development (ssh with
emacs) i get a lot more characters to work with than that.

personally i find the code harder to read, not easier. like i kept
wondering why there are weird newlines in the
middle of constructors and such, only to realise later it was because of
the 100 character limit.

also, i find "mvn package" erroring out because of style errors somewhat
excessive. i understand that a pull request needs to conform to "the style"
before being accepted, but this means i cant even run tests on code that
does not conform to the style guide, which is a bit silly.

i keep going out for coffee while package and tests run, only to come back
for an annoying error that my line is 101 characters and therefore nothing
ran.

is there some maven switch to disable the style checks?

best! koert

--089e012297506a458405061ae157--

From dev-return-9946-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 18:07:58 2014
Return-Path: <dev-return-9946-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1C7D517CE2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 18:07:58 +0000 (UTC)
Received: (qmail 28740 invoked by uid 500); 23 Oct 2014 18:07:57 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 28666 invoked by uid 500); 23 Oct 2014 18:07:57 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 28654 invoked by uid 99); 23 Oct 2014 18:07:56 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 18:07:56 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id 097CB43820
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 18:07:57 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id F340A43863; Thu, 23 Oct 2014 18:07:56 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-0.8 required=10.0 tests=DKIM_SIGNED,DKIM_VALID,
	DKIM_VALID_AU,RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,RCVD_IN_MSPIKE_WL,SPF_PASS,
	URIBL_BLOCKED autolearn=disabled version=3.4.0
Received: from mail-oi0-f54.google.com (mail-oi0-f54.google.com [209.85.218.54])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id 99CFE43820
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 18:07:56 +0000 (UTC)
Received: by mail-oi0-f54.google.com with SMTP id v63so1123671oia.27
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 11:07:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=8vhZ/CxbY76hDVVaRXp4z84bA/081oF6vwjsIrfMW4s=;
        b=ANetuvIdkRNi8+bOJE7Uk8eUjBdXTP59Rv3xbyg+O6Bnpcn/AMeyXBmPh35HsVMt8d
         jsCR30s6cwt3VDV5MRTyDp2x8YHDFQ+Bkq1U1RMN/87mMDdF0wMw9syUbobK+2EUuVZX
         7B7SYcbsmyMSnfNLm6imJqDatBggDQ36z7Kv3oPWDsqtLenLSHEh6Q2tDuoPNaZnrjxu
         CczH10DDQe3516nTO0tcnz/QhGAqEbePfT/ck80C5NODHviXLnYEtb9vho+8XVBd4qKP
         u31c7www6r5HpOQel3GdboNJrfZcNOUDohqeNZit661L4lSP+FJCxgUeNLYqNLbknmAP
         cbWw==
MIME-Version: 1.0
X-Received: by 10.60.132.102 with SMTP id ot6mr2559298oeb.62.1414087629975;
 Thu, 23 Oct 2014 11:07:09 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Thu, 23 Oct 2014 11:07:09 -0700 (PDT)
In-Reply-To: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
Date: Thu, 23 Oct 2014 11:07:09 -0700
Message-ID: <CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Patrick Wendell <pwendell@gmail.com>
To: Koert Kuipers <koert@tresata.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Scanned: ClamAV using ClamSMTP

Hey Koert,

I think disabling the style checks in maven package could be a good
idea for the reason you point out. I was sort of mixed on that when it
was proposed for this exact reason. It's just annoying to developers.

In terms of changing the global limit, this is more religion than
anything else, but there are other cases where the current limit is
useful (e.g. if you have many windows open in a large screen).

- Patrick

On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com> wrote:
> 100 max width seems very restrictive to me.
>
> even the most restrictive environment i have for development (ssh with
> emacs) i get a lot more characters to work with than that.
>
> personally i find the code harder to read, not easier. like i kept
> wondering why there are weird newlines in the
> middle of constructors and such, only to realise later it was because of
> the 100 character limit.
>
> also, i find "mvn package" erroring out because of style errors somewhat
> excessive. i understand that a pull request needs to conform to "the style"
> before being accepted, but this means i cant even run tests on code that
> does not conform to the style guide, which is a bit silly.
>
> i keep going out for coffee while package and tests run, only to come back
> for an annoying error that my line is 101 characters and therefore nothing
> ran.
>
> is there some maven switch to disable the style checks?
>
> best! koert

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9947-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 18:09:01 2014
Return-Path: <dev-return-9947-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5B83D17CE6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 18:09:01 +0000 (UTC)
Received: (qmail 32184 invoked by uid 500); 23 Oct 2014 18:08:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32109 invoked by uid 500); 23 Oct 2014 18:08:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32098 invoked by uid 99); 23 Oct 2014 18:08:59 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 18:08:59 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id 5B86843820
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 18:08:59 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id 511E243863; Thu, 23 Oct 2014 18:08:59 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-0.5 required=10.0 tests=RCVD_IN_DNSWL_BLOCKED,
	RCVD_IN_MSPIKE_H2,SPF_PASS,URIBL_BLOCKED autolearn=disabled version=3.4.0
Received: from mail-qg0-f43.google.com (mail-qg0-f43.google.com [209.85.192.43])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id EE6C143820
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 18:08:58 +0000 (UTC)
Received: by mail-qg0-f43.google.com with SMTP id j107so1030449qga.2
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 11:08:51 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=NEdfMmUQhxNIBfzeYosQ2aSJm11ecLdFpAfke5T9m8g=;
        b=KtsqCxt3ki0Li/5UmUGjcLGMlE5Brso7y6flp9VlcgLNxBL3xVdKODywu8t5RHeBh4
         g1SHqvRipzVOscWdFeqyqGJU1VasjiaTqb1fyap6Vp/IZ2rSYq/+F3DLSvEMnbbQQEdJ
         lP3EbVP3OVgatsn7aJquEmjhUX+OEm1QOLY8/C3GyXwJ2us0Wmnp0gWTKPylxnN64DEH
         s2crO1O04E9uwINrKWaozOrziJa/TObDzHN/P2t8k2wdkeXqdeSkrddeTmdCVRDm7ZDB
         RZSqOuE8hx/XqM9uROB+QXcEr7yvzjLsPia6jkegOtASiAj6T0XdBSy4FFWKJC/INoCi
         vE/Q==
X-Gm-Message-State: ALoCoQmAIl4ROv5r0ZmudvKz52Hk4Iy6C4EfXX8NNbqZ4wNA5rEkqMOjB0sGudd5CUEUd6n0RzOo
MIME-Version: 1.0
X-Received: by 10.140.35.228 with SMTP id n91mr9822048qgn.9.1414087731221;
 Thu, 23 Oct 2014 11:08:51 -0700 (PDT)
Received: by 10.229.8.68 with HTTP; Thu, 23 Oct 2014 11:08:51 -0700 (PDT)
In-Reply-To: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
Date: Thu, 23 Oct 2014 11:08:51 -0700
Message-ID: <CAAOnQ7sVs5-u30-D62vQcU72+jXba0yxKD37e6Ej-CvoH2wTsA@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Koert Kuipers <koert@tresata.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Scanned: ClamAV using ClamSMTP

I know this is all very subjective, but I find long lines difficult to read.

I also like how 100 characters fit in my editor setup fine (split wide
screen), while a longer line length would mean I can't have two
buffers side-by-side without horizontal scrollbars.

I think it's fine to add a switch to skip the style tests, but then,
you'll still have to fix the issues at some point...


On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com> wrote:
> 100 max width seems very restrictive to me.
>
> even the most restrictive environment i have for development (ssh with
> emacs) i get a lot more characters to work with than that.
>
> personally i find the code harder to read, not easier. like i kept
> wondering why there are weird newlines in the
> middle of constructors and such, only to realise later it was because of
> the 100 character limit.
>
> also, i find "mvn package" erroring out because of style errors somewhat
> excessive. i understand that a pull request needs to conform to "the style"
> before being accepted, but this means i cant even run tests on code that
> does not conform to the style guide, which is a bit silly.
>
> i keep going out for coffee while package and tests run, only to come back
> for an annoying error that my line is 101 characters and therefore nothing
> ran.
>
> is there some maven switch to disable the style checks?
>
> best! koert



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9948-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 18:14:32 2014
Return-Path: <dev-return-9948-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AA9FC17D40
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 18:14:32 +0000 (UTC)
Received: (qmail 56814 invoked by uid 500); 23 Oct 2014 18:14:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56742 invoked by uid 500); 23 Oct 2014 18:14:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56728 invoked by uid 99); 23 Oct 2014 18:14:31 -0000
Received: from mx1-us-east.apache.org (HELO mx1-us-east.apache.org) (54.164.171.186)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 18:14:31 +0000
Received: from mx1-us-east.apache.org (localhost [127.0.0.1])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTP id 48F304354D
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 18:14:31 +0000 (UTC)
Received: by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org, from userid 111)
	id 3DDDE43863; Thu, 23 Oct 2014 18:14:31 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-us-east.apache.org
X-Spam-Level: *
X-Spam-Status: No, score=1.4 required=10.0 tests=DKIM_SIGNED,DKIM_VALID,
	DKIM_VALID_AU,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,
	RCVD_IN_MSPIKE_WL,SPF_PASS,URIBL_BLOCKED autolearn=disabled version=3.4.0
Received: from mail-yh0-f50.google.com (mail-yh0-f50.google.com [209.85.213.50])
	by mx1-us-east.apache.org (ASF Mail Server at mx1-us-east.apache.org) with ESMTPS id EA6974354D
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 18:14:30 +0000 (UTC)
Received: by mail-yh0-f50.google.com with SMTP id a41so1853433yho.23
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 11:14:29 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=BY1dGXaLM7V+5xKFbhz7vYYdofqr+y4IX4IgdO73gcE=;
        b=y20VpEdLkr1ld95CbhFsMJUM5IP5XVvgPJ1NQ3PUW40bbsrAK6kDd6s+IVSnIdKMyA
         lmcvM+gTe4EtO3RUuGR7SisZegunpqmW7dc+pmoHBMYT31sTqvyWY/6L2zcB5q6Ns8JE
         MF9ncJGvFFy+PvWXVqjePJ2IkZ76S7sHjxxVRTroTNQ6u+Ioi2rI0ZERdVPDvY7lkZcu
         kBaWbUUXP/q6p/cf/lW/8JQoVopiTKoGRNo/+eenpevo/1hzj/8ObXMFgitDeh4UWrlg
         5xf3BSBF+tsTSS8oPRhW9wzJAkFflm0DN3SG25fGZRTJbB2ZOCKCyz0ix6VzNL7ad46I
         Zieg==
MIME-Version: 1.0
X-Received: by 10.170.216.131 with SMTP id i125mr661042ykf.46.1414088069574;
 Thu, 23 Oct 2014 11:14:29 -0700 (PDT)
Received: by 10.170.180.7 with HTTP; Thu, 23 Oct 2014 11:14:29 -0700 (PDT)
In-Reply-To: <CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
Date: Thu, 23 Oct 2014 11:14:29 -0700
Message-ID: <CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Ted Yu <yuzhihong@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Koert Kuipers <koert@tresata.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1139fb0011782d05061b09a9
X-Virus-Scanned: ClamAV using ClamSMTP

--001a1139fb0011782d05061b09a9
Content-Type: text/plain; charset=UTF-8

Koert:
Have you tried adding the following on your commandline ?

-Dscalastyle.failOnViolation=false

Cheers

On Thu, Oct 23, 2014 at 11:07 AM, Patrick Wendell <pwendell@gmail.com>
wrote:

> Hey Koert,
>
> I think disabling the style checks in maven package could be a good
> idea for the reason you point out. I was sort of mixed on that when it
> was proposed for this exact reason. It's just annoying to developers.
>
> In terms of changing the global limit, this is more religion than
> anything else, but there are other cases where the current limit is
> useful (e.g. if you have many windows open in a large screen).
>
> - Patrick
>
> On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com> wrote:
> > 100 max width seems very restrictive to me.
> >
> > even the most restrictive environment i have for development (ssh with
> > emacs) i get a lot more characters to work with than that.
> >
> > personally i find the code harder to read, not easier. like i kept
> > wondering why there are weird newlines in the
> > middle of constructors and such, only to realise later it was because of
> > the 100 character limit.
> >
> > also, i find "mvn package" erroring out because of style errors somewhat
> > excessive. i understand that a pull request needs to conform to "the
> style"
> > before being accepted, but this means i cant even run tests on code that
> > does not conform to the style guide, which is a bit silly.
> >
> > i keep going out for coffee while package and tests run, only to come
> back
> > for an annoying error that my line is 101 characters and therefore
> nothing
> > ran.
> >
> > is there some maven switch to disable the style checks?
> >
> > best! koert
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1139fb0011782d05061b09a9--

From dev-return-9949-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 19:06:40 2014
Return-Path: <dev-return-9949-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BCF9F17FB3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 19:06:40 +0000 (UTC)
Received: (qmail 51659 invoked by uid 500); 23 Oct 2014 19:06:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51587 invoked by uid 500); 23 Oct 2014 19:06:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51573 invoked by uid 99); 23 Oct 2014 19:06:39 -0000
Received: from ec2-54-76-25-247.eu-west-1.compute.amazonaws.com (HELO mx1-eu-west.apache.org) (54.76.25.247)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 19:06:39 +0000
Received: from mx1-eu-west.apache.org (localhost [127.0.0.1])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTP id 3E18026E82
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 19:06:38 +0000 (UTC)
Received: by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org, from userid 113)
	id 33FBE26E84; Thu, 23 Oct 2014 19:06:38 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-eu-west.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-0.7 required=10.0 tests=RCVD_IN_DNSWL_LOW,
	RCVD_IN_MSPIKE_H3,RCVD_IN_MSPIKE_WL,SPF_PASS,T_DKIM_INVALID
	autolearn=disabled version=3.4.0
Received: from mail-ob0-f173.google.com (mail-ob0-f173.google.com [209.85.214.173])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTPS id B38D226E82
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 19:06:37 +0000 (UTC)
Received: by mail-ob0-f173.google.com with SMTP id wp4so1242233obc.32
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 12:06:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=U+NE5KarJKiwOJjLGf7SIBVqhhVpoyLHHPAAbIBucjk=;
        b=rltWBbyOa0CMj8EuNfwkyDJSaIR4Ks73aGJ9FEQef0cRN51jUboNvXlKsS4mP4LiRZ
         UEbEztdltgxv2DpdZe/JyPjZhnqeb6hdU8pJUQKJqb1tX+o5YEwuOyW3KI1oeqhpwOwe
         tPAERunrlqi3EsUFxjLeFLpSV3F1JffIXe3RwB4mO3j2Z9LAyHcQy47rGhVutrGLn0i0
         2T0zEwCTszCmgckRdtBoUWhB1f5djSx6SSOkxtja7yqynBYJTLPGLdHNCCvs2iWN+LZ+
         XrY578j4BIfVDuyIR+lYktiSzBeXYzNPVwsP9qmGAY8zQ0qyJBCeqwOddfnnXCW3LA0U
         5RXA==
MIME-Version: 1.0
X-Received: by 10.60.54.170 with SMTP id k10mr3588595oep.48.1414091190029;
 Thu, 23 Oct 2014 12:06:30 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Thu, 23 Oct 2014 12:06:29 -0700 (PDT)
Date: Thu, 23 Oct 2014 12:06:29 -0700
Message-ID: <CABPQxsurYGFnyh4xgRBzXrRPD3jNwjo-efE9N+dWgSYjq_tDmw@mail.gmail.com>
Subject: Spark 1.2 feature freeze on November 1
From: Patrick Wendell <pwendell@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Scanned: ClamAV using ClamSMTP

Hey All,

Just a reminder that as planned [1] we'll go into a feature freeze on
November 1. On that date I'll cut a 1.2 release branch and make the
up-or-down call on any patches that go into that branch, along with
individual committers.

It is common for us to receive a very large volume of patches near the
deadline. The highest priority will be fixes and features that are in
review and were submitted earlier in the window. As a heads up, new
feature patches that are submitted in the next week have a good chance
of being pushed after 1.2.

During this coming weeks, I'd like to invite the community to help
with code review, testing patches, helping isolate bugs, our test
infra, etc. In past releases, community participation has helped
increase our ability to merge patches substantially. Individuals
really can make a huge difference here!

[1] https://cwiki.apache.org/confluence/display/SPARK/Wiki+Homepage

- Patrick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9950-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 19:07:17 2014
Return-Path: <dev-return-9950-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E6A6517FB6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 19:07:17 +0000 (UTC)
Received: (qmail 53319 invoked by uid 500); 23 Oct 2014 19:07:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53249 invoked by uid 500); 23 Oct 2014 19:07:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 53232 invoked by uid 99); 23 Oct 2014 19:07:16 -0000
Received: from ec2-54-76-25-247.eu-west-1.compute.amazonaws.com (HELO mx1-eu-west.apache.org) (54.76.25.247)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 19:07:16 +0000
Received: from mx1-eu-west.apache.org (localhost [127.0.0.1])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTP id 46DB426E80
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 19:07:15 +0000 (UTC)
Received: by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org, from userid 113)
	id 3C29726E83; Thu, 23 Oct 2014 19:07:15 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-eu-west.apache.org
X-Spam-Level: *
X-Spam-Status: No, score=1.5 required=10.0 tests=HTML_MESSAGE,
	RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H3,RCVD_IN_MSPIKE_WL,URIBL_BLOCKED
	autolearn=disabled version=3.4.0
Received: from mail-wg0-f47.google.com (mail-wg0-f47.google.com [74.125.82.47])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTPS id 9DB0126E80
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 19:07:14 +0000 (UTC)
Received: by mail-wg0-f47.google.com with SMTP id x13so1800045wgg.6
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 12:07:14 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=A/rGhCuJJCJ7dXV/DzqTkssEYNLPkuaOi4hMQ+fybzQ=;
        b=GWBk8kO0yOVXY2He5vNths2ZWhbQ4FaRDwP96+lCLoY2jmIC8V/RLvDcc+oI65l+KL
         pugluVFhNvsk9yLEGBOTO3LROEYF4pzIDlZz+C8+Tz99603uqKIFl8Pa9H97ebP8tmT7
         yeo6H7XJldQgZnwhEukXTkpZX4pYc0qRV0ju8Cn+lmk16xJ7D13MD9n17IJIgdAeP1DL
         ouGKcSZ8KBc4PsYzMYjkzN6ZG99ZsY0YOA9YGkOUk5uW/fOw6FOflld1chDIDhR7nlGa
         dqMGuSL6lMtJj//a0KGdlh7pqBLV0UfIXonOR7rlUQaUu/5MvsqRLBYgUUdZ68dTXBNo
         MijQ==
X-Gm-Message-State: ALoCoQnTYoEojO9tKxkwnrhtZk0ROCns6vSItYGqlbYjXIK4h1IU5lfLO1PXLL+DFcpf1Azxxp92
MIME-Version: 1.0
X-Received: by 10.194.243.164 with SMTP id wz4mr5135623wjc.129.1414091234307;
 Thu, 23 Oct 2014 12:07:14 -0700 (PDT)
Received: by 10.217.116.69 with HTTP; Thu, 23 Oct 2014 12:07:14 -0700 (PDT)
X-Originating-IP: [204.148.13.62]
In-Reply-To: <CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
Date: Thu, 23 Oct 2014 15:07:14 -0400
Message-ID: <CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Koert Kuipers <koert@tresata.com>
To: Ted Yu <yuzhihong@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01494050b3855305061bc526
X-Virus-Scanned: ClamAV using ClamSMTP

--089e01494050b3855305061bc526
Content-Type: text/plain; charset=UTF-8

Hey Ted,
i tried:
mvn clean package -DskipTests -Dscalastyle.failOnViolation=false

no luck, still get
[ERROR] Failed to execute goal
org.scalastyle:scalastyle-maven-plugin:0.4.0:check (default) on project
spark-core_2.10: Failed during scalastyle execution: You have 3 Scalastyle
violation(s). -> [Help 1]


On Thu, Oct 23, 2014 at 2:14 PM, Ted Yu <yuzhihong@gmail.com> wrote:

> Koert:
> Have you tried adding the following on your commandline ?
>
> -Dscalastyle.failOnViolation=false
>
> Cheers
>
> On Thu, Oct 23, 2014 at 11:07 AM, Patrick Wendell <pwendell@gmail.com>
> wrote:
>
>> Hey Koert,
>>
>> I think disabling the style checks in maven package could be a good
>> idea for the reason you point out. I was sort of mixed on that when it
>> was proposed for this exact reason. It's just annoying to developers.
>>
>> In terms of changing the global limit, this is more religion than
>> anything else, but there are other cases where the current limit is
>> useful (e.g. if you have many windows open in a large screen).
>>
>> - Patrick
>>
>> On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com>
>> wrote:
>> > 100 max width seems very restrictive to me.
>> >
>> > even the most restrictive environment i have for development (ssh with
>> > emacs) i get a lot more characters to work with than that.
>> >
>> > personally i find the code harder to read, not easier. like i kept
>> > wondering why there are weird newlines in the
>> > middle of constructors and such, only to realise later it was because of
>> > the 100 character limit.
>> >
>> > also, i find "mvn package" erroring out because of style errors somewhat
>> > excessive. i understand that a pull request needs to conform to "the
>> style"
>> > before being accepted, but this means i cant even run tests on code that
>> > does not conform to the style guide, which is a bit silly.
>> >
>> > i keep going out for coffee while package and tests run, only to come
>> back
>> > for an annoying error that my line is 101 characters and therefore
>> nothing
>> > ran.
>> >
>> > is there some maven switch to disable the style checks?
>> >
>> > best! koert
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>

--089e01494050b3855305061bc526--

From dev-return-9951-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 19:27:43 2014
Return-Path: <dev-return-9951-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 72C2F17305
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 19:27:43 +0000 (UTC)
Received: (qmail 17922 invoked by uid 500); 23 Oct 2014 19:27:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17848 invoked by uid 500); 23 Oct 2014 19:27:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17829 invoked by uid 99); 23 Oct 2014 19:27:42 -0000
Received: from ec2-54-76-25-247.eu-west-1.compute.amazonaws.com (HELO mx1-eu-west.apache.org) (54.76.25.247)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 19:27:42 +0000
Received: from mx1-eu-west.apache.org (localhost [127.0.0.1])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTP id 24AFA26E0E
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 19:27:41 +0000 (UTC)
Received: by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org, from userid 113)
	id 19C0826E40; Thu, 23 Oct 2014 19:27:41 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	mx1-eu-west.apache.org
X-Spam-Level: 
X-Spam-Status: No, score=-0.2 required=10.0 tests=FREEMAIL_REPLY,
	RCVD_IN_DNSWL_LOW,RCVD_IN_MSPIKE_H2,SPF_PASS,T_DKIM_INVALID,URIBL_BLOCKED
	autolearn=disabled version=3.4.0
Received: from mail-ie0-f171.google.com (mail-ie0-f171.google.com [209.85.223.171])
	by mx1-eu-west.apache.org (ASF Mail Server at mx1-eu-west.apache.org) with ESMTPS id 679A926E0E
	for <dev@spark.apache.org>; Thu, 23 Oct 2014 19:27:40 +0000 (UTC)
Received: by mail-ie0-f171.google.com with SMTP id x19so1597576ier.16
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 12:26:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=tp2BBz44Zsl64tzmjBY5XTrNWEbKMCl6azpoNb0JcfY=;
        b=o9q2EmwOrn02yRbA+xKVukWct60HmcL8ISvLFo8KLRwkElSc6aqHTCXGG+kUl0JrYV
         gmNXPNBDp1klsKA8UNNZWpXoDCVtiZmeMY4Jlu1eEUw5gZsYupkr+F+95mAv+a2Rv+Ec
         9vwil06tc7qXj+iDl3KnVoJOazC6IoD8MF0si1t3g4us/0VvReLvrQWsQapYh3Kx/avU
         DCbHrUzJi0yAggidTlDhl/EZGHxKXzDrtcFeNTf8JQdDw4avD/Z/f6n9T3w3IUFR6xrq
         fbod9s3SjlFwGEpIgGiIVyegwFJoYqSSnYv5gd2JuIhKqL3NKfadCw92Gl/+4gUgc5iG
         ncrQ==
MIME-Version: 1.0
X-Received: by 10.42.5.72 with SMTP id 8mr11878710icv.27.1414092368671; Thu,
 23 Oct 2014 12:26:08 -0700 (PDT)
Received: by 10.107.162.21 with HTTP; Thu, 23 Oct 2014 12:26:08 -0700 (PDT)
In-Reply-To: <CADtDQQJPbtofBi=HTDbnD3fgFOX+vTCKnU=fOgor55ZDsCDwpQ@mail.gmail.com>
References: <CADtDQQJPbtofBi=HTDbnD3fgFOX+vTCKnU=fOgor55ZDsCDwpQ@mail.gmail.com>
Date: Thu, 23 Oct 2014 12:26:08 -0700
Message-ID: <CAJgQjQ-6oiB6jA-aekoDx98T9zBpuJdA=dj+anP8G22-bk2mAg@mail.gmail.com>
Subject: Re: PR for Hierarchical Clustering Needs Review
From: Xiangrui Meng <mengxr@gmail.com>
To: RJ Nowling <rnowling@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Scanned: ClamAV using ClamSMTP

Hi RJ,

We are close to the v1.2 feature freeze deadline, so I'm busy with the
pipeline feature and couple bugs. I will ask other developers to help
review the PR. Thanks for working with Yu and helping the code review!

Best,
Xiangrui

On Thu, Oct 23, 2014 at 2:58 AM, RJ Nowling <rnowling@gmail.com> wrote:
> Hi all,
>
> A few months ago, I collected feedback on what the community was looking
> for in clustering methods.  A number of the community members requested a
> divisive hierarchical clustering method.
>
> Yu Ishikawa has stepped up to implement such a method.  I've been working
> with him to communicate what I heard the community request and to review
> and improve his code.
>
> You can find the JIRA here:
> https://issues.apache.org/jira/browse/SPARK-2429
>
> He has now submitted a PR:
> https://github.com/apache/spark/pull/2906
>
> I was hoping Xiangrui, other committers, and community members would be
> willing to take a look?  It's quite a large patch so it'll need extra
> attention.
>
> Thank you,
> RJ
>
> --
> em rnowling@gmail.com
> c 954.496.2314

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9952-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 19:56:07 2014
Return-Path: <dev-return-9952-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C6C6917428
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 19:56:07 +0000 (UTC)
Received: (qmail 77068 invoked by uid 500); 23 Oct 2014 19:56:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 76989 invoked by uid 500); 23 Oct 2014 19:56:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 76977 invoked by uid 99); 23 Oct 2014 19:56:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 19:56:06 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.213.44 as permitted sender)
Received: from [209.85.213.44] (HELO mail-yh0-f44.google.com) (209.85.213.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 19:56:02 +0000
Received: by mail-yh0-f44.google.com with SMTP id i57so259397yha.17
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 12:55:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=ljd9jmmeHv2KB5fPwxUwPYONrD82Xf0qdb0Rd2NgAfU=;
        b=IydmBRMpGL818IBy8uWaXKHv1pJQJte3a9X657qDWw8dkj9LqG62mBkiVpcfrG1i1G
         AbKF+HhiUrTK4xZ/w65wRZqi9+vqP4IkDxL43S3LcSzNCMf3dXKgsu1dNo+T9oLM2CYT
         8cOWsjxKsdxjuWf6y30cYmELLI6EwPzHk6ARnYDSSYrA2LRokg0A8Ek9+v5Yl0wU/CyU
         U0wWL8y9M0oZ5jsc0Ot61XjhqmVk4roHX7X/91fCSueFK581f5cK3576EoS4H84f/f7Q
         VQ9jzPVTeq+D2F46YPPdgvaBmE9ZRXNsRHKRL9SlU8rp11Ktj+Xi7Bm8QEURHlFoBheP
         Dt/Q==
MIME-Version: 1.0
X-Received: by 10.170.205.129 with SMTP id w123mr925397yke.0.1414094141408;
 Thu, 23 Oct 2014 12:55:41 -0700 (PDT)
Received: by 10.170.180.7 with HTTP; Thu, 23 Oct 2014 12:55:41 -0700 (PDT)
In-Reply-To: <CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
	<CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
Date: Thu, 23 Oct 2014 12:55:41 -0700
Message-ID: <CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Ted Yu <yuzhihong@gmail.com>
To: Koert Kuipers <koert@tresata.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11393808fa6e2605061c72c2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11393808fa6e2605061c72c2
Content-Type: text/plain; charset=UTF-8

Koert:
If you have time, you can try this diff - with which you would be able to
specify the following on the command line:
-Dscalastyle.failonviolation=false

diff --git a/pom.xml b/pom.xml
index 687cc63..108585e 100644
--- a/pom.xml
+++ b/pom.xml
@@ -123,6 +123,7 @@
     <log4j.version>1.2.17</log4j.version>
     <hadoop.version>1.0.4</hadoop.version>
     <protobuf.version>2.4.1</protobuf.version>
+    <scalastyle.failonviolation>true</scalastyle.failonviolation>
     <yarn.version>${hadoop.version}</yarn.version>
     <hbase.version>0.94.6</hbase.version>
     <flume.version>1.4.0</flume.version>
@@ -1071,7 +1072,7 @@
         <version>0.4.0</version>
         <configuration>
           <verbose>false</verbose>
-          <failOnViolation>true</failOnViolation>
+          <failOnViolation>${scalastyle.failonviolation}</failOnViolation>
           <includeTestSourceDirectory>false</includeTestSourceDirectory>
           <failOnWarning>false</failOnWarning>
           <sourceDirectory>${basedir}/src/main/scala</sourceDirectory>



On Thu, Oct 23, 2014 at 12:07 PM, Koert Kuipers <koert@tresata.com> wrote:

> Hey Ted,
> i tried:
> mvn clean package -DskipTests -Dscalastyle.failOnViolation=false
>
> no luck, still get
> [ERROR] Failed to execute goal
> org.scalastyle:scalastyle-maven-plugin:0.4.0:check (default) on project
> spark-core_2.10: Failed during scalastyle execution: You have 3 Scalastyle
> violation(s). -> [Help 1]
>
>
> On Thu, Oct 23, 2014 at 2:14 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>
>> Koert:
>> Have you tried adding the following on your commandline ?
>>
>> -Dscalastyle.failOnViolation=false
>>
>> Cheers
>>
>> On Thu, Oct 23, 2014 at 11:07 AM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>>
>>> Hey Koert,
>>>
>>> I think disabling the style checks in maven package could be a good
>>> idea for the reason you point out. I was sort of mixed on that when it
>>> was proposed for this exact reason. It's just annoying to developers.
>>>
>>> In terms of changing the global limit, this is more religion than
>>> anything else, but there are other cases where the current limit is
>>> useful (e.g. if you have many windows open in a large screen).
>>>
>>> - Patrick
>>>
>>> On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com>
>>> wrote:
>>> > 100 max width seems very restrictive to me.
>>> >
>>> > even the most restrictive environment i have for development (ssh with
>>> > emacs) i get a lot more characters to work with than that.
>>> >
>>> > personally i find the code harder to read, not easier. like i kept
>>> > wondering why there are weird newlines in the
>>> > middle of constructors and such, only to realise later it was because
>>> of
>>> > the 100 character limit.
>>> >
>>> > also, i find "mvn package" erroring out because of style errors
>>> somewhat
>>> > excessive. i understand that a pull request needs to conform to "the
>>> style"
>>> > before being accepted, but this means i cant even run tests on code
>>> that
>>> > does not conform to the style guide, which is a bit silly.
>>> >
>>> > i keep going out for coffee while package and tests run, only to come
>>> back
>>> > for an annoying error that my line is 101 characters and therefore
>>> nothing
>>> > ran.
>>> >
>>> > is there some maven switch to disable the style checks?
>>> >
>>> > best! koert
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>
>>>
>>
>

--001a11393808fa6e2605061c72c2--

From dev-return-9953-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 20:08:38 2014
Return-Path: <dev-return-9953-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C47F3174BD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 20:08:38 +0000 (UTC)
Received: (qmail 9063 invoked by uid 500); 23 Oct 2014 20:08:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 8992 invoked by uid 500); 23 Oct 2014 20:08:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 8972 invoked by uid 99); 23 Oct 2014 20:08:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 20:08:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.212.175] (HELO mail-wi0-f175.google.com) (209.85.212.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 20:08:09 +0000
Received: by mail-wi0-f175.google.com with SMTP id d1so5137276wiv.2
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 13:07:24 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=RDAekXY3nZVRxHoCfJ/VCBSwQcUwblTQukNzk3lEuks=;
        b=jgxX198whW58Y559vi2kxPYqa3Bkbyeery3BRqMeH1p6kR4D7QEDXg0Wm+WUJnsUdj
         /P/GUyFtTonzM9gMFw3bZGchbV7S/QJKul/oJE4KBXPhA6OfC723++d3d9HRbNRZKwsa
         Q+l97acqscXPGC23VuFTba02/WIb282/NpgJYohlfi8hxT81w3Cad63sv2vEmB5zAcsD
         vzGLzr2GYMOuq5J6dOfdzCHWTgD6VFJ+bLb1/5YbCzelgwyEFbOVS9GncjIFruf7RaZ2
         e2FMmR7QVCdkr9dk7/RHzYms6hUUgN6asOUENcbaIvG1rsHsUI+EraMITb2TZIUjGjNm
         97jA==
X-Gm-Message-State: ALoCoQko/eM6tphAEc9MqJJbJ6KA0StOoM0cH/lkvS4cAdzqjAJyciGicZptFWV+ILZdJOTHvVVm
MIME-Version: 1.0
X-Received: by 10.180.210.167 with SMTP id mv7mr15237430wic.15.1414094844200;
 Thu, 23 Oct 2014 13:07:24 -0700 (PDT)
Received: by 10.217.116.69 with HTTP; Thu, 23 Oct 2014 13:07:24 -0700 (PDT)
X-Originating-IP: [204.148.13.62]
In-Reply-To: <CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
	<CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
	<CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
Date: Thu, 23 Oct 2014 16:07:24 -0400
Message-ID: <CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Koert Kuipers <koert@tresata.com>
To: Ted Yu <yuzhihong@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2691ede21f305061c9c8c
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2691ede21f305061c9c8c
Content-Type: text/plain; charset=UTF-8

great thanks i will do that

On Thu, Oct 23, 2014 at 3:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:

> Koert:
> If you have time, you can try this diff - with which you would be able to
> specify the following on the command line:
> -Dscalastyle.failonviolation=false
>
> diff --git a/pom.xml b/pom.xml
> index 687cc63..108585e 100644
> --- a/pom.xml
> +++ b/pom.xml
> @@ -123,6 +123,7 @@
>      <log4j.version>1.2.17</log4j.version>
>      <hadoop.version>1.0.4</hadoop.version>
>      <protobuf.version>2.4.1</protobuf.version>
> +    <scalastyle.failonviolation>true</scalastyle.failonviolation>
>      <yarn.version>${hadoop.version}</yarn.version>
>      <hbase.version>0.94.6</hbase.version>
>      <flume.version>1.4.0</flume.version>
> @@ -1071,7 +1072,7 @@
>          <version>0.4.0</version>
>          <configuration>
>            <verbose>false</verbose>
> -          <failOnViolation>true</failOnViolation>
> +          <failOnViolation>${scalastyle.failonviolation}</failOnViolation>
>            <includeTestSourceDirectory>false</includeTestSourceDirectory>
>            <failOnWarning>false</failOnWarning>
>            <sourceDirectory>${basedir}/src/main/scala</sourceDirectory>
>
>
>
> On Thu, Oct 23, 2014 at 12:07 PM, Koert Kuipers <koert@tresata.com> wrote:
>
>> Hey Ted,
>> i tried:
>> mvn clean package -DskipTests -Dscalastyle.failOnViolation=false
>>
>> no luck, still get
>> [ERROR] Failed to execute goal
>> org.scalastyle:scalastyle-maven-plugin:0.4.0:check (default) on project
>> spark-core_2.10: Failed during scalastyle execution: You have 3 Scalastyle
>> violation(s). -> [Help 1]
>>
>>
>> On Thu, Oct 23, 2014 at 2:14 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>
>>> Koert:
>>> Have you tried adding the following on your commandline ?
>>>
>>> -Dscalastyle.failOnViolation=false
>>>
>>> Cheers
>>>
>>> On Thu, Oct 23, 2014 at 11:07 AM, Patrick Wendell <pwendell@gmail.com>
>>> wrote:
>>>
>>>> Hey Koert,
>>>>
>>>> I think disabling the style checks in maven package could be a good
>>>> idea for the reason you point out. I was sort of mixed on that when it
>>>> was proposed for this exact reason. It's just annoying to developers.
>>>>
>>>> In terms of changing the global limit, this is more religion than
>>>> anything else, but there are other cases where the current limit is
>>>> useful (e.g. if you have many windows open in a large screen).
>>>>
>>>> - Patrick
>>>>
>>>> On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com>
>>>> wrote:
>>>> > 100 max width seems very restrictive to me.
>>>> >
>>>> > even the most restrictive environment i have for development (ssh with
>>>> > emacs) i get a lot more characters to work with than that.
>>>> >
>>>> > personally i find the code harder to read, not easier. like i kept
>>>> > wondering why there are weird newlines in the
>>>> > middle of constructors and such, only to realise later it was because
>>>> of
>>>> > the 100 character limit.
>>>> >
>>>> > also, i find "mvn package" erroring out because of style errors
>>>> somewhat
>>>> > excessive. i understand that a pull request needs to conform to "the
>>>> style"
>>>> > before being accepted, but this means i cant even run tests on code
>>>> that
>>>> > does not conform to the style guide, which is a bit silly.
>>>> >
>>>> > i keep going out for coffee while package and tests run, only to come
>>>> back
>>>> > for an annoying error that my line is 101 characters and therefore
>>>> nothing
>>>> > ran.
>>>> >
>>>> > is there some maven switch to disable the style checks?
>>>> >
>>>> > best! koert
>>>>
>>>> ---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>
>>>>
>>>
>>
>

--001a11c2691ede21f305061c9c8c--

From dev-return-9954-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 23 20:45:11 2014
Return-Path: <dev-return-9954-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25CE117650
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 23 Oct 2014 20:45:11 +0000 (UTC)
Received: (qmail 12975 invoked by uid 500); 23 Oct 2014 20:45:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 12908 invoked by uid 500); 23 Oct 2014 20:45:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 12896 invoked by uid 99); 23 Oct 2014 20:45:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 20:45:09 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of yuzhihong@gmail.com designates 209.85.213.54 as permitted sender)
Received: from [209.85.213.54] (HELO mail-yh0-f54.google.com) (209.85.213.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 23 Oct 2014 20:45:05 +0000
Received: by mail-yh0-f54.google.com with SMTP id 29so459678yhl.41
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 13:44:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=SkQUAtRDGOKJlgj9bpjVV8GReF7QCSe/N6TTsYoxzm8=;
        b=QR3Bvc4CWndAzXgGVSnHRzJuWUYa2TOwt19WwsOEF73kwwTqL0AYhYmTBPqGUANZX5
         U90umKRqDS670IlMLbWnlOs2IPZvLYEkxMKGE7deKgr8yxrgYstHIJGVrI9qjo3CD3ar
         54sq5lpaqtsH/+DYhBp/HHnB+GOkIXR5/mSlON/V89YHEVfZixSY6+DDgit1ydbUpsqH
         hSDY2WJ0SdIIK88tVVJdGVkuc47WR4pt0rYKRa4MDxA7jtqDUKuSZ2Xf8RJdW0m7YgT0
         mDT8nS+HKt5MaVWS9kgF4kms3pu+/D4QrF7D6zdCk2X34Fgl7wUqIWtrrCWdIA6sRlGO
         9Acg==
MIME-Version: 1.0
X-Received: by 10.170.111.5 with SMTP id d5mr104740ykb.20.1414097084429; Thu,
 23 Oct 2014 13:44:44 -0700 (PDT)
Received: by 10.170.180.7 with HTTP; Thu, 23 Oct 2014 13:44:44 -0700 (PDT)
In-Reply-To: <CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
	<CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
	<CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
	<CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
Date: Thu, 23 Oct 2014 13:44:44 -0700
Message-ID: <CALte62x95NQ1JimQ53DHxto23dkVMYo_D6KMcRs8MzPSSP9g3Q@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Ted Yu <yuzhihong@gmail.com>
To: Koert Kuipers <koert@tresata.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1137a38a653abe05061d22db
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1137a38a653abe05061d22db
Content-Type: text/plain; charset=UTF-8

Created SPARK-4066 and attached patch there.

On Thu, Oct 23, 2014 at 1:07 PM, Koert Kuipers <koert@tresata.com> wrote:

> great thanks i will do that
>
> On Thu, Oct 23, 2014 at 3:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>
>> Koert:
>> If you have time, you can try this diff - with which you would be able to
>> specify the following on the command line:
>> -Dscalastyle.failonviolation=false
>>
>> diff --git a/pom.xml b/pom.xml
>> index 687cc63..108585e 100644
>> --- a/pom.xml
>> +++ b/pom.xml
>> @@ -123,6 +123,7 @@
>>      <log4j.version>1.2.17</log4j.version>
>>      <hadoop.version>1.0.4</hadoop.version>
>>      <protobuf.version>2.4.1</protobuf.version>
>> +    <scalastyle.failonviolation>true</scalastyle.failonviolation>
>>      <yarn.version>${hadoop.version}</yarn.version>
>>      <hbase.version>0.94.6</hbase.version>
>>      <flume.version>1.4.0</flume.version>
>> @@ -1071,7 +1072,7 @@
>>          <version>0.4.0</version>
>>          <configuration>
>>            <verbose>false</verbose>
>> -          <failOnViolation>true</failOnViolation>
>> +
>>  <failOnViolation>${scalastyle.failonviolation}</failOnViolation>
>>            <includeTestSourceDirectory>false</includeTestSourceDirectory>
>>            <failOnWarning>false</failOnWarning>
>>            <sourceDirectory>${basedir}/src/main/scala</sourceDirectory>
>>
>>
>>
>> On Thu, Oct 23, 2014 at 12:07 PM, Koert Kuipers <koert@tresata.com>
>> wrote:
>>
>>> Hey Ted,
>>> i tried:
>>> mvn clean package -DskipTests -Dscalastyle.failOnViolation=false
>>>
>>> no luck, still get
>>> [ERROR] Failed to execute goal
>>> org.scalastyle:scalastyle-maven-plugin:0.4.0:check (default) on project
>>> spark-core_2.10: Failed during scalastyle execution: You have 3 Scalastyle
>>> violation(s). -> [Help 1]
>>>
>>>
>>> On Thu, Oct 23, 2014 at 2:14 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>
>>>> Koert:
>>>> Have you tried adding the following on your commandline ?
>>>>
>>>> -Dscalastyle.failOnViolation=false
>>>>
>>>> Cheers
>>>>
>>>> On Thu, Oct 23, 2014 at 11:07 AM, Patrick Wendell <pwendell@gmail.com>
>>>> wrote:
>>>>
>>>>> Hey Koert,
>>>>>
>>>>> I think disabling the style checks in maven package could be a good
>>>>> idea for the reason you point out. I was sort of mixed on that when it
>>>>> was proposed for this exact reason. It's just annoying to developers.
>>>>>
>>>>> In terms of changing the global limit, this is more religion than
>>>>> anything else, but there are other cases where the current limit is
>>>>> useful (e.g. if you have many windows open in a large screen).
>>>>>
>>>>> - Patrick
>>>>>
>>>>> On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com>
>>>>> wrote:
>>>>> > 100 max width seems very restrictive to me.
>>>>> >
>>>>> > even the most restrictive environment i have for development (ssh
>>>>> with
>>>>> > emacs) i get a lot more characters to work with than that.
>>>>> >
>>>>> > personally i find the code harder to read, not easier. like i kept
>>>>> > wondering why there are weird newlines in the
>>>>> > middle of constructors and such, only to realise later it was
>>>>> because of
>>>>> > the 100 character limit.
>>>>> >
>>>>> > also, i find "mvn package" erroring out because of style errors
>>>>> somewhat
>>>>> > excessive. i understand that a pull request needs to conform to "the
>>>>> style"
>>>>> > before being accepted, but this means i cant even run tests on code
>>>>> that
>>>>> > does not conform to the style guide, which is a bit silly.
>>>>> >
>>>>> > i keep going out for coffee while package and tests run, only to
>>>>> come back
>>>>> > for an annoying error that my line is 101 characters and therefore
>>>>> nothing
>>>>> > ran.
>>>>> >
>>>>> > is there some maven switch to disable the style checks?
>>>>> >
>>>>> > best! koert
>>>>>
>>>>> ---------------------------------------------------------------------
>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>>
>>>>>
>>>>
>>>
>>
>

--001a1137a38a653abe05061d22db--

From dev-return-9955-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 02:30:00 2014
Return-Path: <dev-return-9955-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B5BBE10179
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 02:30:00 +0000 (UTC)
Received: (qmail 88108 invoked by uid 500); 24 Oct 2014 02:29:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88037 invoked by uid 500); 24 Oct 2014 02:29:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88021 invoked by uid 99); 24 Oct 2014 02:29:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 02:29:59 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lochanac@gmail.com designates 209.85.192.180 as permitted sender)
Received: from [209.85.192.180] (HELO mail-pd0-f180.google.com) (209.85.192.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 02:29:29 +0000
Received: by mail-pd0-f180.google.com with SMTP id fp1so574402pdb.39
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 19:27:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject
         :content-type:content-transfer-encoding;
        bh=baue1aZaXvhxX4KPCEnbObesyQykpm2JYMyYwg/XacA=;
        b=ucfMk5ICaMq4RssUG1IeZ/3yNhvwoUUXAnnS/N/HaFoZtZaXoKA6UHYV3skc8Fs8O1
         Yts+Jyg0cVFJ4tGqexKtqf4CedkwA1/bFlnJijJ1gjPnw3KMSK2oNMnEXbf/LL9Z0LKy
         GhMrIL+zNT5WD46TvqRCswxRollpcmSH06nbRllqlPTsjA3iEOnhXoecfY+k1JnBk8sU
         EW12Y1NQ+KBZLLwqwv4s/VC5gWz63z6FaXmMqAMpXL7UL7vhWmMp/L2WTZlaiegDTmnb
         cOHm/B0FV9V0/ZiNfSW9B9ci1IJ8PyFKVKkG+JLpNtFj11KW9W6hpJpOXOmB6PFPoanW
         t8ng==
X-Received: by 10.66.171.135 with SMTP id au7mr1626581pac.80.1414117677287;
        Thu, 23 Oct 2014 19:27:57 -0700 (PDT)
Received: from Lochanas-MacBook-Pro.local ([203.94.95.4])
        by mx.google.com with ESMTPSA id m1sm2627590pdm.53.2014.10.23.19.27.54
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 23 Oct 2014 19:27:55 -0700 (PDT)
Message-ID: <5449B929.6080402@gmail.com>
Date: Fri, 24 Oct 2014 07:57:53 +0530
From: Lochana Menikarachchi <lochanac@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.2.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: label points with a given index
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org


     SparkConf conf = new 
SparkConf().setAppName("LogisticRegression").setMaster("local[4]");
     JavaSparkContext sc = new JavaSparkContext(conf);
     JavaRDD<String> lines = sc.textFile("some.csv");
     JavaRDD<LabeledPoint> lPoints = lines.map(new CSVLineParser());

Is there anyway to parse an index to a function.. for example instead of 
hard coding (parts[0]) below is there a way to parse this



public class CSVLineParser implements Function<String, LabeledPoint> {
     private static final Pattern COMMA = Pattern.compile(",");

     @Override
     public LabeledPoint call(String line) {
         String[] parts = COMMA.split(line);
         double y = Double.parseDouble(parts[0]);
         double[] x = new double[parts.length];
         for (int i = 1; i < parts.length; ++i) {
             x[i] = Double.parseDouble(parts[i]);
         }
         return new LabeledPoint(y, Vectors.dense(x));
     }
}

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9956-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 03:23:25 2014
Return-Path: <dev-return-9956-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2B56510321
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 03:23:25 +0000 (UTC)
Received: (qmail 48536 invoked by uid 500); 24 Oct 2014 03:23:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 48462 invoked by uid 500); 24 Oct 2014 03:23:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 48450 invoked by uid 99); 24 Oct 2014 03:23:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 03:23:23 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lochanac@gmail.com designates 209.85.220.43 as permitted sender)
Received: from [209.85.220.43] (HELO mail-pa0-f43.google.com) (209.85.220.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 03:23:17 +0000
Received: by mail-pa0-f43.google.com with SMTP id eu11so331032pac.2
        for <dev@spark.apache.org>; Thu, 23 Oct 2014 20:22:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:subject:references
         :in-reply-to:content-type:content-transfer-encoding;
        bh=JPxwytphTP8qwzZCjDNzkKlYg9z9GGtXzIs1NFWxNuI=;
        b=Gb9f0YnJJ8TtnmXC0RoRhRaXPjDxcANdJLWiDEpx602VUGQUMZAZxZF3aHrIf40xfC
         1vO2Q87sTAKtXm4JnQvqflz2XCTD2NqFQze2JUkpIRgdH9Tz+3/sxaU+4PysnCcdSOxD
         aLghi77tGh4NVfZ5WF5mctLrMHz3pjH06DSZYG+ublZW90GU9Vzt7RYQC4jM1NNKE1Rp
         AXmD5EfLN2S1Sk47wW3LDl5e8laQsSdaQzNmOl0YeNqYj6FD+WH79rN7e8caWNYud3K9
         9/P5wnIy5pMabVS8SjAZ9fndv04ndcmJwgiZ7328KykWhQ4Jas1B61iwLb9lAnImnFf1
         ygtA==
X-Received: by 10.70.36.76 with SMTP id o12mr1748109pdj.5.1414120977112;
        Thu, 23 Oct 2014 20:22:57 -0700 (PDT)
Received: from Lochanas-MacBook-Pro.local ([203.94.95.4])
        by mx.google.com with ESMTPSA id km5sm2721930pdb.18.2014.10.23.20.22.55
        for <dev@spark.apache.org>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 23 Oct 2014 20:22:56 -0700 (PDT)
Message-ID: <5449C60D.2030906@gmail.com>
Date: Fri, 24 Oct 2014 08:52:53 +0530
From: Lochana Menikarachchi <lochanac@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.2.0
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: Re: label points with a given index
References: <5449B929.6080402@gmail.com>
In-Reply-To: <5449B929.6080402@gmail.com>
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Figured constructor can be used for this purpose..
On 10/24/14 7:57 AM, Lochana Menikarachchi wrote:
>
>     SparkConf conf = new 
> SparkConf().setAppName("LogisticRegression").setMaster("local[4]");
>     JavaSparkContext sc = new JavaSparkContext(conf);
>     JavaRDD<String> lines = sc.textFile("some.csv");
>     JavaRDD<LabeledPoint> lPoints = lines.map(new CSVLineParser());
>
> Is there anyway to parse an index to a function.. for example instead 
> of hard coding (parts[0]) below is there a way to parse this
>
>
>
> public class CSVLineParser implements Function<String, LabeledPoint> {
>     private static final Pattern COMMA = Pattern.compile(",");
>
>     @Override
>     public LabeledPoint call(String line) {
>         String[] parts = COMMA.split(line);
>         double y = Double.parseDouble(parts[0]);
>         double[] x = new double[parts.length];
>         for (int i = 1; i < parts.length; ++i) {
>             x[i] = Double.parseDouble(parts[i]);
>         }
>         return new LabeledPoint(y, Vectors.dense(x));
>     }
> }


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9957-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 04:37:50 2014
Return-Path: <dev-return-9957-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1C91C105F9
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 04:37:50 +0000 (UTC)
Received: (qmail 53580 invoked by uid 500); 24 Oct 2014 04:37:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 53507 invoked by uid 500); 24 Oct 2014 04:37:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 52375 invoked by uid 99); 24 Oct 2014 04:37:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 04:37:47 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of velvia.github@gmail.com designates 209.85.212.170 as permitted sender)
Received: from [209.85.212.170] (HELO mail-wi0-f170.google.com) (209.85.212.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 04:37:22 +0000
Received: by mail-wi0-f170.google.com with SMTP id n3so268253wiv.1
        for <multiple recipients>; Thu, 23 Oct 2014 21:35:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=LUNIiBr5qZj5gjtFc5zIHq3phEhsjulF+Sj+akqP8fo=;
        b=ZddW6PShwauR4w85IEN+K30n4zF2YWJfA0drMQKMyJfG7WfLCmXoKTJTFqfNA2Vlil
         CMoulfCA3hEbxLc/C++h99jfan4bieDCZ18QL/G4hvUp5otekPd7s2su4yoUgPhKKtbY
         eColykb4bHYForgH6boIIZymIMXENSxD2GpKsS4HJ/LJpW8KrNwc8tYD84LbkoRT3RNx
         DBzB/qmXgCsG9arV9e2hwkWrsaftvmox9r3CvwHKRpMYDPoeeA24/aCHCeDCuK5RBVzt
         tr3pyUFwZQjzZLOOFKoEVMzRuHIviZUxFsoIU9BsPR6bN1xJ4qJ7gZSq3nQhJzLlBIs6
         0fEw==
MIME-Version: 1.0
X-Received: by 10.180.11.66 with SMTP id o2mr1484082wib.22.1414125351467; Thu,
 23 Oct 2014 21:35:51 -0700 (PDT)
Received: by 10.216.9.200 with HTTP; Thu, 23 Oct 2014 21:35:51 -0700 (PDT)
In-Reply-To: <CAAOnQ7t_e77Kw5iVgRGeSJeBWb70c5b=1Vm23H_5CqgBX=vy+Q@mail.gmail.com>
References: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
	<CAAOnQ7tkPYTKwAx=6J_pz1=TXC0TE57JvUZ=UJbg5+2fvDr4Vg@mail.gmail.com>
	<CAHwrdDF4nkXyg2X4U6CtgkAcrc=PKxkEr+6W4J4e=cow-kfoiQ@mail.gmail.com>
	<CAAOnQ7sL_rusQqWthLARKCoWep9Yj4jGGJk8xGOcVSrqPqT-9w@mail.gmail.com>
	<CACA1tWLEy1R8Wud6HZVvDJ1j=QTnwAnwx9KDViRxH1U+kHb9hw@mail.gmail.com>
	<CAAOnQ7t_e77Kw5iVgRGeSJeBWb70c5b=1Vm23H_5CqgBX=vy+Q@mail.gmail.com>
Date: Fri, 24 Oct 2014 00:35:51 -0400
Message-ID: <CAN6Vra2NaUTobn7s1BL=HcNgedScEb0Yuui84Y1Rc+dXpOrQGg@mail.gmail.com>
Subject: Re: Multitenancy in Spark - within/across spark context
From: Evan Chan <velvia.github@gmail.com>
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: Jianshi Huang <jianshi.huang@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>, 
	"user@spark.apache.org" <user@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Ashwin,

I would say the strategies in general are:

1) Have each user submit separate Spark app (each its own Spark
Context), with its own resource settings, and share data through HDFS
or something like Tachyon for speed.

2) Share a single spark context amongst multiple users, using fair
scheduler.  This is sort of like having a Hadoop resource pool.    It
has some obvious HA/SPOF issues, namely that if the context dies then
every user using it is also dead.   Also, sharing RDDs in cached
memory has the same resiliency problems, namely that if any executor
dies then Spark must recompute / rebuild the RDD (it tries to only
rebuild the missing part, but sometimes it must rebuild everything).

Job server can help with 1 or 2, 2 in particular.  If you have any
questions about job server, feel free to ask at the spark-jobserver
google group.   I am the maintainer.

-Evan


On Thu, Oct 23, 2014 at 1:06 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:
> You may want to take a look at https://issues.apache.org/jira/browse/SPARK-3174.
>
> On Thu, Oct 23, 2014 at 2:56 AM, Jianshi Huang <jianshi.huang@gmail.com> wrote:
>> Upvote for the multitanency requirement.
>>
>> I'm also building a data analytic platform and there'll be multiple users
>> running queries and computations simultaneously. One of the paint point is
>> control of resource size. Users don't really know how much nodes they need,
>> they always use as much as possible... The result is lots of wasted resource
>> in our Yarn cluster.
>>
>> A way to 1) allow multiple spark context to share the same resource or 2)
>> add dynamic resource management for Yarn mode is very much wanted.
>>
>> Jianshi
>>
>> On Thu, Oct 23, 2014 at 5:36 AM, Marcelo Vanzin <vanzin@cloudera.com> wrote:
>>>
>>> On Wed, Oct 22, 2014 at 2:17 PM, Ashwin Shankar
>>> <ashwinshankar77@gmail.com> wrote:
>>> >> That's not something you might want to do usually. In general, a
>>> >> SparkContext maps to a user application
>>> >
>>> > My question was basically this. In this page in the official doc, under
>>> > "Scheduling within an application" section, it talks about multiuser and
>>> > fair sharing within an app. How does multiuser within an application
>>> > work(how users connect to an app,run their stuff) ? When would I want to
>>> > use
>>> > this ?
>>>
>>> I see. The way I read that page is that Spark supports all those
>>> scheduling options; but Spark doesn't give you the means to actually
>>> be able to submit jobs from different users to a running SparkContext
>>> hosted on a different process. For that, you'll need something like
>>> the job server that I referenced before, or write your own framework
>>> for supporting that.
>>>
>>> Personally, I'd use the information on that page when dealing with
>>> concurrent jobs in the same SparkContext, but still restricted to the
>>> same user. I'd avoid trying to create any application where a single
>>> SparkContext is trying to be shared by multiple users in any way.
>>>
>>> >> As far as I understand, this will cause executors to be killed, which
>>> >> means that Spark will start retrying tasks to rebuild the data that
>>> >> was held by those executors when needed.
>>> >
>>> > I basically wanted to find out if there were any "gotchas" related to
>>> > preemption on Spark. Things like say half of an application's executors
>>> > got
>>> > preempted say while doing reduceByKey, will the application progress
>>> > with
>>> > the remaining resources/fair share ?
>>>
>>> Jobs should still make progress as long as at least one executor is
>>> available. The gotcha would be the one I mentioned, where Spark will
>>> fail your job after "x" executors failed, which might be a common
>>> occurrence when preemption is enabled. That being said, it's a
>>> configurable option, so you can set "x" to a very large value and your
>>> job should keep on chugging along.
>>>
>>> The options you'd want to take a look at are: spark.task.maxFailures
>>> and spark.yarn.max.executor.failures
>>>
>>> --
>>> Marcelo
>>>
>>> ---------------------------------------------------------------------
>>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
>>> For additional commands, e-mail: user-help@spark.apache.org
>>>
>>
>>
>>
>> --
>> Jianshi Huang
>>
>> LinkedIn: jianshi
>> Twitter: @jshuang
>> Github & Blog: http://huangjs.github.com/
>
>
>
> --
> Marcelo
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9958-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 11:56:37 2014
Return-Path: <dev-return-9958-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8B3CE1725D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 11:56:37 +0000 (UTC)
Received: (qmail 45963 invoked by uid 500); 24 Oct 2014 11:56:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 45894 invoked by uid 500); 24 Oct 2014 11:56:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 45882 invoked by uid 99); 24 Oct 2014 11:56:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 11:56:36 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 11:56:31 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <ashutosh.trivedi@iiitb.org>)
	id 1XhdTA-00015X-EM
	for dev@spark.incubator.apache.org; Fri, 24 Oct 2014 04:55:48 -0700
Date: Fri, 24 Oct 2014 04:55:48 -0700 (PDT)
From: Ashutosh <ashutosh.trivedi@iiitb.org>
To: dev@spark.incubator.apache.org
Message-ID: <1414151748436-8935.post@n3.nabble.com>
In-Reply-To: <1413920470217-8894.post@n3.nabble.com>
References: <1413883380883-8880.post@n3.nabble.com> <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com> <1413920470217-8894.post@n3.nabble.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,
We are ready with the initial code. Where can I submit it for review ? I
want to get it reviewed before testing 
it at scale.
Also, I see that most of the algorithms take data as RDD[LabeledPoint] . How
should we take input for this since there are no labels.

Can any body help me out with these issues. Here is the JIRA opened for it.
https://issues.apache.org/jira/browse/SPARK-4038

Regards,
Ashutosh 



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p8935.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9959-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:02:29 2014
Return-Path: <dev-return-9959-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A04E5173E2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:02:29 +0000 (UTC)
Received: (qmail 10145 invoked by uid 500); 24 Oct 2014 20:02:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 10075 invoked by uid 500); 24 Oct 2014 20:02:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 10064 invoked by uid 99); 24 Oct 2014 20:02:28 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:02:28 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [74.125.82.43] (HELO mail-wg0-f43.google.com) (74.125.82.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:02:01 +0000
Received: by mail-wg0-f43.google.com with SMTP id n12so1798384wgh.26
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 12:59:45 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=hFfILS4Kx48ZM2RViHl6AKxpFqU43LwkzR6FUx1RUNw=;
        b=hYBjqIolBZ9KFuedjJn2jkStUPbViTlO3+iWXR7NspIFYQ9zFIhthYUxO3G+PT5Pw2
         DkUxmpVpacYtw9KB4raqf196XowYczPGpROMsrLpO9KSPtG4u5modTdljyBWsQbUrlJG
         KtxheDnNGrpQ08/8ETqrw+Yc0iOwBl4fSGdG4yaHFu3h7UlzLOEPI+TrcYGb/RzX3Ux2
         qRNBDAYpqKZ9KwZjoyjap7tuOcm18V4DOZTHGkbB4kitZdxgfVWMBmMWzlgZ8N2u5m8p
         OMkWpDYtT0s/Ktd6jOHG6iLtIU0sLiu8OElG58889r2Omc0xZuYIxJcK2+f+zo9w1jZK
         xODA==
X-Gm-Message-State: ALoCoQl7nl4NDaV5QggzKNejNgE7P/5NnvwEKgxZRLrdcTaioMCT/kp3hUvGTGfBRuw3FjUD9jaQ
MIME-Version: 1.0
X-Received: by 10.194.24.197 with SMTP id w5mr6998716wjf.71.1414180785451;
 Fri, 24 Oct 2014 12:59:45 -0700 (PDT)
Received: by 10.217.116.69 with HTTP; Fri, 24 Oct 2014 12:59:45 -0700 (PDT)
X-Originating-IP: [199.47.226.148]
In-Reply-To: <CALte62x95NQ1JimQ53DHxto23dkVMYo_D6KMcRs8MzPSSP9g3Q@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
	<CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
	<CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
	<CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
	<CALte62x95NQ1JimQ53DHxto23dkVMYo_D6KMcRs8MzPSSP9g3Q@mail.gmail.com>
Date: Fri, 24 Oct 2014 15:59:45 -0400
Message-ID: <CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Koert Kuipers <koert@tresata.com>
To: Ted Yu <yuzhihong@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b450e065d8a7f0506309f60
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b450e065d8a7f0506309f60
Content-Type: text/plain; charset=UTF-8

thanks ted.

apologies for complaining about maven here again, but this is the first
time i seriously use it for development, and i am completely unfamiliar
with it.

a few more issues:

"mvn clean package -DskipTests" takes about 30 mins for me. thats painful
since its needed for the tests. does anyone know any tricks to speed it up?
(besides getting a better laptop). does zinc help?

does scalastyle overwrite files? after i do "mvn package" emacs is
completely confused and for every file it says "it has been edited" and i
need to re-open it. not helpful for a development cycle. i think i am
simply going to edit the pom and remove scalacheck for development.

mvn test runs through the projects until one fails. then it skips the rest!
since its very likely that i get a failure in some subproject, this means
its nearly impossible to do a general test run and get a good sense of the
status of the project. for example:

[INFO]
------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO]
[INFO] Spark Project Parent POM .......................... SUCCESS [2.199s]
[INFO] Spark Project Core ................................ SUCCESS
[39:43.028s]
[INFO] Spark Project Bagel ............................... SUCCESS [42.569s]
[INFO] Spark Project GraphX .............................. SUCCESS
[3:22.104s]
[INFO] Spark Project Streaming ........................... SUCCESS
[7:12.592s]
[INFO] Spark Project ML Library .......................... SUCCESS
[10:32.682s]
[INFO] Spark Project Tools ............................... SUCCESS [17.070s]
[INFO] Spark Project Catalyst ............................ SUCCESS
[3:03.470s]
[INFO] Spark Project SQL ................................. SUCCESS
[5:23.993s]
[INFO] Spark Project Hive ................................ FAILURE
[2:08.387s]
[INFO] Spark Project REPL ................................ SKIPPED
[INFO] Spark Project Assembly ............................ SKIPPED
[INFO] Spark Project External Twitter .................... SKIPPED
[INFO] Spark Project External Kafka ...................... SKIPPED
[INFO] Spark Project External Flume Sink ................. SKIPPED
[INFO] Spark Project External Flume ...................... SKIPPED
[INFO] Spark Project External ZeroMQ ..................... SKIPPED
[INFO] Spark Project External MQTT ....................... SKIPPED
[INFO] Spark Project Examples ............................ SKIPPED

in this case i dont care about Hive, but i would have liked to see REPL
run, and Kafka.




On Thu, Oct 23, 2014 at 4:44 PM, Ted Yu <yuzhihong@gmail.com> wrote:

> Created SPARK-4066 and attached patch there.
>
> On Thu, Oct 23, 2014 at 1:07 PM, Koert Kuipers <koert@tresata.com> wrote:
>
>> great thanks i will do that
>>
>> On Thu, Oct 23, 2014 at 3:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>
>>> Koert:
>>> If you have time, you can try this diff - with which you would be able
>>> to specify the following on the command line:
>>> -Dscalastyle.failonviolation=false
>>>
>>> diff --git a/pom.xml b/pom.xml
>>> index 687cc63..108585e 100644
>>> --- a/pom.xml
>>> +++ b/pom.xml
>>> @@ -123,6 +123,7 @@
>>>      <log4j.version>1.2.17</log4j.version>
>>>      <hadoop.version>1.0.4</hadoop.version>
>>>      <protobuf.version>2.4.1</protobuf.version>
>>> +    <scalastyle.failonviolation>true</scalastyle.failonviolation>
>>>      <yarn.version>${hadoop.version}</yarn.version>
>>>      <hbase.version>0.94.6</hbase.version>
>>>      <flume.version>1.4.0</flume.version>
>>> @@ -1071,7 +1072,7 @@
>>>          <version>0.4.0</version>
>>>          <configuration>
>>>            <verbose>false</verbose>
>>> -          <failOnViolation>true</failOnViolation>
>>> +
>>>  <failOnViolation>${scalastyle.failonviolation}</failOnViolation>
>>>            <includeTestSourceDirectory>false</includeTestSourceDirectory>
>>>            <failOnWarning>false</failOnWarning>
>>>            <sourceDirectory>${basedir}/src/main/scala</sourceDirectory>
>>>
>>>
>>>
>>> On Thu, Oct 23, 2014 at 12:07 PM, Koert Kuipers <koert@tresata.com>
>>> wrote:
>>>
>>>> Hey Ted,
>>>> i tried:
>>>> mvn clean package -DskipTests -Dscalastyle.failOnViolation=false
>>>>
>>>> no luck, still get
>>>> [ERROR] Failed to execute goal
>>>> org.scalastyle:scalastyle-maven-plugin:0.4.0:check (default) on project
>>>> spark-core_2.10: Failed during scalastyle execution: You have 3 Scalastyle
>>>> violation(s). -> [Help 1]
>>>>
>>>>
>>>> On Thu, Oct 23, 2014 at 2:14 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>>
>>>>> Koert:
>>>>> Have you tried adding the following on your commandline ?
>>>>>
>>>>> -Dscalastyle.failOnViolation=false
>>>>>
>>>>> Cheers
>>>>>
>>>>> On Thu, Oct 23, 2014 at 11:07 AM, Patrick Wendell <pwendell@gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hey Koert,
>>>>>>
>>>>>> I think disabling the style checks in maven package could be a good
>>>>>> idea for the reason you point out. I was sort of mixed on that when it
>>>>>> was proposed for this exact reason. It's just annoying to developers.
>>>>>>
>>>>>> In terms of changing the global limit, this is more religion than
>>>>>> anything else, but there are other cases where the current limit is
>>>>>> useful (e.g. if you have many windows open in a large screen).
>>>>>>
>>>>>> - Patrick
>>>>>>
>>>>>> On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com>
>>>>>> wrote:
>>>>>> > 100 max width seems very restrictive to me.
>>>>>> >
>>>>>> > even the most restrictive environment i have for development (ssh
>>>>>> with
>>>>>> > emacs) i get a lot more characters to work with than that.
>>>>>> >
>>>>>> > personally i find the code harder to read, not easier. like i kept
>>>>>> > wondering why there are weird newlines in the
>>>>>> > middle of constructors and such, only to realise later it was
>>>>>> because of
>>>>>> > the 100 character limit.
>>>>>> >
>>>>>> > also, i find "mvn package" erroring out because of style errors
>>>>>> somewhat
>>>>>> > excessive. i understand that a pull request needs to conform to
>>>>>> "the style"
>>>>>> > before being accepted, but this means i cant even run tests on code
>>>>>> that
>>>>>> > does not conform to the style guide, which is a bit silly.
>>>>>> >
>>>>>> > i keep going out for coffee while package and tests run, only to
>>>>>> come back
>>>>>> > for an annoying error that my line is 101 characters and therefore
>>>>>> nothing
>>>>>> > ran.
>>>>>> >
>>>>>> > is there some maven switch to disable the style checks?
>>>>>> >
>>>>>> > best! koert
>>>>>>
>>>>>> ---------------------------------------------------------------------
>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--047d7b450e065d8a7f0506309f60--

From dev-return-9960-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:06:29 2014
Return-Path: <dev-return-9960-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6816E17402
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:06:29 +0000 (UTC)
Received: (qmail 26059 invoked by uid 500); 24 Oct 2014 20:06:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25986 invoked by uid 500); 24 Oct 2014 20:06:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25974 invoked by uid 99); 24 Oct 2014 20:06:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:06:27 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.212.173] (HELO mail-wi0-f173.google.com) (209.85.212.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:06:00 +0000
Received: by mail-wi0-f173.google.com with SMTP id ex7so2120683wid.6
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:05:59 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=0H/ssL6OAPuicWes9gKdgn37AygI8hmqkl4oQE7w4Nk=;
        b=IU3W5zWUTekzvF/zazv5cAFNJYJKVKozFyWHBrKUERtXuMrKrjo4+siVi1wkTSh8ZK
         2x8joJf3hAPQt62LO3NpIBcEQV1Ngf+h9NMFWe4k9WgGctYjLyJBdRjAfOw8XEdzYW0M
         +Wj5E2HfRPo8I27ArFHPlVhi+NRrELu1t6ySgfgwzZwUxGH9Yt+2u06/cz0jUDE7RY+9
         XBvpLg9fK7wf0cLECN99RMf22ELYpyoZ8iyxWjZEs4O7MS57SmD/rxfhD+76us6YmQnf
         4FjCgXGK6gHxrL3FssCRwkklGDzzNpk5/pr0s9rfC68GswfrrZLdVKSe7K9tSxF9pDmb
         Qevw==
X-Gm-Message-State: ALoCoQkvEVCrejppZlnI9JCl1K1RxMiCt0e3HF09fIseXMY0qetSRoJGpWnhI9QiLT9i0EeUWeTr
MIME-Version: 1.0
X-Received: by 10.194.104.170 with SMTP id gf10mr7109778wjb.88.1414181159263;
 Fri, 24 Oct 2014 13:05:59 -0700 (PDT)
Received: by 10.217.116.69 with HTTP; Fri, 24 Oct 2014 13:05:59 -0700 (PDT)
X-Originating-IP: [199.47.226.148]
In-Reply-To: <CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
	<CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
	<CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
	<CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
	<CALte62x95NQ1JimQ53DHxto23dkVMYo_D6KMcRs8MzPSSP9g3Q@mail.gmail.com>
	<CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
Date: Fri, 24 Oct 2014 16:05:59 -0400
Message-ID: <CANx3uAj92N93W6fy9n1=V4M1jw=nN+f3hJrjDbir6oPmV5AqFw@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Koert Kuipers <koert@tresata.com>
To: Ted Yu <yuzhihong@gmail.com>
Cc: Patrick Wendell <pwendell@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e010d8b06a57616050630b520
X-Virus-Checked: Checked by ClamAV on apache.org

--089e010d8b06a57616050630b520
Content-Type: text/plain; charset=UTF-8

oh i found some stuff about tests and how to continue them, gonna try that
now (-fae switch). should have googled before asking...

On Fri, Oct 24, 2014 at 3:59 PM, Koert Kuipers <koert@tresata.com> wrote:

> thanks ted.
>
> apologies for complaining about maven here again, but this is the first
> time i seriously use it for development, and i am completely unfamiliar
> with it.
>
> a few more issues:
>
> "mvn clean package -DskipTests" takes about 30 mins for me. thats painful
> since its needed for the tests. does anyone know any tricks to speed it up?
> (besides getting a better laptop). does zinc help?
>
> does scalastyle overwrite files? after i do "mvn package" emacs is
> completely confused and for every file it says "it has been edited" and i
> need to re-open it. not helpful for a development cycle. i think i am
> simply going to edit the pom and remove scalacheck for development.
>
> mvn test runs through the projects until one fails. then it skips the
> rest! since its very likely that i get a failure in some subproject, this
> means its nearly impossible to do a general test run and get a good sense
> of the status of the project. for example:
>
> [INFO]
> ------------------------------------------------------------------------
> [INFO] Reactor Summary:
> [INFO]
> [INFO] Spark Project Parent POM .......................... SUCCESS [2.199s]
> [INFO] Spark Project Core ................................ SUCCESS
> [39:43.028s]
> [INFO] Spark Project Bagel ............................... SUCCESS
> [42.569s]
> [INFO] Spark Project GraphX .............................. SUCCESS
> [3:22.104s]
> [INFO] Spark Project Streaming ........................... SUCCESS
> [7:12.592s]
> [INFO] Spark Project ML Library .......................... SUCCESS
> [10:32.682s]
> [INFO] Spark Project Tools ............................... SUCCESS
> [17.070s]
> [INFO] Spark Project Catalyst ............................ SUCCESS
> [3:03.470s]
> [INFO] Spark Project SQL ................................. SUCCESS
> [5:23.993s]
> [INFO] Spark Project Hive ................................ FAILURE
> [2:08.387s]
> [INFO] Spark Project REPL ................................ SKIPPED
> [INFO] Spark Project Assembly ............................ SKIPPED
> [INFO] Spark Project External Twitter .................... SKIPPED
> [INFO] Spark Project External Kafka ...................... SKIPPED
> [INFO] Spark Project External Flume Sink ................. SKIPPED
> [INFO] Spark Project External Flume ...................... SKIPPED
> [INFO] Spark Project External ZeroMQ ..................... SKIPPED
> [INFO] Spark Project External MQTT ....................... SKIPPED
> [INFO] Spark Project Examples ............................ SKIPPED
>
> in this case i dont care about Hive, but i would have liked to see REPL
> run, and Kafka.
>
>
>
>
> On Thu, Oct 23, 2014 at 4:44 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>
>> Created SPARK-4066 and attached patch there.
>>
>> On Thu, Oct 23, 2014 at 1:07 PM, Koert Kuipers <koert@tresata.com> wrote:
>>
>>> great thanks i will do that
>>>
>>> On Thu, Oct 23, 2014 at 3:55 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>
>>>> Koert:
>>>> If you have time, you can try this diff - with which you would be able
>>>> to specify the following on the command line:
>>>> -Dscalastyle.failonviolation=false
>>>>
>>>> diff --git a/pom.xml b/pom.xml
>>>> index 687cc63..108585e 100644
>>>> --- a/pom.xml
>>>> +++ b/pom.xml
>>>> @@ -123,6 +123,7 @@
>>>>      <log4j.version>1.2.17</log4j.version>
>>>>      <hadoop.version>1.0.4</hadoop.version>
>>>>      <protobuf.version>2.4.1</protobuf.version>
>>>> +    <scalastyle.failonviolation>true</scalastyle.failonviolation>
>>>>      <yarn.version>${hadoop.version}</yarn.version>
>>>>      <hbase.version>0.94.6</hbase.version>
>>>>      <flume.version>1.4.0</flume.version>
>>>> @@ -1071,7 +1072,7 @@
>>>>          <version>0.4.0</version>
>>>>          <configuration>
>>>>            <verbose>false</verbose>
>>>> -          <failOnViolation>true</failOnViolation>
>>>> +
>>>>  <failOnViolation>${scalastyle.failonviolation}</failOnViolation>
>>>>
>>>>  <includeTestSourceDirectory>false</includeTestSourceDirectory>
>>>>            <failOnWarning>false</failOnWarning>
>>>>            <sourceDirectory>${basedir}/src/main/scala</sourceDirectory>
>>>>
>>>>
>>>>
>>>> On Thu, Oct 23, 2014 at 12:07 PM, Koert Kuipers <koert@tresata.com>
>>>> wrote:
>>>>
>>>>> Hey Ted,
>>>>> i tried:
>>>>> mvn clean package -DskipTests -Dscalastyle.failOnViolation=false
>>>>>
>>>>> no luck, still get
>>>>> [ERROR] Failed to execute goal
>>>>> org.scalastyle:scalastyle-maven-plugin:0.4.0:check (default) on project
>>>>> spark-core_2.10: Failed during scalastyle execution: You have 3 Scalastyle
>>>>> violation(s). -> [Help 1]
>>>>>
>>>>>
>>>>> On Thu, Oct 23, 2014 at 2:14 PM, Ted Yu <yuzhihong@gmail.com> wrote:
>>>>>
>>>>>> Koert:
>>>>>> Have you tried adding the following on your commandline ?
>>>>>>
>>>>>> -Dscalastyle.failOnViolation=false
>>>>>>
>>>>>> Cheers
>>>>>>
>>>>>> On Thu, Oct 23, 2014 at 11:07 AM, Patrick Wendell <pwendell@gmail.com
>>>>>> > wrote:
>>>>>>
>>>>>>> Hey Koert,
>>>>>>>
>>>>>>> I think disabling the style checks in maven package could be a good
>>>>>>> idea for the reason you point out. I was sort of mixed on that when
>>>>>>> it
>>>>>>> was proposed for this exact reason. It's just annoying to developers.
>>>>>>>
>>>>>>> In terms of changing the global limit, this is more religion than
>>>>>>> anything else, but there are other cases where the current limit is
>>>>>>> useful (e.g. if you have many windows open in a large screen).
>>>>>>>
>>>>>>> - Patrick
>>>>>>>
>>>>>>> On Thu, Oct 23, 2014 at 11:03 AM, Koert Kuipers <koert@tresata.com>
>>>>>>> wrote:
>>>>>>> > 100 max width seems very restrictive to me.
>>>>>>> >
>>>>>>> > even the most restrictive environment i have for development (ssh
>>>>>>> with
>>>>>>> > emacs) i get a lot more characters to work with than that.
>>>>>>> >
>>>>>>> > personally i find the code harder to read, not easier. like i kept
>>>>>>> > wondering why there are weird newlines in the
>>>>>>> > middle of constructors and such, only to realise later it was
>>>>>>> because of
>>>>>>> > the 100 character limit.
>>>>>>> >
>>>>>>> > also, i find "mvn package" erroring out because of style errors
>>>>>>> somewhat
>>>>>>> > excessive. i understand that a pull request needs to conform to
>>>>>>> "the style"
>>>>>>> > before being accepted, but this means i cant even run tests on
>>>>>>> code that
>>>>>>> > does not conform to the style guide, which is a bit silly.
>>>>>>> >
>>>>>>> > i keep going out for coffee while package and tests run, only to
>>>>>>> come back
>>>>>>> > for an annoying error that my line is 101 characters and therefore
>>>>>>> nothing
>>>>>>> > ran.
>>>>>>> >
>>>>>>> > is there some maven switch to disable the style checks?
>>>>>>> >
>>>>>>> > best! koert
>>>>>>>
>>>>>>> ---------------------------------------------------------------------
>>>>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>

--089e010d8b06a57616050630b520--

From dev-return-9961-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:08:04 2014
Return-Path: <dev-return-9961-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AA15317411
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:08:04 +0000 (UTC)
Received: (qmail 34778 invoked by uid 500); 24 Oct 2014 20:08:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34707 invoked by uid 500); 24 Oct 2014 20:08:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34696 invoked by uid 99); 24 Oct 2014 20:08:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:08:02 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vanzin@cloudera.com designates 209.85.216.176 as permitted sender)
Received: from [209.85.216.176] (HELO mail-qc0-f176.google.com) (209.85.216.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:07:37 +0000
Received: by mail-qc0-f176.google.com with SMTP id r5so1326440qcx.7
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:07:36 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=XR+82rYVXVsJWR0Zycp1p4+2EfoLCnQbaFPoWDup1+w=;
        b=LWZfGWMd5/SdZYc5lCYTAEzRPhzihDqCu8HiJACEILoeLjY1tzB386rUVC0GAb4zKH
         fTYuaKMQ9dfMLrgJE/BuMBmerPujfPTw186zw4JN5Y951COERH0wWHmXqLiAGA7j42Y3
         j+zSHn25hIcKR/gM8oFIkNOwNCWs7WqYnR56Iqc+RApqPQuCpaDvWwjJ7uD2XO1gYTXe
         3208p3ttuxndA70vk0Avtjj4SRf4/YcwVImlHlbkS+7Pt6FXc7YCyMrSCJAhgL4hjXwf
         kA3VXZIdGqR4pBScCZdVx9hBy0HpAdsDxTuzORzNOaoVOeSqvKyY1QzuVbdtj4kSQ+QU
         QrEQ==
X-Gm-Message-State: ALoCoQkM0K2V1HebKVjambLIpoErJgjJfTx6fyQZaSaRy28uQ/msKTcXB85qzy8bXlchhZJKMZHN
MIME-Version: 1.0
X-Received: by 10.140.84.179 with SMTP id l48mr8954471qgd.24.1414181256074;
 Fri, 24 Oct 2014 13:07:36 -0700 (PDT)
Received: by 10.229.8.68 with HTTP; Fri, 24 Oct 2014 13:07:35 -0700 (PDT)
In-Reply-To: <CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
	<CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
	<CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
	<CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
	<CALte62x95NQ1JimQ53DHxto23dkVMYo_D6KMcRs8MzPSSP9g3Q@mail.gmail.com>
	<CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
Date: Fri, 24 Oct 2014 13:07:35 -0700
Message-ID: <CAAOnQ7vtFP+XbBHahqZURs6YEmYh5s5bNZu35jqhyt-ETqdjXQ@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Marcelo Vanzin <vanzin@cloudera.com>
To: Koert Kuipers <koert@tresata.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On Fri, Oct 24, 2014 at 12:59 PM, Koert Kuipers <koert@tresata.com> wrote:
> "mvn clean package -DskipTests" takes about 30 mins for me. thats painful
> since its needed for the tests. does anyone know any tricks to speed it up?
> (besides getting a better laptop). does zinc help?

I noticed this too, and I also noticed some messages about running out
of space for the code cache on the output. In the pom.xml I added this
to the scala compiler options:

              <jvmArg>-XX:ReservedCodeCacheSize=512m</jvmArg>

Although I haven't actually measured if it improves things yet.
Haven't tried zinc either.

> mvn test runs through the projects until one fails. then it skips the rest!
> since its very likely that i get a failure in some subproject, this means
> its nearly impossible to do a general test run and get a good sense of the
> status of the project. for example:

You can try "mvn -fn" or "mvn -fae" (check "mvn --help" for what they mean).

-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9962-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:10:12 2014
Return-Path: <dev-return-9962-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E58D417425
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:10:11 +0000 (UTC)
Received: (qmail 43663 invoked by uid 500); 24 Oct 2014 20:10:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43588 invoked by uid 500); 24 Oct 2014 20:10:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43577 invoked by uid 99); 24 Oct 2014 20:10:10 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:10:10 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.213.181 as permitted sender)
Received: from [209.85.213.181] (HELO mail-ig0-f181.google.com) (209.85.213.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:10:05 +0000
Received: by mail-ig0-f181.google.com with SMTP id l13so1092928iga.14
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:09:10 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=XU6nQKaELYVIbtWBJZC5P5LZblYM+002TZ0ldOoGpFI=;
        b=AXtH/LtYDn12QYtPxeLzuelClZHXehjnWUe4HtMPaSkF9Yuwte+J0P5BEi2ahLvS7L
         E6m5x3176mrKDpKB4gUETqoBEo+STWmgvrdo0eL6EsaRh9gAJ84Jo26WcjHFLnMp+3hi
         M4HNWwivWllph2gpdWT5VBFAVmrVWKSH5TP2exsmN5+psQtWIJ0ybW8ke36LFy7Xowgt
         LJCkv1mtwK7ilGANB2DJxTOmT/irCbyMRLopOPKg2oYXRf44V4uwj7WmIs+27uyHZhvJ
         NGeuPMffPR/JsVkDszdrJ8BSFb9ct1oiD0FxlQjLFgI67YrjEsBbgFcWYndx7HsPWwzO
         GuAg==
X-Gm-Message-State: ALoCoQkV+jByYSVN1ttFWJfunAUSnimN89XiiEKRbExw8di7iFqB/7rFccnDqwZg38Ju4IpV0Qra
X-Received: by 10.50.41.34 with SMTP id c2mr5957015igl.5.1414181350020; Fri,
 24 Oct 2014 13:09:10 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Fri, 24 Oct 2014 13:08:48 -0700 (PDT)
In-Reply-To: <CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
 <CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
 <CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
 <CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
 <CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
 <CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
 <CALte62x95NQ1JimQ53DHxto23dkVMYo_D6KMcRs8MzPSSP9g3Q@mail.gmail.com> <CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Fri, 24 Oct 2014 21:08:48 +0100
Message-ID: <CAMAsSdLG4_NbEWjCu9pfmh8S8gv+KMNkO2wkk8WVqtfFLkWbxg@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
To: Koert Kuipers <koert@tresata.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On Fri, Oct 24, 2014 at 8:59 PM, Koert Kuipers <koert@tresata.com> wrote:
> "mvn clean package -DskipTests" takes about 30 mins for me. thats painful
> since its needed for the tests. does anyone know any tricks to speed it up?
> (besides getting a better laptop). does zinc help?

Zinc helps by about 50-100%. Worthwhile for sure. brew install zinc
and zinc -start

> mvn test runs through the projects until one fails. then it skips the rest!
> since its very likely that i get a failure in some subproject, this means
> its nearly impossible to do a general test run and get a good sense of the
> status of the project. for example:

You can mvn test -pl [module] to test just one module.
It will also indicate to you that after a failure you can mvn test -rf
:[module] to continue where it left off -- you can use this to resume
at the next module.

Or try "-Dscalatest.testFailureIgnore=true" if the mvn flags
themselves don't work, for continuing after a test failure.

> [INFO]
> ------------------------------------------------------------------------
> [INFO] Reactor Summary:
> [INFO]
> [INFO] Spark Project Parent POM .......................... SUCCESS [2.199s]
> [INFO] Spark Project Core ................................ SUCCESS
> [39:43.028s]
> [INFO] Spark Project Bagel ............................... SUCCESS [42.569s]
> [INFO] Spark Project GraphX .............................. SUCCESS
> [3:22.104s]
> [INFO] Spark Project Streaming ........................... SUCCESS
> [7:12.592s]
> [INFO] Spark Project ML Library .......................... SUCCESS
> [10:32.682s]
> [INFO] Spark Project Tools ............................... SUCCESS [17.070s]
> [INFO] Spark Project Catalyst ............................ SUCCESS
> [3:03.470s]
> [INFO] Spark Project SQL ................................. SUCCESS
> [5:23.993s]
> [INFO] Spark Project Hive ................................ FAILURE
> [2:08.387s]
> [INFO] Spark Project REPL ................................ SKIPPED
> [INFO] Spark Project Assembly ............................ SKIPPED
> [INFO] Spark Project External Twitter .................... SKIPPED
> [INFO] Spark Project External Kafka ...................... SKIPPED
> [INFO] Spark Project External Flume Sink ................. SKIPPED
> [INFO] Spark Project External Flume ...................... SKIPPED
> [INFO] Spark Project External ZeroMQ ..................... SKIPPED
> [INFO] Spark Project External MQTT ....................... SKIPPED
> [INFO] Spark Project Examples ............................ SKIPPED
>
> in this case i dont care about Hive, but i would have liked to see REPL
> run, and Kafka.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9963-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:21:57 2014
Return-Path: <dev-return-9963-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A4AB7174B2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:21:57 +0000 (UTC)
Received: (qmail 77119 invoked by uid 500); 24 Oct 2014 20:21:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77051 invoked by uid 500); 24 Oct 2014 20:21:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77039 invoked by uid 99); 24 Oct 2014 20:21:56 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:21:56 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of rnowling@gmail.com designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:21:30 +0000
Received: by mail-wg0-f46.google.com with SMTP id l18so1851764wgh.17
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:20:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=o9Y2W7BG8MOmFfwX/txAXrPhIkQLH7biZ07A70rFUp0=;
        b=fmQjTbFt9PHPNjfalhSydlxZw3XY/w/v1trmBoYZQnQUGQn7G/Xjj8fI1doUZK1Q+0
         IqcoVjZO6NePu4b4py/BMfhhUKboruGt2conlnRUKizLjnpaUQwhZhJzSXIgr3T7XEWb
         22nWKMQMpu6b9HQD5L6GLi74sMb4DZSC8ZdP9qY/k1oI+mmCwzxlQtrTKPL81zm7n/ze
         OZKh0qbcb/YyjxszZOmue9U7bXAJb2V+SUBzXL9ig85mdSuKZ1x6sE5IBd+pXcjkzhp8
         Hwr2/BvbGKDD5RpNJ0zzZ9FAemjU0NQ0OHW2KUa0QxKNNYn7IyV7QDZUY7WTl53x8Zti
         nVXA==
MIME-Version: 1.0
X-Received: by 10.194.92.82 with SMTP id ck18mr5486737wjb.103.1414182044504;
 Fri, 24 Oct 2014 13:20:44 -0700 (PDT)
Received: by 10.194.37.225 with HTTP; Fri, 24 Oct 2014 13:20:44 -0700 (PDT)
In-Reply-To: <CAJgQjQ-6oiB6jA-aekoDx98T9zBpuJdA=dj+anP8G22-bk2mAg@mail.gmail.com>
References: <CADtDQQJPbtofBi=HTDbnD3fgFOX+vTCKnU=fOgor55ZDsCDwpQ@mail.gmail.com>
	<CAJgQjQ-6oiB6jA-aekoDx98T9zBpuJdA=dj+anP8G22-bk2mAg@mail.gmail.com>
Date: Fri, 24 Oct 2014 16:20:44 -0400
Message-ID: <CADtDQQJ1Zw-TGiJ=z78wHN+kJgPA_P1nzNpdOGhro5QA+RWagg@mail.gmail.com>
Subject: Re: PR for Hierarchical Clustering Needs Review
From: RJ Nowling <rnowling@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7bd9201a691b0d050630ea3c
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bd9201a691b0d050630ea3c
Content-Type: text/plain; charset=UTF-8

Thanks, Xiangrui!

Might be worth waiting until after the feature freeze to review since it's
a large patch.

On Thu, Oct 23, 2014 at 3:26 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> Hi RJ,
>
> We are close to the v1.2 feature freeze deadline, so I'm busy with the
> pipeline feature and couple bugs. I will ask other developers to help
> review the PR. Thanks for working with Yu and helping the code review!
>
> Best,
> Xiangrui
>
> On Thu, Oct 23, 2014 at 2:58 AM, RJ Nowling <rnowling@gmail.com> wrote:
> > Hi all,
> >
> > A few months ago, I collected feedback on what the community was looking
> > for in clustering methods.  A number of the community members requested a
> > divisive hierarchical clustering method.
> >
> > Yu Ishikawa has stepped up to implement such a method.  I've been working
> > with him to communicate what I heard the community request and to review
> > and improve his code.
> >
> > You can find the JIRA here:
> > https://issues.apache.org/jira/browse/SPARK-2429
> >
> > He has now submitted a PR:
> > https://github.com/apache/spark/pull/2906
> >
> > I was hoping Xiangrui, other committers, and community members would be
> > willing to take a look?  It's quite a large patch so it'll need extra
> > attention.
> >
> > Thank you,
> > RJ
> >
> > --
> > em rnowling@gmail.com
> > c 954.496.2314
>



-- 
em rnowling@gmail.com
c 954.496.2314

--047d7bd9201a691b0d050630ea3c--

From dev-return-9964-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:23:14 2014
Return-Path: <dev-return-9964-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 31576174BC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:23:14 +0000 (UTC)
Received: (qmail 82838 invoked by uid 500); 24 Oct 2014 20:23:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 82772 invoked by uid 500); 24 Oct 2014 20:23:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 82748 invoked by uid 99); 24 Oct 2014 20:23:12 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:23:12 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of javadba@gmail.com designates 209.85.220.177 as permitted sender)
Received: from [209.85.220.177] (HELO mail-vc0-f177.google.com) (209.85.220.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:22:47 +0000
Received: by mail-vc0-f177.google.com with SMTP id hq11so669320vcb.22
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:22:46 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=dPUNRt9aa7MIASSrPW74SUDJeNDAspX0nkD1G/+4V24=;
        b=p/N2i2v5O0KX1xTuCVFtgbfM9hVILdhIv1St+/Oz58EJMVW+eKNbHXbb7tXkQGButk
         1tl5bJtMYI1wY50H+4JDf0SqLyNwSW6id2RrMWunuVtq+z20IQM2rCWlB1/UK2pWlrH5
         O1cDh61xHP6Yp3Ytft17pUQ76YPjAMDQ8AkbJYbFfaxgRD4nGOkMki8/SW3A+EUhT1An
         +X2m7iaD/R2HTgBhsxzrPD5w75c/l74O6SmTx51SOcWGC7cxycP/eID5kdANZiKOA4lK
         64MUMsQawRcoy+EobhFphvWhXTYJi9+D4p01spL02p/KX86VTXwNGfDCdNDU1DZPyobl
         puwg==
MIME-Version: 1.0
X-Received: by 10.221.29.134 with SMTP id ry6mr4400009vcb.26.1414182166009;
 Fri, 24 Oct 2014 13:22:46 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Fri, 24 Oct 2014 13:22:45 -0700 (PDT)
In-Reply-To: <CAMAsSdLG4_NbEWjCu9pfmh8S8gv+KMNkO2wkk8WVqtfFLkWbxg@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
	<CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
	<CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
	<CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
	<CALte62x95NQ1JimQ53DHxto23dkVMYo_D6KMcRs8MzPSSP9g3Q@mail.gmail.com>
	<CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
	<CAMAsSdLG4_NbEWjCu9pfmh8S8gv+KMNkO2wkk8WVqtfFLkWbxg@mail.gmail.com>
Date: Fri, 24 Oct 2014 13:22:45 -0700
Message-ID: <CACkSZy3freZ4xJ_9nCciNSPHaUGiS1GaQJew4vaFgGtDpdiAdA@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Stephen Boesch <javadba@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Koert Kuipers <koert@tresata.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1133a068a71e0e050630f179
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1133a068a71e0e050630f179
Content-Type: text/plain; charset=UTF-8

Sean Owen beat me to (strongly) recommending running zinc server.  Using
the -pl option is great too - but be careful to only use it when your work
is restricted to the modules in the (comma separated) list you provide to
-pl.   Also before using -pl you should do a  mvn compile package install
on all modules.  Use the -pl after those steps are done - and then it is
very effective.

2014-10-24 13:08 GMT-07:00 Sean Owen <sowen@cloudera.com>:

> On Fri, Oct 24, 2014 at 8:59 PM, Koert Kuipers <koert@tresata.com> wrote:
> > "mvn clean package -DskipTests" takes about 30 mins for me. thats painful
> > since its needed for the tests. does anyone know any tricks to speed it
> up?
> > (besides getting a better laptop). does zinc help?
>
> Zinc helps by about 50-100%. Worthwhile for sure. brew install zinc
> and zinc -start
>
> > mvn test runs through the projects until one fails. then it skips the
> rest!
> > since its very likely that i get a failure in some subproject, this means
> > its nearly impossible to do a general test run and get a good sense of
> the
> > status of the project. for example:
>
> You can mvn test -pl [module] to test just one module.
> It will also indicate to you that after a failure you can mvn test -rf
> :[module] to continue where it left off -- you can use this to resume
> at the next module.
>
> Or try "-Dscalatest.testFailureIgnore=true" if the mvn flags
> themselves don't work, for continuing after a test failure.
>
> > [INFO]
> > ------------------------------------------------------------------------
> > [INFO] Reactor Summary:
> > [INFO]
> > [INFO] Spark Project Parent POM .......................... SUCCESS
> [2.199s]
> > [INFO] Spark Project Core ................................ SUCCESS
> > [39:43.028s]
> > [INFO] Spark Project Bagel ............................... SUCCESS
> [42.569s]
> > [INFO] Spark Project GraphX .............................. SUCCESS
> > [3:22.104s]
> > [INFO] Spark Project Streaming ........................... SUCCESS
> > [7:12.592s]
> > [INFO] Spark Project ML Library .......................... SUCCESS
> > [10:32.682s]
> > [INFO] Spark Project Tools ............................... SUCCESS
> [17.070s]
> > [INFO] Spark Project Catalyst ............................ SUCCESS
> > [3:03.470s]
> > [INFO] Spark Project SQL ................................. SUCCESS
> > [5:23.993s]
> > [INFO] Spark Project Hive ................................ FAILURE
> > [2:08.387s]
> > [INFO] Spark Project REPL ................................ SKIPPED
> > [INFO] Spark Project Assembly ............................ SKIPPED
> > [INFO] Spark Project External Twitter .................... SKIPPED
> > [INFO] Spark Project External Kafka ...................... SKIPPED
> > [INFO] Spark Project External Flume Sink ................. SKIPPED
> > [INFO] Spark Project External Flume ...................... SKIPPED
> > [INFO] Spark Project External ZeroMQ ..................... SKIPPED
> > [INFO] Spark Project External MQTT ....................... SKIPPED
> > [INFO] Spark Project Examples ............................ SKIPPED
> >
> > in this case i dont care about Hive, but i would have liked to see REPL
> > run, and Kafka.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a1133a068a71e0e050630f179--

From dev-return-9965-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:35:00 2014
Return-Path: <dev-return-9965-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CE09D1753D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:35:00 +0000 (UTC)
Received: (qmail 13753 invoked by uid 500); 24 Oct 2014 20:35:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13674 invoked by uid 500); 24 Oct 2014 20:35:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13662 invoked by uid 99); 24 Oct 2014 20:34:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:34:59 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.176 as permitted sender)
Received: from [209.85.217.176] (HELO mail-lb0-f176.google.com) (209.85.217.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:34:33 +0000
Received: by mail-lb0-f176.google.com with SMTP id p9so3140115lbv.21
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:33:02 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=v8YxeR0UN8mMQbMU4I9eCpXc47ay6BLlj4RqbzpZr9I=;
        b=gZMlv6sDqVuNE1+/VYdmOiVuC62htLvJtgPjUaHtpEyBMwuHFe7JUsanpu6IA85gHz
         dxQ1lViUTTeiJ3kTHMYgJ4FNHo5ULwcaVEAJ8twfQ0hCV7LunD7Oi6kYELaTn0VCZlGR
         WUmW8GnRJI5SwRTVUVKqzb4W2tYkpwACD1WOHyldlz8L4bpiXE7A28WgxlxTbc/10w5r
         z4rY/HFYYWWf/r9BzkEvKm57OqGUY9y2WueiPauQWmwRzt/TGyt2J2C321ZSKH6hadhY
         diu6rDHEAuTW1n7vP1FZCOy1Cv47kRcbtSuGgseI5vRre+s1wM5xnlXWb+ElfH18PnCR
         XKrA==
X-Gm-Message-State: ALoCoQkOBPKCkrXGN5v9dW5ICocuf1Xzoq6v2RHMVQRlGtvR3nomlrgnLR4RThEVJ3q4MGWOqm+L
X-Received: by 10.112.132.34 with SMTP id or2mr6810401lbb.75.1414182782253;
 Fri, 24 Oct 2014 13:33:02 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.24.14 with HTTP; Fri, 24 Oct 2014 13:32:42 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Fri, 24 Oct 2014 13:32:42 -0700
Message-ID: <CACdU-dR76VBkhUJ6k_UC8hR-oq3QmCoX-eqiE7tOVv8MR_gqWg@mail.gmail.com>
Subject: your weekly git timeout update! TL;DR: i'm now almost certain we're
 not hitting rate limits.
To: dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>
Content-Type: multipart/alternative; boundary=047d7b3a82386249d3050631169c
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a82386249d3050631169c
Content-Type: text/plain; charset=UTF-8

so, things look like they've stabilized significantly over the past 10
days, and without any changes on our end:
<snip>
$ /root/tools/get_timeouts.sh 10
timeouts by date:
2014-10-14 -- 2
2014-10-16 -- 1
2014-10-19 -- 1
2014-10-20 -- 2
2014-10-23 -- 5

timeouts by project:
      5 NewSparkPullRequestBuilder
      5 SparkPullRequestBuilder
      1 Tachyon-Pull-Request-Builder
total builds (excepting aborted by a user):
602

total percentage of builds timing out:
01
</snip>

the NewSparkPullRequestBuilder failures are spread over five different days
(10-14 through 10-20), and the SparkPullRequestBuilder failures all
happened yesterday.  there were a LOT of SparkPullRequestBuilder builds
yesterday (60), and the failures happened during these hours (first number
== number of builds failed, second number == hour of the day):
<snip>
$ cat timeouts-102414-130817 | grep SparkPullRequestBuilder | grep
2014-10-23 | awk '{print$3}' | awk -F":" '{print$1'} | sort | uniq -c
      1 03
      2 20
      1 22
      1 23
</snip>

however, the number of total SparkPullRequestBuilder builds during these
times don't seem egregious:
<snip>
      4 03
      9 20
      4 22
      9 23
</snip>

nor does the total for ALL builds at those times:
<snip>
      5 03
      9 20
      7 22
     11 23
</snip>

9 builds was the largest number of SparkPullRequestBuilder builds per hour,
but there were other hours with 5, 6 or 7 builds/hour that didn't have a
timeout issue.

in fact, hour 16 (4pm) had the most builds running total yesterday, which
includes 7 SparkPullRequestBuilder builds, and nothing timed out.

most of the pull request builder hits on github are authenticated w/an
oauth token.  this gives us 5000 hits/hour, and unauthed gives us 60/hour.

in conclusion:  there is no way are we hitting github often enough to be
rate limited.  i think i've finally ruled that out completely.  :)

--047d7b3a82386249d3050631169c--

From dev-return-9966-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:39:45 2014
Return-Path: <dev-return-9966-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0A81717557
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:39:45 +0000 (UTC)
Received: (qmail 25534 invoked by uid 500); 24 Oct 2014 20:39:43 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25463 invoked by uid 500); 24 Oct 2014 20:39:43 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25383 invoked by uid 99); 24 Oct 2014 20:39:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:39:42 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hshreedharan@cloudera.com designates 209.85.216.175 as permitted sender)
Received: from [209.85.216.175] (HELO mail-qc0-f175.google.com) (209.85.216.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:39:15 +0000
Received: by mail-qc0-f175.google.com with SMTP id b13so1510574qcw.6
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:39:14 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:date:mime-version:message-id:from:to:subject
         :content-type;
        bh=V+IK1yU9pfnavoduLsWvc3JkjoKN5BEkt0ZseOxT3SM=;
        b=YVGpSE+P35g7ta+GDmhAEc8rTlsg6IzkDFvd7nS/ispczBp3ubvTXKYDraV/ga4XY4
         gnurwIfVD7c/B3pJcwssDX2dQpXNV8yu7zYXTXAoOz+gwcKDbeh63MKh2+Q9mgt8/hXg
         hz+a5vohzJqpY1Bv8C5PGbOoRMddVnkgMY5vf5IKI7hKBLfdJkaY4SJAWG5GH0EUfKYT
         hSli41wdGxF1nLfzhtPMZRgdkzm3fLBBBrdiRSo+Q9M2HkQb3danp8JqUx1iOV861Nhh
         jjg415XBT0juaiMKoDBanMD4hHxh3eYnoSIVzGYIcAAUCaqOzEy/nt0aZcuP+9rBkEf+
         Bkrg==
X-Gm-Message-State: ALoCoQl48cVzxQ8mPpGA9WnbGO4YEB2j8LioPmoi5uZTuSudUxdP/2kU/YX27rQ1ddz/QIIJ555D
X-Received: by 10.224.47.2 with SMTP id l2mr9667985qaf.28.1414183153936;
        Fri, 24 Oct 2014 13:39:13 -0700 (PDT)
Received: from hedwig-6.prd.orcali.com (ec2-54-85-253-252.compute-1.amazonaws.com. [54.85.253.252])
        by mx.google.com with ESMTPSA id b88sm5028086qgb.6.2014.10.24.13.39.13
        for <dev@spark.apache.org>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 24 Oct 2014 13:39:13 -0700 (PDT)
Date: Fri, 24 Oct 2014 13:39:13 -0700 (PDT)
X-Google-Original-Date: Fri, 24 Oct 2014 20:39:13 GMT
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Message-Id: <1414183153144.407f1f85@Nodemailer>
X-Orchestra-Oid: F459EC23-8318-46D1-9F12-51A23CD2CC00
X-Orchestra-Sig: b815fcf0ae10466b35974b245a67cd4cbe67d89c
X-Orchestra-Thrid: 50FE6937-3491-4FA4-8FDD-8B267CBDF487
X-Orchestra-Thrid-Sig: 650c0854feeca515d9dcee7edfde7a33f71cfb42
X-Orchestra-Account: fbaaec17bfa9b5464be86b2ba8399e68683ca20d
From: "Hari Shreedharan" <hshreedharan@cloudera.com>
To: dev@spark.apache.org
Subject: Moving PR Builder to mvn
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1414183153508"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1414183153508
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Over the last few months, it seems like we have selected Maven to be the =
=E2=80=9Cofficial=E2=80=9D build system for Spark.=C2=A0


I realize that removing the sbt build may not be easy, but it might be a =
good idea to start looking into that. We had issues over the past few days =
where mvn builds were fine, while sbt was failing to resolve dependencies =
which were test-jars causing compilation of certain tests to fail.


As a first step, I am wondering if it might be a good idea to change the PR=
 builder to mvn and test PRs consistent with the way we test releases. I am=
 not sure how technically feasible it is, but it would be a start to =
standardizing on one build system.

Thanks,
Hari
------Nodemailer-0.5.0-?=_1-1414183153508--

From dev-return-9967-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:47:07 2014
Return-Path: <dev-return-9967-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 13AF717597
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:47:07 +0000 (UTC)
Received: (qmail 42141 invoked by uid 500); 24 Oct 2014 20:47:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 42068 invoked by uid 500); 24 Oct 2014 20:47:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 42057 invoked by uid 99); 24 Oct 2014 20:47:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:47:05 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.212.169] (HELO mail-wi0-f169.google.com) (209.85.212.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:46:39 +0000
Received: by mail-wi0-f169.google.com with SMTP id q5so2083345wiv.2
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:45:53 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=SYw0mQGRBFetDEU0ejU8aqiCwszkqjJNB8R2fP1A/a8=;
        b=NgEDf0rf4DgT2vqn2MzCVZARpMX2Hk+mOBjgopw8dCIIlUQTujcX/BqvEQN6mox2gF
         HCwQIyH1fwqJcd67RoMPWoD78j28n++QqjL+koViyIyE/eSDSdm6D0fswv8mgbnMEQhN
         wKXaNXhG11UbwHpFMvUsJ5Yy04436/nC8A9WYdrkKY+EhDjwkSEbEkCxnOCp44woVOsH
         ws0UWOjmjIkL3ukFhiwVdvn2GclJWK/WwOxil6bv0AgfhU4QyqSg6ib7Fa4yKBX6vQvD
         /yJ4maBCVd6pqlon8vwaPg+aV+FAycsnerFLcMzBtjix1vPXmN/0ChI+at8itus9xyMT
         +JQQ==
X-Gm-Message-State: ALoCoQl6FosGJtmDKH1qT5D9nzkk/Ms7R2k4IQp1B+yXpmmMdN4Ka/rCGBch3NihUTxsuQUJiKsg
MIME-Version: 1.0
X-Received: by 10.180.126.9 with SMTP id mu9mr6475819wib.38.1414183553412;
 Fri, 24 Oct 2014 13:45:53 -0700 (PDT)
Received: by 10.217.116.69 with HTTP; Fri, 24 Oct 2014 13:45:53 -0700 (PDT)
X-Originating-IP: [199.47.226.148]
In-Reply-To: <CACkSZy3freZ4xJ_9nCciNSPHaUGiS1GaQJew4vaFgGtDpdiAdA@mail.gmail.com>
References: <CANx3uAgn83FA3ohy9vBw9LTqEj579WrNCJUZOchXuJfMSpd5NA@mail.gmail.com>
	<CABPQxsvyc-52H4_LsqbtxgMnV6K6oyen4hwvOh8JkpW61mTV4A@mail.gmail.com>
	<CALte62zwq1abw0eQD2St1Pq3dzLUEm0JTow9WU+gE9368UGXkg@mail.gmail.com>
	<CANx3uAi7ugZKG1yYo77Dkk8XZpeK7QDVG-P1HJ55GZKi8kexDQ@mail.gmail.com>
	<CALte62w-8LfS2eHuMyE8h+Rx=BqwLsORgzU0ettjf1qqTLASwg@mail.gmail.com>
	<CANx3uAhjNxFn0si=tG+zDBJQSOGpidUAVeMqY852eQ1TE+D+uA@mail.gmail.com>
	<CALte62x95NQ1JimQ53DHxto23dkVMYo_D6KMcRs8MzPSSP9g3Q@mail.gmail.com>
	<CANx3uAhTrMx_1pxuXkU483O3_Gkkr1tFAHAE_L9ODHJvZ_0DBg@mail.gmail.com>
	<CAMAsSdLG4_NbEWjCu9pfmh8S8gv+KMNkO2wkk8WVqtfFLkWbxg@mail.gmail.com>
	<CACkSZy3freZ4xJ_9nCciNSPHaUGiS1GaQJew4vaFgGtDpdiAdA@mail.gmail.com>
Date: Fri, 24 Oct 2014 16:45:53 -0400
Message-ID: <CANx3uAjTOr5shnWxjv5BFfN2MORwZVoaq=+c30uy6CZwBohp6Q@mail.gmail.com>
Subject: Re: scalastyle annoys me a little bit
From: Koert Kuipers <koert@tresata.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=e89a8f839d295949c005063144ca
X-Virus-Checked: Checked by ClamAV on apache.org

--e89a8f839d295949c005063144ca
Content-Type: text/plain; charset=UTF-8

thanks everyone, very helpful

On Fri, Oct 24, 2014 at 4:22 PM, Stephen Boesch <javadba@gmail.com> wrote:

> Sean Owen beat me to (strongly) recommending running zinc server.  Using
> the -pl option is great too - but be careful to only use it when your work
> is restricted to the modules in the (comma separated) list you provide to
> -pl.   Also before using -pl you should do a  mvn compile package install
> on all modules.  Use the -pl after those steps are done - and then it is
> very effective.
>
> 2014-10-24 13:08 GMT-07:00 Sean Owen <sowen@cloudera.com>:
>
>> On Fri, Oct 24, 2014 at 8:59 PM, Koert Kuipers <koert@tresata.com> wrote:
>> > "mvn clean package -DskipTests" takes about 30 mins for me. thats
>> painful
>> > since its needed for the tests. does anyone know any tricks to speed it
>> up?
>> > (besides getting a better laptop). does zinc help?
>>
>> Zinc helps by about 50-100%. Worthwhile for sure. brew install zinc
>> and zinc -start
>>
>> > mvn test runs through the projects until one fails. then it skips the
>> rest!
>> > since its very likely that i get a failure in some subproject, this
>> means
>> > its nearly impossible to do a general test run and get a good sense of
>> the
>> > status of the project. for example:
>>
>> You can mvn test -pl [module] to test just one module.
>> It will also indicate to you that after a failure you can mvn test -rf
>> :[module] to continue where it left off -- you can use this to resume
>> at the next module.
>>
>> Or try "-Dscalatest.testFailureIgnore=true" if the mvn flags
>> themselves don't work, for continuing after a test failure.
>>
>> > [INFO]
>> > ------------------------------------------------------------------------
>> > [INFO] Reactor Summary:
>> > [INFO]
>> > [INFO] Spark Project Parent POM .......................... SUCCESS
>> [2.199s]
>> > [INFO] Spark Project Core ................................ SUCCESS
>> > [39:43.028s]
>> > [INFO] Spark Project Bagel ............................... SUCCESS
>> [42.569s]
>> > [INFO] Spark Project GraphX .............................. SUCCESS
>> > [3:22.104s]
>> > [INFO] Spark Project Streaming ........................... SUCCESS
>> > [7:12.592s]
>> > [INFO] Spark Project ML Library .......................... SUCCESS
>> > [10:32.682s]
>> > [INFO] Spark Project Tools ............................... SUCCESS
>> [17.070s]
>> > [INFO] Spark Project Catalyst ............................ SUCCESS
>> > [3:03.470s]
>> > [INFO] Spark Project SQL ................................. SUCCESS
>> > [5:23.993s]
>> > [INFO] Spark Project Hive ................................ FAILURE
>> > [2:08.387s]
>> > [INFO] Spark Project REPL ................................ SKIPPED
>> > [INFO] Spark Project Assembly ............................ SKIPPED
>> > [INFO] Spark Project External Twitter .................... SKIPPED
>> > [INFO] Spark Project External Kafka ...................... SKIPPED
>> > [INFO] Spark Project External Flume Sink ................. SKIPPED
>> > [INFO] Spark Project External Flume ...................... SKIPPED
>> > [INFO] Spark Project External ZeroMQ ..................... SKIPPED
>> > [INFO] Spark Project External MQTT ....................... SKIPPED
>> > [INFO] Spark Project Examples ............................ SKIPPED
>> >
>> > in this case i dont care about Hive, but i would have liked to see REPL
>> > run, and Kafka.
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
>

--e89a8f839d295949c005063144ca--

From dev-return-9968-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:47:37 2014
Return-Path: <dev-return-9968-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 165CA175A4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:47:37 +0000 (UTC)
Received: (qmail 47303 invoked by uid 500); 24 Oct 2014 20:47:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47231 invoked by uid 500); 24 Oct 2014 20:47:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47216 invoked by uid 99); 24 Oct 2014 20:47:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:47:35 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.180 as permitted sender)
Received: from [209.85.214.180] (HELO mail-ob0-f180.google.com) (209.85.214.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:47:31 +0000
Received: by mail-ob0-f180.google.com with SMTP id vb8so937585obc.39
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:46:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type:content-transfer-encoding;
        bh=/y74HqzZIfv0zAShfutVJBuN7/+y/axLdag92EqO0T4=;
        b=ujX8wmvEBhDWvJk5fHb8Rr/8Ub6OeIQCfLNb1VUHyHS+7UG5H/aspaKmlsa7M/DNrs
         gq1x2nlp616KOEL2OdifGQPFAsSIVTq+misxAZ9m722EBww6D5Ct++xdwfXQc7Zazykb
         093CbNrODfinuoqkqM/n1d/5qnfqmBbBucEWZdgux0gACUjP/ldQakKIesu9K980t8sB
         RdYe7pAz0tEpdHRL1r5Dvs/xETQWGGiz4BueqGOew7fYsrcq50KzTimEOCjnscmPjXM2
         FhF5nuBpiCFUZ19JbqaOO1nZCyjPxHF66LnBx57517+5FkVjGcDUeTxeyDLzYgjQlVQ8
         k8cw==
MIME-Version: 1.0
X-Received: by 10.182.56.15 with SMTP id w15mr3174007obp.55.1414183585740;
 Fri, 24 Oct 2014 13:46:25 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Fri, 24 Oct 2014 13:46:25 -0700 (PDT)
In-Reply-To: <1414183153144.407f1f85@Nodemailer>
References: <1414183153144.407f1f85@Nodemailer>
Date: Fri, 24 Oct 2014 13:46:25 -0700
Message-ID: <CABPQxsuyZaPEq53gntrUd5O5SeyYjmhpAo3uiCSYHz-34A-eFQ@mail.gmail.com>
Subject: Re: Moving PR Builder to mvn
From: Patrick Wendell <pwendell@gmail.com>
To: Hari Shreedharan <hshreedharan@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Overall I think this would be a good idea. The main blocker is just
that I think the Maven build is much slower right now than the SBT
build. However, if we were able to e.g. parallelize the test build on
Jenkins that might make up for it.

I'd actually like to have a trigger where we could tests pull requests
with either one.

- Patrick

On Fri, Oct 24, 2014 at 1:39 PM, Hari Shreedharan
<hshreedharan@cloudera.com> wrote:
> Over the last few months, it seems like we have selected Maven to be the =
"official" build system for Spark.
>
>
> I realize that removing the sbt build may not be easy, but it might be a =
good idea to start looking into that. We had issues over the past few days =
where mvn builds were fine, while sbt was failing to resolve dependencies w=
hich were test-jars causing compilation of certain tests to fail.
>
>
> As a first step, I am wondering if it might be a good idea to change the =
PR builder to mvn and test PRs consistent with the way we test releases. I =
am not sure how technically feasible it is, but it would be a start to stan=
dardizing on one build system.
>
> Thanks,
> Hari

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9969-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:52:04 2014
Return-Path: <dev-return-9969-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E4830175E4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:52:03 +0000 (UTC)
Received: (qmail 62895 invoked by uid 500); 24 Oct 2014 20:52:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62819 invoked by uid 500); 24 Oct 2014 20:52:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62807 invoked by uid 99); 24 Oct 2014 20:52:02 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:52:02 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.43 as permitted sender)
Received: from [209.85.218.43] (HELO mail-oi0-f43.google.com) (209.85.218.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:51:36 +0000
Received: by mail-oi0-f43.google.com with SMTP id u20so924347oif.2
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:50:05 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=+RtqFUvRX+1bUZSPeGxHXIVAAHxAffrVhySBrU64YsY=;
        b=f3RGUipbBlK0P96+0qnQkQjonw4v/CMLuhw5adUvUD+PGm7nfDMEscYfJLigH5QzZv
         HzZiKv1UgqHhJU4j9buRCz/7D/6Wyr8g5akePeGztHfeUEUVDI8ikJvZerfgJDn+b7XP
         LPvRYfU8vTv3y3YHgn3V7b50QGdIp2X34UiZm6jSAZkhmSY+5wm2s897eX7h+UY0AErj
         asUYE7p8ls+7q0SwYsIE0qNW8QS9vCVH/JOnm4e8upd9qnLrCiuy7u5+yF5GSXZOSttU
         rcNd4VHl2SxVD98lFjoV5odDRoUuVrYQLGZWNIXwdJ0vn+ovDHaFWmSDzgG+sA6sFQpy
         x/aQ==
MIME-Version: 1.0
X-Received: by 10.60.80.231 with SMTP id u7mr5611298oex.27.1414183805147; Fri,
 24 Oct 2014 13:50:05 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Fri, 24 Oct 2014 13:50:05 -0700 (PDT)
In-Reply-To: <CACdU-dR76VBkhUJ6k_UC8hR-oq3QmCoX-eqiE7tOVv8MR_gqWg@mail.gmail.com>
References: <CACdU-dR76VBkhUJ6k_UC8hR-oq3QmCoX-eqiE7tOVv8MR_gqWg@mail.gmail.com>
Date: Fri, 24 Oct 2014 13:50:05 -0700
Message-ID: <CABPQxssj+6VJF8y0Z5gb3junrK2LvN6ce2aHvywbgE5BLDX65w@mail.gmail.com>
Subject: Re: your weekly git timeout update! TL;DR: i'm now almost certain
 we're not hitting rate limits.
From: Patrick Wendell <pwendell@gmail.com>
To: amp-infra@googlegroups.com
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Thanks for the update Shane.

As a point of process, for things like this where we re debugging
specific issues - can we use JIRA instead of notifying everyone on the
spark-dev list?

I'd prefer if ops/infra announcements on the dev list are restricted
to things that are widely applicable to developers (e.g. planned or
unplanned maintenance on jenkins), since this last has hundreds of
people on it.

- Patrick

On Fri, Oct 24, 2014 at 1:32 PM, shane knapp <sknapp@berkeley.edu> wrote:
> so, things look like they've stabilized significantly over the past 10 days,
> and without any changes on our end:
> <snip>
> $ /root/tools/get_timeouts.sh 10
> timeouts by date:
> 2014-10-14 -- 2
> 2014-10-16 -- 1
> 2014-10-19 -- 1
> 2014-10-20 -- 2
> 2014-10-23 -- 5
>
> timeouts by project:
>       5 NewSparkPullRequestBuilder
>       5 SparkPullRequestBuilder
>       1 Tachyon-Pull-Request-Builder
> total builds (excepting aborted by a user):
> 602
>
> total percentage of builds timing out:
> 01
> </snip>
>
> the NewSparkPullRequestBuilder failures are spread over five different days
> (10-14 through 10-20), and the SparkPullRequestBuilder failures all happened
> yesterday.  there were a LOT of SparkPullRequestBuilder builds yesterday
> (60), and the failures happened during these hours (first number == number
> of builds failed, second number == hour of the day):
> <snip>
> $ cat timeouts-102414-130817 | grep SparkPullRequestBuilder | grep
> 2014-10-23 | awk '{print$3}' | awk -F":" '{print$1'} | sort | uniq -c
>       1 03
>       2 20
>       1 22
>       1 23
> </snip>
>
> however, the number of total SparkPullRequestBuilder builds during these
> times don't seem egregious:
> <snip>
>       4 03
>       9 20
>       4 22
>       9 23
> </snip>
>
> nor does the total for ALL builds at those times:
> <snip>
>       5 03
>       9 20
>       7 22
>      11 23
> </snip>
>
> 9 builds was the largest number of SparkPullRequestBuilder builds per hour,
> but there were other hours with 5, 6 or 7 builds/hour that didn't have a
> timeout issue.
>
> in fact, hour 16 (4pm) had the most builds running total yesterday, which
> includes 7 SparkPullRequestBuilder builds, and nothing timed out.
>
> most of the pull request builder hits on github are authenticated w/an oauth
> token.  this gives us 5000 hits/hour, and unauthed gives us 60/hour.
>
> in conclusion:  there is no way are we hitting github often enough to be
> rate limited.  i think i've finally ruled that out completely.  :)
>
> --
> You received this message because you are subscribed to the Google Groups
> "amp-infra" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to amp-infra+unsubscribe@googlegroups.com.
> For more options, visit https://groups.google.com/d/optout.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9970-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 20:55:42 2014
Return-Path: <dev-return-9970-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E478617616
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 20:55:41 +0000 (UTC)
Received: (qmail 71578 invoked by uid 500); 24 Oct 2014 20:55:39 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 71510 invoked by uid 500); 24 Oct 2014 20:55:39 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 71499 invoked by uid 99); 24 Oct 2014 20:55:38 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:55:38 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hshreedharan@cloudera.com designates 209.85.216.52 as permitted sender)
Received: from [209.85.216.52] (HELO mail-qa0-f52.google.com) (209.85.216.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 20:55:12 +0000
Received: by mail-qa0-f52.google.com with SMTP id v10so1538693qac.11
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 13:55:11 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:date:mime-version:message-id:in-reply-to
         :references:from:to:cc:subject:content-type;
        bh=M9Wj4Uer+1B9HiuBIGMi7udJMB0I9mbvoCMtSTGtWSI=;
        b=brCXLI7wJMxJ6GChLtddQQIHhCnNJ8D9g74eCHO1T+Jv+yh7SKUUaM+OP90439uOnX
         tOEYJyFEbAky2l5EV3HbgjELbN4zniZyr7N1vsukKE57P0Htst6nQzdgtGm21v9fOss2
         GZ4RtjGz2zJBHkSuLdJtqizWXB9nx7xBuJcb3141/SbMtNHjmvtBbDmunxuMqcJyi0gt
         Z/vqz+F64Tm/kLDhYwwPX1SWosFZFSgZhAGy2CCBjGamO3iJ+7hHn8qd1z0BOz5gEN6T
         m6FVcp+6PVlITRffn9XPaMYsnsHLBNEUzCPnuKqxPey7KMPVZynSHaHvF1JtmS/MW/u8
         R86A==
X-Gm-Message-State: ALoCoQlbu/mtP5+yZqnTSKFVy2mbqUXlro1tyxzIo1GtzjDNf1Az4GULz20/+vMn5p0v4vfNYAi/
X-Received: by 10.140.87.67 with SMTP id q61mr9351181qgd.92.1414184111421;
        Fri, 24 Oct 2014 13:55:11 -0700 (PDT)
Received: from hedwig-6.prd.orcali.com (ec2-54-85-253-252.compute-1.amazonaws.com. [54.85.253.252])
        by mx.google.com with ESMTPSA id j2sm5087866qab.39.2014.10.24.13.55.10
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 24 Oct 2014 13:55:10 -0700 (PDT)
Date: Fri, 24 Oct 2014 13:55:10 -0700 (PDT)
X-Google-Original-Date: Fri, 24 Oct 2014 20:55:10 GMT
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Message-Id: <1414184110567.f539e75b@Nodemailer>
In-Reply-To: <CABPQxsuyZaPEq53gntrUd5O5SeyYjmhpAo3uiCSYHz-34A-eFQ@mail.gmail.com>
References: <CABPQxsuyZaPEq53gntrUd5O5SeyYjmhpAo3uiCSYHz-34A-eFQ@mail.gmail.com>
X-Orchestra-Oid: AA322405-36A2-4554-892E-FAED527BDBA9
X-Orchestra-Sig: da62211b380a1d06f19d57a265d8812ec58d79d6
X-Orchestra-Thrid: 50FE6937-3491-4FA4-8FDD-8B267CBDF487
X-Orchestra-Thrid-Sig: 650c0854feeca515d9dcee7edfde7a33f71cfb42
X-Orchestra-Account: 665d186881ca3da77035b387a5c30438f48a7cbc
From: "Hari Shreedharan" <hshreedharan@cloudera.com>
To: "Patrick Wendell" <pwendell@gmail.com>
Cc: dev@spark.apache.org
Subject: Re: Moving PR Builder to mvn
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1414184110931"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1414184110931
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

I have zinc server running on my mac, and I see maven compilation to be =
much better than before I had it running. Is the sbt build still faster =
(sorry, long time since I did a build with sbt).


Thanks,
Hari

On Fri, Oct 24, 2014 at 1:46 PM, Patrick Wendell <pwendell@gmail.com>
wrote:

> Overall I think this would be a good idea. The main blocker is just
> that I think the Maven build is much slower right now than the SBT
> build. However, if we were able to e.g. parallelize the test build on
> Jenkins that might make up for it.
> I'd actually like to have a trigger where we could tests pull requests
> with either one.
> - Patrick
> On Fri, Oct 24, 2014 at 1:39 PM, Hari Shreedharan
> <hshreedharan@cloudera.com> wrote:
>> Over the last few months, it seems like we have selected Maven to be the=
 =22official=22 build system for Spark.
>>
>>
>> I realize that removing the sbt build may not be easy, but it might be a=
 good idea to start looking into that. We had issues over the past few days=
 where mvn builds were fine, while sbt was failing to resolve dependencies =
which were test-jars causing compilation of certain tests to fail.
>>
>>
>> As a first step, I am wondering if it might be a good idea to change the=
 PR builder to mvn and test PRs consistent with the way we test releases. I=
 am not sure how technically feasible it is, but it would be a start to =
standardizing on one build system.
>>
>> Thanks,
>> Hari
------Nodemailer-0.5.0-?=_1-1414184110931--

From dev-return-9971-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 21:07:52 2014
Return-Path: <dev-return-9971-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DDC9A17686
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 21:07:51 +0000 (UTC)
Received: (qmail 98167 invoked by uid 500); 24 Oct 2014 21:07:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98097 invoked by uid 500); 24 Oct 2014 21:07:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98084 invoked by uid 99); 24 Oct 2014 21:07:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 21:07:50 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.218.45 as permitted sender)
Received: from [209.85.218.45] (HELO mail-oi0-f45.google.com) (209.85.218.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 21:07:46 +0000
Received: by mail-oi0-f45.google.com with SMTP id i138so947874oig.32
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 14:06:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=K+a9AilmE087udi56I4/IpxGgwv1y5lxLhO6QLnk1II=;
        b=WAjg0bPxfK2NCe8I6UZWMmU2NQE+4M98JlEwCaN18F8eD/40o5ze/37KH0SMSRfPHJ
         Jq0DKnGzNTNgQfDdTcurb0VEds/cDR6CzHTm+N3li9jMB/xaVOwlTGwPyucJCiXPlbTk
         YCoQwZlE6dTj8Sxw1Hwn+lF4nf5mCIgD6Rdq9DW8cbl0x3guhzTppNwkUPST656zGdU1
         1LisWnWtZlhri9YJz25ILYf95b4K7oN11OFHfxTle1T62AoO5N2AwDnGnOqpESRwcwYd
         5Y+X2e9etIk977rCfrG9KijqweknXwSBax70Rwbbr03zZN4oYKKZQZKBGct5S+fiXiNN
         QAqA==
MIME-Version: 1.0
X-Received: by 10.202.205.147 with SMTP id d141mr3228314oig.67.1414184800779;
 Fri, 24 Oct 2014 14:06:40 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Fri, 24 Oct 2014 14:06:40 -0700 (PDT)
In-Reply-To: <1414184110567.f539e75b@Nodemailer>
References: <CABPQxsuyZaPEq53gntrUd5O5SeyYjmhpAo3uiCSYHz-34A-eFQ@mail.gmail.com>
	<1414184110567.f539e75b@Nodemailer>
Date: Fri, 24 Oct 2014 14:06:40 -0700
Message-ID: <CABPQxsvd+3QVxosA6dMEqHeNy=Fd++a5Z-87CT+Nu84pd=qr-Q@mail.gmail.com>
Subject: Re: Moving PR Builder to mvn
From: Patrick Wendell <pwendell@gmail.com>
To: Hari Shreedharan <hshreedharan@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Does Zinc still help if you are just running a single totally fresh
build? For the pull request builder we purge all state from previous
builds.

- Patrick

On Fri, Oct 24, 2014 at 1:55 PM, Hari Shreedharan
<hshreedharan@cloudera.com> wrote:
> I have zinc server running on my mac, and I see maven compilation to be much
> better than before I had it running. Is the sbt build still faster (sorry,
> long time since I did a build with sbt).
>
> Thanks,
> Hari
>
>
> On Fri, Oct 24, 2014 at 1:46 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>>
>> Overall I think this would be a good idea. The main blocker is just
>> that I think the Maven build is much slower right now than the SBT
>> build. However, if we were able to e.g. parallelize the test build on
>> Jenkins that might make up for it.
>>
>> I'd actually like to have a trigger where we could tests pull requests
>> with either one.
>>
>> - Patrick
>>
>> On Fri, Oct 24, 2014 at 1:39 PM, Hari Shreedharan
>> <hshreedharan@cloudera.com> wrote:
>> > Over the last few months, it seems like we have selected Maven to be the
>> > "official" build system for Spark.
>> >
>> >
>> > I realize that removing the sbt build may not be easy, but it might be a
>> > good idea to start looking into that. We had issues over the past few days
>> > where mvn builds were fine, while sbt was failing to resolve dependencies
>> > which were test-jars causing compilation of certain tests to fail.
>> >
>> >
>> > As a first step, I am wondering if it might be a good idea to change the
>> > PR builder to mvn and test PRs consistent with the way we test releases. I
>> > am not sure how technically feasible it is, but it would be a start to
>> > standardizing on one build system.
>> >
>> > Thanks,
>> > Hari
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9972-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 21:36:10 2014
Return-Path: <dev-return-9972-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 25424177E7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 21:36:10 +0000 (UTC)
Received: (qmail 73468 invoked by uid 500); 24 Oct 2014 21:36:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73374 invoked by uid 500); 24 Oct 2014 21:36:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73362 invoked by uid 99); 24 Oct 2014 21:36:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 21:36:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of hshreedharan@cloudera.com designates 209.85.216.50 as permitted sender)
Received: from [209.85.216.50] (HELO mail-qa0-f50.google.com) (209.85.216.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 21:35:42 +0000
Received: by mail-qa0-f50.google.com with SMTP id cs9so1549969qab.37
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 14:35:41 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:date:mime-version:message-id:in-reply-to
         :references:from:to:cc:subject:content-type;
        bh=IYF91i/tkTgoqbsqKUOf7ENfQNvJCxf80LCN2foLFZ0=;
        b=Y1dEZhuCO6cvnuyowmRQ5OWQp7Fq7vA60p7SqTHcgVY30CQ3sfYG7qZo2jXww5qczR
         FJDOYjE0aCaFgg3hR2UnEDN/fq2vO0I0XucPQ/bVBI6ueWkQCkUOFYnwavRBX+MoMSaJ
         aZdMz+UltcNWSd0po7gZcuj0Ps5VTUi75Lzs6OodLXgzLvG7WCyMYRb8mS4eU7TAFpUB
         aGiPm9nesZ4GUap1unRG5B288xtAtl9NXZyUp6ctrb5kSDsxCFb/Ojqqtjr3dj94PXlB
         9Q9LSqrXredk4ZqFlGK1mFnLDwT3e/7V9YTgq0ZuDv+UFvxZo9GX4oyShqvY8nBY5m0H
         pfMA==
X-Gm-Message-State: ALoCoQnfNBZsoqnOdyJZo+cifhZfD02rtXHqOu8tq9k7os1V3dPSE5zYF5uJNE7/CM6kth3RgZzP
X-Received: by 10.224.125.68 with SMTP id x4mr10310681qar.78.1414186537705;
        Fri, 24 Oct 2014 14:35:37 -0700 (PDT)
Received: from hedwig-6.prd.orcali.com (ec2-54-85-253-252.compute-1.amazonaws.com. [54.85.253.252])
        by mx.google.com with ESMTPSA id b59sm5112442qga.45.2014.10.24.14.35.36
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Fri, 24 Oct 2014 14:35:37 -0700 (PDT)
Date: Fri, 24 Oct 2014 14:35:37 -0700 (PDT)
X-Google-Original-Date: Fri, 24 Oct 2014 21:35:36 GMT
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Message-Id: <1414186536796.7f819a4e@Nodemailer>
In-Reply-To: <CACkSZy1P9vh2uD=n18XKxQWniAKiJkw1fbY+ridMD5mi-DJKpw@mail.gmail.com>
References: <CACkSZy1P9vh2uD=n18XKxQWniAKiJkw1fbY+ridMD5mi-DJKpw@mail.gmail.com>
X-Orchestra-Oid: DCDCB0B3-14C7-43DD-AAB5-9B7E00574DDF
X-Orchestra-Sig: 567063e4e45ec5a7cc8bce771ce329f5f6d79324
X-Orchestra-Thrid: 50FE6937-3491-4FA4-8FDD-8B267CBDF487
X-Orchestra-Thrid-Sig: 650c0854feeca515d9dcee7edfde7a33f71cfb42
X-Orchestra-Account: 2c5387fee041687b79d0c8424bf0a6ce6e0c73ef
From: "Hari Shreedharan" <hshreedharan@cloudera.com>
To: "Stephen Boesch" <javadba@gmail.com>
Cc: "Patrick Wendell" <pwendell@gmail.com>, dev@spark.apache.org
Subject: Re: Moving PR Builder to mvn
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1414186537189"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1414186537189
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

+1. From what I can see, it definitely does - though I must say I rarely do=
 full end to end builds though. Maybe worth running as an experiment=3F


Thanks,
Hari

On Fri, Oct 24, 2014 at 2:34 PM, Stephen Boesch <javadba@gmail.com> wrote:

> Zinc absolutely helps - feels like makes builds  more than twice as fast =
-
> both on Mac and Linux.   It helps both on fresh and existing builds.
> 2014-10-24 14:06 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>> Does Zinc still help if you are just running a single totally fresh
>> build=3F For the pull request builder we purge all state from previous
>> builds.
>>
>> - Patrick
>>
>> On Fri, Oct 24, 2014 at 1:55 PM, Hari Shreedharan
>> <hshreedharan@cloudera.com> wrote:
>> > I have zinc server running on my mac, and I see maven compilation to =
be
>> much
>> > better than before I had it running. Is the sbt build still faster
>> (sorry,
>> > long time since I did a build with sbt).
>> >
>> > Thanks,
>> > Hari
>> >
>> >
>> > On Fri, Oct 24, 2014 at 1:46 PM, Patrick Wendell <pwendell@gmail.com>
>> wrote:
>> >>
>> >> Overall I think this would be a good idea. The main blocker is just
>> >> that I think the Maven build is much slower right now than the SBT
>> >> build. However, if we were able to e.g. parallelize the test build =
on
>> >> Jenkins that might make up for it.
>> >>
>> >> I'd actually like to have a trigger where we could tests pull =
requests
>> >> with either one.
>> >>
>> >> - Patrick
>> >>
>> >> On Fri, Oct 24, 2014 at 1:39 PM, Hari Shreedharan
>> >> <hshreedharan@cloudera.com> wrote:
>> >> > Over the last few months, it seems like we have selected Maven to =
be
>> the
>> >> > =22official=22 build system for Spark.
>> >> >
>> >> >
>> >> > I realize that removing the sbt build may not be easy, but it =
might
>> be a
>> >> > good idea to start looking into that. We had issues over the past =
few
>> days
>> >> > where mvn builds were fine, while sbt was failing to resolve
>> dependencies
>> >> > which were test-jars causing compilation of certain tests to fail.
>> >> >
>> >> >
>> >> > As a first step, I am wondering if it might be a good idea to =
change
>> the
>> >> > PR builder to mvn and test PRs consistent with the way we test
>> releases. I
>> >> > am not sure how technically feasible it is, but it would be a start=
 to
>> >> > standardizing on one build system.
>> >> >
>> >> > Thanks,
>> >> > Hari
>> >
>> >
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>>
------Nodemailer-0.5.0-?=_1-1414186537189--

From dev-return-9973-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 21:37:08 2014
Return-Path: <dev-return-9973-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 99624177EF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 21:37:08 +0000 (UTC)
Received: (qmail 77822 invoked by uid 500); 24 Oct 2014 21:37:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77750 invoked by uid 500); 24 Oct 2014 21:37:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77543 invoked by uid 99); 24 Oct 2014 21:37:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 21:37:07 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of javadba@gmail.com designates 209.85.220.181 as permitted sender)
Received: from [209.85.220.181] (HELO mail-vc0-f181.google.com) (209.85.220.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 21:36:41 +0000
Received: by mail-vc0-f181.google.com with SMTP id le20so755241vcb.12
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 14:34:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=HYPzPtE1XhV0gaifDwucWcaih9iGKqQacPkmWApflPY=;
        b=osVX+WBxojGidKGrIBl69bdo3qsgYBbmSUl7mJ0inj3Hiw1ytHQ9vXEtv5oE8oexds
         0jAKOT95E8LZb29vubKycXljdoB9XhtkHujeI8xVHHRxW67k/MwgsWjxFyVwBhZsY/Rd
         Oo2w91s0AyUphvZccpYOMFM7sY96V1mmYvitwqEG2cz/rJhVOJRjOq7VXrG1DmtZMXdr
         gVTxJtN2s4fD1Hfy5QtCeK1/7GP9nxg8L22Lx74J7O/Hnqz+JAcFxShr6EcnwzQlgMGX
         V20lQ1c7hXJrMx5MaXkYFTQY1A67Q1mqczYlw2fBGVxDUzc6PbwtrnCmd9pgFL0e5mFZ
         OtzA==
MIME-Version: 1.0
X-Received: by 10.221.67.137 with SMTP id xu9mr4591261vcb.11.1414186465241;
 Fri, 24 Oct 2014 14:34:25 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Fri, 24 Oct 2014 14:34:25 -0700 (PDT)
In-Reply-To: <CABPQxsvd+3QVxosA6dMEqHeNy=Fd++a5Z-87CT+Nu84pd=qr-Q@mail.gmail.com>
References: <CABPQxsuyZaPEq53gntrUd5O5SeyYjmhpAo3uiCSYHz-34A-eFQ@mail.gmail.com>
	<1414184110567.f539e75b@Nodemailer>
	<CABPQxsvd+3QVxosA6dMEqHeNy=Fd++a5Z-87CT+Nu84pd=qr-Q@mail.gmail.com>
Date: Fri, 24 Oct 2014 14:34:25 -0700
Message-ID: <CACkSZy1P9vh2uD=n18XKxQWniAKiJkw1fbY+ridMD5mi-DJKpw@mail.gmail.com>
Subject: Re: Moving PR Builder to mvn
From: Stephen Boesch <javadba@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Hari Shreedharan <hshreedharan@cloudera.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113397b0e83237050631f1c2
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113397b0e83237050631f1c2
Content-Type: text/plain; charset=UTF-8

Zinc absolutely helps - feels like makes builds  more than twice as fast -
both on Mac and Linux.   It helps both on fresh and existing builds.

2014-10-24 14:06 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:

> Does Zinc still help if you are just running a single totally fresh
> build? For the pull request builder we purge all state from previous
> builds.
>
> - Patrick
>
> On Fri, Oct 24, 2014 at 1:55 PM, Hari Shreedharan
> <hshreedharan@cloudera.com> wrote:
> > I have zinc server running on my mac, and I see maven compilation to be
> much
> > better than before I had it running. Is the sbt build still faster
> (sorry,
> > long time since I did a build with sbt).
> >
> > Thanks,
> > Hari
> >
> >
> > On Fri, Oct 24, 2014 at 1:46 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >>
> >> Overall I think this would be a good idea. The main blocker is just
> >> that I think the Maven build is much slower right now than the SBT
> >> build. However, if we were able to e.g. parallelize the test build on
> >> Jenkins that might make up for it.
> >>
> >> I'd actually like to have a trigger where we could tests pull requests
> >> with either one.
> >>
> >> - Patrick
> >>
> >> On Fri, Oct 24, 2014 at 1:39 PM, Hari Shreedharan
> >> <hshreedharan@cloudera.com> wrote:
> >> > Over the last few months, it seems like we have selected Maven to be
> the
> >> > "official" build system for Spark.
> >> >
> >> >
> >> > I realize that removing the sbt build may not be easy, but it might
> be a
> >> > good idea to start looking into that. We had issues over the past few
> days
> >> > where mvn builds were fine, while sbt was failing to resolve
> dependencies
> >> > which were test-jars causing compilation of certain tests to fail.
> >> >
> >> >
> >> > As a first step, I am wondering if it might be a good idea to change
> the
> >> > PR builder to mvn and test PRs consistent with the way we test
> releases. I
> >> > am not sure how technically feasible it is, but it would be a start to
> >> > standardizing on one build system.
> >> >
> >> > Thanks,
> >> > Hari
> >
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113397b0e83237050631f1c2--

From dev-return-9974-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 21:40:38 2014
Return-Path: <dev-return-9974-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C40B217825
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 21:40:38 +0000 (UTC)
Received: (qmail 90187 invoked by uid 500); 24 Oct 2014 21:40:38 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90126 invoked by uid 500); 24 Oct 2014 21:40:38 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90112 invoked by uid 99); 24 Oct 2014 21:40:37 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 21:40:37 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of malouf.gary@gmail.com designates 209.85.192.44 as permitted sender)
Received: from [209.85.192.44] (HELO mail-qg0-f44.google.com) (209.85.192.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 21:40:33 +0000
Received: by mail-qg0-f44.google.com with SMTP id j5so1686470qga.3
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 14:40:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=lQkw+fkE1g2RdLRGaMUrEx/9/TeqKxyptahIkUy1/go=;
        b=VE+3eCLsgKg1diS3D9474SC1mY6CR4/8g+nrhrsicS9kVY8tPtidsgal1FmXu6XcN0
         IUrgCMAVzXEfygw1Dkh3lJHI2vNNY/34Uyp6DJ3V6UUNDhL20FonZK1Lv7AsaZcVaAep
         1P4TzX/h8GHnh8lvqgCPs2l6iCE2Ni/4/28CkEAF5kGcB1vAgXGgsOTlRj9u0dHDPpLL
         U1Pk35o7cy7rRonC2Wl4qG1ulXY16PIJPTeruiIbOdpLroCk7vyD99lLh+5d0SQHH3Xd
         YnfVnL7dsE9qFpP4IWQzQsQdSOOQCPiAHBvmjL1g76V6V4ROu2yf//XY1lP01kRhfPTm
         Mk3w==
MIME-Version: 1.0
X-Received: by 10.229.244.1 with SMTP id lo1mr10221396qcb.29.1414186812634;
 Fri, 24 Oct 2014 14:40:12 -0700 (PDT)
Received: by 10.140.29.102 with HTTP; Fri, 24 Oct 2014 14:40:12 -0700 (PDT)
In-Reply-To: <CAKWX9VV2j0m2Axsa9OUHB4T0CW7GDZs-Zi3DsyCgqWs-Zc4k8Q@mail.gmail.com>
References: <CAKWX9VWaNzDcHjxFC3XpwSG+bi7Y+bM2z1jo2g2D8kR1aFES6w@mail.gmail.com>
	<CA+-p3AGEW78LtPbDBHvf1qzsV3bYSwtpBQAS04jRkFq5e0rBzw@mail.gmail.com>
	<CAAswR-4-Z7m7z0+Sp1NHhSS1-YNx1vTVn_Kag7-PKuGgn-DwmA@mail.gmail.com>
	<CAKWX9VXu4yv2ubKE3-5o6FYHZh068Fk_0f98Mac8tK4Aw--1-w@mail.gmail.com>
	<CAAswR-5KJhBm8oNgGWjDQCnh+Qq=ZwbtkQM43jsL5CSh-Qzqrg@mail.gmail.com>
	<CAKWX9VV2j0m2Axsa9OUHB4T0CW7GDZs-Zi3DsyCgqWs-Zc4k8Q@mail.gmail.com>
Date: Fri, 24 Oct 2014 17:40:12 -0400
Message-ID: <CAGOvqir9U43N36-RCuW9csCBRZkpoKPXCwp4yhZwSoCokM0HDA@mail.gmail.com>
Subject: Re: Parquet schema migrations
From: Gary Malouf <malouf.gary@gmail.com>
To: Cody Koeninger <cody@koeninger.org>
Cc: Michael Armbrust <michael@databricks.com>, Andrew Ash <andrew@andrewash.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2fbb69cfe0b0506320619
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2fbb69cfe0b0506320619
Content-Type: text/plain; charset=UTF-8

Hi Michael,

Does this affect people who use Hive for their metadata store as well?  I'm
wondering if the issue is as bad as I think it is - namely that if you
build up a year's worth of data, adding a field forces you to have to
migrate that entire year's data.

Gary

On Wed, Oct 8, 2014 at 5:08 PM, Cody Koeninger <cody@koeninger.org> wrote:

> On Wed, Oct 8, 2014 at 3:19 PM, Michael Armbrust <michael@databricks.com>
> wrote:
>
> >
> > I was proposing you manually convert each different format into one
> > unified format  (by adding literal nulls and such for missing columns)
> and
> > then union these converted datasets.  It would be weird to have union all
> > try and do this automatically.
> >
>
>
> Sure, I was just musing on what an api for doing the merging without manual
> user input should look like / do.   I'll comment on the ticket, thanks for
> making it
>

--001a11c2fbb69cfe0b0506320619--

From dev-return-9975-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 24 23:26:22 2014
Return-Path: <dev-return-9975-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 83E3E17B7F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 24 Oct 2014 23:26:22 +0000 (UTC)
Received: (qmail 20279 invoked by uid 500); 24 Oct 2014 23:26:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20210 invoked by uid 500); 24 Oct 2014 23:26:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20192 invoked by uid 99); 24 Oct 2014 23:26:21 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 23:26:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.223.178 as permitted sender)
Received: from [209.85.223.178] (HELO mail-ie0-f178.google.com) (209.85.223.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 24 Oct 2014 23:25:55 +0000
Received: by mail-ie0-f178.google.com with SMTP id rl12so3327208iec.9
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 16:25:09 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=N4OKUs90LZbqHiV2/6DdUCbU4ONd0yOxdcdXSDn2rzw=;
        b=ZnlS7ssUEsghh3HLAnO7gY085r4kNQ/5C1hwdGQQGKBmUpnxeCddpe+zMrBRQSwOUp
         KCOcPn7m13W7EhO+FDINlH26tpOgpJUEHfUdYFS12PpGCEK+/kr9HvWDnskdO8HZf8lR
         0oKJT+/qAWPf/IBnEly1z1B2mCg+UZIlP4W0bUCDicD9xE7bX5doqk9qfAIbBmkr4imo
         hfa2tevVFRgwia8pTH2mQ7rbjTy9yBVQ5WREZzL3uptzj+fzHBOiLB7NkIQ5DPY7pcG8
         e7xvqAB/rcFUWYU1HOIV0xwkCXHbypwEn/taC+RwZ5hVTmJ3ZGAiA5z+kFHQAYUOpU8X
         /GDw==
X-Gm-Message-State: ALoCoQlvS0drZnVdOGZTkxjpi/RvIbHzyxRtGTATl7Iqe8EZ3ZSvsIU+J0t4rK18gx6UIbLRWOJ7
X-Received: by 10.50.43.130 with SMTP id w2mr6868653igl.34.1414193109182; Fri,
 24 Oct 2014 16:25:09 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.12.158 with HTTP; Fri, 24 Oct 2014 16:24:49 -0700 (PDT)
In-Reply-To: <CABPQxsvd+3QVxosA6dMEqHeNy=Fd++a5Z-87CT+Nu84pd=qr-Q@mail.gmail.com>
References: <CABPQxsuyZaPEq53gntrUd5O5SeyYjmhpAo3uiCSYHz-34A-eFQ@mail.gmail.com>
 <1414184110567.f539e75b@Nodemailer> <CABPQxsvd+3QVxosA6dMEqHeNy=Fd++a5Z-87CT+Nu84pd=qr-Q@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Sat, 25 Oct 2014 00:24:49 +0100
Message-ID: <CAMAsSdJYQ=VeePYSDEgt-PrtkMa4jXr4H2B7fOjV5oZZOa_xMA@mail.gmail.com>
Subject: Re: Moving PR Builder to mvn
To: Patrick Wendell <pwendell@gmail.com>
Cc: Hari Shreedharan <hshreedharan@cloudera.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Here's a crude benchmark on a Linux box (GCE n1-standard-4). zinc gets
the assembly build in range of SBT's time.

mvn -DskipTests clean package
15:27
(start zinc)
8:18
(rebuild)
7:08

./sbt/sbt -DskipTests clean assembly
5:10
(start zinc)
5:11
(rebuild)
5:06

The dependencies were already downloaded, and the whole build was
cleaned in between.

These are smallish in comparison with time to run tests. I admit I
didn't run them here in the interest of time and because I assumed
zinc doesn't help that.


On Fri, Oct 24, 2014 at 10:06 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Does Zinc still help if you are just running a single totally fresh
> build? For the pull request builder we purge all state from previous
> builds.
>
> - Patrick
>
> On Fri, Oct 24, 2014 at 1:55 PM, Hari Shreedharan
> <hshreedharan@cloudera.com> wrote:
>> I have zinc server running on my mac, and I see maven compilation to be much
>> better than before I had it running. Is the sbt build still faster (sorry,
>> long time since I did a build with sbt).
>>
>> Thanks,
>> Hari

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9976-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 00:31:48 2014
Return-Path: <dev-return-9976-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 35B3F17D55
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 00:31:48 +0000 (UTC)
Received: (qmail 34923 invoked by uid 500); 25 Oct 2014 00:31:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34854 invoked by uid 500); 25 Oct 2014 00:31:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34842 invoked by uid 99); 25 Oct 2014 00:31:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 00:31:46 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mark@clearstorydata.com designates 74.125.82.45 as permitted sender)
Received: from [74.125.82.45] (HELO mail-wg0-f45.google.com) (74.125.82.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 00:31:42 +0000
Received: by mail-wg0-f45.google.com with SMTP id l18so2087961wgh.28
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 17:30:35 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=JkQqTgBicWjSL/CCTIQ8AWyhbnPhuaTeBj3120vu/bI=;
        b=Yyz/Cl4YIlTG0oTv6Ntu7p165XeroOX9YhO80NShBQLWOweSouw+meE5QzVgvXh0Lw
         fadUcyU8hzGng781NTjfsmNVNs9+lZgxqlGg2yLIlwKjOhq4CX0SKC3PbhKIiwDq+G1Z
         jmmd5gHw7sIyrgR1rpkx6lmnn4tzDd/xsrqx/9h6ZrgMWk5owLqUNOf4WdkJWvdGyOBG
         3Xhj0EaOiHncMWdXMQK+KJiGUePD3cZcdpE23OdlDwi3kLUjKnK/gKFQeUgaIidqLvNy
         yp9gyExxtPmPw2QNR2RjHOVFEmeHg1p5Zj3GMP144EQtDY6gBygxeO+MvM/RIIRSxZFc
         lN5A==
X-Gm-Message-State: ALoCoQlH5jmfCMadWa3q2bOrUd587EzJbuTxEszriDUqt+zcEUj/3XHtC1j7mygAKskKrykDKhc6
MIME-Version: 1.0
X-Received: by 10.194.108.104 with SMTP id hj8mr8225989wjb.28.1414197035187;
 Fri, 24 Oct 2014 17:30:35 -0700 (PDT)
Received: by 10.216.190.130 with HTTP; Fri, 24 Oct 2014 17:30:35 -0700 (PDT)
In-Reply-To: <CAMAsSdJYQ=VeePYSDEgt-PrtkMa4jXr4H2B7fOjV5oZZOa_xMA@mail.gmail.com>
References: <CABPQxsuyZaPEq53gntrUd5O5SeyYjmhpAo3uiCSYHz-34A-eFQ@mail.gmail.com>
	<1414184110567.f539e75b@Nodemailer>
	<CABPQxsvd+3QVxosA6dMEqHeNy=Fd++a5Z-87CT+Nu84pd=qr-Q@mail.gmail.com>
	<CAMAsSdJYQ=VeePYSDEgt-PrtkMa4jXr4H2B7fOjV5oZZOa_xMA@mail.gmail.com>
Date: Fri, 24 Oct 2014 17:30:35 -0700
Message-ID: <CAAsvFP=SUa+7US70OFoYXULvjkcMPc3N8x0TGphag29fVxs8xw@mail.gmail.com>
Subject: Re: Moving PR Builder to mvn
From: Mark Hamstra <mark@clearstorydata.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Patrick Wendell <pwendell@gmail.com>, Hari Shreedharan <hshreedharan@cloudera.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b6d96c4ecd62e05063467d5
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b6d96c4ecd62e05063467d5
Content-Type: text/plain; charset=UTF-8

Your's are in the same ballpark with mine, where maven builds with zinc
take about 1.4x the time to build with SBT.

On Fri, Oct 24, 2014 at 4:24 PM, Sean Owen <sowen@cloudera.com> wrote:

> Here's a crude benchmark on a Linux box (GCE n1-standard-4). zinc gets
> the assembly build in range of SBT's time.
>
> mvn -DskipTests clean package
> 15:27
> (start zinc)
> 8:18
> (rebuild)
> 7:08
>
> ./sbt/sbt -DskipTests clean assembly
> 5:10
> (start zinc)
> 5:11
> (rebuild)
> 5:06
>
> The dependencies were already downloaded, and the whole build was
> cleaned in between.
>
> These are smallish in comparison with time to run tests. I admit I
> didn't run them here in the interest of time and because I assumed
> zinc doesn't help that.
>
>
> On Fri, Oct 24, 2014 at 10:06 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Does Zinc still help if you are just running a single totally fresh
> > build? For the pull request builder we purge all state from previous
> > builds.
> >
> > - Patrick
> >
> > On Fri, Oct 24, 2014 at 1:55 PM, Hari Shreedharan
> > <hshreedharan@cloudera.com> wrote:
> >> I have zinc server running on my mac, and I see maven compilation to be
> much
> >> better than before I had it running. Is the sbt build still faster
> (sorry,
> >> long time since I did a build with sbt).
> >>
> >> Thanks,
> >> Hari
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--047d7b6d96c4ecd62e05063467d5--

From dev-return-9977-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 01:17:27 2014
Return-Path: <dev-return-9977-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A16FB17E55
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 01:17:27 +0000 (UTC)
Received: (qmail 96340 invoked by uid 500); 25 Oct 2014 01:17:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96270 invoked by uid 500); 25 Oct 2014 01:17:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96255 invoked by uid 99); 25 Oct 2014 01:17:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:17:25 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of qiuzhuang.lian@gmail.com designates 209.85.220.181 as permitted sender)
Received: from [209.85.220.181] (HELO mail-vc0-f181.google.com) (209.85.220.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:17:20 +0000
Received: by mail-vc0-f181.google.com with SMTP id le20so850753vcb.40
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 18:16:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=T/akyaHSG6/B8/Ar6TD8xpNFZ/tyqZR/qK8CgLhcya8=;
        b=sDLuplUu06mEklQrrTcxVRm6JkBQm6h0/SalBvPJaWAh3/vYXSi5THStWKV1ZDD1TB
         0hT2ZvybfFDi1qxw5sZ4iAPOaMZZFXEUMvVY8bcTEK4wh6tkzaYP4Pxq5jsxO4XZsI4h
         XNJ+muZcreQYjhBwX16bOBNI1Ym1AFZ0ll4QJoK0RWdQl0Th8TUyY+xeBdBnnIBFmWbt
         9ppSNGicRx3yBQeGC37Q2CL64B2zy75MZiAdGLES9d8yp+7iJU0QzLfEg0kTJmgnZ1nd
         mctmIUkOG3jMNXXYH/3nthd0WBMS7tqVi97IQ3N6z+eoKCVjxL2AY0t1wAvA1RFeq+Xs
         lHXA==
MIME-Version: 1.0
X-Received: by 10.52.114.228 with SMTP id jj4mr85410vdb.46.1414199819046; Fri,
 24 Oct 2014 18:16:59 -0700 (PDT)
Received: by 10.221.7.132 with HTTP; Fri, 24 Oct 2014 18:16:59 -0700 (PDT)
Date: Sat, 25 Oct 2014 09:16:59 +0800
Message-ID: <CABKvOWsH-JqzkVK5RoYXAn7q_jOQ3m7iy+7MYCOmTXgjo+i7pw@mail.gmail.com>
Subject: serialVersionUID incompatible error in class BlockManagerId
From: Qiuzhuang Lian <qiuzhuang.lian@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=bcaec5485a14db20700506350de9
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec5485a14db20700506350de9
Content-Type: text/plain; charset=UTF-8

Hi,

I update git today and when connecting to spark cluster, I got
the serialVersionUID incompatible error in class BlockManagerId.

Here is  the log,

Shouldn't we better give BlockManagerId a constant serialVersionUID  avoid
this?

Thanks,
Qiuzhuang

scala> val rdd = sc.parparallelize(1 to 100014/10/25 09:10:48 ERROR
Remoting: org.apache.spark.storage.BlockManagerId; local class
incompatible: stream classdesc serialVersionUID = 2439208141545036836,
local class serialVersionUID = 4657685702603429489
java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
local class incompatible: stream classdesc serialVersionUID =
2439208141545036836, local class serialVersionUID = 4657685702603429489
        at
java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
        at
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
        at
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        at
java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        at
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        at
akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
        at
akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
        at
akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serialization.scala:104)
        at scala.util.Try$.apply(Try.scala:161)
        at
akka.serialization.Serialization.deserialize(Serialization.scala:98)
        at
akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
        at
akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:58)
        at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
        at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
        at
akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:937)
        at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
        at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
        at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
        at akka.actor.ActorCell.invoke(ActorCell.scala:487)
        at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
        at akka.dispatch.Mailbox.run(Mailbox.scala:220)
        at
akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
        at
scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at
scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at
scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at
scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
14/10/25 09:10:48 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 1
0014/10/25 09:11:21 ERROR Remoting:
org.apache.spark.storage.BlockManagerId; local class incompatible: stream
classdesc serialVersionUID = 2439208141545036836, local class
serialVersionUID = 4657685702603429489
java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
local class incompatible: stream classdesc serialVersionUID =
2439208141545036836, local class serialVersionUID = 4657685702603429489
        at
java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
        at
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
        at
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        at
java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        at
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        at
akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
        at
akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
        at
akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serialization.scala:104)
        at scala.util.Try$.apply(Try.scala:161)
        at
akka.serialization.Serialization.deserialize(Serialization.scala:98)
        at
akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
        at
akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:58)
        at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
        at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
        at
akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:937)
        at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
        at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
        at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
        at akka.actor.ActorCell.invoke(ActorCell.scala:487)
        at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
        at akka.dispatch.Mailbox.run(Mailbox.scala:220)
        at
akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
        at
scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at
scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at
scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at
scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
14/10/25 09:11:21 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 1
14/10/25 09:11:54 INFO SparkDeploySchedulerBackend: Registered executor:
Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006/user/Executor#-1410691203]
with ID 1
14/10/25 09:11:54 INFO DAGScheduler: Host added was in lost list earlier:
DEV-02.SpringB.GZ
14/10/25 09:11:55 ERROR TaskSchedulerImpl: Lost executor 1 on
DEV-02.SpringB.GZ: remote Akka client disassociated
14/10/25 09:11:55 WARN ReliableDeliverySupervisor: Association with remote
system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006] has failed,
address is now gated for [5000] ms. Reason is: [Association failed with
[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006]].
14/10/25 09:11:55 INFO DAGScheduler: Executor lost: 1 (epoch 1)
14/10/25 09:11:55 INFO BlockManagerMasterActor: Trying to remove executor 1
from BlockManagerMaster.
14/10/25 09:11:55 INFO BlockManagerMaster: Removed 1 successfully in
removeExecutor
14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 1
14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 1
14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
app-20141025091012-0002/1 is now EXITED (Command exited with code 1)
14/10/25 09:11:55 INFO SparkDeploySchedulerBackend: Executor
app-20141025091012-0002/1 removed: Command exited with code 1
14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 1
14/10/25 09:11:55 INFO AppClient$ClientActor: Executor added:
app-20141025091012-0002/3 on worker-20141025170311-DEV-02.SpringB.GZ-35162
(DEV-02.SpringB.GZ:35162) with 2 cores
14/10/25 09:11:55 INFO SparkDeploySchedulerBackend: Granted executor ID
app-20141025091012-0002/3 on hostPort DEV-02.SpringB.GZ:35162 with 2 cores,
512.0 MB RAM
14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
app-20141025091012-0002/3 is now LOADING
14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
app-20141025091012-0002/3 is now RUNNING
14/10/25 09:11:58 INFO SparkDeploySchedulerBackend: Registered executor:
Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50740/user/Executor#1229699385]
with ID 3
14/10/25 09:11:58 WARN ReliableDeliverySupervisor: Association with remote
system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50740] has failed,
address is now gated for [5000] ms. Reason is:
[org.apache.spark.storage.BlockManagerId; local class incompatible: stream
classdesc serialVersionUID = 2439208141545036836, local class
serialVersionUID = 4657685702603429489].
14/10/25 09:11:58 ERROR TaskSchedulerImpl: Lost executor 3 on
DEV-02.SpringB.GZ: remote Akka client disassociated
14/10/25 09:11:58 INFO DAGScheduler: Executor lost: 3 (epoch 2)
14/10/25 09:11:58 INFO BlockManagerMasterActor: Trying to remove executor 3
from BlockManagerMaster.
14/10/25 09:11:58 INFO BlockManagerMaster: Removed 3 successfully in
removeExecutor
14/10/25 09:12:31 ERROR Remoting: org.apache.spark.storage.BlockManagerId;
local class incompatible: stream classdesc serialVersionUID =
2439208141545036836, local class serialVersionUID = 4657685702603429489
java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
local class incompatible: stream classdesc serialVersionUID =
2439208141545036836, local class serialVersionUID = 4657685702603429489
        at
java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
        at
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
        at
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        at
java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        at
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        at
akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
        at
akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
        at
akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serialization.scala:104)
        at scala.util.Try$.apply(Try.scala:161)
        at
akka.serialization.Serialization.deserialize(Serialization.scala:98)
        at
akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
        at
akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:58)
        at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
        at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
        at
akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:937)
        at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
        at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
        at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
        at akka.actor.ActorCell.invoke(ActorCell.scala:487)
        at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
        at akka.dispatch.Mailbox.run(Mailbox.scala:220)
        at
akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
        at
scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at
scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at
scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at
scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
14/10/25 09:12:31 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 3
14/10/25 09:13:04 ERROR Remoting: org.apache.spark.storage.BlockManagerId;
local class incompatible: stream classdesc serialVersionUID =
2439208141545036836, local class serialVersionUID = 4657685702603429489
java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
local class incompatible: stream classdesc serialVersionUID =
2439208141545036836, local class serialVersionUID = 4657685702603429489
        at
java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
        at
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
        at
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        at
java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        at
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        at
akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
        at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
        at
akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
        at
akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serialization.scala:104)
        at scala.util.Try$.apply(Try.scala:161)
        at
akka.serialization.Serialization.deserialize(Serialization.scala:98)
        at
akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
        at
akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:58)
        at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
        at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
        at
akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:937)
        at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
        at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
        at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
        at akka.actor.ActorCell.invoke(ActorCell.scala:487)
        at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
        at akka.dispatch.Mailbox.run(Mailbox.scala:220)
        at
akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
        at
scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at
scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at
scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at
scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
14/10/25 09:13:04 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 3
14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 3
14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 3
14/10/25 09:13:37 INFO AppClient$ClientActor: Executor updated:
app-20141025091012-0002/3 is now EXITED (Command exited with code 1)
14/10/25 09:13:37 INFO SparkDeploySchedulerBackend: Executor
app-20141025091012-0002/3 removed: Command exited with code 1
14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
existant executor 3
14/10/25 09:13:37 INFO AppClient$ClientActor: Executor added:
app-20141025091012-0002/4 on worker-20141025170311-DEV-02.SpringB.GZ-35162
(DEV-02.SpringB.GZ:35162) with 2 cores
14/10/25 09:13:37 INFO SparkDeploySchedulerBackend: Granted executor ID
app-20141025091012-0002/4 on hostPort DEV-02.SpringB.GZ:35162 with 2 cores,
512.0 MB RAM
14/10/25 09:13:37 INFO AppClient$ClientActor: Executor updated:
app-20141025091012-0002/4 is now LOADING
14/10/25 09:13:38 INFO AppClient$ClientActor: Executor updated:
app-20141025091012-0002/4 is now RUNNING
14/10/25 09:13:40 INFO SparkDeploySchedulerBackend: Registered executor:
Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:56019/user/Executor#1354626597]
with ID 4
14/10/25 09:13:40 WARN ReliableDeliverySupervisor: Association with remote
system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:56019] has failed,
address is now gated for [5000] ms. Reason is:
[org.apache.spark.storage.BlockManagerId; local class incompatible: stream
classdesc serialVersionUID = 2439208141545036836, local class
serialVersionUID = 4657685702603429489].
14/10/25 09:13:40 ERROR TaskSchedulerImpl: Lost executor 4 on
DEV-02.SpringB.GZ: remote Akka client disassociated
14/10/25 09:13:40 INFO DAGScheduler: Executor lost: 4 (epoch 3)
14/10/25 09:13:40 INFO BlockManagerMasterActor: Trying to remove executor 4
from BlockManagerMaster.
14/10/25 09:13:40 INFO BlockManagerMaster: Removed 4 successfully in
removeExecutor

--bcaec5485a14db20700506350de9--

From dev-return-9978-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 01:23:37 2014
Return-Path: <dev-return-9978-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 08C2E17E77
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 01:23:37 +0000 (UTC)
Received: (qmail 2953 invoked by uid 500); 25 Oct 2014 01:23:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2886 invoked by uid 500); 25 Oct 2014 01:23:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2871 invoked by uid 99); 25 Oct 2014 01:23:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:23:35 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rosenville@gmail.com designates 209.85.220.43 as permitted sender)
Received: from [209.85.220.43] (HELO mail-pa0-f43.google.com) (209.85.220.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:23:28 +0000
Received: by mail-pa0-f43.google.com with SMTP id eu11so2089584pac.30
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 18:23:08 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:message-id:in-reply-to:references:subject:mime-version
         :content-type;
        bh=iS2IghKnLvJBnQmlazojBjNB9QX1CnkM+V8Pm8BhjRI=;
        b=R2zlxtfC0LJBKfy/AVRb+jB99Kl5PEu8O0gC1Op24YW4fqFmzP06jnlHbmKlb6WaOI
         0J+N7BbdjdnKT05b+It3Fr9vOR1b/aABEzY1Dpe5NrBFEhbNNmMwuXSvlaOIm+Mr1oxK
         yxuzsDnYjm1KksQMADqpu4KpRiuNh5m+V7662+EgEYtrjEpRCl/qCbwwMhEW2erPqxVX
         1fbgZiTla/dmfSsZkunLOqLijNi/+axHoK7nNDKj97lvuyiJ4Y+mzQfUdzY/x/U4O8L+
         D1TJQPAW0ouKNHLF5bAB35eDPMoxePM4waMtkQipuYOCp2VjmR0TqQ23imwnrsAnn4N0
         UowQ==
X-Received: by 10.70.54.74 with SMTP id h10mr8302517pdp.50.1414200188210;
        Fri, 24 Oct 2014 18:23:08 -0700 (PDT)
Received: from joshs-mbp (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id p1sm4869383pds.80.2014.10.24.18.23.07
        for <multiple recipients>
        (version=SSLv3 cipher=RC4-SHA bits=128/128);
        Fri, 24 Oct 2014 18:23:07 -0700 (PDT)
Date: Fri, 24 Oct 2014 18:23:06 -0700
From: Josh Rosen <rosenville@gmail.com>
To: Qiuzhuang Lian <qiuzhuang.lian@gmail.com>, dev@spark.apache.org
Message-ID: <etPan.544afb7a.25e45d32.10a@joshs-mbp>
In-Reply-To: <CABKvOWsH-JqzkVK5RoYXAn7q_jOQ3m7iy+7MYCOmTXgjo+i7pw@mail.gmail.com>
References: <CABKvOWsH-JqzkVK5RoYXAn7q_jOQ3m7iy+7MYCOmTXgjo+i7pw@mail.gmail.com>
Subject: Re: serialVersionUID incompatible error in class BlockManagerId
X-Mailer: Airmail Beta (269)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="544afb7a_519b500d_10a"
X-Virus-Checked: Checked by ClamAV on apache.org

--544afb7a_519b500d_10a
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

Are all processes (Master, Worker, Executors, Driver) running the same Sp=
ark build=3F =C2=A0This error implies that you=E2=80=99re seeing protocol=
 / binary incompatibilities between your Spark driver and cluster.

Spark is API-compatibile across the 1.x series, but we don=E2=80=99t make=
 binary link-level compatibility guarantees:=C2=A0https://cwiki.apache.or=
g/confluence/display/SPARK/Spark+Versioning+Policy. =C2=A0This means that=
 your Spark driver=E2=80=99s runtime classpath should use the same versio=
n of Spark that=E2=80=99s installed on your cluster. =C2=A0You can compil=
e=C2=A0against a different API-compatible version of Spark, but the runti=
me versions must match across all components.

To fix this issue, I=E2=80=99d check that you=E2=80=99ve run the =E2=80=9C=
package=E2=80=9D and =E2=80=9Cassembly=E2=80=9D phases and that your Spar=
k cluster is using this updated version.

- Josh

On October 24, 2014 at 6:17:26 PM, Qiuzhuang Lian (qiuzhuang.lian=40gmail=
.com) wrote:

Hi, =20

I update git today and when connecting to spark cluster, I got =20
the serialVersionUID incompatible error in class BlockManagerId. =20

Here is the log, =20

Shouldn't we better give BlockManagerId a constant serialVersionUID avoid=
 =20
this=3F =20

Thanks, =20
Qiuzhuang =20

scala> val rdd =3D sc.parparallelize(1 to 100014/10/25 09:10:48 ERROR =20
Remoting: org.apache.spark.storage.BlockManagerId; local class =20
incompatible: stream classdesc serialVersionUID =3D 2439208141545036836, =
=20
local class serialVersionUID =3D 4657685702603429489 =20
java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId; =20
local class incompatible: stream classdesc serialVersionUID =3D =20
2439208141545036836, local class serialVersionUID =3D 4657685702603429489=
 =20
at =20
java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617) =20
at =20
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622) =20
at =20
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) =20
at =20
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)=
 =20
at =20
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
at =20
java.io.ObjectInputStream.defaultRead=46ields(ObjectInputStream.java:1990=
) =20
at =20
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) =20
at =20
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)=
 =20
at =20
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) =20
at =20
akka.serialization.JavaSerializer=24=24anonfun=241.apply(Serializer.scala=
:136) =20
at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) =20
at =20
akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136) =20
at =20
akka.serialization.Serialization=24=24anonfun=24deserialize=241.apply(Ser=
ialization.scala:104) =20
at scala.util.Try=24.apply(Try.scala:161) =20
at =20
akka.serialization.Serialization.deserialize(Serialization.scala:98) =20
at =20
akka.remote.MessageSerializer=24.deserialize(MessageSerializer.scala:23) =
=20
at =20
akka.remote.DefaultMessageDispatcher.payload=24lzycompute=241(Endpoint.sc=
ala:58) =20
at akka.remote.DefaultMessageDispatcher.payload=241(Endpoint.scala:58) =20
at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76) =20
at =20
akka.remote.EndpointReader=24=24anonfun=24receive=242.applyOrElse(Endpoin=
t.scala:937) =20
at akka.actor.Actor=24class.aroundReceive(Actor.scala:465) =20
at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415) =20
at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) =20
at akka.actor.ActorCell.invoke(ActorCell.scala:487) =20
at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) =20
at akka.dispatch.Mailbox.run(Mailbox.scala:220) =20
at =20
akka.dispatch.=46orkJoinExecutorConfigurator=24Akka=46orkJoinTask.exec(Ab=
stractDispatcher.scala:393) =20
at =20
scala.concurrent.forkjoin.=46orkJoinTask.doExec(=46orkJoinTask.java:260) =
=20
at =20
scala.concurrent.forkjoin.=46orkJoinPool=24WorkQueue.runTask(=46orkJoinPo=
ol.java:1339) =20
at =20
scala.concurrent.forkjoin.=46orkJoinPool.runWorker(=46orkJoinPool.java:19=
79) =20
at =20
scala.concurrent.forkjoin.=46orkJoinWorkerThread.run(=46orkJoinWorkerThre=
ad.java:107) =20
14/10/25 09:10:48 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 1 =20
0014/10/25 09:11:21 ERROR Remoting: =20
org.apache.spark.storage.BlockManagerId; local class incompatible: stream=
 =20
classdesc serialVersionUID =3D 2439208141545036836, local class =20
serialVersionUID =3D 4657685702603429489 =20
java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId; =20
local class incompatible: stream classdesc serialVersionUID =3D =20
2439208141545036836, local class serialVersionUID =3D 4657685702603429489=
 =20
at =20
java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617) =20
at =20
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622) =20
at =20
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) =20
at =20
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)=
 =20
at =20
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
at =20
java.io.ObjectInputStream.defaultRead=46ields(ObjectInputStream.java:1990=
) =20
at =20
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) =20
at =20
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)=
 =20
at =20
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) =20
at =20
akka.serialization.JavaSerializer=24=24anonfun=241.apply(Serializer.scala=
:136) =20
at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) =20
at =20
akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136) =20
at =20
akka.serialization.Serialization=24=24anonfun=24deserialize=241.apply(Ser=
ialization.scala:104) =20
at scala.util.Try=24.apply(Try.scala:161) =20
at =20
akka.serialization.Serialization.deserialize(Serialization.scala:98) =20
at =20
akka.remote.MessageSerializer=24.deserialize(MessageSerializer.scala:23) =
=20
at =20
akka.remote.DefaultMessageDispatcher.payload=24lzycompute=241(Endpoint.sc=
ala:58) =20
at akka.remote.DefaultMessageDispatcher.payload=241(Endpoint.scala:58) =20
at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76) =20
at =20
akka.remote.EndpointReader=24=24anonfun=24receive=242.applyOrElse(Endpoin=
t.scala:937) =20
at akka.actor.Actor=24class.aroundReceive(Actor.scala:465) =20
at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415) =20
at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) =20
at akka.actor.ActorCell.invoke(ActorCell.scala:487) =20
at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) =20
at akka.dispatch.Mailbox.run(Mailbox.scala:220) =20
at =20
akka.dispatch.=46orkJoinExecutorConfigurator=24Akka=46orkJoinTask.exec(Ab=
stractDispatcher.scala:393) =20
at =20
scala.concurrent.forkjoin.=46orkJoinTask.doExec(=46orkJoinTask.java:260) =
=20
at =20
scala.concurrent.forkjoin.=46orkJoinPool=24WorkQueue.runTask(=46orkJoinPo=
ol.java:1339) =20
at =20
scala.concurrent.forkjoin.=46orkJoinPool.runWorker(=46orkJoinPool.java:19=
79) =20
at =20
scala.concurrent.forkjoin.=46orkJoinWorkerThread.run(=46orkJoinWorkerThre=
ad.java:107) =20
14/10/25 09:11:21 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 1 =20
14/10/25 09:11:54 IN=46O SparkDeploySchedulerBackend: Registered executor=
: =20
Actor=5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ:50006/user/Executor=23=
-1410691203=5D =20
with ID 1 =20
14/10/25 09:11:54 IN=46O DAGScheduler: Host added was in lost list earlie=
r: =20
DEV-02.SpringB.GZ =20
14/10/25 09:11:55 ERROR TaskSchedulerImpl: Lost executor 1 on =20
DEV-02.SpringB.GZ: remote Akka client disassociated =20
14/10/25 09:11:55 WARN ReliableDeliverySupervisor: Association with remot=
e =20
system =5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ:50006=5D has faile=
d, =20
address is now gated for =5B5000=5D ms. Reason is: =5BAssociation failed =
with =20
=5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ:50006=5D=5D. =20
14/10/25 09:11:55 IN=46O DAGScheduler: Executor lost: 1 (epoch 1) =20
14/10/25 09:11:55 IN=46O BlockManagerMasterActor: Trying to remove execut=
or 1 =20
from BlockManagerMaster. =20
14/10/25 09:11:55 IN=46O BlockManagerMaster: Removed 1 successfully in =20
removeExecutor =20
14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 1 =20
14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 1 =20
14/10/25 09:11:55 IN=46O AppClient=24ClientActor: Executor updated: =20
app-20141025091012-0002/1 is now EXITED (Command exited with code 1) =20
14/10/25 09:11:55 IN=46O SparkDeploySchedulerBackend: Executor =20
app-20141025091012-0002/1 removed: Command exited with code 1 =20
14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 1 =20
14/10/25 09:11:55 IN=46O AppClient=24ClientActor: Executor added: =20
app-20141025091012-0002/3 on worker-20141025170311-DEV-02.SpringB.GZ-3516=
2 =20
(DEV-02.SpringB.GZ:35162) with 2 cores =20
14/10/25 09:11:55 IN=46O SparkDeploySchedulerBackend: Granted executor ID=
 =20
app-20141025091012-0002/3 on hostPort DEV-02.SpringB.GZ:35162 with 2 core=
s, =20
512.0 MB RAM =20
14/10/25 09:11:55 IN=46O AppClient=24ClientActor: Executor updated: =20
app-20141025091012-0002/3 is now LOADING =20
14/10/25 09:11:55 IN=46O AppClient=24ClientActor: Executor updated: =20
app-20141025091012-0002/3 is now RUNNING =20
14/10/25 09:11:58 IN=46O SparkDeploySchedulerBackend: Registered executor=
: =20
Actor=5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ:50740/user/Executor=23=
1229699385=5D =20
with ID 3 =20
14/10/25 09:11:58 WARN ReliableDeliverySupervisor: Association with remot=
e =20
system =5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ:50740=5D has faile=
d, =20
address is now gated for =5B5000=5D ms. Reason is: =20
=5Borg.apache.spark.storage.BlockManagerId; local class incompatible: str=
eam =20
classdesc serialVersionUID =3D 2439208141545036836, local class =20
serialVersionUID =3D 4657685702603429489=5D. =20
14/10/25 09:11:58 ERROR TaskSchedulerImpl: Lost executor 3 on =20
DEV-02.SpringB.GZ: remote Akka client disassociated =20
14/10/25 09:11:58 IN=46O DAGScheduler: Executor lost: 3 (epoch 2) =20
14/10/25 09:11:58 IN=46O BlockManagerMasterActor: Trying to remove execut=
or 3 =20
from BlockManagerMaster. =20
14/10/25 09:11:58 IN=46O BlockManagerMaster: Removed 3 successfully in =20
removeExecutor =20
14/10/25 09:12:31 ERROR Remoting: org.apache.spark.storage.BlockManagerId=
; =20
local class incompatible: stream classdesc serialVersionUID =3D =20
2439208141545036836, local class serialVersionUID =3D 4657685702603429489=
 =20
java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId; =20
local class incompatible: stream classdesc serialVersionUID =3D =20
2439208141545036836, local class serialVersionUID =3D 4657685702603429489=
 =20
at =20
java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617) =20
at =20
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622) =20
at =20
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) =20
at =20
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)=
 =20
at =20
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
at =20
java.io.ObjectInputStream.defaultRead=46ields(ObjectInputStream.java:1990=
) =20
at =20
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) =20
at =20
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)=
 =20
at =20
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) =20
at =20
akka.serialization.JavaSerializer=24=24anonfun=241.apply(Serializer.scala=
:136) =20
at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) =20
at =20
akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136) =20
at =20
akka.serialization.Serialization=24=24anonfun=24deserialize=241.apply(Ser=
ialization.scala:104) =20
at scala.util.Try=24.apply(Try.scala:161) =20
at =20
akka.serialization.Serialization.deserialize(Serialization.scala:98) =20
at =20
akka.remote.MessageSerializer=24.deserialize(MessageSerializer.scala:23) =
=20
at =20
akka.remote.DefaultMessageDispatcher.payload=24lzycompute=241(Endpoint.sc=
ala:58) =20
at akka.remote.DefaultMessageDispatcher.payload=241(Endpoint.scala:58) =20
at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76) =20
at =20
akka.remote.EndpointReader=24=24anonfun=24receive=242.applyOrElse(Endpoin=
t.scala:937) =20
at akka.actor.Actor=24class.aroundReceive(Actor.scala:465) =20
at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415) =20
at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) =20
at akka.actor.ActorCell.invoke(ActorCell.scala:487) =20
at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) =20
at akka.dispatch.Mailbox.run(Mailbox.scala:220) =20
at =20
akka.dispatch.=46orkJoinExecutorConfigurator=24Akka=46orkJoinTask.exec(Ab=
stractDispatcher.scala:393) =20
at =20
scala.concurrent.forkjoin.=46orkJoinTask.doExec(=46orkJoinTask.java:260) =
=20
at =20
scala.concurrent.forkjoin.=46orkJoinPool=24WorkQueue.runTask(=46orkJoinPo=
ol.java:1339) =20
at =20
scala.concurrent.forkjoin.=46orkJoinPool.runWorker(=46orkJoinPool.java:19=
79) =20
at =20
scala.concurrent.forkjoin.=46orkJoinWorkerThread.run(=46orkJoinWorkerThre=
ad.java:107) =20
14/10/25 09:12:31 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 3 =20
14/10/25 09:13:04 ERROR Remoting: org.apache.spark.storage.BlockManagerId=
; =20
local class incompatible: stream classdesc serialVersionUID =3D =20
2439208141545036836, local class serialVersionUID =3D 4657685702603429489=
 =20
java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId; =20
local class incompatible: stream classdesc serialVersionUID =3D =20
2439208141545036836, local class serialVersionUID =3D 4657685702603429489=
 =20
at =20
java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617) =20
at =20
java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622) =20
at =20
java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) =20
at =20
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)=
 =20
at =20
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
at =20
java.io.ObjectInputStream.defaultRead=46ields(ObjectInputStream.java:1990=
) =20
at =20
java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) =20
at =20
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)=
 =20
at =20
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) =20
at =20
akka.serialization.JavaSerializer=24=24anonfun=241.apply(Serializer.scala=
:136) =20
at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) =20
at =20
akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136) =20
at =20
akka.serialization.Serialization=24=24anonfun=24deserialize=241.apply(Ser=
ialization.scala:104) =20
at scala.util.Try=24.apply(Try.scala:161) =20
at =20
akka.serialization.Serialization.deserialize(Serialization.scala:98) =20
at =20
akka.remote.MessageSerializer=24.deserialize(MessageSerializer.scala:23) =
=20
at =20
akka.remote.DefaultMessageDispatcher.payload=24lzycompute=241(Endpoint.sc=
ala:58) =20
at akka.remote.DefaultMessageDispatcher.payload=241(Endpoint.scala:58) =20
at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76) =20
at =20
akka.remote.EndpointReader=24=24anonfun=24receive=242.applyOrElse(Endpoin=
t.scala:937) =20
at akka.actor.Actor=24class.aroundReceive(Actor.scala:465) =20
at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415) =20
at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) =20
at akka.actor.ActorCell.invoke(ActorCell.scala:487) =20
at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) =20
at akka.dispatch.Mailbox.run(Mailbox.scala:220) =20
at =20
akka.dispatch.=46orkJoinExecutorConfigurator=24Akka=46orkJoinTask.exec(Ab=
stractDispatcher.scala:393) =20
at =20
scala.concurrent.forkjoin.=46orkJoinTask.doExec(=46orkJoinTask.java:260) =
=20
at =20
scala.concurrent.forkjoin.=46orkJoinPool=24WorkQueue.runTask(=46orkJoinPo=
ol.java:1339) =20
at =20
scala.concurrent.forkjoin.=46orkJoinPool.runWorker(=46orkJoinPool.java:19=
79) =20
at =20
scala.concurrent.forkjoin.=46orkJoinWorkerThread.run(=46orkJoinWorkerThre=
ad.java:107) =20
14/10/25 09:13:04 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 3 =20
14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 3 =20
14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 3 =20
14/10/25 09:13:37 IN=46O AppClient=24ClientActor: Executor updated: =20
app-20141025091012-0002/3 is now EXITED (Command exited with code 1) =20
14/10/25 09:13:37 IN=46O SparkDeploySchedulerBackend: Executor =20
app-20141025091012-0002/3 removed: Command exited with code 1 =20
14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non =
=20
existant executor 3 =20
14/10/25 09:13:37 IN=46O AppClient=24ClientActor: Executor added: =20
app-20141025091012-0002/4 on worker-20141025170311-DEV-02.SpringB.GZ-3516=
2 =20
(DEV-02.SpringB.GZ:35162) with 2 cores =20
14/10/25 09:13:37 IN=46O SparkDeploySchedulerBackend: Granted executor ID=
 =20
app-20141025091012-0002/4 on hostPort DEV-02.SpringB.GZ:35162 with 2 core=
s, =20
512.0 MB RAM =20
14/10/25 09:13:37 IN=46O AppClient=24ClientActor: Executor updated: =20
app-20141025091012-0002/4 is now LOADING =20
14/10/25 09:13:38 IN=46O AppClient=24ClientActor: Executor updated: =20
app-20141025091012-0002/4 is now RUNNING =20
14/10/25 09:13:40 IN=46O SparkDeploySchedulerBackend: Registered executor=
: =20
Actor=5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ:56019/user/Executor=23=
1354626597=5D =20
with ID 4 =20
14/10/25 09:13:40 WARN ReliableDeliverySupervisor: Association with remot=
e =20
system =5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ:56019=5D has faile=
d, =20
address is now gated for =5B5000=5D ms. Reason is: =20
=5Borg.apache.spark.storage.BlockManagerId; local class incompatible: str=
eam =20
classdesc serialVersionUID =3D 2439208141545036836, local class =20
serialVersionUID =3D 4657685702603429489=5D. =20
14/10/25 09:13:40 ERROR TaskSchedulerImpl: Lost executor 4 on =20
DEV-02.SpringB.GZ: remote Akka client disassociated =20
14/10/25 09:13:40 IN=46O DAGScheduler: Executor lost: 4 (epoch 3) =20
14/10/25 09:13:40 IN=46O BlockManagerMasterActor: Trying to remove execut=
or 4 =20
from BlockManagerMaster. =20
14/10/25 09:13:40 IN=46O BlockManagerMaster: Removed 4 successfully in =20
removeExecutor =20

--544afb7a_519b500d_10a--


From dev-return-9979-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 01:26:17 2014
Return-Path: <dev-return-9979-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E371217E85
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 01:26:16 +0000 (UTC)
Received: (qmail 7039 invoked by uid 500); 25 Oct 2014 01:26:15 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 6967 invoked by uid 500); 25 Oct 2014 01:26:15 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 6955 invoked by uid 99); 25 Oct 2014 01:26:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:26:15 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of qiuzhuang.lian@gmail.com designates 209.85.220.179 as permitted sender)
Received: from [209.85.220.179] (HELO mail-vc0-f179.google.com) (209.85.220.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:26:09 +0000
Received: by mail-vc0-f179.google.com with SMTP id hy4so843784vcb.24
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 18:25:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=zQwASeyCdwLnp7oTfgsIN5YKUh1uTVWC+w5yit11WQI=;
        b=odhA9QGL061RS/d4WQv3XE1oC9V7LlhAioz+o1DnO+gZAm6TBFoZBAZN8TSGLtw8/x
         Q1GKz21o9qc3qjW5Xq5QuWp0TmV/PXE/Jy0jnLpap5rTwR3mOrBe2c+qWIlgqpG9GKgX
         Ik3S2ObhFzjNx+FvyBkYsHuJHfx7mCk2f6ajm2lHscbLFH6Q56avttB2v/cfvXLNjLNW
         ZYQUJMBqE6y7FuL+lGrRXUdUQGStdf9P4t22rh3jA3Hgu+2Rw94Bk6310hoLPF56ywia
         vkW4k+n0bN3EkYLwjbdVZOWf2lEVKpDgDgo43p9QHtTXzBTkH8p4lgO9Xbssj4uOAJ2H
         eKfQ==
MIME-Version: 1.0
X-Received: by 10.221.46.196 with SMTP id up4mr5360167vcb.2.1414200348491;
 Fri, 24 Oct 2014 18:25:48 -0700 (PDT)
Received: by 10.221.7.132 with HTTP; Fri, 24 Oct 2014 18:25:48 -0700 (PDT)
In-Reply-To: <etPan.544afb7a.25e45d32.10a@joshs-mbp>
References: <CABKvOWsH-JqzkVK5RoYXAn7q_jOQ3m7iy+7MYCOmTXgjo+i7pw@mail.gmail.com>
	<etPan.544afb7a.25e45d32.10a@joshs-mbp>
Date: Sat, 25 Oct 2014 09:25:48 +0800
Message-ID: <CABKvOWsXFCJK9bu1fVfB6d4sOYjB3ZeY_LEaUvH6GQ50qTDtDA@mail.gmail.com>
Subject: Re: serialVersionUID incompatible error in class BlockManagerId
From: Qiuzhuang Lian <qiuzhuang.lian@gmail.com>
To: Josh Rosen <rosenville@gmail.com>
Cc: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11339dae69c7ef0506352dcd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11339dae69c7ef0506352dcd
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I update git trunk and build in the two linux machines. I think they should
have the same version. I am going to do a force clean build and then retry.

Thanks.


On Sat, Oct 25, 2014 at 9:23 AM, Josh Rosen <rosenville@gmail.com> wrote:

> Are all processes (Master, Worker, Executors, Driver) running the same
> Spark build?  This error implies that you=E2=80=99re seeing protocol / bi=
nary
> incompatibilities between your Spark driver and cluster.
>
> Spark is API-compatibile across the 1.x series, but we don=E2=80=99t make=
 binary
> link-level compatibility guarantees:
> https://cwiki.apache.org/confluence/display/SPARK/Spark+Versioning+Policy=
.
> This means that your Spark driver=E2=80=99s runtime classpath should use =
the same
> version of Spark that=E2=80=99s installed on your cluster.  You can *comp=
ile* against
> a different API-compatible version of Spark, but the runtime versions mus=
t
> match across all components.
>
> To fix this issue, I=E2=80=99d check that you=E2=80=99ve run the =E2=80=
=9Cpackage=E2=80=9D and =E2=80=9Cassembly=E2=80=9D
> phases and that your Spark cluster is using this updated version.
>
> - Josh
>
> On October 24, 2014 at 6:17:26 PM, Qiuzhuang Lian (
> qiuzhuang.lian@gmail.com) wrote:
>
> Hi,
>
> I update git today and when connecting to spark cluster, I got
> the serialVersionUID incompatible error in class BlockManagerId.
>
> Here is the log,
>
> Shouldn't we better give BlockManagerId a constant serialVersionUID avoid
> this?
>
> Thanks,
> Qiuzhuang
>
> scala> val rdd =3D sc.parparallelize(1 to 100014/10/25 09:10:48 ERROR
> Remoting: org.apache.spark.storage.BlockManagerId; local class
> incompatible: stream classdesc serialVersionUID =3D 2439208141545036836,
> local class serialVersionUID =3D 4657685702603429489
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> at
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
> at
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
> at
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at
> java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
> at
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> at
> akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
> at
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
> at
> akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serializati=
on.scala:104)
>
> at scala.util.Try$.apply(Try.scala:161)
> at
> akka.serialization.Serialization.deserialize(Serialization.scala:98)
> at
> akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
> at
> akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:=
58)
>
> at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
> at
> akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:=
937)
>
> at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
> at akka.actor.ActorCell.invoke(ActorCell.scala:487)
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
> at akka.dispatch.Mailbox.run(Mailbox.scala:220)
> at
> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(Abstract=
Dispatcher.scala:393)
>
> at
> scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
> at
> scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.jav=
a:1339)
>
> at
> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> at
> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.j=
ava:107)
>
> 14/10/25 09:10:48 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 0014/10/25 09:11:21 ERROR Remoting:
> org.apache.spark.storage.BlockManagerId; local class incompatible: stream
> classdesc serialVersionUID =3D 2439208141545036836, local class
> serialVersionUID =3D 4657685702603429489
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> at
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
> at
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
> at
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at
> java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
> at
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> at
> akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
> at
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
> at
> akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serializati=
on.scala:104)
>
> at scala.util.Try$.apply(Try.scala:161)
> at
> akka.serialization.Serialization.deserialize(Serialization.scala:98)
> at
> akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
> at
> akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:=
58)
>
> at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
> at
> akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:=
937)
>
> at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
> at akka.actor.ActorCell.invoke(ActorCell.scala:487)
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
> at akka.dispatch.Mailbox.run(Mailbox.scala:220)
> at
> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(Abstract=
Dispatcher.scala:393)
>
> at
> scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
> at
> scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.jav=
a:1339)
>
> at
> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> at
> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.j=
ava:107)
>
> 14/10/25 09:11:21 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 14/10/25 09:11:54 INFO SparkDeploySchedulerBackend: Registered executor:
> Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006/user/Executor#-141=
0691203]
>
> with ID 1
> 14/10/25 09:11:54 INFO DAGScheduler: Host added was in lost list earlier:
> DEV-02.SpringB.GZ
> 14/10/25 09:11:55 ERROR TaskSchedulerImpl: Lost executor 1 on
> DEV-02.SpringB.GZ: remote Akka client disassociated
> 14/10/25 09:11:55 WARN ReliableDeliverySupervisor: Association with remot=
e
> system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006] has failed,
> address is now gated for [5000] ms. Reason is: [Association failed with
> [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006]].
> 14/10/25 09:11:55 INFO DAGScheduler: Executor lost: 1 (epoch 1)
> 14/10/25 09:11:55 INFO BlockManagerMasterActor: Trying to remove executor
> 1
> from BlockManagerMaster.
> 14/10/25 09:11:55 INFO BlockManagerMaster: Removed 1 successfully in
> removeExecutor
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/1 is now EXITED (Command exited with code 1)
> 14/10/25 09:11:55 INFO SparkDeploySchedulerBackend: Executor
> app-20141025091012-0002/1 removed: Command exited with code 1
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 14/10/25 09:11:55 INFO AppClient$ClientActor: Executor added:
> app-20141025091012-0002/3 on worker-20141025170311-DEV-02.SpringB.GZ-3516=
2
> (DEV-02.SpringB.GZ:35162) with 2 cores
> 14/10/25 09:11:55 INFO SparkDeploySchedulerBackend: Granted executor ID
> app-20141025091012-0002/3 on hostPort DEV-02.SpringB.GZ:35162 with 2
> cores,
> 512.0 MB RAM
> 14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/3 is now LOADING
> 14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/3 is now RUNNING
> 14/10/25 09:11:58 INFO SparkDeploySchedulerBackend: Registered executor:
> Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50740/user/Executor#1229=
699385]
>
> with ID 3
> 14/10/25 09:11:58 WARN ReliableDeliverySupervisor: Association with remot=
e
> system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50740] has failed,
> address is now gated for [5000] ms. Reason is:
> [org.apache.spark.storage.BlockManagerId; local class incompatible: strea=
m
> classdesc serialVersionUID =3D 2439208141545036836, local class
> serialVersionUID =3D 4657685702603429489].
> 14/10/25 09:11:58 ERROR TaskSchedulerImpl: Lost executor 3 on
> DEV-02.SpringB.GZ: remote Akka client disassociated
> 14/10/25 09:11:58 INFO DAGScheduler: Executor lost: 3 (epoch 2)
> 14/10/25 09:11:58 INFO BlockManagerMasterActor: Trying to remove executor
> 3
> from BlockManagerMaster.
> 14/10/25 09:11:58 INFO BlockManagerMaster: Removed 3 successfully in
> removeExecutor
> 14/10/25 09:12:31 ERROR Remoting: org.apache.spark.storage.BlockManagerId=
;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> at
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
> at
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
> at
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at
> java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
> at
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> at
> akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
> at
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
> at
> akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serializati=
on.scala:104)
>
> at scala.util.Try$.apply(Try.scala:161)
> at
> akka.serialization.Serialization.deserialize(Serialization.scala:98)
> at
> akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
> at
> akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:=
58)
>
> at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
> at
> akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:=
937)
>
> at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
> at akka.actor.ActorCell.invoke(ActorCell.scala:487)
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
> at akka.dispatch.Mailbox.run(Mailbox.scala:220)
> at
> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(Abstract=
Dispatcher.scala:393)
>
> at
> scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
> at
> scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.jav=
a:1339)
>
> at
> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> at
> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.j=
ava:107)
>
> 14/10/25 09:12:31 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:04 ERROR Remoting: org.apache.spark.storage.BlockManagerId=
;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> at
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
> at
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
> at
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at
> java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
> at
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> at
> akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
> at
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
> at
> akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serializati=
on.scala:104)
>
> at scala.util.Try$.apply(Try.scala:161)
> at
> akka.serialization.Serialization.deserialize(Serialization.scala:98)
> at
> akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
> at
> akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:=
58)
>
> at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
> at
> akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:=
937)
>
> at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
> at akka.actor.ActorCell.invoke(ActorCell.scala:487)
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
> at akka.dispatch.Mailbox.run(Mailbox.scala:220)
> at
> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(Abstract=
Dispatcher.scala:393)
>
> at
> scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
> at
> scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.jav=
a:1339)
>
> at
> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> at
> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.j=
ava:107)
>
> 14/10/25 09:13:04 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:37 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/3 is now EXITED (Command exited with code 1)
> 14/10/25 09:13:37 INFO SparkDeploySchedulerBackend: Executor
> app-20141025091012-0002/3 removed: Command exited with code 1
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:37 INFO AppClient$ClientActor: Executor added:
> app-20141025091012-0002/4 on worker-20141025170311-DEV-02.SpringB.GZ-3516=
2
> (DEV-02.SpringB.GZ:35162) with 2 cores
> 14/10/25 09:13:37 INFO SparkDeploySchedulerBackend: Granted executor ID
> app-20141025091012-0002/4 on hostPort DEV-02.SpringB.GZ:35162 with 2
> cores,
> 512.0 MB RAM
> 14/10/25 09:13:37 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/4 is now LOADING
> 14/10/25 09:13:38 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/4 is now RUNNING
> 14/10/25 09:13:40 INFO SparkDeploySchedulerBackend: Registered executor:
> Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:56019/user/Executor#1354=
626597]
>
> with ID 4
> 14/10/25 09:13:40 WARN ReliableDeliverySupervisor: Association with remot=
e
> system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:56019] has failed,
> address is now gated for [5000] ms. Reason is:
> [org.apache.spark.storage.BlockManagerId; local class incompatible: strea=
m
> classdesc serialVersionUID =3D 2439208141545036836, local class
> serialVersionUID =3D 4657685702603429489].
> 14/10/25 09:13:40 ERROR TaskSchedulerImpl: Lost executor 4 on
> DEV-02.SpringB.GZ: remote Akka client disassociated
> 14/10/25 09:13:40 INFO DAGScheduler: Executor lost: 4 (epoch 3)
> 14/10/25 09:13:40 INFO BlockManagerMasterActor: Trying to remove executor
> 4
> from BlockManagerMaster.
> 14/10/25 09:13:40 INFO BlockManagerMaster: Removed 4 successfully in
> removeExecutor
>
>

--001a11339dae69c7ef0506352dcd--

From dev-return-9980-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 01:28:27 2014
Return-Path: <dev-return-9980-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 01B1517E9F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 01:28:27 +0000 (UTC)
Received: (qmail 13255 invoked by uid 500); 25 Oct 2014 01:28:26 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13185 invoked by uid 500); 25 Oct 2014 01:28:26 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13170 invoked by uid 99); 25 Oct 2014 01:28:25 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:28:25 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zhunanmcgill@gmail.com designates 209.85.216.177 as permitted sender)
Received: from [209.85.216.177] (HELO mail-qc0-f177.google.com) (209.85.216.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:28:18 +0000
Received: by mail-qc0-f177.google.com with SMTP id l6so1611312qcy.36
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 18:27:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:from:to:cc:message-id:in-reply-to:references:subject
         :mime-version:content-type;
        bh=ywh+Z5Ru9zGE9iJHkmZzfEXaLmYZZNq0eJnIUy1HmiA=;
        b=KN/ihww+m6kJJSCv9CbQU/0DOZI5BaFIz/h+dABsdVQGA1xS2HV4KLJuTPLzTkp5i5
         XhhtpbjCFCGnvqSg9IID7e5rIA4JTo6XnVGIsJBIbXJuWMQKOtO0Dg2hSIeaLD9DklN9
         b2LZu4BbH83/JBHoxZFC0Etilvb3sfTi0vasaO+qyEhFUudlCtwZKH02Q1vZLOJ/LZME
         zPJL/wtw8rao9g9Yy14YvyDI14dDqhjOitudVhDGaoxqhdze5WKQnHV/0o6iTECIIp1d
         hLVKQEyhY0xU3e37X8ShMN13O/0zTb1fw+pVKj/fyhUQ6WDTiuX6oRwEjQkeggBAOoOz
         e+4Q==
X-Received: by 10.140.40.99 with SMTP id w90mr10901260qgw.18.1414200477937;
        Fri, 24 Oct 2014 18:27:57 -0700 (PDT)
Received: from [192.168.2.13] (bas3-montreal42-1167938673.dsl.bell.ca. [69.157.84.113])
        by mx.google.com with ESMTPSA id v37sm5563691qge.29.2014.10.24.18.27.56
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Fri, 24 Oct 2014 18:27:57 -0700 (PDT)
Date: Fri, 24 Oct 2014 21:42:01 -0400
From: Nan Zhu <zhunanmcgill@gmail.com>
To: Josh Rosen <rosenville@gmail.com>
Cc: Qiuzhuang Lian <qiuzhuang.lian@gmail.com>, dev@spark.apache.org
Message-ID: <D44752A0A14741EF843C0545D2B5E036@gmail.com>
In-Reply-To: <etPan.544afb7a.25e45d32.10a@joshs-mbp>
References: <CABKvOWsH-JqzkVK5RoYXAn7q_jOQ3m7iy+7MYCOmTXgjo+i7pw@mail.gmail.com>
 <etPan.544afb7a.25e45d32.10a@joshs-mbp>
Subject: Re: serialVersionUID incompatible error in class BlockManagerId
X-Mailer: sparrow 1.6.4 (build 1176)
MIME-Version: 1.0
Content-Type: multipart/alternative; boundary="544affe9_257130a3_a51"
X-Virus-Checked: Checked by ClamAV on apache.org

--544affe9_257130a3_a51
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: quoted-printable
Content-Disposition: inline

According to my experience, there are more issues rather than BlockManage=
r when you try to run spark application whose build version is different =
with your cluster=E2=80=A6. =20

I once tried to make jdbc server build with branch-jdbc-1.0 run with a br=
anch-1.0 cluster=E2=80=A6no workaround exits=E2=80=A6just had to replace =
cluster jar with branch-jdbc-1.0 jar file=E2=80=A6..

Best, =20

-- =20
Nan Zhu


On =46riday, October 24, 2014 at 9:23 PM, Josh Rosen wrote:

> Are all processes (Master, Worker, Executors, Driver) running the same =
Spark build=3F  This error implies that you=E2=80=99re seeing protocol / =
binary incompatibilities between your Spark driver and cluster.
> =20
> Spark is API-compatibile across the 1.x series, but we don=E2=80=99t ma=
ke binary link-level compatibility guarantees: https://cwiki.apache.org/c=
onfluence/display/SPARK/Spark+Versioning+Policy.  This means that your Sp=
ark driver=E2=80=99s runtime classpath should use the same version of Spa=
rk that=E2=80=99s installed on your cluster.  You can compile against a d=
ifferent API-compatible version of Spark, but the runtime versions must m=
atch across all components.
> =20
> To fix this issue, I=E2=80=99d check that you=E2=80=99ve run the =E2=80=
=9Cpackage=E2=80=9D and =E2=80=9Cassembly=E2=80=9D phases and that your S=
park cluster is using this updated version.
> =20
> - Josh
> =20
> On October 24, 2014 at 6:17:26 PM, Qiuzhuang Lian (qiuzhuang.lian=40gma=
il.com (mailto:qiuzhuang.lian=40gmail.com)) wrote:
> =20
> Hi, =20
> =20
> I update git today and when connecting to spark cluster, I got =20
> the serialVersionUID incompatible error in class BlockManagerId. =20
> =20
> Here is the log, =20
> =20
> Shouldn't we better give BlockManagerId a constant serialVersionUID avo=
id =20
> this=3F =20
> =20
> Thanks, =20
> Qiuzhuang =20
> =20
> scala> val rdd =3D sc.parparallelize(1 to 100014/10/25 09:10:48 ERROR =20
> Remoting: org.apache.spark.storage.BlockManagerId; local class =20
> incompatible: stream classdesc serialVersionUID =3D 2439208141545036836=
, =20
> local class serialVersionUID =3D 4657685702603429489 =20
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;=
 =20
> local class incompatible: stream classdesc serialVersionUID =3D =20
> 2439208141545036836, local class serialVersionUID =3D 46576857026034294=
89 =20
> at =20
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617) =20
> at =20
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)=
 =20
> at =20
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) =20
> at =20
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:177=
1) =20
> at =20
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
> at =20
> java.io.ObjectInputStream.defaultRead=46ields(ObjectInputStream.java:19=
90) =20
> at =20
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) =20
> at =20
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:179=
8) =20
> at =20
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) =20
> at =20
> akka.serialization.JavaSerializer=24=24anonfun=241.apply(Serializer.sca=
la:136) =20
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) =20
> at =20
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136) =20
> at =20
> akka.serialization.Serialization=24=24anonfun=24deserialize=241.apply(S=
erialization.scala:104) =20
> at scala.util.Try=24.apply(Try.scala:161) =20
> at =20
> akka.serialization.Serialization.deserialize(Serialization.scala:98) =20
> at =20
> akka.remote.MessageSerializer=24.deserialize(MessageSerializer.scala:23=
) =20
> at =20
> akka.remote.DefaultMessageDispatcher.payload=24lzycompute=241(Endpoint.=
scala:58) =20
> at akka.remote.DefaultMessageDispatcher.payload=241(Endpoint.scala:58) =
=20
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76) =20
> at =20
> akka.remote.EndpointReader=24=24anonfun=24receive=242.applyOrElse(Endpo=
int.scala:937) =20
> at akka.actor.Actor=24class.aroundReceive(Actor.scala:465) =20
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415) =20
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) =20
> at akka.actor.ActorCell.invoke(ActorCell.scala:487) =20
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) =20
> at akka.dispatch.Mailbox.run(Mailbox.scala:220) =20
> at =20
> akka.dispatch.=46orkJoinExecutorConfigurator=24Akka=46orkJoinTask.exec(=
AbstractDispatcher.scala:393) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinTask.doExec(=46orkJoinTask.java:260=
) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinPool=24WorkQueue.runTask(=46orkJoin=
Pool.java:1339) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinPool.runWorker(=46orkJoinPool.java:=
1979) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinWorkerThread.run(=46orkJoinWorkerTh=
read.java:107) =20
> 14/10/25 09:10:48 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 1 =20
> 0014/10/25 09:11:21 ERROR Remoting: =20
> org.apache.spark.storage.BlockManagerId; local class incompatible: stre=
am =20
> classdesc serialVersionUID =3D 2439208141545036836, local class =20
> serialVersionUID =3D 4657685702603429489 =20
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;=
 =20
> local class incompatible: stream classdesc serialVersionUID =3D =20
> 2439208141545036836, local class serialVersionUID =3D 46576857026034294=
89 =20
> at =20
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617) =20
> at =20
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)=
 =20
> at =20
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) =20
> at =20
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:177=
1) =20
> at =20
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
> at =20
> java.io.ObjectInputStream.defaultRead=46ields(ObjectInputStream.java:19=
90) =20
> at =20
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) =20
> at =20
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:179=
8) =20
> at =20
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) =20
> at =20
> akka.serialization.JavaSerializer=24=24anonfun=241.apply(Serializer.sca=
la:136) =20
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) =20
> at =20
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136) =20
> at =20
> akka.serialization.Serialization=24=24anonfun=24deserialize=241.apply(S=
erialization.scala:104) =20
> at scala.util.Try=24.apply(Try.scala:161) =20
> at =20
> akka.serialization.Serialization.deserialize(Serialization.scala:98) =20
> at =20
> akka.remote.MessageSerializer=24.deserialize(MessageSerializer.scala:23=
) =20
> at =20
> akka.remote.DefaultMessageDispatcher.payload=24lzycompute=241(Endpoint.=
scala:58) =20
> at akka.remote.DefaultMessageDispatcher.payload=241(Endpoint.scala:58) =
=20
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76) =20
> at =20
> akka.remote.EndpointReader=24=24anonfun=24receive=242.applyOrElse(Endpo=
int.scala:937) =20
> at akka.actor.Actor=24class.aroundReceive(Actor.scala:465) =20
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415) =20
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) =20
> at akka.actor.ActorCell.invoke(ActorCell.scala:487) =20
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) =20
> at akka.dispatch.Mailbox.run(Mailbox.scala:220) =20
> at =20
> akka.dispatch.=46orkJoinExecutorConfigurator=24Akka=46orkJoinTask.exec(=
AbstractDispatcher.scala:393) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinTask.doExec(=46orkJoinTask.java:260=
) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinPool=24WorkQueue.runTask(=46orkJoin=
Pool.java:1339) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinPool.runWorker(=46orkJoinPool.java:=
1979) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinWorkerThread.run(=46orkJoinWorkerTh=
read.java:107) =20
> 14/10/25 09:11:21 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 1 =20
> 14/10/25 09:11:54 IN=46O SparkDeploySchedulerBackend: Registered execut=
or: =20
> Actor=5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ (mailto:sparkExecu=
tor=40DEV-02.SpringB.GZ):50006/user/Executor=23-1410691203=5D =20
> with ID 1 =20
> 14/10/25 09:11:54 IN=46O DAGScheduler: Host added was in lost list earl=
ier: =20
> DEV-02.SpringB.GZ =20
> 14/10/25 09:11:55 ERROR TaskSchedulerImpl: Lost executor 1 on =20
> DEV-02.SpringB.GZ: remote Akka client disassociated =20
> 14/10/25 09:11:55 WARN ReliableDeliverySupervisor: Association with rem=
ote =20
> system =5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ (mailto:sparkExe=
cutor=40DEV-02.SpringB.GZ):50006=5D has failed, =20
> address is now gated for =5B5000=5D ms. Reason is: =5BAssociation faile=
d with =20
> =5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ (mailto:sparkExecutor=40=
DEV-02.SpringB.GZ):50006=5D=5D. =20
> 14/10/25 09:11:55 IN=46O DAGScheduler: Executor lost: 1 (epoch 1) =20
> 14/10/25 09:11:55 IN=46O BlockManagerMasterActor: Trying to remove exec=
utor 1 =20
> from BlockManagerMaster. =20
> 14/10/25 09:11:55 IN=46O BlockManagerMaster: Removed 1 successfully in =
=20
> removeExecutor =20
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 1 =20
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 1 =20
> 14/10/25 09:11:55 IN=46O AppClient=24ClientActor: Executor updated: =20
> app-20141025091012-0002/1 is now EXITED (Command exited with code 1) =20
> 14/10/25 09:11:55 IN=46O SparkDeploySchedulerBackend: Executor =20
> app-20141025091012-0002/1 removed: Command exited with code 1 =20
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 1 =20
> 14/10/25 09:11:55 IN=46O AppClient=24ClientActor: Executor added: =20
> app-20141025091012-0002/3 on worker-20141025170311-DEV-02.SpringB.GZ-35=
162 =20
> (DEV-02.SpringB.GZ:35162) with 2 cores =20
> 14/10/25 09:11:55 IN=46O SparkDeploySchedulerBackend: Granted executor =
ID =20
> app-20141025091012-0002/3 on hostPort DEV-02.SpringB.GZ:35162 with 2 co=
res, =20
> 512.0 MB RAM =20
> 14/10/25 09:11:55 IN=46O AppClient=24ClientActor: Executor updated: =20
> app-20141025091012-0002/3 is now LOADING =20
> 14/10/25 09:11:55 IN=46O AppClient=24ClientActor: Executor updated: =20
> app-20141025091012-0002/3 is now RUNNING =20
> 14/10/25 09:11:58 IN=46O SparkDeploySchedulerBackend: Registered execut=
or: =20
> Actor=5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ (mailto:sparkExecu=
tor=40DEV-02.SpringB.GZ):50740/user/Executor=231229699385=5D =20
> with ID 3 =20
> 14/10/25 09:11:58 WARN ReliableDeliverySupervisor: Association with rem=
ote =20
> system =5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ (mailto:sparkExe=
cutor=40DEV-02.SpringB.GZ):50740=5D has failed, =20
> address is now gated for =5B5000=5D ms. Reason is: =20
> =5Borg.apache.spark.storage.BlockManagerId; local class incompatible: s=
tream =20
> classdesc serialVersionUID =3D 2439208141545036836, local class =20
> serialVersionUID =3D 4657685702603429489=5D. =20
> 14/10/25 09:11:58 ERROR TaskSchedulerImpl: Lost executor 3 on =20
> DEV-02.SpringB.GZ: remote Akka client disassociated =20
> 14/10/25 09:11:58 IN=46O DAGScheduler: Executor lost: 3 (epoch 2) =20
> 14/10/25 09:11:58 IN=46O BlockManagerMasterActor: Trying to remove exec=
utor 3 =20
> from BlockManagerMaster. =20
> 14/10/25 09:11:58 IN=46O BlockManagerMaster: Removed 3 successfully in =
=20
> removeExecutor =20
> 14/10/25 09:12:31 ERROR Remoting: org.apache.spark.storage.BlockManager=
Id; =20
> local class incompatible: stream classdesc serialVersionUID =3D =20
> 2439208141545036836, local class serialVersionUID =3D 46576857026034294=
89 =20
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;=
 =20
> local class incompatible: stream classdesc serialVersionUID =3D =20
> 2439208141545036836, local class serialVersionUID =3D 46576857026034294=
89 =20
> at =20
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617) =20
> at =20
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)=
 =20
> at =20
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) =20
> at =20
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:177=
1) =20
> at =20
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
> at =20
> java.io.ObjectInputStream.defaultRead=46ields(ObjectInputStream.java:19=
90) =20
> at =20
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) =20
> at =20
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:179=
8) =20
> at =20
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) =20
> at =20
> akka.serialization.JavaSerializer=24=24anonfun=241.apply(Serializer.sca=
la:136) =20
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) =20
> at =20
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136) =20
> at =20
> akka.serialization.Serialization=24=24anonfun=24deserialize=241.apply(S=
erialization.scala:104) =20
> at scala.util.Try=24.apply(Try.scala:161) =20
> at =20
> akka.serialization.Serialization.deserialize(Serialization.scala:98) =20
> at =20
> akka.remote.MessageSerializer=24.deserialize(MessageSerializer.scala:23=
) =20
> at =20
> akka.remote.DefaultMessageDispatcher.payload=24lzycompute=241(Endpoint.=
scala:58) =20
> at akka.remote.DefaultMessageDispatcher.payload=241(Endpoint.scala:58) =
=20
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76) =20
> at =20
> akka.remote.EndpointReader=24=24anonfun=24receive=242.applyOrElse(Endpo=
int.scala:937) =20
> at akka.actor.Actor=24class.aroundReceive(Actor.scala:465) =20
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415) =20
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) =20
> at akka.actor.ActorCell.invoke(ActorCell.scala:487) =20
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) =20
> at akka.dispatch.Mailbox.run(Mailbox.scala:220) =20
> at =20
> akka.dispatch.=46orkJoinExecutorConfigurator=24Akka=46orkJoinTask.exec(=
AbstractDispatcher.scala:393) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinTask.doExec(=46orkJoinTask.java:260=
) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinPool=24WorkQueue.runTask(=46orkJoin=
Pool.java:1339) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinPool.runWorker(=46orkJoinPool.java:=
1979) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinWorkerThread.run(=46orkJoinWorkerTh=
read.java:107) =20
> 14/10/25 09:12:31 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 3 =20
> 14/10/25 09:13:04 ERROR Remoting: org.apache.spark.storage.BlockManager=
Id; =20
> local class incompatible: stream classdesc serialVersionUID =3D =20
> 2439208141545036836, local class serialVersionUID =3D 46576857026034294=
89 =20
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;=
 =20
> local class incompatible: stream classdesc serialVersionUID =3D =20
> 2439208141545036836, local class serialVersionUID =3D 46576857026034294=
89 =20
> at =20
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617) =20
> at =20
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)=
 =20
> at =20
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517) =20
> at =20
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:177=
1) =20
> at =20
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
> at =20
> java.io.ObjectInputStream.defaultRead=46ields(ObjectInputStream.java:19=
90) =20
> at =20
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915) =20
> at =20
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:179=
8) =20
> at =20
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350) =20
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370) =20
> at =20
> akka.serialization.JavaSerializer=24=24anonfun=241.apply(Serializer.sca=
la:136) =20
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57) =20
> at =20
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136) =20
> at =20
> akka.serialization.Serialization=24=24anonfun=24deserialize=241.apply(S=
erialization.scala:104) =20
> at scala.util.Try=24.apply(Try.scala:161) =20
> at =20
> akka.serialization.Serialization.deserialize(Serialization.scala:98) =20
> at =20
> akka.remote.MessageSerializer=24.deserialize(MessageSerializer.scala:23=
) =20
> at =20
> akka.remote.DefaultMessageDispatcher.payload=24lzycompute=241(Endpoint.=
scala:58) =20
> at akka.remote.DefaultMessageDispatcher.payload=241(Endpoint.scala:58) =
=20
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76) =20
> at =20
> akka.remote.EndpointReader=24=24anonfun=24receive=242.applyOrElse(Endpo=
int.scala:937) =20
> at akka.actor.Actor=24class.aroundReceive(Actor.scala:465) =20
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415) =20
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) =20
> at akka.actor.ActorCell.invoke(ActorCell.scala:487) =20
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) =20
> at akka.dispatch.Mailbox.run(Mailbox.scala:220) =20
> at =20
> akka.dispatch.=46orkJoinExecutorConfigurator=24Akka=46orkJoinTask.exec(=
AbstractDispatcher.scala:393) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinTask.doExec(=46orkJoinTask.java:260=
) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinPool=24WorkQueue.runTask(=46orkJoin=
Pool.java:1339) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinPool.runWorker(=46orkJoinPool.java:=
1979) =20
> at =20
> scala.concurrent.forkjoin.=46orkJoinWorkerThread.run(=46orkJoinWorkerTh=
read.java:107) =20
> 14/10/25 09:13:04 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 3 =20
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 3 =20
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 3 =20
> 14/10/25 09:13:37 IN=46O AppClient=24ClientActor: Executor updated: =20
> app-20141025091012-0002/3 is now EXITED (Command exited with code 1) =20
> 14/10/25 09:13:37 IN=46O SparkDeploySchedulerBackend: Executor =20
> app-20141025091012-0002/3 removed: Command exited with code 1 =20
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove no=
n =20
> existant executor 3 =20
> 14/10/25 09:13:37 IN=46O AppClient=24ClientActor: Executor added: =20
> app-20141025091012-0002/4 on worker-20141025170311-DEV-02.SpringB.GZ-35=
162 =20
> (DEV-02.SpringB.GZ:35162) with 2 cores =20
> 14/10/25 09:13:37 IN=46O SparkDeploySchedulerBackend: Granted executor =
ID =20
> app-20141025091012-0002/4 on hostPort DEV-02.SpringB.GZ:35162 with 2 co=
res, =20
> 512.0 MB RAM =20
> 14/10/25 09:13:37 IN=46O AppClient=24ClientActor: Executor updated: =20
> app-20141025091012-0002/4 is now LOADING =20
> 14/10/25 09:13:38 IN=46O AppClient=24ClientActor: Executor updated: =20
> app-20141025091012-0002/4 is now RUNNING =20
> 14/10/25 09:13:40 IN=46O SparkDeploySchedulerBackend: Registered execut=
or: =20
> Actor=5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ (mailto:sparkExecu=
tor=40DEV-02.SpringB.GZ):56019/user/Executor=231354626597=5D =20
> with ID 4 =20
> 14/10/25 09:13:40 WARN ReliableDeliverySupervisor: Association with rem=
ote =20
> system =5Bakka.tcp://sparkExecutor=40DEV-02.SpringB.GZ (mailto:sparkExe=
cutor=40DEV-02.SpringB.GZ):56019=5D has failed, =20
> address is now gated for =5B5000=5D ms. Reason is: =20
> =5Borg.apache.spark.storage.BlockManagerId; local class incompatible: s=
tream =20
> classdesc serialVersionUID =3D 2439208141545036836, local class =20
> serialVersionUID =3D 4657685702603429489=5D. =20
> 14/10/25 09:13:40 ERROR TaskSchedulerImpl: Lost executor 4 on =20
> DEV-02.SpringB.GZ: remote Akka client disassociated =20
> 14/10/25 09:13:40 IN=46O DAGScheduler: Executor lost: 4 (epoch 3) =20
> 14/10/25 09:13:40 IN=46O BlockManagerMasterActor: Trying to remove exec=
utor 4 =20
> from BlockManagerMaster. =20
> 14/10/25 09:13:40 IN=46O BlockManagerMaster: Removed 4 successfully in =
=20
> removeExecutor =20
> =20
> =20



--544affe9_257130a3_a51--


From dev-return-9981-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 01:31:56 2014
Return-Path: <dev-return-9981-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9702917EA5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 01:31:56 +0000 (UTC)
Received: (qmail 16714 invoked by uid 500); 25 Oct 2014 01:31:55 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16634 invoked by uid 500); 25 Oct 2014 01:31:55 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16622 invoked by uid 99); 25 Oct 2014 01:31:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:31:55 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of qiuzhuang.lian@gmail.com designates 209.85.220.179 as permitted sender)
Received: from [209.85.220.179] (HELO mail-vc0-f179.google.com) (209.85.220.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 01:31:26 +0000
Received: by mail-vc0-f179.google.com with SMTP id hy4so885704vcb.10
        for <dev@spark.apache.org>; Fri, 24 Oct 2014 18:31:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=r5yZX8yKG7iJYDLsRKUEUSs1FtoobN+Eksm1ArIVj8M=;
        b=XUPdecCInvcJP+WTUYBKOIHCnKAXgypotfO9A4Lj9MtT4We0M1hHxfZ9xwYjuxMlMk
         saNa1e3e3FDMAL5VPHcSdMQe7R/ckKrSKVTV8iO8JS7zmTrkPzGxjr721rchNsZZN+1+
         1Ym4ol7urNFzbAVNYJU7bx+7GwamNDLAuCMq/rKu49DHYWbjUPpIRF9BRZU7C09PUE0h
         1RM+tx7DCpSTQg6X5zwr6h/vg11+5UswPBeWVuRRJp7GhHbhquEC6xL0JfvdqeuhBfXm
         oohu5ecTYTHVA8wK/gq9tIczdsw6AlslQU4tYTjEGOR8Vj/76aRwwRVsHKswMwS+28FZ
         RJvw==
MIME-Version: 1.0
X-Received: by 10.221.4.73 with SMTP id ob9mr5321889vcb.13.1414200684728; Fri,
 24 Oct 2014 18:31:24 -0700 (PDT)
Received: by 10.221.7.132 with HTTP; Fri, 24 Oct 2014 18:31:24 -0700 (PDT)
In-Reply-To: <D44752A0A14741EF843C0545D2B5E036@gmail.com>
References: <CABKvOWsH-JqzkVK5RoYXAn7q_jOQ3m7iy+7MYCOmTXgjo+i7pw@mail.gmail.com>
	<etPan.544afb7a.25e45d32.10a@joshs-mbp>
	<D44752A0A14741EF843C0545D2B5E036@gmail.com>
Date: Sat, 25 Oct 2014 09:31:24 +0800
Message-ID: <CABKvOWu6zihuVQcRKXESXZ8LbJJeSGtn7nHGjWUrZJJQswAvZQ@mail.gmail.com>
Subject: Re: serialVersionUID incompatible error in class BlockManagerId
From: Qiuzhuang Lian <qiuzhuang.lian@gmail.com>
To: Nan Zhu <zhunanmcgill@gmail.com>
Cc: Josh Rosen <rosenville@gmail.com>, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=089e011605247458b9050635413d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011605247458b9050635413d
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

After I do a clean rebuild. It works now.

Thanks,
Qiuzhuang

On Sat, Oct 25, 2014 at 9:42 AM, Nan Zhu <zhunanmcgill@gmail.com> wrote:

>  According to my experience, there are more issues rather than
> BlockManager when you try to run spark application whose build version is
> different with your cluster=E2=80=A6.
>
> I once tried to make jdbc server build with branch-jdbc-1.0 run with a
> branch-1.0 cluster=E2=80=A6no workaround exits=E2=80=A6just had to replac=
e cluster jar with
> branch-jdbc-1.0 jar file=E2=80=A6..
>
> Best,
>
> --
> Nan Zhu
>
> On Friday, October 24, 2014 at 9:23 PM, Josh Rosen wrote:
>
> Are all processes (Master, Worker, Executors, Driver) running the same
> Spark build?  This error implies that you=E2=80=99re seeing protocol / bi=
nary
> incompatibilities between your Spark driver and cluster.
>
> Spark is API-compatibile across the 1.x series, but we don=E2=80=99t make=
 binary
> link-level compatibility guarantees:
> https://cwiki.apache.org/confluence/display/SPARK/Spark+Versioning+Policy=
.
> This means that your Spark driver=E2=80=99s runtime classpath should use =
the same
> version of Spark that=E2=80=99s installed on your cluster.  You can compi=
le against
> a different API-compatible version of Spark, but the runtime versions mus=
t
> match across all components.
>
> To fix this issue, I=E2=80=99d check that you=E2=80=99ve run the =E2=80=
=9Cpackage=E2=80=9D and =E2=80=9Cassembly=E2=80=9D
> phases and that your Spark cluster is using this updated version.
>
> - Josh
>
> On October 24, 2014 at 6:17:26 PM, Qiuzhuang Lian (
> qiuzhuang.lian@gmail.com) wrote:
>
> Hi,
>
> I update git today and when connecting to spark cluster, I got
> the serialVersionUID incompatible error in class BlockManagerId.
>
> Here is the log,
>
> Shouldn't we better give BlockManagerId a constant serialVersionUID avoid
> this?
>
> Thanks,
> Qiuzhuang
>
> scala> val rdd =3D sc.parparallelize(1 to 100014/10/25 09:10:48 ERROR
> Remoting: org.apache.spark.storage.BlockManagerId; local class
> incompatible: stream classdesc serialVersionUID =3D 2439208141545036836,
> local class serialVersionUID =3D 4657685702603429489
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> at
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
> at
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
> at
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at
> java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
> at
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> at
> akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
> at
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
> at
> akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serializati=
on.scala:104)
>
> at scala.util.Try$.apply(Try.scala:161)
> at
> akka.serialization.Serialization.deserialize(Serialization.scala:98)
> at
> akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
> at
> akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:=
58)
>
> at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
> at
> akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:=
937)
>
> at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
> at akka.actor.ActorCell.invoke(ActorCell.scala:487)
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
> at akka.dispatch.Mailbox.run(Mailbox.scala:220)
> at
> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(Abstract=
Dispatcher.scala:393)
>
> at
> scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
> at
> scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.jav=
a:1339)
>
> at
> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> at
> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.j=
ava:107)
>
> 14/10/25 09:10:48 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 0014/10/25 09:11:21 ERROR Remoting:
> org.apache.spark.storage.BlockManagerId; local class incompatible: stream
> classdesc serialVersionUID =3D 2439208141545036836, local class
> serialVersionUID =3D 4657685702603429489
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> at
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
> at
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
> at
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at
> java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
> at
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> at
> akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
> at
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
> at
> akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serializati=
on.scala:104)
>
> at scala.util.Try$.apply(Try.scala:161)
> at
> akka.serialization.Serialization.deserialize(Serialization.scala:98)
> at
> akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
> at
> akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:=
58)
>
> at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
> at
> akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:=
937)
>
> at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
> at akka.actor.ActorCell.invoke(ActorCell.scala:487)
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
> at akka.dispatch.Mailbox.run(Mailbox.scala:220)
> at
> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(Abstract=
Dispatcher.scala:393)
>
> at
> scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
> at
> scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.jav=
a:1339)
>
> at
> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> at
> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.j=
ava:107)
>
> 14/10/25 09:11:21 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 14/10/25 09:11:54 INFO SparkDeploySchedulerBackend: Registered executor:
> Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006/user/Executor#-141=
0691203]
>
> with ID 1
> 14/10/25 09:11:54 INFO DAGScheduler: Host added was in lost list earlier:
> DEV-02.SpringB.GZ
> 14/10/25 09:11:55 ERROR TaskSchedulerImpl: Lost executor 1 on
> DEV-02.SpringB.GZ: remote Akka client disassociated
> 14/10/25 09:11:55 WARN ReliableDeliverySupervisor: Association with remot=
e
> system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006] has failed,
> address is now gated for [5000] ms. Reason is: [Association failed with
> [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50006]].
> 14/10/25 09:11:55 INFO DAGScheduler: Executor lost: 1 (epoch 1)
> 14/10/25 09:11:55 INFO BlockManagerMasterActor: Trying to remove executor
> 1
> from BlockManagerMaster.
> 14/10/25 09:11:55 INFO BlockManagerMaster: Removed 1 successfully in
> removeExecutor
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/1 is now EXITED (Command exited with code 1)
> 14/10/25 09:11:55 INFO SparkDeploySchedulerBackend: Executor
> app-20141025091012-0002/1 removed: Command exited with code 1
> 14/10/25 09:11:55 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 1
> 14/10/25 09:11:55 INFO AppClient$ClientActor: Executor added:
> app-20141025091012-0002/3 on worker-20141025170311-DEV-02.SpringB.GZ-3516=
2
> (DEV-02.SpringB.GZ:35162) with 2 cores
> 14/10/25 09:11:55 INFO SparkDeploySchedulerBackend: Granted executor ID
> app-20141025091012-0002/3 on hostPort DEV-02.SpringB.GZ:35162 with 2
> cores,
> 512.0 MB RAM
> 14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/3 is now LOADING
> 14/10/25 09:11:55 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/3 is now RUNNING
> 14/10/25 09:11:58 INFO SparkDeploySchedulerBackend: Registered executor:
> Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50740/user/Executor#1229=
699385]
>
> with ID 3
> 14/10/25 09:11:58 WARN ReliableDeliverySupervisor: Association with remot=
e
> system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:50740] has failed,
> address is now gated for [5000] ms. Reason is:
> [org.apache.spark.storage.BlockManagerId; local class incompatible: strea=
m
> classdesc serialVersionUID =3D 2439208141545036836, local class
> serialVersionUID =3D 4657685702603429489].
> 14/10/25 09:11:58 ERROR TaskSchedulerImpl: Lost executor 3 on
> DEV-02.SpringB.GZ: remote Akka client disassociated
> 14/10/25 09:11:58 INFO DAGScheduler: Executor lost: 3 (epoch 2)
> 14/10/25 09:11:58 INFO BlockManagerMasterActor: Trying to remove executor
> 3
> from BlockManagerMaster.
> 14/10/25 09:11:58 INFO BlockManagerMaster: Removed 3 successfully in
> removeExecutor
> 14/10/25 09:12:31 ERROR Remoting: org.apache.spark.storage.BlockManagerId=
;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> at
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
> at
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
> at
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at
> java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
> at
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> at
> akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
> at
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
> at
> akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serializati=
on.scala:104)
>
> at scala.util.Try$.apply(Try.scala:161)
> at
> akka.serialization.Serialization.deserialize(Serialization.scala:98)
> at
> akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
> at
> akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:=
58)
>
> at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
> at
> akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:=
937)
>
> at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
> at akka.actor.ActorCell.invoke(ActorCell.scala:487)
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
> at akka.dispatch.Mailbox.run(Mailbox.scala:220)
> at
> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(Abstract=
Dispatcher.scala:393)
>
> at
> scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
> at
> scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.jav=
a:1339)
>
> at
> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> at
> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.j=
ava:107)
>
> 14/10/25 09:12:31 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:04 ERROR Remoting: org.apache.spark.storage.BlockManagerId=
;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> java.io.InvalidClassException: org.apache.spark.storage.BlockManagerId;
> local class incompatible: stream classdesc serialVersionUID =3D
> 2439208141545036836, local class serialVersionUID =3D 4657685702603429489
> at
> java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:617)
> at
> java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1622)
> at
> java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at
> java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
> at
> java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
> at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
> at
> java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
> at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
> at
> akka.serialization.JavaSerializer$$anonfun$1.apply(Serializer.scala:136)
> at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
> at
> akka.serialization.JavaSerializer.fromBinary(Serializer.scala:136)
> at
> akka.serialization.Serialization$$anonfun$deserialize$1.apply(Serializati=
on.scala:104)
>
> at scala.util.Try$.apply(Try.scala:161)
> at
> akka.serialization.Serialization.deserialize(Serialization.scala:98)
> at
> akka.remote.MessageSerializer$.deserialize(MessageSerializer.scala:23)
> at
> akka.remote.DefaultMessageDispatcher.payload$lzycompute$1(Endpoint.scala:=
58)
>
> at akka.remote.DefaultMessageDispatcher.payload$1(Endpoint.scala:58)
> at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:76)
> at
> akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:=
937)
>
> at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
> at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
> at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
> at akka.actor.ActorCell.invoke(ActorCell.scala:487)
> at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
> at akka.dispatch.Mailbox.run(Mailbox.scala:220)
> at
> akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(Abstract=
Dispatcher.scala:393)
>
> at
> scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
> at
> scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.jav=
a:1339)
>
> at
> scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
> at
> scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.j=
ava:107)
>
> 14/10/25 09:13:04 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:37 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/3 is now EXITED (Command exited with code 1)
> 14/10/25 09:13:37 INFO SparkDeploySchedulerBackend: Executor
> app-20141025091012-0002/3 removed: Command exited with code 1
> 14/10/25 09:13:37 ERROR SparkDeploySchedulerBackend: Asked to remove non
> existant executor 3
> 14/10/25 09:13:37 INFO AppClient$ClientActor: Executor added:
> app-20141025091012-0002/4 on worker-20141025170311-DEV-02.SpringB.GZ-3516=
2
> (DEV-02.SpringB.GZ:35162) with 2 cores
> 14/10/25 09:13:37 INFO SparkDeploySchedulerBackend: Granted executor ID
> app-20141025091012-0002/4 on hostPort DEV-02.SpringB.GZ:35162 with 2
> cores,
> 512.0 MB RAM
> 14/10/25 09:13:37 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/4 is now LOADING
> 14/10/25 09:13:38 INFO AppClient$ClientActor: Executor updated:
> app-20141025091012-0002/4 is now RUNNING
> 14/10/25 09:13:40 INFO SparkDeploySchedulerBackend: Registered executor:
> Actor[akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:56019/user/Executor#1354=
626597]
>
> with ID 4
> 14/10/25 09:13:40 WARN ReliableDeliverySupervisor: Association with remot=
e
> system [akka.tcp://sparkExecutor@DEV-02.SpringB.GZ:56019] has failed,
> address is now gated for [5000] ms. Reason is:
> [org.apache.spark.storage.BlockManagerId; local class incompatible: strea=
m
> classdesc serialVersionUID =3D 2439208141545036836, local class
> serialVersionUID =3D 4657685702603429489].
> 14/10/25 09:13:40 ERROR TaskSchedulerImpl: Lost executor 4 on
> DEV-02.SpringB.GZ: remote Akka client disassociated
> 14/10/25 09:13:40 INFO DAGScheduler: Executor lost: 4 (epoch 3)
> 14/10/25 09:13:40 INFO BlockManagerMasterActor: Trying to remove executor
> 4
> from BlockManagerMaster.
> 14/10/25 09:13:40 INFO BlockManagerMaster: Removed 4 successfully in
> removeExecutor
>
>
>

--089e011605247458b9050635413d--

From dev-return-9982-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 13:03:52 2014
Return-Path: <dev-return-9982-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5F8EE178D8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 13:03:52 +0000 (UTC)
Received: (qmail 39300 invoked by uid 500); 25 Oct 2014 13:03:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39221 invoked by uid 500); 25 Oct 2014 13:03:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39210 invoked by uid 99); 25 Oct 2014 13:03:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 13:03:50 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of salexln@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 13:03:25 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <salexln@gmail.com>)
	id 1Xi107-0001DF-SC
	for dev@spark.incubator.apache.org; Sat, 25 Oct 2014 06:03:23 -0700
Date: Sat, 25 Oct 2014 06:03:23 -0700 (PDT)
From: salexln <salexln@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1414242203814-8959.post@n3.nabble.com>
Subject: Matix operations in Scala \ Spark
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi guys,

I'm working on the implementation of the FuzzyCMeans algorithm (Jira
https://issues.apache.org/jira/browse/SPARK-2344)
and I need to use some operations on Matrices (norm & subtraction)

I could not find any Scala\ Spark Matrix class that will support these
actions.

Should I implement the Matrix as a two dimensional array and make my own
code for the norm & subtraction ?







--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Matix-operations-in-Scala-Spark-tp8959.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9983-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 14:12:06 2014
Return-Path: <dev-return-9983-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2A80D17A1B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 14:12:06 +0000 (UTC)
Received: (qmail 5066 invoked by uid 500); 25 Oct 2014 14:12:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5009 invoked by uid 500); 25 Oct 2014 14:12:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4997 invoked by uid 99); 25 Oct 2014 14:12:04 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 14:12:04 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of benewu@gmail.com designates 209.85.220.48 as permitted sender)
Received: from [209.85.220.48] (HELO mail-pa0-f48.google.com) (209.85.220.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 14:11:59 +0000
Received: by mail-pa0-f48.google.com with SMTP id ey11so2752375pad.21
        for <dev@spark.incubator.apache.org>; Sat, 25 Oct 2014 07:11:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=references:mime-version:in-reply-to:content-type
         :content-transfer-encoding:message-id:cc:from:subject:date:to;
        bh=SWyUsnBtJuwEQ8FoQtt4KhHaRGKQfxA9Vqpsxcj+llM=;
        b=gGagDi0iELGNN7iE7ET0WMc6LJyBoMbBCC8ZehIUHj7vh/S+gkP5XIt1kqVo5wZ6/F
         RM7ImEe9xrIVvTnn4HUl621aULpBQV1MT6QmVGQxeWz3SguDfh3YuGM4+O9eyCC6IsNY
         4X5KfuXI2PTMTcww3AOLRc/AHlXRV6ogL9srlqye9wdWc1uqL/k9dq1UJi48MrgVvGoN
         PVmbt0gcreAfDMQu22HzlhfbwhINrVTBV9XHMvzmeZ2xrMyH0bV1Pb/Qw6+E3sqv0jOf
         gyoiPAwvi4wYMB17yDQUlkDelvmJ1VF+2GyGj5+CCzUBNg8+8IpNnmATjJ5+lhmwjnPd
         00FA==
X-Received: by 10.66.138.47 with SMTP id qn15mr11574814pab.82.1414246298927;
        Sat, 25 Oct 2014 07:11:38 -0700 (PDT)
Received: from [10.0.0.7] ([59.174.50.219])
        by mx.google.com with ESMTPSA id qp9sm6347150pbc.31.2014.10.25.07.11.36
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 25 Oct 2014 07:11:37 -0700 (PDT)
References: <1414242203814-8959.post@n3.nabble.com>
Mime-Version: 1.0 (1.0)
In-Reply-To: <1414242203814-8959.post@n3.nabble.com>
Content-Type: text/plain;
	charset=gb2312
Content-Transfer-Encoding: quoted-printable
Message-Id: <FA14516C-0846-4DF4-AA19-4292BCFBAA96@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
X-Mailer: iPhone Mail (12B411)
From: Xuefeng Wu <benewu@gmail.com>
Subject: Re: Matix operations in Scala \ Spark
Date: Sat, 25 Oct 2014 22:11:29 +0800
To: salexln <salexln@gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org

how about non/spire or twitter/scalding


Yours, Xuefeng Wu =CE=E2=D1=A9=B7=E5 =BE=B4=C9=CF

> On 2014=C4=EA10=D4=C225=C8=D5, at =CF=C2=CE=E79:03, salexln <salexln@gmail=
.com> wrote:
>=20
> Hi guys,
>=20
> I'm working on the implementation of the FuzzyCMeans algorithm (Jira
> https://issues.apache.org/jira/browse/SPARK-2344)
> and I need to use some operations on Matrices (norm & subtraction)
>=20
> I could not find any Scala\ Spark Matrix class that will support these
> actions.
>=20
> Should I implement the Matrix as a two dimensional array and make my own
> code for the norm & subtraction ?
>=20
>=20
>=20
>=20
>=20
>=20
>=20
> --
> View this message in context: http://apache-spark-developers-list.1001551.=
n3.nabble.com/Matix-operations-in-Scala-Spark-tp8959.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.=
com.
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9984-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sat Oct 25 16:59:37 2014
Return-Path: <dev-return-9984-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0C45D17C92
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sat, 25 Oct 2014 16:59:37 +0000 (UTC)
Received: (qmail 31387 invoked by uid 500); 25 Oct 2014 16:59:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31309 invoked by uid 500); 25 Oct 2014 16:59:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31282 invoked by uid 99); 25 Oct 2014 16:59:35 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 16:59:35 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of concretevitamin@gmail.com designates 209.85.220.51 as permitted sender)
Received: from [209.85.220.51] (HELO mail-pa0-f51.google.com) (209.85.220.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sat, 25 Oct 2014 16:59:31 +0000
Received: by mail-pa0-f51.google.com with SMTP id kq14so444174pab.24
        for <dev@spark.incubator.apache.org>; Sat, 25 Oct 2014 09:58:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:references:from:date:message-id:subject:to:cc
         :content-type;
        bh=THl3OENae4IC8HPSCeREmg8eTiIybdNqOnRPm1RNVt8=;
        b=xAAV8RTDyrzmiZBO+zbSj/PsUx3QuP4ccw+sUyGoY89p3yYT4YsmoIZ21J2I9fl2F1
         3n2sZK3LyJ6sjIsMp37FaPb2omNQpE0KJmxAGeqEphCi7Gsp00i5uhNTKIFSvOW1ZSoW
         nuG1ziS2ln1lswAIFTulzvwHLBnDvgwz1ge+BooG+RxnuKCzC22YbNglEvEaCFXvy5Ms
         vbhkBiO4kfZgJllKM0iAYNuTJVKO5ZQiXKpPuh/HgmwPc+9w8J6UR/CFklh//0n5Iw2m
         sg8/+HWL/u+6IHGyrrwRGyguhW0OPg/y2tNi8LHkgppiI+1IZastacco/5MhHZSXPp/3
         2rIg==
X-Received: by 10.67.30.162 with SMTP id kf2mr12513332pad.102.1414256305938;
 Sat, 25 Oct 2014 09:58:25 -0700 (PDT)
MIME-Version: 1.0
References: <1414242203814-8959.post@n3.nabble.com> <FA14516C-0846-4DF4-AA19-4292BCFBAA96@gmail.com>
From: Zongheng Yang <zongheng.y@gmail.com>
Date: Sat, 25 Oct 2014 16:58:25 +0000
Message-ID: <CAG2+eohhLLBKQRmrPFoR9dXma9aidJv9Yyt=jUkiYibOCCrWCQ@mail.gmail.com>
Subject: Re: Matix operations in Scala \ Spark
To: Xuefeng Wu <benewu@gmail.com>, salexln <salexln@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11343da0bca90a05064234eb
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11343da0bca90a05064234eb
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

We recently released a research prototype of a lightweight matrix library
for Spark here: https://github.com/amplab/ml-matrix which does support norm
and subtraction. Feel free to base your implementation on top of it.

Zongheng
On Sat, Oct 25, 2014 at 07:12 Xuefeng Wu <benewu@gmail.com> wrote:

> how about non/spire or twitter/scalding
>
>
> Yours, Xuefeng Wu =E5=90=B4=E9=9B=AA=E5=B3=B0 =E6=95=AC=E4=B8=8A
>
> > On 2014=E5=B9=B410=E6=9C=8825=E6=97=A5, at =E4=B8=8B=E5=8D=889:03, sale=
xln <salexln@gmail.com> wrote:
> >
> > Hi guys,
> >
> > I'm working on the implementation of the FuzzyCMeans algorithm (Jira
> > https://issues.apache.org/jira/browse/SPARK-2344)
> > and I need to use some operations on Matrices (norm & subtraction)
> >
> > I could not find any Scala\ Spark Matrix class that will support these
> > actions.
> >
> > Should I implement the Matrix as a two dimensional array and make my ow=
n
> > code for the norm & subtraction ?
> >
> >
> >
> >
> >
> >
> >
> > --
> > View this message in context: http://apache-spark-
> developers-list.1001551.n3.nabble.com/Matix-operations-
> in-Scala-Spark-tp8959.html
> > Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a11343da0bca90a05064234eb--

From dev-return-9985-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 02:49:30 2014
Return-Path: <dev-return-9985-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C3A18175FE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 02:49:30 +0000 (UTC)
Received: (qmail 31295 invoked by uid 500); 26 Oct 2014 02:49:28 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31218 invoked by uid 500); 26 Oct 2014 02:49:28 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 30071 invoked by uid 99); 26 Oct 2014 02:49:28 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 02:49:28 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of rnowling@gmail.com designates 74.125.82.47 as permitted sender)
Received: from [74.125.82.47] (HELO mail-wg0-f47.google.com) (74.125.82.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 02:49:24 +0000
Received: by mail-wg0-f47.google.com with SMTP id x13so3370590wgg.18
        for <multiple recipients>; Sat, 25 Oct 2014 19:49:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=LBil/80NEORMxCND2TJlGnJYMSh0ELDfPNi8Qs5qVBM=;
        b=ou3qS7KqwHP+qaX+QdWDffzxuP71QtSRaYT2UzYuUQjTVAL3+EiYwT6q1zF91lyvo4
         tBCDSuqAMqCnSQI4ndasQk8MRSIRYDaHqqtNAPhGZ6S3CR6sfyB7kyq7QkHQ1jJZu52C
         L1FrDAB7GiCPIavJxz8RCiJmsROzhDFnWGLBA2kw2vyBUJxrv7g9aWfHHuoAYlou4q5L
         oygfyn42qV7LZMoBJtyBHdxRmqb7L44LHtSP29s0soPi/Ewk+VDh2GW2P6mfc2+IYf/U
         6+XhxK5fWLKEpkAAr8xfd1GVd/S1ltxt6NpCXCqCCUjF2lAmtZ5+FXbz+JbcBpbRor9v
         ev2A==
MIME-Version: 1.0
X-Received: by 10.194.100.98 with SMTP id ex2mr13945479wjb.48.1414291742561;
 Sat, 25 Oct 2014 19:49:02 -0700 (PDT)
Received: by 10.194.37.225 with HTTP; Sat, 25 Oct 2014 19:49:02 -0700 (PDT)
In-Reply-To: <CAN6Vra2NaUTobn7s1BL=HcNgedScEb0Yuui84Y1Rc+dXpOrQGg@mail.gmail.com>
References: <CAHwrdDE=Un0mfbeG2D9dqHHyzKAZw2LrgHXc_Py47i5OFqXc8A@mail.gmail.com>
	<CAAOnQ7tkPYTKwAx=6J_pz1=TXC0TE57JvUZ=UJbg5+2fvDr4Vg@mail.gmail.com>
	<CAHwrdDF4nkXyg2X4U6CtgkAcrc=PKxkEr+6W4J4e=cow-kfoiQ@mail.gmail.com>
	<CAAOnQ7sL_rusQqWthLARKCoWep9Yj4jGGJk8xGOcVSrqPqT-9w@mail.gmail.com>
	<CACA1tWLEy1R8Wud6HZVvDJ1j=QTnwAnwx9KDViRxH1U+kHb9hw@mail.gmail.com>
	<CAAOnQ7t_e77Kw5iVgRGeSJeBWb70c5b=1Vm23H_5CqgBX=vy+Q@mail.gmail.com>
	<CAN6Vra2NaUTobn7s1BL=HcNgedScEb0Yuui84Y1Rc+dXpOrQGg@mail.gmail.com>
Date: Sat, 25 Oct 2014 22:49:02 -0400
Message-ID: <CADtDQQK-wv9XDeEb-qh3biLtJF0a46A5KuQmt2NJZwvWUhgMDw@mail.gmail.com>
Subject: Re: Multitenancy in Spark - within/across spark context
From: RJ Nowling <rnowling@gmail.com>
To: Evan Chan <velvia.github@gmail.com>
Cc: Marcelo Vanzin <vanzin@cloudera.com>, Jianshi Huang <jianshi.huang@gmail.com>, 
	"dev@spark.apache.org" <dev@spark.apache.org>, "user@spark.apache.org" <user@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160be3eec9bbf05064a7452
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160be3eec9bbf05064a7452
Content-Type: text/plain; charset=UTF-8

Ashwin,

What is your motivation for needing to share RDDs between jobs? Optimizing
for reusing data across jobs?

If so, you may want to look into Tachyon. My understanding is that Tachyon
acts like a caching layer and you can designate when data will be reused in
multiple jobs so it know to keep that in memory or local disk for faster
access. But my knowledge of tachyon is second hand so forgive me if I have
it wrong :)

RJ

On Friday, October 24, 2014, Evan Chan <velvia.github@gmail.com> wrote:

> Ashwin,
>
> I would say the strategies in general are:
>
> 1) Have each user submit separate Spark app (each its own Spark
> Context), with its own resource settings, and share data through HDFS
> or something like Tachyon for speed.
>
> 2) Share a single spark context amongst multiple users, using fair
> scheduler.  This is sort of like having a Hadoop resource pool.    It
> has some obvious HA/SPOF issues, namely that if the context dies then
> every user using it is also dead.   Also, sharing RDDs in cached
> memory has the same resiliency problems, namely that if any executor
> dies then Spark must recompute / rebuild the RDD (it tries to only
> rebuild the missing part, but sometimes it must rebuild everything).
>
> Job server can help with 1 or 2, 2 in particular.  If you have any
> questions about job server, feel free to ask at the spark-jobserver
> google group.   I am the maintainer.
>
> -Evan
>
>
> On Thu, Oct 23, 2014 at 1:06 PM, Marcelo Vanzin <vanzin@cloudera.com
> <javascript:;>> wrote:
> > You may want to take a look at
> https://issues.apache.org/jira/browse/SPARK-3174.
> >
> > On Thu, Oct 23, 2014 at 2:56 AM, Jianshi Huang <jianshi.huang@gmail.com
> <javascript:;>> wrote:
> >> Upvote for the multitanency requirement.
> >>
> >> I'm also building a data analytic platform and there'll be multiple
> users
> >> running queries and computations simultaneously. One of the paint point
> is
> >> control of resource size. Users don't really know how much nodes they
> need,
> >> they always use as much as possible... The result is lots of wasted
> resource
> >> in our Yarn cluster.
> >>
> >> A way to 1) allow multiple spark context to share the same resource or
> 2)
> >> add dynamic resource management for Yarn mode is very much wanted.
> >>
> >> Jianshi
> >>
> >> On Thu, Oct 23, 2014 at 5:36 AM, Marcelo Vanzin <vanzin@cloudera.com
> <javascript:;>> wrote:
> >>>
> >>> On Wed, Oct 22, 2014 at 2:17 PM, Ashwin Shankar
> >>> <ashwinshankar77@gmail.com <javascript:;>> wrote:
> >>> >> That's not something you might want to do usually. In general, a
> >>> >> SparkContext maps to a user application
> >>> >
> >>> > My question was basically this. In this page in the official doc,
> under
> >>> > "Scheduling within an application" section, it talks about multiuser
> and
> >>> > fair sharing within an app. How does multiuser within an application
> >>> > work(how users connect to an app,run their stuff) ? When would I
> want to
> >>> > use
> >>> > this ?
> >>>
> >>> I see. The way I read that page is that Spark supports all those
> >>> scheduling options; but Spark doesn't give you the means to actually
> >>> be able to submit jobs from different users to a running SparkContext
> >>> hosted on a different process. For that, you'll need something like
> >>> the job server that I referenced before, or write your own framework
> >>> for supporting that.
> >>>
> >>> Personally, I'd use the information on that page when dealing with
> >>> concurrent jobs in the same SparkContext, but still restricted to the
> >>> same user. I'd avoid trying to create any application where a single
> >>> SparkContext is trying to be shared by multiple users in any way.
> >>>
> >>> >> As far as I understand, this will cause executors to be killed,
> which
> >>> >> means that Spark will start retrying tasks to rebuild the data that
> >>> >> was held by those executors when needed.
> >>> >
> >>> > I basically wanted to find out if there were any "gotchas" related to
> >>> > preemption on Spark. Things like say half of an application's
> executors
> >>> > got
> >>> > preempted say while doing reduceByKey, will the application progress
> >>> > with
> >>> > the remaining resources/fair share ?
> >>>
> >>> Jobs should still make progress as long as at least one executor is
> >>> available. The gotcha would be the one I mentioned, where Spark will
> >>> fail your job after "x" executors failed, which might be a common
> >>> occurrence when preemption is enabled. That being said, it's a
> >>> configurable option, so you can set "x" to a very large value and your
> >>> job should keep on chugging along.
> >>>
> >>> The options you'd want to take a look at are: spark.task.maxFailures
> >>> and spark.yarn.max.executor.failures
> >>>
> >>> --
> >>> Marcelo
> >>>
> >>> ---------------------------------------------------------------------
> >>> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org
> <javascript:;>
> >>> For additional commands, e-mail: user-help@spark.apache.org
> <javascript:;>
> >>>
> >>
> >>
> >>
> >> --
> >> Jianshi Huang
> >>
> >> LinkedIn: jianshi
> >> Twitter: @jshuang
> >> Github & Blog: http://huangjs.github.com/
> >
> >
> >
> > --
> > Marcelo
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org <javascript:;>
> > For additional commands, e-mail: dev-help@spark.apache.org
> <javascript:;>
> >
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: user-unsubscribe@spark.apache.org <javascript:;>
> For additional commands, e-mail: user-help@spark.apache.org <javascript:;>
>
>

-- 
em rnowling@gmail.com
c 954.496.2314

--089e0160be3eec9bbf05064a7452--

From dev-return-9986-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 09:45:30 2014
Return-Path: <dev-return-9986-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 486C517AD0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 09:45:30 +0000 (UTC)
Received: (qmail 93623 invoked by uid 500); 26 Oct 2014 09:45:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93555 invoked by uid 500); 26 Oct 2014 09:45:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 93543 invoked by uid 99); 26 Oct 2014 09:45:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 09:45:29 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vibhanshugsoc2@gmail.com designates 209.85.217.172 as permitted sender)
Received: from [209.85.217.172] (HELO mail-lb0-f172.google.com) (209.85.217.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 09:45:02 +0000
Received: by mail-lb0-f172.google.com with SMTP id n15so535239lbi.3
        for <dev@spark.apache.org>; Sun, 26 Oct 2014 02:43:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=2tuVK0z4Zm2hnztswXJvp0t+sPT4ZfrMXYMIxmrIO4Y=;
        b=awc7gI61YxNilI/8dtfYIoNGhsUEQq3ewM7K/j3EvBiUuhrLpVnik7KsdzK6lEX9wL
         cIIe2BRJLvvHIE2ZoXLWsBF8757/v99+SoJEK+PF3OByygeyow4fPgLMc/7z+70Y96Z8
         VBaVEsvT4oRCIUsMFl6P4a4VPG3wCiI2cLjPObvtP/Nxfdr7Lwgbzd9tZ6U/5p2f7n1T
         a7hH/ZQvSAPT6FYy6cvCKcnkaV1lvGwvR8m7ho0FgP9xISvgpOzQM8kzLY1hbJsR0vOY
         dpHiDf7nJaz/SM+/4k7vDcnrMuOhhg4vT5BGC2O0Q6z82c45ybaQOc3nR/K0pcVTi7OL
         NqXg==
MIME-Version: 1.0
X-Received: by 10.112.73.103 with SMTP id k7mr15889997lbv.41.1414316611784;
 Sun, 26 Oct 2014 02:43:31 -0700 (PDT)
Received: by 10.25.24.214 with HTTP; Sun, 26 Oct 2014 02:43:31 -0700 (PDT)
Date: Sun, 26 Oct 2014 15:13:31 +0530
Message-ID: <CACuyFYJp36vzVgmv=fh80DkJgz-Qzy=uKWcqDsaMCbzbvVhSgw@mail.gmail.com>
Subject: Potential areas for working
From: Vibhanshu Prasad <vibhanshugsoc2@gmail.com>
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=001a11c32ce43ed4f50506503f8b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c32ce43ed4f50506503f8b
Content-Type: text/plain; charset=UTF-8

Hello everyone,
I am new to the spark developer community,
I want to know what are the areas where currently programming is in
progress. What areas I can work on as a started.

Vibhanshu

--001a11c32ce43ed4f50506503f8b--

From dev-return-9987-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 11:29:10 2014
Return-Path: <dev-return-9987-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F188417BD5
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 11:29:09 +0000 (UTC)
Received: (qmail 55089 invoked by uid 500); 26 Oct 2014 11:29:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55023 invoked by uid 500); 26 Oct 2014 11:29:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54195 invoked by uid 99); 26 Oct 2014 11:29:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 11:29:07 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of srinathsmn@gmail.com designates 209.85.213.175 as permitted sender)
Received: from [209.85.213.175] (HELO mail-ig0-f175.google.com) (209.85.213.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 11:28:42 +0000
Received: by mail-ig0-f175.google.com with SMTP id uq10so3672593igb.14
        for <dev@spark.apache.org>; Sun, 26 Oct 2014 04:28:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=MRGCgS45Jqy9SjILJMeD+33LMG2TW0/z3f0B4CZ9aMU=;
        b=EOUIIxrllq8JkcJh+yKjGJCqrtvpTRD2GcA6nQKxvyxMINRCIQZb15jtWXsNS2uO03
         AL04iInf+quNgwGG20kDD+nBgVE1oHkM+RY/FCI1hphur7dVuzqAl1Fx7lBToDSDoUgR
         MRS0zO7zRoL26HJR5i1PGjpqyLzNuW6v60/7awjwYUDATirmyjFGg+uQtcQN76jYNzfn
         H7KPSHitgTKEt2LmAUpdFRwJd6NGRJKNg3fgmvtZGm84D0HgXcT+69JNqyg7caTnNr6f
         pHOSnHUo/op9EXb9LNhLHLIYDCwGplnYXQMAjcXKO2uoLDZ0/iGitws+FqDyR324DDaw
         x/aQ==
MIME-Version: 1.0
X-Received: by 10.43.141.67 with SMTP id jd3mr13379240icc.24.1414322919307;
 Sun, 26 Oct 2014 04:28:39 -0700 (PDT)
Received: by 10.64.106.5 with HTTP; Sun, 26 Oct 2014 04:28:39 -0700 (PDT)
In-Reply-To: <CACuyFYJp36vzVgmv=fh80DkJgz-Qzy=uKWcqDsaMCbzbvVhSgw@mail.gmail.com>
References: <CACuyFYJp36vzVgmv=fh80DkJgz-Qzy=uKWcqDsaMCbzbvVhSgw@mail.gmail.com>
Date: Sun, 26 Oct 2014 16:58:39 +0530
Message-ID: <CACKkDGGoqp+wG-JVuBeAUZfYe2TwE25iBR04Ge0_4sFn7c2omA@mail.gmail.com>
Subject: Re: Potential areas for working
From: Varadharajan Mukundan <srinathsmn@gmail.com>
To: Vibhanshu Prasad <vibhanshugsoc2@gmail.com>
Cc: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

+1, I'm interested in contributing to Spark SQL and i'm looking for
starter tasks.

On Sun, Oct 26, 2014 at 3:13 PM, Vibhanshu Prasad
<vibhanshugsoc2@gmail.com> wrote:
> Hello everyone,
> I am new to the spark developer community,
> I want to know what are the areas where currently programming is in
> progress. What areas I can work on as a started.
>
> Vibhanshu



-- 
Thanks,
M. Varadharajan

------------------------------------------------

"Experience is what you get when you didn't get what you wanted"
               -By Prof. Randy Pausch in "The Last Lecture"

My Journal :- www.thinkasgeek.wordpress.com

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9988-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 15:07:48 2014
Return-Path: <dev-return-9988-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 966A117F7D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 15:07:48 +0000 (UTC)
Received: (qmail 29653 invoked by uid 500); 26 Oct 2014 15:07:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 29587 invoked by uid 500); 26 Oct 2014 15:07:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 29573 invoked by uid 99); 26 Oct 2014 15:07:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 15:07:47 +0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of duy.huynh.uiv@gmail.com does not designate 216.139.236.26 as permitted sender)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 15:07:21 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <duy.huynh.uiv@gmail.com>)
	id 1XiPPc-00065H-H6
	for dev@spark.incubator.apache.org; Sun, 26 Oct 2014 08:07:20 -0700
Date: Sun, 26 Oct 2014 08:07:20 -0700 (PDT)
From: ll <duy.huynh.uiv@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1414336040472-8965.post@n3.nabble.com>
Subject: best IDE for scala + spark development?
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

i'm new to both scala and spark.  what IDE / dev environment do you find most
productive for writing code in scala with spark?  is it just vim + sbt?  or
does a full IDE like intellij works out better?  thanks!



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9989-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 15:23:38 2014
Return-Path: <dev-return-9989-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DA7FC17FBC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 15:23:38 +0000 (UTC)
Received: (qmail 50406 invoked by uid 500); 26 Oct 2014 15:23:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50331 invoked by uid 500); 26 Oct 2014 15:23:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50319 invoked by uid 99); 26 Oct 2014 15:23:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 15:23:36 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of msubramm@gmail.com designates 74.125.82.41 as permitted sender)
Received: from [74.125.82.41] (HELO mail-wg0-f41.google.com) (74.125.82.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 15:23:31 +0000
Received: by mail-wg0-f41.google.com with SMTP id b13so4070909wgh.24
        for <dev@spark.incubator.apache.org>; Sun, 26 Oct 2014 08:23:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=RqCPrx+eFchDhWbE7FV2weaB0yLBYZPRpDy3WbuhsWU=;
        b=BA/tx/F0k7w4X3T1IbEP/oxM/xKDmMZIi2xj9oTGpg2+FICfInqMdnxKh+IRjDkwZ6
         NOndmWkTZ+bLa258XeqsfhR0QLy6xjbJp2OUspVvAw7Spf+SKXWZn19kzBhX8lOsMrsz
         qmhEr6rt0jE+8jau/x9F4ebT8+QN+u0jyRtJQKE23L8z5edA/cNkA04FyACaLDIH7jhO
         OI+X1Ces5kEP0m1FaUziL3gdhYtNgKicD8ME1HvS6pnrWPZNgrcbxP1hF4cc/iFo5gYM
         d/+I+J+dccWJWwvhgmGTA9StVRNLL80jThg8TK66AXR5NhZAoRqgXNx3bORyctKen1Z6
         YbfA==
MIME-Version: 1.0
X-Received: by 10.180.14.231 with SMTP id s7mr15965180wic.0.1414336990403;
 Sun, 26 Oct 2014 08:23:10 -0700 (PDT)
Received: by 10.194.134.68 with HTTP; Sun, 26 Oct 2014 08:23:10 -0700 (PDT)
In-Reply-To: <1414336040472-8965.post@n3.nabble.com>
References: <1414336040472-8965.post@n3.nabble.com>
Date: Sun, 26 Oct 2014 08:23:10 -0700
Message-ID: <CAN1qEex3+pvZuVB4Z-B=FNDAi14pbd0rJjgmGwK0zycniHVZwA@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
From: Subbu M <msubramm@gmail.com>
To: ll <duy.huynh.uiv@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=f46d040fa004e7dfb8050654fdfa
X-Virus-Checked: Checked by ClamAV on apache.org

--f46d040fa004e7dfb8050654fdfa
Content-Type: text/plain; charset=UTF-8

Eclipse would be a ideal choice for both.
Download and deploy plugins for required things scala+SBT+Spark

On Sun, Oct 26, 2014 at 8:07 AM, ll <duy.huynh.uiv@gmail.com> wrote:

> i'm new to both scala and spark.  what IDE / dev environment do you find
> most
> productive for writing code in scala with spark?  is it just vim + sbt?  or
> does a full IDE like intellij works out better?  thanks!
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--f46d040fa004e7dfb8050654fdfa--

From dev-return-9990-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 16:29:11 2014
Return-Path: <dev-return-9990-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 77D8D172A7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 16:29:11 +0000 (UTC)
Received: (qmail 17957 invoked by uid 500); 26 Oct 2014 16:29:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17884 invoked by uid 500); 26 Oct 2014 16:29:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 17861 invoked by uid 99); 26 Oct 2014 16:29:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 16:29:09 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of javadba@gmail.com designates 209.85.220.178 as permitted sender)
Received: from [209.85.220.178] (HELO mail-vc0-f178.google.com) (209.85.220.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 16:28:43 +0000
Received: by mail-vc0-f178.google.com with SMTP id hq12so1651726vcb.23
        for <dev@spark.incubator.apache.org>; Sun, 26 Oct 2014 09:27:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=7LsscTxgzNdzubKnXRq+MLlWW+RV5uYTpZu4+cAdGdI=;
        b=uL6sKtgIt/JMIhyfL9wH4Re8IkE9atIxbgBMpu3Be5QVvA2SFOqP/nzsdJfyXxI5sU
         9iXPxi7PgyMTTmSszadylcXhz6tTfbt0SjjyQ6wZTtu2xY5X2+PdtZk0JcYLsdX74fRz
         g4RIsdSjv6Uch0WoPSy1H5moP3O4Lok3jBR1k0KT5bzcFua9u4Ef4732vXtReHqqudEu
         8sg9idFrnef6PmlX7g4MHRQGaBtI89RaoxeIaY/xR0LqE8rExO84Gt+KU+aL3b9qmfaE
         2qr8LBR7b4+GhT5zZ/p5x7NKVJdfl15FbETOd6PhD0FuD3sH5et+P4elcPFANbg/IGwp
         nFhQ==
MIME-Version: 1.0
X-Received: by 10.52.240.209 with SMTP id wc17mr10608380vdc.22.1414340877283;
 Sun, 26 Oct 2014 09:27:57 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Sun, 26 Oct 2014 09:27:57 -0700 (PDT)
In-Reply-To: <1414336040472-8965.post@n3.nabble.com>
References: <1414336040472-8965.post@n3.nabble.com>
Date: Sun, 26 Oct 2014 09:27:57 -0700
Message-ID: <CACkSZy2niZP3Z8S-m8ooEWMkKzfEW9qpjmnWV=ytyaxQk0p2GA@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
From: Stephen Boesch <javadba@gmail.com>
To: ll <duy.huynh.uiv@gmail.com>
Cc: dev@spark.incubator.apache.org
Content-Type: multipart/alternative; boundary=20cf307ac46994f97d050655e545
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf307ac46994f97d050655e545
Content-Type: text/plain; charset=UTF-8

Many of the spark developers use Intellij.   You will in any case probably
want a full IDE (either IJ or eclipse)

2014-10-26 8:07 GMT-07:00 ll <duy.huynh.uiv@gmail.com>:

> i'm new to both scala and spark.  what IDE / dev environment do you find
> most
> productive for writing code in scala with spark?  is it just vim + sbt?  or
> does a full IDE like intellij works out better?  thanks!
>
>
>
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--20cf307ac46994f97d050655e545--

From dev-return-9991-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 16:33:26 2014
Return-Path: <dev-return-9991-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8CFC5172BA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 16:33:26 +0000 (UTC)
Received: (qmail 21645 invoked by uid 500); 26 Oct 2014 16:33:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 21574 invoked by uid 500); 26 Oct 2014 16:33:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 21561 invoked by uid 99); 26 Oct 2014 16:33:25 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 16:33:25 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of jayunit100.apache@gmail.com designates 209.85.192.51 as permitted sender)
Received: from [209.85.192.51] (HELO mail-qg0-f51.google.com) (209.85.192.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 16:32:59 +0000
Received: by mail-qg0-f51.google.com with SMTP id j5so709534qga.24
        for <dev@spark.incubator.apache.org>; Sun, 26 Oct 2014 09:32:13 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=AQrrPPlznhNFfZxLt5mQAdI8Zsoza7AJEEcuhltY+jw=;
        b=e3uiiHa502KgIFFS4KeTCZfkgKdDZ3+NZxxO1fsUzHJ0YXwElSa67j3cVZpvtoDVeL
         BFmhUuq2NNgEc11LVxKSL12Ns77iliD9we8eK/ZQ9XK1XRrW9ks6wBZRuQHCEIpGWGja
         fvl0JO8Z9LDrKNtKU18P5Ac1cMNEdqMaE57fVUWqsSbe6IMlcYiDVW1IeiIRWnoy6a9a
         oPFkIRqP7cZ5YnOMBeM8xijE8f5pWQxvwKyGIoOLSZLtbjmuXaVuLQKenozf4btvlFsM
         WkSbAtKazr65YD9EVAoPkvX1eHN0xwGojEUWJ7+vjYHRBP/qGCWdHej/D7LSlG1Za3bS
         tVcg==
X-Received: by 10.229.244.1 with SMTP id lo1mr25406096qcb.29.1414341133266;
        Sun, 26 Oct 2014 09:32:13 -0700 (PDT)
Received: from [10.0.1.7] ([73.182.181.57])
        by mx.google.com with ESMTPSA id x1sm9154351qax.17.2014.10.26.09.32.12
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sun, 26 Oct 2014 09:32:12 -0700 (PDT)
Content-Type: text/plain;
	charset=us-ascii
Mime-Version: 1.0 (1.0)
Subject: Re: best IDE for scala + spark development?
From: Jay Vyas <jayunit100.apache@gmail.com>
X-Mailer: iPhone Mail (11D257)
In-Reply-To: <1414336040472-8965.post@n3.nabble.com>
Date: Sun, 26 Oct 2014 12:32:12 -0400
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <6558B993-2715-4F0D-9E96-257F0D3AF2FC@gmail.com>
References: <1414336040472-8965.post@n3.nabble.com>
To: ll <duy.huynh.uiv@gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org

I tried the scala eclipse ide but in scala 2.10 I ran into some weird issues=
 http://stackoverflow.com/questions/24253084/scalaide-and-cryptic-classnotfo=
und-errors ... So I switched to IntelliJ and was much more satisfied...

I've written a post on how I use fedora,sbt, and intellij for spark apps.
http://jayunit100.blogspot.com/2014/07/set-up-spark-application-devleopment.=
html?m=3D1

The IntelliJ sbt plugin is imo less buggy then the eclipse scalaIDE stuff.  =
For example, I found I had to set some special preferences

Finally... given sbts automated recompile option, if you just use tmux, and v=
im nerdtree, with sbt , you could come pretty close to something like an IDE=
 without all the drama ..

> On Oct 26, 2014, at 11:07 AM, ll <duy.huynh.uiv@gmail.com> wrote:
>=20
> i'm new to both scala and spark.  what IDE / dev environment do you find m=
ost
> productive for writing code in scala with spark?  is it just vim + sbt?  o=
r
> does a full IDE like intellij works out better?  thanks!
>=20
>=20
>=20
> --
> View this message in context: http://apache-spark-developers-list.1001551.=
n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> Sent from the Apache Spark Developers List mailing list archive at Nabble.=
com.
>=20
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-9992-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 18:13:33 2014
Return-Path: <dev-return-9992-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C0938174B2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 18:13:33 +0000 (UTC)
Received: (qmail 18393 invoked by uid 500); 26 Oct 2014 18:13:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18300 invoked by uid 500); 26 Oct 2014 18:13:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18286 invoked by uid 99); 26 Oct 2014 18:13:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 18:13:31 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 18:13:05 +0000
Received: by mail-wi0-f178.google.com with SMTP id q5so4696231wiv.11
        for <dev@spark.apache.org>; Sun, 26 Oct 2014 11:12:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=FcgE0rY9TUOOoaXnuNfadGFQa0sC0GQHt5wA2ZQ8fUE=;
        b=RIZEyCyN0ZoHB9f5qEF3XWs/ZtmcwY7E40/+AIx1bYbKPn5/ZDcqH6dkfHMlU9Zo4y
         2C/SF5YU5f6FqTCQaqgG/+kcVoTK/dO5cKa4Q/w/rBkTWBKojPL5lshjTLlzhg2ICHIt
         Xv9RjBywExTmymmL2rAxpBwTZQibf7eQ+SchB/4JMRYL4al/AQnD6Ho7kTulbc3JTQGc
         zfYnq7GRSkB9lQA8oAMEoja21LxzHUlcRfalz5u75WeCxAdjcUTprnVpvcfmBlwFfDNQ
         YLt8X2RwVz27k8ev7PYR8mQ1LjOCMwRAO8qDOPudO1G2z42xFYOkiV4JYQisfxAufomH
         1QVQ==
X-Received: by 10.194.142.147 with SMTP id rw19mr4386226wjb.64.1414347139756;
 Sun, 26 Oct 2014 11:12:19 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.180.108.13 with HTTP; Sun, 26 Oct 2014 11:11:39 -0700 (PDT)
In-Reply-To: <CACKkDGGoqp+wG-JVuBeAUZfYe2TwE25iBR04Ge0_4sFn7c2omA@mail.gmail.com>
References: <CACuyFYJp36vzVgmv=fh80DkJgz-Qzy=uKWcqDsaMCbzbvVhSgw@mail.gmail.com>
 <CACKkDGGoqp+wG-JVuBeAUZfYe2TwE25iBR04Ge0_4sFn7c2omA@mail.gmail.com>
From: Nicholas Chammas <nicholas.chammas@gmail.com>
Date: Sun, 26 Oct 2014 14:11:39 -0400
Message-ID: <CAOhmDze8MTdRZW+k6PuutOyAPr93mc=RnPqbY7R-c6zkJ7pURw@mail.gmail.com>
Subject: Re: Potential areas for working
To: Varadharajan Mukundan <srinathsmn@gmail.com>
Cc: Vibhanshu Prasad <vibhanshugsoc2@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013a2992dab7940506575a5a
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013a2992dab7940506575a5a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Have y=E2=80=99all taken a look at these links?

   -


   https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#=
ContributingtoSpark-StarterTasks
    -


   https://issues.apache.org/jira/browse/SPARK-3740?jql=3Dproject%20%3D%20S=
PARK%20AND%20labels%20%3D%20Starter%20AND%20status%20in%20(Open%2C%20%22In%=
20Progress%22%2C%20Reopened)
   <https://issues.apache.org/jira/browse/SPARK-3740?jql=3Dproject%20%3D%20=
SPARK%20AND%20labels%20%3D%20Starter%20AND%20status%20in%20(Open%2C%20%22In=
%20Progress%22%2C%20Reopened>
   )

Nick
=E2=80=8B

On Sun, Oct 26, 2014 at 7:28 AM, Varadharajan Mukundan <srinathsmn@gmail.co=
m
> wrote:

> +1, I'm interested in contributing to Spark SQL and i'm looking for
> starter tasks.
>
> On Sun, Oct 26, 2014 at 3:13 PM, Vibhanshu Prasad
> <vibhanshugsoc2@gmail.com> wrote:
> > Hello everyone,
> > I am new to the spark developer community,
> > I want to know what are the areas where currently programming is in
> > progress. What areas I can work on as a started.
> >
> > Vibhanshu
>
>
>
> --
> Thanks,
> M. Varadharajan
>
> ------------------------------------------------
>
> "Experience is what you get when you didn't get what you wanted"
>                -By Prof. Randy Pausch in "The Last Lecture"
>
> My Journal :- www.thinkasgeek.wordpress.com
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--089e013a2992dab7940506575a5a--

From dev-return-9993-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Sun Oct 26 22:06:46 2014
Return-Path: <dev-return-9993-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7D145178BB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Sun, 26 Oct 2014 22:06:46 +0000 (UTC)
Received: (qmail 34732 invoked by uid 500); 26 Oct 2014 22:06:45 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 34663 invoked by uid 500); 26 Oct 2014 22:06:45 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 34651 invoked by uid 99); 26 Oct 2014 22:06:45 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 22:06:45 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of duy.huynh.uiv@gmail.com designates 209.85.218.54 as permitted sender)
Received: from [209.85.218.54] (HELO mail-oi0-f54.google.com) (209.85.218.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Sun, 26 Oct 2014 22:06:41 +0000
Received: by mail-oi0-f54.google.com with SMTP id v63so2552286oia.27
        for <dev@spark.incubator.apache.org>; Sun, 26 Oct 2014 15:06:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=AwtpCkReNdZSYV8GWHMhttiCGxSYi0b+9YvMien4xyc=;
        b=MwZVO2fvnS3JS+HB9El8Z1mJPueHfjtQf3mXcV0iiWvyAAvy7xm95J+CPgYsL3lrqc
         i1EMWMlQUmxGWnUSmenHuEj5M1H9uFYlRh1WyBJD66hssdNUyqu5PHJDQ1XKnoyAkHcE
         btJQNWjHrsNJdkG7BDPNnu4/S5A35MrYLutV2BT8HojLhc8EfVf0kNRCzW7nq5D8fUhz
         linyVQ41doO8uXKITB4mD31XXIHy9DNVcVXZ195pnU+B4wzSHCyUaBVOwTAwxbQ1J/mU
         aqhgnjBmSFjY2luppkQxX+uTnOuYSpKauE4u/9k+hbXMNShpP4VoWbwVgYRWpFYnmGJH
         ZxnA==
MIME-Version: 1.0
X-Received: by 10.60.160.103 with SMTP id xj7mr16704978oeb.6.1414361180410;
 Sun, 26 Oct 2014 15:06:20 -0700 (PDT)
Received: by 10.76.75.74 with HTTP; Sun, 26 Oct 2014 15:06:20 -0700 (PDT)
In-Reply-To: <6558B993-2715-4F0D-9E96-257F0D3AF2FC@gmail.com>
References: <1414336040472-8965.post@n3.nabble.com>
	<6558B993-2715-4F0D-9E96-257F0D3AF2FC@gmail.com>
Date: Sun, 26 Oct 2014 18:06:20 -0400
Message-ID: <CAN3RKnNRZ5dwQCuwCoYgCzj6BUCFqSeuTQ2m_DhM4RAnF+CWZQ@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
From: Duy Huynh <duy.huynh.uiv@gmail.com>
To: Jay Vyas <jayunit100.apache@gmail.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e01182862be195005065a9f78
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01182862be195005065a9f78
Content-Type: text/plain; charset=UTF-8

i like intellij and eclipse too, but some that they are too heavy.  i would
love to use vim.  are there are good scala plugins for vim?  (i.e code
completion, scala doc, etc)

On Sun, Oct 26, 2014 at 12:32 PM, Jay Vyas <jayunit100.apache@gmail.com>
wrote:

> I tried the scala eclipse ide but in scala 2.10 I ran into some weird
> issues
> http://stackoverflow.com/questions/24253084/scalaide-and-cryptic-classnotfound-errors
> ... So I switched to IntelliJ and was much more satisfied...
>
> I've written a post on how I use fedora,sbt, and intellij for spark apps.
>
> http://jayunit100.blogspot.com/2014/07/set-up-spark-application-devleopment.html?m=1
>
> The IntelliJ sbt plugin is imo less buggy then the eclipse scalaIDE
> stuff.  For example, I found I had to set some special preferences
>
> Finally... given sbts automated recompile option, if you just use tmux,
> and vim nerdtree, with sbt , you could come pretty close to something like
> an IDE without all the drama ..
>
> > On Oct 26, 2014, at 11:07 AM, ll <duy.huynh.uiv@gmail.com> wrote:
> >
> > i'm new to both scala and spark.  what IDE / dev environment do you find
> most
> > productive for writing code in scala with spark?  is it just vim + sbt?
> or
> > does a full IDE like intellij works out better?  thanks!
> >
> >
> >
> > --
> > View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> > Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
>

--089e01182862be195005065a9f78--

From dev-return-9994-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 08:48:28 2014
Return-Path: <dev-return-9994-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0910A17703
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 08:48:28 +0000 (UTC)
Received: (qmail 15244 invoked by uid 500); 27 Oct 2014 08:48:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 15176 invoked by uid 500); 27 Oct 2014 08:48:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 15164 invoked by uid 99); 27 Oct 2014 08:48:26 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 08:48:26 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jianshi.huang@gmail.com designates 209.85.217.169 as permitted sender)
Received: from [209.85.217.169] (HELO mail-lb0-f169.google.com) (209.85.217.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 08:48:22 +0000
Received: by mail-lb0-f169.google.com with SMTP id l4so236443lbv.0
        for <dev@spark.apache.org>; Mon, 27 Oct 2014 01:48:01 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=NK3+3CgjVrhNUF5/wQsXoAzFOOVSk4qRyC074VOoEIE=;
        b=j2MRxzKk5IwK1gLnpg40vhsU53iOsgK8S5qT4qw+ofqwSBw7IvnWnkuk/eWwdxzRaR
         6XL2cnXFe5KCNaCyHsP6yjx3gBHgMSXY9iknNudilbFhT41Ei+zsYFA1uCcBORFcN0oY
         NzTeXkoAda9mdQ0W1SYQjhh+4KLo4kBdGgZrqLwv/qewoxvOUmadIlu3bb/tBF7YYHve
         SVW63E39DfIwPUUiHli2uCi5To0F0b6Q32H/KbaZQpp6uvbOJiifEuWF/aayfNAdHD/n
         8dEW+WxvjD1Yzg63RctvzQZqD0xWyaaowfjuPEqHBfXp58pKogYIypquw9xdmIL6+3Bc
         ZzdQ==
X-Received: by 10.112.85.138 with SMTP id h10mr21874250lbz.33.1414399680930;
 Mon, 27 Oct 2014 01:48:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.210.1 with HTTP; Mon, 27 Oct 2014 01:47:40 -0700 (PDT)
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Mon, 27 Oct 2014 16:47:40 +0800
Message-ID: <CACA1tWLSVEadkBGn0MEsCQeU7xdejO1pB_aXu-byVX0nyB3tXA@mail.gmail.com>
Subject: Build with Hive 0.13.1 doesn't have datanucleus and parquet dependencies.
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113471688d6a4c05066396e5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113471688d6a4c05066396e5
Content-Type: text/plain; charset=UTF-8

There's a change in build process lately for Hive 0.13 support and we
should make it obvious. Based on the new pom.xml I tried to enable Hive
0.13.1 support by using option

  -Phive-0.13.1

However, it seems datanucleus and parquet dependencies are not available in
the final build.

Am I missing anything?

Jianshi

-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--001a113471688d6a4c05066396e5--

From dev-return-9995-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 09:02:07 2014
Return-Path: <dev-return-9995-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 95FA31775A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 09:02:07 +0000 (UTC)
Received: (qmail 43137 invoked by uid 500); 27 Oct 2014 09:02:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 43058 invoked by uid 500); 27 Oct 2014 09:02:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 43045 invoked by uid 99); 27 Oct 2014 09:02:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 09:02:05 +0000
X-ASF-Spam-Status: No, hits=-5.0 required=10.0
	tests=RCVD_IN_DNSWL_HI,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of hao.cheng@intel.com designates 134.134.136.24 as permitted sender)
Received: from [134.134.136.24] (HELO mga09.intel.com) (134.134.136.24)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 09:02:01 +0000
Received: from orsmga001.jf.intel.com ([10.7.209.18])
  by orsmga102.jf.intel.com with ESMTP; 27 Oct 2014 01:58:17 -0700
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="5.04,794,1406617200"; 
   d="scan'208";a="596776687"
Received: from pgsmsx103.gar.corp.intel.com ([10.221.44.82])
  by orsmga001.jf.intel.com with ESMTP; 27 Oct 2014 01:59:34 -0700
Received: from kmsmsx153.gar.corp.intel.com (172.21.73.88) by
 PGSMSX103.gar.corp.intel.com (10.221.44.82) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Mon, 27 Oct 2014 16:57:34 +0800
Received: from shsmsx151.ccr.corp.intel.com (10.239.6.50) by
 KMSMSX153.gar.corp.intel.com (172.21.73.88) with Microsoft SMTP Server (TLS)
 id 14.3.195.1; Mon, 27 Oct 2014 16:57:34 +0800
Received: from shsmsx102.ccr.corp.intel.com ([169.254.2.156]) by
 SHSMSX151.ccr.corp.intel.com ([169.254.3.44]) with mapi id 14.03.0195.001;
 Mon, 27 Oct 2014 16:57:33 +0800
From: "Cheng, Hao" <hao.cheng@intel.com>
To: Jianshi Huang <jianshi.huang@gmail.com>, "dev@spark.apache.org"
	<dev@spark.apache.org>
Subject: RE: Build with Hive 0.13.1 doesn't have datanucleus and parquet
 dependencies.
Thread-Topic: Build with Hive 0.13.1 doesn't have datanucleus and parquet
 dependencies.
Thread-Index: AQHP8cLmvfzvYSGrZE26OHDH3wJjxJxDpCuA
Date: Mon, 27 Oct 2014 08:57:32 +0000
Message-ID: <80833ADD533E324CA05C160E41B636610277E87D@shsmsx102.ccr.corp.intel.com>
References: <CACA1tWLSVEadkBGn0MEsCQeU7xdejO1pB_aXu-byVX0nyB3tXA@mail.gmail.com>
In-Reply-To: <CACA1tWLSVEadkBGn0MEsCQeU7xdejO1pB_aXu-byVX0nyB3tXA@mail.gmail.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [10.239.127.40]
Content-Type: text/plain; charset="utf-8"
Content-Transfer-Encoding: base64
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

SGl2ZS10aHJpZnRzZXJ2ZXIgbW9kdWxlIGlzIG5vdCBpbmNsdWRlZCB3aGlsZSBzcGVjaWZ5aW5n
IHRoZSBwcm9maWxlIGhpdmUtMC4xMy4xLiANCg0KLS0tLS1PcmlnaW5hbCBNZXNzYWdlLS0tLS0N
CkZyb206IEppYW5zaGkgSHVhbmcgW21haWx0bzpqaWFuc2hpLmh1YW5nQGdtYWlsLmNvbV0gDQpT
ZW50OiBNb25kYXksIE9jdG9iZXIgMjcsIDIwMTQgNDo0OCBQTQ0KVG86IGRldkBzcGFyay5hcGFj
aGUub3JnDQpTdWJqZWN0OiBCdWlsZCB3aXRoIEhpdmUgMC4xMy4xIGRvZXNuJ3QgaGF2ZSBkYXRh
bnVjbGV1cyBhbmQgcGFycXVldCBkZXBlbmRlbmNpZXMuDQoNClRoZXJlJ3MgYSBjaGFuZ2UgaW4g
YnVpbGQgcHJvY2VzcyBsYXRlbHkgZm9yIEhpdmUgMC4xMyBzdXBwb3J0IGFuZCB3ZSBzaG91bGQg
bWFrZSBpdCBvYnZpb3VzLiBCYXNlZCBvbiB0aGUgbmV3IHBvbS54bWwgSSB0cmllZCB0byBlbmFi
bGUgSGl2ZQ0KMC4xMy4xIHN1cHBvcnQgYnkgdXNpbmcgb3B0aW9uDQoNCiAgLVBoaXZlLTAuMTMu
MQ0KDQpIb3dldmVyLCBpdCBzZWVtcyBkYXRhbnVjbGV1cyBhbmQgcGFycXVldCBkZXBlbmRlbmNp
ZXMgYXJlIG5vdCBhdmFpbGFibGUgaW4gdGhlIGZpbmFsIGJ1aWxkLg0KDQpBbSBJIG1pc3Npbmcg
YW55dGhpbmc/DQoNCkppYW5zaGkNCg0KLS0NCkppYW5zaGkgSHVhbmcNCg0KTGlua2VkSW46IGpp
YW5zaGkNClR3aXR0ZXI6IEBqc2h1YW5nDQpHaXRodWIgJiBCbG9nOiBodHRwOi8vaHVhbmdqcy5n
aXRodWIuY29tLw0K
DQotLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0t
LS0tLS0tLS0tLS0tLS0tLS0NClRvIHVuc3Vic2NyaWJlLCBlLW1haWw6IGRldi11bnN1YnNj
cmliZUBzcGFyay5hcGFjaGUub3JnDQpGb3IgYWRkaXRpb25hbCBjb21tYW5kcywgZS1tYWls
OiBkZXYtaGVscEBzcGFyay5hcGFjaGUub3JnDQoN

From dev-return-9996-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 09:17:10 2014
Return-Path: <dev-return-9996-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 43C21177E1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 09:17:10 +0000 (UTC)
Received: (qmail 81994 invoked by uid 500); 27 Oct 2014 09:17:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81926 invoked by uid 500); 27 Oct 2014 09:17:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81914 invoked by uid 99); 27 Oct 2014 09:17:08 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 09:17:08 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of jianshi.huang@gmail.com designates 209.85.217.169 as permitted sender)
Received: from [209.85.217.169] (HELO mail-lb0-f169.google.com) (209.85.217.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 09:17:04 +0000
Received: by mail-lb0-f169.google.com with SMTP id l4so271955lbv.14
        for <dev@spark.apache.org>; Mon, 27 Oct 2014 02:15:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=3j55YKi98eMFsgsV9Rf8FNw0BaaAcNkVlwPT27mP4Uo=;
        b=DRv1IAJiYPNLL0+7hqpE4j7jhyrVvDwsi3BSaoAu57OztMSb5kWQwRvXl5PtiImqdE
         KAVBNhmW5WNk1ReWbWKfg/+TM+xoiJjY+BFnVFlYG6QtLSivyDOjUJQhiHiM0paOhHLz
         jviL4FH94B24xyUOxGaDhwQ/4NC8h+hVvp8fHNu7/METOnYQ/Fn6BunIi+Mp200TlgtH
         rOTgA5DXFUigM/qZC9b+Tbh2jFEiOfAvDyg5E8YafJTHXkBZnyZG/57BuFjfLBOJP1BJ
         DjgPTWt9MY5jHGBqQGGZ5vOhlaP167mzxGZ57oFG4DnrdEJ61bmBW9JTcU4n5t1rSKHD
         qjfg==
X-Received: by 10.112.138.39 with SMTP id qn7mr21976247lbb.57.1414401358455;
 Mon, 27 Oct 2014 02:15:58 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.210.1 with HTTP; Mon, 27 Oct 2014 02:15:38 -0700 (PDT)
In-Reply-To: <80833ADD533E324CA05C160E41B636610277E87D@shsmsx102.ccr.corp.intel.com>
References: <CACA1tWLSVEadkBGn0MEsCQeU7xdejO1pB_aXu-byVX0nyB3tXA@mail.gmail.com>
 <80833ADD533E324CA05C160E41B636610277E87D@shsmsx102.ccr.corp.intel.com>
From: Jianshi Huang <jianshi.huang@gmail.com>
Date: Mon, 27 Oct 2014 17:15:38 +0800
Message-ID: <CACA1tW+Stk6RL_W7aVXvm3XFf5u3wgx8N+dONrZ6o=hdMQS_9Q@mail.gmail.com>
Subject: Re: Build with Hive 0.13.1 doesn't have datanucleus and parquet dependencies.
To: "Cheng, Hao" <hao.cheng@intel.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e011614ec8a6bd8050663faed
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011614ec8a6bd8050663faed
Content-Type: text/plain; charset=UTF-8

Ah I see. Thanks Hao! I'll wait for the fix.

Jianshi

On Mon, Oct 27, 2014 at 4:57 PM, Cheng, Hao <hao.cheng@intel.com> wrote:

> Hive-thriftserver module is not included while specifying the profile
> hive-0.13.1.
>
> -----Original Message-----
> From: Jianshi Huang [mailto:jianshi.huang@gmail.com]
> Sent: Monday, October 27, 2014 4:48 PM
> To: dev@spark.apache.org
> Subject: Build with Hive 0.13.1 doesn't have datanucleus and parquet
> dependencies.
>
> There's a change in build process lately for Hive 0.13 support and we
> should make it obvious. Based on the new pom.xml I tried to enable Hive
> 0.13.1 support by using option
>
>   -Phive-0.13.1
>
> However, it seems datanucleus and parquet dependencies are not available
> in the final build.
>
> Am I missing anything?
>
> Jianshi
>
> --
> Jianshi Huang
>
> LinkedIn: jianshi
> Twitter: @jshuang
> Github & Blog: http://huangjs.github.com/
>



-- 
Jianshi Huang

LinkedIn: jianshi
Twitter: @jshuang
Github & Blog: http://huangjs.github.com/

--089e011614ec8a6bd8050663faed--

From dev-return-9997-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 13:16:08 2014
Return-Path: <dev-return-9997-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E109F17DA8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 13:16:08 +0000 (UTC)
Received: (qmail 66817 invoked by uid 500); 27 Oct 2014 13:16:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66743 invoked by uid 500); 27 Oct 2014 13:16:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66728 invoked by uid 99); 27 Oct 2014 13:16:07 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 13:16:07 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of deanwampler@gmail.com designates 209.85.213.41 as permitted sender)
Received: from [209.85.213.41] (HELO mail-yh0-f41.google.com) (209.85.213.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 13:15:42 +0000
Received: by mail-yh0-f41.google.com with SMTP id b6so2619018yha.0
        for <dev@spark.incubator.apache.org>; Mon, 27 Oct 2014 06:15:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=430uHVz5Id+IAQeoVgfnCor7sfU12Ee3GDvFoaiSrbY=;
        b=Bwa2GL0XsUPDw9y69TYyjcwiGRajcXD/Z9Ea+isZLrB+wywMFAAfDSC/cPOYi5X73Z
         fQJgDtrAoQGhvgluNMbkyhAd3RPjtrXsZpnY3VhDHEj+UFbeSwxh8yKb1/cF9zoEuRmG
         0eMifD+1SvS3GDgnSBbQi+38oKC/pq4d9uU4tSSQU3RDlyz36DOKGHnSNR/v97ZoRNZt
         rBI1fm6yMSzWIh8B0i7DLxkewctLvnTpSHV6ai0Yg0cB9sEjYJLGuNJT1QeneJg4fkOT
         Q7ODTtilwS+O9o5pQh2B1wva6Uv0P1xKoY16t3s+DyetankgPrKUByH3dtjHqAZXGJDu
         ZhXw==
X-Received: by 10.236.37.99 with SMTP id x63mr21842937yha.15.1414415740375;
 Mon, 27 Oct 2014 06:15:40 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.170.186.145 with HTTP; Mon, 27 Oct 2014 06:15:20 -0700 (PDT)
In-Reply-To: <CAN3RKnNRZ5dwQCuwCoYgCzj6BUCFqSeuTQ2m_DhM4RAnF+CWZQ@mail.gmail.com>
References: <1414336040472-8965.post@n3.nabble.com> <6558B993-2715-4F0D-9E96-257F0D3AF2FC@gmail.com>
 <CAN3RKnNRZ5dwQCuwCoYgCzj6BUCFqSeuTQ2m_DhM4RAnF+CWZQ@mail.gmail.com>
From: Dean Wampler <deanwampler@gmail.com>
Date: Mon, 27 Oct 2014 08:15:20 -0500
Message-ID: <CAKW0i0xwWMSE_p2Ncbq45d=0x9Sg2Rqme3bKQSybzU9ymuWC7A@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
To: Duy Huynh <duy.huynh.uiv@gmail.com>
Cc: Jay Vyas <jayunit100.apache@gmail.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e011848ecc5188d05066753bb
X-Virus-Checked: Checked by ClamAV on apache.org

--089e011848ecc5188d05066753bb
Content-Type: text/plain; charset=UTF-8

For what it's worth, I use Sublime Text + the SBT console for everything. I
can live without the extra IDE features.

However, if you like an IDE, the Eclipse "Scala IDE" 4.0 RC1 is a big
improvement over previous releases. For one thing, it can now supports
projects using different versions of Scala, which is convenient for Spark's
current 2.10.4 support and emerging 2.11 support.

http://scala-ide.org/download/milestone.html

Dean


Dean Wampler, Ph.D.
Author: Programming Scala, 2nd Edition
<http://shop.oreilly.com/product/0636920033073.do> (O'Reilly)
Typesafe <http://typesafe.com>
@deanwampler <http://twitter.com/deanwampler>
http://polyglotprogramming.com

On Sun, Oct 26, 2014 at 5:06 PM, Duy Huynh <duy.huynh.uiv@gmail.com> wrote:

> i like intellij and eclipse too, but some that they are too heavy.  i would
> love to use vim.  are there are good scala plugins for vim?  (i.e code
> completion, scala doc, etc)
>
> On Sun, Oct 26, 2014 at 12:32 PM, Jay Vyas <jayunit100.apache@gmail.com>
> wrote:
>
> > I tried the scala eclipse ide but in scala 2.10 I ran into some weird
> > issues
> >
> http://stackoverflow.com/questions/24253084/scalaide-and-cryptic-classnotfound-errors
> > ... So I switched to IntelliJ and was much more satisfied...
> >
> > I've written a post on how I use fedora,sbt, and intellij for spark apps.
> >
> >
> http://jayunit100.blogspot.com/2014/07/set-up-spark-application-devleopment.html?m=1
> >
> > The IntelliJ sbt plugin is imo less buggy then the eclipse scalaIDE
> > stuff.  For example, I found I had to set some special preferences
> >
> > Finally... given sbts automated recompile option, if you just use tmux,
> > and vim nerdtree, with sbt , you could come pretty close to something
> like
> > an IDE without all the drama ..
> >
> > > On Oct 26, 2014, at 11:07 AM, ll <duy.huynh.uiv@gmail.com> wrote:
> > >
> > > i'm new to both scala and spark.  what IDE / dev environment do you
> find
> > most
> > > productive for writing code in scala with spark?  is it just vim + sbt?
> > or
> > > does a full IDE like intellij works out better?  thanks!
> > >
> > >
> > >
> > > --
> > > View this message in context:
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> > > Sent from the Apache Spark Developers List mailing list archive at
> > Nabble.com.
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> >
>

--089e011848ecc5188d05066753bb--

From dev-return-9998-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 13:20:14 2014
Return-Path: <dev-return-9998-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F346A17DBB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 13:20:13 +0000 (UTC)
Received: (qmail 90478 invoked by uid 500); 27 Oct 2014 13:20:13 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 90414 invoked by uid 500); 27 Oct 2014 13:20:13 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 90354 invoked by uid 99); 27 Oct 2014 13:20:12 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 13:20:12 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of andy.petrella@gmail.com designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 13:20:08 +0000
Received: by mail-la0-f42.google.com with SMTP id gq15so610208lab.29
        for <dev@spark.incubator.apache.org>; Mon, 27 Oct 2014 06:18:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=ALYvjRpwcbT8S/jD5gYep8XKupF/KqGaLFdUjAs5qcU=;
        b=vEoNv8jg2VfycjupGIWDyvXykVFprzM+DhgUJTAoTcC+SuScqd4hZHcjSyoZQBQdbf
         czouj4LLWue1XS6dARDmlE9FJ2EmWYFhySbcI4tbEE9CSHTuBQulJ7abEj9wi2Cpd8F2
         yKaTlDCW9X++IKo8RClYEHEMZmcZ+N0/7ag172N0WsgSwPGBTorJcqb4FAkDVbRHHHHa
         G+AGZEIX2MEUSzNo5fhBIl1vfsqAh9pBb0GPutVP0xeRfgi3od3BKNvKJUs4/ya12S7x
         FsZ6M9DKY6mJXjtpnPyCog8k11jrFNFUeqOTmMzx93upQvL9Rvs2PW6Qjz2q3z8wwKdu
         g5OA==
X-Received: by 10.152.163.101 with SMTP id yh5mr15192942lab.68.1414415896558;
 Mon, 27 Oct 2014 06:18:16 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.112.235.7 with HTTP; Mon, 27 Oct 2014 06:17:56 -0700 (PDT)
In-Reply-To: <CAKW0i0xwWMSE_p2Ncbq45d=0x9Sg2Rqme3bKQSybzU9ymuWC7A@mail.gmail.com>
References: <1414336040472-8965.post@n3.nabble.com> <6558B993-2715-4F0D-9E96-257F0D3AF2FC@gmail.com>
 <CAN3RKnNRZ5dwQCuwCoYgCzj6BUCFqSeuTQ2m_DhM4RAnF+CWZQ@mail.gmail.com> <CAKW0i0xwWMSE_p2Ncbq45d=0x9Sg2Rqme3bKQSybzU9ymuWC7A@mail.gmail.com>
From: andy petrella <andy.petrella@gmail.com>
Date: Mon, 27 Oct 2014 14:17:56 +0100
Message-ID: <CAKn3j0sLkGZ8CCQdK1cMGZSRs8+Q+hnUNwK9y6TLJEn6m7M3eA@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
To: Dean Wampler <deanwampler@gmail.com>
Cc: Duy Huynh <duy.huynh.uiv@gmail.com>, Jay Vyas <jayunit100.apache@gmail.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a113369a614453e0506675d01
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113369a614453e0506675d01
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I second the S[B]T combo!

I tried ATOM =E2=86=92 lack of features and stability (atm)

a=E2=84=95dy =E2=84=99etrella
about.me/noootsab
[image: a=E2=84=95dy =E2=84=99etrella on about.me]

<http://about.me/noootsab>

On Mon, Oct 27, 2014 at 2:15 PM, Dean Wampler <deanwampler@gmail.com> wrote=
:

> For what it's worth, I use Sublime Text + the SBT console for everything.=
 I
> can live without the extra IDE features.
>
> However, if you like an IDE, the Eclipse "Scala IDE" 4.0 RC1 is a big
> improvement over previous releases. For one thing, it can now supports
> projects using different versions of Scala, which is convenient for Spark=
's
> current 2.10.4 support and emerging 2.11 support.
>
> http://scala-ide.org/download/milestone.html
>
> Dean
>
>
> Dean Wampler, Ph.D.
> Author: Programming Scala, 2nd Edition
> <http://shop.oreilly.com/product/0636920033073.do> (O'Reilly)
> Typesafe <http://typesafe.com>
> @deanwampler <http://twitter.com/deanwampler>
> http://polyglotprogramming.com
>
> On Sun, Oct 26, 2014 at 5:06 PM, Duy Huynh <duy.huynh.uiv@gmail.com>
> wrote:
>
> > i like intellij and eclipse too, but some that they are too heavy.  i
> would
> > love to use vim.  are there are good scala plugins for vim?  (i.e code
> > completion, scala doc, etc)
> >
> > On Sun, Oct 26, 2014 at 12:32 PM, Jay Vyas <jayunit100.apache@gmail.com=
>
> > wrote:
> >
> > > I tried the scala eclipse ide but in scala 2.10 I ran into some weird
> > > issues
> > >
> >
> http://stackoverflow.com/questions/24253084/scalaide-and-cryptic-classnot=
found-errors
> > > ... So I switched to IntelliJ and was much more satisfied...
> > >
> > > I've written a post on how I use fedora,sbt, and intellij for spark
> apps.
> > >
> > >
> >
> http://jayunit100.blogspot.com/2014/07/set-up-spark-application-devleopme=
nt.html?m=3D1
> > >
> > > The IntelliJ sbt plugin is imo less buggy then the eclipse scalaIDE
> > > stuff.  For example, I found I had to set some special preferences
> > >
> > > Finally... given sbts automated recompile option, if you just use tmu=
x,
> > > and vim nerdtree, with sbt , you could come pretty close to something
> > like
> > > an IDE without all the drama ..
> > >
> > > > On Oct 26, 2014, at 11:07 AM, ll <duy.huynh.uiv@gmail.com> wrote:
> > > >
> > > > i'm new to both scala and spark.  what IDE / dev environment do you
> > find
> > > most
> > > > productive for writing code in scala with spark?  is it just vim +
> sbt?
> > > or
> > > > does a full IDE like intellij works out better?  thanks!
> > > >
> > > >
> > > >
> > > > --
> > > > View this message in context:
> > >
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-sc=
ala-spark-development-tp8965.html
> > > > Sent from the Apache Spark Developers List mailing list archive at
> > > Nabble.com.
> > > >
> > > > -------------------------------------------------------------------=
--
> > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > >
> > >
> >
>

--001a113369a614453e0506675d01--

From dev-return-9999-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 15:50:45 2014
Return-Path: <dev-return-9999-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AA24C17446
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 15:50:45 +0000 (UTC)
Received: (qmail 74196 invoked by uid 500); 27 Oct 2014 15:50:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74118 invoked by uid 500); 27 Oct 2014 15:50:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74106 invoked by uid 99); 27 Oct 2014 15:50:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 15:50:44 +0000
X-ASF-Spam-Status: No, hits=3.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.212.172] (HELO mail-wi0-f172.google.com) (209.85.212.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 15:50:18 +0000
Received: by mail-wi0-f172.google.com with SMTP id d1so3240691wiv.5
        for <dev@spark.incubator.apache.org>; Mon, 27 Oct 2014 08:49:33 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=2xpqU4CiS5U0cBQGNzJrgDhxLlbI1h7XRgs2lAa6zEY=;
        b=FRm6aZ3o8+oebwjhgoXC4g5EfdOBOPNo8WAAXQfaNi5ZcgeN6/HbTOWZXr8IiS7MY1
         kpkPyGNx0dfpIPiuVjZoiDIH146DaazqlDpuI/Sp3LKSy7FD8hTBfH8CpQamvK9t1CIl
         l3iPBTkdADrUqmylIV5kUpkRxwnFuyV+V63+o1aY92XUNge3RhCa53CgfE9lhtq/xlTv
         TYhU99nmLHeToCY/uRRVOUQYiWRUMX0qvn11eH4fxDErmblyHQSzWBpuc8N3trBbasjI
         iDmnVXn0IeK7XTSG48JUkxVOjOVTMhOZJsP47nVapBE/eTtfwL9m7P1BsE74+WMw9ZM5
         1SjQ==
X-Gm-Message-State: ALoCoQkFK6VvWAuuZ5aC5+jobKkv1888rEPFnt1Vcu1vqlZs3U4f8B+j3uemwW+5PCiG7mO+2juB
MIME-Version: 1.0
X-Received: by 10.180.11.66 with SMTP id o2mr22116804wib.22.1414424972968;
 Mon, 27 Oct 2014 08:49:32 -0700 (PDT)
Received: by 10.217.116.69 with HTTP; Mon, 27 Oct 2014 08:49:32 -0700 (PDT)
X-Originating-IP: [204.148.13.62]
In-Reply-To: <CAKn3j0sLkGZ8CCQdK1cMGZSRs8+Q+hnUNwK9y6TLJEn6m7M3eA@mail.gmail.com>
References: <1414336040472-8965.post@n3.nabble.com>
	<6558B993-2715-4F0D-9E96-257F0D3AF2FC@gmail.com>
	<CAN3RKnNRZ5dwQCuwCoYgCzj6BUCFqSeuTQ2m_DhM4RAnF+CWZQ@mail.gmail.com>
	<CAKW0i0xwWMSE_p2Ncbq45d=0x9Sg2Rqme3bKQSybzU9ymuWC7A@mail.gmail.com>
	<CAKn3j0sLkGZ8CCQdK1cMGZSRs8+Q+hnUNwK9y6TLJEn6m7M3eA@mail.gmail.com>
Date: Mon, 27 Oct 2014 11:49:32 -0400
Message-ID: <CANx3uAiZLhM80TkaAbA5GejdGj-bcfHLOjs9CBQiwgVtaj2p0w@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
From: Koert Kuipers <koert@tresata.com>
To: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c26a08135b630506697a05
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c26a08135b630506697a05
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

editor of your choice + sbt console works + grep great.

if only folks stopped using wildcard imports (it has little benefits in
terms of coding yet requires an IDE with 1G+ of ram to track em down).

On Mon, Oct 27, 2014 at 9:17 AM, andy petrella <andy.petrella@gmail.com>
wrote:

> I second the S[B]T combo!
>
> I tried ATOM =E2=86=92 lack of features and stability (atm)
>
> a=E2=84=95dy =E2=84=99etrella
> about.me/noootsab
> [image: a=E2=84=95dy =E2=84=99etrella on about.me]
>
> <http://about.me/noootsab>
>
> On Mon, Oct 27, 2014 at 2:15 PM, Dean Wampler <deanwampler@gmail.com>
> wrote:
>
> > For what it's worth, I use Sublime Text + the SBT console for
> everything. I
> > can live without the extra IDE features.
> >
> > However, if you like an IDE, the Eclipse "Scala IDE" 4.0 RC1 is a big
> > improvement over previous releases. For one thing, it can now supports
> > projects using different versions of Scala, which is convenient for
> Spark's
> > current 2.10.4 support and emerging 2.11 support.
> >
> > http://scala-ide.org/download/milestone.html
> >
> > Dean
> >
> >
> > Dean Wampler, Ph.D.
> > Author: Programming Scala, 2nd Edition
> > <http://shop.oreilly.com/product/0636920033073.do> (O'Reilly)
> > Typesafe <http://typesafe.com>
> > @deanwampler <http://twitter.com/deanwampler>
> > http://polyglotprogramming.com
> >
> > On Sun, Oct 26, 2014 at 5:06 PM, Duy Huynh <duy.huynh.uiv@gmail.com>
> > wrote:
> >
> > > i like intellij and eclipse too, but some that they are too heavy.  i
> > would
> > > love to use vim.  are there are good scala plugins for vim?  (i.e cod=
e
> > > completion, scala doc, etc)
> > >
> > > On Sun, Oct 26, 2014 at 12:32 PM, Jay Vyas <
> jayunit100.apache@gmail.com>
> > > wrote:
> > >
> > > > I tried the scala eclipse ide but in scala 2.10 I ran into some wei=
rd
> > > > issues
> > > >
> > >
> >
> http://stackoverflow.com/questions/24253084/scalaide-and-cryptic-classnot=
found-errors
> > > > ... So I switched to IntelliJ and was much more satisfied...
> > > >
> > > > I've written a post on how I use fedora,sbt, and intellij for spark
> > apps.
> > > >
> > > >
> > >
> >
> http://jayunit100.blogspot.com/2014/07/set-up-spark-application-devleopme=
nt.html?m=3D1
> > > >
> > > > The IntelliJ sbt plugin is imo less buggy then the eclipse scalaIDE
> > > > stuff.  For example, I found I had to set some special preferences
> > > >
> > > > Finally... given sbts automated recompile option, if you just use
> tmux,
> > > > and vim nerdtree, with sbt , you could come pretty close to somethi=
ng
> > > like
> > > > an IDE without all the drama ..
> > > >
> > > > > On Oct 26, 2014, at 11:07 AM, ll <duy.huynh.uiv@gmail.com> wrote:
> > > > >
> > > > > i'm new to both scala and spark.  what IDE / dev environment do y=
ou
> > > find
> > > > most
> > > > > productive for writing code in scala with spark?  is it just vim =
+
> > sbt?
> > > > or
> > > > > does a full IDE like intellij works out better?  thanks!
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > View this message in context:
> > > >
> > >
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-sc=
ala-spark-development-tp8965.html
> > > > > Sent from the Apache Spark Developers List mailing list archive a=
t
> > > > Nabble.com.
> > > > >
> > > > >
> ---------------------------------------------------------------------
> > > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > > > For additional commands, e-mail: dev-help@spark.apache.org
> > > > >
> > > >
> > >
> >
>

--001a11c26a08135b630506697a05--

From dev-return-10000-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 15:56:55 2014
Return-Path: <dev-return-10000-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B873D17475
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 15:56:55 +0000 (UTC)
Received: (qmail 93786 invoked by uid 500); 27 Oct 2014 15:56:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 93718 invoked by uid 500); 27 Oct 2014 15:56:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 93706 invoked by uid 99); 27 Oct 2014 15:56:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 15:56:49 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of shivaram@berkeley.edu designates 209.85.212.178 as permitted sender)
Received: from [209.85.212.178] (HELO mail-wi0-f178.google.com) (209.85.212.178)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 15:56:24 +0000
Received: by mail-wi0-f178.google.com with SMTP id q5so6871471wiv.17
        for <dev@spark.incubator.apache.org>; Mon, 27 Oct 2014 08:54:53 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:reply-to:in-reply-to:references
         :date:message-id:subject:from:to:cc:content-type
         :content-transfer-encoding;
        bh=ZyYLLB2Ihrr1GOEYKbHpg/46ffXoyVNRFkeWk+j6cWc=;
        b=U6BmqCHKBusiOZLfiWvYLQzNhxsgIpSsQbegtvuNVDmY5+Po4E608P55OVoezPufzN
         kD3PA7pOHqh/disLBxH4eprIMZP9ii+Hs/f5iIY+0Xdokp94avPzYl/jW7PNSm99gZSs
         e9+C/BE9cj0TH1z2kcIBITB44FWTvxSV19ttaGqNiGW3yNxUTrlgFPDPPnMfiFZIAJae
         ZDFGiS/St8xO/1XWdT1c645CKmw9+SUhpHXyYQJZH7yYUVPGhd7FG7PA9SbYX8Z+vQeR
         uABo50JwDMaC2cw03fo1lvYKIxpPOCxEUpWYYDz0DWvVrjbxdTrhm8Qd+NHkPc1nTZdP
         HaQA==
X-Gm-Message-State: ALoCoQmzTxoamoqnqv8tFRcCviP8W7LIz53XXOn870q86K5LFR3ynqvjXYJdcn1Vm0ICXRNig/A8
MIME-Version: 1.0
X-Received: by 10.194.243.164 with SMTP id wz4mr3055267wjc.129.1414425293034;
 Mon, 27 Oct 2014 08:54:53 -0700 (PDT)
Reply-To: shivaram@eecs.berkeley.edu
Received: by 10.217.95.133 with HTTP; Mon, 27 Oct 2014 08:54:52 -0700 (PDT)
In-Reply-To: <CANx3uAiZLhM80TkaAbA5GejdGj-bcfHLOjs9CBQiwgVtaj2p0w@mail.gmail.com>
References: <1414336040472-8965.post@n3.nabble.com>
	<6558B993-2715-4F0D-9E96-257F0D3AF2FC@gmail.com>
	<CAN3RKnNRZ5dwQCuwCoYgCzj6BUCFqSeuTQ2m_DhM4RAnF+CWZQ@mail.gmail.com>
	<CAKW0i0xwWMSE_p2Ncbq45d=0x9Sg2Rqme3bKQSybzU9ymuWC7A@mail.gmail.com>
	<CAKn3j0sLkGZ8CCQdK1cMGZSRs8+Q+hnUNwK9y6TLJEn6m7M3eA@mail.gmail.com>
	<CANx3uAiZLhM80TkaAbA5GejdGj-bcfHLOjs9CBQiwgVtaj2p0w@mail.gmail.com>
Date: Mon, 27 Oct 2014 08:54:52 -0700
Message-ID: <CAKx7Bf_Ux=s9ZCMWC6=RVQHx1FGqns=k1yyHR=CdQ3BR2NRY0A@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
From: Shivaram Venkataraman <shivaram@eecs.berkeley.edu>
To: Koert Kuipers <koert@tresata.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

Also ctags works fine with vim for browsing scala classes

Shivaram

On Mon, Oct 27, 2014 at 8:49 AM, Koert Kuipers <koert@tresata.com> wrote:
> editor of your choice + sbt console works + grep great.
>
> if only folks stopped using wildcard imports (it has little benefits in
> terms of coding yet requires an IDE with 1G+ of ram to track em down).
>
> On Mon, Oct 27, 2014 at 9:17 AM, andy petrella <andy.petrella@gmail.com>
> wrote:
>
>> I second the S[B]T combo!
>>
>> I tried ATOM =E2=86=92 lack of features and stability (atm)
>>
>> a=E2=84=95dy =E2=84=99etrella
>> about.me/noootsab
>> [image: a=E2=84=95dy =E2=84=99etrella on about.me]
>>
>> <http://about.me/noootsab>
>>
>> On Mon, Oct 27, 2014 at 2:15 PM, Dean Wampler <deanwampler@gmail.com>
>> wrote:
>>
>> > For what it's worth, I use Sublime Text + the SBT console for
>> everything. I
>> > can live without the extra IDE features.
>> >
>> > However, if you like an IDE, the Eclipse "Scala IDE" 4.0 RC1 is a big
>> > improvement over previous releases. For one thing, it can now supports
>> > projects using different versions of Scala, which is convenient for
>> Spark's
>> > current 2.10.4 support and emerging 2.11 support.
>> >
>> > http://scala-ide.org/download/milestone.html
>> >
>> > Dean
>> >
>> >
>> > Dean Wampler, Ph.D.
>> > Author: Programming Scala, 2nd Edition
>> > <http://shop.oreilly.com/product/0636920033073.do> (O'Reilly)
>> > Typesafe <http://typesafe.com>
>> > @deanwampler <http://twitter.com/deanwampler>
>> > http://polyglotprogramming.com
>> >
>> > On Sun, Oct 26, 2014 at 5:06 PM, Duy Huynh <duy.huynh.uiv@gmail.com>
>> > wrote:
>> >
>> > > i like intellij and eclipse too, but some that they are too heavy.  =
i
>> > would
>> > > love to use vim.  are there are good scala plugins for vim?  (i.e co=
de
>> > > completion, scala doc, etc)
>> > >
>> > > On Sun, Oct 26, 2014 at 12:32 PM, Jay Vyas <
>> jayunit100.apache@gmail.com>
>> > > wrote:
>> > >
>> > > > I tried the scala eclipse ide but in scala 2.10 I ran into some we=
ird
>> > > > issues
>> > > >
>> > >
>> >
>> http://stackoverflow.com/questions/24253084/scalaide-and-cryptic-classno=
tfound-errors
>> > > > ... So I switched to IntelliJ and was much more satisfied...
>> > > >
>> > > > I've written a post on how I use fedora,sbt, and intellij for spar=
k
>> > apps.
>> > > >
>> > > >
>> > >
>> >
>> http://jayunit100.blogspot.com/2014/07/set-up-spark-application-devleopm=
ent.html?m=3D1
>> > > >
>> > > > The IntelliJ sbt plugin is imo less buggy then the eclipse scalaID=
E
>> > > > stuff.  For example, I found I had to set some special preferences
>> > > >
>> > > > Finally... given sbts automated recompile option, if you just use
>> tmux,
>> > > > and vim nerdtree, with sbt , you could come pretty close to someth=
ing
>> > > like
>> > > > an IDE without all the drama ..
>> > > >
>> > > > > On Oct 26, 2014, at 11:07 AM, ll <duy.huynh.uiv@gmail.com> wrote=
:
>> > > > >
>> > > > > i'm new to both scala and spark.  what IDE / dev environment do =
you
>> > > find
>> > > > most
>> > > > > productive for writing code in scala with spark?  is it just vim=
 +
>> > sbt?
>> > > > or
>> > > > > does a full IDE like intellij works out better?  thanks!
>> > > > >
>> > > > >
>> > > > >
>> > > > > --
>> > > > > View this message in context:
>> > > >
>> > >
>> >
>> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-s=
cala-spark-development-tp8965.html
>> > > > > Sent from the Apache Spark Developers List mailing list archive =
at
>> > > > Nabble.com.
>> > > > >
>> > > > >
>> ---------------------------------------------------------------------
>> > > > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> > > > > For additional commands, e-mail: dev-help@spark.apache.org
>> > > > >
>> > > >
>> > >
>> >
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10001-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 17:48:06 2014
Return-Path: <dev-return-10001-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 947F617916
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 17:48:06 +0000 (UTC)
Received: (qmail 50648 invoked by uid 500); 27 Oct 2014 17:48:05 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 50581 invoked by uid 500); 27 Oct 2014 17:48:05 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 50569 invoked by uid 99); 27 Oct 2014 17:48:05 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 17:48:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.179 as permitted sender)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 17:47:59 +0000
Received: by mail-lb0-f179.google.com with SMTP id w7so1567672lbi.10
        for <dev@spark.apache.org>; Mon, 27 Oct 2014 10:46:53 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=bLhgfsQPeH499wCQliwEmqO5GQeetYnwKDSN+eOIKj4=;
        b=fLQ+8tHKAg8FBqlpWaJQ9KlsZyT6sOoFae2enGamB2s/qeZ4mNxJoera8VjGPfcxaK
         lSXkkhRpX1z1QVjoRQrMav4+yVN5DWYSvcJ//7RVGEGl+vodaXCJMxXCe47QKicLkveZ
         HoQjpNXRddPevrpxCcH3QlI82K6Ec6jNX0QMleyFdoTPo6zw//9L9bCmA7nFynYcjCNB
         KMShBvZ4BbBjop8tdYBovZ3H0RBUWAQ5T6evj+1c1KLt04Ga+UFpDcO7o1XPX71glJJ3
         6G3gLrbUxwTDVrXE2S82lZO3ycJHEWIImtiaSW2IGU4fLvKDKdNfkoh8M4X6jwtJvWe6
         GsJg==
X-Gm-Message-State: ALoCoQkSSUOcD59bz7SmdmrUPE8ZJ8mPW/K2YuLGKZAffLDiwllkQ1QKpePAAaMAELsJmpozqfm0
X-Received: by 10.112.137.234 with SMTP id ql10mr5189570lbb.91.1414432013083;
 Mon, 27 Oct 2014 10:46:53 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.24.14 with HTTP; Mon, 27 Oct 2014 10:46:32 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 27 Oct 2014 10:46:32 -0700
Message-ID: <CACdU-dRGm71CO9Ov8R+a8FgE9kS0kj7e-dqS1Pkt9=4LdxpawQ@mail.gmail.com>
Subject: jenkins downtime tomorrow morning ~6am-8am PDT
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01176f07b2f2e005066b1d44
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01176f07b2f2e005066b1d44
Content-Type: text/plain; charset=UTF-8

i'll be bringing jenkins down tomorrow morning for some system maintenance
and to get our backups kicked off.

i do expect to have the system back up and running before 8am.

please let me know ASAP if i need to reschedule this.

thanks,

shane

--089e01176f07b2f2e005066b1d44--

From dev-return-10002-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 20:26:43 2014
Return-Path: <dev-return-10002-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1075517FC7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 20:26:43 +0000 (UTC)
Received: (qmail 77913 invoked by uid 500); 27 Oct 2014 20:26:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 77846 invoked by uid 500); 27 Oct 2014 20:26:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 77834 invoked by uid 99); 27 Oct 2014 20:26:41 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 20:26:41 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.217.170 as permitted sender)
Received: from [209.85.217.170] (HELO mail-lb0-f170.google.com) (209.85.217.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 20:26:37 +0000
Received: by mail-lb0-f170.google.com with SMTP id u10so6730712lbd.1
        for <dev@spark.apache.org>; Mon, 27 Oct 2014 13:24:45 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:from:date:message-id:subject:to
         :content-type;
        bh=YpZd+u2yEqANpmVS2DUiMeqn84WjspsWaaQ5XJJIRfI=;
        b=d5czcrBRwSd/P1ApDMA8sJurDHkgRktjLcXXyMHPPZcLADFwedPMU1816jyjhRfRL5
         nGiJT5fiTzB0F60FyBnyn4TA5RfoQXjKU0e3NdRvbh3t9ST4MVZ7XdeMRhrn5mFFVFq5
         PtqpgTuQiTIa14KSMlhjDZToV8PM8/BmE8wGjPbhrYliWyF6+9uDFCb9A1DA3v98/NHf
         Hz+1hpxqDffqzxU/KgDHQZMSptdYM/HOAVEOkWU9Ez4iig220Fm5YmkFB+C2+n+jHz2N
         bUXMnUH/9yCPyImgP1DQP+vy+7cO57YrVA3ISrpERXgpvRXu9KykMsaHfmBDBY8pSaci
         YKrg==
X-Gm-Message-State: ALoCoQn1gsEVH1dhzyBITMyLJAWItN/aBDvV9bh/amgqPazNz8hGZefUqG9sjqxhN/FEyj8za0S1
X-Received: by 10.112.137.234 with SMTP id ql10mr6099405lbb.91.1414441485692;
 Mon, 27 Oct 2014 13:24:45 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.24.14 with HTTP; Mon, 27 Oct 2014 13:24:25 -0700 (PDT)
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 27 Oct 2014 13:24:25 -0700
Message-ID: <CACdU-dRe6b-HL9-eTgF_fjuJAD+gRkU+pZKC-oTM5wXqTzzZ-A@mail.gmail.com>
Subject: jenkins emergency restart now, was Re: jenkins downtime tomorrow
 morning ~6am-8am PDT
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01176f074f7d9905066d521d
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01176f074f7d9905066d521d
Content-Type: text/plain; charset=UTF-8

so, i'm having a race condition between a plugin i installed putting
jenkins in to quiet mode and it failing to perform a backup from this past
weekend.  i'll need to restart the process and get it out of the
constantly-in-to-quiet-mode cycle it's in now.

this will be quick, and i'll restart the jobs i've killed.

this DOES NOT effect the restart/maintenance tomorrow morning.

sorry about the inconvenience,

shane

On Mon, Oct 27, 2014 at 10:46 AM, shane knapp <sknapp@berkeley.edu> wrote:

> i'll be bringing jenkins down tomorrow morning for some system maintenance
> and to get our backups kicked off.
>
> i do expect to have the system back up and running before 8am.
>
> please let me know ASAP if i need to reschedule this.
>
> thanks,
>
> shane
>

--089e01176f074f7d9905066d521d--

From dev-return-10003-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 20:41:29 2014
Return-Path: <dev-return-10003-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 96F8017209
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 20:41:29 +0000 (UTC)
Received: (qmail 20344 invoked by uid 500); 27 Oct 2014 20:41:27 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20280 invoked by uid 500); 27 Oct 2014 20:41:27 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20266 invoked by uid 99); 27 Oct 2014 20:41:27 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 20:41:27 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.48 as permitted sender)
Received: from [209.85.215.48] (HELO mail-la0-f48.google.com) (209.85.215.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 20:41:01 +0000
Received: by mail-la0-f48.google.com with SMTP id gq15so215746lab.7
        for <dev@spark.apache.org>; Mon, 27 Oct 2014 13:41:00 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=zUN/1IE1k8ceCgP9wdVJPstIY7WZgl8pFvcBDaNdZ6M=;
        b=JVmuvJ6oNupU0ELZWn94KGHEWjfVl5c0scuXYyxdy8PfJNW1of26vTcGBN2j5m2kqu
         yN2uaQ/rNkwgqOz80yfRp7BaSuKLg15FlVm2h7kFfcMVIP8LODMLj8D7HXhxn+oj/EOh
         qCPX0MJpQ6yO+JLH6f/OvRbHEz8qwP06wNiJoJskBFxfWKpTCm8xRtJo3HLrHbb+F9zd
         tKC1gOgwU/YepmfowFCZSjCdDjhYXBfUzKQPqCuzVPbYJul5qcxUY4yTY8rkiCOFbIUb
         3bzOLRlX00UoDy53lOR1ZY2itVnfISryBLZeLpkVP4NAtKu5js6i6oHeD89Vfx2tnXRn
         WA2w==
X-Gm-Message-State: ALoCoQli5HHFkWEKs0Xr1wXMa/zi5WTmPne+aqdS22O1R81UoK2v2J5eAcp/Q1UK5wyCzh731zs7
X-Received: by 10.112.148.130 with SMTP id ts2mr26533232lbb.43.1414442460526;
 Mon, 27 Oct 2014 13:41:00 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.24.14 with HTTP; Mon, 27 Oct 2014 13:40:39 -0700 (PDT)
In-Reply-To: <CACdU-dRe6b-HL9-eTgF_fjuJAD+gRkU+pZKC-oTM5wXqTzzZ-A@mail.gmail.com>
References: <CACdU-dRe6b-HL9-eTgF_fjuJAD+gRkU+pZKC-oTM5wXqTzzZ-A@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Mon, 27 Oct 2014 13:40:39 -0700
Message-ID: <CACdU-dR==OxkoU5iTgUpOzqsMMJ_THCOtq52mbK3PgN6+v6zAQ@mail.gmail.com>
Subject: Re: jenkins emergency restart now, was Re: jenkins downtime tomorrow
 morning ~6am-8am PDT
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a81ea6a50d505066d8c07
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a81ea6a50d505066d8c07
Content-Type: text/plain; charset=UTF-8

ok we're back up and building.  i've retriggered the jobs i killed.

On Mon, Oct 27, 2014 at 1:24 PM, shane knapp <sknapp@berkeley.edu> wrote:

> so, i'm having a race condition between a plugin i installed putting
> jenkins in to quiet mode and it failing to perform a backup from this past
> weekend.  i'll need to restart the process and get it out of the
> constantly-in-to-quiet-mode cycle it's in now.
>
> this will be quick, and i'll restart the jobs i've killed.
>
> this DOES NOT effect the restart/maintenance tomorrow morning.
>
> sorry about the inconvenience,
>
> shane
>
> On Mon, Oct 27, 2014 at 10:46 AM, shane knapp <sknapp@berkeley.edu> wrote:
>
>> i'll be bringing jenkins down tomorrow morning for some system
>> maintenance and to get our backups kicked off.
>>
>> i do expect to have the system back up and running before 8am.
>>
>> please let me know ASAP if i need to reschedule this.
>>
>> thanks,
>>
>> shane
>>
>
>

--047d7b3a81ea6a50d505066d8c07--

From dev-return-10004-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 21:15:37 2014
Return-Path: <dev-return-10004-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C494C173F2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 21:15:37 +0000 (UTC)
Received: (qmail 38186 invoked by uid 500); 27 Oct 2014 21:15:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38115 invoked by uid 500); 27 Oct 2014 21:15:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 38091 invoked by uid 99); 27 Oct 2014 21:15:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 21:15:36 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_HELO_PASS,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of wibenton@redhat.com designates 209.132.183.37 as permitted sender)
Received: from [209.132.183.37] (HELO mx5-phx2.redhat.com) (209.132.183.37)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 21:15:10 +0000
Received: from zmail14.collab.prod.int.phx2.redhat.com (zmail14.collab.prod.int.phx2.redhat.com [10.5.83.16])
	by mx5-phx2.redhat.com (8.14.4/8.14.4) with ESMTP id s9RLE6Qx014032;
	Mon, 27 Oct 2014 17:14:06 -0400
Date: Mon, 27 Oct 2014 17:14:06 -0400 (EDT)
From: Will Benton <willb@redhat.com>
To: ll <duy.huynh.uiv@gmail.com>
Cc: dev@spark.incubator.apache.org
Message-ID: <663587489.1004025.1414444445996.JavaMail.zimbra@redhat.com>
In-Reply-To: <1414336040472-8965.post@n3.nabble.com>
References: <1414336040472-8965.post@n3.nabble.com>
Subject: Re: best IDE for scala + spark development?
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: 7bit
X-Originating-IP: [10.5.82.11]
X-Mailer: Zimbra 8.0.6_GA_5922 (ZimbraWebClient - FF32 (Mac)/8.0.6_GA_5922)
Thread-Topic: best IDE for scala + spark development?
Thread-Index: kx1DTILFTP8n7rCKigrmrg7mtsGNBA==
X-Virus-Checked: Checked by ClamAV on apache.org

I'll chime in as yet another user who is extremely happy with sbt and a text editor.  (In my experience, running "ack" from the command line is usually just as easy and fast as using an IDE's find-in-project facility.)  You can, of course, extend editors with Scala-specific IDE-like functionality (in particular, I am aware of -- but have not used -- ENSIME for emacs or TextMate).

Since you're new to Scala, you may not know that you can run any sbt command preceded by a tilde, which will watch files in your project and run the command when anything changes.  Therefore, running "~compile" from the sbt repl will get you most of the continuous syntax-checking functionality you can get from an IDE.

best,
wb

----- Original Message -----
> From: "ll" <duy.huynh.uiv@gmail.com>
> To: dev@spark.incubator.apache.org
> Sent: Sunday, October 26, 2014 10:07:20 AM
> Subject: best IDE for scala + spark development?
> 
> i'm new to both scala and spark.  what IDE / dev environment do you find most
> productive for writing code in scala with spark?  is it just vim + sbt?  or
> does a full IDE like intellij works out better?  thanks!
> 
> 
> 
> --
> View this message in context:
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> Sent from the Apache Spark Developers List mailing list archive at
> Nabble.com.
> 
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
> 
> 

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10005-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 22:28:12 2014
Return-Path: <dev-return-10005-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 400A217737
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 22:28:12 +0000 (UTC)
Received: (qmail 51342 invoked by uid 500); 27 Oct 2014 22:28:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51263 invoked by uid 500); 27 Oct 2014 22:28:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51252 invoked by uid 99); 27 Oct 2014 22:28:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 22:28:09 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of vanzin@cloudera.com designates 209.85.192.46 as permitted sender)
Received: from [209.85.192.46] (HELO mail-qg0-f46.google.com) (209.85.192.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 22:27:44 +0000
Received: by mail-qg0-f46.google.com with SMTP id z60so4748303qgd.33
        for <dev@spark.apache.org>; Mon, 27 Oct 2014 15:25:28 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:date:message-id:subject:from:to
         :content-type;
        bh=p8Cxv6KzzttEHGjqWK8Bt+bnSjQF+c5Yi66L501Qa/g=;
        b=mtB3SV5/o6IRvTJN0uvqUdhcUb1eglbtWKyjOo7dXYYhkRtqgonOHx/LgkBHkLxB/2
         4GrpkLPtYRlqT4LdXMmwtCDQHxV8HBEK02B5/ld6zWa40uVoJh6Ts0dKp+1/TEa0eDr8
         2S3/DyOK6LkPw0F0Ys3PayvqVCpB/EKQvAgd+/6OUe9uQVSkS6/GDwbgIimhSqCSvwDb
         +Gb8jZwZWxW+wEZlxFA05gyc0p9XVXn4uOTiI48kUJ0rCc7eVkqJ5zW61aHWvjrzBySJ
         xv/Hvk0V7cJWgUC4j0czV85Uhm4IW3V/BqifrT3zIEaOFxpcWu638v0CtB1Uxs1mmAnZ
         9ZxA==
X-Gm-Message-State: ALoCoQnUJ1Vm1PamW6si18vCHAKMzLmq5NH0NQNPFYtP7aI6yKwyVLBWxXhdXvk4NVhN95pj6tmT
MIME-Version: 1.0
X-Received: by 10.224.65.9 with SMTP id g9mr38143469qai.96.1414448727949; Mon,
 27 Oct 2014 15:25:27 -0700 (PDT)
Received: by 10.229.114.5 with HTTP; Mon, 27 Oct 2014 15:25:27 -0700 (PDT)
Date: Mon, 27 Oct 2014 15:25:27 -0700
Message-ID: <CAAOnQ7uOso+F13HpLL+ngBfnGWYq_EFHnQ4H_Wf3zgiFzpci+g@mail.gmail.com>
Subject: HiveContext bug?
From: Marcelo Vanzin <vanzin@cloudera.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Hey guys,

I've been using the "HiveFromSpark" example to test some changes and I
ran into an issue that manifests itself as an NPE inside Hive code
because some configuration object is null.

Tracing back, it seems that `sessionState` being a lazy val in
HiveContext is causing it. That variably is only evaluated in [1],
while the call in [2] causes a Driver to be initialized by [3], which
the tries to use the thread-local session state ([4]) which hasn't
been set yet.

This could be seen as a Hive bug ([3] should probably be calling the
constructor that takes a conf object), but is there a reason why these
fields are lazy in HiveContext? I explicitly called
SessionState.setCurrentSessionState() before the
CommandProcessorFactory call and that seems to fix the issue too.

[1] https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala#L305
[2] https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala#L289
[3] https://github.com/apache/hive/blob/9c63b2fdc35387d735f4c9d08761203711d4974b/ql/src/java/org/apache/hadoop/hive/ql/processors/CommandProcessorFactory.java#L104
[4] https://github.com/apache/hive/blob/9c63b2fdc35387d735f4c9d08761203711d4974b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java#L286

-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10006-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Mon Oct 27 22:41:31 2014
Return-Path: <dev-return-10006-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 46052177A7
	for <apmail-spark-dev-archive@minotaur.apache.org>; Mon, 27 Oct 2014 22:41:31 +0000 (UTC)
Received: (qmail 83908 invoked by uid 500); 27 Oct 2014 22:41:30 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 83840 invoked by uid 500); 27 Oct 2014 22:41:30 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83827 invoked by uid 99); 27 Oct 2014 22:41:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 22:41:30 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of vanzin@cloudera.com designates 209.85.216.45 as permitted sender)
Received: from [209.85.216.45] (HELO mail-qa0-f45.google.com) (209.85.216.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Mon, 27 Oct 2014 22:41:26 +0000
Received: by mail-qa0-f45.google.com with SMTP id dc16so4574350qab.18
        for <dev@spark.apache.org>; Mon, 27 Oct 2014 15:41:05 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:content-type;
        bh=SWcR658wyaE3LJQlwdxzmAlclfr+qRA/i5gWigaB4UY=;
        b=bGUXKNj3OsxakCfYKTeE70tBtCIx6Ric4/vD79PcRNjq1etRzi3BllZ6CR3xzh6M4s
         fcx5o2KBQTGX/dR1Y258h1G12qmO2tXLc6y6Z3Wa/L6EgnXlVbsGqKMm1UqQMg1r85q1
         RWeLa1Eo8szs2O6l/m/XfjbhC4wS6bLu8D3CjmBpqjyxsOsTOK+nsibBigHpSW2apCnC
         Q0nJACC5EcMtmfS6wC8Xd6MGbhlbRPf2oeOdhh+evonzIegwj5Tt2se6/WgEtEyQebb9
         tsG1FWMhNLBcrXiY5vFvOCeg/Sh1Rb6D957F5Rv9CwfehJjpam7Vw24gqODYmmibiKsl
         AgbQ==
X-Gm-Message-State: ALoCoQkSCyabg3+TNfhuGO1yVa360kmXBRlEUNy4qIQcNv4mquzUpEZYDKT9Q4d4B1ZA/1fAS8ZS
MIME-Version: 1.0
X-Received: by 10.140.98.233 with SMTP id o96mr36330256qge.31.1414449665470;
 Mon, 27 Oct 2014 15:41:05 -0700 (PDT)
Received: by 10.229.114.5 with HTTP; Mon, 27 Oct 2014 15:41:05 -0700 (PDT)
In-Reply-To: <CAAOnQ7uOso+F13HpLL+ngBfnGWYq_EFHnQ4H_Wf3zgiFzpci+g@mail.gmail.com>
References: <CAAOnQ7uOso+F13HpLL+ngBfnGWYq_EFHnQ4H_Wf3zgiFzpci+g@mail.gmail.com>
Date: Mon, 27 Oct 2014 15:41:05 -0700
Message-ID: <CAAOnQ7vcgjn+sdbwGK0kjjPR2nu-6dfxdCNyyx7jK95b24PNFA@mail.gmail.com>
Subject: Re: HiveContext bug?
From: Marcelo Vanzin <vanzin@cloudera.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Well, looks like a huge coincidence, but this was just sent to github:
https://github.com/apache/spark/pull/2967

On Mon, Oct 27, 2014 at 3:25 PM, Marcelo Vanzin <vanzin@cloudera.com> wrote:
> Hey guys,
>
> I've been using the "HiveFromSpark" example to test some changes and I
> ran into an issue that manifests itself as an NPE inside Hive code
> because some configuration object is null.
>
> Tracing back, it seems that `sessionState` being a lazy val in
> HiveContext is causing it. That variably is only evaluated in [1],
> while the call in [2] causes a Driver to be initialized by [3], which
> the tries to use the thread-local session state ([4]) which hasn't
> been set yet.
>
> This could be seen as a Hive bug ([3] should probably be calling the
> constructor that takes a conf object), but is there a reason why these
> fields are lazy in HiveContext? I explicitly called
> SessionState.setCurrentSessionState() before the
> CommandProcessorFactory call and that seems to fix the issue too.
>
> [1] https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala#L305
> [2] https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala#L289
> [3] https://github.com/apache/hive/blob/9c63b2fdc35387d735f4c9d08761203711d4974b/ql/src/java/org/apache/hadoop/hive/ql/processors/CommandProcessorFactory.java#L104
> [4] https://github.com/apache/hive/blob/9c63b2fdc35387d735f4c9d08761203711d4974b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java#L286
>
> --
> Marcelo



-- 
Marcelo

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10007-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 05:40:37 2014
Return-Path: <dev-return-10007-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A156717640
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 05:40:37 +0000 (UTC)
Received: (qmail 9539 invoked by uid 500); 28 Oct 2014 05:40:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 9471 invoked by uid 500); 28 Oct 2014 05:40:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 9459 invoked by uid 99); 28 Oct 2014 05:40:36 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 05:40:36 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of Rahul.Singhal@guavus.com designates 204.232.241.167 as permitted sender)
Received: from [204.232.241.167] (HELO mx1.guavus.com) (204.232.241.167)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 05:40:08 +0000
Received: from MX3.guavus.com ([192.168.11.2]) by mx1.guavus.com
 ([204.232.241.167]) with mapi id 14.03.0174.001; Mon, 27 Oct 2014 22:39:04
 -0700
From: Rahul Singhal <Rahul.Singhal@guavus.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Workaround for python's inability to unzip zip64 spark assembly jar
Thread-Topic: Workaround for python's inability to unzip zip64 spark
 assembly jar
Thread-Index: AQHP8nF7NdWDkrqAgkGR9dJ/hDdHWw==
Date: Tue, 28 Oct 2014 05:39:04 +0000
Message-ID: <D0752A0D.2B088%rahul.singhal@guavus.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [61.12.3.116]
Content-Type: multipart/alternative;
	boundary="_000_D0752A0D2B088rahulsinghalguavuscom_"
MIME-Version: 1.0
X-Virus-Checked: Checked by ClamAV on apache.org

--_000_D0752A0D2B088rahulsinghalguavuscom_
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

Hi All,

We recently faced the known issue where pyspark does not work when the asse=
mbly jar contains more than 65K files. Our build and run time environment a=
re both Java 7 but python fails to unzip the assembly jar as expected (http=
s://issues.apache.org/jira/browse/SPARK-1911).

All nodes in our YARN cluster have spark deployed (at the same local locati=
on) on them so we are contemplating the following workaround (apart from us=
ing a Java 6 compiled assembly):

Modify PYTHONPATH to give preference to "$SPARK_HOME/python" & "$SPARK_HOME=
/python/lib/py4j-0.8.1-src.zip", with this the assembly does not need to be=
 unzipped to access the python files. This worked fine for with my limited =
testing. And I think, this should work as long as the only reason to unzip =
the assembly jar is to extract the python files and nothing else (any reaso=
n to believe that this may not be the case?).

I would appreciate your opinion on this workaround.

Thanks,
Rahul Singhal

--_000_D0752A0D2B088rahulsinghalguavuscom_--

From dev-return-10008-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 06:53:54 2014
Return-Path: <dev-return-10008-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2A2ED1788A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 06:53:54 +0000 (UTC)
Received: (qmail 56077 invoked by uid 500); 28 Oct 2014 06:53:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55960 invoked by uid 500); 28 Oct 2014 06:53:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 54972 invoked by uid 99); 28 Oct 2014 06:53:52 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 06:53:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=5.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of pwendell@gmail.com designates 209.85.214.176 as permitted sender)
Received: from [209.85.214.176] (HELO mail-ob0-f176.google.com) (209.85.214.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 06:53:48 +0000
Received: by mail-ob0-f176.google.com with SMTP id va2so28178obc.21
        for <multiple recipients>; Mon, 27 Oct 2014 23:51:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=5H9jQ0ZVkcKGEROct7U/FLOe7iRd0MtpsZyvdJWgf3E=;
        b=wV8QqkwUeetQD2adCjgcdSqvBZ+7Q3kppebEch0ovTHErRtRkZV7gY+dUOAKRR9W6a
         018M9+paNwdrcSXvU84eJUSabDZlPg+VugkXdhPmGwxKF0Ss7Fr/Qsm5KYvEDEZ94dqJ
         jdsrS+GRVfpLW9jLdZXcsZnsywRw0r/toSF1DUoY3qt5+fRUDHOQVXyWy5YbQ+Dg4cpR
         uUZWAOJ5RfFxUcxI64V8yGaWbV2gTykJG9t8i5kpImP56gCg5HPn9FfFZ9/nP57XOEl+
         N1IfL+dZIKtlb8S6FhsXXuofX8adRoJ9GC4JThRVOkgS/Qf7dk78M614EjNFijlZbn5Y
         KXUg==
MIME-Version: 1.0
X-Received: by 10.182.104.40 with SMTP id gb8mr167895obb.61.1414479117288;
 Mon, 27 Oct 2014 23:51:57 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Mon, 27 Oct 2014 23:51:57 -0700 (PDT)
In-Reply-To: <80833ADD533E324CA05C160E41B636610277F302@shsmsx102.ccr.corp.intel.com>
References: <80833ADD533E324CA05C160E41B636610277F302@shsmsx102.ccr.corp.intel.com>
Date: Mon, 27 Oct 2014 23:51:57 -0700
Message-ID: <CABPQxssd9Z99gWqxzA7xhF+QtD-+puT_tcU1xnM_jH1vxeYABw@mail.gmail.com>
Subject: Re: Support Hive 0.13 .1 in Spark SQL
From: Patrick Wendell <pwendell@gmail.com>
To: "Cheng, Hao" <hao.cheng@intel.com>
Cc: "user@spark.apache.org" <user@spark.apache.org>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Cheng,

Right now we aren't using stable API's to communicate with the Hive
Metastore. We didn't want to drop support for Hive 0.12 so right now
we are using a shim layer to support compiling for 0.12 and 0.13. This
is very costly to maintain.

If Hive has a stable meta-data API for talking to a Metastore, we
should use that (is HCatalog sufficient for this purpose?). Ideally we
would be able to talk to multiple versions of the Hive metastore and
we can keep a single internal version of Hive for our use of Serde's,
etc.

I've created SPARK-4114 for this:
https://issues.apache.org/jira/browse/SPARK-4114

This is a very important issue for Spark SQL, so I'd welcome comments
on that JIRA from anyone who is familiar with Hive/HCatalog internals.

- Patrick

On Mon, Oct 27, 2014 at 9:54 PM, Cheng, Hao <hao.cheng@intel.com> wrote:
> Hi, all
>
>    I have some PRs blocked by hive upgrading (e.g.
> https://github.com/apache/spark/pull/2570), the problem is some internal
> hive method signature changed, it's hard to make the compatible in code
> level (sql/hive) when switching back/forth the Hive versions.
>
>
>
>   I guess the motivation of the upgrading is to support the Metastore with
> different Hive versions. So, how about just keep the metastore related hive
> jars upgrading or utilize the HCatalog directly? And of course we can either
> leaving hive-exec.jar hive-cli.jar etc as 0.12 or upgrade to 0.13.1, but not
> support them both.
>
>
>
> Sorry if I missed some discussion of Hive upgrading.
>
>
>
> Cheng Hao

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10009-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 08:28:42 2014
Return-Path: <dev-return-10009-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1D37A17B39
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 08:28:42 +0000 (UTC)
Received: (qmail 74212 invoked by uid 500); 28 Oct 2014 08:28:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74138 invoked by uid 500); 28 Oct 2014 08:28:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74126 invoked by uid 99); 28 Oct 2014 08:28:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 08:28:39 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of duy.huynh.uiv@gmail.com designates 209.85.214.179 as permitted sender)
Received: from [209.85.214.179] (HELO mail-ob0-f179.google.com) (209.85.214.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 08:28:35 +0000
Received: by mail-ob0-f179.google.com with SMTP id m8so125165obr.10
        for <dev@spark.incubator.apache.org>; Tue, 28 Oct 2014 01:26:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=/bOvMw5eb1sSH5BV5Y0fgEckAq7AsxAw57tnecMf8VA=;
        b=afounzX2f6zW0Q1SidecdX1az8S5AaN5J4D8M8I9nVlckkIo/9vdYabqj8LShAWPTm
         DABn6Vt1+H4s1OcgJl5KbPWkNFx9VMFtnTB7Gf/e8DrZkI4deDJ2QVqSU+pdJrM9RWlP
         jKZG8IafYBaEAlTeRFaIwY3hc/gLqW3FjETxW4pZFvJjNQt94ZEBaK6GbpD3VKtTlwSk
         MIzF+XWHy3gNhL8yZVrcRuQ0UoFeip4b7ahTIo6NzpShWlncPMdE2sq7ZKIOCplnW7Fy
         6wc+4uTdC/0QkyzAAZzxnRWfz0DCdg23KfrmqnYlUr3jUUyd2vAnpiLTu7Qsy1cFgdh2
         EqPA==
MIME-Version: 1.0
X-Received: by 10.60.94.73 with SMTP id da9mr1682505oeb.10.1414484804505; Tue,
 28 Oct 2014 01:26:44 -0700 (PDT)
Received: by 10.76.75.74 with HTTP; Tue, 28 Oct 2014 01:26:44 -0700 (PDT)
In-Reply-To: <663587489.1004025.1414444445996.JavaMail.zimbra@redhat.com>
References: <1414336040472-8965.post@n3.nabble.com>
	<663587489.1004025.1414444445996.JavaMail.zimbra@redhat.com>
Date: Tue, 28 Oct 2014 04:26:44 -0400
Message-ID: <CAN3RKnPrhoLBiCfwbD5N1GVMxuMjSjO_VzFg6NLmbmNawmy+zw@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
From: Duy Huynh <duy.huynh.uiv@gmail.com>
To: Will Benton <willb@redhat.com>
Cc: "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=089e012291765014ad0506776866
X-Virus-Checked: Checked by ClamAV on apache.org

--089e012291765014ad0506776866
Content-Type: text/plain; charset=UTF-8

thanks everyone.  i've been using vim and sbt recently, and i really like
it.  it's lightweight, fast.  plus, ack, ctrl-t, nerdtre, etc. in vim do
all the good work.

but, as i'm not familiar with scala/spark api yet, i really wish to have
these two things in vim + sbt.

1.  code completion as in intellij (typing long method / class name in
scala/spark isn't that fun!)

2.  scala doc on the fly in the text editor (just so i don't have to switch
back and forth between the text editor and the scala doc)

did anyone have experience with adding these 2 things to vim?

thanks!






On Mon, Oct 27, 2014 at 5:14 PM, Will Benton <willb@redhat.com> wrote:

> I'll chime in as yet another user who is extremely happy with sbt and a
> text editor.  (In my experience, running "ack" from the command line is
> usually just as easy and fast as using an IDE's find-in-project facility.)
> You can, of course, extend editors with Scala-specific IDE-like
> functionality (in particular, I am aware of -- but have not used -- ENSIME
> for emacs or TextMate).
>
> Since you're new to Scala, you may not know that you can run any sbt
> command preceded by a tilde, which will watch files in your project and run
> the command when anything changes.  Therefore, running "~compile" from the
> sbt repl will get you most of the continuous syntax-checking functionality
> you can get from an IDE.
>
> best,
> wb
>
> ----- Original Message -----
> > From: "ll" <duy.huynh.uiv@gmail.com>
> > To: dev@spark.incubator.apache.org
> > Sent: Sunday, October 26, 2014 10:07:20 AM
> > Subject: best IDE for scala + spark development?
> >
> > i'm new to both scala and spark.  what IDE / dev environment do you find
> most
> > productive for writing code in scala with spark?  is it just vim + sbt?
> or
> > does a full IDE like intellij works out better?  thanks!
> >
> >
> >
> > --
> > View this message in context:
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> > Sent from the Apache Spark Developers List mailing list archive at
> > Nabble.com.
> >
> > ---------------------------------------------------------------------
> > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > For additional commands, e-mail: dev-help@spark.apache.org
> >
> >
>

--089e012291765014ad0506776866--

From dev-return-10010-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 09:30:41 2014
Return-Path: <dev-return-10010-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 377F717D8D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 09:30:41 +0000 (UTC)
Received: (qmail 23107 invoked by uid 500); 28 Oct 2014 09:30:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23036 invoked by uid 500); 28 Oct 2014 09:30:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23024 invoked by uid 99); 28 Oct 2014 09:30:39 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 09:30:39 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.216.175 as permitted sender)
Received: from [209.85.216.175] (HELO mail-qc0-f175.google.com) (209.85.216.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 09:30:35 +0000
Received: by mail-qc0-f175.google.com with SMTP id b13so175682qcw.6
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 02:30:15 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=He/UN28zKi09GjdsDTG51pSn4vnfsD8vu0Q1Az0Cfd8=;
        b=nKC7wiVapSfQm3beRHJXq23DKgHOwMKwsvRIjV6iy64dR5RdbgZK6/6A7VYLV4eNca
         YwoCB0P+fo3/97WA+tGh2oFgzAAYKfnF5sfrblvqm/JkWoi3fiZPQ1iba2fGvw0XCMFD
         /Mv2Bj/Yu8c0MooqNLTwhdHOx+Vce6LK5KbLozstVEzDNrsOzRWvNFCMCEPqpN7z2gHh
         iX1g8P3S/PmwNspccWv/7nyKRogFVWbrBYqXYjk/6gYto02kmB7BANd6zoGVX3gD/Emq
         vmRrDpEEDhfrVijNlAj6a0z0t49/DKJoqmIKL7urqNUVxaXNWRnNFGh4MaU7yOEQb6vi
         j5Sw==
X-Received: by 10.140.31.139 with SMTP id f11mr2869970qgf.30.1414488614484;
 Tue, 28 Oct 2014 02:30:14 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.86.149 with HTTP; Tue, 28 Oct 2014 02:29:54 -0700 (PDT)
In-Reply-To: <CAAOnQ7vcgjn+sdbwGK0kjjPR2nu-6dfxdCNyyx7jK95b24PNFA@mail.gmail.com>
References: <CAAOnQ7uOso+F13HpLL+ngBfnGWYq_EFHnQ4H_Wf3zgiFzpci+g@mail.gmail.com>
 <CAAOnQ7vcgjn+sdbwGK0kjjPR2nu-6dfxdCNyyx7jK95b24PNFA@mail.gmail.com>
From: Cheng Lian <lian.cs.zju@gmail.com>
Date: Tue, 28 Oct 2014 17:29:54 +0800
Message-ID: <CAA_qdLqdiDcX9muaHKBkHozo0XWVA5m1aRNq+me6M63XijCfDw@mail.gmail.com>
Subject: Re: HiveContext bug?
To: Marcelo Vanzin <vanzin@cloudera.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113a920867d42a0506784b6e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113a920867d42a0506784b6e
Content-Type: text/plain; charset=UTF-8

Hi Marcelo, yes this is a known Spark SQL bug and we've got PRs to fix it
(2887 & 2967). Not merged yet because newly merged Hive 0.13.1 support
causes some conflicts. Thanks for reporting this :)

On Tue, Oct 28, 2014 at 6:41 AM, Marcelo Vanzin <vanzin@cloudera.com> wrote:

> Well, looks like a huge coincidence, but this was just sent to github:
> https://github.com/apache/spark/pull/2967
>
> On Mon, Oct 27, 2014 at 3:25 PM, Marcelo Vanzin <vanzin@cloudera.com>
> wrote:
> > Hey guys,
> >
> > I've been using the "HiveFromSpark" example to test some changes and I
> > ran into an issue that manifests itself as an NPE inside Hive code
> > because some configuration object is null.
> >
> > Tracing back, it seems that `sessionState` being a lazy val in
> > HiveContext is causing it. That variably is only evaluated in [1],
> > while the call in [2] causes a Driver to be initialized by [3], which
> > the tries to use the thread-local session state ([4]) which hasn't
> > been set yet.
> >
> > This could be seen as a Hive bug ([3] should probably be calling the
> > constructor that takes a conf object), but is there a reason why these
> > fields are lazy in HiveContext? I explicitly called
> > SessionState.setCurrentSessionState() before the
> > CommandProcessorFactory call and that seems to fix the issue too.
> >
> > [1]
> https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala#L305
> > [2]
> https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveContext.scala#L289
> > [3]
> https://github.com/apache/hive/blob/9c63b2fdc35387d735f4c9d08761203711d4974b/ql/src/java/org/apache/hadoop/hive/ql/processors/CommandProcessorFactory.java#L104
> > [4]
> https://github.com/apache/hive/blob/9c63b2fdc35387d735f4c9d08761203711d4974b/ql/src/java/org/apache/hadoop/hive/ql/Driver.java#L286
> >
> > --
> > Marcelo
>
>
>
> --
> Marcelo
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--001a113a920867d42a0506784b6e--

From dev-return-10011-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 09:35:04 2014
Return-Path: <dev-return-10011-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C83CC17DAB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 09:35:04 +0000 (UTC)
Received: (qmail 35589 invoked by uid 500); 28 Oct 2014 09:35:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 35517 invoked by uid 500); 28 Oct 2014 09:35:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 35505 invoked by uid 99); 28 Oct 2014 09:35:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 09:35:03 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.216.46 as permitted sender)
Received: from [209.85.216.46] (HELO mail-qa0-f46.google.com) (209.85.216.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 09:34:59 +0000
Received: by mail-qa0-f46.google.com with SMTP id s7so153687qap.5
        for <dev@spark.incubator.apache.org>; Tue, 28 Oct 2014 02:34:38 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=rrV2QM9zgbtjb5amYWbb41R/d4h9oHNr1ruWrd7AEvU=;
        b=qjiINJB4ld+HJRlAC7YtTesCORNARBhjtUI7nmErVMi2CXNw/RnQR70Xbzrg8dF1mr
         aCp0A1Y9XmPyt9TR92BtpfVsaf5/rJdVyAvFp5SOt8O9bKigLUwHcCj9eiktugHWE5kj
         k6iROYRpbWErdVQXAPSnYeuqbeUXh0oDpLSDgi7gfW+F019Wq8b3hpWzx8zS6pn4EJ5H
         jXRoOhZ2hQnNIs6UuJZtn4vGSX3WDZCfRVB05f5XMQ4DKhbM1AGkBeTH5ktj7KVMoG4s
         nBNwxXe02uLBE9AESZyfyJPx+QW9pMZjPj4D8g/3ily0lBSZygy8fRATXI/N+ZmXe52a
         WlVA==
X-Received: by 10.224.61.7 with SMTP id r7mr3023675qah.9.1414488878713; Tue,
 28 Oct 2014 02:34:38 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.140.86.149 with HTTP; Tue, 28 Oct 2014 02:34:18 -0700 (PDT)
In-Reply-To: <CAN3RKnPrhoLBiCfwbD5N1GVMxuMjSjO_VzFg6NLmbmNawmy+zw@mail.gmail.com>
References: <1414336040472-8965.post@n3.nabble.com> <663587489.1004025.1414444445996.JavaMail.zimbra@redhat.com>
 <CAN3RKnPrhoLBiCfwbD5N1GVMxuMjSjO_VzFg6NLmbmNawmy+zw@mail.gmail.com>
From: Cheng Lian <lian.cs.zju@gmail.com>
Date: Tue, 28 Oct 2014 17:34:18 +0800
Message-ID: <CAA_qdLrckQBCwPJNJtiO4kzQgkDURA0HY1+HjWNK1RebOCG1AQ@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
To: Duy Huynh <duy.huynh.uiv@gmail.com>
Cc: Will Benton <willb@redhat.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3d4022790920506785b5b
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3d4022790920506785b5b
Content-Type: text/plain; charset=UTF-8

My two cents for Mac Vim/Emacs users. Fixed a Scala ctags Mac compatibility
bug months ago, and you may want to use the most recent version here
https://github.com/scala/scala-dist/blob/master/tool-support/src/emacs/contrib/dot-ctags



On Tue, Oct 28, 2014 at 4:26 PM, Duy Huynh <duy.huynh.uiv@gmail.com> wrote:

> thanks everyone.  i've been using vim and sbt recently, and i really like
> it.  it's lightweight, fast.  plus, ack, ctrl-t, nerdtre, etc. in vim do
> all the good work.
>
> but, as i'm not familiar with scala/spark api yet, i really wish to have
> these two things in vim + sbt.
>
> 1.  code completion as in intellij (typing long method / class name in
> scala/spark isn't that fun!)
>
> 2.  scala doc on the fly in the text editor (just so i don't have to switch
> back and forth between the text editor and the scala doc)
>
> did anyone have experience with adding these 2 things to vim?
>
> thanks!
>
>
>
>
>
>
> On Mon, Oct 27, 2014 at 5:14 PM, Will Benton <willb@redhat.com> wrote:
>
> > I'll chime in as yet another user who is extremely happy with sbt and a
> > text editor.  (In my experience, running "ack" from the command line is
> > usually just as easy and fast as using an IDE's find-in-project
> facility.)
> > You can, of course, extend editors with Scala-specific IDE-like
> > functionality (in particular, I am aware of -- but have not used --
> ENSIME
> > for emacs or TextMate).
> >
> > Since you're new to Scala, you may not know that you can run any sbt
> > command preceded by a tilde, which will watch files in your project and
> run
> > the command when anything changes.  Therefore, running "~compile" from
> the
> > sbt repl will get you most of the continuous syntax-checking
> functionality
> > you can get from an IDE.
> >
> > best,
> > wb
> >
> > ----- Original Message -----
> > > From: "ll" <duy.huynh.uiv@gmail.com>
> > > To: dev@spark.incubator.apache.org
> > > Sent: Sunday, October 26, 2014 10:07:20 AM
> > > Subject: best IDE for scala + spark development?
> > >
> > > i'm new to both scala and spark.  what IDE / dev environment do you
> find
> > most
> > > productive for writing code in scala with spark?  is it just vim + sbt?
> > or
> > > does a full IDE like intellij works out better?  thanks!
> > >
> > >
> > >
> > > --
> > > View this message in context:
> > >
> >
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> > > Sent from the Apache Spark Developers List mailing list archive at
> > > Nabble.com.
> > >
> > > ---------------------------------------------------------------------
> > > To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> > > For additional commands, e-mail: dev-help@spark.apache.org
> > >
> > >
> >
>

--001a11c3d4022790920506785b5b--

From dev-return-10012-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 09:45:49 2014
Return-Path: <dev-return-10012-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E31A617DE8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 09:45:48 +0000 (UTC)
Received: (qmail 63176 invoked by uid 500); 28 Oct 2014 09:45:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 63108 invoked by uid 500); 28 Oct 2014 09:45:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 63097 invoked by uid 99); 28 Oct 2014 09:45:47 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 09:45:47 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 09:45:43 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <ashutosh.trivedi@iiitb.org>)
	id 1Xj3Kn-0005IL-Rn
	for dev@spark.incubator.apache.org; Tue, 28 Oct 2014 02:45:01 -0700
Date: Tue, 28 Oct 2014 02:45:01 -0700 (PDT)
From: Ashutosh <ashutosh.trivedi@iiitb.org>
To: dev@spark.incubator.apache.org
Message-ID: <1414489501850-8990.post@n3.nabble.com>
In-Reply-To: <1414471251511-8984.post@n3.nabble.com>
References: <1413883380883-8880.post@n3.nabble.com> <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com> <1413920470217-8894.post@n3.nabble.com> <1414151748436-8935.post@n3.nabble.com> <1414471251511-8984.post@n3.nabble.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Anant,

Thank you for reviewing and helping us out. Please find the following link
where you can see the initial code.
https://github.com/codeAshu/Outlier-Detection-with-AVF-Spark/blob/master/OutlierWithAVFModel.scala


The input file for the code should be in csv format. We have provided a
dataset there at the link.

We are currently facing the following style issues in the code(code is
working fine though) :

At line no 62 and 79 we have redundant functions and variables
(count_dataPoint, count_trimmedData) for giving  line numbers within the
function trimScores().
 
At line no 144 and 149 if we do not use two separate functions to increment
line numbers we get erroneous results . Is there any alternative way of
handling that?

We think that it because of scala clousers where any local variable which is
not in RDD doesn't get updated in subsequent pairRDDFunctions.


Regards,
Ashutosh & Kaushik 



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p8990.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10013-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 13:37:02 2014
Return-Path: <dev-return-10013-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3635417590
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 13:37:02 +0000 (UTC)
Received: (qmail 57298 invoked by uid 500); 28 Oct 2014 13:37:01 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57228 invoked by uid 500); 28 Oct 2014 13:37:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57217 invoked by uid 99); 28 Oct 2014 13:37:00 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 13:37:00 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sknapp@berkeley.edu designates 209.85.215.48 as permitted sender)
Received: from [209.85.215.48] (HELO mail-la0-f48.google.com) (209.85.215.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 13:36:56 +0000
Received: by mail-la0-f48.google.com with SMTP id gq15so608459lab.7
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 06:35:49 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:content-type;
        bh=GsT7aVmy7LGwQWcv/hR3X8n1YtMVSqYKhYLA7Mwmbjg=;
        b=JzR66zOT5G8SNBC0ocJrCKYV1VMOCk6+VmCrGnf1srr9u5ZbDC0eA4/gnOiuxoeXDT
         qYlFcZBAA61hsA869EhMgyfYlTAN8dsb8W+SOIRGsUlZdMRpO38WGnLTek9bddqvzWpx
         hurr7nfllzXik1RCW3w2fC3+9sHq3CfSSmruRe4d8Cnd2a6MOL0625Xz5yecCEiVMFKf
         q3ICl9Nf7e8+zOJT5NmIiwL+/ujwLT7cs9je0W/IC8s7FNWrBB72YauPZLNgk42LwjT+
         cMml9hDSokCCoRnQyGlfsTkh3fe+wOmIkm6Cw/ouefDbG+tzfzu+gAC0kPE98iBQ1liX
         PWmA==
X-Gm-Message-State: ALoCoQnqqPV2IdaZbmikZw6QmzODjA1MhHtQgwYDbn5sngRGVTexpVGNGaE/fETDxjBIyfw8+YbL
X-Received: by 10.152.28.134 with SMTP id b6mr4285288lah.12.1414503347798;
 Tue, 28 Oct 2014 06:35:47 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.24.14 with HTTP; Tue, 28 Oct 2014 06:35:27 -0700 (PDT)
In-Reply-To: <CACdU-dRGm71CO9Ov8R+a8FgE9kS0kj7e-dqS1Pkt9=4LdxpawQ@mail.gmail.com>
References: <CACdU-dRGm71CO9Ov8R+a8FgE9kS0kj7e-dqS1Pkt9=4LdxpawQ@mail.gmail.com>
From: shane knapp <sknapp@berkeley.edu>
Date: Tue, 28 Oct 2014 06:35:27 -0700
Message-ID: <CACdU-dSsNnccPG2656YKpUDKPPEe-mORJ=iaYxbzwviNmnfY4w@mail.gmail.com>
Subject: Re: jenkins downtime tomorrow morning ~6am-8am PDT
To: amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e0160a63894593905067bb981
X-Virus-Checked: Checked by ClamAV on apache.org

--089e0160a63894593905067bb981
Content-Type: text/plain; charset=UTF-8

this is done, and jenkins is up and building again.

On Mon, Oct 27, 2014 at 10:46 AM, shane knapp <sknapp@berkeley.edu> wrote:

> i'll be bringing jenkins down tomorrow morning for some system maintenance
> and to get our backups kicked off.
>
> i do expect to have the system back up and running before 8am.
>
> please let me know ASAP if i need to reschedule this.
>
> thanks,
>
> shane
>

--089e0160a63894593905067bb981--

From dev-return-10014-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 17:18:53 2014
Return-Path: <dev-return-10014-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 1AA3C17DBD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 17:18:53 +0000 (UTC)
Received: (qmail 2519 invoked by uid 500); 28 Oct 2014 17:18:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2453 invoked by uid 500); 28 Oct 2014 17:18:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2432 invoked by uid 99); 28 Oct 2014 17:18:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 17:18:50 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [134.100.9.70] (HELO mailhost.informatik.uni-hamburg.de) (134.100.9.70)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 17:18:22 +0000
Received: from localhost (localhost [127.0.0.1])
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTP id B7FC6EC4
	for <dev@spark.apache.org>; Tue, 28 Oct 2014 18:18:21 +0100 (CET)
X-Virus-Scanned: amavisd-new at informatik.uni-hamburg.de
Received: from mailhost.informatik.uni-hamburg.de ([127.0.0.1])
	by localhost (mailhost.informatik.uni-hamburg.de [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id 3qxkSavfdXl1 for <dev@spark.apache.org>;
	Tue, 28 Oct 2014 18:18:21 +0100 (CET)
Received: from [172.21.59.33] (uhh-wlan-fo-134-100-17-1.rrz.uni-hamburg.de [134.100.17.1])
	(using TLSv1 with cipher ECDHE-RSA-AES128-SHA (128/128 bits))
	(Client did not present a certificate)
	(Authenticated sender: 1wilcke)
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTPSA id 38465EC3
	for <dev@spark.apache.org>; Tue, 28 Oct 2014 18:18:21 +0100 (CET)
Message-ID: <544FCFD3.9020606@informatik.uni-hamburg.de>
Date: Tue, 28 Oct 2014 18:18:11 +0100
From: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Icedove/24.8.1
MIME-Version: 1.0
To: dev@spark.apache.org
Subject: How to run tests properly?
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

I want to contribute to the MLlib library but I can't get the tests up
working. I've found three ways of running the tests on the commandline.
I just want to execute the MLlib tests.

1. via dev/run-tests script
    This script executes all tests and take several hours to finish.
Some tests failed but I can't say which of them. Should this really take
that long? Can I specify to run only MLlib tests?

2. directly via maven
I did the following described in the docs [0].

export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M
-XX:ReservedCodeCacheSize=512m"
mvn -Pyarn -Phadoop-2.3 -DskipTests -Phive clean package
mvn -Pyarn -Phadoop-2.3 -Phive test

This also doesn't work.
Why do I have to package spark bevore running the tests?

3. via sbt
I tried the following. I freshly cloned spark and checked out the tag
v1.1.0-rc4.

sbt/sbt "project mllib" test

and get the following exception in several cluster tests.

[info] - task size should be small in both training and prediction ***
FAILED ***
[info]   org.apache.spark.SparkException: Job aborted due to stage
failure: Master removed our application: FAILED
[info]   at
org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1185)
[info]   at
org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1174)
[info]   at
org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1173)
[info]   at
scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
[info]   at
scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
[info]   at
org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1173)
[info]   at
org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:688)
[info]   at
org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:688)
[info]   at scala.Option.foreach(Option.scala:236)
[info]   at
org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:688)

summary:

[error] Failed: Total 223, Failed 12, Errors 0, Passed 211
[error] Failed tests:
[error]         org.apache.spark.mllib.clustering.KMeansClusterSuite
[error]        
org.apache.spark.mllib.classification.LogisticRegressionClusterSuite
[error]        
org.apache.spark.mllib.optimization.GradientDescentClusterSuite
[error]         org.apache.spark.mllib.classification.SVMClusterSuite
[error]        
org.apache.spark.mllib.linalg.distributed.RowMatrixClusterSuite
[error]        
org.apache.spark.mllib.regression.LinearRegressionClusterSuite
[error]         org.apache.spark.mllib.classification.NaiveBayesClusterSuite
[error]         org.apache.spark.mllib.regression.LassoClusterSuite
[error]        
org.apache.spark.mllib.regression.RidgeRegressionClusterSuite
[error]         org.apache.spark.mllib.optimization.LBFGSClusterSuite
[error] (mllib/test:test) sbt.TestsFailedException: Tests unsuccessful
[error] Total time: 661 s, completed 28.10.2014 17:13:10
sbt/sbt "project mllib" test  761,74s user 22,86s system 109% cpu
11:59,57 total

I tried several slightly different ways but I can't get the tests working.
I observed that the tests are running __very__ slow in some
configurations. The cpu nearly idles and the ram usage is low.

Am I doing something fundamental wrong? After many hours of trial and
error I'm stuck.
Long build and test durations are making it difficult to investigate.
Hopefully someone can give me a hint.
Which one is the right way to flexibly run the tests of the different
sub projects.

Thanks,
Niklas


[0] https://spark.apache.org/docs/latest/building-with-maven.html

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10015-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 17:22:41 2014
Return-Path: <dev-return-10015-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4874317DE1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 17:22:41 +0000 (UTC)
Received: (qmail 17830 invoked by uid 500); 28 Oct 2014 17:22:40 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 17755 invoked by uid 500); 28 Oct 2014 17:22:40 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 87804 invoked by uid 99); 28 Oct 2014 17:12:59 -0000
X-ASF-Spam-Status: No, hits=2.3 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of anant.asty@gmail.com does not designate 216.139.236.26 as permitted sender)
Date: Tue, 28 Oct 2014 10:12:33 -0700 (PDT)
From: slcclimber <anant.asty@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <1414516353788-8992.post@n3.nabble.com>
In-Reply-To: <1414489501850-8990.post@n3.nabble.com>
References: <1413883380883-8880.post@n3.nabble.com> <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com> <1413920470217-8894.post@n3.nabble.com> <1414151748436-8935.post@n3.nabble.com> <1414471251511-8984.post@n3.nabble.com> <1414489501850-8990.post@n3.nabble.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Ashu,
There is one main issue and  a few stylistic/ grammatical things I noticed.
1> You take and rdd or type String which you expect to be comma separated.
This limits usability since the user will have to convert their RDD to that
format only for you to split it on string.
It would make more sense to take an RDD of type (col_num:Int ,
attr_value:Int), frequency:Int) 
You could also use Long instead of Int.

2> the increment functions could be more along the lines of 
    def incr = {count += 1; count}
which is ina a more functional style

3> reset functions could be simply 
    def reset_count = count = 1L

4> in
https://github.com/codeAshu/Outlier-Detection-with-AVF-Spark/blob/master/OutlierWithAVFModel.scala#L108
You have a key of type string which is basically a string of form "number,
string"
when you could just have a tuple of the form (i:Int, word:String)

5? the lines exceed the style guides 100 character length

Thanks
Anant



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p8992.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10016-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 18:05:19 2014
Return-Path: <dev-return-10016-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 679C017FB8
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 18:05:19 +0000 (UTC)
Received: (qmail 46359 invoked by uid 500); 28 Oct 2014 18:05:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46288 invoked by uid 500); 28 Oct 2014 18:05:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46277 invoked by uid 99); 28 Oct 2014 18:05:15 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 18:05:15 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.213.181 as permitted sender)
Received: from [209.85.213.181] (HELO mail-ig0-f181.google.com) (209.85.213.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Tue, 28 Oct 2014 18:05:11 +0000
Received: by mail-ig0-f181.google.com with SMTP id l13so1681251iga.2
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 11:03:41 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=NYltHqgnmhdCuuzITv/PdVjO7hujekeCWXU+a1dH+iM=;
        b=dEmZWF1hF1fKjJR0Fy6Mlln8oQ5SHtY0WJYjWHfNbWn2J2fCVW0N7BIPERvmZih5Hb
         J8aFonDjyzMkObMt1fJDbvczzTn3JhkflKHEyhFX+jem2Dit7hdbFHjkJ/J7kcnjq3Gt
         8cTcWbT0xU8P/LXcP45ME6cxby97rs6ArsM0iL8Gwq4nYtF0LsYZ63w1eN5rWlpsh3OQ
         nuSAp00lhehfFggGf3fz4VfxoDKP+H/qE2J+YvmgHHbKKg36VdOeKp2lacgfcdvy/to6
         L94/kPtDrpTyOV9llVGlSq8BOUoM6vblq5d0SZd2OwQ5t8KjrGp97YqHZBLLnpKz8haS
         9XuA==
X-Gm-Message-State: ALoCoQnegCEVDPrhgRkjNjZhy5ZjCK23SsMUnSrUCfBlgUZ/CcYwotJt+LCevKzheU5xyF+mW2gB
X-Received: by 10.50.119.195 with SMTP id kw3mr6566516igb.5.1414519421178;
 Tue, 28 Oct 2014 11:03:41 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.136.221 with HTTP; Tue, 28 Oct 2014 11:03:20 -0700 (PDT)
In-Reply-To: <544FCFD3.9020606@informatik.uni-hamburg.de>
References: <544FCFD3.9020606@informatik.uni-hamburg.de>
From: Sean Owen <sowen@cloudera.com>
Date: Tue, 28 Oct 2014 19:03:20 +0100
Message-ID: <CAMAsSdLbDLE_Lo3pAGOC05FSPjhRC8wN_3BqqbqzUFaarxdmgg@mail.gmail.com>
Subject: Re: How to run tests properly?
To: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
Cc: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On Tue, Oct 28, 2014 at 6:18 PM, Niklas Wilcke
<1wilcke@informatik.uni-hamburg.de> wrote:
> 1. via dev/run-tests script
>     This script executes all tests and take several hours to finish.
> Some tests failed but I can't say which of them. Should this really take
> that long? Can I specify to run only MLlib tests?

Yes, running all tests takes a long long time. It does print which
tests failed, and you can see the errors in the test output.

Did you read http://spark.apache.org/docs/latest/building-with-maven.html#spark-tests-in-maven
? This shows how to run just one test suite.

In any Maven project you can try things like "mvn test -pl [module]"
to run just one module's tests.


> 2. directly via maven
> I did the following described in the docs [0].
>
> export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M
> -XX:ReservedCodeCacheSize=512m"
> mvn -Pyarn -Phadoop-2.3 -DskipTests -Phive clean package
> mvn -Pyarn -Phadoop-2.3 -Phive test
>
> This also doesn't work.
> Why do I have to package spark bevore running the tests?

What doesn't work?
Some tests use the built assembly, which requires packaging.


> 3. via sbt
> I tried the following. I freshly cloned spark and checked out the tag
> v1.1.0-rc4.
>
> sbt/sbt "project mllib" test
>
> and get the following exception in several cluster tests.
>
> [info] - task size should be small in both training and prediction ***
> FAILED ***

This just looks like a flaky test failure; I'd try again.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10017-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Tue Oct 28 20:02:53 2014
Return-Path: <dev-return-10017-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0A9E0176B0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Tue, 28 Oct 2014 20:02:53 +0000 (UTC)
Received: (qmail 2577 invoked by uid 500); 28 Oct 2014 20:02:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2504 invoked by uid 500); 28 Oct 2014 20:02:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 84386 invoked by uid 99); 28 Oct 2014 19:54:11 -0000
X-ASF-Spam-Status: No, hits=3.0 required=10.0
	tests=FORGED_YAHOO_RCVD,RCVD_IN_DNSWL_NONE,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: 216.139.236.26 is neither permitted nor denied by domain of xs6w@yahoo.com)
Date: Tue, 28 Oct 2014 12:53:45 -0700 (PDT)
From: Xuepeng Sun <xs6w@yahoo.com>
To: dev@spark.incubator.apache.org
Message-ID: <1414526025763-8996.post@n3.nabble.com>
Subject: Breeze::DiffFunction not serializable
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi,

    I'm trying to call Breeze::LBFGS from the master on each partition but
getting *NonSerializable* error. 
I guess it's well-known that the Breeze DiffFunction is not serializable. 
 
///
import breeze.linalg.{Vector => BV, DenseVector=>BDV, SparseVector=>BSV}

val lbfgs = new breeze.optimize.LBFGS[BDV[Double]]
val wInit: BDV[Double] = Array.fill(numFeatures)(0.0).toBreeze

def localUpdate(d:Array[(Double, BV[Double])], w:BDV[Double]) : BDV[Double]
{
    	 
    def getObj = new DiffFunction[BDV[Double]] {

       def calculate(w: BDV[Double]) : (Double, BDV[Double]) = 
       {
        ...
       }
    }
    lbfgs.minimize(getObj, w)  
}

rdd.mapPartitions{ 

   iter: Iterator[(Double, BV[Double])] => {
            
         val d : Array[(Double, BV[Double])] = iter.toArray			
 	 
         val w : BDV[Double] = localUpdate(d, wInit) 	
         Iterator(w)
} 




The following link talks about using the KyroSerializationWrapper as a
solution: 

http://http://stackoverflow.com/questions/23050067/spark-task-not-serializable-how-to-work-with-complex-map-closures-that-call-o
<http://http://stackoverflow.com/questions/23050067/spark-task-not-serializable-how-to-work-with-complex-map-closures-that-call-o>  

But I didn't have good luck yet. Can some one points to a work-around way to
do the serialization?   
Thanks a lot. 


Xuepeng






--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Breeze-DiffFunction-not-serializable-tp8996.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10018-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 02:44:02 2014
Return-Path: <dev-return-10018-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F1F19176C1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 02:44:02 +0000 (UTC)
Received: (qmail 59502 invoked by uid 500); 29 Oct 2014 02:44:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 59445 invoked by uid 500); 29 Oct 2014 02:44:02 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 59433 invoked by uid 99); 29 Oct 2014 02:44:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 02:44:01 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of javadba@gmail.com designates 209.85.220.171 as permitted sender)
Received: from [209.85.220.171] (HELO mail-vc0-f171.google.com) (209.85.220.171)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 02:43:35 +0000
Received: by mail-vc0-f171.google.com with SMTP id im17so1101252vcb.16
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 19:42:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=DLmgTFykc5PiMEm0sdHzSfsaftQQDp5wKH8mtJ2WxJQ=;
        b=W1V8t/fgRCKB0B+c3VCKW58xfTqR/Zdend3ULZB3+QZUsIaQThQKndojUjAQG/wxb0
         wvUAVc3Jx/z8ylYCSmHZdoYN+8kKJcwOGG8tz4RPKMyBzL1/hjE5892WBLZEU+l1IIMS
         +FHnBeb46300o///hhbpfIkNhbgOraPaGdjjUBPCPM4B4PNEB8kOnSpo371DO7B9kfa4
         OYWbKTl/rhFlTYU57VpoU4+AtAwcOfH0+RMwGrEoVMJVoDw9bTLwVfgaRT3OjocRmmue
         7fkZoc85ETJTjWdRAqydztFULFbAwg/wzvl78a2z+sZK2t2Zm2a9e5d0q8DGwW0el0jV
         pLRA==
MIME-Version: 1.0
X-Received: by 10.52.75.200 with SMTP id e8mr4191441vdw.32.1414550568506; Tue,
 28 Oct 2014 19:42:48 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Tue, 28 Oct 2014 19:42:48 -0700 (PDT)
Date: Tue, 28 Oct 2014 19:42:48 -0700
Message-ID: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
Subject: HiveShim not found when building in Intellij
From: Stephen Boesch <javadba@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=20cf3071c9fa271956050686b8b1
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf3071c9fa271956050686b8b1
Content-Type: text/plain; charset=UTF-8

I have run on the command line via maven and it is fine:

mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn -Phadoop-2.3
 compile package install


But with the latest code Intellij builds do not work. Following is one of
26 similar errors:


Error:(173, 38) not found: value HiveShim
          Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
                                     ^

--20cf3071c9fa271956050686b8b1--

From dev-return-10019-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 02:48:25 2014
Return-Path: <dev-return-10019-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 384D4176CD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 02:48:25 +0000 (UTC)
Received: (qmail 66356 invoked by uid 500); 29 Oct 2014 02:48:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 66291 invoked by uid 500); 29 Oct 2014 02:48:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 66279 invoked by uid 99); 29 Oct 2014 02:48:23 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 02:48:23 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of matei.zaharia@gmail.com designates 209.85.220.46 as permitted sender)
Received: from [209.85.220.46] (HELO mail-pa0-f46.google.com) (209.85.220.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 02:47:55 +0000
Received: by mail-pa0-f46.google.com with SMTP id lf10so2135650pab.19
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 19:46:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=content-type:mime-version:subject:from:in-reply-to:date:cc
         :content-transfer-encoding:message-id:references:to;
        bh=gHpVlRuJ+sViL9YmtBzlu8MpwFaRVwdCy2FeMePwR1I=;
        b=MxtbyzWaBrkXmuNmT7bxGB4c9k/UIjJkGpCnZjdLL9rme6Chx65bmzaglBAEbAOb6n
         yzc+kb5hXnPFghwGezJOp3UuNam19EtaA0sVNoZWWNT9RxgE/uMUB5caBBMXl30Ohmpk
         0Q+3SlG2SRPy+waIPEXENMcM38f0QuxX+ujVQnwZHldqxKhKNpJdUjVaOjU29IrNNmf7
         UqxHyf/EhiaRm1Ab2LRIISbOyWdKWqm4ZfKEoW2E6gMWGPCFDaWdndU4/xfliPDRmDB9
         AehWkE74wocedwHc1oeltGt9q0mQQjBGMs123R8mNK3OYATpUNkqsp5diHfFCvGYE3SH
         KeeQ==
X-Received: by 10.68.88.195 with SMTP id bi3mr7587114pbb.118.1414550784167;
        Tue, 28 Oct 2014 19:46:24 -0700 (PDT)
Received: from [192.168.1.106] (c-67-164-94-237.hsd1.ca.comcast.net. [67.164.94.237])
        by mx.google.com with ESMTPSA id ez4sm2843785pab.36.2014.10.28.19.46.23
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 28 Oct 2014 19:46:23 -0700 (PDT)
Content-Type: text/plain; charset=us-ascii
Mime-Version: 1.0 (Mac OS X Mail 8.0 \(1990.1\))
Subject: Re: HiveShim not found when building in Intellij
From: Matei Zaharia <matei.zaharia@gmail.com>
In-Reply-To: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
Date: Tue, 28 Oct 2014 19:46:22 -0700
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Transfer-Encoding: quoted-printable
Message-Id: <0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
To: Stephen Boesch <javadba@gmail.com>
X-Mailer: Apple Mail (2.1990.1)
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Stephen,

How did you generate your Maven workspace? You need to make sure the =
Hive profile is enabled for it. For example sbt/sbt -Phive gen-idea.

Matei

> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com> wrote:
>=20
> I have run on the command line via maven and it is fine:
>=20
> mvn   -Dscalastyle.failOnViolation=3Dfalse -DskipTests -Pyarn =
-Phadoop-2.3
> compile package install
>=20
>=20
> But with the latest code Intellij builds do not work. Following is one =
of
> 26 similar errors:
>=20
>=20
> Error:(173, 38) not found: value HiveShim
>          =
Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>                                     ^


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10020-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 02:58:06 2014
Return-Path: <dev-return-10020-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 302B2176EB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 02:58:06 +0000 (UTC)
Received: (qmail 74813 invoked by uid 500); 29 Oct 2014 02:58:03 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74740 invoked by uid 500); 29 Oct 2014 02:58:03 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74728 invoked by uid 99); 29 Oct 2014 02:58:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 02:58:03 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of javadba@gmail.com designates 209.85.220.169 as permitted sender)
Received: from [209.85.220.169] (HELO mail-vc0-f169.google.com) (209.85.220.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 02:57:57 +0000
Received: by mail-vc0-f169.google.com with SMTP id hy4so998981vcb.28
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 19:57:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=+zJx68Ugxz5der9ATsfUqsNVyIjNk/Lci4DEZqkMSdc=;
        b=nbQoWUPKRHyCyGwKuKqEiIvuG9KZqD2oH559wgkAUAgtE4GjYm9/RZf6H2Nau7bJs1
         UZgjMuiUMeJHdhLi7+dCiTTQbP3vKIzKENRT7wvBUaNHy3PxeH05r80wUdI8uhRQT/32
         aiCbG3rJA3dMHwostw/BeNyzIxnGO5NKDknqpV/z1CsjDLjGNZOMnknnjgliCwzEJR/T
         yHTeP+vD2gRZzEB48oXA8Moz+S+U1/6skPF8lPk55VQJtWCRxIw39YFY9sEaJHP5fCUz
         FDoxCG/s9nRYhPv/2/euZFwUvZ8qMvpqxMXbv1VA1jVJfnGalqIVukmPMeR4Q7yoDHXf
         nPHw==
MIME-Version: 1.0
X-Received: by 10.220.10.66 with SMTP id o2mr5040256vco.31.1414551457129; Tue,
 28 Oct 2014 19:57:37 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Tue, 28 Oct 2014 19:57:37 -0700 (PDT)
In-Reply-To: <0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
Date: Tue, 28 Oct 2014 19:57:37 -0700
Message-ID: <CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Stephen Boesch <javadba@gmail.com>
To: Matei Zaharia <matei.zaharia@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3eb081e6c63050686ed4f
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3eb081e6c63050686ed4f
Content-Type: text/plain; charset=UTF-8

Hi Matei,
  Until my latest pull from upstream/master it had not been necessary to
add the hive profile: is it now??

I am not using sbt gen-idea. The way to open in intellij has been to Open
the parent directory. IJ recognizes it as a maven project.

There are several steps to do surgery on the yarn-parent / yarn projects ,
then do a full rebuild.  That was working until one week ago.
Intellij/maven is presently broken in  two ways:  this hive shim (which may
yet hopefully be a small/simple fix - let us see) and  (2) the
"NoClassDefFoundError
on ThreadFactoryBuilder" from my prior emails -and which is quite a serious
 problem .

2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:

> Hi Stephen,
>
> How did you generate your Maven workspace? You need to make sure the Hive
> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>
> Matei
>
> > On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com> wrote:
> >
> > I have run on the command line via maven and it is fine:
> >
> > mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn -Phadoop-2.3
> > compile package install
> >
> >
> > But with the latest code Intellij builds do not work. Following is one of
> > 26 similar errors:
> >
> >
> > Error:(173, 38) not found: value HiveShim
> >
> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
> >                                     ^
>
>

--001a11c3eb081e6c63050686ed4f--

From dev-return-10021-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 03:22:53 2014
Return-Path: <dev-return-10021-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DA458177AB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 03:22:53 +0000 (UTC)
Received: (qmail 11341 invoked by uid 500); 29 Oct 2014 03:22:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 11268 invoked by uid 500); 29 Oct 2014 03:22:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 11254 invoked by uid 99); 29 Oct 2014 03:22:52 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 03:22:52 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.175 as permitted sender)
Received: from [209.85.214.175] (HELO mail-ob0-f175.google.com) (209.85.214.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 03:22:23 +0000
Received: by mail-ob0-f175.google.com with SMTP id wm4so1713695obc.6
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 20:20:52 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=0t1qUuZcWh3Mh8zdPXPQgCD26u/OvPM7b0mXJkhoJMU=;
        b=qUrhv+IH601njXwMdeaMhr6fZrAA6BS42WiPsooJpbl2ZoWFDZ6d0HzoWgd887KNsE
         ApgLdIYrYFsaAArNoGIRnyOvXxQGPDw7Mrl0nrEZheaMkvENJn2n0RjxVUTf/wkH5Hvf
         d4UMdaAWnl+WmlMz8itSCw56a4QKXPha8TEeyzwkFWt8iqoAXV3BgjklfRcMD+JcH/EY
         +6ByyPCY8z0GTfLzRPQ8os/CzEGpKcs3EjhJkRnmJFdW7N1r+/2ofiKOl65vq2bH+VPv
         3Tk50H+cvJJpTCtA3Yinbff3Ayrzt5mv6TGH3LmYAFtaXMtGslGzPmDUyON3hYYa4o0P
         HQRA==
MIME-Version: 1.0
X-Received: by 10.182.225.232 with SMTP id rn8mr6317272obc.23.1414552852135;
 Tue, 28 Oct 2014 20:20:52 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Tue, 28 Oct 2014 20:20:52 -0700 (PDT)
In-Reply-To: <CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
Date: Tue, 28 Oct 2014 20:20:52 -0700
Message-ID: <CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Patrick Wendell <pwendell@gmail.com>
To: Stephen Boesch <javadba@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Stephen,

In some cases in the maven build we now have pluggable source
directories based on profiles using the maven build helper plug-in.
This is necessary to support cross building against different Hive
versions, and there will be additional instances of this due to
supporting scala 2.11 and 2.10.

In these cases, you may need to add source locations explicitly to
intellij if you want the entire project to compile there.

Unfortunately as long as we support cross-building like this, it will
be an issue. Intellij's maven support does not correctly detect our
use of the maven-build-plugin to add source directories.

We should come up with a good set of instructions on how to import the
pom files + add the few extra source directories. Off hand I am not
sure exactly what the correct sequence is.

- Patrick

On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com> wrote:
> Hi Matei,
>   Until my latest pull from upstream/master it had not been necessary to
> add the hive profile: is it now??
>
> I am not using sbt gen-idea. The way to open in intellij has been to Open
> the parent directory. IJ recognizes it as a maven project.
>
> There are several steps to do surgery on the yarn-parent / yarn projects ,
> then do a full rebuild.  That was working until one week ago.
> Intellij/maven is presently broken in  two ways:  this hive shim (which may
> yet hopefully be a small/simple fix - let us see) and  (2) the
> "NoClassDefFoundError
> on ThreadFactoryBuilder" from my prior emails -and which is quite a serious
>  problem .
>
> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>
>> Hi Stephen,
>>
>> How did you generate your Maven workspace? You need to make sure the Hive
>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>
>> Matei
>>
>> > On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com> wrote:
>> >
>> > I have run on the command line via maven and it is fine:
>> >
>> > mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn -Phadoop-2.3
>> > compile package install
>> >
>> >
>> > But with the latest code Intellij builds do not work. Following is one of
>> > 26 similar errors:
>> >
>> >
>> > Error:(173, 38) not found: value HiveShim
>> >
>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>> >                                     ^
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10022-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 04:10:08 2014
Return-Path: <dev-return-10022-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 134F8178B4
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 04:10:08 +0000 (UTC)
Received: (qmail 91351 invoked by uid 500); 29 Oct 2014 04:10:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 91279 invoked by uid 500); 29 Oct 2014 04:10:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 91264 invoked by uid 99); 29 Oct 2014 04:10:05 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:10:05 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of javadba@gmail.com designates 209.85.220.180 as permitted sender)
Received: from [209.85.220.180] (HELO mail-vc0-f180.google.com) (209.85.220.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:09:39 +0000
Received: by mail-vc0-f180.google.com with SMTP id hy10so1114179vcb.25
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 21:09:37 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=OOj69f62drs5Ym3YsTC8FoWJDG06LEdw4FbbFIaaYy8=;
        b=nJ3hJ6q65YDtczSPcbLEedqnxTqMCmGl7x88zYJuqRVjDhDBVJUOE1JcuqNfQnadGI
         MLSpA/0gnqJpkb/4wFEo45m34pALpeE9s2fOLBropKItF0LfDezZZHWb/GaIKh/QIxc7
         sONxYOgK+3Nzyn4Y/xpgHETbtwpov0OeEn6WoMHeUdRqb248vZU2ZsFq0QARUU+YMi4u
         K6MZmSCAWUU41CDk5Wy8f6Ro/xspQhM4VgiFnzuvjqyfTFpxRsMzbuyQ42koSzJc4LTl
         4QmPAwlDCBOT9llsLeEM1dcnelvIfNk6+RXamuIpono59JwUsL4BEEToO6BjRpVnTF2i
         VBMQ==
MIME-Version: 1.0
X-Received: by 10.220.76.134 with SMTP id c6mr3144508vck.49.1414555777626;
 Tue, 28 Oct 2014 21:09:37 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Tue, 28 Oct 2014 21:09:37 -0700 (PDT)
In-Reply-To: <CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
Date: Tue, 28 Oct 2014 21:09:37 -0700
Message-ID: <CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Stephen Boesch <javadba@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c2ca04a42580050687eeb4
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c2ca04a42580050687eeb4
Content-Type: text/plain; charset=UTF-8

Thanks Patrick for the heads up.

I have not been successful to discover a combination of profiles (i.e.
enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
maven. Anyone who knows how to handle this - a quick note here would be
appreciated.



2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:

> Hey Stephen,
>
> In some cases in the maven build we now have pluggable source
> directories based on profiles using the maven build helper plug-in.
> This is necessary to support cross building against different Hive
> versions, and there will be additional instances of this due to
> supporting scala 2.11 and 2.10.
>
> In these cases, you may need to add source locations explicitly to
> intellij if you want the entire project to compile there.
>
> Unfortunately as long as we support cross-building like this, it will
> be an issue. Intellij's maven support does not correctly detect our
> use of the maven-build-plugin to add source directories.
>
> We should come up with a good set of instructions on how to import the
> pom files + add the few extra source directories. Off hand I am not
> sure exactly what the correct sequence is.
>
> - Patrick
>
> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com> wrote:
> > Hi Matei,
> >   Until my latest pull from upstream/master it had not been necessary to
> > add the hive profile: is it now??
> >
> > I am not using sbt gen-idea. The way to open in intellij has been to Open
> > the parent directory. IJ recognizes it as a maven project.
> >
> > There are several steps to do surgery on the yarn-parent / yarn projects
> ,
> > then do a full rebuild.  That was working until one week ago.
> > Intellij/maven is presently broken in  two ways:  this hive shim (which
> may
> > yet hopefully be a small/simple fix - let us see) and  (2) the
> > "NoClassDefFoundError
> > on ThreadFactoryBuilder" from my prior emails -and which is quite a
> serious
> >  problem .
> >
> > 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
> >
> >> Hi Stephen,
> >>
> >> How did you generate your Maven workspace? You need to make sure the
> Hive
> >> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
> >>
> >> Matei
> >>
> >> > On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
> wrote:
> >> >
> >> > I have run on the command line via maven and it is fine:
> >> >
> >> > mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
> -Phadoop-2.3
> >> > compile package install
> >> >
> >> >
> >> > But with the latest code Intellij builds do not work. Following is
> one of
> >> > 26 similar errors:
> >> >
> >> >
> >> > Error:(173, 38) not found: value HiveShim
> >> >
> >> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
> >> >                                     ^
> >>
> >>
>

--001a11c2ca04a42580050687eeb4--

From dev-return-10023-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 04:33:53 2014
Return-Path: <dev-return-10023-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2D3D717907
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 04:33:53 +0000 (UTC)
Received: (qmail 16461 invoked by uid 500); 29 Oct 2014 04:33:52 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 16388 invoked by uid 500); 29 Oct 2014 04:33:52 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 16377 invoked by uid 99); 29 Oct 2014 04:33:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:33:51 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of zzhang@hortonworks.com designates 209.85.192.170 as permitted sender)
Received: from [209.85.192.170] (HELO mail-pd0-f170.google.com) (209.85.192.170)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:33:45 +0000
Received: by mail-pd0-f170.google.com with SMTP id z10so2194163pdj.1
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 21:32:39 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:subject:from:in-reply-to:date:cc
         :message-id:references:to:content-type:content-transfer-encoding;
        bh=axPG9Uixj3yaqE3U9wyGWbmupXWczVaK0JWjnQcODS8=;
        b=Aziz6O1LTd+1jvlstBcACUzzMZhpwQdb0XVvNrFaZv8mGlAkn6mwH23selo4OUYrup
         jOsBn87HGCa3B6DapM3bMHyI1c+52m3v/gbFplFW7BYFhxuWGyxkSP38Ch45s/Isu6bc
         5VYlWQBU7QbGaIkaza6zPBJhovsvxsYHd+G8/2IYOsmzJulSCiqZIr656otQAy7/fhr1
         WAOBTjFXb3P3barDACrxlphpCA+HLU0xEnG62lxrqmpTGimmt5EGBVLfS2PbRZEeKyW3
         rKc/uaBSSBMPh5D8eegQrZDUu4PDQTqjmWmhUSbOgUPqxbcW4TL5LHH+NWH5uGw/Sa6c
         poqQ==
X-Gm-Message-State: ALoCoQlhWrk3OU7QVNgbELp6jCDZ0YUANJcNQLA4aqpssgrNOREY3h5S8vqMOz9mUroJhbYeizXocsKxWkVpjK78npmB6ccn3kJFv0k7lUJ32ZTZ8uSGsyQ=
X-Received: by 10.70.27.225 with SMTP id w1mr8132723pdg.40.1414557159436;
        Tue, 28 Oct 2014 21:32:39 -0700 (PDT)
Received: from [192.168.0.11] (c-24-6-100-89.hsd1.ca.comcast.net. [24.6.100.89])
        by mx.google.com with ESMTPSA id l6sm3020964pdr.39.2014.10.28.21.32.37
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Tue, 28 Oct 2014 21:32:38 -0700 (PDT)
Mime-Version: 1.0 (Mac OS X Mail 7.3 \(1878.6\))
Subject: Re: HiveShim not found when building in Intellij
From: Zhan Zhang <zzhang@hortonworks.com>
In-Reply-To: <CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
Date: Tue, 28 Oct 2014 21:32:35 -0700
Cc: Patrick Wendell <pwendell@gmail.com>,
 Matei Zaharia <matei.zaharia@gmail.com>,
 "dev@spark.apache.org" <dev@spark.apache.org>
Message-Id: <FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com> <0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com> <CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com> <CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com> <CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
To: Stephen Boesch <javadba@gmail.com>
X-Mailer: Apple Mail (2.1878.6)
Content-Type: text/plain; charset=windows-1252
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

-Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0=94 is to enable h=
ive-0.12.0. Note that the thrift-server is not supported yet in hive-0.13, =
but expected to go to upstream soon (Spark-3720).

Thanks.

Zhan Zhang


=20
On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:

> Thanks Patrick for the heads up.
>=20
> I have not been successful to discover a combination of profiles (i.e.
> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
> maven. Anyone who knows how to handle this - a quick note here would be
> appreciated.
>=20
>=20
>=20
> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>=20
>> Hey Stephen,
>>=20
>> In some cases in the maven build we now have pluggable source
>> directories based on profiles using the maven build helper plug-in.
>> This is necessary to support cross building against different Hive
>> versions, and there will be additional instances of this due to
>> supporting scala 2.11 and 2.10.
>>=20
>> In these cases, you may need to add source locations explicitly to
>> intellij if you want the entire project to compile there.
>>=20
>> Unfortunately as long as we support cross-building like this, it will
>> be an issue. Intellij's maven support does not correctly detect our
>> use of the maven-build-plugin to add source directories.
>>=20
>> We should come up with a good set of instructions on how to import the
>> pom files + add the few extra source directories. Off hand I am not
>> sure exactly what the correct sequence is.
>>=20
>> - Patrick
>>=20
>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com> wrot=
e:
>>> Hi Matei,
>>>  Until my latest pull from upstream/master it had not been necessary to
>>> add the hive profile: is it now??
>>>=20
>>> I am not using sbt gen-idea. The way to open in intellij has been to Op=
en
>>> the parent directory. IJ recognizes it as a maven project.
>>>=20
>>> There are several steps to do surgery on the yarn-parent / yarn project=
s
>> ,
>>> then do a full rebuild.  That was working until one week ago.
>>> Intellij/maven is presently broken in  two ways:  this hive shim (which
>> may
>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>> "NoClassDefFoundError
>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>> serious
>>> problem .
>>>=20
>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>=20
>>>> Hi Stephen,
>>>>=20
>>>> How did you generate your Maven workspace? You need to make sure the
>> Hive
>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>=20
>>>> Matei
>>>>=20
>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>> wrote:
>>>>>=20
>>>>> I have run on the command line via maven and it is fine:
>>>>>=20
>>>>> mvn   -Dscalastyle.failOnViolation=3Dfalse -DskipTests -Pyarn
>> -Phadoop-2.3
>>>>> compile package install
>>>>>=20
>>>>>=20
>>>>> But with the latest code Intellij builds do not work. Following is
>> one of
>>>>> 26 similar errors:
>>>>>=20
>>>>>=20
>>>>> Error:(173, 38) not found: value HiveShim
>>>>>=20
>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>                                    ^
>>>>=20
>>>>=20
>>=20


--=20
CONFIDENTIALITY NOTICE
NOTICE: This message is intended for the use of the individual or entity to=
=20
which it is addressed and may contain information that is confidential,=20
privileged and exempt from disclosure under applicable law. If the reader=
=20
of this message is not the intended recipient, you are hereby notified that=
=20
any printing, copying, dissemination, distribution, disclosure or=20
forwarding of this communication is strictly prohibited. If you have=20
received this communication in error, please contact the sender immediately=
=20
and delete it from your system. Thank You.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10024-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 04:38:48 2014
Return-Path: <dev-return-10024-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2CBCB1790D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 04:38:48 +0000 (UTC)
Received: (qmail 20430 invoked by uid 500); 29 Oct 2014 04:38:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20342 invoked by uid 500); 29 Oct 2014 04:38:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20325 invoked by uid 99); 29 Oct 2014 04:38:46 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:38:46 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.48 as permitted sender)
Received: from [209.85.220.48] (HELO mail-pa0-f48.google.com) (209.85.220.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:38:40 +0000
Received: by mail-pa0-f48.google.com with SMTP id ey11so2324770pad.7
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 21:38:19 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type:content-transfer-encoding;
        bh=w2vX2ex1PgOCGyrQQ3geLRUzwhSt2OWbTHm/4S18KTo=;
        b=HKAwzm54mONJG8/n4/AGNE80+983DkUJCfffwKd3MW3672i3E4iGRDHOq5shP2b7wM
         78i1f9aq597tPE7XjvDUIMYfpQro/YrYfBY4OhojOXgRJxTq1ZF9VEHGFD5dtlOsKBgP
         E6cyb4DtUCeZyZejNErUOb3pad4Pm4q63dJ5vt4hsFOXS1IK5ISIwES59gRAWgXb0IYc
         vvHxBgz4awF+O9+JwXXV82+9+3yyC++8CQGts4PpEQ1xagZj6LtybvEr/zWaMp2IFCsQ
         TH2Rd7HxaSEkg0EmuWG4+c8/7VrRGbLa1AaM2+BWFiw9cOCKR/K+MMi5K/osA8njUdpf
         424w==
X-Received: by 10.66.254.164 with SMTP id aj4mr7949258pad.116.1414557499803;
        Tue, 28 Oct 2014 21:38:19 -0700 (PDT)
Received: from lian-laptop.local ([199.101.117.27])
        by mx.google.com with ESMTPSA id o5sm3042355pdc.24.2014.10.28.21.38.17
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 28 Oct 2014 21:38:19 -0700 (PDT)
Message-ID: <54506F38.1000505@gmail.com>
Date: Wed, 29 Oct 2014 12:38:16 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.2.0
MIME-Version: 1.0
To: Zhan Zhang <zzhang@hortonworks.com>, 
 Stephen Boesch <javadba@gmail.com>
CC: Patrick Wendell <pwendell@gmail.com>, 
 Matei Zaharia <matei.zaharia@gmail.com>,
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: HiveShim not found when building in Intellij
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com> <0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com> <CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com> <CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com> <CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com> <FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
In-Reply-To: <FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 8bit
X-Virus-Checked: Checked by ClamAV on apache.org

Yes, these two combinations work for me.

On 10/29/14 12:32 PM, Zhan Zhang wrote:
> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0 is to enable hive-0.12.0. Note that the thrift-server is not supported yet in hive-0.13, but expected to go to upstream soon (Spark-3720).
>
> Thanks.
>
> Zhan Zhang
>
>
>   
> On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:
>
>> Thanks Patrick for the heads up.
>>
>> I have not been successful to discover a combination of profiles (i.e.
>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
>> maven. Anyone who knows how to handle this - a quick note here would be
>> appreciated.
>>
>>
>>
>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>>
>>> Hey Stephen,
>>>
>>> In some cases in the maven build we now have pluggable source
>>> directories based on profiles using the maven build helper plug-in.
>>> This is necessary to support cross building against different Hive
>>> versions, and there will be additional instances of this due to
>>> supporting scala 2.11 and 2.10.
>>>
>>> In these cases, you may need to add source locations explicitly to
>>> intellij if you want the entire project to compile there.
>>>
>>> Unfortunately as long as we support cross-building like this, it will
>>> be an issue. Intellij's maven support does not correctly detect our
>>> use of the maven-build-plugin to add source directories.
>>>
>>> We should come up with a good set of instructions on how to import the
>>> pom files + add the few extra source directories. Off hand I am not
>>> sure exactly what the correct sequence is.
>>>
>>> - Patrick
>>>
>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com> wrote:
>>>> Hi Matei,
>>>>   Until my latest pull from upstream/master it had not been necessary to
>>>> add the hive profile: is it now??
>>>>
>>>> I am not using sbt gen-idea. The way to open in intellij has been to Open
>>>> the parent directory. IJ recognizes it as a maven project.
>>>>
>>>> There are several steps to do surgery on the yarn-parent / yarn projects
>>> ,
>>>> then do a full rebuild.  That was working until one week ago.
>>>> Intellij/maven is presently broken in  two ways:  this hive shim (which
>>> may
>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>>> "NoClassDefFoundError
>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>>> serious
>>>> problem .
>>>>
>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>>
>>>>> Hi Stephen,
>>>>>
>>>>> How did you generate your Maven workspace? You need to make sure the
>>> Hive
>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>>
>>>>> Matei
>>>>>
>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>>> wrote:
>>>>>> I have run on the command line via maven and it is fine:
>>>>>>
>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
>>> -Phadoop-2.3
>>>>>> compile package install
>>>>>>
>>>>>>
>>>>>> But with the latest code Intellij builds do not work. Following is
>>> one of
>>>>>> 26 similar errors:
>>>>>>
>>>>>>
>>>>>> Error:(173, 38) not found: value HiveShim
>>>>>>
>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>>                                     ^
>>>>>
>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10025-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 04:43:21 2014
Return-Path: <dev-return-10025-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DD8FE1791B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 04:43:21 +0000 (UTC)
Received: (qmail 23470 invoked by uid 500); 29 Oct 2014 04:43:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 23407 invoked by uid 500); 29 Oct 2014 04:43:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 23395 invoked by uid 99); 29 Oct 2014 04:43:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:43:20 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of javadba@gmail.com designates 209.85.220.181 as permitted sender)
Received: from [209.85.220.181] (HELO mail-vc0-f181.google.com) (209.85.220.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:43:15 +0000
Received: by mail-vc0-f181.google.com with SMTP id hy10so1146530vcb.26
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 21:42:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=tdIACgsHNWsEXH0g67vPpAFr7jl41P7VRO4x7a2EAZE=;
        b=TGzg5ysHwy/tCiDyQhjbENLyFTnSJmnLJj/Lh/pycHXvU44tyCpKdxIy+ZlyaAFzS5
         4e3K5nreo1aSE+jcnmrE0yDMzsIGqlGrv2ZzXuRHGP3hyJ2dlbAQMSPLbP57qwuArzXK
         lTG1cT8viHThnX/i0ZMWDNUts3RhAv6FBXS/2uiuZjjK5ug2NBLbUqJJdh4LBZx0DYt5
         o+1Wy68khfRkr2AYLUTVWF79WnlLo+kPZfotFXX48okCO6TuCZAF/fNEhLc1gj6J6t50
         dUCsdUIt/1p2MtNtqSC+MQTgmGh/4E3PYBIhhiGD6T5CMifo7ytht3vx4PEXlCPOyoM4
         YVeA==
MIME-Version: 1.0
X-Received: by 10.220.116.193 with SMTP id n1mr3399086vcq.48.1414557774368;
 Tue, 28 Oct 2014 21:42:54 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Tue, 28 Oct 2014 21:42:54 -0700 (PDT)
In-Reply-To: <54506F38.1000505@gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
	<54506F38.1000505@gmail.com>
Date: Tue, 28 Oct 2014 21:42:54 -0700
Message-ID: <CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Stephen Boesch <javadba@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Zhan Zhang <zzhang@hortonworks.com>, Patrick Wendell <pwendell@gmail.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3437a2a7d4f105068865e9
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3437a2a7d4f105068865e9
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I am interested specifically in how to build (and hopefully run/debug..)
under Intellij.  Your posts sound like command line maven - which has
always been working already.

Do you have instructions for building in IJ?

2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:

> Yes, these two combinations work for me.
>
>
> On 10/29/14 12:32 PM, Zhan Zhang wrote:
>
>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0=E2=80=9D is to=
 enable
>> hive-0.12.0. Note that the thrift-server is not supported yet in hive-0.=
13,
>> but expected to go to upstream soon (Spark-3720).
>>
>> Thanks.
>>
>> Zhan Zhang
>>
>>
>>   On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:
>>
>>  Thanks Patrick for the heads up.
>>>
>>> I have not been successful to discover a combination of profiles (i.e.
>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
>>> maven. Anyone who knows how to handle this - a quick note here would be
>>> appreciated.
>>>
>>>
>>>
>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>>>
>>>  Hey Stephen,
>>>>
>>>> In some cases in the maven build we now have pluggable source
>>>> directories based on profiles using the maven build helper plug-in.
>>>> This is necessary to support cross building against different Hive
>>>> versions, and there will be additional instances of this due to
>>>> supporting scala 2.11 and 2.10.
>>>>
>>>> In these cases, you may need to add source locations explicitly to
>>>> intellij if you want the entire project to compile there.
>>>>
>>>> Unfortunately as long as we support cross-building like this, it will
>>>> be an issue. Intellij's maven support does not correctly detect our
>>>> use of the maven-build-plugin to add source directories.
>>>>
>>>> We should come up with a good set of instructions on how to import the
>>>> pom files + add the few extra source directories. Off hand I am not
>>>> sure exactly what the correct sequence is.
>>>>
>>>> - Patrick
>>>>
>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Matei,
>>>>>   Until my latest pull from upstream/master it had not been necessary
>>>>> to
>>>>> add the hive profile: is it now??
>>>>>
>>>>> I am not using sbt gen-idea. The way to open in intellij has been to
>>>>> Open
>>>>> the parent directory. IJ recognizes it as a maven project.
>>>>>
>>>>> There are several steps to do surgery on the yarn-parent / yarn
>>>>> projects
>>>>>
>>>> ,
>>>>
>>>>> then do a full rebuild.  That was working until one week ago.
>>>>> Intellij/maven is presently broken in  two ways:  this hive shim (whi=
ch
>>>>>
>>>> may
>>>>
>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>>>> "NoClassDefFoundError
>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>>>>>
>>>> serious
>>>>
>>>>> problem .
>>>>>
>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>>>
>>>>>  Hi Stephen,
>>>>>>
>>>>>> How did you generate your Maven workspace? You need to make sure the
>>>>>>
>>>>> Hive
>>>>
>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>>>
>>>>>> Matei
>>>>>>
>>>>>>  On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>>>>>>>
>>>>>> wrote:
>>>>
>>>>> I have run on the command line via maven and it is fine:
>>>>>>>
>>>>>>> mvn   -Dscalastyle.failOnViolation=3Dfalse -DskipTests -Pyarn
>>>>>>>
>>>>>> -Phadoop-2.3
>>>>
>>>>> compile package install
>>>>>>>
>>>>>>>
>>>>>>> But with the latest code Intellij builds do not work. Following is
>>>>>>>
>>>>>> one of
>>>>
>>>>> 26 similar errors:
>>>>>>>
>>>>>>>
>>>>>>> Error:(173, 38) not found: value HiveShim
>>>>>>>
>>>>>>>  Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>>
>>>>>>>                                     ^
>>>>>>>
>>>>>>
>>>>>>
>>
>

--047d7b3437a2a7d4f105068865e9--

From dev-return-10026-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 04:48:11 2014
Return-Path: <dev-return-10026-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DEDD317927
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 04:48:10 +0000 (UTC)
Received: (qmail 31480 invoked by uid 500); 29 Oct 2014 04:48:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31412 invoked by uid 500); 29 Oct 2014 04:48:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31399 invoked by uid 99); 29 Oct 2014 04:48:09 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:48:09 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.179 as permitted sender)
Received: from [209.85.214.179] (HELO mail-ob0-f179.google.com) (209.85.214.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:47:42 +0000
Received: by mail-ob0-f179.google.com with SMTP id m8so1805696obr.10
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 21:45:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=QugVHX/EEl9nE8DAGukxaGejzqaxgUqo1g/WTJPQ/Pg=;
        b=n1bfImpNbYMGOYTnLjN/qSHddYf+8pGspF/9jVoz6AXt7eHC3Ms/ieBf+pX7VcNtxj
         GN4Zc7I95IDjwIy0rT3XhJToIzFXSkDbGkQuMhDcytPDYtxtb8b3s1B3VCClpi5IVo0R
         hh4aYgK+3JorLJ7xCgFSv/xoo0APQmG4CsgLsYOsJQTonW1gIRJGb7WoLmhBJfyy4lhY
         5Y9adxcPY9nV2z9bjQBY3zcf11YdniuAy7vyOv3/cY6zAbNEf+nhemg02LhuQoSr8R/H
         opgsMIwBuXcdfBf3fN1gkT9Fdb/TtmVWRzp3GwoYhtPM+ijtPz200f9aBThPRP1DEXh0
         SspQ==
MIME-Version: 1.0
X-Received: by 10.202.185.139 with SMTP id j133mr6197190oif.25.1414557926510;
 Tue, 28 Oct 2014 21:45:26 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Tue, 28 Oct 2014 21:45:26 -0700 (PDT)
In-Reply-To: <CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
	<54506F38.1000505@gmail.com>
	<CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
Date: Tue, 28 Oct 2014 21:45:26 -0700
Message-ID: <CABPQxsvFLgMk9WdUgLxEeAfSSnTv7AHSD-3kF+q1F5zsdL_D=w@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Patrick Wendell <pwendell@gmail.com>
To: Stephen Boesch <javadba@gmail.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Zhan Zhang <zzhang@hortonworks.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Btw - we should have part of the official docs that describes a full
"from scratch" build in IntelliJ including any gotchas. Then we can
update it if there are build changes that alter it. I created this
JIRA for it:

https://issues.apache.org/jira/browse/SPARK-4128

On Tue, Oct 28, 2014 at 9:42 PM, Stephen Boesch <javadba@gmail.com> wrote:
> I am interested specifically in how to build (and hopefully run/debug..)
> under Intellij.  Your posts sound like command line maven - which has always
> been working already.
>
> Do you have instructions for building in IJ?
>
> 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:
>
>> Yes, these two combinations work for me.
>>
>>
>> On 10/29/14 12:32 PM, Zhan Zhang wrote:
>>>
>>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0" is to enable
>>> hive-0.12.0. Note that the thrift-server is not supported yet in hive-0.13,
>>> but expected to go to upstream soon (Spark-3720).
>>>
>>> Thanks.
>>>
>>> Zhan Zhang
>>>
>>>
>>>   On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:
>>>
>>>> Thanks Patrick for the heads up.
>>>>
>>>> I have not been successful to discover a combination of profiles (i.e.
>>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
>>>> maven. Anyone who knows how to handle this - a quick note here would be
>>>> appreciated.
>>>>
>>>>
>>>>
>>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>>>>
>>>>> Hey Stephen,
>>>>>
>>>>> In some cases in the maven build we now have pluggable source
>>>>> directories based on profiles using the maven build helper plug-in.
>>>>> This is necessary to support cross building against different Hive
>>>>> versions, and there will be additional instances of this due to
>>>>> supporting scala 2.11 and 2.10.
>>>>>
>>>>> In these cases, you may need to add source locations explicitly to
>>>>> intellij if you want the entire project to compile there.
>>>>>
>>>>> Unfortunately as long as we support cross-building like this, it will
>>>>> be an issue. Intellij's maven support does not correctly detect our
>>>>> use of the maven-build-plugin to add source directories.
>>>>>
>>>>> We should come up with a good set of instructions on how to import the
>>>>> pom files + add the few extra source directories. Off hand I am not
>>>>> sure exactly what the correct sequence is.
>>>>>
>>>>> - Patrick
>>>>>
>>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com>
>>>>> wrote:
>>>>>>
>>>>>> Hi Matei,
>>>>>>   Until my latest pull from upstream/master it had not been necessary
>>>>>> to
>>>>>> add the hive profile: is it now??
>>>>>>
>>>>>> I am not using sbt gen-idea. The way to open in intellij has been to
>>>>>> Open
>>>>>> the parent directory. IJ recognizes it as a maven project.
>>>>>>
>>>>>> There are several steps to do surgery on the yarn-parent / yarn
>>>>>> projects
>>>>>
>>>>> ,
>>>>>>
>>>>>> then do a full rebuild.  That was working until one week ago.
>>>>>> Intellij/maven is presently broken in  two ways:  this hive shim
>>>>>> (which
>>>>>
>>>>> may
>>>>>>
>>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>>>>> "NoClassDefFoundError
>>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>>>>>
>>>>> serious
>>>>>>
>>>>>> problem .
>>>>>>
>>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>>>>
>>>>>>> Hi Stephen,
>>>>>>>
>>>>>>> How did you generate your Maven workspace? You need to make sure the
>>>>>
>>>>> Hive
>>>>>>>
>>>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>>>>
>>>>>>> Matei
>>>>>>>
>>>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>>>>>
>>>>> wrote:
>>>>>>>>
>>>>>>>> I have run on the command line via maven and it is fine:
>>>>>>>>
>>>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
>>>>>
>>>>> -Phadoop-2.3
>>>>>>>>
>>>>>>>> compile package install
>>>>>>>>
>>>>>>>>
>>>>>>>> But with the latest code Intellij builds do not work. Following is
>>>>>
>>>>> one of
>>>>>>>>
>>>>>>>> 26 similar errors:
>>>>>>>>
>>>>>>>>
>>>>>>>> Error:(173, 38) not found: value HiveShim
>>>>>>>>
>>>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>>>>
>>>>>>>>                                     ^
>>>>>>>
>>>>>>>
>>>
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10027-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 04:54:37 2014
Return-Path: <dev-return-10027-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 4876617943
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 04:54:37 +0000 (UTC)
Received: (qmail 40915 invoked by uid 500); 29 Oct 2014 04:54:36 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40849 invoked by uid 500); 29 Oct 2014 04:54:36 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40835 invoked by uid 99); 29 Oct 2014 04:54:35 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:54:35 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.48 as permitted sender)
Received: from [209.85.220.48] (HELO mail-pa0-f48.google.com) (209.85.220.48)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:54:06 +0000
Received: by mail-pa0-f48.google.com with SMTP id ey11so2337183pad.35
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 21:54:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type;
        bh=tA7Vh2IR/gsexu45R9MXhzJZJPUVRiLBOOUHeJaJAxw=;
        b=o40Fgcr7ggFANrqakaqKmAdsXtquFV2O5cL/hF73CpJMV/9DCX/fWNaUUprJ1mYJX3
         fh0wIuYcDRTeT59uLiYpXDpZF8kjKJ3kJUA4iRuwRPtGJkMzF5U0r4DseS4KO26m4Cyi
         BkpRGkzWJO1iSUWdPXxh8vW6VtMuasdMt4PNcLBOSlyscRGpgDNuOeBu7TE9910kMnEQ
         mKlhozQ769m52pFSAPLW44TGTRl300Y6TQsdKtxVwYvaVZET3PE8PxUcqV0tuKfec16+
         JSDDEb5+hP1fqxCmnvprd/iiy9MdXmpD9uZhDgjyPc2pi8SDSjC2SwgLEOTz0mOnqTXa
         CCWw==
X-Received: by 10.68.106.161 with SMTP id gv1mr8060173pbb.1.1414558444608;
        Tue, 28 Oct 2014 21:54:04 -0700 (PDT)
Received: from lian-laptop.local ([199.101.117.27])
        by mx.google.com with ESMTPSA id xf9sm3099618pab.2.2014.10.28.21.54.01
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 28 Oct 2014 21:54:03 -0700 (PDT)
Message-ID: <545072E8.8070600@gmail.com>
Date: Wed, 29 Oct 2014 12:54:00 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.2.0
MIME-Version: 1.0
To: Stephen Boesch <javadba@gmail.com>
CC: Zhan Zhang <zzhang@hortonworks.com>, 
 Patrick Wendell <pwendell@gmail.com>,
 Matei Zaharia <matei.zaharia@gmail.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: HiveShim not found when building in Intellij
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>	<54506F38.1000505@gmail.com> <CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
In-Reply-To: <CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
Content-Type: multipart/alternative;
 boundary="------------070402070408090306070104"
X-Virus-Checked: Checked by ClamAV on apache.org

--------------070402070408090306070104
Content-Type: text/plain; charset=utf-8; format=flowed
Content-Transfer-Encoding: 8bit

You may first open the root pom.xml file in IDEA, and then go for menu 
View / Tool Windows / Maven Projects, then choose desired Maven profile 
combination under the "Profiles" node (e.g. I usually use hadoop-2.4 + 
hive + hive-0.12.0). IDEA will ask you to re-import the Maven projects, 
confirm, then it should be OK.

I can debug within IDEA with this approach. However, you have to clean 
the whole project before debugging Spark within IDEA if you compiled the 
project outside IDEA. Haven't got time to investigate this annoying issue.

Also, you can remove sub projects unrelated to your tasks to accelerate 
compilation and/or avoid other IDEA build issues (e.g. Avro related 
Spark streaming build failure in IDEA).

On 10/29/14 12:42 PM, Stephen Boesch wrote:
> I am interested specifically in how to build (and hopefully 
> run/debug..) under Intellij.  Your posts sound like command line maven 
> - which has always been working already.
>
> Do you have instructions for building in IJ?
>
> 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com 
> <mailto:lian.cs.zju@gmail.com>>:
>
>     Yes, these two combinations work for me.
>
>
>     On 10/29/14 12:32 PM, Zhan Zhang wrote:
>
>         -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0 is
>         to enable hive-0.12.0. Note that the thrift-server is not
>         supported yet in hive-0.13, but expected to go to upstream
>         soon (Spark-3720).
>
>         Thanks.
>
>         Zhan Zhang
>
>
>           On Oct 28, 2014, at 9:09 PM, Stephen Boesch
>         <javadba@gmail.com <mailto:javadba@gmail.com>> wrote:
>
>             Thanks Patrick for the heads up.
>
>             I have not been successful to discover a combination of
>             profiles (i.e.
>             enabling hive or hive-0.12.0 or hive-13.0) that works in
>             Intellij with
>             maven. Anyone who knows how to handle this - a quick note
>             here would be
>             appreciated.
>
>
>
>             2014-10-28 20:20 GMT-07:00 Patrick Wendell
>             <pwendell@gmail.com <mailto:pwendell@gmail.com>>:
>
>                 Hey Stephen,
>
>                 In some cases in the maven build we now have pluggable
>                 source
>                 directories based on profiles using the maven build
>                 helper plug-in.
>                 This is necessary to support cross building against
>                 different Hive
>                 versions, and there will be additional instances of
>                 this due to
>                 supporting scala 2.11 and 2.10.
>
>                 In these cases, you may need to add source locations
>                 explicitly to
>                 intellij if you want the entire project to compile there.
>
>                 Unfortunately as long as we support cross-building
>                 like this, it will
>                 be an issue. Intellij's maven support does not
>                 correctly detect our
>                 use of the maven-build-plugin to add source directories.
>
>                 We should come up with a good set of instructions on
>                 how to import the
>                 pom files + add the few extra source directories. Off
>                 hand I am not
>                 sure exactly what the correct sequence is.
>
>                 - Patrick
>
>                 On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch
>                 <javadba@gmail.com <mailto:javadba@gmail.com>> wrote:
>
>                     Hi Matei,
>                       Until my latest pull from upstream/master it had
>                     not been necessary to
>                     add the hive profile: is it now??
>
>                     I am not using sbt gen-idea. The way to open in
>                     intellij has been to Open
>                     the parent directory. IJ recognizes it as a maven
>                     project.
>
>                     There are several steps to do surgery on the
>                     yarn-parent / yarn projects
>
>                 ,
>
>                     then do a full rebuild.  That was working until
>                     one week ago.
>                     Intellij/maven is presently broken in  two ways: 
>                     this hive shim (which
>
>                 may
>
>                     yet hopefully be a small/simple fix - let us see)
>                     and  (2) the
>                     "NoClassDefFoundError
>                     on ThreadFactoryBuilder" from my prior emails -and
>                     which is quite a
>
>                 serious
>
>                     problem .
>
>                     2014-10-28 19:46 GMT-07:00 Matei Zaharia
>                     <matei.zaharia@gmail.com
>                     <mailto:matei.zaharia@gmail.com>>:
>
>                         Hi Stephen,
>
>                         How did you generate your Maven workspace? You
>                         need to make sure the
>
>                 Hive
>
>                         profile is enabled for it. For example sbt/sbt
>                         -Phive gen-idea.
>
>                         Matei
>
>                             On Oct 28, 2014, at 7:42 PM, Stephen
>                             Boesch <javadba@gmail.com
>                             <mailto:javadba@gmail.com>>
>
>                 wrote:
>
>                             I have run on the command line via maven
>                             and it is fine:
>
>                             mvn   -Dscalastyle.failOnViolation=false
>                             -DskipTests -Pyarn
>
>                 -Phadoop-2.3
>
>                             compile package install
>
>
>                             But with the latest code Intellij builds
>                             do not work. Following is
>
>                 one of
>
>                             26 similar errors:
>
>
>                             Error:(173, 38) not found: value HiveShim
>
>                         Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>
>                                                                 ^
>
>
>
>
>


--------------070402070408090306070104--

From dev-return-10028-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 04:58:19 2014
Return-Path: <dev-return-10028-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2343B17955
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 04:58:19 +0000 (UTC)
Received: (qmail 47431 invoked by uid 500); 29 Oct 2014 04:58:18 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 47357 invoked by uid 500); 29 Oct 2014 04:58:18 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 47345 invoked by uid 99); 29 Oct 2014 04:58:17 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:58:17 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.41 as permitted sender)
Received: from [209.85.218.41] (HELO mail-oi0-f41.google.com) (209.85.218.41)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:57:51 +0000
Received: by mail-oi0-f41.google.com with SMTP id e131so1766024oig.0
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 21:57:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=1oXU4nvahoLmalk7kP6tbVgwgb3acTKTMH/8e1h6duo=;
        b=OyMKoztG+beVyviXvsfpsEBqfRtmdeuXNrHBIYKgCS01JoZ4icuboFrOyU3/FmGHS8
         yyAl/oLf1RaK6EtNapndbYq3aTRxJWclzoU1sME87y0ql3lpEoppMd4HjdCy7oPYO7V7
         1cvBC6J/9Re/wWThnXJL0B4PRqaXH+e8OE1HI7QRbSdU4xiJX4doENHdcfoWvwns+f5J
         XhwkA/9jIvjXvehESM1+RKFNm4zDnPvAk8NtI4z5VF64+M0hpdAWIYFjQcmTZtv4m8EF
         h+YZKBo3pMGqr9/OOVT94UbpoJoolhzt7MwsgIkh6dol4tBHQJzAbGWsju5znyqzQgln
         CLEA==
MIME-Version: 1.0
X-Received: by 10.182.142.70 with SMTP id ru6mr6549563obb.11.1414558669807;
 Tue, 28 Oct 2014 21:57:49 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Tue, 28 Oct 2014 21:57:49 -0700 (PDT)
In-Reply-To: <545072E8.8070600@gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
	<54506F38.1000505@gmail.com>
	<CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
	<545072E8.8070600@gmail.com>
Date: Tue, 28 Oct 2014 21:57:49 -0700
Message-ID: <CABPQxstiBxKcfg993UhtK-yAV9BrH5b=EYOdq-QN8AzUtvUVHQ@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Patrick Wendell <pwendell@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Stephen Boesch <javadba@gmail.com>, Zhan Zhang <zzhang@hortonworks.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

I just started a totally fresh IntelliJ project importing from our
root pom. I used all the default options and I added "hadoop-2.4,
hive, hive-0.13.1" profiles. I was able to run spark core tests from
within IntelliJ. Didn't try anything beyond that, but FWIW this
worked.

- Patrick

On Tue, Oct 28, 2014 at 9:54 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
> You may first open the root pom.xml file in IDEA, and then go for menu View
> / Tool Windows / Maven Projects, then choose desired Maven profile
> combination under the "Profiles" node (e.g. I usually use hadoop-2.4 + hive
> + hive-0.12.0). IDEA will ask you to re-import the Maven projects, confirm,
> then it should be OK.
>
> I can debug within IDEA with this approach. However, you have to clean the
> whole project before debugging Spark within IDEA if you compiled the project
> outside IDEA. Haven't got time to investigate this annoying issue.
>
> Also, you can remove sub projects unrelated to your tasks to accelerate
> compilation and/or avoid other IDEA build issues (e.g. Avro related Spark
> streaming build failure in IDEA).
>
>
> On 10/29/14 12:42 PM, Stephen Boesch wrote:
>
> I am interested specifically in how to build (and hopefully run/debug..)
> under Intellij.  Your posts sound like command line maven - which has always
> been working already.
>
> Do you have instructions for building in IJ?
>
> 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:
>>
>> Yes, these two combinations work for me.
>>
>>
>> On 10/29/14 12:32 PM, Zhan Zhang wrote:
>>>
>>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0" is to enable
>>> hive-0.12.0. Note that the thrift-server is not supported yet in hive-0.13,
>>> but expected to go to upstream soon (Spark-3720).
>>>
>>> Thanks.
>>>
>>> Zhan Zhang
>>>
>>>
>>>   On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:
>>>
>>>> Thanks Patrick for the heads up.
>>>>
>>>> I have not been successful to discover a combination of profiles (i.e.
>>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
>>>> maven. Anyone who knows how to handle this - a quick note here would be
>>>> appreciated.
>>>>
>>>>
>>>>
>>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>>>>
>>>>> Hey Stephen,
>>>>>
>>>>> In some cases in the maven build we now have pluggable source
>>>>> directories based on profiles using the maven build helper plug-in.
>>>>> This is necessary to support cross building against different Hive
>>>>> versions, and there will be additional instances of this due to
>>>>> supporting scala 2.11 and 2.10.
>>>>>
>>>>> In these cases, you may need to add source locations explicitly to
>>>>> intellij if you want the entire project to compile there.
>>>>>
>>>>> Unfortunately as long as we support cross-building like this, it will
>>>>> be an issue. Intellij's maven support does not correctly detect our
>>>>> use of the maven-build-plugin to add source directories.
>>>>>
>>>>> We should come up with a good set of instructions on how to import the
>>>>> pom files + add the few extra source directories. Off hand I am not
>>>>> sure exactly what the correct sequence is.
>>>>>
>>>>> - Patrick
>>>>>
>>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com>
>>>>> wrote:
>>>>>>
>>>>>> Hi Matei,
>>>>>>   Until my latest pull from upstream/master it had not been necessary
>>>>>> to
>>>>>> add the hive profile: is it now??
>>>>>>
>>>>>> I am not using sbt gen-idea. The way to open in intellij has been to
>>>>>> Open
>>>>>> the parent directory. IJ recognizes it as a maven project.
>>>>>>
>>>>>> There are several steps to do surgery on the yarn-parent / yarn
>>>>>> projects
>>>>>
>>>>> ,
>>>>>>
>>>>>> then do a full rebuild.  That was working until one week ago.
>>>>>> Intellij/maven is presently broken in  two ways:  this hive shim
>>>>>> (which
>>>>>
>>>>> may
>>>>>>
>>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>>>>> "NoClassDefFoundError
>>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>>>>>
>>>>> serious
>>>>>>
>>>>>> problem .
>>>>>>
>>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>>>>
>>>>>>> Hi Stephen,
>>>>>>>
>>>>>>> How did you generate your Maven workspace? You need to make sure the
>>>>>
>>>>> Hive
>>>>>>>
>>>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>>>>
>>>>>>> Matei
>>>>>>>
>>>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>>>>>
>>>>> wrote:
>>>>>>>>
>>>>>>>> I have run on the command line via maven and it is fine:
>>>>>>>>
>>>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
>>>>>
>>>>> -Phadoop-2.3
>>>>>>>>
>>>>>>>> compile package install
>>>>>>>>
>>>>>>>>
>>>>>>>> But with the latest code Intellij builds do not work. Following is
>>>>>
>>>>> one of
>>>>>>>>
>>>>>>>> 26 similar errors:
>>>>>>>>
>>>>>>>>
>>>>>>>> Error:(173, 38) not found: value HiveShim
>>>>>>>>
>>>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>>>>
>>>>>>>>                                     ^
>>>>>>>
>>>>>>>
>>>
>>
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10029-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 04:59:08 2014
Return-Path: <dev-return-10029-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id DC0C91795C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 04:59:08 +0000 (UTC)
Received: (qmail 49301 invoked by uid 500); 29 Oct 2014 04:59:08 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 49233 invoked by uid 500); 29 Oct 2014 04:59:08 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 49221 invoked by uid 99); 29 Oct 2014 04:59:07 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:59:07 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.47 as permitted sender)
Received: from [209.85.220.47] (HELO mail-pa0-f47.google.com) (209.85.220.47)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 04:59:03 +0000
Received: by mail-pa0-f47.google.com with SMTP id kx10so2350645pab.34
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 21:57:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type:content-transfer-encoding;
        bh=PPVBsgiZIhE47Ct6zzbfY940aJPv+3Dc3u6RCuhgHvo=;
        b=cXwFSr8cAuD+JVggUZ2kHqUi0W8wHmH/2kbHLuiiQNm0I93KoSLbJQ+1Ok8XMDxsbI
         DaDZiP4G2bvZ1SsvtVxXPiBbDj3VCDV3crziIIRjHjlHqIb7pIzpTRydIQ7CAuTZ+mjQ
         CIYKmTSdasa1tFQg+X7G4OXO7vu8rRVUZzNPITu2HCmo/nAbx+R9QyfC5TMv2je0clQz
         igo8aOq1Fx2Bhh2+teQ8mvQ1J9bXKW1KRF5TGP+D3ET5iJE/Q7mMTLE/Nh2ukY45QYvi
         Bhi7doJCBU05RecKXTHjn5DV6M2L8hSx+ccVjYXw1zuYDEr9BwwKTgXMEAB7+oo/ucP6
         E91Q==
X-Received: by 10.70.140.203 with SMTP id ri11mr3151430pdb.19.1414558632771;
        Tue, 28 Oct 2014 21:57:12 -0700 (PDT)
Received: from lian-laptop.local ([199.101.117.27])
        by mx.google.com with ESMTPSA id jj12sm3042835pbd.78.2014.10.28.21.57.10
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 28 Oct 2014 21:57:12 -0700 (PDT)
Message-ID: <545073A5.60703@gmail.com>
Date: Wed, 29 Oct 2014 12:57:09 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.2.0
MIME-Version: 1.0
To: Patrick Wendell <pwendell@gmail.com>, 
 Stephen Boesch <javadba@gmail.com>
CC: Zhan Zhang <zzhang@hortonworks.com>, 
 Matei Zaharia <matei.zaharia@gmail.com>,
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: HiveShim not found when building in Intellij
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>	<54506F38.1000505@gmail.com>	<CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com> <CABPQxsvFLgMk9WdUgLxEeAfSSnTv7AHSD-3kF+q1F5zsdL_D=w@mail.gmail.com>
In-Reply-To: <CABPQxsvFLgMk9WdUgLxEeAfSSnTv7AHSD-3kF+q1F5zsdL_D=w@mail.gmail.com>
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hao Cheng had just written such a "from scratch" guide for building 
Spark SQL in IDEA. Although it's written in Chinese, I think the 
illustrations are already descriptive enough.

http://www.cnblogs.com/cccchhhh/articles/4058371.html


On 10/29/14 12:45 PM, Patrick Wendell wrote:
> Btw - we should have part of the official docs that describes a full
> "from scratch" build in IntelliJ including any gotchas. Then we can
> update it if there are build changes that alter it. I created this
> JIRA for it:
>
> https://issues.apache.org/jira/browse/SPARK-4128
>
> On Tue, Oct 28, 2014 at 9:42 PM, Stephen Boesch <javadba@gmail.com> wrote:
>> I am interested specifically in how to build (and hopefully run/debug..)
>> under Intellij.  Your posts sound like command line maven - which has always
>> been working already.
>>
>> Do you have instructions for building in IJ?
>>
>> 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:
>>
>>> Yes, these two combinations work for me.
>>>
>>>
>>> On 10/29/14 12:32 PM, Zhan Zhang wrote:
>>>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0" is to enable
>>>> hive-0.12.0. Note that the thrift-server is not supported yet in hive-0.13,
>>>> but expected to go to upstream soon (Spark-3720).
>>>>
>>>> Thanks.
>>>>
>>>> Zhan Zhang
>>>>
>>>>
>>>>    On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:
>>>>
>>>>> Thanks Patrick for the heads up.
>>>>>
>>>>> I have not been successful to discover a combination of profiles (i.e.
>>>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
>>>>> maven. Anyone who knows how to handle this - a quick note here would be
>>>>> appreciated.
>>>>>
>>>>>
>>>>>
>>>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>>>>>
>>>>>> Hey Stephen,
>>>>>>
>>>>>> In some cases in the maven build we now have pluggable source
>>>>>> directories based on profiles using the maven build helper plug-in.
>>>>>> This is necessary to support cross building against different Hive
>>>>>> versions, and there will be additional instances of this due to
>>>>>> supporting scala 2.11 and 2.10.
>>>>>>
>>>>>> In these cases, you may need to add source locations explicitly to
>>>>>> intellij if you want the entire project to compile there.
>>>>>>
>>>>>> Unfortunately as long as we support cross-building like this, it will
>>>>>> be an issue. Intellij's maven support does not correctly detect our
>>>>>> use of the maven-build-plugin to add source directories.
>>>>>>
>>>>>> We should come up with a good set of instructions on how to import the
>>>>>> pom files + add the few extra source directories. Off hand I am not
>>>>>> sure exactly what the correct sequence is.
>>>>>>
>>>>>> - Patrick
>>>>>>
>>>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com>
>>>>>> wrote:
>>>>>>> Hi Matei,
>>>>>>>    Until my latest pull from upstream/master it had not been necessary
>>>>>>> to
>>>>>>> add the hive profile: is it now??
>>>>>>>
>>>>>>> I am not using sbt gen-idea. The way to open in intellij has been to
>>>>>>> Open
>>>>>>> the parent directory. IJ recognizes it as a maven project.
>>>>>>>
>>>>>>> There are several steps to do surgery on the yarn-parent / yarn
>>>>>>> projects
>>>>>> ,
>>>>>>> then do a full rebuild.  That was working until one week ago.
>>>>>>> Intellij/maven is presently broken in  two ways:  this hive shim
>>>>>>> (which
>>>>>> may
>>>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>>>>>> "NoClassDefFoundError
>>>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>>>>>> serious
>>>>>>> problem .
>>>>>>>
>>>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>>>>>
>>>>>>>> Hi Stephen,
>>>>>>>>
>>>>>>>> How did you generate your Maven workspace? You need to make sure the
>>>>>> Hive
>>>>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>>>>>
>>>>>>>> Matei
>>>>>>>>
>>>>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>>>>>> wrote:
>>>>>>>>> I have run on the command line via maven and it is fine:
>>>>>>>>>
>>>>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
>>>>>> -Phadoop-2.3
>>>>>>>>> compile package install
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> But with the latest code Intellij builds do not work. Following is
>>>>>> one of
>>>>>>>>> 26 similar errors:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Error:(173, 38) not found: value HiveShim
>>>>>>>>>
>>>>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>>>>>                                      ^
>>>>>>>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10030-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 05:03:58 2014
Return-Path: <dev-return-10030-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 284B11797B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 05:03:58 +0000 (UTC)
Received: (qmail 56383 invoked by uid 500); 29 Oct 2014 05:03:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 56316 invoked by uid 500); 29 Oct 2014 05:03:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 56301 invoked by uid 99); 29 Oct 2014 05:03:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:03:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of javadba@gmail.com designates 209.85.220.182 as permitted sender)
Received: from [209.85.220.182] (HELO mail-vc0-f182.google.com) (209.85.220.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:03:45 +0000
Received: by mail-vc0-f182.google.com with SMTP id id10so285606vcb.27
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 22:03:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=8cXA05yhPj0IE6OjEetflzKRnLTneGSqmdyQygPQXLw=;
        b=i+lS92dmLTvLFcPp76sGGLcPtN8QLrZqV+M9ei5sDrc+ffkOAOF8sg/tTL1AttWcyC
         1l8Unww0RD8Rn66WBZtTMr81YDqSrxsmOBn84SfOBaQ2CzxTCBBioXtW6p+3DOaqxpNF
         4Ep/exyfX7Z99NuMFq7xejbMKm8C25XbWvR0xUx1I24VyWrNNOJxzwtE80C9AURuVRwf
         vr02UfnGwBXEdLXsWR4LEe3jcELgow68xs8Mr1iegpspCF7CDaKzrNRYZXsU+Vy5pNGN
         Z9zcqXT59waLYW/cvub8xgo9X961t7hLvZ2K4CQstq/5Vmf+iQqQzG2djW7D0suUs48h
         wP3w==
MIME-Version: 1.0
X-Received: by 10.220.128.4 with SMTP id i4mr5462486vcs.32.1414559004246; Tue,
 28 Oct 2014 22:03:24 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Tue, 28 Oct 2014 22:03:24 -0700 (PDT)
In-Reply-To: <CABPQxstiBxKcfg993UhtK-yAV9BrH5b=EYOdq-QN8AzUtvUVHQ@mail.gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
	<54506F38.1000505@gmail.com>
	<CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
	<545072E8.8070600@gmail.com>
	<CABPQxstiBxKcfg993UhtK-yAV9BrH5b=EYOdq-QN8AzUtvUVHQ@mail.gmail.com>
Date: Tue, 28 Oct 2014 22:03:24 -0700
Message-ID: <CACkSZy2OeVn6Dy1XrMTZP4T3sAO6X5P_d77bikQiBnWYWANuTA@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Stephen Boesch <javadba@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Zhan Zhang <zzhang@hortonworks.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1132f210f665f9050688aea0
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1132f210f665f9050688aea0
Content-Type: text/plain; charset=UTF-8

I have selected the same options as Cheng LIang: hadoop-2.4, hive, hive
0.12.0 .  After  a full Rebuild in IJ I  still see the HiveShim errors.

I really do not know what is different. I had pulled three hours ago from
github upstream master.

Just for kicks i am trying PW's combination which uses 0.13.1 now.. But it
appears there is something else going on here.

Patrick/ Cheng:  did you build on the command line using Maven first?  I do
that since in the past that had been required.

2014-10-28 21:57 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:

> I just started a totally fresh IntelliJ project importing from our
> root pom. I used all the default options and I added "hadoop-2.4,
> hive, hive-0.13.1" profiles. I was able to run spark core tests from
> within IntelliJ. Didn't try anything beyond that, but FWIW this
> worked.
>
> - Patrick
>
> On Tue, Oct 28, 2014 at 9:54 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
> > You may first open the root pom.xml file in IDEA, and then go for menu
> View
> > / Tool Windows / Maven Projects, then choose desired Maven profile
> > combination under the "Profiles" node (e.g. I usually use hadoop-2.4 +
> hive
> > + hive-0.12.0). IDEA will ask you to re-import the Maven projects,
> confirm,
> > then it should be OK.
> >
> > I can debug within IDEA with this approach. However, you have to clean
> the
> > whole project before debugging Spark within IDEA if you compiled the
> project
> > outside IDEA. Haven't got time to investigate this annoying issue.
> >
> > Also, you can remove sub projects unrelated to your tasks to accelerate
> > compilation and/or avoid other IDEA build issues (e.g. Avro related Spark
> > streaming build failure in IDEA).
> >
> >
> > On 10/29/14 12:42 PM, Stephen Boesch wrote:
> >
> > I am interested specifically in how to build (and hopefully run/debug..)
> > under Intellij.  Your posts sound like command line maven - which has
> always
> > been working already.
> >
> > Do you have instructions for building in IJ?
> >
> > 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:
> >>
> >> Yes, these two combinations work for me.
> >>
> >>
> >> On 10/29/14 12:32 PM, Zhan Zhang wrote:
> >>>
> >>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0" is to enable
> >>> hive-0.12.0. Note that the thrift-server is not supported yet in
> hive-0.13,
> >>> but expected to go to upstream soon (Spark-3720).
> >>>
> >>> Thanks.
> >>>
> >>> Zhan Zhang
> >>>
> >>>
> >>>   On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com>
> wrote:
> >>>
> >>>> Thanks Patrick for the heads up.
> >>>>
> >>>> I have not been successful to discover a combination of profiles (i.e.
> >>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
> >>>> maven. Anyone who knows how to handle this - a quick note here would
> be
> >>>> appreciated.
> >>>>
> >>>>
> >>>>
> >>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
> >>>>
> >>>>> Hey Stephen,
> >>>>>
> >>>>> In some cases in the maven build we now have pluggable source
> >>>>> directories based on profiles using the maven build helper plug-in.
> >>>>> This is necessary to support cross building against different Hive
> >>>>> versions, and there will be additional instances of this due to
> >>>>> supporting scala 2.11 and 2.10.
> >>>>>
> >>>>> In these cases, you may need to add source locations explicitly to
> >>>>> intellij if you want the entire project to compile there.
> >>>>>
> >>>>> Unfortunately as long as we support cross-building like this, it will
> >>>>> be an issue. Intellij's maven support does not correctly detect our
> >>>>> use of the maven-build-plugin to add source directories.
> >>>>>
> >>>>> We should come up with a good set of instructions on how to import
> the
> >>>>> pom files + add the few extra source directories. Off hand I am not
> >>>>> sure exactly what the correct sequence is.
> >>>>>
> >>>>> - Patrick
> >>>>>
> >>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com>
> >>>>> wrote:
> >>>>>>
> >>>>>> Hi Matei,
> >>>>>>   Until my latest pull from upstream/master it had not been
> necessary
> >>>>>> to
> >>>>>> add the hive profile: is it now??
> >>>>>>
> >>>>>> I am not using sbt gen-idea. The way to open in intellij has been to
> >>>>>> Open
> >>>>>> the parent directory. IJ recognizes it as a maven project.
> >>>>>>
> >>>>>> There are several steps to do surgery on the yarn-parent / yarn
> >>>>>> projects
> >>>>>
> >>>>> ,
> >>>>>>
> >>>>>> then do a full rebuild.  That was working until one week ago.
> >>>>>> Intellij/maven is presently broken in  two ways:  this hive shim
> >>>>>> (which
> >>>>>
> >>>>> may
> >>>>>>
> >>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
> >>>>>> "NoClassDefFoundError
> >>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
> >>>>>
> >>>>> serious
> >>>>>>
> >>>>>> problem .
> >>>>>>
> >>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
> >>>>>>
> >>>>>>> Hi Stephen,
> >>>>>>>
> >>>>>>> How did you generate your Maven workspace? You need to make sure
> the
> >>>>>
> >>>>> Hive
> >>>>>>>
> >>>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
> >>>>>>>
> >>>>>>> Matei
> >>>>>>>
> >>>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
> >>>>>
> >>>>> wrote:
> >>>>>>>>
> >>>>>>>> I have run on the command line via maven and it is fine:
> >>>>>>>>
> >>>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
> >>>>>
> >>>>> -Phadoop-2.3
> >>>>>>>>
> >>>>>>>> compile package install
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> But with the latest code Intellij builds do not work. Following is
> >>>>>
> >>>>> one of
> >>>>>>>>
> >>>>>>>> 26 similar errors:
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Error:(173, 38) not found: value HiveShim
> >>>>>>>>
> >>>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
> >>>>>>>>
> >>>>>>>>                                     ^
> >>>>>>>
> >>>>>>>
> >>>
> >>
> >
> >
>

--001a1132f210f665f9050688aea0--

From dev-return-10031-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 05:06:45 2014
Return-Path: <dev-return-10031-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6821317993
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 05:06:45 +0000 (UTC)
Received: (qmail 60313 invoked by uid 500); 29 Oct 2014 05:06:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 60237 invoked by uid 500); 29 Oct 2014 05:06:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 60224 invoked by uid 99); 29 Oct 2014 05:06:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:06:44 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.42 as permitted sender)
Received: from [209.85.218.42] (HELO mail-oi0-f42.google.com) (209.85.218.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:06:17 +0000
Received: by mail-oi0-f42.google.com with SMTP id a3so1123407oib.29
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 22:05:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=HO+SH/MvdUxcAA/FvSfGEcBQI7oy/xjOypYVSkWKab4=;
        b=wTuMfNlBryxCKTGcF0KTEEfhrVfm5tAsoUTnVAu038gHgE9+BBir/Nn+gjyfypKDhq
         9WeWRna4Sz4jX23Sfa+hjW5kxFu+2wmalt1LYVhQ33zLhhgS1ZuRWRPapLZQhRFMNVmJ
         oN0NxdEto5zI7dkETMcENWjn4BV7r1zRQCSfZSqiQdW048b48xaU6cteioZPPtH42xnu
         qmhr3SEVA5r1DnLwzXAwEQqoSgSkCsepZLrAyh0/ykowO2xnGysz3DNtHUFBGo/V4gMZ
         bqkjGfHmPciu6PHg/sv8GuMCcHObMnvQx8Rrm/BtzMeTS6PtSScZNMdXEPMUm2aTEkCp
         gn8Q==
MIME-Version: 1.0
X-Received: by 10.182.176.66 with SMTP id cg2mr6731437obc.21.1414559130911;
 Tue, 28 Oct 2014 22:05:30 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Tue, 28 Oct 2014 22:05:30 -0700 (PDT)
In-Reply-To: <CABPQxstiBxKcfg993UhtK-yAV9BrH5b=EYOdq-QN8AzUtvUVHQ@mail.gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
	<54506F38.1000505@gmail.com>
	<CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
	<545072E8.8070600@gmail.com>
	<CABPQxstiBxKcfg993UhtK-yAV9BrH5b=EYOdq-QN8AzUtvUVHQ@mail.gmail.com>
Date: Tue, 28 Oct 2014 22:05:30 -0700
Message-ID: <CABPQxsviKAVFfOiy2BbgOWaXKPzR5c7hB6EGbM6bcRx4uGt06Q@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Patrick Wendell <pwendell@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Stephen Boesch <javadba@gmail.com>, Zhan Zhang <zzhang@hortonworks.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Cheng - to make it recognize the new HiveShim for 0.12 I had to click
on spark-hive under "packages" in the left pane, then go to "Open
Module Settings" - then explicitly add the v0.12.0/src/main/scala
folder to the sources by navigating to it and then <ctrl>+click to add
it as a source. Did you have to do this?

On Tue, Oct 28, 2014 at 9:57 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> I just started a totally fresh IntelliJ project importing from our
> root pom. I used all the default options and I added "hadoop-2.4,
> hive, hive-0.13.1" profiles. I was able to run spark core tests from
> within IntelliJ. Didn't try anything beyond that, but FWIW this
> worked.
>
> - Patrick
>
> On Tue, Oct 28, 2014 at 9:54 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
>> You may first open the root pom.xml file in IDEA, and then go for menu View
>> / Tool Windows / Maven Projects, then choose desired Maven profile
>> combination under the "Profiles" node (e.g. I usually use hadoop-2.4 + hive
>> + hive-0.12.0). IDEA will ask you to re-import the Maven projects, confirm,
>> then it should be OK.
>>
>> I can debug within IDEA with this approach. However, you have to clean the
>> whole project before debugging Spark within IDEA if you compiled the project
>> outside IDEA. Haven't got time to investigate this annoying issue.
>>
>> Also, you can remove sub projects unrelated to your tasks to accelerate
>> compilation and/or avoid other IDEA build issues (e.g. Avro related Spark
>> streaming build failure in IDEA).
>>
>>
>> On 10/29/14 12:42 PM, Stephen Boesch wrote:
>>
>> I am interested specifically in how to build (and hopefully run/debug..)
>> under Intellij.  Your posts sound like command line maven - which has always
>> been working already.
>>
>> Do you have instructions for building in IJ?
>>
>> 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:
>>>
>>> Yes, these two combinations work for me.
>>>
>>>
>>> On 10/29/14 12:32 PM, Zhan Zhang wrote:
>>>>
>>>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0" is to enable
>>>> hive-0.12.0. Note that the thrift-server is not supported yet in hive-0.13,
>>>> but expected to go to upstream soon (Spark-3720).
>>>>
>>>> Thanks.
>>>>
>>>> Zhan Zhang
>>>>
>>>>
>>>>   On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:
>>>>
>>>>> Thanks Patrick for the heads up.
>>>>>
>>>>> I have not been successful to discover a combination of profiles (i.e.
>>>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
>>>>> maven. Anyone who knows how to handle this - a quick note here would be
>>>>> appreciated.
>>>>>
>>>>>
>>>>>
>>>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>>>>>
>>>>>> Hey Stephen,
>>>>>>
>>>>>> In some cases in the maven build we now have pluggable source
>>>>>> directories based on profiles using the maven build helper plug-in.
>>>>>> This is necessary to support cross building against different Hive
>>>>>> versions, and there will be additional instances of this due to
>>>>>> supporting scala 2.11 and 2.10.
>>>>>>
>>>>>> In these cases, you may need to add source locations explicitly to
>>>>>> intellij if you want the entire project to compile there.
>>>>>>
>>>>>> Unfortunately as long as we support cross-building like this, it will
>>>>>> be an issue. Intellij's maven support does not correctly detect our
>>>>>> use of the maven-build-plugin to add source directories.
>>>>>>
>>>>>> We should come up with a good set of instructions on how to import the
>>>>>> pom files + add the few extra source directories. Off hand I am not
>>>>>> sure exactly what the correct sequence is.
>>>>>>
>>>>>> - Patrick
>>>>>>
>>>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com>
>>>>>> wrote:
>>>>>>>
>>>>>>> Hi Matei,
>>>>>>>   Until my latest pull from upstream/master it had not been necessary
>>>>>>> to
>>>>>>> add the hive profile: is it now??
>>>>>>>
>>>>>>> I am not using sbt gen-idea. The way to open in intellij has been to
>>>>>>> Open
>>>>>>> the parent directory. IJ recognizes it as a maven project.
>>>>>>>
>>>>>>> There are several steps to do surgery on the yarn-parent / yarn
>>>>>>> projects
>>>>>>
>>>>>> ,
>>>>>>>
>>>>>>> then do a full rebuild.  That was working until one week ago.
>>>>>>> Intellij/maven is presently broken in  two ways:  this hive shim
>>>>>>> (which
>>>>>>
>>>>>> may
>>>>>>>
>>>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>>>>>> "NoClassDefFoundError
>>>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>>>>>>
>>>>>> serious
>>>>>>>
>>>>>>> problem .
>>>>>>>
>>>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>>>>>
>>>>>>>> Hi Stephen,
>>>>>>>>
>>>>>>>> How did you generate your Maven workspace? You need to make sure the
>>>>>>
>>>>>> Hive
>>>>>>>>
>>>>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>>>>>
>>>>>>>> Matei
>>>>>>>>
>>>>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>>>>>>
>>>>>> wrote:
>>>>>>>>>
>>>>>>>>> I have run on the command line via maven and it is fine:
>>>>>>>>>
>>>>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
>>>>>>
>>>>>> -Phadoop-2.3
>>>>>>>>>
>>>>>>>>> compile package install
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> But with the latest code Intellij builds do not work. Following is
>>>>>>
>>>>>> one of
>>>>>>>>>
>>>>>>>>> 26 similar errors:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Error:(173, 38) not found: value HiveShim
>>>>>>>>>
>>>>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>>>>>
>>>>>>>>>                                     ^
>>>>>>>>
>>>>>>>>
>>>>
>>>
>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10032-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 05:15:21 2014
Return-Path: <dev-return-10032-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 5CE45179BF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 05:15:21 +0000 (UTC)
Received: (qmail 81993 invoked by uid 500); 29 Oct 2014 05:15:20 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81920 invoked by uid 500); 29 Oct 2014 05:15:20 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81906 invoked by uid 99); 29 Oct 2014 05:15:20 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:15:20 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of javadba@gmail.com designates 209.85.220.172 as permitted sender)
Received: from [209.85.220.172] (HELO mail-vc0-f172.google.com) (209.85.220.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:14:52 +0000
Received: by mail-vc0-f172.google.com with SMTP id le20so257897vcb.31
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 22:14:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=49NrgSbMzE3vOmcELpIC5SxGhD5GU1xOkTvof5coDjA=;
        b=qqyF7lhdsmDVdVasxo/KkOI8AwrlHWDVlGObff3pUvk8hkM1qCDKuybrneMA6VX0EK
         ZWVJggDmRkNdYZ7tnLDfDYjwxNhmxVc1+fPtkItUDzNRMV8cZfeYjk9fFa+9J8OMQl58
         2eEpinrNYVcAy39w/5DNt6KzvSBlgpJ/2GLeywRjvkcz+mPY5SkQEF4kvXjOqCqUCS2J
         Q77jU6rq4Z52Zh60oV8CvvXQ4ZkglaK6QaT7C+ljgAQA9zewh4nEumNkyMgy3/uWfrLu
         buCXlbuH9Il5pRtw82zbfO8dmo8xyv4FkGOUhcJe4y/hX04YvWskL0MsE3k9n/F4+cnZ
         qWMw==
MIME-Version: 1.0
X-Received: by 10.220.197.9 with SMTP id ei9mr3455587vcb.45.1414559691266;
 Tue, 28 Oct 2014 22:14:51 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Tue, 28 Oct 2014 22:14:51 -0700 (PDT)
In-Reply-To: <CABPQxsuTbmqYNRVj3sjNaw_0Uo88TKtZNAw_gAFvEhzvJExUMA@mail.gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
	<54506F38.1000505@gmail.com>
	<CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
	<545072E8.8070600@gmail.com>
	<CABPQxstiBxKcfg993UhtK-yAV9BrH5b=EYOdq-QN8AzUtvUVHQ@mail.gmail.com>
	<CABPQxsviKAVFfOiy2BbgOWaXKPzR5c7hB6EGbM6bcRx4uGt06Q@mail.gmail.com>
	<CABPQxsuTbmqYNRVj3sjNaw_0Uo88TKtZNAw_gAFvEhzvJExUMA@mail.gmail.com>
Date: Tue, 28 Oct 2014 22:14:51 -0700
Message-ID: <CACkSZy38azP+Y3QLey73sOvsjyP1akQwBE7Lg-OjSDyC4S6vyQ@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Stephen Boesch <javadba@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Zhan Zhang <zzhang@hortonworks.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c1e27ae95fef050688d7e6
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c1e27ae95fef050688d7e6
Content-Type: text/plain; charset=UTF-8

Thanks guys - adding the source root for the shim manually was the issue.

For some reason the other issue I  was struggling with
(NoCLassDefFoundError on ThreadFactoryBuilder) also disappeared. I am able
to run tests now inside IJ.  Woot

2014-10-28 22:13 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:

> Oops - I actually should have added v0.13.0 (i.e. to match whatever I
> did in the profile).
>
> On Tue, Oct 28, 2014 at 10:05 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> > Cheng - to make it recognize the new HiveShim for 0.12 I had to click
> > on spark-hive under "packages" in the left pane, then go to "Open
> > Module Settings" - then explicitly add the v0.12.0/src/main/scala
> > folder to the sources by navigating to it and then <ctrl>+click to add
> > it as a source. Did you have to do this?
> >
> > On Tue, Oct 28, 2014 at 9:57 PM, Patrick Wendell <pwendell@gmail.com>
> wrote:
> >> I just started a totally fresh IntelliJ project importing from our
> >> root pom. I used all the default options and I added "hadoop-2.4,
> >> hive, hive-0.13.1" profiles. I was able to run spark core tests from
> >> within IntelliJ. Didn't try anything beyond that, but FWIW this
> >> worked.
> >>
> >> - Patrick
> >>
> >> On Tue, Oct 28, 2014 at 9:54 PM, Cheng Lian <lian.cs.zju@gmail.com>
> wrote:
> >>> You may first open the root pom.xml file in IDEA, and then go for menu
> View
> >>> / Tool Windows / Maven Projects, then choose desired Maven profile
> >>> combination under the "Profiles" node (e.g. I usually use hadoop-2.4 +
> hive
> >>> + hive-0.12.0). IDEA will ask you to re-import the Maven projects,
> confirm,
> >>> then it should be OK.
> >>>
> >>> I can debug within IDEA with this approach. However, you have to clean
> the
> >>> whole project before debugging Spark within IDEA if you compiled the
> project
> >>> outside IDEA. Haven't got time to investigate this annoying issue.
> >>>
> >>> Also, you can remove sub projects unrelated to your tasks to accelerate
> >>> compilation and/or avoid other IDEA build issues (e.g. Avro related
> Spark
> >>> streaming build failure in IDEA).
> >>>
> >>>
> >>> On 10/29/14 12:42 PM, Stephen Boesch wrote:
> >>>
> >>> I am interested specifically in how to build (and hopefully
> run/debug..)
> >>> under Intellij.  Your posts sound like command line maven - which has
> always
> >>> been working already.
> >>>
> >>> Do you have instructions for building in IJ?
> >>>
> >>> 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:
> >>>>
> >>>> Yes, these two combinations work for me.
> >>>>
> >>>>
> >>>> On 10/29/14 12:32 PM, Zhan Zhang wrote:
> >>>>>
> >>>>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0" is to
> enable
> >>>>> hive-0.12.0. Note that the thrift-server is not supported yet in
> hive-0.13,
> >>>>> but expected to go to upstream soon (Spark-3720).
> >>>>>
> >>>>> Thanks.
> >>>>>
> >>>>> Zhan Zhang
> >>>>>
> >>>>>
> >>>>>   On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com>
> wrote:
> >>>>>
> >>>>>> Thanks Patrick for the heads up.
> >>>>>>
> >>>>>> I have not been successful to discover a combination of profiles
> (i.e.
> >>>>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij
> with
> >>>>>> maven. Anyone who knows how to handle this - a quick note here
> would be
> >>>>>> appreciated.
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
> >>>>>>
> >>>>>>> Hey Stephen,
> >>>>>>>
> >>>>>>> In some cases in the maven build we now have pluggable source
> >>>>>>> directories based on profiles using the maven build helper plug-in.
> >>>>>>> This is necessary to support cross building against different Hive
> >>>>>>> versions, and there will be additional instances of this due to
> >>>>>>> supporting scala 2.11 and 2.10.
> >>>>>>>
> >>>>>>> In these cases, you may need to add source locations explicitly to
> >>>>>>> intellij if you want the entire project to compile there.
> >>>>>>>
> >>>>>>> Unfortunately as long as we support cross-building like this, it
> will
> >>>>>>> be an issue. Intellij's maven support does not correctly detect our
> >>>>>>> use of the maven-build-plugin to add source directories.
> >>>>>>>
> >>>>>>> We should come up with a good set of instructions on how to import
> the
> >>>>>>> pom files + add the few extra source directories. Off hand I am not
> >>>>>>> sure exactly what the correct sequence is.
> >>>>>>>
> >>>>>>> - Patrick
> >>>>>>>
> >>>>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com
> >
> >>>>>>> wrote:
> >>>>>>>>
> >>>>>>>> Hi Matei,
> >>>>>>>>   Until my latest pull from upstream/master it had not been
> necessary
> >>>>>>>> to
> >>>>>>>> add the hive profile: is it now??
> >>>>>>>>
> >>>>>>>> I am not using sbt gen-idea. The way to open in intellij has been
> to
> >>>>>>>> Open
> >>>>>>>> the parent directory. IJ recognizes it as a maven project.
> >>>>>>>>
> >>>>>>>> There are several steps to do surgery on the yarn-parent / yarn
> >>>>>>>> projects
> >>>>>>>
> >>>>>>> ,
> >>>>>>>>
> >>>>>>>> then do a full rebuild.  That was working until one week ago.
> >>>>>>>> Intellij/maven is presently broken in  two ways:  this hive shim
> >>>>>>>> (which
> >>>>>>>
> >>>>>>> may
> >>>>>>>>
> >>>>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
> >>>>>>>> "NoClassDefFoundError
> >>>>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite
> a
> >>>>>>>
> >>>>>>> serious
> >>>>>>>>
> >>>>>>>> problem .
> >>>>>>>>
> >>>>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com
> >:
> >>>>>>>>
> >>>>>>>>> Hi Stephen,
> >>>>>>>>>
> >>>>>>>>> How did you generate your Maven workspace? You need to make sure
> the
> >>>>>>>
> >>>>>>> Hive
> >>>>>>>>>
> >>>>>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
> >>>>>>>>>
> >>>>>>>>> Matei
> >>>>>>>>>
> >>>>>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
> >>>>>>>
> >>>>>>> wrote:
> >>>>>>>>>>
> >>>>>>>>>> I have run on the command line via maven and it is fine:
> >>>>>>>>>>
> >>>>>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
> >>>>>>>
> >>>>>>> -Phadoop-2.3
> >>>>>>>>>>
> >>>>>>>>>> compile package install
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> But with the latest code Intellij builds do not work. Following
> is
> >>>>>>>
> >>>>>>> one of
> >>>>>>>>>>
> >>>>>>>>>> 26 similar errors:
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> Error:(173, 38) not found: value HiveShim
> >>>>>>>>>>
> >>>>>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
> >>>>>>>>>>
> >>>>>>>>>>                                     ^
> >>>>>>>>>
> >>>>>>>>>
> >>>>>
> >>>>
> >>>
> >>>
>

--001a11c1e27ae95fef050688d7e6--

From dev-return-10033-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 05:16:07 2014
Return-Path: <dev-return-10033-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9FC1A179CC
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 05:16:07 +0000 (UTC)
Received: (qmail 84331 invoked by uid 500); 29 Oct 2014 05:16:06 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84263 invoked by uid 500); 29 Oct 2014 05:16:06 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 83937 invoked by uid 99); 29 Oct 2014 05:16:06 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:16:06 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.45 as permitted sender)
Received: from [209.85.218.45] (HELO mail-oi0-f45.google.com) (209.85.218.45)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:15:29 +0000
Received: by mail-oi0-f45.google.com with SMTP id i138so1731807oig.18
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 22:13:12 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=a8L/fVAEcee+fnhyck7tAtuBFCkmal3f4xVHBtKi1N4=;
        b=aozMP2nxHDfJ17dTfHTXbh+QjnRV6nx5MZZSFHHJDmrzqIeSo7LYLKNFtvUsRYUumF
         zCnSCTa57rrJajrTBy570VIhSb5e0berZPsdT36lI2t9qSYBJWYe50mbK8XXk8QFpX6M
         5ouI8bL1JkvAHH8hX6us/OAk+7DqycUVrKPV8J1n/PPg9TgYPHP0bB2bEyW8YHhOAgO8
         rrXmWcjDgkboIyx5SrP+zx7KSlf3T9kM6QlUXu5Z63uIplWBDj19QdzLPMPAgnkC263b
         8ytEFnMrALYaIhjQMy5Ef+RQpQxtMmPEMoLvPDDxqEaBFdv4ETMXES5vyYg2c1n39Mba
         5Avw==
MIME-Version: 1.0
X-Received: by 10.182.5.71 with SMTP id q7mr6764660obq.28.1414559592934; Tue,
 28 Oct 2014 22:13:12 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Tue, 28 Oct 2014 22:13:12 -0700 (PDT)
In-Reply-To: <CABPQxsviKAVFfOiy2BbgOWaXKPzR5c7hB6EGbM6bcRx4uGt06Q@mail.gmail.com>
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>
	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>
	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>
	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>
	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>
	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>
	<54506F38.1000505@gmail.com>
	<CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>
	<545072E8.8070600@gmail.com>
	<CABPQxstiBxKcfg993UhtK-yAV9BrH5b=EYOdq-QN8AzUtvUVHQ@mail.gmail.com>
	<CABPQxsviKAVFfOiy2BbgOWaXKPzR5c7hB6EGbM6bcRx4uGt06Q@mail.gmail.com>
Date: Tue, 28 Oct 2014 22:13:12 -0700
Message-ID: <CABPQxsuTbmqYNRVj3sjNaw_0Uo88TKtZNAw_gAFvEhzvJExUMA@mail.gmail.com>
Subject: Re: HiveShim not found when building in Intellij
From: Patrick Wendell <pwendell@gmail.com>
To: Cheng Lian <lian.cs.zju@gmail.com>
Cc: Stephen Boesch <javadba@gmail.com>, Zhan Zhang <zzhang@hortonworks.com>, 
	Matei Zaharia <matei.zaharia@gmail.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Oops - I actually should have added v0.13.0 (i.e. to match whatever I
did in the profile).

On Tue, Oct 28, 2014 at 10:05 PM, Patrick Wendell <pwendell@gmail.com> wrote:
> Cheng - to make it recognize the new HiveShim for 0.12 I had to click
> on spark-hive under "packages" in the left pane, then go to "Open
> Module Settings" - then explicitly add the v0.12.0/src/main/scala
> folder to the sources by navigating to it and then <ctrl>+click to add
> it as a source. Did you have to do this?
>
> On Tue, Oct 28, 2014 at 9:57 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>> I just started a totally fresh IntelliJ project importing from our
>> root pom. I used all the default options and I added "hadoop-2.4,
>> hive, hive-0.13.1" profiles. I was able to run spark core tests from
>> within IntelliJ. Didn't try anything beyond that, but FWIW this
>> worked.
>>
>> - Patrick
>>
>> On Tue, Oct 28, 2014 at 9:54 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
>>> You may first open the root pom.xml file in IDEA, and then go for menu View
>>> / Tool Windows / Maven Projects, then choose desired Maven profile
>>> combination under the "Profiles" node (e.g. I usually use hadoop-2.4 + hive
>>> + hive-0.12.0). IDEA will ask you to re-import the Maven projects, confirm,
>>> then it should be OK.
>>>
>>> I can debug within IDEA with this approach. However, you have to clean the
>>> whole project before debugging Spark within IDEA if you compiled the project
>>> outside IDEA. Haven't got time to investigate this annoying issue.
>>>
>>> Also, you can remove sub projects unrelated to your tasks to accelerate
>>> compilation and/or avoid other IDEA build issues (e.g. Avro related Spark
>>> streaming build failure in IDEA).
>>>
>>>
>>> On 10/29/14 12:42 PM, Stephen Boesch wrote:
>>>
>>> I am interested specifically in how to build (and hopefully run/debug..)
>>> under Intellij.  Your posts sound like command line maven - which has always
>>> been working already.
>>>
>>> Do you have instructions for building in IJ?
>>>
>>> 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:
>>>>
>>>> Yes, these two combinations work for me.
>>>>
>>>>
>>>> On 10/29/14 12:32 PM, Zhan Zhang wrote:
>>>>>
>>>>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0" is to enable
>>>>> hive-0.12.0. Note that the thrift-server is not supported yet in hive-0.13,
>>>>> but expected to go to upstream soon (Spark-3720).
>>>>>
>>>>> Thanks.
>>>>>
>>>>> Zhan Zhang
>>>>>
>>>>>
>>>>>   On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:
>>>>>
>>>>>> Thanks Patrick for the heads up.
>>>>>>
>>>>>> I have not been successful to discover a combination of profiles (i.e.
>>>>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
>>>>>> maven. Anyone who knows how to handle this - a quick note here would be
>>>>>> appreciated.
>>>>>>
>>>>>>
>>>>>>
>>>>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>>>>>>
>>>>>>> Hey Stephen,
>>>>>>>
>>>>>>> In some cases in the maven build we now have pluggable source
>>>>>>> directories based on profiles using the maven build helper plug-in.
>>>>>>> This is necessary to support cross building against different Hive
>>>>>>> versions, and there will be additional instances of this due to
>>>>>>> supporting scala 2.11 and 2.10.
>>>>>>>
>>>>>>> In these cases, you may need to add source locations explicitly to
>>>>>>> intellij if you want the entire project to compile there.
>>>>>>>
>>>>>>> Unfortunately as long as we support cross-building like this, it will
>>>>>>> be an issue. Intellij's maven support does not correctly detect our
>>>>>>> use of the maven-build-plugin to add source directories.
>>>>>>>
>>>>>>> We should come up with a good set of instructions on how to import the
>>>>>>> pom files + add the few extra source directories. Off hand I am not
>>>>>>> sure exactly what the correct sequence is.
>>>>>>>
>>>>>>> - Patrick
>>>>>>>
>>>>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com>
>>>>>>> wrote:
>>>>>>>>
>>>>>>>> Hi Matei,
>>>>>>>>   Until my latest pull from upstream/master it had not been necessary
>>>>>>>> to
>>>>>>>> add the hive profile: is it now??
>>>>>>>>
>>>>>>>> I am not using sbt gen-idea. The way to open in intellij has been to
>>>>>>>> Open
>>>>>>>> the parent directory. IJ recognizes it as a maven project.
>>>>>>>>
>>>>>>>> There are several steps to do surgery on the yarn-parent / yarn
>>>>>>>> projects
>>>>>>>
>>>>>>> ,
>>>>>>>>
>>>>>>>> then do a full rebuild.  That was working until one week ago.
>>>>>>>> Intellij/maven is presently broken in  two ways:  this hive shim
>>>>>>>> (which
>>>>>>>
>>>>>>> may
>>>>>>>>
>>>>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>>>>>>> "NoClassDefFoundError
>>>>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>>>>>>>
>>>>>>> serious
>>>>>>>>
>>>>>>>> problem .
>>>>>>>>
>>>>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>>>>>>
>>>>>>>>> Hi Stephen,
>>>>>>>>>
>>>>>>>>> How did you generate your Maven workspace? You need to make sure the
>>>>>>>
>>>>>>> Hive
>>>>>>>>>
>>>>>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>>>>>>
>>>>>>>>> Matei
>>>>>>>>>
>>>>>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>>>>>>>
>>>>>>> wrote:
>>>>>>>>>>
>>>>>>>>>> I have run on the command line via maven and it is fine:
>>>>>>>>>>
>>>>>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
>>>>>>>
>>>>>>> -Phadoop-2.3
>>>>>>>>>>
>>>>>>>>>> compile package install
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> But with the latest code Intellij builds do not work. Following is
>>>>>>>
>>>>>>> one of
>>>>>>>>>>
>>>>>>>>>> 26 similar errors:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Error:(173, 38) not found: value HiveShim
>>>>>>>>>>
>>>>>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>>>>>>
>>>>>>>>>>                                     ^
>>>>>>>>>
>>>>>>>>>
>>>>>
>>>>
>>>
>>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10034-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 05:22:43 2014
Return-Path: <dev-return-10034-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 7D32717A23
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 05:22:43 +0000 (UTC)
Received: (qmail 98504 invoked by uid 500); 29 Oct 2014 05:22:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 98432 invoked by uid 500); 29 Oct 2014 05:22:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 98420 invoked by uid 99); 29 Oct 2014 05:22:42 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:22:42 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of lian.cs.zju@gmail.com designates 209.85.220.50 as permitted sender)
Received: from [209.85.220.50] (HELO mail-pa0-f50.google.com) (209.85.220.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 05:22:14 +0000
Received: by mail-pa0-f50.google.com with SMTP id eu11so2367327pac.23
        for <dev@spark.apache.org>; Tue, 28 Oct 2014 22:19:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=message-id:date:from:user-agent:mime-version:to:cc:subject
         :references:in-reply-to:content-type:content-transfer-encoding;
        bh=zeLZwdVJQg2kX01EG2egYtQYmkMmMlsjSvn5lDYlql0=;
        b=z8E5V7Pii3CwWeQPed8RxNMCqsL2jTuBCIqwhoyMa5EDI3KWrrNQPOp4CUA5JQM/QS
         AAOBxl+kQmp4wFU8AhE8HHn/KA6tTENbuYmcRnzKA3p2yrGK8tero9PeAhxCz3GPNCzq
         KE8hQf+xfQV+5zyKbSMmujkYVa6XJleFS51t0INDEnVsu8c/Dl+1dZcbKKpn+0vXeZ6j
         /bIHMQT/v6vaDkKmGileJz76FZtQvcRH4M6FoS4zxDXo9dRvCsSd4Qy+WVqfMdbZRpTg
         TmH5XlbT/w16VpMa6P2FvoDP/MWTZbJ5VcWrW+QYg/VoCeauIpv6hd/QxAi8OsRpugh5
         gFBg==
X-Received: by 10.66.244.233 with SMTP id xj9mr6883507pac.67.1414559997640;
        Tue, 28 Oct 2014 22:19:57 -0700 (PDT)
Received: from lian-laptop.local ([199.101.117.27])
        by mx.google.com with ESMTPSA id ny9sm3150165pab.25.2014.10.28.22.19.55
        for <multiple recipients>
        (version=TLSv1.2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 28 Oct 2014 22:19:57 -0700 (PDT)
Message-ID: <545078F9.7020805@gmail.com>
Date: Wed, 29 Oct 2014 13:19:53 +0800
From: Cheng Lian <lian.cs.zju@gmail.com>
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Thunderbird/31.2.0
MIME-Version: 1.0
To: Patrick Wendell <pwendell@gmail.com>
CC: Stephen Boesch <javadba@gmail.com>, 
 Zhan Zhang <zzhang@hortonworks.com>,
 Matei Zaharia <matei.zaharia@gmail.com>, 
 "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: HiveShim not found when building in Intellij
References: <CACkSZy0F+BPdSGTJpKi_tzD8shZ_0x-zRAso1q5f=9Q4__DgPA@mail.gmail.com>	<0038F127-94D3-4CB6-8B4A-2E6438B57EA5@gmail.com>	<CACkSZy21ME=cw99A4cc8nyM0B5bPwkRE4TprmyaM38ciPmaTSA@mail.gmail.com>	<CABPQxsvhvY+syRSWRwLFjZAWp5_zeyzzsFQ9AgKBPTh43uZ3kQ@mail.gmail.com>	<CACkSZy37bLmFYEHR14EdeOGqse0nKBe1ak21H_Joub3Gb29gwA@mail.gmail.com>	<FB2722E5-64A2-4EF5-8ABF-873BA61F2E43@hortonworks.com>	<54506F38.1000505@gmail.com>	<CACkSZy2WbbL22AkqHn6=+wCoEvMMsZN06rK8YRUhafVMyikh2A@mail.gmail.com>	<545072E8.8070600@gmail.com>	<CABPQxstiBxKcfg993UhtK-yAV9BrH5b=EYOdq-QN8AzUtvUVHQ@mail.gmail.com> <CABPQxsviKAVFfOiy2BbgOWaXKPzR5c7hB6EGbM6bcRx4uGt06Q@mail.gmail.com>
In-Reply-To: <CABPQxsviKAVFfOiy2BbgOWaXKPzR5c7hB6EGbM6bcRx4uGt06Q@mail.gmail.com>
Content-Type: text/plain; charset=windows-1252; format=flowed
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hm, the shim source folder could be automatically recognized some time 
before, although at a wrong directory level (sql/hive/v0.12.0/src 
instead of sql/hive/v0.12.0/src/main/scala), it compiles.

Just tried against a fresh checkout, indeed need to add shim source 
folder manually. Sorry for the confusion.

Cheng

On 10/29/14 1:05 PM, Patrick Wendell wrote:
> Cheng - to make it recognize the new HiveShim for 0.12 I had to click
> on spark-hive under "packages" in the left pane, then go to "Open
> Module Settings" - then explicitly add the v0.12.0/src/main/scala
> folder to the sources by navigating to it and then <ctrl>+click to add
> it as a source. Did you have to do this?
>
> On Tue, Oct 28, 2014 at 9:57 PM, Patrick Wendell <pwendell@gmail.com> wrote:
>> I just started a totally fresh IntelliJ project importing from our
>> root pom. I used all the default options and I added "hadoop-2.4,
>> hive, hive-0.13.1" profiles. I was able to run spark core tests from
>> within IntelliJ. Didn't try anything beyond that, but FWIW this
>> worked.
>>
>> - Patrick
>>
>> On Tue, Oct 28, 2014 at 9:54 PM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
>>> You may first open the root pom.xml file in IDEA, and then go for menu View
>>> / Tool Windows / Maven Projects, then choose desired Maven profile
>>> combination under the "Profiles" node (e.g. I usually use hadoop-2.4 + hive
>>> + hive-0.12.0). IDEA will ask you to re-import the Maven projects, confirm,
>>> then it should be OK.
>>>
>>> I can debug within IDEA with this approach. However, you have to clean the
>>> whole project before debugging Spark within IDEA if you compiled the project
>>> outside IDEA. Haven't got time to investigate this annoying issue.
>>>
>>> Also, you can remove sub projects unrelated to your tasks to accelerate
>>> compilation and/or avoid other IDEA build issues (e.g. Avro related Spark
>>> streaming build failure in IDEA).
>>>
>>>
>>> On 10/29/14 12:42 PM, Stephen Boesch wrote:
>>>
>>> I am interested specifically in how to build (and hopefully run/debug..)
>>> under Intellij.  Your posts sound like command line maven - which has always
>>> been working already.
>>>
>>> Do you have instructions for building in IJ?
>>>
>>> 2014-10-28 21:38 GMT-07:00 Cheng Lian <lian.cs.zju@gmail.com>:
>>>> Yes, these two combinations work for me.
>>>>
>>>>
>>>> On 10/29/14 12:32 PM, Zhan Zhang wrote:
>>>>> -Phive is to enable hive-0.13.1 and "-Phive -Phive-0.12.0" is to enable
>>>>> hive-0.12.0. Note that the thrift-server is not supported yet in hive-0.13,
>>>>> but expected to go to upstream soon (Spark-3720).
>>>>>
>>>>> Thanks.
>>>>>
>>>>> Zhan Zhang
>>>>>
>>>>>
>>>>>    On Oct 28, 2014, at 9:09 PM, Stephen Boesch <javadba@gmail.com> wrote:
>>>>>
>>>>>> Thanks Patrick for the heads up.
>>>>>>
>>>>>> I have not been successful to discover a combination of profiles (i.e.
>>>>>> enabling hive or hive-0.12.0 or hive-13.0) that works in Intellij with
>>>>>> maven. Anyone who knows how to handle this - a quick note here would be
>>>>>> appreciated.
>>>>>>
>>>>>>
>>>>>>
>>>>>> 2014-10-28 20:20 GMT-07:00 Patrick Wendell <pwendell@gmail.com>:
>>>>>>
>>>>>>> Hey Stephen,
>>>>>>>
>>>>>>> In some cases in the maven build we now have pluggable source
>>>>>>> directories based on profiles using the maven build helper plug-in.
>>>>>>> This is necessary to support cross building against different Hive
>>>>>>> versions, and there will be additional instances of this due to
>>>>>>> supporting scala 2.11 and 2.10.
>>>>>>>
>>>>>>> In these cases, you may need to add source locations explicitly to
>>>>>>> intellij if you want the entire project to compile there.
>>>>>>>
>>>>>>> Unfortunately as long as we support cross-building like this, it will
>>>>>>> be an issue. Intellij's maven support does not correctly detect our
>>>>>>> use of the maven-build-plugin to add source directories.
>>>>>>>
>>>>>>> We should come up with a good set of instructions on how to import the
>>>>>>> pom files + add the few extra source directories. Off hand I am not
>>>>>>> sure exactly what the correct sequence is.
>>>>>>>
>>>>>>> - Patrick
>>>>>>>
>>>>>>> On Tue, Oct 28, 2014 at 7:57 PM, Stephen Boesch <javadba@gmail.com>
>>>>>>> wrote:
>>>>>>>> Hi Matei,
>>>>>>>>    Until my latest pull from upstream/master it had not been necessary
>>>>>>>> to
>>>>>>>> add the hive profile: is it now??
>>>>>>>>
>>>>>>>> I am not using sbt gen-idea. The way to open in intellij has been to
>>>>>>>> Open
>>>>>>>> the parent directory. IJ recognizes it as a maven project.
>>>>>>>>
>>>>>>>> There are several steps to do surgery on the yarn-parent / yarn
>>>>>>>> projects
>>>>>>> ,
>>>>>>>> then do a full rebuild.  That was working until one week ago.
>>>>>>>> Intellij/maven is presently broken in  two ways:  this hive shim
>>>>>>>> (which
>>>>>>> may
>>>>>>>> yet hopefully be a small/simple fix - let us see) and  (2) the
>>>>>>>> "NoClassDefFoundError
>>>>>>>> on ThreadFactoryBuilder" from my prior emails -and which is quite a
>>>>>>> serious
>>>>>>>> problem .
>>>>>>>>
>>>>>>>> 2014-10-28 19:46 GMT-07:00 Matei Zaharia <matei.zaharia@gmail.com>:
>>>>>>>>
>>>>>>>>> Hi Stephen,
>>>>>>>>>
>>>>>>>>> How did you generate your Maven workspace? You need to make sure the
>>>>>>> Hive
>>>>>>>>> profile is enabled for it. For example sbt/sbt -Phive gen-idea.
>>>>>>>>>
>>>>>>>>> Matei
>>>>>>>>>
>>>>>>>>>> On Oct 28, 2014, at 7:42 PM, Stephen Boesch <javadba@gmail.com>
>>>>>>> wrote:
>>>>>>>>>> I have run on the command line via maven and it is fine:
>>>>>>>>>>
>>>>>>>>>> mvn   -Dscalastyle.failOnViolation=false -DskipTests -Pyarn
>>>>>>> -Phadoop-2.3
>>>>>>>>>> compile package install
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> But with the latest code Intellij builds do not work. Following is
>>>>>>> one of
>>>>>>>>>> 26 similar errors:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> Error:(173, 38) not found: value HiveShim
>>>>>>>>>>
>>>>>>>>> Option(tableParameters.get(HiveShim.getStatsSetupConstTotalSize))
>>>>>>>>>>                                      ^
>>>>>>>>>
>>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10035-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 17:03:20 2014
Return-Path: <dev-return-10035-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id CA808171E1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 17:03:20 +0000 (UTC)
Received: (qmail 25168 invoked by uid 500); 29 Oct 2014 17:03:19 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25092 invoked by uid 500); 29 Oct 2014 17:03:19 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25078 invoked by uid 99); 29 Oct 2014 17:03:19 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 17:03:19 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: local policy)
Received: from [134.100.9.70] (HELO mailhost.informatik.uni-hamburg.de) (134.100.9.70)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 17:02:53 +0000
Received: from localhost (localhost [127.0.0.1])
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTP id 5BC1757B;
	Wed, 29 Oct 2014 18:02:52 +0100 (CET)
X-Virus-Scanned: amavisd-new at informatik.uni-hamburg.de
Received: from mailhost.informatik.uni-hamburg.de ([127.0.0.1])
	by localhost (mailhost.informatik.uni-hamburg.de [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id g7aQBR7KQKEL; Wed, 29 Oct 2014 18:02:51 +0100 (CET)
Received: from [172.21.59.33] (uhh-wlan-fo-134-100-17-1.rrz.uni-hamburg.de [134.100.17.1])
	(using TLSv1 with cipher ECDHE-RSA-AES128-SHA (128/128 bits))
	(Client did not present a certificate)
	(Authenticated sender: 1wilcke)
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTPSA id 06A60579;
	Wed, 29 Oct 2014 18:02:51 +0100 (CET)
Message-ID: <54511DAF.7000007@informatik.uni-hamburg.de>
Date: Wed, 29 Oct 2014 18:02:39 +0100
From: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Icedove/24.8.1
MIME-Version: 1.0
To: Sean Owen <sowen@cloudera.com>
CC: dev@spark.apache.org
Subject: Re: How to run tests properly?
References: <544FCFD3.9020606@informatik.uni-hamburg.de> <CAMAsSdLbDLE_Lo3pAGOC05FSPjhRC8wN_3BqqbqzUFaarxdmgg@mail.gmail.com>
In-Reply-To: <CAMAsSdLbDLE_Lo3pAGOC05FSPjhRC8wN_3BqqbqzUFaarxdmgg@mail.gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Sean,

thanks for your reply. The tests still don't work. I focused on the
mllib and core tests and made some observations.

The core tests seems to fail because of my german locale. Some tests are
locale dependend like the
UtilsSuite.scala
 - "string formatting of time durations" - checks for locale dependend
seperators like "." and ","
 - "isBindCollision" - checks for the locale dependend exception message

In the MLlib it seems to be just one source of failure. The same
Exception I described in my first mail appears several times in
different tests.
The reason for all the similar failures is the line 29 in
LocalClusterSparkContext.scala.
When I change the line
.setMaster("local-cluster[2, 1, 512]")
to
.setMaster("local")
all tests run without a failure. The local-cluster mode seems to be the
reason for the failure. I tried some different configurations like
[1,1,512], [2,1,1024] etc. but couldn't get the tests run without a failure.

Could this be a configuration issue?

On 28.10.2014 19:03, Sean Owen wrote:
> On Tue, Oct 28, 2014 at 6:18 PM, Niklas Wilcke
> <1wilcke@informatik.uni-hamburg.de> wrote:
>> 1. via dev/run-tests script
>>     This script executes all tests and take several hours to finish.
>> Some tests failed but I can't say which of them. Should this really take
>> that long? Can I specify to run only MLlib tests?
> Yes, running all tests takes a long long time. It does print which
> tests failed, and you can see the errors in the test output.
>
> Did you read http://spark.apache.org/docs/latest/building-with-maven.html#spark-tests-in-maven
> ? This shows how to run just one test suite.
>
> In any Maven project you can try things like "mvn test -pl [module]"
> to run just one module's tests.
Yes I tried that as described below at point 2.
>> 2. directly via maven
>> I did the following described in the docs [0].
>>
>> export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M
>> -XX:ReservedCodeCacheSize=512m"
>> mvn -Pyarn -Phadoop-2.3 -DskipTests -Phive clean package
>> mvn -Pyarn -Phadoop-2.3 -Phive test
>>
>> This also doesn't work.
>> Why do I have to package spark bevore running the tests?
> What doesn't work?
> Some tests use the built assembly, which requires packaging.
I get the same Exceptions as in every other way.
>> 3. via sbt
>> I tried the following. I freshly cloned spark and checked out the tag
>> v1.1.0-rc4.
>>
>> sbt/sbt "project mllib" test
>>
>> and get the following exception in several cluster tests.
>>
>> [info] - task size should be small in both training and prediction ***
>> FAILED ***
> This just looks like a flaky test failure; I'd try again.
>
I don't think so. I tried for several times now in several different ways.

Thanks,
Niklas



---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10036-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 18:01:56 2014
Return-Path: <dev-return-10036-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E832817529
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 18:01:56 +0000 (UTC)
Received: (qmail 18960 invoked by uid 500); 29 Oct 2014 18:01:56 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 18875 invoked by uid 500); 29 Oct 2014 18:01:56 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 18777 invoked by uid 99); 29 Oct 2014 18:01:55 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 18:01:55 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.46 as permitted sender)
Received: from [209.85.218.46] (HELO mail-oi0-f46.google.com) (209.85.218.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 18:01:30 +0000
Received: by mail-oi0-f46.google.com with SMTP id g201so2692323oib.5
        for <dev@spark.apache.org>; Wed, 29 Oct 2014 11:01:28 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=aidsjmUafPtUmAkHJhfau60a4LM5ILmZqBNNg6S0mv4=;
        b=JEpGrhIvTzN0nGbiNq8UcYvDjIWMNxfo49G1XiiRf15kURwgVHv2uuLKt0F0Fi2ljf
         ZDtoDSkpVE2xdgaAqMPyQAg0iY8LyK9sLZKRZfQff7aiqH9ExZS0HNGTq5AbgoitKnYm
         xdAjxu8eThYLD5639Owz9LbZNnwZJ6+TdjWqjkLlNvSUufrOu5AmB17GP1um8K9bqSeJ
         9A1QVMelQC0de3y3XzOlC6OPFfb3WAEJQrsDS5PT0u1zGcHCM8t/ZIkwAQpUtCC6qktC
         lk+t9WWJJaW5m2f/y5BIgRvR4Nz5VNJv4YgxRmjBo+IvI/Ci7oyBeKFyWI9tSTE4MQDF
         ouyw==
MIME-Version: 1.0
X-Received: by 10.202.229.13 with SMTP id c13mr9377454oih.23.1414605688743;
 Wed, 29 Oct 2014 11:01:28 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Wed, 29 Oct 2014 11:01:28 -0700 (PDT)
In-Reply-To: <54511DAF.7000007@informatik.uni-hamburg.de>
References: <544FCFD3.9020606@informatik.uni-hamburg.de>
	<CAMAsSdLbDLE_Lo3pAGOC05FSPjhRC8wN_3BqqbqzUFaarxdmgg@mail.gmail.com>
	<54511DAF.7000007@informatik.uni-hamburg.de>
Date: Wed, 29 Oct 2014 11:01:28 -0700
Message-ID: <CABPQxss-GDg55FMzLB6LxshH9G5W8qdLLgcextnEmgc1m=4cWQ@mail.gmail.com>
Subject: Re: How to run tests properly?
From: Patrick Wendell <pwendell@gmail.com>
To: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
Cc: Sean Owen <sowen@cloudera.com>, "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

One thing is you need to do a "maven package" before you run tests.
The "local-cluster" tests depend on Spark already being packaged.

- Patrick

On Wed, Oct 29, 2014 at 10:02 AM, Niklas Wilcke
<1wilcke@informatik.uni-hamburg.de> wrote:
> Hi Sean,
>
> thanks for your reply. The tests still don't work. I focused on the
> mllib and core tests and made some observations.
>
> The core tests seems to fail because of my german locale. Some tests are
> locale dependend like the
> UtilsSuite.scala
>  - "string formatting of time durations" - checks for locale dependend
> seperators like "." and ","
>  - "isBindCollision" - checks for the locale dependend exception message
>
> In the MLlib it seems to be just one source of failure. The same
> Exception I described in my first mail appears several times in
> different tests.
> The reason for all the similar failures is the line 29 in
> LocalClusterSparkContext.scala.
> When I change the line
> .setMaster("local-cluster[2, 1, 512]")
> to
> .setMaster("local")
> all tests run without a failure. The local-cluster mode seems to be the
> reason for the failure. I tried some different configurations like
> [1,1,512], [2,1,1024] etc. but couldn't get the tests run without a failure.
>
> Could this be a configuration issue?
>
> On 28.10.2014 19:03, Sean Owen wrote:
>> On Tue, Oct 28, 2014 at 6:18 PM, Niklas Wilcke
>> <1wilcke@informatik.uni-hamburg.de> wrote:
>>> 1. via dev/run-tests script
>>>     This script executes all tests and take several hours to finish.
>>> Some tests failed but I can't say which of them. Should this really take
>>> that long? Can I specify to run only MLlib tests?
>> Yes, running all tests takes a long long time. It does print which
>> tests failed, and you can see the errors in the test output.
>>
>> Did you read http://spark.apache.org/docs/latest/building-with-maven.html#spark-tests-in-maven
>> ? This shows how to run just one test suite.
>>
>> In any Maven project you can try things like "mvn test -pl [module]"
>> to run just one module's tests.
> Yes I tried that as described below at point 2.
>>> 2. directly via maven
>>> I did the following described in the docs [0].
>>>
>>> export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M
>>> -XX:ReservedCodeCacheSize=512m"
>>> mvn -Pyarn -Phadoop-2.3 -DskipTests -Phive clean package
>>> mvn -Pyarn -Phadoop-2.3 -Phive test
>>>
>>> This also doesn't work.
>>> Why do I have to package spark bevore running the tests?
>> What doesn't work?
>> Some tests use the built assembly, which requires packaging.
> I get the same Exceptions as in every other way.
>>> 3. via sbt
>>> I tried the following. I freshly cloned spark and checked out the tag
>>> v1.1.0-rc4.
>>>
>>> sbt/sbt "project mllib" test
>>>
>>> and get the following exception in several cluster tests.
>>>
>>> [info] - task size should be small in both training and prediction ***
>>> FAILED ***
>> This just looks like a flaky test failure; I'd try again.
>>
> I don't think so. I tried for several times now in several different ways.
>
> Thanks,
> Niklas
>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10037-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 18:24:26 2014
Return-Path: <dev-return-10037-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id F125A17687
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 18:24:25 +0000 (UTC)
Received: (qmail 27670 invoked by uid 500); 29 Oct 2014 18:24:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 27598 invoked by uid 500); 29 Oct 2014 18:24:24 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 27581 invoked by uid 99); 29 Oct 2014 18:24:24 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 18:24:24 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.179 as permitted sender)
Received: from [209.85.217.179] (HELO mail-lb0-f179.google.com) (209.85.217.179)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 18:24:19 +0000
Received: by mail-lb0-f179.google.com with SMTP id w7so2957874lbi.24
        for <dev@spark.apache.org>; Wed, 29 Oct 2014 11:23:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=t0gSHL7YAkEAuygWs6SvoZS/sYVbcdwocQkdoHqQ+pw=;
        b=xwndtFX74/xkTIYcsCQjpz/RCa/e5sdVyKllFiyX79RRTZb0hXBeVByvWVAX8XiQyS
         TUcKVe/6XyaH15vA2JnotSwEG3GEOhavSmEKE/LDaLY85mRR99Pg7jPIEwZnN+NrRxVs
         u15uVUsD8JwkelB/5baCGyIAv9GO0MNO3kRcIDTTkIxpCFHdTZ75c8gryZkILNdLWgni
         izgIKCkOsYVMoLxWX91Cq3r/OTJwUFzmF51G0k3edeEEZUgrI3TX4DqOhr16klOOrEeo
         GjSyDqYDGHS+RbhXmLwldIclcyEgcfV6H5CwAYTPa832cHZebvz/D6/Jn0lt80+xDptD
         KDZQ==
MIME-Version: 1.0
X-Received: by 10.112.16.195 with SMTP id i3mr13208942lbd.72.1414607037401;
 Wed, 29 Oct 2014 11:23:57 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Wed, 29 Oct 2014 11:23:57 -0700 (PDT)
Date: Wed, 29 Oct 2014 11:23:57 -0700
Message-ID: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
Subject: matrix factorization cross validation
From: Debasish Das <debasish.das83@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c3cdfcf60fa6050693ddc5
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c3cdfcf60fa6050693ddc5
Content-Type: text/plain; charset=UTF-8

Hi,

In the current factorization flow, we cross validate on the test dataset
using the RMSE number but there are some other measures which are worth
looking into.

If we consider the problem as a regression problem and the ratings 1-5 are
considered as 5 classes, it is possible to generate a confusion matrix
using MultiClassMetrics.scala

If the ratings are only 0/1 (like from the spotify demo from spark summit)
then it is possible to use Binary Classification Metrices to come up with
the ROC curve...

For topK user/products we should also look into prec@k and pdcg@k as the
metric..

Does it make sense to add the multiclass metric and prec@k, pdcg@k in
examples.MovielensALS along with RMSE ?

Thanks.
Deb

--001a11c3cdfcf60fa6050693ddc5--

From dev-return-10038-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 19:15:16 2014
Return-Path: <dev-return-10038-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 63EC61788B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 19:15:16 +0000 (UTC)
Received: (qmail 74360 invoked by uid 500); 29 Oct 2014 19:15:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74288 invoked by uid 500); 29 Oct 2014 19:15:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74262 invoked by uid 99); 29 Oct 2014 19:15:14 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 19:15:14 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of mengxr@gmail.com designates 209.85.223.180 as permitted sender)
Received: from [209.85.223.180] (HELO mail-ie0-f180.google.com) (209.85.223.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 19:15:08 +0000
Received: by mail-ie0-f180.google.com with SMTP id y20so1299693ier.39
        for <dev@spark.apache.org>; Wed, 29 Oct 2014 12:14:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=z9UNL6kpCfhucwS2Hz32FjXsI8dz2lBbsUh56ulQ3VM=;
        b=EY59zBvSzT2GH8r2PNcxn2qhBEvBbij2WaFUGIfw1o3M678yIaldvU4/gC+6KgOgja
         eV2rYJ14bnE8iuroyqNE9Q7YNiNvlDU6TQxWXCrqRDEbnyc6qQh+3Jb7q/wttrwFNa0i
         hNu92I+3dx0Hx/D5rxjhBHxuC36kCU3C1MhKwahIBblheFDyenh4rpXa5vkspPCP3xRO
         hGya01/5xCX5TuLjGda2MOM1shmDVzBwC0A5OHaV0eaDrct4KfPpOTowsevSXAoXCnOw
         8TZ0GGOxLHMq40tsdRpLFxr2sH5sId43ZzS4UN14mn+0pR0h4ZFleRjsCpOLA032iRIY
         DRYw==
MIME-Version: 1.0
X-Received: by 10.43.168.8 with SMTP id ng8mr4527664icc.67.1414610088210; Wed,
 29 Oct 2014 12:14:48 -0700 (PDT)
Received: by 10.107.162.21 with HTTP; Wed, 29 Oct 2014 12:14:48 -0700 (PDT)
In-Reply-To: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
Date: Wed, 29 Oct 2014 12:14:48 -0700
Message-ID: <CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
Subject: Re: matrix factorization cross validation
From: Xiangrui Meng <mengxr@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

Let's narrow the context from matrix factorization to recommendation
via ALS. It adds extra complexity if we treat it as a multi-class
classification problem. ALS only outputs a single value for each
prediction, which is hard to convert to probability distribution over
the 5 rating levels. Treating it as a binary classification problem or
a ranking problem does make sense. The RankingMetricc is in master.
Free free to add prec@k and ndcg@k to examples.MovielensALS. ROC
should be good to add as well. -Xiangrui


On Wed, Oct 29, 2014 at 11:23 AM, Debasish Das <debasish.das83@gmail.com> wrote:
> Hi,
>
> In the current factorization flow, we cross validate on the test dataset
> using the RMSE number but there are some other measures which are worth
> looking into.
>
> If we consider the problem as a regression problem and the ratings 1-5 are
> considered as 5 classes, it is possible to generate a confusion matrix
> using MultiClassMetrics.scala
>
> If the ratings are only 0/1 (like from the spotify demo from spark summit)
> then it is possible to use Binary Classification Metrices to come up with
> the ROC curve...
>
> For topK user/products we should also look into prec@k and pdcg@k as the
> metric..
>
> Does it make sense to add the multiclass metric and prec@k, pdcg@k in
> examples.MovielensALS along with RMSE ?
>
> Thanks.
> Deb

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10039-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 20:18:00 2014
Return-Path: <dev-return-10039-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id A99E617B83
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 20:18:00 +0000 (UTC)
Received: (qmail 61095 invoked by uid 500); 29 Oct 2014 20:17:59 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61031 invoked by uid 500); 29 Oct 2014 20:17:59 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61019 invoked by uid 99); 29 Oct 2014 20:17:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 20:17:59 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.176 as permitted sender)
Received: from [209.85.217.176] (HELO mail-lb0-f176.google.com) (209.85.217.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 20:17:32 +0000
Received: by mail-lb0-f176.google.com with SMTP id z11so1151587lbi.7
        for <dev@spark.apache.org>; Wed, 29 Oct 2014 13:17:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=sdbFNIA6vy4AXf9Y6U70+Hvfi4My5a5aco0rc6gTCqY=;
        b=FeELRMT5QtB11jRR8G5w5+Nx6aWuOjfD524EWk/wtmUaE8AWAsweCYWLMY1El0IQYJ
         9JJTualq0FehsVxq2rC59h9+yFqym3+8H41pvasPd42zz/R+wra8rnV8DzTUsVdiC9Qv
         R/Zzr+knaIQPmDF9OL4Ph3NbAi88GuJ7g09llNdtwQIGHftGR3F7xFZ/GlARUJJ1zT3W
         HkokMI2XE+V4Ka87KzmA47ezZUCHjj/yNNHGUxkG/8cOaMbLcVYrUkh3JC4ymDryn/p1
         JGFPS0xoZQgI+WqLMoUsdpArcLMDUqkHKoMdWkOj6eNIAoqKKclv3v2EhO/huU67hRto
         3FzQ==
MIME-Version: 1.0
X-Received: by 10.152.87.18 with SMTP id t18mr9679382laz.0.1414613851553; Wed,
 29 Oct 2014 13:17:31 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Wed, 29 Oct 2014 13:17:31 -0700 (PDT)
In-Reply-To: <CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
	<CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
Date: Wed, 29 Oct 2014 13:17:31 -0700
Message-ID: <CA+B-+fwgwnbq0nAp6PRJFdyeRc4K1i+6pGypsC2i32DMPg27Qg@mail.gmail.com>
Subject: Re: matrix factorization cross validation
From: Debasish Das <debasish.das83@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c342161dc45e0506957423
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c342161dc45e0506957423
Content-Type: text/plain; charset=UTF-8

Makes sense for the binary and ranking problem but for example linear
regression for multi-class also optimizes on RMSE but we still measure the
prediction efficiency using some measure on confusion matrix...Is not the
same idea should hold for ALS as well ?


On Wed, Oct 29, 2014 at 12:14 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> Let's narrow the context from matrix factorization to recommendation
> via ALS. It adds extra complexity if we treat it as a multi-class
> classification problem. ALS only outputs a single value for each
> prediction, which is hard to convert to probability distribution over
> the 5 rating levels. Treating it as a binary classification problem or
> a ranking problem does make sense. The RankingMetricc is in master.
> Free free to add prec@k and ndcg@k to examples.MovielensALS. ROC
> should be good to add as well. -Xiangrui
>
>
> On Wed, Oct 29, 2014 at 11:23 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > Hi,
> >
> > In the current factorization flow, we cross validate on the test dataset
> > using the RMSE number but there are some other measures which are worth
> > looking into.
> >
> > If we consider the problem as a regression problem and the ratings 1-5
> are
> > considered as 5 classes, it is possible to generate a confusion matrix
> > using MultiClassMetrics.scala
> >
> > If the ratings are only 0/1 (like from the spotify demo from spark
> summit)
> > then it is possible to use Binary Classification Metrices to come up with
> > the ROC curve...
> >
> > For topK user/products we should also look into prec@k and pdcg@k as the
> > metric..
> >
> > Does it make sense to add the multiclass metric and prec@k, pdcg@k in
> > examples.MovielensALS along with RMSE ?
> >
> > Thanks.
> > Deb
>

--001a11c342161dc45e0506957423--

From dev-return-10040-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Wed Oct 29 21:38:54 2014
Return-Path: <dev-return-10040-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 91F4A17F18
	for <apmail-spark-dev-archive@minotaur.apache.org>; Wed, 29 Oct 2014 21:38:54 +0000 (UTC)
Received: (qmail 32797 invoked by uid 500); 29 Oct 2014 21:38:53 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 32727 invoked by uid 500); 29 Oct 2014 21:38:53 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 32702 invoked by uid 99); 29 Oct 2014 21:38:53 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 21:38:53 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Wed, 29 Oct 2014 21:38:28 +0000
Received: by mail-ig0-f177.google.com with SMTP id hl2so3038609igb.16
        for <dev@spark.apache.org>; Wed, 29 Oct 2014 14:37:42 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=lhjlNnuJzTHmMi8x0xm4W4Id3HDpMiljZTX0dUdwhYY=;
        b=A7dMdIRF3TYN+HjRxRST4Ms1kIg51x8jnLpvuM1WzTiXle+NWaoODoM8jnpLznZXEh
         izoAWrttAfNzIazRZmsLpGZIV5SwwedPlfPQX4LLxjekn6H/blLcOKzY9hpldGNmYMHo
         7gUaQUtWpq3VmdcsvotrspkIAGCdw4rsfliea8rCXMRDle4h0IxhOtSs1G92//mxCM9B
         2OPmZPRXTECmus7GeC/Ex7yG5C37HLiiqduyA912GjvNBkTKeSYd9IeacpvoV9bWUBXg
         hqoSQC+O6/lAf/Uj3btRPC7EDuFdL48Oc2ES7CkCpd1v4uKF7v6HFveMfzTde9JAcy0g
         05qw==
X-Gm-Message-State: ALoCoQnwuDbgKO7R6mz5KNFlmBmWReAdml/Pf5AaoKA70zNnbernfKApzZXQkgxFmxVdbjd+SVAJ
X-Received: by 10.107.17.230 with SMTP id 99mr5378561ior.78.1414618662202;
 Wed, 29 Oct 2014 14:37:42 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.136.221 with HTTP; Wed, 29 Oct 2014 14:37:21 -0700 (PDT)
In-Reply-To: <54511DAF.7000007@informatik.uni-hamburg.de>
References: <544FCFD3.9020606@informatik.uni-hamburg.de> <CAMAsSdLbDLE_Lo3pAGOC05FSPjhRC8wN_3BqqbqzUFaarxdmgg@mail.gmail.com>
 <54511DAF.7000007@informatik.uni-hamburg.de>
From: Sean Owen <sowen@cloudera.com>
Date: Wed, 29 Oct 2014 22:37:21 +0100
Message-ID: <CAMAsSdKRMLGxTEnzuBD-f+AV9TpcuqznQP+5vu46GwpKLSZFRQ@mail.gmail.com>
Subject: Re: How to run tests properly?
To: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
Cc: dev@spark.apache.org
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

On Wed, Oct 29, 2014 at 6:02 PM, Niklas Wilcke
<1wilcke@informatik.uni-hamburg.de> wrote:
> The core tests seems to fail because of my german locale. Some tests are
> locale dependend like the
> UtilsSuite.scala
>  - "string formatting of time durations" - checks for locale dependend
> seperators like "." and ","
>  - "isBindCollision" - checks for the locale dependend exception message

Could be! If you can fix them with a few uses of Locale in the code,
that's definitely worth filing a JIRA and opening a PR.

> LocalClusterSparkContext.scala.
> When I change the line
> .setMaster("local-cluster[2, 1, 512]")
> to
> .setMaster("local")
> all tests run without a failure. The local-cluster mode seems to be the
> reason for the failure. I tried some different configurations like
> [1,1,512], [2,1,1024] etc. but couldn't get the tests run without a failure.

Not sure, what do you mean that it fails?

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10041-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 03:28:45 2014
Return-Path: <dev-return-10041-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 8A82717D4D
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 03:28:45 +0000 (UTC)
Received: (qmail 74372 invoked by uid 500); 30 Oct 2014 03:28:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74293 invoked by uid 500); 30 Oct 2014 03:28:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74281 invoked by uid 99); 30 Oct 2014 03:28:43 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 03:28:43 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 03:28:38 +0000
Received: by mail-la0-f51.google.com with SMTP id q1so3668723lam.38
        for <dev@spark.apache.org>; Wed, 29 Oct 2014 20:28:17 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=68d09c25qd/dWWSnMkmkUhXI10FSNkMRWIjFYnWHXiA=;
        b=AK4uKiDB7FvntyQpE8SqegQaD5ns8fsnXQ4TC8vR9erCSNEuBu3jhWH/ipmaBXAbSX
         YPG2elk/Uvg0RVhXgjlfNRdzGEBAzqK7MVg11Ef/+uqs1q7DOskExFqfqwIMB/yem8Uz
         6f0jblNHz6oDPW5oZ3tsUDzdLbQuNXjnaem7mStZub3YD+VyUeUfQkp+r3h+Vkl8t7Fo
         k4i/St5GeKymaz2XdpSxSeTw5kR1e9KnxyRpTyu7qslQ4GBo0dOnSR6Y6O9yvjSxzKYh
         j29TzmoBF6MVYZdFAVM39rfgWx4iGE4grJzvbHgjMLFsuz92O90+cD1G8KJtXjZlQPzl
         uiCA==
MIME-Version: 1.0
X-Received: by 10.112.150.68 with SMTP id ug4mr15671800lbb.82.1414639696918;
 Wed, 29 Oct 2014 20:28:16 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Wed, 29 Oct 2014 20:28:16 -0700 (PDT)
In-Reply-To: <CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
	<CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
Date: Wed, 29 Oct 2014 20:28:16 -0700
Message-ID: <CA+B-+fyRP1SVyz=Ouu-kMQEN54c14G4s3dCPh+E8kNH0zUf1pg@mail.gmail.com>
Subject: Re: matrix factorization cross validation
From: Debasish Das <debasish.das83@gmail.com>
To: Xiangrui Meng <mengxr@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b342d489ec18605069b7895
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b342d489ec18605069b7895
Content-Type: text/plain; charset=UTF-8

Is there an example of how to use RankingMetrics ?

Let's take the user, document example...we get user x topic and document x
topic matrices as the model...

Now for each user, we can generate topK document by doing a sort on (1 x
topic)dot(topic x document) and picking topK...

Is it possible to validate such a topK finding algorithm using
RankingMetrics ?


On Wed, Oct 29, 2014 at 12:14 PM, Xiangrui Meng <mengxr@gmail.com> wrote:

> Let's narrow the context from matrix factorization to recommendation
> via ALS. It adds extra complexity if we treat it as a multi-class
> classification problem. ALS only outputs a single value for each
> prediction, which is hard to convert to probability distribution over
> the 5 rating levels. Treating it as a binary classification problem or
> a ranking problem does make sense. The RankingMetricc is in master.
> Free free to add prec@k and ndcg@k to examples.MovielensALS. ROC
> should be good to add as well. -Xiangrui
>
>
> On Wed, Oct 29, 2014 at 11:23 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > Hi,
> >
> > In the current factorization flow, we cross validate on the test dataset
> > using the RMSE number but there are some other measures which are worth
> > looking into.
> >
> > If we consider the problem as a regression problem and the ratings 1-5
> are
> > considered as 5 classes, it is possible to generate a confusion matrix
> > using MultiClassMetrics.scala
> >
> > If the ratings are only 0/1 (like from the spotify demo from spark
> summit)
> > then it is possible to use Binary Classification Metrices to come up with
> > the ROC curve...
> >
> > For topK user/products we should also look into prec@k and pdcg@k as the
> > metric..
> >
> > Does it make sense to add the multiclass metric and prec@k, pdcg@k in
> > examples.MovielensALS along with RMSE ?
> >
> > Thanks.
> > Deb
>

--047d7b342d489ec18605069b7895--

From dev-return-10042-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 08:13:45 2014
Return-Path: <dev-return-10042-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B10B417618
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 08:13:45 +0000 (UTC)
Received: (qmail 57473 invoked by uid 500); 30 Oct 2014 08:13:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 57406 invoked by uid 500); 30 Oct 2014 08:13:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 57390 invoked by uid 99); 30 Oct 2014 08:13:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 08:13:44 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nick.pentreath@gmail.com designates 209.85.214.173 as permitted sender)
Received: from [209.85.214.173] (HELO mail-ob0-f173.google.com) (209.85.214.173)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 08:13:39 +0000
Received: by mail-ob0-f173.google.com with SMTP id wn1so3745091obc.18
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 01:12:34 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=u7s1fYr3oVihzAPWxaQLWZR0Y5BMAKVvhvOLHLIwJsU=;
        b=Jlk7KaHlF5RMFouaEB4VC84rHT41MoOdEvb1T1dZcMGbz4HhUp6yuuG7oWen9+oZ8h
         71YquyAMVYLj9zzaiwlR3WMNIegfwKUg8DI6jBdAlZI01RT6dKsPuwiaiFB9ML5C3N9D
         0GELJf/7lilhgfRNFle7lpq8DSSiI/BheuJUechD5hcyOh4YDw2I2gwLihFOK3EIQW1L
         kdprw+D5jmaPurdETHFyR1c+jn8XI/C/E45NSzP3NRo3hCrLsV4dBTiEdgVi5C/XJIjW
         8cRwSRZGL+CgANpgWw9WkIC/LW2fDkHtlyZLPh4FvXRzbPQPfp94ZCFrMLWMpd3j1NBI
         I/rA==
MIME-Version: 1.0
X-Received: by 10.60.94.235 with SMTP id df11mr13435007oeb.20.1414656754023;
 Thu, 30 Oct 2014 01:12:34 -0700 (PDT)
Received: by 10.182.107.196 with HTTP; Thu, 30 Oct 2014 01:12:33 -0700 (PDT)
In-Reply-To: <CA+B-+fyRP1SVyz=Ouu-kMQEN54c14G4s3dCPh+E8kNH0zUf1pg@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
	<CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
	<CA+B-+fyRP1SVyz=Ouu-kMQEN54c14G4s3dCPh+E8kNH0zUf1pg@mail.gmail.com>
Date: Thu, 30 Oct 2014 10:12:33 +0200
Message-ID: <CALD+6GO-6b5yX_MYBuYLOhXtLx1vQgT3Zem4R5gYsnENQyubsQ@mail.gmail.com>
Subject: Re: matrix factorization cross validation
From: Nick Pentreath <nick.pentreath@gmail.com>
To: Debasish Das <debasish.das83@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01183fdc4d828905069f713f
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01183fdc4d828905069f713f
Content-Type: text/plain; charset=UTF-8

Looking at
https://github.com/apache/spark/blob/814a9cd7fabebf2a06f7e2e5d46b6a2b28b917c2/mllib/src/main/scala/org/apache/spark/mllib/evaluation/RankingMetrics.scala#L82

For each user in test set, you generate an Array of top K predicted item
ids (Int or String probably), and an Array of ground truth item ids (the
known rated or liked items in the test set for that user), and pass that to
precisionAt(k) to compute MAP@k (Actually this method name is a bit
misleading - it should be meanAveragePrecisionAt where the other method
there is without a cutoff at k. However, both compute MAP).

The challenge at scale is actually computing all the top Ks for each user,
as it requires broadcasting all the item factors (unless there is a smarter
way?)

I wonder if it is possible to extend the DIMSUM idea to computing top K
matrix multiply between the user and item factor matrices, as opposed to
all-pairs similarity of one matrix?

On Thu, Oct 30, 2014 at 5:28 AM, Debasish Das <debasish.das83@gmail.com>
wrote:

> Is there an example of how to use RankingMetrics ?
>
> Let's take the user, document example...we get user x topic and document x
> topic matrices as the model...
>
> Now for each user, we can generate topK document by doing a sort on (1 x
> topic)dot(topic x document) and picking topK...
>
> Is it possible to validate such a topK finding algorithm using
> RankingMetrics ?
>
>
> On Wed, Oct 29, 2014 at 12:14 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
>
> > Let's narrow the context from matrix factorization to recommendation
> > via ALS. It adds extra complexity if we treat it as a multi-class
> > classification problem. ALS only outputs a single value for each
> > prediction, which is hard to convert to probability distribution over
> > the 5 rating levels. Treating it as a binary classification problem or
> > a ranking problem does make sense. The RankingMetricc is in master.
> > Free free to add prec@k and ndcg@k to examples.MovielensALS. ROC
> > should be good to add as well. -Xiangrui
> >
> >
> > On Wed, Oct 29, 2014 at 11:23 AM, Debasish Das <debasish.das83@gmail.com
> >
> > wrote:
> > > Hi,
> > >
> > > In the current factorization flow, we cross validate on the test
> dataset
> > > using the RMSE number but there are some other measures which are worth
> > > looking into.
> > >
> > > If we consider the problem as a regression problem and the ratings 1-5
> > are
> > > considered as 5 classes, it is possible to generate a confusion matrix
> > > using MultiClassMetrics.scala
> > >
> > > If the ratings are only 0/1 (like from the spotify demo from spark
> > summit)
> > > then it is possible to use Binary Classification Metrices to come up
> with
> > > the ROC curve...
> > >
> > > For topK user/products we should also look into prec@k and pdcg@k as
> the
> > > metric..
> > >
> > > Does it make sense to add the multiclass metric and prec@k, pdcg@k in
> > > examples.MovielensALS along with RMSE ?
> > >
> > > Thanks.
> > > Deb
> >
>

--089e01183fdc4d828905069f713f--

From dev-return-10043-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 10:42:21 2014
Return-Path: <dev-return-10043-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id E1C6417A59
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 10:42:21 +0000 (UTC)
Received: (qmail 55308 invoked by uid 500); 30 Oct 2014 10:42:21 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 55237 invoked by uid 500); 30 Oct 2014 10:42:21 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 55219 invoked by uid 99); 30 Oct 2014 10:42:20 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 10:42:20 +0000
X-ASF-Spam-Status: No, hits=0.6 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nm3mon@gmail.com designates 209.85.216.50 as permitted sender)
Received: from [209.85.216.50] (HELO mail-qa0-f50.google.com) (209.85.216.50)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 10:42:16 +0000
Received: by mail-qa0-f50.google.com with SMTP id bm13so1731708qab.37
        for <dev@spark.incubator.apache.org>; Thu, 30 Oct 2014 03:41:55 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=references:mime-version:in-reply-to:content-type
         :content-transfer-encoding:message-id:cc:from:subject:date:to;
        bh=pVBuGOWAJj9H5GOJ9Y/LFYbDNpQH+rmCDtGDp9TqeuI=;
        b=DtznUbAkZ5JlZV1ZCiB3NvmB5wdtuxCcNwqV5cDkhp02ONs+7pGfT+nr45vqaa6V0j
         6TmWYMylV2mRbIi6Ks0rX7pdOGDQ4gcU0x2fkh9YsIw5QuhlzGZWwZxZLuoSj7GhpdAL
         8ZVVAbd0EFeVfeL5gc8WT2VioKQSHJLmN2SbYaJzI7YD6VLe5lRIP5ylmiK/vHom23Tu
         N4ZY7hLXmAugSfmdn4K9g1tQoGFnQRjRf9OAUpgNqGml9jrxxBjHJOw4kppCe7t3tieR
         LEJaW6iVdQXTmUr+qIlANOfQczSTkQeYnOtGEp2rylrQYNvBX9nYTrbtN0S2qJxqmNUq
         li+A==
X-Received: by 10.140.31.139 with SMTP id f11mr23361165qgf.30.1414665715666;
        Thu, 30 Oct 2014 03:41:55 -0700 (PDT)
Received: from ?IPv6:2601:6:2500:83:296d:7f99:5dc8:97e8? ([2601:6:2500:83:296d:7f99:5dc8:97e8])
        by mx.google.com with ESMTPSA id e8sm6405066qai.33.2014.10.30.03.41.54
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 30 Oct 2014 03:41:55 -0700 (PDT)
References: <1414336040472-8965.post@n3.nabble.com> <663587489.1004025.1414444445996.JavaMail.zimbra@redhat.com> <CAN3RKnPrhoLBiCfwbD5N1GVMxuMjSjO_VzFg6NLmbmNawmy+zw@mail.gmail.com> <CAA_qdLrckQBCwPJNJtiO4kzQgkDURA0HY1+HjWNK1RebOCG1AQ@mail.gmail.com>
Mime-Version: 1.0 (1.0)
In-Reply-To: <CAA_qdLrckQBCwPJNJtiO4kzQgkDURA0HY1+HjWNK1RebOCG1AQ@mail.gmail.com>
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: quoted-printable
Message-Id: <00B9E00F-CC9F-4BB8-AC83-2780F0A670E6@gmail.com>
Cc: Duy Huynh <duy.huynh.uiv@gmail.com>, Will Benton <willb@redhat.com>,
 "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
X-Mailer: iPhone Mail (12B411)
From: nm3mon@gmail.com
Subject: Re: best IDE for scala + spark development?
Date: Thu, 30 Oct 2014 06:41:55 -0400
To: Cheng Lian <lian.cs.zju@gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org

IntelliJ idea scala plugin comes with an enhanced REPL. It's a pretty decent=
 option too.=20

Nabeel

> On Oct 28, 2014, at 5:34 AM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
>=20
> My two cents for Mac Vim/Emacs users. Fixed a Scala ctags Mac compatibilit=
y
> bug months ago, and you may want to use the most recent version here
> https://github.com/scala/scala-dist/blob/master/tool-support/src/emacs/con=
trib/dot-ctags
>=20
>=20
>=20
>> On Tue, Oct 28, 2014 at 4:26 PM, Duy Huynh <duy.huynh.uiv@gmail.com> wrot=
e:
>>=20
>> thanks everyone.  i've been using vim and sbt recently, and i really like=

>> it.  it's lightweight, fast.  plus, ack, ctrl-t, nerdtre, etc. in vim do
>> all the good work.
>>=20
>> but, as i'm not familiar with scala/spark api yet, i really wish to have
>> these two things in vim + sbt.
>>=20
>> 1.  code completion as in intellij (typing long method / class name in
>> scala/spark isn't that fun!)
>>=20
>> 2.  scala doc on the fly in the text editor (just so i don't have to swit=
ch
>> back and forth between the text editor and the scala doc)
>>=20
>> did anyone have experience with adding these 2 things to vim?
>>=20
>> thanks!
>>=20
>>=20
>>=20
>>=20
>>=20
>>=20
>>> On Mon, Oct 27, 2014 at 5:14 PM, Will Benton <willb@redhat.com> wrote:
>>>=20
>>> I'll chime in as yet another user who is extremely happy with sbt and a
>>> text editor.  (In my experience, running "ack" from the command line is
>>> usually just as easy and fast as using an IDE's find-in-project
>> facility.)
>>> You can, of course, extend editors with Scala-specific IDE-like
>>> functionality (in particular, I am aware of -- but have not used --
>> ENSIME
>>> for emacs or TextMate).
>>>=20
>>> Since you're new to Scala, you may not know that you can run any sbt
>>> command preceded by a tilde, which will watch files in your project and
>> run
>>> the command when anything changes.  Therefore, running "~compile" from
>> the
>>> sbt repl will get you most of the continuous syntax-checking
>> functionality
>>> you can get from an IDE.
>>>=20
>>> best,
>>> wb
>>>=20
>>> ----- Original Message -----
>>>> From: "ll" <duy.huynh.uiv@gmail.com>
>>>> To: dev@spark.incubator.apache.org
>>>> Sent: Sunday, October 26, 2014 10:07:20 AM
>>>> Subject: best IDE for scala + spark development?
>>>>=20
>>>> i'm new to both scala and spark.  what IDE / dev environment do you
>> find
>>> most
>>>> productive for writing code in scala with spark?  is it just vim + sbt?=

>>> or
>>>> does a full IDE like intellij works out better?  thanks!
>>>>=20
>>>>=20
>>>>=20
>>>> --
>>>> View this message in context:
>> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-sc=
ala-spark-development-tp8965.html
>>>> Sent from the Apache Spark Developers List mailing list archive at
>>>> Nabble.com.
>>>>=20
>>>> ---------------------------------------------------------------------
>>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>>>> For additional commands, e-mail: dev-help@spark.apache.org
>>=20

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10044-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 11:28:08 2014
Return-Path: <dev-return-10044-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 0140017B87
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 11:28:08 +0000 (UTC)
Received: (qmail 46449 invoked by uid 500); 30 Oct 2014 11:28:07 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 46376 invoked by uid 500); 30 Oct 2014 11:28:07 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 46365 invoked by uid 99); 30 Oct 2014 11:28:06 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 11:28:06 +0000
X-ASF-Spam-Status: No, hits=-2.3 required=10.0
	tests=RCVD_IN_DNSWL_MED,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: local policy)
Received: from [134.100.9.70] (HELO mailhost.informatik.uni-hamburg.de) (134.100.9.70)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 11:28:01 +0000
Received: from localhost (localhost [127.0.0.1])
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTP id 2FB6A59D;
	Thu, 30 Oct 2014 12:27:39 +0100 (CET)
X-Virus-Scanned: amavisd-new at informatik.uni-hamburg.de
Received: from mailhost.informatik.uni-hamburg.de ([127.0.0.1])
	by localhost (mailhost.informatik.uni-hamburg.de [127.0.0.1]) (amavisd-new, port 10024)
	with LMTP id jXF05LgaOakq; Thu, 30 Oct 2014 12:27:38 +0100 (CET)
Received: from [192.168.178.117] (x2f089ed.dyn.telefonica.de [2.240.137.237])
	(using TLSv1 with cipher ECDHE-RSA-AES128-SHA (128/128 bits))
	(Client did not present a certificate)
	(Authenticated sender: 1wilcke)
	by mailhost.informatik.uni-hamburg.de (Postfix) with ESMTPSA id 7F4EB59B;
	Thu, 30 Oct 2014 12:27:38 +0100 (CET)
Message-ID: <5452209F.3020208@informatik.uni-hamburg.de>
Date: Thu, 30 Oct 2014 12:27:27 +0100
From: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Icedove/24.8.1
MIME-Version: 1.0
To: Patrick Wendell <pwendell@gmail.com>
CC: "dev@spark.apache.org" <dev@spark.apache.org>
Subject: Re: How to run tests properly?
References: <544FCFD3.9020606@informatik.uni-hamburg.de>	<CAMAsSdLbDLE_Lo3pAGOC05FSPjhRC8wN_3BqqbqzUFaarxdmgg@mail.gmail.com>	<54511DAF.7000007@informatik.uni-hamburg.de> <CABPQxss-GDg55FMzLB6LxshH9G5W8qdLLgcextnEmgc1m=4cWQ@mail.gmail.com>
In-Reply-To: <CABPQxss-GDg55FMzLB6LxshH9G5W8qdLLgcextnEmgc1m=4cWQ@mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Can you please briefly explain why packaging is necessary. I thought
packaging would only build the jar and place it in the target folder.
How does that affect the tests? If tests depend on the assembly a "mvn
install" would be more sensible to me.
Probably I misunderstand the maven build life-cycle.

Thanks,
Niklas

On 29.10.2014 19:01, Patrick Wendell wrote:
> One thing is you need to do a "maven package" before you run tests.
> The "local-cluster" tests depend on Spark already being packaged.
>
> - Patrick
>
> On Wed, Oct 29, 2014 at 10:02 AM, Niklas Wilcke
> <1wilcke@informatik.uni-hamburg.de> wrote:
>> Hi Sean,
>>
>> thanks for your reply. The tests still don't work. I focused on the
>> mllib and core tests and made some observations.
>>
>> The core tests seems to fail because of my german locale. Some tests are
>> locale dependend like the
>> UtilsSuite.scala
>>  - "string formatting of time durations" - checks for locale dependend
>> seperators like "." and ","
>>  - "isBindCollision" - checks for the locale dependend exception message
>>
>> In the MLlib it seems to be just one source of failure. The same
>> Exception I described in my first mail appears several times in
>> different tests.
>> The reason for all the similar failures is the line 29 in
>> LocalClusterSparkContext.scala.
>> When I change the line
>> .setMaster("local-cluster[2, 1, 512]")
>> to
>> .setMaster("local")
>> all tests run without a failure. The local-cluster mode seems to be the
>> reason for the failure. I tried some different configurations like
>> [1,1,512], [2,1,1024] etc. but couldn't get the tests run without a failure.
>>
>> Could this be a configuration issue?
>>
>> On 28.10.2014 19:03, Sean Owen wrote:
>>> On Tue, Oct 28, 2014 at 6:18 PM, Niklas Wilcke
>>> <1wilcke@informatik.uni-hamburg.de> wrote:
>>>> 1. via dev/run-tests script
>>>>     This script executes all tests and take several hours to finish.
>>>> Some tests failed but I can't say which of them. Should this really take
>>>> that long? Can I specify to run only MLlib tests?
>>> Yes, running all tests takes a long long time. It does print which
>>> tests failed, and you can see the errors in the test output.
>>>
>>> Did you read http://spark.apache.org/docs/latest/building-with-maven.html#spark-tests-in-maven
>>> ? This shows how to run just one test suite.
>>>
>>> In any Maven project you can try things like "mvn test -pl [module]"
>>> to run just one module's tests.
>> Yes I tried that as described below at point 2.
>>>> 2. directly via maven
>>>> I did the following described in the docs [0].
>>>>
>>>> export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M
>>>> -XX:ReservedCodeCacheSize=512m"
>>>> mvn -Pyarn -Phadoop-2.3 -DskipTests -Phive clean package
>>>> mvn -Pyarn -Phadoop-2.3 -Phive test
>>>>
>>>> This also doesn't work.
>>>> Why do I have to package spark bevore running the tests?
>>> What doesn't work?
>>> Some tests use the built assembly, which requires packaging.
>> I get the same Exceptions as in every other way.
>>>> 3. via sbt
>>>> I tried the following. I freshly cloned spark and checked out the tag
>>>> v1.1.0-rc4.
>>>>
>>>> sbt/sbt "project mllib" test
>>>>
>>>> and get the following exception in several cluster tests.
>>>>
>>>> [info] - task size should be small in both training and prediction ***
>>>> FAILED ***
>>> This just looks like a flaky test failure; I'd try again.
>>>
>> I don't think so. I tried for several times now in several different ways.
>>
>> Thanks,
>> Niklas
>>
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>


---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10045-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 11:39:18 2014
Return-Path: <dev-return-10045-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B4F4617BAF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 11:39:18 +0000 (UTC)
Received: (qmail 73854 invoked by uid 500); 30 Oct 2014 11:39:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 73788 invoked by uid 500); 30 Oct 2014 11:39:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 73765 invoked by uid 99); 30 Oct 2014 11:39:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 11:39:17 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.213.172 as permitted sender)
Received: from [209.85.213.172] (HELO mail-ig0-f172.google.com) (209.85.213.172)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 11:39:13 +0000
Received: by mail-ig0-f172.google.com with SMTP id a13so3104658igq.17
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 04:36:37 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:date
         :message-id:subject:from:to:cc:content-type;
        bh=HcAH+2ThL5NkmsOCLoMBg8bEf34KfSIuveE907yi6Yw=;
        b=GDKA9rgpLIaUy8nlxxqlcqRyeKNdtjzW3GcYGE+jtnpKjSz32ahoxkvBt09u596V4a
         Z+dq9MG5lWstiGktUu7UHAW0rjx6iR6tJPsc+9oNTi8RUkf+g8FS6P9E9Q0lBQeUACXs
         DRhLqGT7bLIojM3rMknJ1uuEWXMJ9KnCUCFkOy5BWyrOvFgrQ+qGmc7OavS3+Fa5J3IO
         4fENsV6wfewwv8QsIX5TQjTdEWNMXYodnjnVJqnetwFsUGyTFFsdodNozgGdTyIfAPZ6
         Rg92d8cN80aUsApWz7ShhIk8PqKj9qisXTPBSvATWwtgDZ/jS3PQvgYqC0JVog+dxHQp
         7H1g==
X-Gm-Message-State: ALoCoQllRLQEjuw4702wk72OqwVfuimwlVJYoyrzT2dKiQdgyQ9rR2WMFG6x2yFcNFGwoCISacpW
MIME-Version: 1.0
X-Received: by 10.42.15.135 with SMTP id l7mr16418101ica.38.1414668997633;
 Thu, 30 Oct 2014 04:36:37 -0700 (PDT)
Received: by 10.107.136.221 with HTTP; Thu, 30 Oct 2014 04:36:37 -0700 (PDT)
Received: by 10.107.136.221 with HTTP; Thu, 30 Oct 2014 04:36:37 -0700 (PDT)
In-Reply-To: <5452209F.3020208@informatik.uni-hamburg.de>
References: <544FCFD3.9020606@informatik.uni-hamburg.de>
	<CAMAsSdLbDLE_Lo3pAGOC05FSPjhRC8wN_3BqqbqzUFaarxdmgg@mail.gmail.com>
	<54511DAF.7000007@informatik.uni-hamburg.de>
	<CABPQxss-GDg55FMzLB6LxshH9G5W8qdLLgcextnEmgc1m=4cWQ@mail.gmail.com>
	<5452209F.3020208@informatik.uni-hamburg.de>
Date: Thu, 30 Oct 2014 12:36:37 +0100
Message-ID: <CAMAsSdKoD=2ZX8Z6XvsNvdRg7KW0YFgUCucnuH008xPBwjCNoA@mail.gmail.com>
Subject: Re: How to run tests properly?
From: Sean Owen <sowen@cloudera.com>
To: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>
Cc: Patrick Wendell <pwendell@gmail.com>, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=20cf303ea8d81461a90506a24bfe
X-Virus-Checked: Checked by ClamAV on apache.org

--20cf303ea8d81461a90506a24bfe
Content-Type: text/plain; charset=UTF-8

You are right that this is a bit weird compared to the Maven lifecycle
semantics. Maven wants assembly to come after tests but here tests want to
launch the final assembly as part of some tests. Yes you would not normally
have to do this in 2 stages.
On Oct 30, 2014 12:28 PM, "Niklas Wilcke" <1wilcke@informatik.uni-hamburg.de>
wrote:

> Can you please briefly explain why packaging is necessary. I thought
> packaging would only build the jar and place it in the target folder.
> How does that affect the tests? If tests depend on the assembly a "mvn
> install" would be more sensible to me.
> Probably I misunderstand the maven build life-cycle.
>
> Thanks,
> Niklas
>
> On 29.10.2014 19:01, Patrick Wendell wrote:
> > One thing is you need to do a "maven package" before you run tests.
> > The "local-cluster" tests depend on Spark already being packaged.
> >
> > - Patrick
> >
> > On Wed, Oct 29, 2014 at 10:02 AM, Niklas Wilcke
> > <1wilcke@informatik.uni-hamburg.de> wrote:
> >> Hi Sean,
> >>
> >> thanks for your reply. The tests still don't work. I focused on the
> >> mllib and core tests and made some observations.
> >>
> >> The core tests seems to fail because of my german locale. Some tests are
> >> locale dependend like the
> >> UtilsSuite.scala
> >>  - "string formatting of time durations" - checks for locale dependend
> >> seperators like "." and ","
> >>  - "isBindCollision" - checks for the locale dependend exception message
> >>
> >> In the MLlib it seems to be just one source of failure. The same
> >> Exception I described in my first mail appears several times in
> >> different tests.
> >> The reason for all the similar failures is the line 29 in
> >> LocalClusterSparkContext.scala.
> >> When I change the line
> >> .setMaster("local-cluster[2, 1, 512]")
> >> to
> >> .setMaster("local")
> >> all tests run without a failure. The local-cluster mode seems to be the
> >> reason for the failure. I tried some different configurations like
> >> [1,1,512], [2,1,1024] etc. but couldn't get the tests run without a
> failure.
> >>
> >> Could this be a configuration issue?
> >>
> >> On 28.10.2014 19:03, Sean Owen wrote:
> >>> On Tue, Oct 28, 2014 at 6:18 PM, Niklas Wilcke
> >>> <1wilcke@informatik.uni-hamburg.de> wrote:
> >>>> 1. via dev/run-tests script
> >>>>     This script executes all tests and take several hours to finish.
> >>>> Some tests failed but I can't say which of them. Should this really
> take
> >>>> that long? Can I specify to run only MLlib tests?
> >>> Yes, running all tests takes a long long time. It does print which
> >>> tests failed, and you can see the errors in the test output.
> >>>
> >>> Did you read
> http://spark.apache.org/docs/latest/building-with-maven.html#spark-tests-in-maven
> >>> ? This shows how to run just one test suite.
> >>>
> >>> In any Maven project you can try things like "mvn test -pl [module]"
> >>> to run just one module's tests.
> >> Yes I tried that as described below at point 2.
> >>>> 2. directly via maven
> >>>> I did the following described in the docs [0].
> >>>>
> >>>> export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M
> >>>> -XX:ReservedCodeCacheSize=512m"
> >>>> mvn -Pyarn -Phadoop-2.3 -DskipTests -Phive clean package
> >>>> mvn -Pyarn -Phadoop-2.3 -Phive test
> >>>>
> >>>> This also doesn't work.
> >>>> Why do I have to package spark bevore running the tests?
> >>> What doesn't work?
> >>> Some tests use the built assembly, which requires packaging.
> >> I get the same Exceptions as in every other way.
> >>>> 3. via sbt
> >>>> I tried the following. I freshly cloned spark and checked out the tag
> >>>> v1.1.0-rc4.
> >>>>
> >>>> sbt/sbt "project mllib" test
> >>>>
> >>>> and get the following exception in several cluster tests.
> >>>>
> >>>> [info] - task size should be small in both training and prediction ***
> >>>> FAILED ***
> >>> This just looks like a flaky test failure; I'd try again.
> >>>
> >> I don't think so. I tried for several times now in several different
> ways.
> >>
> >> Thanks,
> >> Niklas
> >>
> >>
> >>
> >> ---------------------------------------------------------------------
> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >> For additional commands, e-mail: dev-help@spark.apache.org
> >>
>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--20cf303ea8d81461a90506a24bfe--

From dev-return-10046-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 13:41:45 2014
Return-Path: <dev-return-10046-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 53C2317F14
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 13:41:45 +0000 (UTC)
Received: (qmail 88633 invoked by uid 500); 30 Oct 2014 13:41:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 88555 invoked by uid 500); 30 Oct 2014 13:41:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 88543 invoked by uid 99); 30 Oct 2014 13:41:44 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 13:41:44 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of javadba@gmail.com designates 209.85.220.180 as permitted sender)
Received: from [209.85.220.180] (HELO mail-vc0-f180.google.com) (209.85.220.180)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 13:41:39 +0000
Received: by mail-vc0-f180.google.com with SMTP id hy10so2753192vcb.11
        for <dev@spark.incubator.apache.org>; Thu, 30 Oct 2014 06:39:49 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=OtdvPX9SSFn5/INYxWujOgdwHgrZbzgAoL3c4cpVi5I=;
        b=xtydtBJOT6IZ4U4GTay6ka/5+owDYkZzI4rkwQFDYWXpmUR9M5kmeCHGKHUoSxEggS
         NSv2z09QO3kgm9VYhj0rdT2m5eeZDiXC2MA9HmNbOXJi/ftrJ1GBcpwfkiMChqCUFFkQ
         LkPt6TRKkEP2spuIx5c7ZL5lQnm6s4Xztnv1IJEahlF3jsPdnuBRSIeqWSMmlgKn5x3o
         Zb7580Cw5nhS2sMssXQHAGNhQt6lKsIAdp2idxRtuyRN1+G9P78tgQv6KJARq+2Y329z
         Y9z44/ryRXuXTUcOmheodVv3XnnTP4VMIoayYwqa/D/n5PvTVd3GDVxhuV9aTP1fE7rn
         hP4A==
MIME-Version: 1.0
X-Received: by 10.52.187.227 with SMTP id fv3mr60300vdc.90.1414676388870; Thu,
 30 Oct 2014 06:39:48 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Thu, 30 Oct 2014 06:39:48 -0700 (PDT)
In-Reply-To: <00B9E00F-CC9F-4BB8-AC83-2780F0A670E6@gmail.com>
References: <1414336040472-8965.post@n3.nabble.com>
	<663587489.1004025.1414444445996.JavaMail.zimbra@redhat.com>
	<CAN3RKnPrhoLBiCfwbD5N1GVMxuMjSjO_VzFg6NLmbmNawmy+zw@mail.gmail.com>
	<CAA_qdLrckQBCwPJNJtiO4kzQgkDURA0HY1+HjWNK1RebOCG1AQ@mail.gmail.com>
	<00B9E00F-CC9F-4BB8-AC83-2780F0A670E6@gmail.com>
Date: Thu, 30 Oct 2014 06:39:48 -0700
Message-ID: <CACkSZy3D=6=1Xyh2yeGeOWXmnjZ1OrBh7UpvDrs+9sXSKErPOw@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
From: Stephen Boesch <javadba@gmail.com>
To: nm3mon@gmail.com
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Duy Huynh <duy.huynh.uiv@gmail.com>, 
	Will Benton <willb@redhat.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=bcaec548a239a181570506a403c7
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec548a239a181570506a403c7
Content-Type: text/plain; charset=UTF-8

HI Nabeel,
  In what ways is the IJ version of scala repl enhanced?  thx!

2014-10-30 3:41 GMT-07:00 <nm3mon@gmail.com>:

> IntelliJ idea scala plugin comes with an enhanced REPL. It's a pretty
> decent option too.
>
> Nabeel
>
> > On Oct 28, 2014, at 5:34 AM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
> >
> > My two cents for Mac Vim/Emacs users. Fixed a Scala ctags Mac
> compatibility
> > bug months ago, and you may want to use the most recent version here
> >
> https://github.com/scala/scala-dist/blob/master/tool-support/src/emacs/contrib/dot-ctags
> >
> >
> >
> >> On Tue, Oct 28, 2014 at 4:26 PM, Duy Huynh <duy.huynh.uiv@gmail.com>
> wrote:
> >>
> >> thanks everyone.  i've been using vim and sbt recently, and i really
> like
> >> it.  it's lightweight, fast.  plus, ack, ctrl-t, nerdtre, etc. in vim do
> >> all the good work.
> >>
> >> but, as i'm not familiar with scala/spark api yet, i really wish to have
> >> these two things in vim + sbt.
> >>
> >> 1.  code completion as in intellij (typing long method / class name in
> >> scala/spark isn't that fun!)
> >>
> >> 2.  scala doc on the fly in the text editor (just so i don't have to
> switch
> >> back and forth between the text editor and the scala doc)
> >>
> >> did anyone have experience with adding these 2 things to vim?
> >>
> >> thanks!
> >>
> >>
> >>
> >>
> >>
> >>
> >>> On Mon, Oct 27, 2014 at 5:14 PM, Will Benton <willb@redhat.com> wrote:
> >>>
> >>> I'll chime in as yet another user who is extremely happy with sbt and a
> >>> text editor.  (In my experience, running "ack" from the command line is
> >>> usually just as easy and fast as using an IDE's find-in-project
> >> facility.)
> >>> You can, of course, extend editors with Scala-specific IDE-like
> >>> functionality (in particular, I am aware of -- but have not used --
> >> ENSIME
> >>> for emacs or TextMate).
> >>>
> >>> Since you're new to Scala, you may not know that you can run any sbt
> >>> command preceded by a tilde, which will watch files in your project and
> >> run
> >>> the command when anything changes.  Therefore, running "~compile" from
> >> the
> >>> sbt repl will get you most of the continuous syntax-checking
> >> functionality
> >>> you can get from an IDE.
> >>>
> >>> best,
> >>> wb
> >>>
> >>> ----- Original Message -----
> >>>> From: "ll" <duy.huynh.uiv@gmail.com>
> >>>> To: dev@spark.incubator.apache.org
> >>>> Sent: Sunday, October 26, 2014 10:07:20 AM
> >>>> Subject: best IDE for scala + spark development?
> >>>>
> >>>> i'm new to both scala and spark.  what IDE / dev environment do you
> >> find
> >>> most
> >>>> productive for writing code in scala with spark?  is it just vim +
> sbt?
> >>> or
> >>>> does a full IDE like intellij works out better?  thanks!
> >>>>
> >>>>
> >>>>
> >>>> --
> >>>> View this message in context:
> >>
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> >>>> Sent from the Apache Spark Developers List mailing list archive at
> >>>> Nabble.com.
> >>>>
> >>>> ---------------------------------------------------------------------
> >>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>>> For additional commands, e-mail: dev-help@spark.apache.org
> >>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--bcaec548a239a181570506a403c7--

From dev-return-10047-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 13:42:38 2014
Return-Path: <dev-return-10047-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 42C9E17F1F
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 13:42:38 +0000 (UTC)
Received: (qmail 96323 invoked by uid 500); 30 Oct 2014 13:42:37 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96259 invoked by uid 500); 30 Oct 2014 13:42:37 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96234 invoked by uid 99); 30 Oct 2014 13:42:36 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 13:42:36 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of javadba@gmail.com designates 209.85.220.181 as permitted sender)
Received: from [209.85.220.181] (HELO mail-vc0-f181.google.com) (209.85.220.181)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 13:42:32 +0000
Received: by mail-vc0-f181.google.com with SMTP id hy10so2741823vcb.12
        for <dev@spark.incubator.apache.org>; Thu, 30 Oct 2014 06:40:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=OtdvPX9SSFn5/INYxWujOgdwHgrZbzgAoL3c4cpVi5I=;
        b=xtydtBJOT6IZ4U4GTay6ka/5+owDYkZzI4rkwQFDYWXpmUR9M5kmeCHGKHUoSxEggS
         NSv2z09QO3kgm9VYhj0rdT2m5eeZDiXC2MA9HmNbOXJi/ftrJ1GBcpwfkiMChqCUFFkQ
         LkPt6TRKkEP2spuIx5c7ZL5lQnm6s4Xztnv1IJEahlF3jsPdnuBRSIeqWSMmlgKn5x3o
         Zb7580Cw5nhS2sMssXQHAGNhQt6lKsIAdp2idxRtuyRN1+G9P78tgQv6KJARq+2Y329z
         Y9z44/ryRXuXTUcOmheodVv3XnnTP4VMIoayYwqa/D/n5PvTVd3GDVxhuV9aTP1fE7rn
         hP4A==
MIME-Version: 1.0
X-Received: by 10.52.187.227 with SMTP id fv3mr60300vdc.90.1414676388870; Thu,
 30 Oct 2014 06:39:48 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Thu, 30 Oct 2014 06:39:48 -0700 (PDT)
In-Reply-To: <00B9E00F-CC9F-4BB8-AC83-2780F0A670E6@gmail.com>
References: <1414336040472-8965.post@n3.nabble.com>
	<663587489.1004025.1414444445996.JavaMail.zimbra@redhat.com>
	<CAN3RKnPrhoLBiCfwbD5N1GVMxuMjSjO_VzFg6NLmbmNawmy+zw@mail.gmail.com>
	<CAA_qdLrckQBCwPJNJtiO4kzQgkDURA0HY1+HjWNK1RebOCG1AQ@mail.gmail.com>
	<00B9E00F-CC9F-4BB8-AC83-2780F0A670E6@gmail.com>
Date: Thu, 30 Oct 2014 06:39:48 -0700
Message-ID: <CACkSZy3D=6=1Xyh2yeGeOWXmnjZ1OrBh7UpvDrs+9sXSKErPOw@mail.gmail.com>
Subject: Re: best IDE for scala + spark development?
From: Stephen Boesch <javadba@gmail.com>
To: nm3mon@gmail.com
Cc: Cheng Lian <lian.cs.zju@gmail.com>, Duy Huynh <duy.huynh.uiv@gmail.com>, 
	Will Benton <willb@redhat.com>, 
	"dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
Content-Type: multipart/alternative; boundary=bcaec548a239a181570506a403c7
X-Virus-Checked: Checked by ClamAV on apache.org

--bcaec548a239a181570506a403c7
Content-Type: text/plain; charset=UTF-8

HI Nabeel,
  In what ways is the IJ version of scala repl enhanced?  thx!

2014-10-30 3:41 GMT-07:00 <nm3mon@gmail.com>:

> IntelliJ idea scala plugin comes with an enhanced REPL. It's a pretty
> decent option too.
>
> Nabeel
>
> > On Oct 28, 2014, at 5:34 AM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
> >
> > My two cents for Mac Vim/Emacs users. Fixed a Scala ctags Mac
> compatibility
> > bug months ago, and you may want to use the most recent version here
> >
> https://github.com/scala/scala-dist/blob/master/tool-support/src/emacs/contrib/dot-ctags
> >
> >
> >
> >> On Tue, Oct 28, 2014 at 4:26 PM, Duy Huynh <duy.huynh.uiv@gmail.com>
> wrote:
> >>
> >> thanks everyone.  i've been using vim and sbt recently, and i really
> like
> >> it.  it's lightweight, fast.  plus, ack, ctrl-t, nerdtre, etc. in vim do
> >> all the good work.
> >>
> >> but, as i'm not familiar with scala/spark api yet, i really wish to have
> >> these two things in vim + sbt.
> >>
> >> 1.  code completion as in intellij (typing long method / class name in
> >> scala/spark isn't that fun!)
> >>
> >> 2.  scala doc on the fly in the text editor (just so i don't have to
> switch
> >> back and forth between the text editor and the scala doc)
> >>
> >> did anyone have experience with adding these 2 things to vim?
> >>
> >> thanks!
> >>
> >>
> >>
> >>
> >>
> >>
> >>> On Mon, Oct 27, 2014 at 5:14 PM, Will Benton <willb@redhat.com> wrote:
> >>>
> >>> I'll chime in as yet another user who is extremely happy with sbt and a
> >>> text editor.  (In my experience, running "ack" from the command line is
> >>> usually just as easy and fast as using an IDE's find-in-project
> >> facility.)
> >>> You can, of course, extend editors with Scala-specific IDE-like
> >>> functionality (in particular, I am aware of -- but have not used --
> >> ENSIME
> >>> for emacs or TextMate).
> >>>
> >>> Since you're new to Scala, you may not know that you can run any sbt
> >>> command preceded by a tilde, which will watch files in your project and
> >> run
> >>> the command when anything changes.  Therefore, running "~compile" from
> >> the
> >>> sbt repl will get you most of the continuous syntax-checking
> >> functionality
> >>> you can get from an IDE.
> >>>
> >>> best,
> >>> wb
> >>>
> >>> ----- Original Message -----
> >>>> From: "ll" <duy.huynh.uiv@gmail.com>
> >>>> To: dev@spark.incubator.apache.org
> >>>> Sent: Sunday, October 26, 2014 10:07:20 AM
> >>>> Subject: best IDE for scala + spark development?
> >>>>
> >>>> i'm new to both scala and spark.  what IDE / dev environment do you
> >> find
> >>> most
> >>>> productive for writing code in scala with spark?  is it just vim +
> sbt?
> >>> or
> >>>> does a full IDE like intellij works out better?  thanks!
> >>>>
> >>>>
> >>>>
> >>>> --
> >>>> View this message in context:
> >>
> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for-scala-spark-development-tp8965.html
> >>>> Sent from the Apache Spark Developers List mailing list archive at
> >>>> Nabble.com.
> >>>>
> >>>> ---------------------------------------------------------------------
> >>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> >>>> For additional commands, e-mail: dev-help@spark.apache.org
> >>
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
> For additional commands, e-mail: dev-help@spark.apache.org
>
>

--bcaec548a239a181570506a403c7--

From dev-return-10048-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 15:14:49 2014
Return-Path: <dev-return-10048-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 198BF17512
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 15:14:49 +0000 (UTC)
Received: (qmail 31803 invoked by uid 500); 30 Oct 2014 15:14:48 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31730 invoked by uid 500); 30 Oct 2014 15:14:48 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31709 invoked by uid 99); 30 Oct 2014 15:14:47 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 15:14:47 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of debasish.das83@gmail.com designates 209.85.217.182 as permitted sender)
Received: from [209.85.217.182] (HELO mail-lb0-f182.google.com) (209.85.217.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 15:14:21 +0000
Received: by mail-lb0-f182.google.com with SMTP id f15so4984616lbj.27
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 08:13:10 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=eSB/wJrtDt6mv5tvCElU9z3BdDogiQUu2vuWLIqErRQ=;
        b=CJNlYDmiJKHnDHTAGphHsIzTaD7WsRVI6WZkQ/cdT4VvSQgBk3ggNPNujJ0TrjZtXQ
         WnVBlXpN/3FKsld53A9ua7PmFUrmDPaz9itoGTJ073bD8IxZqECNhla5/Ng/8xc527Vw
         h4i+hNczPjOwyDnqIIFJ+DT05KKQgPgBTL3MXvw+6TAsBoxkBzIN3gPAgefNfOdKM7Lb
         b5L8XR/CWJDODAn8Jf09HrujDGIv6jFnBbmsNWKJ+WlqaqH7Sbh5+R41xIvyR8c/W+IH
         IXGpeobijTDYBX8f/m6rjttIhPnMmJFh3G2uo82VzFwXzFhSD/2BTvrs/C7jvccDq8Nk
         sJcg==
MIME-Version: 1.0
X-Received: by 10.112.157.194 with SMTP id wo2mr19562481lbb.55.1414681990417;
 Thu, 30 Oct 2014 08:13:10 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Thu, 30 Oct 2014 08:13:10 -0700 (PDT)
In-Reply-To: <CALD+6GO-6b5yX_MYBuYLOhXtLx1vQgT3Zem4R5gYsnENQyubsQ@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
	<CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
	<CA+B-+fyRP1SVyz=Ouu-kMQEN54c14G4s3dCPh+E8kNH0zUf1pg@mail.gmail.com>
	<CALD+6GO-6b5yX_MYBuYLOhXtLx1vQgT3Zem4R5gYsnENQyubsQ@mail.gmail.com>
Date: Thu, 30 Oct 2014 08:13:10 -0700
Message-ID: <CA+B-+fweAvG3ws0E5L63xExFOeiaGGEjBsHa_iOzJYTyEJz9aA@mail.gmail.com>
Subject: Re: matrix factorization cross validation
From: Debasish Das <debasish.das83@gmail.com>
To: Nick Pentreath <nick.pentreath@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c33f5e82538c0506a551d3
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c33f5e82538c0506a551d3
Content-Type: text/plain; charset=UTF-8

I thought topK will save us...for each user we have 1xrank...now our movie
factor is a RDD...we pick topK movie factors based on vector norm...with K
= 50, we will have 50 vectors * num_executors in a RDD...with the user
1xrank we do a distributed dot product using RowMatrix APIs...

May be we can't find topK using vector norm on movie factors...

On Thu, Oct 30, 2014 at 1:12 AM, Nick Pentreath <nick.pentreath@gmail.com>
wrote:

> Looking at
> https://github.com/apache/spark/blob/814a9cd7fabebf2a06f7e2e5d46b6a2b28b917c2/mllib/src/main/scala/org/apache/spark/mllib/evaluation/RankingMetrics.scala#L82
>
> For each user in test set, you generate an Array of top K predicted item
> ids (Int or String probably), and an Array of ground truth item ids (the
> known rated or liked items in the test set for that user), and pass that to
> precisionAt(k) to compute MAP@k (Actually this method name is a bit
> misleading - it should be meanAveragePrecisionAt where the other method
> there is without a cutoff at k. However, both compute MAP).
>
> The challenge at scale is actually computing all the top Ks for each user,
> as it requires broadcasting all the item factors (unless there is a smarter
> way?)
>
> I wonder if it is possible to extend the DIMSUM idea to computing top K
> matrix multiply between the user and item factor matrices, as opposed to
> all-pairs similarity of one matrix?
>
> On Thu, Oct 30, 2014 at 5:28 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
>
>> Is there an example of how to use RankingMetrics ?
>>
>> Let's take the user, document example...we get user x topic and document x
>> topic matrices as the model...
>>
>> Now for each user, we can generate topK document by doing a sort on (1 x
>> topic)dot(topic x document) and picking topK...
>>
>> Is it possible to validate such a topK finding algorithm using
>> RankingMetrics ?
>>
>>
>> On Wed, Oct 29, 2014 at 12:14 PM, Xiangrui Meng <mengxr@gmail.com> wrote:
>>
>> > Let's narrow the context from matrix factorization to recommendation
>> > via ALS. It adds extra complexity if we treat it as a multi-class
>> > classification problem. ALS only outputs a single value for each
>> > prediction, which is hard to convert to probability distribution over
>> > the 5 rating levels. Treating it as a binary classification problem or
>> > a ranking problem does make sense. The RankingMetricc is in master.
>> > Free free to add prec@k and ndcg@k to examples.MovielensALS. ROC
>> > should be good to add as well. -Xiangrui
>> >
>> >
>> > On Wed, Oct 29, 2014 at 11:23 AM, Debasish Das <
>> debasish.das83@gmail.com>
>> > wrote:
>> > > Hi,
>> > >
>> > > In the current factorization flow, we cross validate on the test
>> dataset
>> > > using the RMSE number but there are some other measures which are
>> worth
>> > > looking into.
>> > >
>> > > If we consider the problem as a regression problem and the ratings 1-5
>> > are
>> > > considered as 5 classes, it is possible to generate a confusion matrix
>> > > using MultiClassMetrics.scala
>> > >
>> > > If the ratings are only 0/1 (like from the spotify demo from spark
>> > summit)
>> > > then it is possible to use Binary Classification Metrices to come up
>> with
>> > > the ROC curve...
>> > >
>> > > For topK user/products we should also look into prec@k and pdcg@k as
>> the
>> > > metric..
>> > >
>> > > Does it make sense to add the multiclass metric and prec@k, pdcg@k in
>> > > examples.MovielensALS along with RMSE ?
>> > >
>> > > Thanks.
>> > > Deb
>> >
>>
>
>

--001a11c33f5e82538c0506a551d3--

From dev-return-10049-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 18:31:10 2014
Return-Path: <dev-return-10049-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3FF5B17E64
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 18:31:10 +0000 (UTC)
Received: (qmail 19534 invoked by uid 500); 30 Oct 2014 18:31:09 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 19458 invoked by uid 500); 30 Oct 2014 18:31:09 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 19441 invoked by uid 99); 30 Oct 2014 18:31:08 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 18:31:08 +0000
X-ASF-Spam-Status: No, hits=2.8 required=10.0
	tests=HTML_MESSAGE,MIME_QP_LONG_LINE,RCVD_IN_DNSWL_LOW,SPF_PASS,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nm3mon@gmail.com designates 209.85.216.43 as permitted sender)
Received: from [209.85.216.43] (HELO mail-qa0-f43.google.com) (209.85.216.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 18:30:42 +0000
Received: by mail-qa0-f43.google.com with SMTP id j7so4235919qaq.30
        for <dev@spark.incubator.apache.org>; Thu, 30 Oct 2014 11:30:41 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=references:mime-version:in-reply-to:content-type
         :content-transfer-encoding:message-id:cc:from:subject:date:to;
        bh=BhdT5+EYs5Fsh/NII7ZOIxFfE36ZnswaSpnzGftkZ68=;
        b=xc3YDFuU0lalYn7yxK7vm4eQef9CD8t4FuI2/Hx6s7uTxpNrP/Hc5hnV3r4YvWyyjV
         +TAGOboZfoA6emOpakMKE3dsCDtY6iQ6AdKXrEsP9JDiwu57po7nL4I8P3sxpQvAslF3
         g2yaP5akpwcCvrNkZZe45yQQYQk1U1nVyMcreFP0fdYKF95uiqkZRStIdDStlF9g5xs4
         fr63dFE3YzfPKUOaf333RDpjx06Sbo/FdBBj89FyxigyMWpdWnrNNHkQSAmC5I2tv2HW
         VfZLsPLl7w9qroZJp5uHbV4PwZ3aTtbFot98q+sKbQ0/cvxWCH9N5XzlZ291UVUWKNMW
         y91Q==
X-Received: by 10.229.252.196 with SMTP id mx4mr29165650qcb.4.1414693841410;
        Thu, 30 Oct 2014 11:30:41 -0700 (PDT)
Received: from ?IPv6:2601:6:2500:83:61f9:f362:6565:d237? ([2601:6:2500:83:61f9:f362:6565:d237])
        by mx.google.com with ESMTPSA id m36sm7343681qgd.28.2014.10.30.11.30.40
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 30 Oct 2014 11:30:40 -0700 (PDT)
References: <1414336040472-8965.post@n3.nabble.com> <663587489.1004025.1414444445996.JavaMail.zimbra@redhat.com> <CAN3RKnPrhoLBiCfwbD5N1GVMxuMjSjO_VzFg6NLmbmNawmy+zw@mail.gmail.com> <CAA_qdLrckQBCwPJNJtiO4kzQgkDURA0HY1+HjWNK1RebOCG1AQ@mail.gmail.com> <00B9E00F-CC9F-4BB8-AC83-2780F0A670E6@gmail.com> <CACkSZy3D=6=1Xyh2yeGeOWXmnjZ1OrBh7UpvDrs+9sXSKErPOw@mail.gmail.com>
Mime-Version: 1.0 (1.0)
In-Reply-To: <CACkSZy3D=6=1Xyh2yeGeOWXmnjZ1OrBh7UpvDrs+9sXSKErPOw@mail.gmail.com>
Content-Type: multipart/alternative;
	boundary=Apple-Mail-2F8D85D4-9E71-402C-92A5-B95CDC9A0B0E
Content-Transfer-Encoding: 7bit
Message-Id: <1A63C968-24DE-4823-BF68-6B21C99D6A11@gmail.com>
Cc: Cheng Lian <lian.cs.zju@gmail.com>,
 Duy Huynh <duy.huynh.uiv@gmail.com>, Will Benton <willb@redhat.com>,
 "dev@spark.incubator.apache.org" <dev@spark.incubator.apache.org>
X-Mailer: iPhone Mail (12B411)
From: nm3mon@gmail.com
Subject: Re: best IDE for scala + spark development?
Date: Thu, 30 Oct 2014 14:30:41 -0400
To: Stephen Boesch <javadba@gmail.com>
X-Virus-Checked: Checked by ClamAV on apache.org

--Apple-Mail-2F8D85D4-9E71-402C-92A5-B95CDC9A0B0E
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: quoted-printable

Multiline support (much shinier than :paste), smart completion and things th=
at an IDE makes easy or better (without any hassle). In particular, fast swi=
tching between REPL and editor while staying in the same screen makes me eve=
n more productive.=20

Nabeel

> On Oct 30, 2014, at 9:39 AM, Stephen Boesch <javadba@gmail.com> wrote:
>=20
> HI Nabeel,
>   In what ways is the IJ version of scala repl enhanced?  thx!
>=20
> 2014-10-30 3:41 GMT-07:00 <nm3mon@gmail.com>:
>> IntelliJ idea scala plugin comes with an enhanced REPL. It's a pretty dec=
ent option too.
>>=20
>> Nabeel
>>=20
>> > On Oct 28, 2014, at 5:34 AM, Cheng Lian <lian.cs.zju@gmail.com> wrote:
>> >
>> > My two cents for Mac Vim/Emacs users. Fixed a Scala ctags Mac compatibi=
lity
>> > bug months ago, and you may want to use the most recent version here
>> > https://github.com/scala/scala-dist/blob/master/tool-support/src/emacs/=
contrib/dot-ctags
>> >
>> >
>> >
>> >> On Tue, Oct 28, 2014 at 4:26 PM, Duy Huynh <duy.huynh.uiv@gmail.com> w=
rote:
>> >>
>> >> thanks everyone.  i've been using vim and sbt recently, and i really l=
ike
>> >> it.  it's lightweight, fast.  plus, ack, ctrl-t, nerdtre, etc. in vim d=
o
>> >> all the good work.
>> >>
>> >> but, as i'm not familiar with scala/spark api yet, i really wish to ha=
ve
>> >> these two things in vim + sbt.
>> >>
>> >> 1.  code completion as in intellij (typing long method / class name in=

>> >> scala/spark isn't that fun!)
>> >>
>> >> 2.  scala doc on the fly in the text editor (just so i don't have to s=
witch
>> >> back and forth between the text editor and the scala doc)
>> >>
>> >> did anyone have experience with adding these 2 things to vim?
>> >>
>> >> thanks!
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>> On Mon, Oct 27, 2014 at 5:14 PM, Will Benton <willb@redhat.com> wrote=
:
>> >>>
>> >>> I'll chime in as yet another user who is extremely happy with sbt and=
 a
>> >>> text editor.  (In my experience, running "ack" from the command line i=
s
>> >>> usually just as easy and fast as using an IDE's find-in-project
>> >> facility.)
>> >>> You can, of course, extend editors with Scala-specific IDE-like
>> >>> functionality (in particular, I am aware of -- but have not used --
>> >> ENSIME
>> >>> for emacs or TextMate).
>> >>>
>> >>> Since you're new to Scala, you may not know that you can run any sbt
>> >>> command preceded by a tilde, which will watch files in your project a=
nd
>> >> run
>> >>> the command when anything changes.  Therefore, running "~compile" fro=
m
>> >> the
>> >>> sbt repl will get you most of the continuous syntax-checking
>> >> functionality
>> >>> you can get from an IDE.
>> >>>
>> >>> best,
>> >>> wb
>> >>>
>> >>> ----- Original Message -----
>> >>>> From: "ll" <duy.huynh.uiv@gmail.com>
>> >>>> To: dev@spark.incubator.apache.org
>> >>>> Sent: Sunday, October 26, 2014 10:07:20 AM
>> >>>> Subject: best IDE for scala + spark development?
>> >>>>
>> >>>> i'm new to both scala and spark.  what IDE / dev environment do you
>> >> find
>> >>> most
>> >>>> productive for writing code in scala with spark?  is it just vim + s=
bt?
>> >>> or
>> >>>> does a full IDE like intellij works out better?  thanks!
>> >>>>
>> >>>>
>> >>>>
>> >>>> --
>> >>>> View this message in context:
>> >> http://apache-spark-developers-list.1001551.n3.nabble.com/best-IDE-for=
-scala-spark-development-tp8965.html
>> >>>> Sent from the Apache Spark Developers List mailing list archive at
>> >>>> Nabble.com.
>> >>>>
>> >>>> --------------------------------------------------------------------=
-
>> >>>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >>>> For additional commands, e-mail: dev-help@spark.apache.org
>> >>
>>=20
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>=20

--Apple-Mail-2F8D85D4-9E71-402C-92A5-B95CDC9A0B0E--

From dev-return-10050-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 18:36:01 2014
Return-Path: <dev-return-10050-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 2AC1F17ED1
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 18:36:01 +0000 (UTC)
Received: (qmail 40272 invoked by uid 500); 30 Oct 2014 18:36:00 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 40197 invoked by uid 500); 30 Oct 2014 18:36:00 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 40180 invoked by uid 99); 30 Oct 2014 18:35:59 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 18:35:59 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.214.176 as permitted sender)
Received: from [209.85.214.176] (HELO mail-ob0-f176.google.com) (209.85.214.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 18:35:34 +0000
Received: by mail-ob0-f176.google.com with SMTP id va2so4585319obc.7
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 11:35:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=4iizFW2VAXASvsf0v9OA2+SbDPKVEy0/khhUYIxf6+I=;
        b=xQgQdOOF392egLqx2uBD+j+eCZUb7a93jb9SYObWzRQpX1HlgUb4ifSTRQgEgUuvA8
         XnuxYAeaU2Yex7bvVymU9gw/38a4MWLsZ+GjhshJmfff6fPqz5IoPuyQVQJeXGWT8iB+
         9e7PpdQxraJvfewu8b/yZnBSr0naeHAiU7tlQy8iiuJq0Tp9mv7bnJ/pcDXkzDNSi4AT
         qvHb5Ro+8OyomphPE9lxw4WAikjmAU5FZzxLMoZIVldYqENeOqbQV6IUTuL161aVy15m
         KN4BFOBuXN0yfkTcXD1dPu3gzfd2zq6mHYXjpptlFM96Ao/SC6dFu4q0VhaKcSYYtyd7
         prug==
MIME-Version: 1.0
X-Received: by 10.202.3.70 with SMTP id 67mr3157482oid.69.1414694133000; Thu,
 30 Oct 2014 11:35:33 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Thu, 30 Oct 2014 11:35:32 -0700 (PDT)
In-Reply-To: <CAMAsSdKoD=2ZX8Z6XvsNvdRg7KW0YFgUCucnuH008xPBwjCNoA@mail.gmail.com>
References: <544FCFD3.9020606@informatik.uni-hamburg.de>
	<CAMAsSdLbDLE_Lo3pAGOC05FSPjhRC8wN_3BqqbqzUFaarxdmgg@mail.gmail.com>
	<54511DAF.7000007@informatik.uni-hamburg.de>
	<CABPQxss-GDg55FMzLB6LxshH9G5W8qdLLgcextnEmgc1m=4cWQ@mail.gmail.com>
	<5452209F.3020208@informatik.uni-hamburg.de>
	<CAMAsSdKoD=2ZX8Z6XvsNvdRg7KW0YFgUCucnuH008xPBwjCNoA@mail.gmail.com>
Date: Thu, 30 Oct 2014 11:35:32 -0700
Message-ID: <CABPQxsuJK2Pg9FpcP25uygEm3MXzObpxi4=9ajwNPiDLjpedYg@mail.gmail.com>
Subject: Re: How to run tests properly?
From: Patrick Wendell <pwendell@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Niklas Wilcke <1wilcke@informatik.uni-hamburg.de>, 
	"dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Some of our tests actually require spinning up a small multi-process
spark cluster. These use the normal deployment codepath for Spark
which is that we rely on the spark "assembly jar" to be present. That
jar is generated when you run "mvn package" via a special sub project
called assembly in our build. This is a bit non-standard. The reason
is that some of our tests are really mini integration tests.

- Patrick

On Thu, Oct 30, 2014 at 4:36 AM, Sean Owen <sowen@cloudera.com> wrote:
> You are right that this is a bit weird compared to the Maven lifecycle
> semantics. Maven wants assembly to come after tests but here tests want to
> launch the final assembly as part of some tests. Yes you would not normally
> have to do this in 2 stages.
>
> On Oct 30, 2014 12:28 PM, "Niklas Wilcke"
> <1wilcke@informatik.uni-hamburg.de> wrote:
>>
>> Can you please briefly explain why packaging is necessary. I thought
>> packaging would only build the jar and place it in the target folder.
>> How does that affect the tests? If tests depend on the assembly a "mvn
>> install" would be more sensible to me.
>> Probably I misunderstand the maven build life-cycle.
>>
>> Thanks,
>> Niklas
>>
>> On 29.10.2014 19:01, Patrick Wendell wrote:
>> > One thing is you need to do a "maven package" before you run tests.
>> > The "local-cluster" tests depend on Spark already being packaged.
>> >
>> > - Patrick
>> >
>> > On Wed, Oct 29, 2014 at 10:02 AM, Niklas Wilcke
>> > <1wilcke@informatik.uni-hamburg.de> wrote:
>> >> Hi Sean,
>> >>
>> >> thanks for your reply. The tests still don't work. I focused on the
>> >> mllib and core tests and made some observations.
>> >>
>> >> The core tests seems to fail because of my german locale. Some tests
>> >> are
>> >> locale dependend like the
>> >> UtilsSuite.scala
>> >>  - "string formatting of time durations" - checks for locale dependend
>> >> seperators like "." and ","
>> >>  - "isBindCollision" - checks for the locale dependend exception
>> >> message
>> >>
>> >> In the MLlib it seems to be just one source of failure. The same
>> >> Exception I described in my first mail appears several times in
>> >> different tests.
>> >> The reason for all the similar failures is the line 29 in
>> >> LocalClusterSparkContext.scala.
>> >> When I change the line
>> >> .setMaster("local-cluster[2, 1, 512]")
>> >> to
>> >> .setMaster("local")
>> >> all tests run without a failure. The local-cluster mode seems to be the
>> >> reason for the failure. I tried some different configurations like
>> >> [1,1,512], [2,1,1024] etc. but couldn't get the tests run without a
>> >> failure.
>> >>
>> >> Could this be a configuration issue?
>> >>
>> >> On 28.10.2014 19:03, Sean Owen wrote:
>> >>> On Tue, Oct 28, 2014 at 6:18 PM, Niklas Wilcke
>> >>> <1wilcke@informatik.uni-hamburg.de> wrote:
>> >>>> 1. via dev/run-tests script
>> >>>>     This script executes all tests and take several hours to finish.
>> >>>> Some tests failed but I can't say which of them. Should this really
>> >>>> take
>> >>>> that long? Can I specify to run only MLlib tests?
>> >>> Yes, running all tests takes a long long time. It does print which
>> >>> tests failed, and you can see the errors in the test output.
>> >>>
>> >>> Did you read
>> >>> http://spark.apache.org/docs/latest/building-with-maven.html#spark-tests-in-maven
>> >>> ? This shows how to run just one test suite.
>> >>>
>> >>> In any Maven project you can try things like "mvn test -pl [module]"
>> >>> to run just one module's tests.
>> >> Yes I tried that as described below at point 2.
>> >>>> 2. directly via maven
>> >>>> I did the following described in the docs [0].
>> >>>>
>> >>>> export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M
>> >>>> -XX:ReservedCodeCacheSize=512m"
>> >>>> mvn -Pyarn -Phadoop-2.3 -DskipTests -Phive clean package
>> >>>> mvn -Pyarn -Phadoop-2.3 -Phive test
>> >>>>
>> >>>> This also doesn't work.
>> >>>> Why do I have to package spark bevore running the tests?
>> >>> What doesn't work?
>> >>> Some tests use the built assembly, which requires packaging.
>> >> I get the same Exceptions as in every other way.
>> >>>> 3. via sbt
>> >>>> I tried the following. I freshly cloned spark and checked out the tag
>> >>>> v1.1.0-rc4.
>> >>>>
>> >>>> sbt/sbt "project mllib" test
>> >>>>
>> >>>> and get the following exception in several cluster tests.
>> >>>>
>> >>>> [info] - task size should be small in both training and prediction
>> >>>> ***
>> >>>> FAILED ***
>> >>> This just looks like a flaky test failure; I'd try again.
>> >>>
>> >> I don't think so. I tried for several times now in several different
>> >> ways.
>> >>
>> >> Thanks,
>> >> Niklas
>> >>
>> >>
>> >>
>> >> ---------------------------------------------------------------------
>> >> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> >> For additional commands, e-mail: dev-help@spark.apache.org
>> >>
>>
>>
>> ---------------------------------------------------------------------
>> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
>> For additional commands, e-mail: dev-help@spark.apache.org
>>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10051-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 20:42:43 2014
Return-Path: <dev-return-10051-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 6219B17594
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 20:42:43 +0000 (UTC)
Received: (qmail 84806 invoked by uid 500); 30 Oct 2014 20:42:42 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 84719 invoked by uid 500); 30 Oct 2014 20:42:42 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 84702 invoked by uid 99); 30 Oct 2014 20:42:42 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 20:42:42 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.42 as permitted sender)
Received: from [209.85.215.42] (HELO mail-la0-f42.google.com) (209.85.215.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 20:42:37 +0000
Received: by mail-la0-f42.google.com with SMTP id gq15so5173127lab.15
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 13:41:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=+ulTr3oGgncdRluozEdLNZg/01QNLrZMhElHkvWck4E=;
        b=lJexuubk5qyOGFRNaKZmqK5Vko+wUxRcQpfTTA5r/zqAcncwWA6hq4JxoDQFcPsMSk
         BzAqAOaxl/2Jg0VWdFavlmNS3mSLIFO+8lgWMkqsSZ1Pc1UrmChBq4Ea1ugIqRa0qvj/
         mhdKmRWWcPKYn0YKfjQH5eSrIdX1rC9drkkSFCA5jhrZSnaUrsGYD71F8YXTbxy2BHPq
         S7UH+o5So6JVUCVVkIGaUfni3VmyX5pW6iC9hTF8Rp9MpVZPbFlbzjM59JpwVINdqvW+
         P2SPh7MG+CAzY8BisEXNgr38r3L8lggWe8IUyFAjSVzjbvc+K0V5YP023tjSZMTxNtjs
         DepA==
MIME-Version: 1.0
X-Received: by 10.112.147.199 with SMTP id tm7mr21699163lbb.92.1414701690791;
 Thu, 30 Oct 2014 13:41:30 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Thu, 30 Oct 2014 13:41:30 -0700 (PDT)
In-Reply-To: <CA+B-+fweAvG3ws0E5L63xExFOeiaGGEjBsHa_iOzJYTyEJz9aA@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
	<CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
	<CA+B-+fyRP1SVyz=Ouu-kMQEN54c14G4s3dCPh+E8kNH0zUf1pg@mail.gmail.com>
	<CALD+6GO-6b5yX_MYBuYLOhXtLx1vQgT3Zem4R5gYsnENQyubsQ@mail.gmail.com>
	<CA+B-+fweAvG3ws0E5L63xExFOeiaGGEjBsHa_iOzJYTyEJz9aA@mail.gmail.com>
Date: Thu, 30 Oct 2014 13:41:30 -0700
Message-ID: <CA+B-+fxBCJ4p-f6yH7hXqB98H4waLrd=wtFXfnBcoFOyqVJ+vw@mail.gmail.com>
Subject: Re: matrix factorization cross validation
From: Debasish Das <debasish.das83@gmail.com>
To: Nick Pentreath <nick.pentreath@gmail.com>
Cc: Xiangrui Meng <mengxr@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b3a893cbe305b0506a9e7e8
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b3a893cbe305b0506a9e7e8
Content-Type: text/plain; charset=UTF-8

I am working on it...I will open up a JIRA once I see some results..

Idea is to come up with a test train set based on users...basically for
each user, we come up with 80% train data and 20% test data...

Now we pick up a K (each user should have a different K based on the movies
he watched so some multiplier) and then we get topK for each user and see
the confusion matrix for each user...

This data will also go to RankingMetrics I think...one is ground truth
array and the other is our prediction...I would like to see the raw
confusions as well..

These measures are necessary to validate any of the topic modeling
algorithms as well...

Is there a better place for it other than mllib examples ?

On Thu, Oct 30, 2014 at 8:13 AM, Debasish Das <debasish.das83@gmail.com>
wrote:

> I thought topK will save us...for each user we have 1xrank...now our movie
> factor is a RDD...we pick topK movie factors based on vector norm...with K
> = 50, we will have 50 vectors * num_executors in a RDD...with the user
> 1xrank we do a distributed dot product using RowMatrix APIs...
>
> May be we can't find topK using vector norm on movie factors...
>
> On Thu, Oct 30, 2014 at 1:12 AM, Nick Pentreath <nick.pentreath@gmail.com>
> wrote:
>
>> Looking at
>> https://github.com/apache/spark/blob/814a9cd7fabebf2a06f7e2e5d46b6a2b28b917c2/mllib/src/main/scala/org/apache/spark/mllib/evaluation/RankingMetrics.scala#L82
>>
>> For each user in test set, you generate an Array of top K predicted item
>> ids (Int or String probably), and an Array of ground truth item ids (the
>> known rated or liked items in the test set for that user), and pass that to
>> precisionAt(k) to compute MAP@k (Actually this method name is a bit
>> misleading - it should be meanAveragePrecisionAt where the other method
>> there is without a cutoff at k. However, both compute MAP).
>>
>> The challenge at scale is actually computing all the top Ks for each
>> user, as it requires broadcasting all the item factors (unless there is a
>> smarter way?)
>>
>> I wonder if it is possible to extend the DIMSUM idea to computing top K
>> matrix multiply between the user and item factor matrices, as opposed to
>> all-pairs similarity of one matrix?
>>
>> On Thu, Oct 30, 2014 at 5:28 AM, Debasish Das <debasish.das83@gmail.com>
>> wrote:
>>
>>> Is there an example of how to use RankingMetrics ?
>>>
>>> Let's take the user, document example...we get user x topic and document
>>> x
>>> topic matrices as the model...
>>>
>>> Now for each user, we can generate topK document by doing a sort on (1 x
>>> topic)dot(topic x document) and picking topK...
>>>
>>> Is it possible to validate such a topK finding algorithm using
>>> RankingMetrics ?
>>>
>>>
>>> On Wed, Oct 29, 2014 at 12:14 PM, Xiangrui Meng <mengxr@gmail.com>
>>> wrote:
>>>
>>> > Let's narrow the context from matrix factorization to recommendation
>>> > via ALS. It adds extra complexity if we treat it as a multi-class
>>> > classification problem. ALS only outputs a single value for each
>>> > prediction, which is hard to convert to probability distribution over
>>> > the 5 rating levels. Treating it as a binary classification problem or
>>> > a ranking problem does make sense. The RankingMetricc is in master.
>>> > Free free to add prec@k and ndcg@k to examples.MovielensALS. ROC
>>> > should be good to add as well. -Xiangrui
>>> >
>>> >
>>> > On Wed, Oct 29, 2014 at 11:23 AM, Debasish Das <
>>> debasish.das83@gmail.com>
>>> > wrote:
>>> > > Hi,
>>> > >
>>> > > In the current factorization flow, we cross validate on the test
>>> dataset
>>> > > using the RMSE number but there are some other measures which are
>>> worth
>>> > > looking into.
>>> > >
>>> > > If we consider the problem as a regression problem and the ratings
>>> 1-5
>>> > are
>>> > > considered as 5 classes, it is possible to generate a confusion
>>> matrix
>>> > > using MultiClassMetrics.scala
>>> > >
>>> > > If the ratings are only 0/1 (like from the spotify demo from spark
>>> > summit)
>>> > > then it is possible to use Binary Classification Metrices to come up
>>> with
>>> > > the ROC curve...
>>> > >
>>> > > For topK user/products we should also look into prec@k and pdcg@k
>>> as the
>>> > > metric..
>>> > >
>>> > > Does it make sense to add the multiclass metric and prec@k, pdcg@k
>>> in
>>> > > examples.MovielensALS along with RMSE ?
>>> > >
>>> > > Thanks.
>>> > > Deb
>>> >
>>>
>>
>>
>

--047d7b3a893cbe305b0506a9e7e8--

From dev-return-10052-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 20:56:52 2014
Return-Path: <dev-return-10052-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 79FC71761A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 20:56:52 +0000 (UTC)
Received: (qmail 25740 invoked by uid 500); 30 Oct 2014 20:56:49 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25689 invoked by uid 500); 30 Oct 2014 20:56:49 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 24536 invoked by uid 99); 30 Oct 2014 20:56:49 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 20:56:49 +0000
X-ASF-Spam-Status: No, hits=1.5 required=5.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of gerard.maas@gmail.com designates 74.125.82.42 as permitted sender)
Received: from [74.125.82.42] (HELO mail-wg0-f42.google.com) (74.125.82.42)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 20:56:22 +0000
Received: by mail-wg0-f42.google.com with SMTP id k14so5184143wgh.29
        for <multiple recipients>; Thu, 30 Oct 2014 13:54:07 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=ZQTvASxSO77sny1wWJNBG5i7sd7+DOvuy4ev6urNwZQ=;
        b=0bzxsYcbcRfQGm/TtLCGSSeZBOQqHwWN0h+/qEhWNYkKfId7ILZRDIeafTmDIUalZ5
         wh/O7qPbT4bdV/bJU6mPNhmGlbDk+y9RBTGrwbGlmHONZeyCcgFciWGYTLFgRkwu6/pO
         JuylJiMPoZbytnr+7389tkKoSEPgz+sBYJ3EQbRzdKH6Swk3ZyzwPXjr9Na3eXVeBmy8
         BxqvEQMYQxHcA4c+kIp1IvSc3ZJcqT0BXnZAoiPj3JgTv1+wcMZQ6J3uaAcMdibLhFZk
         4PDtXmB6X75cvY/T77aXtPe/Bi5GGzZ9VS7vpzyKP6COkdyBp5fFhlFxvniryVzuhaT4
         yd1A==
X-Received: by 10.194.93.194 with SMTP id cw2mr5688205wjb.112.1414702447135;
 Thu, 30 Oct 2014 13:54:07 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.194.71.139 with HTTP; Thu, 30 Oct 2014 13:53:35 -0700 (PDT)
From: Gerard Maas <gerard.maas@gmail.com>
Date: Thu, 30 Oct 2014 21:53:35 +0100
Message-ID: <CAMc-71mSEY2dt0rudpPfNK-H8PD6Ne3d2H47BWtDsDYEBde1_g@mail.gmail.com>
Subject: Registering custom metrics
To: spark users <user@spark.apache.org>, dev@spark.apache.org
Content-Type: multipart/alternative; boundary=047d7bb04c18d313e70506aa149d
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7bb04c18d313e70506aa149d
Content-Type: text/plain; charset=UTF-8

vHi,

I've been exploring the metrics exposed by Spark and I'm wondering whether
there's a way to register job-specific metrics that could be exposed
through the existing metrics system.

Would there be an  example somewhere?

BTW, documentation about how the metrics work could be improved. I found
out about the default servlet and the metrics/json/ endpoint on the code. I
could not find any reference to that on the dedicated doc page [1].
Probably something I could contribute if there's nobody on that at the
moment.

-kr, Gerard.

[1]   http://spark.apache.org/docs/1.1.0/monitoring.html#Metrics

--047d7bb04c18d313e70506aa149d--

From dev-return-10053-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 21:16:26 2014
Return-Path: <dev-return-10053-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 54A6C17707
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 21:16:26 +0000 (UTC)
Received: (qmail 81386 invoked by uid 500); 30 Oct 2014 21:16:25 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 81319 invoked by uid 500); 30 Oct 2014 21:16:25 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 81308 invoked by uid 99); 30 Oct 2014 21:16:24 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 21:16:24 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of sowen@cloudera.com designates 209.85.192.54 as permitted sender)
Received: from [209.85.192.54] (HELO mail-qg0-f54.google.com) (209.85.192.54)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 21:15:59 +0000
Received: by mail-qg0-f54.google.com with SMTP id q108so4617779qgd.41
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 14:15:58 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=H8Se8mXLX3N/252IiACgP/0pu680V4IHzcg8i2WBqfk=;
        b=NUAqdJNrumBdnHiHqVWISXSgscPoI1GT42f75pPU95RejA+8oo1965lGZc+w2HvtcM
         e+s1fDzw09TsqHEEvNBYOcKT3KVfjfhdqTEAX30oO61EPlM+dlAliaG3mLVXAEXo2qua
         16VzxAlkmpREOipWgVbrvOH9PRkrQgXz82MazUb0ya0rtW3Ce+GHKnhMejtlCwGmmb+4
         oDY+qtpcVFA0KSHFPF2Z+ZZ/GSL6Y2IKU3ulLS27eACpybjmmQBJOcjjqVJlhnTS5hEw
         L8HO2E7fWdOuYaaBen18pITkb9QaUfvS2Khdp+v6onjAnCwtfpaFIWb1IKmQqDGx1tDW
         VnUw==
X-Gm-Message-State: ALoCoQmlSs7A2wKRPKG64lH3g81PknsuANA8VJtpBq2I9M3Om/ITuXzyOD+VS3Pc5XnYdUuANexe
X-Received: by 10.224.111.201 with SMTP id t9mr31227281qap.0.1414703757965;
 Thu, 30 Oct 2014 14:15:57 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.78.75 with HTTP; Thu, 30 Oct 2014 14:15:37 -0700 (PDT)
In-Reply-To: <CA+B-+fxBCJ4p-f6yH7hXqB98H4waLrd=wtFXfnBcoFOyqVJ+vw@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
 <CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
 <CA+B-+fyRP1SVyz=Ouu-kMQEN54c14G4s3dCPh+E8kNH0zUf1pg@mail.gmail.com>
 <CALD+6GO-6b5yX_MYBuYLOhXtLx1vQgT3Zem4R5gYsnENQyubsQ@mail.gmail.com>
 <CA+B-+fweAvG3ws0E5L63xExFOeiaGGEjBsHa_iOzJYTyEJz9aA@mail.gmail.com> <CA+B-+fxBCJ4p-f6yH7hXqB98H4waLrd=wtFXfnBcoFOyqVJ+vw@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Thu, 30 Oct 2014 22:15:37 +0100
Message-ID: <CAMAsSdKtR3iD1_35mda22RRZeYrex5i_uNAtK08ochxe6TdaSQ@mail.gmail.com>
Subject: Re: matrix factorization cross validation
To: Debasish Das <debasish.das83@gmail.com>
Cc: Nick Pentreath <nick.pentreath@gmail.com>, Xiangrui Meng <mengxr@gmail.com>, 
	dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

The pretty standard metric for recommenders is mean average precision,
and RankingMetrics will already do that as-is. I don't know that a
confusion matrix for this binary classification does much.


On Thu, Oct 30, 2014 at 9:41 PM, Debasish Das <debasish.das83@gmail.com> wrote:
> I am working on it...I will open up a JIRA once I see some results..
>
> Idea is to come up with a test train set based on users...basically for
> each user, we come up with 80% train data and 20% test data...
>
> Now we pick up a K (each user should have a different K based on the movies
> he watched so some multiplier) and then we get topK for each user and see
> the confusion matrix for each user...
>
> This data will also go to RankingMetrics I think...one is ground truth
> array and the other is our prediction...I would like to see the raw
> confusions as well..
>
> These measures are necessary to validate any of the topic modeling
> algorithms as well...
>
> Is there a better place for it other than mllib examples ?
>
> On Thu, Oct 30, 2014 at 8:13 AM, Debasish Das <debasish.das83@gmail.com>
> wrote:
>
>> I thought topK will save us...for each user we have 1xrank...now our movie
>> factor is a RDD...we pick topK movie factors based on vector norm...with K
>> = 50, we will have 50 vectors * num_executors in a RDD...with the user
>> 1xrank we do a distributed dot product using RowMatrix APIs...
>>
>> May be we can't find topK using vector norm on movie factors...
>>
>> On Thu, Oct 30, 2014 at 1:12 AM, Nick Pentreath <nick.pentreath@gmail.com>
>> wrote:
>>
>>> Looking at
>>> https://github.com/apache/spark/blob/814a9cd7fabebf2a06f7e2e5d46b6a2b28b917c2/mllib/src/main/scala/org/apache/spark/mllib/evaluation/RankingMetrics.scala#L82
>>>
>>> For each user in test set, you generate an Array of top K predicted item
>>> ids (Int or String probably), and an Array of ground truth item ids (the
>>> known rated or liked items in the test set for that user), and pass that to
>>> precisionAt(k) to compute MAP@k (Actually this method name is a bit
>>> misleading - it should be meanAveragePrecisionAt where the other method
>>> there is without a cutoff at k. However, both compute MAP).
>>>
>>> The challenge at scale is actually computing all the top Ks for each
>>> user, as it requires broadcasting all the item factors (unless there is a
>>> smarter way?)
>>>
>>> I wonder if it is possible to extend the DIMSUM idea to computing top K
>>> matrix multiply between the user and item factor matrices, as opposed to
>>> all-pairs similarity of one matrix?
>>>
>>> On Thu, Oct 30, 2014 at 5:28 AM, Debasish Das <debasish.das83@gmail.com>
>>> wrote:
>>>
>>>> Is there an example of how to use RankingMetrics ?
>>>>
>>>> Let's take the user, document example...we get user x topic and document
>>>> x
>>>> topic matrices as the model...
>>>>
>>>> Now for each user, we can generate topK document by doing a sort on (1 x
>>>> topic)dot(topic x document) and picking topK...
>>>>
>>>> Is it possible to validate such a topK finding algorithm using
>>>> RankingMetrics ?
>>>>
>>>>
>>>> On Wed, Oct 29, 2014 at 12:14 PM, Xiangrui Meng <mengxr@gmail.com>
>>>> wrote:
>>>>
>>>> > Let's narrow the context from matrix factorization to recommendation
>>>> > via ALS. It adds extra complexity if we treat it as a multi-class
>>>> > classification problem. ALS only outputs a single value for each
>>>> > prediction, which is hard to convert to probability distribution over
>>>> > the 5 rating levels. Treating it as a binary classification problem or
>>>> > a ranking problem does make sense. The RankingMetricc is in master.
>>>> > Free free to add prec@k and ndcg@k to examples.MovielensALS. ROC
>>>> > should be good to add as well. -Xiangrui
>>>> >
>>>> >
>>>> > On Wed, Oct 29, 2014 at 11:23 AM, Debasish Das <
>>>> debasish.das83@gmail.com>
>>>> > wrote:
>>>> > > Hi,
>>>> > >
>>>> > > In the current factorization flow, we cross validate on the test
>>>> dataset
>>>> > > using the RMSE number but there are some other measures which are
>>>> worth
>>>> > > looking into.
>>>> > >
>>>> > > If we consider the problem as a regression problem and the ratings
>>>> 1-5
>>>> > are
>>>> > > considered as 5 classes, it is possible to generate a confusion
>>>> matrix
>>>> > > using MultiClassMetrics.scala
>>>> > >
>>>> > > If the ratings are only 0/1 (like from the spotify demo from spark
>>>> > summit)
>>>> > > then it is possible to use Binary Classification Metrices to come up
>>>> with
>>>> > > the ROC curve...
>>>> > >
>>>> > > For topK user/products we should also look into prec@k and pdcg@k
>>>> as the
>>>> > > metric..
>>>> > >
>>>> > > Does it make sense to add the multiclass metric and prec@k, pdcg@k
>>>> in
>>>> > > examples.MovielensALS along with RMSE ?
>>>> > >
>>>> > > Thanks.
>>>> > > Deb
>>>> >
>>>>
>>>
>>>
>>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10054-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 21:22:19 2014
Return-Path: <dev-return-10054-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 391BB1774B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 21:22:19 +0000 (UTC)
Received: (qmail 96123 invoked by uid 500); 30 Oct 2014 21:22:17 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96057 invoked by uid 500); 30 Oct 2014 21:22:17 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 96044 invoked by uid 99); 30 Oct 2014 21:22:17 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 21:22:17 +0000
X-ASF-Spam-Status: No, hits=1.7 required=10.0
	tests=FREEMAIL_ENVFROM_END_DIGIT,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of debasish.das83@gmail.com designates 209.85.215.51 as permitted sender)
Received: from [209.85.215.51] (HELO mail-la0-f51.google.com) (209.85.215.51)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 21:22:13 +0000
Received: by mail-la0-f51.google.com with SMTP id q1so5179192lam.38
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 14:21:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=wjUr652ytOH6kZhYBH0HGt/VEf1zmeHN70n9HlmF51Q=;
        b=puEjIX5YeSmibEa6Som9dCR7u294tkXTSHY/2qy6aZBVj/AVYKoanbqdv+J/KWCt0j
         wc18WyLTXZ/+uu+od90KHQ0coOYOFgTjcrIzQHt4ISlzHsyRvQMTM23GtLl1e2miCBUZ
         Zt5v/DBIgA0ZcI3gR1RncbatvsjeynOyg6GCmvJ9snMghIz6CqiRV/viSZH1d1IkzaQ+
         w7WRAS2kfPOWGreif5hsiGAAcqXjY4LyWAA1nOpIPBDmARixd6Wfon+dGse/Jzo3Hk+b
         KNOufhCR3po79KiHXqwcbwB/GVjuRM/nbvoFINw7RMQ1ZaoWWqpDQ4YPBKVQO1eiNQqO
         GKdg==
MIME-Version: 1.0
X-Received: by 10.152.120.133 with SMTP id lc5mr21919142lab.62.1414704111569;
 Thu, 30 Oct 2014 14:21:51 -0700 (PDT)
Received: by 10.25.212.16 with HTTP; Thu, 30 Oct 2014 14:21:51 -0700 (PDT)
In-Reply-To: <CAMAsSdKtR3iD1_35mda22RRZeYrex5i_uNAtK08ochxe6TdaSQ@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
	<CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
	<CA+B-+fyRP1SVyz=Ouu-kMQEN54c14G4s3dCPh+E8kNH0zUf1pg@mail.gmail.com>
	<CALD+6GO-6b5yX_MYBuYLOhXtLx1vQgT3Zem4R5gYsnENQyubsQ@mail.gmail.com>
	<CA+B-+fweAvG3ws0E5L63xExFOeiaGGEjBsHa_iOzJYTyEJz9aA@mail.gmail.com>
	<CA+B-+fxBCJ4p-f6yH7hXqB98H4waLrd=wtFXfnBcoFOyqVJ+vw@mail.gmail.com>
	<CAMAsSdKtR3iD1_35mda22RRZeYrex5i_uNAtK08ochxe6TdaSQ@mail.gmail.com>
Date: Thu, 30 Oct 2014 14:21:51 -0700
Message-ID: <CA+B-+fw16nFxicHnLc4mvqnT3ogOWL1vmki5DhAMd2ARVyC6hg@mail.gmail.com>
Subject: Re: matrix factorization cross validation
From: Debasish Das <debasish.das83@gmail.com>
To: Sean Owen <sowen@cloudera.com>
Cc: Nick Pentreath <nick.pentreath@gmail.com>, Xiangrui Meng <mengxr@gmail.com>, 
	dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01176919084e440506aa7862
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01176919084e440506aa7862
Content-Type: text/plain; charset=UTF-8

Does it make sense to have a user specific K or K is considered same over
all users ?

Intuitively the users who watches more movies should get a higher K than
the others...

On Thu, Oct 30, 2014 at 2:15 PM, Sean Owen <sowen@cloudera.com> wrote:

> The pretty standard metric for recommenders is mean average precision,
> and RankingMetrics will already do that as-is. I don't know that a
> confusion matrix for this binary classification does much.
>
>
> On Thu, Oct 30, 2014 at 9:41 PM, Debasish Das <debasish.das83@gmail.com>
> wrote:
> > I am working on it...I will open up a JIRA once I see some results..
> >
> > Idea is to come up with a test train set based on users...basically for
> > each user, we come up with 80% train data and 20% test data...
> >
> > Now we pick up a K (each user should have a different K based on the
> movies
> > he watched so some multiplier) and then we get topK for each user and see
> > the confusion matrix for each user...
> >
> > This data will also go to RankingMetrics I think...one is ground truth
> > array and the other is our prediction...I would like to see the raw
> > confusions as well..
> >
> > These measures are necessary to validate any of the topic modeling
> > algorithms as well...
> >
> > Is there a better place for it other than mllib examples ?
> >
> > On Thu, Oct 30, 2014 at 8:13 AM, Debasish Das <debasish.das83@gmail.com>
> > wrote:
> >
> >> I thought topK will save us...for each user we have 1xrank...now our
> movie
> >> factor is a RDD...we pick topK movie factors based on vector
> norm...with K
> >> = 50, we will have 50 vectors * num_executors in a RDD...with the user
> >> 1xrank we do a distributed dot product using RowMatrix APIs...
> >>
> >> May be we can't find topK using vector norm on movie factors...
> >>
> >> On Thu, Oct 30, 2014 at 1:12 AM, Nick Pentreath <
> nick.pentreath@gmail.com>
> >> wrote:
> >>
> >>> Looking at
> >>>
> https://github.com/apache/spark/blob/814a9cd7fabebf2a06f7e2e5d46b6a2b28b917c2/mllib/src/main/scala/org/apache/spark/mllib/evaluation/RankingMetrics.scala#L82
> >>>
> >>> For each user in test set, you generate an Array of top K predicted
> item
> >>> ids (Int or String probably), and an Array of ground truth item ids
> (the
> >>> known rated or liked items in the test set for that user), and pass
> that to
> >>> precisionAt(k) to compute MAP@k (Actually this method name is a bit
> >>> misleading - it should be meanAveragePrecisionAt where the other method
> >>> there is without a cutoff at k. However, both compute MAP).
> >>>
> >>> The challenge at scale is actually computing all the top Ks for each
> >>> user, as it requires broadcasting all the item factors (unless there
> is a
> >>> smarter way?)
> >>>
> >>> I wonder if it is possible to extend the DIMSUM idea to computing top K
> >>> matrix multiply between the user and item factor matrices, as opposed
> to
> >>> all-pairs similarity of one matrix?
> >>>
> >>> On Thu, Oct 30, 2014 at 5:28 AM, Debasish Das <
> debasish.das83@gmail.com>
> >>> wrote:
> >>>
> >>>> Is there an example of how to use RankingMetrics ?
> >>>>
> >>>> Let's take the user, document example...we get user x topic and
> document
> >>>> x
> >>>> topic matrices as the model...
> >>>>
> >>>> Now for each user, we can generate topK document by doing a sort on
> (1 x
> >>>> topic)dot(topic x document) and picking topK...
> >>>>
> >>>> Is it possible to validate such a topK finding algorithm using
> >>>> RankingMetrics ?
> >>>>
> >>>>
> >>>> On Wed, Oct 29, 2014 at 12:14 PM, Xiangrui Meng <mengxr@gmail.com>
> >>>> wrote:
> >>>>
> >>>> > Let's narrow the context from matrix factorization to recommendation
> >>>> > via ALS. It adds extra complexity if we treat it as a multi-class
> >>>> > classification problem. ALS only outputs a single value for each
> >>>> > prediction, which is hard to convert to probability distribution
> over
> >>>> > the 5 rating levels. Treating it as a binary classification problem
> or
> >>>> > a ranking problem does make sense. The RankingMetricc is in master.
> >>>> > Free free to add prec@k and ndcg@k to examples.MovielensALS. ROC
> >>>> > should be good to add as well. -Xiangrui
> >>>> >
> >>>> >
> >>>> > On Wed, Oct 29, 2014 at 11:23 AM, Debasish Das <
> >>>> debasish.das83@gmail.com>
> >>>> > wrote:
> >>>> > > Hi,
> >>>> > >
> >>>> > > In the current factorization flow, we cross validate on the test
> >>>> dataset
> >>>> > > using the RMSE number but there are some other measures which are
> >>>> worth
> >>>> > > looking into.
> >>>> > >
> >>>> > > If we consider the problem as a regression problem and the ratings
> >>>> 1-5
> >>>> > are
> >>>> > > considered as 5 classes, it is possible to generate a confusion
> >>>> matrix
> >>>> > > using MultiClassMetrics.scala
> >>>> > >
> >>>> > > If the ratings are only 0/1 (like from the spotify demo from spark
> >>>> > summit)
> >>>> > > then it is possible to use Binary Classification Metrices to come
> up
> >>>> with
> >>>> > > the ROC curve...
> >>>> > >
> >>>> > > For topK user/products we should also look into prec@k and pdcg@k
> >>>> as the
> >>>> > > metric..
> >>>> > >
> >>>> > > Does it make sense to add the multiclass metric and prec@k,
> pdcg@k
> >>>> in
> >>>> > > examples.MovielensALS along with RMSE ?
> >>>> > >
> >>>> > > Thanks.
> >>>> > > Deb
> >>>> >
> >>>>
> >>>
> >>>
> >>
>

--089e01176919084e440506aa7862--

From dev-return-10055-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Thu Oct 30 21:25:28 2014
Return-Path: <dev-return-10055-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 38C1017761
	for <apmail-spark-dev-archive@minotaur.apache.org>; Thu, 30 Oct 2014 21:25:28 +0000 (UTC)
Received: (qmail 2251 invoked by uid 500); 30 Oct 2014 21:25:22 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 2179 invoked by uid 500); 30 Oct 2014 21:25:22 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 2167 invoked by uid 99); 30 Oct 2014 21:25:21 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 21:25:21 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.192.46 as permitted sender)
Received: from [209.85.192.46] (HELO mail-qg0-f46.google.com) (209.85.192.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Thu, 30 Oct 2014 21:25:16 +0000
Received: by mail-qg0-f46.google.com with SMTP id i50so3709267qgf.19
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 14:24:55 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=So+Qol50k14avnD3xPGYQBM8EDdeN/EaYRS0Lm6qxDE=;
        b=cNuzdr3CL1EtpiMrERfTvOrghm+EAq5xyahUx7fSyN8tnlvV6xOrwLasmrSSOJmcRz
         cazMcv8dJlUzIzBuBrLPhDnPx0gRQ2R1WXZEQrlRuY6hJCVjO2bj0cktGgZyL8yWq72h
         LQHGEE29FktBliDo5/L5yeQ8G9T2jo15i5Uy99CZB3Qbp3u+kl0DYEYsOZY5zvw6eoQs
         +5c6sN2VFdgME1Wz/uVdIr/jUhL2aANsPWDq2CZAal0GsLTJyc26H5zeg4gkv3ffsPkv
         uQCQ/PQNqCDjtH1QSQpwBhIo0cQUpsaefJaXAz1iahbpGQb5O7j1jagXv4T49sk3/zSa
         AQRA==
X-Gm-Message-State: ALoCoQnbGY7E8fLAJKVTl6aQbk669+HJz6yuKxUZG0jcz//o6tVqRPvqOg4En4DrrT6TQ23CTZ/Z
X-Received: by 10.140.41.39 with SMTP id y36mr28938735qgy.64.1414704295450;
 Thu, 30 Oct 2014 14:24:55 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.96.78.75 with HTTP; Thu, 30 Oct 2014 14:24:35 -0700 (PDT)
In-Reply-To: <CA+B-+fw16nFxicHnLc4mvqnT3ogOWL1vmki5DhAMd2ARVyC6hg@mail.gmail.com>
References: <CA+B-+fyUnCYJupC9P_ebgeFP7DOTUFE7TqjzwdSc6ZgJzp68LQ@mail.gmail.com>
 <CAJgQjQ_441SY1Vkg86r5q5R5tviJ21P=_rQE6Ub9rNUismQZ2g@mail.gmail.com>
 <CA+B-+fyRP1SVyz=Ouu-kMQEN54c14G4s3dCPh+E8kNH0zUf1pg@mail.gmail.com>
 <CALD+6GO-6b5yX_MYBuYLOhXtLx1vQgT3Zem4R5gYsnENQyubsQ@mail.gmail.com>
 <CA+B-+fweAvG3ws0E5L63xExFOeiaGGEjBsHa_iOzJYTyEJz9aA@mail.gmail.com>
 <CA+B-+fxBCJ4p-f6yH7hXqB98H4waLrd=wtFXfnBcoFOyqVJ+vw@mail.gmail.com>
 <CAMAsSdKtR3iD1_35mda22RRZeYrex5i_uNAtK08ochxe6TdaSQ@mail.gmail.com> <CA+B-+fw16nFxicHnLc4mvqnT3ogOWL1vmki5DhAMd2ARVyC6hg@mail.gmail.com>
From: Sean Owen <sowen@cloudera.com>
Date: Thu, 30 Oct 2014 22:24:35 +0100
Message-ID: <CAMAsSd+aGLc4Z2tz5dj_f58F_=bcoDQP0d01=JNP_Xh3Vrfnzw@mail.gmail.com>
Subject: Re: matrix factorization cross validation
To: Debasish Das <debasish.das83@gmail.com>
Cc: Nick Pentreath <nick.pentreath@gmail.com>, Xiangrui Meng <mengxr@gmail.com>, 
	dev <dev@spark.apache.org>
Content-Type: text/plain; charset=UTF-8
X-Virus-Checked: Checked by ClamAV on apache.org

MAP is effectively an average over all k from 1 to min(#
recommendations, # items rated) Getting first recommendations right is
more important than the last.

On Thu, Oct 30, 2014 at 10:21 PM, Debasish Das <debasish.das83@gmail.com> wrote:
> Does it make sense to have a user specific K or K is considered same over
> all users ?
>
> Intuitively the users who watches more movies should get a higher K than the
> others...
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10056-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 04:31:45 2014
Return-Path: <dev-return-10056-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id AA7EF1756B
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 04:31:45 +0000 (UTC)
Received: (qmail 96104 invoked by uid 500); 31 Oct 2014 04:31:44 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 96038 invoked by uid 500); 31 Oct 2014 04:31:44 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 95949 invoked by uid 99); 31 Oct 2014 04:31:44 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 04:31:44 +0000
X-ASF-Spam-Status: No, hits=2.0 required=10.0
	tests=RCVD_IN_DNSWL_NONE,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 04:31:16 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <ashutosh.trivedi@iiitb.org>)
	id 1Xk3ra-0003Ij-D4
	for dev@spark.incubator.apache.org; Thu, 30 Oct 2014 21:31:02 -0700
Date: Thu, 30 Oct 2014 21:31:02 -0700 (PDT)
From: Ashutosh <ashutosh.trivedi@iiitb.org>
To: dev@spark.incubator.apache.org
Message-ID: <1414729862397-9034.post@n3.nabble.com>
In-Reply-To: <1414516353788-8992.post@n3.nabble.com>
References: <1413883380883-8880.post@n3.nabble.com> <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com> <1413920470217-8894.post@n3.nabble.com> <1414151748436-8935.post@n3.nabble.com> <1414471251511-8984.post@n3.nabble.com> <1414489501850-8990.post@n3.nabble.com> <1414516353788-8992.post@n3.nabble.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
X-Virus-Checked: Checked by ClamAV on apache.org

Hi Anant,
sorry for my late reply. Thank you for taking time and reviewing it.
 
I have few comments on first issue.

You are correct on the string (csv) part. But we can not take input of type
you mentioned. We calculate frequency in our function. Otherwise user has to
do all this computation. I realize that taking a RDD[Vector] would be
general enough for all. What do you say?

I agree on rest all the issues. I will correct them soon and post it.
I have a doubt on test cases. Where should I put data while giving test
scripts? or should i generate synthetic data for testing with in the
scripts, how does this work?

Regards,
Ashutosh



--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9034.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10057-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 04:39:02 2014
Return-Path: <dev-return-10057-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id BA3BC1758A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 04:39:02 +0000 (UTC)
Received: (qmail 5550 invoked by uid 500); 31 Oct 2014 04:39:02 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 5474 invoked by uid 500); 31 Oct 2014 04:39:01 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 5406 invoked by uid 99); 31 Oct 2014 04:39:01 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 04:39:01 +0000
X-ASF-Spam-Status: No, hits=4.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 04:38:34 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <ashutosh.trivedi@iiitb.org>)
	id 1Xk3yq-0003Wu-OX
	for dev@spark.incubator.apache.org; Thu, 30 Oct 2014 21:38:32 -0700
Date: Thu, 30 Oct 2014 21:38:32 -0700 (PDT)
From: Ashutosh <ashutosh.trivedi@iiitb.org>
To: dev@spark.incubator.apache.org
Message-ID: <1414730269133.81923@iiitb.org>
In-Reply-To: <CANvqkYM=kC5sKgo4Te1omGmfdBUMtdkVW=MoXSdHNKrHP9cFzg@mail.gmail.com>
References: <1413883380883-8880.post@n3.nabble.com> <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com> <1413920470217-8894.post@n3.nabble.com> <1414151748436-8935.post@n3.nabble.com> <1414471251511-8984.post@n3.nabble.com> <1414489501850-8990.post@n3.nabble.com> <1414516353788-8992.post@n3.nabble.com> <1414729862397-9034.post@n3.nabble.com> <CANvqkYM=kC5sKgo4Te1omGmfdBUMtdkVW=MoXSdHNKrHP9cFzg@mail.gmail.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: multipart/alternative; 
	boundary="----=_Part_211152_1736452.1414730312755"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_211152_1736452.1414730312755
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

?Okay. I'll try it and post it soon with test case. After that I think we can go ahead with the PR.

________________________________
From: slcclimber [via Apache Spark Developers List] <ml-node+s1001551n9035h61@n3.nabble.com>
Sent: Friday, October 31, 2014 10:03 AM
To: Ashutosh Trivedi (MT2013030)
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection


Ashutosh,
A vector would be a good idea vectors are used very frequently.
Test data is usually stored in the spark/data/mllib folder

On Oct 30, 2014 10:31 PM, "Ashutosh [via Apache Spark Developers List]" <[hidden email]</user/SendEmail.jtp?type=node&node=9035&i=0>> wrote:
Hi Anant,
sorry for my late reply. Thank you for taking time and reviewing it.

I have few comments on first issue.

You are correct on the string (csv) part. But we can not take input of type you mentioned. We calculate frequency in our function. Otherwise user has to do all this computation. I realize that taking a RDD[Vector] would be general enough for all. What do you say?

I agree on rest all the issues. I will correct them soon and post it.
I have a doubt on test cases. Where should I put data while giving test scripts? or should i generate synthetic data for testing with in the scripts, how does this work?

Regards,
Ashutosh

________________________________
If you reply to this email, your message will be added to the discussion below:
http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9034.html
To unsubscribe from [MLlib] Contributing Algorithm for Outlier Detection, click here.
NAML<http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>


________________________________
If you reply to this email, your message will be added to the discussion below:
http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9035.html
To unsubscribe from [MLlib] Contributing Algorithm for Outlier Detection, click here<http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=8880&code=YXNodXRvc2gudHJpdmVkaUBpaWl0Yi5vcmd8ODg4MHwtMzkzMzE5NzYx>.
NAML<http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9036.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
------=_Part_211152_1736452.1414730312755--

From dev-return-10058-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 04:42:33 2014
Return-Path: <dev-return-10058-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 53DA017598
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 04:42:33 +0000 (UTC)
Received: (qmail 13654 invoked by uid 500); 31 Oct 2014 04:42:32 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 13587 invoked by uid 500); 31 Oct 2014 04:42:32 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 13575 invoked by uid 99); 31 Oct 2014 04:42:31 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 04:42:31 +0000
X-ASF-Spam-Status: No, hits=4.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_NEUTRAL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: neutral (athena.apache.org: local policy)
Received: from [216.139.236.26] (HELO sam.nabble.com) (216.139.236.26)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 04:42:26 +0000
Received: from ben.nabble.com ([192.168.236.152])
	by sam.nabble.com with esmtp (Exim 4.72)
	(envelope-from <ashutosh.trivedi@iiitb.org>)
	id 1Xk41v-0003hT-Et
	for dev@spark.incubator.apache.org; Thu, 30 Oct 2014 21:41:43 -0700
Date: Thu, 30 Oct 2014 21:41:43 -0700 (PDT)
From: Ashutosh <ashutosh.trivedi@iiitb.org>
To: dev@spark.incubator.apache.org
Message-ID: <1414730487332.68555@iiitb.org>
In-Reply-To: <CANvqkYNgfR_JdMB-mGNHunnNm_NKPu54Kqc-7tm6agc_m6ZS4g@mail.gmail.com>
References: <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com> <1413920470217-8894.post@n3.nabble.com> <1414151748436-8935.post@n3.nabble.com> <1414471251511-8984.post@n3.nabble.com> <1414489501850-8990.post@n3.nabble.com> <1414516353788-8992.post@n3.nabble.com> <1414729862397-9034.post@n3.nabble.com> <CANvqkYM=kC5sKgo4Te1omGmfdBUMtdkVW=MoXSdHNKrHP9cFzg@mail.gmail.com> <1414730269133.81923@iiitb.org> <CANvqkYNgfR_JdMB-mGNHunnNm_NKPu54Kqc-7tm6agc_m6ZS4g@mail.gmail.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: multipart/alternative; 
	boundary="----=_Part_211512_8559849.1414730503455"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_211512_8559849.1414730503455
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

A?lready done. Here is the link

 https://issues.apache.org/jira/browse/SPARK-4038

________________________________
From: slcclimber [via Apache Spark Developers List] <ml-node+s1001551n9037h23@n3.nabble.com>
Sent: Friday, October 31, 2014 10:09 AM
To: Ashutosh Trivedi (MT2013030)
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection


You should create a jira ticket to go with it as well.
Thanks

On Oct 30, 2014 10:38 PM, "Ashutosh [via Apache Spark Developers List]" <[hidden email]</user/SendEmail.jtp?type=node&node=9037&i=0>> wrote:

?Okay. I'll try it and post it soon with test case. After that I think we can go ahead with the PR.

________________________________
From: slcclimber [via Apache Spark Developers List] <ml-node+[hidden email]<http://user/SendEmail.jtp?type=node&node=9036&i=0>>
Sent: Friday, October 31, 2014 10:03 AM
To: Ashutosh Trivedi (MT2013030)
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection


Ashutosh,
A vector would be a good idea vectors are used very frequently.
Test data is usually stored in the spark/data/mllib folder

On Oct 30, 2014 10:31 PM, "Ashutosh [via Apache Spark Developers List]" <[hidden email]<http://user/SendEmail.jtp?type=node&node=9035&i=0>> wrote:
Hi Anant,
sorry for my late reply. Thank you for taking time and reviewing it.

I have few comments on first issue.

You are correct on the string (csv) part. But we can not take input of type you mentioned. We calculate frequency in our function. Otherwise user has to do all this computation. I realize that taking a RDD[Vector] would be general enough for all. What do you say?

I agree on rest all the issues. I will correct them soon and post it.
I have a doubt on test cases. Where should I put data while giving test scripts? or should i generate synthetic data for testing with in the scripts, how does this work?

Regards,
Ashutosh

________________________________
If you reply to this email, your message will be added to the discussion below:
http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9034.html
To unsubscribe from [MLlib] Contributing Algorithm for Outlier Detection, click here.
NAML<http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>


________________________________
If you reply to this email, your message will be added to the discussion below:
http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9035.html
To unsubscribe from [MLlib] Contributing Algorithm for Outlier Detection, click here.
NAML<http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>


________________________________
If you reply to this email, your message will be added to the discussion below:
http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9036.html
To unsubscribe from [MLlib] Contributing Algorithm for Outlier Detection, click here.
NAML<http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>


________________________________
If you reply to this email, your message will be added to the discussion below:
http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9037.html
To unsubscribe from [MLlib] Contributing Algorithm for Outlier Detection, click here<http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=8880&code=YXNodXRvc2gudHJpdmVkaUBpaWl0Yi5vcmd8ODg4MHwtMzkzMzE5NzYx>.
NAML<http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9038.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
------=_Part_211512_8559849.1414730503455--

From dev-return-10059-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 04:46:16 2014
Return-Path: <dev-return-10059-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 289A1175AD
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 04:46:16 +0000 (UTC)
Received: (qmail 21035 invoked by uid 500); 31 Oct 2014 04:46:14 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 20949 invoked by uid 500); 31 Oct 2014 04:46:14 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 20934 invoked by uid 99); 31 Oct 2014 04:46:14 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 04:46:14 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of nick.pentreath@gmail.com designates 209.85.216.46 as permitted sender)
Received: from [209.85.216.46] (HELO mail-qa0-f46.google.com) (209.85.216.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 04:45:48 +0000
Received: by mail-qa0-f46.google.com with SMTP id n8so1242040qaq.33
        for <dev@spark.apache.org>; Thu, 30 Oct 2014 21:45:02 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=date:mime-version:message-id:in-reply-to:references:from:to:cc
         :subject:content-type;
        bh=pSR+ntXDZGZWQPh2vPHN8iYYIPhriei+AKBzKJyLiWk=;
        b=JFaTA5wwD0hmSYPc590eRGDm19NnX+q5p9AavEoTL/I2zuW9XLJMQhux11NyHYNON/
         Z0UNtpocW0uuCCV99pPDfiBScJKWP0nCJVTq9kp5m8Km3mWUyOnVUVsk9iJR+IVC/3fQ
         p0n+D25ATt4wVzRtMXg5GzkuqA+JRZscCCIhjgWWps2zweHUIFcVUf+sqKtPGyJrZdy2
         PkRVzfU0N70nt3Xu8xZ3NiOYJImSnxwywN3M/mwf+OUY2l9whiRcr4aWy7ezaro6jnID
         iYYEQ+kvBsPWhuAZfrUiIjy/wPNU4UECnm78oBI8mMfdZHk794Hif99L+9lorcz4scof
         1kvQ==
X-Received: by 10.224.132.70 with SMTP id a6mr32781019qat.16.1414730701918;
        Thu, 30 Oct 2014 21:45:01 -0700 (PDT)
Received: from hedwig-24.prd.orcali.com (ec2-54-85-253-245.compute-1.amazonaws.com. [54.85.253.245])
        by mx.google.com with ESMTPSA id u46sm8594558qgd.3.2014.10.30.21.45.00
        for <multiple recipients>
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Thu, 30 Oct 2014 21:45:01 -0700 (PDT)
Date: Thu, 30 Oct 2014 21:45:01 -0700 (PDT)
X-Google-Original-Date: Fri, 31 Oct 2014 04:45:00 GMT
MIME-Version: 1.0
X-Mailer: Nodemailer (0.5.0; +http://www.nodemailer.com/)
Message-Id: <1414730700758.b773d5d5@Nodemailer>
In-Reply-To: <CAMAsSd+aGLc4Z2tz5dj_f58F_=bcoDQP0d01=JNP_Xh3Vrfnzw@mail.gmail.com>
References: <CAMAsSd+aGLc4Z2tz5dj_f58F_=bcoDQP0d01=JNP_Xh3Vrfnzw@mail.gmail.com>
X-Orchestra-Oid: 4804B49E-53E4-441B-9CA6-BFDF2C5849E7
X-Orchestra-Sig: 9568cc7cf04a6515466fa0ccb8b403e66cf345f3
X-Orchestra-Thrid: TEDF7BF56-A3FD-4BD3-A0FA-706CB3088F7E_1483323018522489074
X-Orchestra-Thrid-Sig: 78104b45afb1250663bdc45b956df7ec1f5caa52
X-Orchestra-Account: 97e9c800116db95d3da3e3b6ae0a67ad7557d50a
From: "Nick Pentreath" <nick.pentreath@gmail.com>
To: "Sean Owen" <sowen@cloudera.com>
Cc: "Debasish Das" <debasish.das83@gmail.com>, "dev"
 <dev@spark.apache.org>, "Xiangrui Meng" <mengxr@gmail.com>
Subject: Re: matrix factorization cross validation
Content-Type: multipart/alternative;
 boundary="----Nodemailer-0.5.0-?=_1-1414730701076"
X-Virus-Checked: Checked by ClamAV on apache.org

------Nodemailer-0.5.0-?=_1-1414730701076
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Sean, re my point earlier do you know a more efficient way to compute top k=
 for each user, other than to broadcast the item factors=3F=C2=A0


(I guess one can use the new asymmetric lsh paper perhaps to assist)


=E2=80=94
Sent from Mailbox

On Thu, Oct 30, 2014 at 11:24 PM, Sean Owen <sowen@cloudera.com> wrote:

> MAP is effectively an average over all k from 1 to min(#
> recommendations, # items rated) Getting first recommendations right is
> more important than the last.
> On Thu, Oct 30, 2014 at 10:21 PM, Debasish Das <debasish.das83@gmail.com>=
 wrote:
>> Does it make sense to have a user specific K or K is considered same =
over
>> all users =3F
>>
>> Intuitively the users who watches more movies should get a higher K than=
 the
>> others...
>>
------Nodemailer-0.5.0-?=_1-1414730701076--

From dev-return-10060-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 04:51:11 2014
Return-Path: <dev-return-10060-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id B22F6175B6
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 04:51:11 +0000 (UTC)
Received: (qmail 30232 invoked by uid 500); 31 Oct 2014 04:51:11 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 30161 invoked by uid 500); 31 Oct 2014 04:51:11 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Delivered-To: moderator for dev@spark.apache.org
Received: (qmail 98952 invoked by uid 99); 31 Oct 2014 04:34:08 -0000
X-ASF-Spam-Status: No, hits=4.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_NONE,SPF_SOFTFAIL,URI_HEX
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of anant.asty@gmail.com does not designate 216.139.236.26 as permitted sender)
Date: Thu, 30 Oct 2014 21:33:41 -0700 (PDT)
From: slcclimber <anant.asty@gmail.com>
To: dev@spark.incubator.apache.org
Message-ID: <CANvqkYM=kC5sKgo4Te1omGmfdBUMtdkVW=MoXSdHNKrHP9cFzg@mail.gmail.com>
In-Reply-To: <1414729862397-9034.post@n3.nabble.com>
References: <1413883380883-8880.post@n3.nabble.com> <CAJgQjQ-whGZEz28ji9Pc6xcE+F4zW9gMFDxL5BGd6++OUiB7gg@mail.gmail.com> <1413920470217-8894.post@n3.nabble.com> <1414151748436-8935.post@n3.nabble.com> <1414471251511-8984.post@n3.nabble.com> <1414489501850-8990.post@n3.nabble.com> <1414516353788-8992.post@n3.nabble.com> <1414729862397-9034.post@n3.nabble.com>
Subject: Re: [MLlib] Contributing Algorithm for Outlier Detection
MIME-Version: 1.0
Content-Type: multipart/alternative; 
	boundary="----=_Part_211087_14037302.1414730021841"
X-Virus-Checked: Checked by ClamAV on apache.org

------=_Part_211087_14037302.1414730021841
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Ashutosh,
A vector would be a good idea vectors are used very frequently.
Test data is usually stored in the spark/data/mllib folder
 On Oct 30, 2014 10:31 PM, "Ashutosh [via Apache Spark Developers List]" <
ml-node+s1001551n9034h67@n3.nabble.com> wrote:

> Hi Anant,
> sorry for my late reply. Thank you for taking time and reviewing it.
>
> I have few comments on first issue.
>
> You are correct on the string (csv) part. But we can not take input of
> type you mentioned. We calculate frequency in our function. Otherwise user
> has to do all this computation. I realize that taking a RDD[Vector] would
> be general enough for all. What do you say?
>
> I agree on rest all the issues. I will correct them soon and post it.
> I have a doubt on test cases. Where should I put data while giving test
> scripts? or should i generate synthetic data for testing with in the
> scripts, how does this work?
>
> Regards,
> Ashutosh
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9034.html
>  To unsubscribe from [MLlib] Contributing Algorithm for Outlier Detection, click
> here
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=8880&code=YW5hbnQuYXN0eUBnbWFpbC5jb218ODg4MHwxOTU2OTQ5NjMy>
> .
> NAML
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/MLlib-Contributing-Algorithm-for-Outlier-Detection-tp8880p9035.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
------=_Part_211087_14037302.1414730021841--

From dev-return-10061-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 08:29:11 2014
Return-Path: <dev-return-10061-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 287A717BBA
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 08:29:11 +0000 (UTC)
Received: (qmail 4415 invoked by uid 500); 31 Oct 2014 08:29:10 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 4351 invoked by uid 500); 31 Oct 2014 08:29:10 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 4340 invoked by uid 99); 31 Oct 2014 08:29:09 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 08:29:09 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of sowen@cloudera.com designates 209.85.213.177 as permitted sender)
Received: from [209.85.213.177] (HELO mail-ig0-f177.google.com) (209.85.213.177)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 08:29:05 +0000
Received: by mail-ig0-f177.google.com with SMTP id hl2so501031igb.16
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 01:27:15 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type:content-transfer-encoding;
        bh=E24bOwaqNzNA3ZOym2Fu0d53ZyWh9SCUFygYnI1XNBM=;
        b=SncZyFuQ6hClcmLSidhUqozgfhfMdybIlZCSWk37Af+teZ2cRimshCXQ6r68rBXCMu
         FVXvTINk6uF7+IX1ZDA7vGZSYvNd5Ispqb1uzjfDz7apJ+I9tn6XOhRL4kks3V8nBVlY
         V0b9nlMogld7bAVOuUnriK87O5rkvCmkMqyRIJmfdZbWFr4XmHkOD4Cob0Zf+wQrR+pl
         VKkZJNSJughFF+zgaw5lEzdKR25sM7BIfb04/dzZdov2/WWFabbzhJPrOBixdqTMWtwN
         lmOpaUXF00qj020p513cPN9lMlAAN41UygoB6ZQYIHeVJh0hqgaPRRF5e4QOOrl8QSvW
         rkcA==
X-Gm-Message-State: ALoCoQlHJeM5cU8mk0BwcwFQcdMxXVSwxOYD1CRVaX2uiZDnjb4lQKM/7XYPgyiOUztFckobVJmX
X-Received: by 10.43.158.197 with SMTP id lv5mr405075icc.88.1414744035175;
 Fri, 31 Oct 2014 01:27:15 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.136.221 with HTTP; Fri, 31 Oct 2014 01:26:55 -0700 (PDT)
In-Reply-To: <1414730700758.b773d5d5@Nodemailer>
References: <CAMAsSd+aGLc4Z2tz5dj_f58F_=bcoDQP0d01=JNP_Xh3Vrfnzw@mail.gmail.com>
 <1414730700758.b773d5d5@Nodemailer>
From: Sean Owen <sowen@cloudera.com>
Date: Fri, 31 Oct 2014 09:26:55 +0100
Message-ID: <CAMAsSd+rzAqv0JhRB0qLoi6nwEtMahdo_vSND6r-w1s+CATeuw@mail.gmail.com>
Subject: Re: matrix factorization cross validation
To: Nick Pentreath <nick.pentreath@gmail.com>
Cc: Debasish Das <debasish.das83@gmail.com>, dev <dev@spark.apache.org>, 
	Xiangrui Meng <mengxr@gmail.com>
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

No, excepting approximate methods like LSH to figure out the
relatively small set of candidates for the users in the partition, and
broadcast or join those.

On Fri, Oct 31, 2014 at 5:45 AM, Nick Pentreath
<nick.pentreath@gmail.com> wrote:
> Sean, re my point earlier do you know a more efficient way to compute top=
 k
> for each user, other than to broadcast the item factors?
>
> (I guess one can use the new asymmetric lsh paper perhaps to assist)
>
> =E2=80=94
> Sent from Mailbox
>
>
> On Thu, Oct 30, 2014 at 11:24 PM, Sean Owen <sowen@cloudera.com> wrote:
>>
>> MAP is effectively an average over all k from 1 to min(#
>> recommendations, # items rated) Getting first recommendations right is
>> more important than the last.
>>
>> On Thu, Oct 30, 2014 at 10:21 PM, Debasish Das <debasish.das83@gmail.com=
>
>> wrote:
>> > Does it make sense to have a user specific K or K is considered same
>> > over
>> > all users ?
>> >
>> > Intuitively the users who watches more movies should get a higher K th=
an
>> > the
>> > others...
>> >
>
>

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10062-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 17:39:32 2014
Return-Path: <dev-return-10062-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id EAC1417E8C
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 17:39:31 +0000 (UTC)
Received: (qmail 68631 invoked by uid 500); 31 Oct 2014 17:39:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 68564 invoked by uid 500); 31 Oct 2014 17:39:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 68545 invoked by uid 99); 31 Oct 2014 17:39:30 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 17:39:30 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 74.125.82.46 as permitted sender)
Received: from [74.125.82.46] (HELO mail-wg0-f46.google.com) (74.125.82.46)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 17:39:26 +0000
Received: by mail-wg0-f46.google.com with SMTP id x13so8420941wgg.5
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 10:38:20 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=kIQ7lwIq/Kkozja+sk5VsrV1JMh51i1Pg0kbvU6+DVM=;
        b=NChyYo4Udd0oYrhRnjas0rdNAZO8ojxR3Lv0k1DYkAtKqs6+sA+sN3sPzuPDjmHdbV
         lzm2Lv7vRP2x10aNDsmyu5dVZScogu5tRnAu/GZEn/0fNiIvSJMQJJ6uXxJKiPbqRrCu
         r2IIw2dPo4gAsb0t2RtFlNhQrM0f5zSr3h2YQJxAuMPQaPyWgVi8/y4S7oDBW7KBCQs3
         va21XD+KsqH0n3KacquI7ouRbqAgjWrwUo9Ct0QjgIjbHaDL6t0+nX6D/js0a1w2RJil
         F3WaSfrsJxx4opCQGDdvj+olo13v3MiO9fI/4zX2u6H447+r434t/b/cDqMu0yF6BV9S
         es6g==
MIME-Version: 1.0
X-Received: by 10.181.27.161 with SMTP id jh1mr5264039wid.75.1414777100271;
 Fri, 31 Oct 2014 10:38:20 -0700 (PDT)
Received: by 10.180.108.13 with HTTP; Fri, 31 Oct 2014 10:38:20 -0700 (PDT)
Date: Fri, 31 Oct 2014 13:38:20 -0400
Message-ID: <CAOhmDzcta_vkDrByDX=JFVHdcfVqVSvOOtJTydYyf=LoNm-B0Q@mail.gmail.com>
Subject: Surprising Spark SQL benchmark
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1136cbe07f96e50506bb76cd
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1136cbe07f96e50506bb76cd
Content-Type: text/plain; charset=UTF-8

I know we don't want to be jumping at every benchmark someone posts out
there, but this one surprised me:

http://www.citusdata.com/blog/86-making-postgresql-scale-hadoop-style

This benchmark has Spark SQL failing to complete several queries in the
TPC-H benchmark. I don't understand much about the details of performing
benchmarks, but this was surprising.

Are these results expected?

Related HN discussion here: https://news.ycombinator.com/item?id=8539678

Nick

--001a1136cbe07f96e50506bb76cd--

From dev-return-10063-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 18:10:35 2014
Return-Path: <dev-return-10063-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D0DD517FBB
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 18:10:35 +0000 (UTC)
Received: (qmail 75576 invoked by uid 500); 31 Oct 2014 18:10:34 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75489 invoked by uid 500); 31 Oct 2014 18:10:34 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74612 invoked by uid 99); 31 Oct 2014 18:10:34 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 18:10:34 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of pwendell@gmail.com designates 209.85.218.44 as permitted sender)
Received: from [209.85.218.44] (HELO mail-oi0-f44.google.com) (209.85.218.44)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 18:10:04 +0000
Received: by mail-oi0-f44.google.com with SMTP id h136so6094523oig.31
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 11:09:18 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=WvnCu4AEZCfGf/z2OeLvm4PNI2cW1p814JCfJBZ/XAI=;
        b=SNh+8A/jIXohe7B8XeuUcPTQOlqATMObWMvpkt+7vj3UpFF6cqJmIae3PmeV99vxlp
         EPMeTBD23dR2AeczqorIu7nptQvJYk5c2wEw1/hV9lliFwD55Q99TRjq3v1S17XqyG+E
         TkOi0i1g8mRyXjf3Rueh3ksPKwd2WQNHvpQo4aDR+KzXjBO1zsytnJAODvuClGV0KQMP
         DB/5jRY3F+k5KBaH0RlFmJb1UrSe3ByHAFDcE5ji8nO2Dh+CO4P4mayTo0wp+cDHHVTf
         90fudZzZUp9UjBSZ7QM90OxRaeKpU6w6b5hcbqLn0BSnxcCOeb8Qgg8wR5E1VVRDUIqN
         MOvA==
MIME-Version: 1.0
X-Received: by 10.202.74.18 with SMTP id x18mr20516863oia.50.1414778958592;
 Fri, 31 Oct 2014 11:09:18 -0700 (PDT)
Received: by 10.202.56.5 with HTTP; Fri, 31 Oct 2014 11:09:18 -0700 (PDT)
In-Reply-To: <CAOhmDzcta_vkDrByDX=JFVHdcfVqVSvOOtJTydYyf=LoNm-B0Q@mail.gmail.com>
References: <CAOhmDzcta_vkDrByDX=JFVHdcfVqVSvOOtJTydYyf=LoNm-B0Q@mail.gmail.com>
Date: Fri, 31 Oct 2014 11:09:18 -0700
Message-ID: <CABPQxssSQ1ePa=SctOmOgdmVRCHh2vj3_ftPU_okbzRz3pJBnA@mail.gmail.com>
Subject: Re: Surprising Spark SQL benchmark
From: Patrick Wendell <pwendell@gmail.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: text/plain; charset=ISO-8859-1
X-Virus-Checked: Checked by ClamAV on apache.org

Hey Nick,

Unfortunately Citus Data didn't contact any of the Spark or Spark SQL
developers when running this. It is really easy to make one system
look better than others when you are running a benchmark yourself
because tuning and sizing can lead to a 10X performance improvement.
This benchmark doesn't share the mechanism in a reproducible way.

There are a bunch of things that aren't clear here:

1. Spark SQL has optimized parquet features, were these turned on?
2. It doesn't mention computing statistics in Spark SQL, but it does
this for Impala and Parquet. Statistics allow Spark SQL to broadcast
small tables which can make a 10X difference in TPC-H.
3. For data larger than memory, Spark SQL often performs better if you
don't call "cache", did they try this?

Basically, a self-reported marketing benchmark like this that
*shocker* concludes this vendor's solution is the best, is not
particularly useful.

If Citus data wants to run a credible benchmark, I'd invite them to
directly involve Spark SQL developers in the future. Until then, I
wouldn't give much credence to this or any other similar vendor
benchmark.

- Patrick

On Fri, Oct 31, 2014 at 10:38 AM, Nicholas Chammas
<nicholas.chammas@gmail.com> wrote:
> I know we don't want to be jumping at every benchmark someone posts out
> there, but this one surprised me:
>
> http://www.citusdata.com/blog/86-making-postgresql-scale-hadoop-style
>
> This benchmark has Spark SQL failing to complete several queries in the
> TPC-H benchmark. I don't understand much about the details of performing
> benchmarks, but this was surprising.
>
> Are these results expected?
>
> Related HN discussion here: https://news.ycombinator.com/item?id=8539678
>
> Nick

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10064-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 18:31:52 2014
Return-Path: <dev-return-10064-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 72489172A2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 18:31:52 +0000 (UTC)
Received: (qmail 39247 invoked by uid 500); 31 Oct 2014 18:31:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 39182 invoked by uid 500); 31 Oct 2014 18:31:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 39170 invoked by uid 99); 31 Oct 2014 18:31:51 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 18:31:51 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.175 as permitted sender)
Received: from [209.85.212.175] (HELO mail-wi0-f175.google.com) (209.85.212.175)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 18:31:47 +0000
Received: by mail-wi0-f175.google.com with SMTP id ex7so2063610wid.8
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 11:30:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=HcRzsfhMc0rsik+r8NaktUgGskOR5PDVo131t4512AM=;
        b=hw2gzljbxkXk77dVBi9nZ2ckWOWx2jVGWINTqwrnmvyyni5sibic3Tw9idP6sIlV5Z
         dz2aXqmVGx5bMfOp4Oqa7jTT5GEsUN8UKUt2HE7MLKr7cDCoonMlveFEdmRQj7j3KzHg
         V6cX52Ve+6y2O0BaZBnouwymuN7FX24PzTgJZzUamXRY+itJc8lGx/ZTaLZpAUEckkiY
         hXFWxrCkEPqYi95cwCnbfHwMbIDRBBdx4pckpP16Ug8wJ5O5k3NS/ZL1/EO3CLYxqSwh
         o/sVxlnqZ+Sx0y2WL69hr48WWjNjfOzSdmJkr+M6vyhCuyOKsNWrIXlny0sTwdGB2mEB
         9yaw==
MIME-Version: 1.0
X-Received: by 10.194.170.170 with SMTP id an10mr16786104wjc.85.1414780240761;
 Fri, 31 Oct 2014 11:30:40 -0700 (PDT)
Received: by 10.180.108.13 with HTTP; Fri, 31 Oct 2014 11:30:40 -0700 (PDT)
In-Reply-To: <CABPQxssSQ1ePa=SctOmOgdmVRCHh2vj3_ftPU_okbzRz3pJBnA@mail.gmail.com>
References: <CAOhmDzcta_vkDrByDX=JFVHdcfVqVSvOOtJTydYyf=LoNm-B0Q@mail.gmail.com>
	<CABPQxssSQ1ePa=SctOmOgdmVRCHh2vj3_ftPU_okbzRz3pJBnA@mail.gmail.com>
Date: Fri, 31 Oct 2014 14:30:40 -0400
Message-ID: <CAOhmDzcYYxowyMHJK1uf-c5Jj4A4FZJmNiW=1G1=tXt25B-64g@mail.gmail.com>
Subject: Re: Surprising Spark SQL benchmark
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: Patrick Wendell <pwendell@gmail.com>
Cc: dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013c62dcaf988f0506bc3199
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c62dcaf988f0506bc3199
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Thanks for the response, Patrick.

I guess the key takeaways are 1) the tuning/config details are everything
(they're not laid out here), 2) the benchmark should be reproducible (it's
not), and 3) reach out to the relevant devs before publishing (didn't
happen).

Probably key takeaways for any kind of benchmark, really...

Nick


2014=EB=85=84 10=EC=9B=94 31=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, Patrick =
Wendell<pwendell@gmail.com>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =
=EB=A9=94=EC=8B=9C=EC=A7=80:

> Hey Nick,
>
> Unfortunately Citus Data didn't contact any of the Spark or Spark SQL
> developers when running this. It is really easy to make one system
> look better than others when you are running a benchmark yourself
> because tuning and sizing can lead to a 10X performance improvement.
> This benchmark doesn't share the mechanism in a reproducible way.
>
> There are a bunch of things that aren't clear here:
>
> 1. Spark SQL has optimized parquet features, were these turned on?
> 2. It doesn't mention computing statistics in Spark SQL, but it does
> this for Impala and Parquet. Statistics allow Spark SQL to broadcast
> small tables which can make a 10X difference in TPC-H.
> 3. For data larger than memory, Spark SQL often performs better if you
> don't call "cache", did they try this?
>
> Basically, a self-reported marketing benchmark like this that
> *shocker* concludes this vendor's solution is the best, is not
> particularly useful.
>
> If Citus data wants to run a credible benchmark, I'd invite them to
> directly involve Spark SQL developers in the future. Until then, I
> wouldn't give much credence to this or any other similar vendor
> benchmark.
>
> - Patrick
>
> On Fri, Oct 31, 2014 at 10:38 AM, Nicholas Chammas
> <nicholas.chammas@gmail.com <javascript:;>> wrote:
> > I know we don't want to be jumping at every benchmark someone posts out
> > there, but this one surprised me:
> >
> > http://www.citusdata.com/blog/86-making-postgresql-scale-hadoop-style
> >
> > This benchmark has Spark SQL failing to complete several queries in the
> > TPC-H benchmark. I don't understand much about the details of performin=
g
> > benchmarks, but this was surprising.
> >
> > Are these results expected?
> >
> > Related HN discussion here: https://news.ycombinator.com/item?id=3D8539=
678
> >
> > Nick
>

--089e013c62dcaf988f0506bc3199--

From dev-return-10065-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 19:14:50 2014
Return-Path: <dev-return-10065-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 39CAB17454
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 19:14:50 +0000 (UTC)
Received: (qmail 75417 invoked by uid 500); 31 Oct 2014 19:14:47 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 75346 invoked by uid 500); 31 Oct 2014 19:14:47 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 75335 invoked by uid 99); 31 Oct 2014 19:14:46 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 19:14:46 +0000
X-ASF-Spam-Status: No, hits=-0.7 required=10.0
	tests=RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of snunez@hortonworks.com designates 209.85.192.169 as permitted sender)
Received: from [209.85.192.169] (HELO mail-pd0-f169.google.com) (209.85.192.169)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 19:14:20 +0000
Received: by mail-pd0-f169.google.com with SMTP id y10so7829497pdj.28
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 12:13:34 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:user-agent:date:subject:from:to:cc:message-id
         :thread-topic:references:in-reply-to:mime-version:content-type
         :content-transfer-encoding;
        bh=Fpsrwmp2nGBbi28JLx8cfpzN28jTedDZfa0sIAP7EuI=;
        b=jMDJFPN5eUSixrhBhPAkB65GrAnNjZzUYuUX4hQHGBsVbMtSAPc8rXJze8RUDSDVfj
         DwAzonvYG2Q5Q5RBC7BWp/gToJIljUYjx7Vh6ZOw8EtNUyPniBZ2zBPOMPYXFjHl48sK
         w/hsdaSEp/KCDnkwR8wT185b2G+n3eyMaUbg9sSevwhn0j3dnd02MvQd8eEzSQqXm0yf
         0PFTpzXiL+2YvZ5dmeJ9NPyFFCeHxN58biJrljfYrMZAFHfQ912JJsInoUpt+05rsnEh
         nsMqFkYtFfjRQb92tzzQCT+xzZL9ZXs8tY7A6gSi9bCqxIVRu+xlY6Dov9W3oZ8GL896
         YNDA==
X-Gm-Message-State: ALoCoQnpqkHwLqpQqB5f1KHEviZML69OWae2/fQ5ynVgBZI83EEFVluLnthk+/mSxQz0kq4bIKVBGZDISEXCBS7Qsq86H692DB8EWg7C6owG8ID7+lSYgf0=
X-Received: by 10.66.187.209 with SMTP id fu17mr27346687pac.120.1414782814191;
        Fri, 31 Oct 2014 12:13:34 -0700 (PDT)
Received: from [10.0.0.6] ([73.15.1.121])
        by mx.google.com with ESMTPSA id dx10sm10642914pab.38.2014.10.31.12.13.32
        for <multiple recipients>
        (version=TLSv1 cipher=RC4-SHA bits=128/128);
        Fri, 31 Oct 2014 12:13:33 -0700 (PDT)
User-Agent: Microsoft-MacOutlook/14.4.5.141003
Date: Fri, 31 Oct 2014 12:13:29 -0700
Subject: Re: Surprising Spark SQL benchmark
From: Steve Nunez <snunez@hortonworks.com>
To: Nicholas Chammas <nicholas.chammas@gmail.com>,
	Patrick Wendell <pwendell@gmail.com>
CC: dev <dev@spark.apache.org>
Message-ID: <D0792C12.D06C%snunez@hortonworks.com>
Thread-Topic: Surprising Spark SQL benchmark
References: <CAOhmDzcta_vkDrByDX=JFVHdcfVqVSvOOtJTydYyf=LoNm-B0Q@mail.gmail.com>
 <CABPQxssSQ1ePa=SctOmOgdmVRCHh2vj3_ftPU_okbzRz3pJBnA@mail.gmail.com>
 <CAOhmDzcYYxowyMHJK1uf-c5Jj4A4FZJmNiW=1G1=tXt25B-64g@mail.gmail.com>
In-Reply-To: <CAOhmDzcYYxowyMHJK1uf-c5Jj4A4FZJmNiW=1G1=tXt25B-64g@mail.gmail.com>
Mime-version: 1.0
Content-type: text/plain; charset=EUC-KR
Content-transfer-encoding: quoted-printable
X-Virus-Checked: Checked by ClamAV on apache.org

To be fair, we (Spark community) haven=A1=AFt been any better, for example =
this
benchmark:

	https://databricks.com/blog/2014/10/10/spark-petabyte-sort.html


For which no details or code have been released to allow others to
reproduce it. I would encourage anyone doing a Spark benchmark in future
to avoid the stigma of vendor reported benchmarks and publish enough
information and code to let others repeat the exercise easily.

	- Steve



On 10/31/14, 11:30, "Nicholas Chammas" <nicholas.chammas@gmail.com> wrote:

>Thanks for the response, Patrick.
>
>I guess the key takeaways are 1) the tuning/config details are everything
>(they're not laid out here), 2) the benchmark should be reproducible (it's
>not), and 3) reach out to the relevant devs before publishing (didn't
>happen).
>
>Probably key takeaways for any kind of benchmark, really...
>
>Nick
>
>
>2014=B3=E2 10=BF=F9 31=C0=CF =B1=DD=BF=E4=C0=CF, Patrick Wendell<pwendell@=
gmail.com>=B4=D4=C0=CC =C0=DB=BC=BA=C7=D1 =B8=DE=BD=C3=C1=F6:
>
>> Hey Nick,
>>
>> Unfortunately Citus Data didn't contact any of the Spark or Spark SQL
>> developers when running this. It is really easy to make one system
>> look better than others when you are running a benchmark yourself
>> because tuning and sizing can lead to a 10X performance improvement.
>> This benchmark doesn't share the mechanism in a reproducible way.
>>
>> There are a bunch of things that aren't clear here:
>>
>> 1. Spark SQL has optimized parquet features, were these turned on?
>> 2. It doesn't mention computing statistics in Spark SQL, but it does
>> this for Impala and Parquet. Statistics allow Spark SQL to broadcast
>> small tables which can make a 10X difference in TPC-H.
>> 3. For data larger than memory, Spark SQL often performs better if you
>> don't call "cache", did they try this?
>>
>> Basically, a self-reported marketing benchmark like this that
>> *shocker* concludes this vendor's solution is the best, is not
>> particularly useful.
>>
>> If Citus data wants to run a credible benchmark, I'd invite them to
>> directly involve Spark SQL developers in the future. Until then, I
>> wouldn't give much credence to this or any other similar vendor
>> benchmark.
>>
>> - Patrick
>>
>> On Fri, Oct 31, 2014 at 10:38 AM, Nicholas Chammas
>> <nicholas.chammas@gmail.com <javascript:;>> wrote:
>> > I know we don't want to be jumping at every benchmark someone posts
>>out
>> > there, but this one surprised me:
>> >
>> > http://www.citusdata.com/blog/86-making-postgresql-scale-hadoop-style
>> >
>> > This benchmark has Spark SQL failing to complete several queries in
>>the
>> > TPC-H benchmark. I don't understand much about the details of
>>performing
>> > benchmarks, but this was surprising.
>> >
>> > Are these results expected?
>> >
>> > Related HN discussion here:
>>https://news.ycombinator.com/item?id=3D8539678
>> >
>> > Nick
>>



--=20
CONFIDENTIALITY NOTICE
NOTICE: This message is intended for the use of the individual or entity to=
=20
which it is addressed and may contain information that is confidential,=20
privileged and exempt from disclosure under applicable law. If the reader=
=20
of this message is not the intended recipient, you are hereby notified that=
=20
any printing, copying, dissemination, distribution, disclosure or=20
forwarding of this communication is strictly prohibited. If you have=20
received this communication in error, please contact the sender immediately=
=20
and delete it from your system. Thank You.

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org


From dev-return-10066-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 19:47:05 2014
Return-Path: <dev-return-10066-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 298E5175AE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 19:47:05 +0000 (UTC)
Received: (qmail 85943 invoked by uid 500); 31 Oct 2014 19:47:04 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 85874 invoked by uid 500); 31 Oct 2014 19:47:04 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 85862 invoked by uid 99); 31 Oct 2014 19:47:03 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 19:47:03 +0000
X-ASF-Spam-Status: No, hits=2.5 required=10.0
	tests=FREEMAIL_REPLY,HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of nicholas.chammas@gmail.com designates 209.85.212.176 as permitted sender)
Received: from [209.85.212.176] (HELO mail-wi0-f176.google.com) (209.85.212.176)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 19:47:00 +0000
Received: by mail-wi0-f176.google.com with SMTP id h11so2206009wiw.9
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 12:45:09 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=RMseS+AOCtvutMt6yabsVuOUKRM2JXvcV+czFcy4xro=;
        b=cjh3XA2lUTsyUFzCuUqDBtow/4tEX5wL076YEwKqC3E2QsmqLFEFhxoXLipMSMQaie
         n6tObx+bOXxWkm99vIS4o62xFgB07mKS9GN+0DUIGAKaA6a6AdILRv06AAvQVbjJiArA
         URLqr72BeRnPo8OIn921uokaYucy+ipVO2qNYQIFN+lhud2LrP+G5JFZJYJ2/ux2IKO+
         valrrqjHbItqVhi7dLg412zd5o/yjOTlyWWpH3nrWX5UZigoWvpSMlYyCJNAt5+eHsu9
         zdXOnIpXcuWFbib2fQTXYAnFa6yz75/1ho+jnkFzBFsCb7FX7CYseRgaUSkqhDiPkiBv
         vFiA==
MIME-Version: 1.0
X-Received: by 10.194.170.170 with SMTP id an10mr17220393wjc.85.1414784708917;
 Fri, 31 Oct 2014 12:45:08 -0700 (PDT)
Received: by 10.180.108.13 with HTTP; Fri, 31 Oct 2014 12:45:08 -0700 (PDT)
In-Reply-To: <D0792C12.D06C%snunez@hortonworks.com>
References: <CAOhmDzcta_vkDrByDX=JFVHdcfVqVSvOOtJTydYyf=LoNm-B0Q@mail.gmail.com>
	<CABPQxssSQ1ePa=SctOmOgdmVRCHh2vj3_ftPU_okbzRz3pJBnA@mail.gmail.com>
	<CAOhmDzcYYxowyMHJK1uf-c5Jj4A4FZJmNiW=1G1=tXt25B-64g@mail.gmail.com>
	<D0792C12.D06C%snunez@hortonworks.com>
Date: Fri, 31 Oct 2014 15:45:08 -0400
Message-ID: <CAOhmDzfoF_4Kt9W0tOK+zRh6XmF4Uff2_a=+i=Y7USTad3gx_g@mail.gmail.com>
Subject: Re: Surprising Spark SQL benchmark
From: Nicholas Chammas <nicholas.chammas@gmail.com>
To: Steve Nunez <snunez@hortonworks.com>
Cc: Patrick Wendell <pwendell@gmail.com>, dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e013c62dc023fbc0506bd3cf1
X-Virus-Checked: Checked by ClamAV on apache.org

--089e013c62dc023fbc0506bd3cf1
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

I believe that benchmark has a pending certification on it. See
http://sortbenchmark.org under "Process".

It's true they did not share enough details on the blog for readers to
reproduce the benchmark, but they will have to share enough with the
committee behind the benchmark in order to be certified. Given that this is
a benchmark not many people will be able to reproduce due to size and
complexity, I don't see it as a big negative that the details are not laid
out as long as there is independent certification from a third party.

>From what I've seen so far, the best big data benchmark anywhere is this:
https://amplab.cs.berkeley.edu/benchmark/

Is has all the details you'd expect, including hosted datasets, to allow
anyone to reproduce the full benchmark, covering a number of systems. I
look forward to the next update to that benchmark (a lot has changed since
Feb). And from what I can tell, it's produced by the same people behind
Spark (Patrick being among them).

So I disagree that the Spark community "hasn't been any better" in this
regard.

Nick


2014=EB=85=84 10=EC=9B=94 31=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, Steve Nu=
nez<snunez@hortonworks.com>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C =
=EB=A9=94=EC=8B=9C=EC=A7=80:

> To be fair, we (Spark community) haven=E2=80=99t been any better, for exa=
mple this
> benchmark:
>
>         https://databricks.com/blog/2014/10/10/spark-petabyte-sort.html
>
>
> For which no details or code have been released to allow others to
> reproduce it. I would encourage anyone doing a Spark benchmark in future
> to avoid the stigma of vendor reported benchmarks and publish enough
> information and code to let others repeat the exercise easily.
>
>         - Steve
>
>
>
> On 10/31/14, 11:30, "Nicholas Chammas" <nicholas.chammas@gmail.com
> <javascript:;>> wrote:
>
> >Thanks for the response, Patrick.
> >
> >I guess the key takeaways are 1) the tuning/config details are everythin=
g
> >(they're not laid out here), 2) the benchmark should be reproducible (it=
's
> >not), and 3) reach out to the relevant devs before publishing (didn't
> >happen).
> >
> >Probably key takeaways for any kind of benchmark, really...
> >
> >Nick
> >
> >
> >2014=EB=85=84 10=EC=9B=94 31=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, Patri=
ck Wendell<pwendell@gmail.com <javascript:;>>=EB=8B=98=EC=9D=B4
> =EC=9E=91=EC=84=B1=ED=95=9C =EB=A9=94=EC=8B=9C=EC=A7=80:
> >
> >> Hey Nick,
> >>
> >> Unfortunately Citus Data didn't contact any of the Spark or Spark SQL
> >> developers when running this. It is really easy to make one system
> >> look better than others when you are running a benchmark yourself
> >> because tuning and sizing can lead to a 10X performance improvement.
> >> This benchmark doesn't share the mechanism in a reproducible way.
> >>
> >> There are a bunch of things that aren't clear here:
> >>
> >> 1. Spark SQL has optimized parquet features, were these turned on?
> >> 2. It doesn't mention computing statistics in Spark SQL, but it does
> >> this for Impala and Parquet. Statistics allow Spark SQL to broadcast
> >> small tables which can make a 10X difference in TPC-H.
> >> 3. For data larger than memory, Spark SQL often performs better if you
> >> don't call "cache", did they try this?
> >>
> >> Basically, a self-reported marketing benchmark like this that
> >> *shocker* concludes this vendor's solution is the best, is not
> >> particularly useful.
> >>
> >> If Citus data wants to run a credible benchmark, I'd invite them to
> >> directly involve Spark SQL developers in the future. Until then, I
> >> wouldn't give much credence to this or any other similar vendor
> >> benchmark.
> >>
> >> - Patrick
> >>
> >> On Fri, Oct 31, 2014 at 10:38 AM, Nicholas Chammas
> >> <nicholas.chammas@gmail.com <javascript:;> <javascript:;>> wrote:
> >> > I know we don't want to be jumping at every benchmark someone posts
> >>out
> >> > there, but this one surprised me:
> >> >
> >> > http://www.citusdata.com/blog/86-making-postgresql-scale-hadoop-styl=
e
> >> >
> >> > This benchmark has Spark SQL failing to complete several queries in
> >>the
> >> > TPC-H benchmark. I don't understand much about the details of
> >>performing
> >> > benchmarks, but this was surprising.
> >> >
> >> > Are these results expected?
> >> >
> >> > Related HN discussion here:
> >>https://news.ycombinator.com/item?id=3D8539678
> >> >
> >> > Nick
> >>
>
>
>
> --
> CONFIDENTIALITY NOTICE
> NOTICE: This message is intended for the use of the individual or entity =
to
> which it is addressed and may contain information that is confidential,
> privileged and exempt from disclosure under applicable law. If the reader
> of this message is not the intended recipient, you are hereby notified th=
at
> any printing, copying, dissemination, distribution, disclosure or
> forwarding of this communication is strictly prohibited. If you have
> received this communication in error, please contact the sender immediate=
ly
> and delete it from your system. Thank You.
>

--089e013c62dc023fbc0506bd3cf1--

From dev-return-10067-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 20:01:54 2014
Return-Path: <dev-return-10067-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 3D5B21765E
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 20:01:54 +0000 (UTC)
Received: (qmail 31664 invoked by uid 500); 31 Oct 2014 20:01:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 31593 invoked by uid 500); 31 Oct 2014 20:01:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 31581 invoked by uid 99); 31 Oct 2014 20:01:50 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:01:50 +0000
X-ASF-Spam-Status: No, hits=0.9 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_MED,SPF_SOFTFAIL
X-Spam-Check-By: apache.org
Received-SPF: softfail (nike.apache.org: transitioning domain of keo@eecs.berkeley.edu does not designate 169.229.218.145 as permitted sender)
Received: from [169.229.218.145] (HELO cm04fe.IST.Berkeley.EDU) (169.229.218.145)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:01:24 +0000
Received: from mail-yh0-f52.google.com ([209.85.213.52])
	by cm04fe.ist.berkeley.edu with esmtpsa (TLSv1:RC4-SHA:128)
	(Exim 4.76)
	(auth plain:keo@eecs.berkeley.edu)
	(envelope-from <keo@eecs.berkeley.edu>)
	id 1XkIEi-0003AH-Ey
	for dev@spark.apache.org; Fri, 31 Oct 2014 12:51:54 -0700
Received: by mail-yh0-f52.google.com with SMTP id a41so2981586yho.25
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 12:51:51 -0700 (PDT)
MIME-Version: 1.0
X-Received: by 10.170.43.78 with SMTP id 75mr12622514ykl.123.1414785111914;
 Fri, 31 Oct 2014 12:51:51 -0700 (PDT)
Received: by 10.170.45.205 with HTTP; Fri, 31 Oct 2014 12:51:51 -0700 (PDT)
In-Reply-To: <CAOhmDzfoF_4Kt9W0tOK+zRh6XmF4Uff2_a=+i=Y7USTad3gx_g@mail.gmail.com>
References: <CAOhmDzcta_vkDrByDX=JFVHdcfVqVSvOOtJTydYyf=LoNm-B0Q@mail.gmail.com>
	<CABPQxssSQ1ePa=SctOmOgdmVRCHh2vj3_ftPU_okbzRz3pJBnA@mail.gmail.com>
	<CAOhmDzcYYxowyMHJK1uf-c5Jj4A4FZJmNiW=1G1=tXt25B-64g@mail.gmail.com>
	<D0792C12.D06C%snunez@hortonworks.com>
	<CAOhmDzfoF_4Kt9W0tOK+zRh6XmF4Uff2_a=+i=Y7USTad3gx_g@mail.gmail.com>
Date: Fri, 31 Oct 2014 12:51:51 -0700
Message-ID: <CAKJXNjHN4c0aJmGZMgZ_xhvUTXVnjrzCWopeApOoRO3HEgB0BQ@mail.gmail.com>
Subject: Re: Surprising Spark SQL benchmark
From: Kay Ousterhout <keo@eecs.berkeley.edu>
To: Nicholas Chammas <nicholas.chammas@gmail.com>
Cc: Steve Nunez <snunez@hortonworks.com>, Patrick Wendell <pwendell@gmail.com>, 
	dev <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a113905b00780370506bd543e
X-Virus-Checked: Checked by ClamAV on apache.org

--001a113905b00780370506bd543e
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

There's been an effort in the AMPLab at Berkeley to set up a shared
codebase that makes it easy to run TPC-DS on SparkSQL, since it's something
we do frequently in the lab to evaluate new research.  Based on this
thread, it sounds like making this more widely-available is something that
would be useful to folks for reproducing the results published by
Databricks / Hortonworks / Cloudera / etc.; we'll share the code on the
list as soon as we're done.

-Kay

On Fri, Oct 31, 2014 at 12:45 PM, Nicholas Chammas <
nicholas.chammas@gmail.com> wrote:

> I believe that benchmark has a pending certification on it. See
> http://sortbenchmark.org under "Process".
>
> It's true they did not share enough details on the blog for readers to
> reproduce the benchmark, but they will have to share enough with the
> committee behind the benchmark in order to be certified. Given that this =
is
> a benchmark not many people will be able to reproduce due to size and
> complexity, I don't see it as a big negative that the details are not lai=
d
> out as long as there is independent certification from a third party.
>
> From what I've seen so far, the best big data benchmark anywhere is this:
> https://amplab.cs.berkeley.edu/benchmark/
>
> Is has all the details you'd expect, including hosted datasets, to allow
> anyone to reproduce the full benchmark, covering a number of systems. I
> look forward to the next update to that benchmark (a lot has changed sinc=
e
> Feb). And from what I can tell, it's produced by the same people behind
> Spark (Patrick being among them).
>
> So I disagree that the Spark community "hasn't been any better" in this
> regard.
>
> Nick
>
>
> 2014=EB=85=84 10=EC=9B=94 31=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, Steve =
Nunez<snunez@hortonworks.com>=EB=8B=98=EC=9D=B4 =EC=9E=91=EC=84=B1=ED=95=9C=
 =EB=A9=94=EC=8B=9C=EC=A7=80:
>
> > To be fair, we (Spark community) haven=E2=80=99t been any better, for e=
xample
> this
> > benchmark:
> >
> >         https://databricks.com/blog/2014/10/10/spark-petabyte-sort.html
> >
> >
> > For which no details or code have been released to allow others to
> > reproduce it. I would encourage anyone doing a Spark benchmark in futur=
e
> > to avoid the stigma of vendor reported benchmarks and publish enough
> > information and code to let others repeat the exercise easily.
> >
> >         - Steve
> >
> >
> >
> > On 10/31/14, 11:30, "Nicholas Chammas" <nicholas.chammas@gmail.com
> > <javascript:;>> wrote:
> >
> > >Thanks for the response, Patrick.
> > >
> > >I guess the key takeaways are 1) the tuning/config details are
> everything
> > >(they're not laid out here), 2) the benchmark should be reproducible
> (it's
> > >not), and 3) reach out to the relevant devs before publishing (didn't
> > >happen).
> > >
> > >Probably key takeaways for any kind of benchmark, really...
> > >
> > >Nick
> > >
> > >
> > >2014=EB=85=84 10=EC=9B=94 31=EC=9D=BC =EA=B8=88=EC=9A=94=EC=9D=BC, Pat=
rick Wendell<pwendell@gmail.com <javascript:;>>=EB=8B=98=EC=9D=B4
> > =EC=9E=91=EC=84=B1=ED=95=9C =EB=A9=94=EC=8B=9C=EC=A7=80:
> > >
> > >> Hey Nick,
> > >>
> > >> Unfortunately Citus Data didn't contact any of the Spark or Spark SQ=
L
> > >> developers when running this. It is really easy to make one system
> > >> look better than others when you are running a benchmark yourself
> > >> because tuning and sizing can lead to a 10X performance improvement.
> > >> This benchmark doesn't share the mechanism in a reproducible way.
> > >>
> > >> There are a bunch of things that aren't clear here:
> > >>
> > >> 1. Spark SQL has optimized parquet features, were these turned on?
> > >> 2. It doesn't mention computing statistics in Spark SQL, but it does
> > >> this for Impala and Parquet. Statistics allow Spark SQL to broadcast
> > >> small tables which can make a 10X difference in TPC-H.
> > >> 3. For data larger than memory, Spark SQL often performs better if y=
ou
> > >> don't call "cache", did they try this?
> > >>
> > >> Basically, a self-reported marketing benchmark like this that
> > >> *shocker* concludes this vendor's solution is the best, is not
> > >> particularly useful.
> > >>
> > >> If Citus data wants to run a credible benchmark, I'd invite them to
> > >> directly involve Spark SQL developers in the future. Until then, I
> > >> wouldn't give much credence to this or any other similar vendor
> > >> benchmark.
> > >>
> > >> - Patrick
> > >>
> > >> On Fri, Oct 31, 2014 at 10:38 AM, Nicholas Chammas
> > >> <nicholas.chammas@gmail.com <javascript:;> <javascript:;>> wrote:
> > >> > I know we don't want to be jumping at every benchmark someone post=
s
> > >>out
> > >> > there, but this one surprised me:
> > >> >
> > >> >
> http://www.citusdata.com/blog/86-making-postgresql-scale-hadoop-style
> > >> >
> > >> > This benchmark has Spark SQL failing to complete several queries i=
n
> > >>the
> > >> > TPC-H benchmark. I don't understand much about the details of
> > >>performing
> > >> > benchmarks, but this was surprising.
> > >> >
> > >> > Are these results expected?
> > >> >
> > >> > Related HN discussion here:
> > >>https://news.ycombinator.com/item?id=3D8539678
> > >> >
> > >> > Nick
> > >>
> >
> >
> >
> > --
> > CONFIDENTIALITY NOTICE
> > NOTICE: This message is intended for the use of the individual or entit=
y
> to
> > which it is addressed and may contain information that is confidential,
> > privileged and exempt from disclosure under applicable law. If the read=
er
> > of this message is not the intended recipient, you are hereby notified
> that
> > any printing, copying, dissemination, distribution, disclosure or
> > forwarding of this communication is strictly prohibited. If you have
> > received this communication in error, please contact the sender
> immediately
> > and delete it from your system. Thank You.
> >
>

--001a113905b00780370506bd543e--

From dev-return-10068-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 20:35:58 2014
Return-Path: <dev-return-10068-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 9411F1777A
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 20:35:58 +0000 (UTC)
Received: (qmail 25596 invoked by uid 500); 31 Oct 2014 20:35:51 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 25518 invoked by uid 500); 31 Oct 2014 20:35:51 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 25506 invoked by uid 99); 31 Oct 2014 20:35:50 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:35:50 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of alexbaretta@gmail.com designates 209.85.218.52 as permitted sender)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:35:45 +0000
Received: by mail-oi0-f52.google.com with SMTP id u20so6190844oif.39
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 13:35:24 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:from:date:message-id:subject:to:content-type;
        bh=+YKSrr3dy1t4zCGl3BwR54DrSAYX46syXloIlCnZ3xU=;
        b=Vt2/lklhGeSi+wklGqjYPfHtXQ/T8lnoMCCImgBDj14b1dQwcgHGYTsnUxOydlQCR1
         rT4vyeqQ+vyVyoR/TvpFj+AqPTvmn3XoywQOOrGx5iVdyhTOod2qzXVoj9yJzFVa2vn2
         COnRaLBEYQxWy7eMEKHm3XdWPvMpbzpT/F4r0Kz9jmnaby4qJiuzNp+5FR6TiY5OAjQZ
         Og732skkudgAlTLxEtt58nhJOmnQcVwI/05HGFWBqagYtSW93Y0W3oMXuQ+b2hXkAasr
         c64heGz17IgJHe/kPyOUNhAYdEYTH/lRHz+j9s/UJ+XI71PXHUtmOTV0gOfbSeiLXnu4
         vH3A==
X-Received: by 10.60.146.234 with SMTP id tf10mr22248104oeb.3.1414787724716;
 Fri, 31 Oct 2014 13:35:24 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.76.71.9 with HTTP; Fri, 31 Oct 2014 13:35:04 -0700 (PDT)
From: Alessandro Baretta <alexbaretta@gmail.com>
Date: Fri, 31 Oct 2014 13:35:04 -0700
Message-ID: <CAJc_syJ4-cHt8AqBi9VRSv9vWWnsiMOh=-4nhhdrecTeB3+L5A@mail.gmail.com>
Subject: Spark consulting
To: dev@spark.apache.org
Content-Type: multipart/alternative; boundary=047d7b5d314ec3b0670506bdef46
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b5d314ec3b0670506bdef46
Content-Type: text/plain; charset=UTF-8

Hello,

Is anyone open to do some consulting work on Spark in San Mateo?

Thanks.

Alex

--047d7b5d314ec3b0670506bdef46--

From dev-return-10069-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 20:45:33 2014
Return-Path: <dev-return-10069-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id D3A89177B2
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 20:45:33 +0000 (UTC)
Received: (qmail 51078 invoked by uid 500); 31 Oct 2014 20:45:29 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 51014 invoked by uid 500); 31 Oct 2014 20:45:29 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 51001 invoked by uid 99); 31 Oct 2014 20:45:29 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:45:29 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of javadba@gmail.com designates 209.85.220.182 as permitted sender)
Received: from [209.85.220.182] (HELO mail-vc0-f182.google.com) (209.85.220.182)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:45:02 +0000
Received: by mail-vc0-f182.google.com with SMTP id id10so3371979vcb.13
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 13:44:16 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=IYUBz54inMtRiCBXm8MoEHCYTnP46WcJuW7EcQpf3MM=;
        b=hXyQlT9zT0Obkp00tPHvJ4HlaUnrecdE+fLfRvlsucuxLVdF/c4lbD43SuBjW4PYZZ
         bSfAYYtCZMoA1/yhLe3dMe6eg1/tNqu2t/hTs4EjHoCMgQgdvP8Y2siYeO5FsCOERJy/
         G6m979LlRW2NCzNyVEKzahf8xoc+YxW026J/1V9ktyBuhI88xvzeTLKS95lBSt9w2YnF
         SJmvr5gB0GIf2JKdG2GiNeQhHm4LzJ/9ZybcMfBL4Z5rhxPbFfA+PfkTGDeyptd/D9Yw
         V4vCDAd+njOPxI+TMfTOKgoah3MBpWJVPcxJLtXP0c7FkoOqMXv0We7p7mATa5CHNSEl
         MahQ==
MIME-Version: 1.0
X-Received: by 10.221.3.195 with SMTP id nz3mr1662956vcb.43.1414788256524;
 Fri, 31 Oct 2014 13:44:16 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Fri, 31 Oct 2014 13:44:16 -0700 (PDT)
In-Reply-To: <CAJc_syJ4-cHt8AqBi9VRSv9vWWnsiMOh=-4nhhdrecTeB3+L5A@mail.gmail.com>
References: <CAJc_syJ4-cHt8AqBi9VRSv9vWWnsiMOh=-4nhhdrecTeB3+L5A@mail.gmail.com>
Date: Fri, 31 Oct 2014 13:44:16 -0700
Message-ID: <CACkSZy3NTMFa7GECsoE0VYQnA5LdfWYFeO8TLArvLyTh4Ou7sA@mail.gmail.com>
Subject: Re: Spark consulting
From: Stephen Boesch <javadba@gmail.com>
To: Alessandro Baretta <alexbaretta@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01293fe47671de0506be0fbc
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01293fe47671de0506be0fbc
Content-Type: text/plain; charset=UTF-8

May we please refrain from using spark mailing list for job inquiries.
Thanks.

2014-10-31 13:35 GMT-07:00 Alessandro Baretta <alexbaretta@gmail.com>:

> Hello,
>
> Is anyone open to do some consulting work on Spark in San Mateo?
>
> Thanks.
>
> Alex
>

--089e01293fe47671de0506be0fbc--

From dev-return-10071-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 20:50:32 2014
Return-Path: <dev-return-10071-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 95389177CF
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 20:50:32 +0000 (UTC)
Received: (qmail 62915 invoked by uid 500); 31 Oct 2014 20:50:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 62846 invoked by uid 500); 31 Oct 2014 20:50:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 62834 invoked by uid 99); 31 Oct 2014 20:50:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:50:31 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (nike.apache.org: domain of alexbaretta@gmail.com designates 209.85.218.52 as permitted sender)
Received: from [209.85.218.52] (HELO mail-oi0-f52.google.com) (209.85.218.52)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:50:05 +0000
Received: by mail-oi0-f52.google.com with SMTP id u20so6159247oif.25
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 13:48:33 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to
         :cc:content-type;
        bh=OwNttXJ30PgEJmSA84vfXKkSRkH9rTiFeaVkrqv85Rk=;
        b=afy7SxTDeSpuSW8C+OrnDw35wruAMi3bI7hwCRiyP0wvh2o1C8JCJnQroC1qeKInnz
         GRVT7fBxoXo4o3pCTqrdqTqbMEeQlGy0Rh036wACbn4BRDJJxEUpcsC8bjxMzWbvc1aI
         Ny0e4WaPFyxYfTxEh5gAP52KKMG64agMI31VdRHoo79a1dipOfkxNicP8lWVJHsYKutC
         wPZBfozLvjZ3R/Nu4TAbVSDWiBsajDKogTdXT276wyqf/nCfPgnYdDLL//fBK+Gg+Lad
         t7Be6yNlYmBoUxPnHPYV6MOAOPy/9a8HwQ+FCI1oqgGhKH5y30oHHNG7SKw8P8rot1fa
         wa4Q==
X-Received: by 10.60.245.99 with SMTP id xn3mr6462843oec.15.1414788513741;
 Fri, 31 Oct 2014 13:48:33 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.76.71.9 with HTTP; Fri, 31 Oct 2014 13:48:13 -0700 (PDT)
In-Reply-To: <CACkSZy3NTMFa7GECsoE0VYQnA5LdfWYFeO8TLArvLyTh4Ou7sA@mail.gmail.com>
References: <CAJc_syJ4-cHt8AqBi9VRSv9vWWnsiMOh=-4nhhdrecTeB3+L5A@mail.gmail.com>
 <CACkSZy3NTMFa7GECsoE0VYQnA5LdfWYFeO8TLArvLyTh4Ou7sA@mail.gmail.com>
From: Alessandro Baretta <alexbaretta@gmail.com>
Date: Fri, 31 Oct 2014 13:48:13 -0700
Message-ID: <CAJc_syJC56uXTqKNq5WO5c0OxLSbzCZRdzUXy5oPsy3uguHi2Q@mail.gmail.com>
Subject: Re: Spark consulting
To: Stephen Boesch <javadba@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a1130c512cb45bc0506be1e85
X-Virus-Checked: Checked by ClamAV on apache.org

--001a1130c512cb45bc0506be1e85
Content-Type: text/plain; charset=UTF-8

Stephen,

Sorry for being OT. On the other hand, there is no jobs@spark.apache.org,
and the LinkedIn Spark group is a desert.

Alex

On Fri, Oct 31, 2014 at 1:44 PM, Stephen Boesch <javadba@gmail.com> wrote:

> May we please refrain from using spark mailing list for job inquiries.
> Thanks.
>
> 2014-10-31 13:35 GMT-07:00 Alessandro Baretta <alexbaretta@gmail.com>:
>
> Hello,
>>
>> Is anyone open to do some consulting work on Spark in San Mateo?
>>
>> Thanks.
>>
>> Alex
>>
>
>

--001a1130c512cb45bc0506be1e85--

From dev-return-10070-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 20:50:34 2014
Return-Path: <dev-return-10070-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 61CA0177D0
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 20:50:34 +0000 (UTC)
Received: (qmail 61320 invoked by uid 500); 31 Oct 2014 20:50:24 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 61254 invoked by uid 500); 31 Oct 2014 20:50:23 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 61226 invoked by uid 99); 31 Oct 2014 20:50:23 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:50:23 +0000
X-ASF-Spam-Status: No, hits=3.9 required=10.0
	tests=HTML_MESSAGE,HTML_OBFUSCATE_20_30,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of malouf.gary@gmail.com designates 209.85.192.43 as permitted sender)
Received: from [209.85.192.43] (HELO mail-qg0-f43.google.com) (209.85.192.43)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:50:17 +0000
Received: by mail-qg0-f43.google.com with SMTP id f51so6207827qge.2
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 13:49:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:date:message-id:subject:from:to:content-type;
        bh=hhwFD6gWpU1ffc/gZpld8yAQwTH0uMePRCbxblSObZI=;
        b=pQPdkX+2irXsEs5tHU/MsUNYrQP4wxL0lILRQL3791ftUaGFtXu9XQkyIIwQakmS6n
         u7lwKjCpJXWxgZySym0kuMRYyYnRBCyL7wwXAiSgt557k0qWQyukvHxKHXS+aok7KECK
         xAJMED5BafqjGRe1iYwWS5Z1RvxASl//D5MclgG25V0EvZZDF/FK3OasOiQjhzFjaAi8
         tC/Lyuby6sd8GhiHSdR5va5LGBvR62p/T6ozf+RNhqdx3bVvxrIRKELh47Q7y2WVNpE5
         /anJjV5GchYJKaC6d9ljS2QEQ1/Wgoy2OxFldeqNNcgaqFiKt62Pow7F2atB+fF5Rp0/
         LyKQ==
MIME-Version: 1.0
X-Received: by 10.140.95.106 with SMTP id h97mr37917292qge.97.1414788596991;
 Fri, 31 Oct 2014 13:49:56 -0700 (PDT)
Received: by 10.140.29.102 with HTTP; Fri, 31 Oct 2014 13:49:56 -0700 (PDT)
Date: Fri, 31 Oct 2014 16:49:56 -0400
Message-ID: <CAGOvqiq6A5X691Ko7v-HAa4pUy3RVuw_rhqe0hoqTnT18NiMjA@mail.gmail.com>
Subject: Parquet Migrations
From: Gary Malouf <malouf.gary@gmail.com>
To: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=001a11c160eec18e710506be23df
X-Virus-Checked: Checked by ClamAV on apache.org

--001a11c160eec18e710506be23df
Content-Type: text/plain; charset=UTF-8

Outside of what is discussed here
<https://issues.apache.org/jira/browse/SPARK-3851> as a future solution, is
there any path for being able to modify a Parquet schema once some data has
been written?  This seems like the kind of thing that should make people
pause when considering whether or not to use Parquet+Spark...

--001a11c160eec18e710506be23df--

From dev-return-10072-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 20:56:17 2014
Return-Path: <dev-return-10072-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id C8FCC177F3
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 20:56:17 +0000 (UTC)
Received: (qmail 74253 invoked by uid 500); 31 Oct 2014 20:56:16 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 74181 invoked by uid 500); 31 Oct 2014 20:56:16 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 74168 invoked by uid 99); 31 Oct 2014 20:56:16 -0000
Received: from athena.apache.org (HELO athena.apache.org) (140.211.11.136)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:56:16 +0000
X-ASF-Spam-Status: No, hits=1.5 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_PASS
X-Spam-Check-By: apache.org
Received-SPF: pass (athena.apache.org: domain of javadba@gmail.com designates 209.85.220.174 as permitted sender)
Received: from [209.85.220.174] (HELO mail-vc0-f174.google.com) (209.85.220.174)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 20:56:10 +0000
Received: by mail-vc0-f174.google.com with SMTP id im17so1735464vcb.5
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 13:55:04 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:date:message-id:subject:from:to
         :cc:content-type;
        bh=BlpmHfooOjXSbNSi3YFZX10cvHkWgx4GLiCZMLDvVsI=;
        b=QvfZ0cKfGLhXoYAD227BNbGJo8l4hWnzYFkrjDxHN/1nfYNM31bZACCAhuPEIWmM4U
         qMot3LRsf4cWQ6y8erjUpOUsoxQq2tSyMwDMjYQnDt5KGfvClqAEZt1j5FVR2OjYNfsG
         c+Gempo70GKS/e6I8GlS8RfQU26NN0gJN3kf/aGw/biXnrmWmd9WtrDFFras4luQQTGu
         rnNCNKDyxx9ZwHXzg8WIoO8xSakR/5PYJarhVeUawaa2pJAWO6bDLSLyiVhXWINpFTIn
         yafNj9dnjK890GUW+PZHF2DKa/yqmDUZOQGwX+Ff48MnQ+W95agKRzH1IP3jqBU5SrFm
         3fZA==
MIME-Version: 1.0
X-Received: by 10.221.3.195 with SMTP id nz3mr1697171vcb.43.1414788904874;
 Fri, 31 Oct 2014 13:55:04 -0700 (PDT)
Received: by 10.31.129.4 with HTTP; Fri, 31 Oct 2014 13:55:04 -0700 (PDT)
In-Reply-To: <CAJc_syJC56uXTqKNq5WO5c0OxLSbzCZRdzUXy5oPsy3uguHi2Q@mail.gmail.com>
References: <CAJc_syJ4-cHt8AqBi9VRSv9vWWnsiMOh=-4nhhdrecTeB3+L5A@mail.gmail.com>
	<CACkSZy3NTMFa7GECsoE0VYQnA5LdfWYFeO8TLArvLyTh4Ou7sA@mail.gmail.com>
	<CAJc_syJC56uXTqKNq5WO5c0OxLSbzCZRdzUXy5oPsy3uguHi2Q@mail.gmail.com>
Date: Fri, 31 Oct 2014 13:55:04 -0700
Message-ID: <CACkSZy3xOMMQUBiLrFhjtjQQr847JGG4RRmvWTU4m7Tjb9abtw@mail.gmail.com>
Subject: Re: Spark consulting
From: Stephen Boesch <javadba@gmail.com>
To: Alessandro Baretta <alexbaretta@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=089e01293fe41b7dfc0506be369c
X-Virus-Checked: Checked by ClamAV on apache.org

--089e01293fe41b7dfc0506be369c
Content-Type: text/plain; charset=UTF-8

HI Alessandro,
         It is important to me and probably others as well to be able to
focus on the technical issues and not be distracted that way.
thanks

stephenb

2014-10-31 13:48 GMT-07:00 Alessandro Baretta <alexbaretta@gmail.com>:

> Stephen,
>
> Sorry for being OT. On the other hand, there is no jobs@spark.apache.org,
> and the LinkedIn Spark group is a desert.
>
> Alex
>
> On Fri, Oct 31, 2014 at 1:44 PM, Stephen Boesch <javadba@gmail.com> wrote:
>
>> May we please refrain from using spark mailing list for job inquiries.
>> Thanks.
>>
>> 2014-10-31 13:35 GMT-07:00 Alessandro Baretta <alexbaretta@gmail.com>:
>>
>> Hello,
>>>
>>> Is anyone open to do some consulting work on Spark in San Mateo?
>>>
>>> Thanks.
>>>
>>> Alex
>>>
>>
>>
>

--089e01293fe41b7dfc0506be369c--

From dev-return-10073-apmail-spark-dev-archive=spark.apache.org@spark.apache.org  Fri Oct 31 21:24:33 2014
Return-Path: <dev-return-10073-apmail-spark-dev-archive=spark.apache.org@spark.apache.org>
X-Original-To: apmail-spark-dev-archive@minotaur.apache.org
Delivered-To: apmail-spark-dev-archive@minotaur.apache.org
Received: from mail.apache.org (hermes.apache.org [140.211.11.3])
	by minotaur.apache.org (Postfix) with SMTP id 74BA4178EE
	for <apmail-spark-dev-archive@minotaur.apache.org>; Fri, 31 Oct 2014 21:24:33 +0000 (UTC)
Received: (qmail 38204 invoked by uid 500); 31 Oct 2014 21:24:31 -0000
Delivered-To: apmail-spark-dev-archive@spark.apache.org
Received: (qmail 38137 invoked by uid 500); 31 Oct 2014 21:24:31 -0000
Mailing-List: contact dev-help@spark.apache.org; run by ezmlm
Precedence: bulk
List-Help: <mailto:dev-help@spark.apache.org>
List-Unsubscribe: <mailto:dev-unsubscribe@spark.apache.org>
List-Post: <mailto:dev@spark.apache.org>
List-Id: <dev.spark.apache.org>
Delivered-To: mailing list dev@spark.apache.org
Received: (qmail 38126 invoked by uid 99); 31 Oct 2014 21:24:31 -0000
Received: from nike.apache.org (HELO nike.apache.org) (192.87.106.230)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 21:24:31 +0000
X-ASF-Spam-Status: No, hits=2.2 required=10.0
	tests=HTML_MESSAGE,RCVD_IN_DNSWL_LOW,SPF_NEUTRAL
X-Spam-Check-By: apache.org
Received-SPF: neutral (nike.apache.org: local policy)
Received: from [209.85.215.53] (HELO mail-la0-f53.google.com) (209.85.215.53)
    by apache.org (qpsmtpd/0.29) with ESMTP; Fri, 31 Oct 2014 21:24:04 +0000
Received: by mail-la0-f53.google.com with SMTP id mc6so6816847lab.26
        for <dev@spark.apache.org>; Fri, 31 Oct 2014 14:22:32 -0700 (PDT)
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20130820;
        h=x-gm-message-state:mime-version:in-reply-to:references:from:date
         :message-id:subject:to:cc:content-type;
        bh=p2YYQIBebIcKEeUDvpKbactklgCYFLhuJt7J8h1/GsE=;
        b=guygnYtGeYr5D1p1Nevyzxor81c5IATm3aM98ajgF32zKMa+vIHXjDQstTvDlBJ46e
         mjogayQl8MZTFh16vVCoZOZ85GaGiC61TaH1U4YHvEfq1fCfaqBg/CyT3HPKyCPv7S+V
         9a2P65eSuIr0BEjV0QmOn+gUVsv8xU2zQJekzF8XpjLTIfsPOJE35lY2j7gXPK1d7WJW
         nJYJRhrFVGKuuyqrzgdho5ZbsBOurxiS/Yeixv28u3eNgcLH4BVSOix0B9k9xf1EGY7Q
         AiIyk5Moy4cXJfKRuk1wvsrZgx7LXvn2MrTBN2DmcSEnwZs5ZvkUVvSQc6GlIt9Esjez
         DDkg==
X-Gm-Message-State: ALoCoQlZh07q9tnScsf1Q466m2YKBuc3HINnzPEAzPVsCpy9uT/F6CPWk0IwxqD90aNZaB2BBWpq
X-Received: by 10.112.133.138 with SMTP id pc10mr29510070lbb.48.1414790552118;
 Fri, 31 Oct 2014 14:22:32 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.39.17 with HTTP; Fri, 31 Oct 2014 14:22:11 -0700 (PDT)
In-Reply-To: <CAGOvqiq6A5X691Ko7v-HAa4pUy3RVuw_rhqe0hoqTnT18NiMjA@mail.gmail.com>
References: <CAGOvqiq6A5X691Ko7v-HAa4pUy3RVuw_rhqe0hoqTnT18NiMjA@mail.gmail.com>
From: Michael Armbrust <michael@databricks.com>
Date: Fri, 31 Oct 2014 14:22:11 -0700
Message-ID: <CAAswR-4hi=qzMKSe=TAs_2yTDfO=WZwPF3fYzZRRATUJbrO7zA@mail.gmail.com>
Subject: Re: Parquet Migrations
To: Gary Malouf <malouf.gary@gmail.com>
Cc: "dev@spark.apache.org" <dev@spark.apache.org>
Content-Type: multipart/alternative; boundary=047d7b34398e4a7c670506be9898
X-Virus-Checked: Checked by ClamAV on apache.org

--047d7b34398e4a7c670506be9898
Content-Type: text/plain; charset=UTF-8

You can't change parquet schema without reencoding the data as you need to
recalculate the footer index data.  You can manually do what SPARK-3851
<https://issues.apache.org/jira/browse/SPARK-3851> is going to do today
however.

Consider two schemas:

Old Schema: (a: Int, b: String)
New Schema, where I've dropped and added a column: (a: Int, c: Long)

parquetFile(old).registerTempTable("old")
parquetFile(new).registerTempTable("new")

sql("""
  SELECT a, b, CAST(null AS LONG) AS c  FROM old UNION ALL
  SELECT a, CAST(null AS STRING) AS b, c FROM new
""").registerTempTable("unifiedData")

Because of filter/column pushdown past UNIONs this should executed as
desired even if you write more complicated queries on top of
"unifiedData".  Its a little onerous but should work for now.  This can
also support things like column renaming which would be much harder to do
automatically.

On Fri, Oct 31, 2014 at 1:49 PM, Gary Malouf <malouf.gary@gmail.com> wrote:

> Outside of what is discussed here
> <https://issues.apache.org/jira/browse/SPARK-3851> as a future solution,
> is
> there any path for being able to modify a Parquet schema once some data has
> been written?  This seems like the kind of thing that should make people
> pause when considering whether or not to use Parquet+Spark...
>

--047d7b34398e4a7c670506be9898--


Nicholas Chammas <nicholas.chammas@gmail.com>,"Sun, 01 Mar 2015 22:59:56 +0000",spark-ec2 default to Hadoop 2,Spark dev list <dev@spark.apache.org>,"https://github.com/apache/spark/blob/fd8d283eeb98e310b1e85ef8c3a8af9e547ab5e0/ec2/spark_ec2.py#L162-L164

Is there any reason we shouldn't update the default Hadoop major version in
spark-ec2 to 2?

Nick
"
Shivaram Venkataraman <shivaram@eecs.berkeley.edu>,"Sun, 1 Mar 2015 15:14:23 -0800",Re: spark-ec2 default to Hadoop 2,Nicholas Chammas <nicholas.chammas@gmail.com>,"spark-ec2 is not a full Hadoop 2 distribution -- Its more of a hybrid
Hadoop version built using CDH4 (it uses HDFS 2, but not YARN AFAIK).

Also our default Hadoop version in the Spark build is still 1.0.4 [1], so
it makes sense to stick to that in spark-ec2 as well ?

[1] https://github.com/apache/spark/blob/master/pom.xml#L122

Thanks
Shivaram


"
Patrick Wendell <pwendell@gmail.com>,"Sun, 1 Mar 2015 15:40:29 -0800",Re: spark-ec2 default to Hadoop 2,Shivaram Venkataraman <shivaram@eecs.berkeley.edu>,"Yeah calling it Hadoop 2 was a very bad naming choice (of mine!), this
was back when CDH4 was the only real distribution available with some
of the newer Hadoop API's and packaging.

I think to not surprise people using this, it's best to keep v1 as the
default. Overall, we try not to change default values too often to
make upgrading easy for people.

- Patrick


---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Mon, 2 Mar 2015 07:49:46 +0000",Re: spark-ec2 default to Hadoop 2,Nicholas Chammas <nicholas.chammas@gmail.com>,"I agree with that. My anecdotal impression is that Hadoop 1.x usage
out there is maybe a couple percent, and so we should shift towards
2.x at least as defaults.


---------------------------------------------------------------------


"
Wail <w.alkowaileet@cces-kacst-mit.org>,"Mon, 2 Mar 2015 02:55:56 -0700 (MST)",Is SparkSQL optimizer aware of the needed data after the query?,dev@spark.apache.org,"Dears,

I'm just curious about the complexity of the query optimizer. Can the
optimizer evaluates what after the SQL? maybe it's a stupid question ,, but
here is an example to show the case:

val teenagers = sqlContext.sql(""SELECT * FROM people WHERE age >= 13 AND age
<= 19"")

if(condition)
{
    teenagers.map(t => ""Name: "" + t(0)).collect().foreach(println)
}
else
{
    teenagers.map(t => ""Age: "" + t(1)).collect().foreach(println)
}

As for instance ... is the optimizer aware that I need only one column and
pushes down the projection to bring only one  as needed?

Thanks!




--

---------------------------------------------------------------------


"
Dirceu Semighini Filho <dirceu.semighini@gmail.com>,"Mon, 2 Mar 2015 10:16:50 -0300",Re: How to create a Row from a List or Array in Spark using Scala,"""dev@spark.apache.org"" <dev@spark.apache.org>","You can use the parallelize method:

val data = List(
  Row(1, 5, ""vlr1"", 10.5),
  Row(2, 1, ""vl3"", 0.1),
  Row(3, 8, ""vl3"", 10.0),
  Row(4, 1, ""vl4"", 1.0))
val rdd = sc.parallelize(data)

Here I'm using a list of Rows, but you could use it with a list of
other kind of object, like this:


val x = sc.parallelize(List(""a"",""b"",""c""))

Where x is an RDD[String] and sc is the spark context.


Regards,

Dirceu


2015-02-28 5:37 GMT-03:00 DEVAN M.S. <msdevanms@gmail.com>:

"
Shivaram Venkataraman <shivaram@eecs.berkeley.edu>,"Mon, 2 Mar 2015 09:22:00 -0800",Re: spark-ec2 default to Hadoop 2,Sean Owen <sowen@cloudera.com>,"FWIW there is a PR open to add support for Hadoop 2.4 to spark-ec2 scripts
at https://github.com/mesos/spark-ec2/pull/77 -- But it hasnt' received
much review or testing to be merged.

Thanks
Shivaram


"
Xiangrui Meng <mengxr@gmail.com>,"Mon, 2 Mar 2015 11:42:06 -0800",Re: Using CUDA within Spark / boosting linear algebra,Sam Halliday <sam.halliday@gmail.com>,"te:
s

There are two shared libraries in this hybrid setup. nvblas.so must be
loaded before libblas.so to intercept level 3 routines using GPU. More
details are at: http://docs.nvidia.com/cuda/nvblas/index.html#Usage

nd
he
g
n
h
n
s
 =
s
y
as
of
st
en
m
n
he
o
U
,
he
e
e,
R.
lk
50uZHl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
.
Us
S
as-yum-repo==netlib-cublas>netlib-blas>f2jblas
HUMx378T9J5r7kwKSPkY/edit?usp=sharing
gh
---------+
6
11
cally
t
alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
ly
n
ay
lto:
ark.apache.org<mailto:dev@spark.apache.org>>
s
e
re.
nd
e
u
y
alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
a
LAS,
to
lto:
ark.apache.org<mailto:dev@spark.apache.org>>
r
alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
x
---------+
lto:
ark.apache.org<mailto:dev@spark.apache.org>>
er
it
alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
sentation
r
near algebra, it
lto:
ark.apache.org<mailto:dev@spark.apache.org>>
an
e
me
e
or
alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>
Do
ry
ra
lto:
n.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
ark.apache.org<mailto:dev@spark.apache.org>><mailto:
ark.apache.org<mailto:dev@spark.apache.org>>>
U
k
nt
alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>
).
.
d
g
s
------
pache.org><mailto:
pache.org>><mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org>
@spark.apache.org>>>
lto:
ilto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:

---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Mon, 2 Mar 2015 21:04:55 +0000",RE: Using CUDA within Spark / boosting linear algebra,"Xiangrui Meng <mengxr@gmail.com>, Sam Halliday <sam.halliday@gmail.com>","Hi Xiangrui,

Thanks for the link, I am currently trying to use nvblas. It seems that netlib wrappers are implemented with C-BLAS interface and nvblas does not have c-blas. I wonder how it is going to work. I'll keep you updated.

Alexander

-----Original Message-----
From: Xiangrui Meng [mailto:mengxr@gmail.com] 
Sent: Monday, March 02, 2015 11:42 AM
To: Sam Halliday
Cc: Joseph Bradley; Ulanov, Alexander; dev; Evan R. Sparks
Subject: Re: Using CUDA within Spark / boosting linear algebra

On Fri, Feb 27, 2015 at 12:33 PM, Sam Halliday <sam.halliday@gmail.com> wrote:
> Also, check the JNILoader output.
>
> Remember, for netlib-java to use your system libblas all you need to 
> do is setup libblas.so.3 like any native application would expect.
>
> I haven't ever used the cublas ""real BLAS""  implementation, so I'd be 
> interested to hear about this. Do an 'ldd /usr/lib/libblas.so.3' to 
> check that all the runtime links are in order.
>

There are two shared libraries in this hybrid setup. nvblas.so must be loaded before libblas.so to intercept level 3 routines using GPU. More details are at: http://docs.nvidia.com/cuda/nvblas/index.html#Usage

> Btw, I have some DGEMM wrappers in my netlib-java performance 
> module... and I also planned to write more in MultiBLAS (until I 
> mothballed the project for the hardware to catch up, which is probably 
> has and now I just need a reason to look at it)
>
> On 27 Feb 2015 20:26, ""Xiangrui Meng"" <mengxr@gmail.com> wrote:
>>
>> Hey Sam,
>>
>> The running times are not ""big O"" estimates:
>>
>> > The CPU version finished in 12 seconds.
>> > The CPU->GPU->CPU version finished in 2.2 seconds.
>> > The GPU version finished in 1.7 seconds.
>>
>> I think there is something wrong with the netlib/cublas combination.
>> Sam already mentioned that cuBLAS doesn't implement the CPU BLAS 
>> interfaces. I checked the CUDA doc and it seems that to use GPU BLAS 
>> through the CPU BLAS interface we need to use NVBLAS, which 
>> intercepts some Level 3 CPU BLAS calls (including GEMM). So we need 
>> to load nvblas.so first and then some CPU BLAS library in JNI. I 
>> wonder whether the setup was correct.
>>
>> Alexander, could you check whether GPU is used in the netlib-cublas 
>> experiments? You can tell it by watching CPU/GPU usage.
>>
>> Best,
>> Xiangrui
>>
>> On Thu, Feb 26, 2015 at 10:47 PM, Sam Halliday 
>> <sam.halliday@gmail.com>
>> wrote:
>> > Don't use ""big O"" estimates, always measure. It used to work back 
>> > in the days when double multiplication was a bottleneck. The 
>> > computation cost is effectively free on both the CPU and GPU and 
>> > you're seeing pure copying costs. Also, I'm dubious that cublas is 
>> > doing what you think it is. Can you link me to the source code for 
>> > DGEMM?
>> >
>> > I show all of this in my talk, with explanations, I can't stress 
>> > enough how much I recommend that you watch it if you want to 
>> > understand high performance hardware acceleration for linear 
>> > algebra :-)
>> >
>> > On 27 Feb 2015 01:42, ""Xiangrui Meng"" <mengxr@gmail.com> wrote:
>> >>
>> >> The copying overhead should be quadratic on n, while the 
>> >> computation cost is cubic on n. I can understand that 
>> >> netlib-cublas is slower than netlib-openblas on small problems. 
>> >> But I'm surprised to see that it is still 20x slower on 
>> >> 10000x10000. I did the following on a g2.2xlarge instance with BIDMat:
>> >>
>> >> val n = 10000
>> >>
>> >> val f = rand(n, n)
>> >> flip; f*f; val rf = flop
>> >>
>> >> flip; val g = GMat(n, n); g.copyFrom(f); (g*g).toFMat(null); val 
>> >> rg = flop
>> >>
>> >> flip; g*g; val rgg = flop
>> >>
>> >> The CPU version finished in 12 seconds.
>> >> The CPU->GPU->CPU version finished in 2.2 seconds.
>> >> The GPU version finished in 1.7 seconds.
>> >>
>> >> I'm not sure whether my CPU->GPU->CPU code simulates the 
>> >> netlib-cublas path. But based on the result, the data copying 
>> >> overhead is definitely not as big as 20x at n = 10000.
>> >>
>> >> Best,
>> >> Xiangrui
>> >>
>> >>
>> >> On Thu, Feb 26, 2015 at 2:21 PM, Sam Halliday 
>> >> <sam.halliday@gmail.com>
>> >> wrote:
>> >> > I've had some email exchanges with the author of BIDMat: it does 
>> >> > exactly what you need to get the GPU benefit and writes higher 
>> >> > level algorithms entirely in the GPU kernels so that the memory 
>> >> > stays there as long as possible. The restriction with this 
>> >> > approach is that it is only offering high-level algorithms so is 
>> >> > not a toolkit for applied mathematics research and development 
>> >> > --- but it works well as a toolkit for higher level analysis 
>> >> > (e.g. for analysts and practitioners).
>> >> >
>> >> > I believe BIDMat's approach is the best way to get performance 
>> >> > out of GPU hardware at the moment but I also have strong 
>> >> > evidence to suggest that the hardware will catch up and the 
>> >> > memory transfer costs between CPU/GPU will disappear meaning 
>> >> > that there will be no need for custom GPU kernel 
>> >> > implementations. i.e. please continue to use BLAS primitives 
>> >> > when writing new algorithms and only go to the GPU for an 
>> >> > alternative optimised implementation.
>> >> >
>> >> > Note that CUDA and cuBLAS are *not* BLAS. They are BLAS-like, 
>> >> > and offer an API that looks like BLAS but takes pointers to 
>> >> > special regions in the GPU memory region. Somebody has written a 
>> >> > wrapper around CUDA to create a proper BLAS library but it only 
>> >> > gives marginal performance over the CPU because of the memory 
>> >> > transfer overhead.
>> >> >
>> >> > This slide from my talk
>> >> >
>> >> >   http://fommil.github.io/scalax14/#/11/2
>> >> >
>> >> > says it all. X axis is matrix size, Y axis is logarithmic time 
>> >> > to do DGEMM. Black line is the ""cheating"" time for the GPU and 
>> >> > the green line is after copying the memory to/from the GPU 
>> >> > memory. APUs have the potential to eliminate the green line.
>> >> >
>> >> > Best regards,
>> >> > Sam
>> >> >
>> >> >
>> >> >
>> >> > ""Ulanov, Alexander"" <alexander.ulanov@hp.com> writes:
>> >> >
>> >> >> Evan, thank you for the summary. I would like to add some more 
>> >> >> observations. The GPU that I used is 2.5 times cheaper than the 
>> >> >> CPU
>> >> >> ($250 vs
>> >> >> $100). They both are 3 years old. I've also did a small test 
>> >> >> with modern hardware, and the new GPU nVidia Titan was slightly 
>> >> >> more than 1 order of magnitude faster than Intel E5-2650 v2 for 
>> >> >> the same tests. However, it costs as much as CPU ($1200). My 
>> >> >> takeaway is that GPU is making a better price/value progress.
>> >> >>
>> >> >>
>> >> >>
>> >> >> Xiangrui, I was also surprised that BIDMat-cuda was faster than 
>> >> >> netlib-cuda and the most reasonable explanation is that it 
>> >> >> holds the result in GPU memory, as Sam suggested. At the same 
>> >> >> time, it is OK because you can copy the result back from GPU 
>> >> >> only when needed. However, to be sure, I am going to ask the 
>> >> >> developer of BIDMat on his upcoming talk.
>> >> >>
>> >> >>
>> >> >>
>> >> >> Best regards, Alexander
>> >> >>
>> >> >>
>> >> >> From: Sam Halliday [mailto:sam.halliday@gmail.com]
>> >> >> Sent: Thursday, February 26, 2015 1:56 PM
>> >> >> To: Xiangrui Meng
>> >> >> Cc: dev@spark.apache.org; Joseph Bradley; Ulanov, Alexander; Evan R.
>> >> >> Sparks
>> >> >> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >> >>
>> >> >>
>> >> >> Btw, I wish people would stop cheating when comparing CPU and 
>> >> >> GPU timings for things like matrix multiply :-P
>> >> >>
>> >> >> Please always compare apples with apples and include the time 
>> >> >> it takes to set up the matrices, send it to the processing 
>> >> >> unit, doing the calculation AND copying it back to where you 
>> >> >> need to see the results.
>> >> >>
>> >> >> Ignoring this method will make you believe that your GPU is 
>> >> >> thousands of times faster than it really is. Again, jump to the 
>> >> >> end of my talk for graphs and more discussion....  especially 
>> >> >> the bit about me being keen on funding to investigate APU 
>> >> >> hardware further ;-) (I believe it will solve the
>> >> >> problem)
>> >> >> On 26 Feb 2015 21:16, ""Xiangrui Meng""
>> >> >> <mengxr@gmail.com<mailto:mengxr@gmail.com>> wrote:
>> >> >> Hey Alexander,
>> >> >>
>> >> >> I don't quite understand the part where netlib-cublas is about 
>> >> >> 20x slower than netlib-openblas. What is the overhead of using 
>> >> >> a GPU BLAS with netlib-java?
>> >> >>
>> >> >> CC'ed Sam, the author of netlib-java.
>> >> >>
>> >> >> Best,
>> >> >> Xiangrui
>> >> >>
>> >> >> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley 
>> >> >> <joseph@databricks.com<mailto:joseph@databricks.com>> wrote:
>> >> >>> Better documentation for linking would be very helpful!  
>> >> >>> Here's a
>> >> >>> JIRA:
>> >> >>> https://issues.apache.org/jira/browse/SPARK-6019
>> >> >>>
>> >> >>>
>> >> >>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks 
>> >> >>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
>> >> >>> wrote:
>> >> >>>
>> >> >>>> Thanks for compiling all the data and running these 
>> >> >>>> benchmarks, Alex.
>> >> >>>> The
>> >> >>>> big takeaways here can be seen with this chart:
>> >> >>>>
>> >> >>>>
>> >> >>>>
>> >> >>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4
>> >> >>>> StF50uZHl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interac
>> >> >>>> tive
>> >> >>>>
>> >> >>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>> >> >>>> BIDMat+GPU) can provide substantial (but less than an order 
>> >> >>>> BIDMat+of
>> >> >>>> magnitude)
>> >> >>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL 
>> >> >>>> or
>> >> >>>> netlib-java+openblas-compiled).
>> >> >>>> 2) A poorly tuned CPU implementation can be 1-2 orders of 
>> >> >>>> magnitude worse than a well-tuned CPU implementation, 
>> >> >>>> particularly for larger matrices.
>> >> >>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib 
>> >> >>>> - this basically agrees with the authors own benchmarks (
>> >> >>>> https://github.com/fommil/netlib-java)
>> >> >>>>
>> >> >>>> I think that most of our users are in a situation where using 
>> >> >>>> GPUs may not be practical - although we could consider having 
>> >> >>>> a good GPU backend available as an option. However, *ALL* 
>> >> >>>> users of MLlib could benefit (potentially tremendously) from 
>> >> >>>> using a well-tuned CPU-based BLAS implementation. Perhaps we 
>> >> >>>> should consider updating the mllib guide with a more complete 
>> >> >>>> section for enabling high performance binaries on OSX and 
>> >> >>>> Linux? Or better, figure out a way for the system to fetch 
>> >> >>>> these automatically.
>> >> >>>>
>> >> >>>> - Evan
>> >> >>>>
>> >> >>>>
>> >> >>>>
>> >> >>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander < 
>> >> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> >> >>>>
>> >> >>>>> Just to summarize this thread, I was finally able to make 
>> >> >>>>> all performance comparisons that we discussed. It turns out 
>> >> >>>>> that:
>> >> >>>>> BIDMat-cublas>>BIDMat
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yu
>> >> >>>>> m-repo==netlib-cublas>netlib-blas>f2jblas
>> >> >>>>>
>> >> >>>>> Below is the link to the spreadsheet with full results.
>> >> >>>>>
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeo
>> >> >>>>> uQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing
>> >> >>>>>
>> >> >>>>> One thing still needs exploration: does BIDMat-cublas 
>> >> >>>>> perform copying to/from machine’s RAM?
>> >> >>>>>
>> >> >>>>> -----Original Message-----
>> >> >>>>> From: Ulanov, Alexander
>> >> >>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>> >> >>>>> To: Evan R. Sparks
>> >> >>>>> Cc: Joseph Bradley;
>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>> >> >>>>> Subject: RE: Using CUDA within Spark / boosting linear 
>> >> >>>>> algebra
>> >> >>>>>
>> >> >>>>> Thanks, Evan! It seems that ticket was marked as duplicate 
>> >> >>>>> though the original one discusses slightly different topic. 
>> >> >>>>> I was able to link netlib with MKL from BIDMat binaries. 
>> >> >>>>> Indeed, MKL is statically linked inside a 60MB library.
>> >> >>>>>
>> >> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>> >> >>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas 
>> >> >>>>> Breeze+|
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> +-----------------------------------------------------------------------+
>> >> >>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 
>> >> >>>>> |0,002556
>> >> >>>>> |
>> >> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 
>> >> >>>>> |0,51803557
>> >> >>>>> |1,638475459 |
>> >> >>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 
>> >> >>>>> ||445,0935211
>> >> >>>>> |
>> >> >>>>> 1569,233228 |
>> >> >>>>>
>> >> >>>>> It turn out that pre-compiled MKL is faster than precompiled 
>> >> >>>>> OpenBlas on my machine. Probably, I’ll add two more columns 
>> >> >>>>> with locally compiled openblas and cuda.
>> >> >>>>>
>> >> >>>>> Alexander
>> >> >>>>>
>> >> >>>>> From: Evan R. Sparks
>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>]
>> >> >>>>> Sent: Monday, February 09, 2015 6:06 PM
>> >> >>>>> To: Ulanov, Alexander
>> >> >>>>> Cc: Joseph Bradley;
>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >> >>>>>
>> >> >>>>> Great - perhaps we can move this discussion off-list and onto a
>> >> >>>>> JIRA
>> >> >>>>> ticket? (Here's one:
>> >> >>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>> >> >>>>>
>> >> >>>>> It seems like this is going to be somewhat exploratory for a
>> >> >>>>> while
>> >> >>>>> (and
>> >> >>>>> there's probably only a handful of us who really care about fast
>> >> >>>>> linear
>> >> >>>>> algebra!)
>> >> >>>>>
>> >> >>>>> - Evan
>> >> >>>>>
>> >> >>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
>> >> >>>>> wrote:
>> >> >>>>> Hi Evan,
>> >> >>>>>
>> >> >>>>> Thank you for explanation and useful link. I am going to build
>> >> >>>>> OpenBLAS,
>> >> >>>>> link it with Netlib-java and perform benchmark again.
>> >> >>>>>
>> >> >>>>> Do I understand correctly that BIDMat binaries contain statically
>> >> >>>>> linked
>> >> >>>>> Intel MKL BLAS? It might be the reason why I am able to run
>> >> >>>>> BIDMat
>> >> >>>>> not
>> >> >>>>> having MKL BLAS installed on my server. If it is true, I wonder
>> >> >>>>> if
>> >> >>>>> it is OK
>> >> >>>>> because Intel sells this library. Nevertheless, it seems that in
>> >> >>>>> my
>> >> >>>>> case
>> >> >>>>> precompiled MKL BLAS performs better than precompiled OpenBLAS
>> >> >>>>> given
>> >> >>>>> that
>> >> >>>>> BIDMat and Netlib-java are supposed to be on par with JNI
>> >> >>>>> overheads.
>> >> >>>>>
>> >> >>>>> Though, it might be interesting to link Netlib-java with Intel
>> >> >>>>> MKL,
>> >> >>>>> as
>> >> >>>>> you suggested. I wonder, are John Canny (BIDMat) and Sam Halliday
>> >> >>>>> (Netlib-java) interested to compare their libraries.
>> >> >>>>>
>> >> >>>>> Best regards, Alexander
>> >> >>>>>
>> >> >>>>> From: Evan R. Sparks
>> >> >>>>>
>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >> >>>>> Sent: Friday, February 06, 2015 5:58 PM
>> >> >>>>>
>> >> >>>>> To: Ulanov, Alexander
>> >> >>>>> Cc: Joseph Bradley;
>> >> >>>>>
>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >> >>>>>
>> >> >>>>> I would build OpenBLAS yourself, since good BLAS performance
>> >> >>>>> comes
>> >> >>>>> from
>> >> >>>>> getting cache sizes, etc. set up correctly for your particular
>> >> >>>>> hardware -
>> >> >>>>> this is often a very tricky process (see, e.g. ATLAS), but we
>> >> >>>>> found
>> >> >>>>> that on
>> >> >>>>> relatively modern Xeon chips, OpenBLAS builds quickly and yields
>> >> >>>>> performance competitive with MKL.
>> >> >>>>>
>> >> >>>>> To make sure the right library is getting used, you have to make
>> >> >>>>> sure
>> >> >>>>> it's first on the search path - export
>> >> >>>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>> >> >>>>>
>> >> >>>>> For some examples of getting netlib-java setup on an ec2 node and
>> >> >>>>> some
>> >> >>>>> example benchmarking code we ran a while back, see:
>> >> >>>>> https://github.com/shivaram/matrix-bench
>> >> >>>>>
>> >> >>>>> In particular - build-openblas-ec2.sh shows you how to build the
>> >> >>>>> library
>> >> >>>>> and set up symlinks correctly, and scala/run-netlib.sh shows you
>> >> >>>>> how
>> >> >>>>> to get
>> >> >>>>> the path setup and get that library picked up by netlib-java.
>> >> >>>>>
>> >> >>>>> In this way - you could probably get cuBLAS set up to be used by
>> >> >>>>> netlib-java as well.
>> >> >>>>>
>> >> >>>>> - Evan
>> >> >>>>>
>> >> >>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
>> >> >>>>> wrote:
>> >> >>>>> Evan, could you elaborate on how to force BIDMat and netlib-java
>> >> >>>>> to
>> >> >>>>> force
>> >> >>>>> loading the right blas? For netlib, I there are few JVM flags,
>> >> >>>>> such
>> >> >>>>> as
>> >> >>>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS,
>> >> >>>>> so
>> >> >>>>> I can
>> >> >>>>> force it to use Java implementation. Not sure I understand how to
>> >> >>>>> force use
>> >> >>>>> a specific blas (not specific wrapper for blas).
>> >> >>>>>
>> >> >>>>> Btw. I have installed openblas (yum install openblas), so I
>> >> >>>>> suppose
>> >> >>>>> that
>> >> >>>>> netlib is using it.
>> >> >>>>>
>> >> >>>>> From: Evan R. Sparks
>> >> >>>>>
>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >> >>>>> Sent: Friday, February 06, 2015 5:19 PM
>> >> >>>>> To: Ulanov, Alexander
>> >> >>>>> Cc: Joseph Bradley;
>> >> >>>>>
>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>> >> >>>>>
>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >> >>>>>
>> >> >>>>> Getting breeze to pick up the right blas library is critical for
>> >> >>>>> performance. I recommend using OpenBLAS (or MKL, if you already
>> >> >>>>> have
>> >> >>>>> it).
>> >> >>>>> It might make sense to force BIDMat to use the same underlying
>> >> >>>>> BLAS
>> >> >>>>> library
>> >> >>>>> as well.
>> >> >>>>>
>> >> >>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
>> >> >>>>> wrote:
>> >> >>>>> Hi Evan, Joseph
>> >> >>>>>
>> >> >>>>> I did few matrix multiplication test and BIDMat seems to be ~10x
>> >> >>>>> faster
>> >> >>>>> than netlib-java+breeze (sorry for weird table formatting):
>> >> >>>>>
>> >> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
>> >> >>>>> native_system_linux_x86-64|
>> >> >>>>> Breeze+Netlib-java f2jblas |
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> +-----------------------------------------------------------------------+
>> >> >>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>> >> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>> >> >>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 |
>> >> >>>>> 1569,233228 |
>> >> >>>>>
>> >> >>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM,
>> >> >>>>> Fedora
>> >> >>>>> 19
>> >> >>>>> Linux, Scala 2.11.
>> >> >>>>>
>> >> >>>>> Later I will make tests with Cuda. I need to install new Cuda
>> >> >>>>> version for
>> >> >>>>> this purpose.
>> >> >>>>>
>> >> >>>>> Do you have any ideas why breeze-netlib with native blas is so
>> >> >>>>> much
>> >> >>>>> slower than BIDMat MKL?
>> >> >>>>>
>> >> >>>>> Best regards, Alexander
>> >> >>>>>
>> >> >>>>> From: Joseph Bradley
>> >> >>>>>
>> >> >>>>> [mailto:joseph@databricks.com<mailto:joseph@databricks.com><mailto:
>> >> >>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>> >> >>>>> Sent: Thursday, February 05, 2015 5:29 PM
>> >> >>>>> To: Ulanov, Alexander
>> >> >>>>> Cc: Evan R. Sparks;
>> >> >>>>>
>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >> >>>>>
>> >> >>>>> Hi Alexander,
>> >> >>>>>
>> >> >>>>> Using GPUs with Spark would be very exciting.  Small comment:
>> >> >>>>> Concerning
>> >> >>>>> your question earlier about keeping data stored on the GPU rather
>> >> >>>>> than
>> >> >>>>> having to move it between main memory and GPU memory on each
>> >> >>>>> iteration, I
>> >> >>>>> would guess this would be critical to getting good performance.
>> >> >>>>> If
>> >> >>>>> you
>> >> >>>>> could do multiple local iterations before aggregating results,
>> >> >>>>> then
>> >> >>>>> the
>> >> >>>>> cost of data movement to the GPU could be amortized (and I
>> >> >>>>> believe
>> >> >>>>> that is
>> >> >>>>> done in practice).  Having Spark be aware of the GPU and using it
>> >> >>>>> as
>> >> >>>>> another part of memory sounds like a much bigger undertaking.
>> >> >>>>>
>> >> >>>>> Joseph
>> >> >>>>>
>> >> >>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>
>> >> >>>>> wrote:
>> >> >>>>> Thank you for explanation! I’ve watched the BIDMach presentation
>> >> >>>>> by
>> >> >>>>> John
>> >> >>>>> Canny and I am really inspired by his talk and comparisons with
>> >> >>>>> Spark MLlib.
>> >> >>>>>
>> >> >>>>> I am very interested to find out what will be better within
>> >> >>>>> Spark:
>> >> >>>>> BIDMat
>> >> >>>>> or netlib-java with CPU or GPU natives. Could you suggest a fair
>> >> >>>>> way
>> >> >>>>> to
>> >> >>>>> benchmark them? Currently I do benchmarks on artificial neural
>> >> >>>>> networks in
>> >> >>>>> batch mode. While it is not a “pure” test of linear algebra, it
>> >> >>>>> involves
>> >> >>>>> some other things that are essential to machine learning.
>> >> >>>>>
>> >> >>>>> From: Evan R. Sparks
>> >> >>>>>
>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >> >>>>> Sent: Thursday, February 05, 2015 1:29 PM
>> >> >>>>> To: Ulanov, Alexander
>> >> >>>>> Cc:
>> >> >>>>>
>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >> >>>>>
>> >> >>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>> >> >>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due
>> >> >>>>> to
>> >> >>>>> data
>> >> >>>>> layout and fewer levels of indirection - it's definitely a
>> >> >>>>> worthwhile
>> >> >>>>> experiment to run. The main speedups I've seen from using it come
>> >> >>>>> from
>> >> >>>>> highly optimized GPU code for linear algebra. I know that in the
>> >> >>>>> past Canny
>> >> >>>>> has gone as far as to write custom GPU kernels for
>> >> >>>>> performance-critical
>> >> >>>>> regions of code.[1]
>> >> >>>>>
>> >> >>>>> BIDMach is highly optimized for single node performance or
>> >> >>>>> performance on
>> >> >>>>> small clusters.[2] Once data doesn't fit easily in GPU memory (or
>> >> >>>>> can be
>> >> >>>>> batched in that way) the performance tends to fall off. Canny
>> >> >>>>> argues
>> >> >>>>> for
>> >> >>>>> hardware/software codesign and as such prefers machine
>> >> >>>>> configurations that
>> >> >>>>> are quite different than what we find in most commodity cluster
>> >> >>>>> nodes -
>> >> >>>>> e.g. 10 disk cahnnels and 4 GPUs.
>> >> >>>>>
>> >> >>>>> In contrast, MLlib was designed for horizontal scalability on
>> >> >>>>> commodity
>> >> >>>>> clusters and works best on very big datasets - order of
>> >> >>>>> terabytes.
>> >> >>>>>
>> >> >>>>> For the most part, these projects developed concurrently to
>> >> >>>>> address
>> >> >>>>> slightly different use cases. That said, there may be bits of
>> >> >>>>> BIDMach we
>> >> >>>>> could repurpose for MLlib - keep in mind we need to be careful
>> >> >>>>> about
>> >> >>>>> maintaining cross-language compatibility for our Java and
>> >> >>>>> Python-users,
>> >> >>>>> though.
>> >> >>>>>
>> >> >>>>> - Evan
>> >> >>>>>
>> >> >>>>> [1] - http://arxiv.org/abs/1409.5402
>> >> >>>>> [2] - http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>> >> >>>>>
>> >> >>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>
>> >> >>>>> wrote:
>> >> >>>>> Hi Evan,
>> >> >>>>>
>> >> >>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do
>> >> >>>>> you
>> >> >>>>> know what makes them faster than netlib-java?
>> >> >>>>>
>> >> >>>>> The same group has BIDMach library that implements machine
>> >> >>>>> learning.
>> >> >>>>> For
>> >> >>>>> some examples they use Caffe convolutional neural network library
>> >> >>>>> owned by
>> >> >>>>> another group in Berkeley. Could you elaborate on how these all
>> >> >>>>> might be
>> >> >>>>> connected with Spark Mllib? If you take BIDMat for linear algebra
>> >> >>>>> why don’t
>> >> >>>>> you take BIDMach for optimization and learning?
>> >> >>>>>
>> >> >>>>> Best regards, Alexander
>> >> >>>>>
>> >> >>>>> From: Evan R. Sparks
>> >> >>>>>
>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>> >> >>>>> Sent: Thursday, February 05, 2015 12:09 PM
>> >> >>>>> To: Ulanov, Alexander
>> >> >>>>> Cc:
>> >> >>>>>
>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>>
>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >> >>>>>
>> >> >>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU
>> >> >>>>> blas in
>> >> >>>>> many cases.
>> >> >>>>>
>> >> >>>>> You might consider taking a look at the codepaths that BIDMat (
>> >> >>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
>> >> >>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work
>> >> >>>>> optimizing
>> >> >>>>> to make this work really fast from Scala. I've run it on my
>> >> >>>>> laptop
>> >> >>>>> and
>> >> >>>>> compared to MKL and in certain cases it's 10x faster at matrix
>> >> >>>>> multiply.
>> >> >>>>> There are a lot of layers of indirection here and you really want
>> >> >>>>> to
>> >> >>>>> avoid
>> >> >>>>> data copying as much as possible.
>> >> >>>>>
>> >> >>>>> We could also consider swapping out BIDMat for Breeze, but that
>> >> >>>>> would be
>> >> >>>>> a big project and if we can figure out how to get breeze+cublas
>> >> >>>>> to
>> >> >>>>> comparable performance that would be a big win.
>> >> >>>>>
>> >> >>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>
>> >> >>>>> wrote:
>> >> >>>>> Dear Spark developers,
>> >> >>>>>
>> >> >>>>> I am exploring how to make linear algebra operations faster
>> >> >>>>> within
>> >> >>>>> Spark.
>> >> >>>>> One way of doing this is to use Scala Breeze library that is
>> >> >>>>> bundled
>> >> >>>>> with
>> >> >>>>> Spark. For matrix operations, it employs Netlib-java that has a
>> >> >>>>> Java
>> >> >>>>> wrapper for BLAS (basic linear algebra subprograms) and LAPACK
>> >> >>>>> native
>> >> >>>>> binaries if they are available on the worker node. It also has
>> >> >>>>> its
>> >> >>>>> own
>> >> >>>>> optimized Java implementation of BLAS. It is worth mentioning,
>> >> >>>>> that
>> >> >>>>> native
>> >> >>>>> binaries provide better performance only for BLAS level 3, i.e.
>> >> >>>>> matrix-matrix operations or general matrix multiplication (GEMM).
>> >> >>>>> This is
>> >> >>>>> confirmed by GEMM test on Netlib-java page
>> >> >>>>> https://github.com/fommil/netlib-java. I also confirmed it with
>> >> >>>>> my
>> >> >>>>> experiments with training of artificial neural network
>> >> >>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>> >> >>>>> However, I would like to boost performance more.
>> >> >>>>>
>> >> >>>>> GPU is supposed to work fast with linear algebra and there is
>> >> >>>>> Nvidia
>> >> >>>>> CUDA
>> >> >>>>> implementation of BLAS, called cublas. I have one Linux server
>> >> >>>>> with
>> >> >>>>> Nvidia
>> >> >>>>> GPU and I was able to do the following. I linked cublas (instead
>> >> >>>>> of
>> >> >>>>> cpu-based blas) with Netlib-java wrapper and put it into Spark,
>> >> >>>>> so
>> >> >>>>> Breeze/Netlib is using it. Then I did some performance
>> >> >>>>> measurements
>> >> >>>>> with
>> >> >>>>> regards to artificial neural network batch learning in Spark
>> >> >>>>> MLlib
>> >> >>>>> that
>> >> >>>>> involves matrix-matrix multiplications. It turns out that for
>> >> >>>>> matrices of
>> >> >>>>> size less than ~1000x780 GPU cublas has the same speed as CPU
>> >> >>>>> blas.
>> >> >>>>> Cublas
>> >> >>>>> becomes slower for bigger matrices. It worth mentioning that it
>> >> >>>>> is
>> >> >>>>> was not
>> >> >>>>> a test for ONLY multiplication since there are other operations
>> >> >>>>> involved.
>> >> >>>>> One of the reasons for slowdown might be the overhead of copying
>> >> >>>>> the
>> >> >>>>> matrices from computer memory to graphic card memory and back.
>> >> >>>>>
>> >> >>>>> So, few questions:
>> >> >>>>> 1) Do these results with CUDA make sense?
>> >> >>>>> 2) If the problem is with copy overhead, are there any libraries
>> >> >>>>> that
>> >> >>>>> allow to force intermediate results to stay in graphic card
>> >> >>>>> memory
>> >> >>>>> thus
>> >> >>>>> removing the overhead?
>> >> >>>>> 3) Any other options to speed-up linear algebra in Spark?
>> >> >>>>>
>> >> >>>>> Thank you, Alexander
>> >> >>>>>
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> ---------------------------------------------------------------------
>> >> >>>>> To unsubscribe, e-mail:
>> >> >>>>>
>> >> >>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org><mailto:
>> >> >>>>>
>> >> >>"
"
Nicholas Chammas <nicholas.chammas@gmail.com>,Mon"," 02 Mar 2015 22:28:24 +0000""",Re: spark-ec2 default to Hadoop 2,"shivaram@eecs.berkeley.edu, Sean Owen <sowen@cloudera.com>","I might take a look at that pr if we get around to doing some perf testing
of Spark on various resource managers.

2015년 3월 2일 (월) 오후 12:22, Shivaram Venkataraman <shivaram@eecs.berkeley.edu>님이
작성:

FWIW there is a PR open to add support for Hadoop 2.4 to spark-ec2 scripts
"
Nicholas Chammas <nicholas.chammas@gmail.com>,"Mon, 02 Mar 2015 22:39:26 +0000",PSA: Link to files at fixed version,Spark dev list <dev@spark.apache.org>,"*TL;DR*: Hit y on any file page on GitHub to update the URL to a permanent
link.

Many of you probably already know this. Here’s a handy tip for the rest.

So you’re on Github and you want to link to a file in an email, PR, or JIRA
report. Or better yet, you want to link to some specific lines in a file.

So you do this:

https://github.com/apache/spark/blob/master/ec2/spark_ec2.py#L805-L841

This is fine until someone changes the file. Now the link doesn’t make
sense because the line numbers are all different.

Instead, you want to do this:

https://github.com/apache/spark/blob/582e5a24c55e8c876733537c9910001affc8b29b/ec2/spark_ec2.py#L805-L841

This link will always make sense.

To get a link like this, you can just press y while you have the file open
on github.com, and GitHub will update the address in your browser bar to a
perma-link (i.e. from the former link to the latter).

Nick
​
"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Mon, 2 Mar 2015 22:43:49 +0000",RE: Using CUDA within Spark / boosting linear algebra,Sam Halliday <sam.halliday@gmail.com>,"Thanks Sam for suggestion! I should try doing this. Now I suppose that netlib-java linked with cuBlas during the execution time does fall back to cblas library in my system, which is atlas. If I remove atlas, netlib (linked with cublas) fails with the message ""undefined symbol: cblas_dgemm"".  

In the meantime, I have updated my spreadsheet with BIDMat-cuda results that does copy from main memory to GPU, multiplies and the copies it back to main memory (similar to what Xiangrui did). Surprisingly (for myself), the copying overhead seems quite small, especially for the bigger matrices.

https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing

-----Original Message-----
From: Sam Halliday [mailto:sam.halliday@gmail.com] 
Sent: Monday, March 02, 2015 1:24 PM
To: Ulanov, Alexander
Subject: Re: Using CUDA within Spark / boosting linear algebra

That's correct. It's highly unusual for a libblas.so to only provide the Fortran API. Oh well... CBLAS sources are available in the netlib-java repository so you could simply compile them and link against whatever libblas.so[fortran] you like.

On 2 March 2015 at 21:04, Ulanov, Alexander <alexander.ulanov@hp.com> wrote:
> Hi Xiangrui,
>
> Thanks for the link, I am currently trying to use nvblas. It seems that netlib wrappers are implemented with C-BLAS interface and nvblas does not have c-blas. I wonder how it is going to work. I'll keep you updated.
>
> Alexander
>
> -----Original Message-----
> From: Xiangrui Meng [mailto:mengxr@gmail.com]
> Sent: Monday, March 02, 2015 11:42 AM
> To: Sam Halliday
> Cc: Joseph Bradley; Ulanov, Alexander; dev; Evan R. Sparks
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> On Fri, Feb 27, 2015 at 12:33 PM, Sam Halliday <sam.halliday@gmail.com> wrote:
>> Also, check the JNILoader output.
>>
>> Remember, for netlib-java to use your system libblas all you need to 
>> do is setup libblas.so.3 like any native application would expect.
>>
>> I haven't ever used the cublas ""real BLAS""  implementation, so I'd be 
>> interested to hear about this. Do an 'ldd /usr/lib/libblas.so.3' to 
>> check that all the runtime links are in order.
>>
>
> There are two shared libraries in this hybrid setup. nvblas.so must be 
> loaded before libblas.so to intercept level 3 routines using GPU. More 
> details are at: http://docs.nvidia.com/cuda/nvblas/index.html#Usage
>
>> Btw, I have some DGEMM wrappers in my netlib-java performance 
>> module... and I also planned to write more in MultiBLAS (until I 
>> mothballed the project for the hardware to catch up, which is 
>> probably has and now I just need a reason to look at it)
>>
>> On 27 Feb 2015 20:26, ""Xiangrui Meng"" <mengxr@gmail.com> wrote:
>>>
>>> Hey Sam,
>>>
>>> The running times are not ""big O"" estimates:
>>>
>>> > The CPU version finished in 12 seconds.
>>> > The CPU->GPU->CPU version finished in 2.2 seconds.
>>> > The GPU version finished in 1.7 seconds.
>>>
>>> I think there is something wrong with the netlib/cublas combination.
>>> Sam already mentioned that cuBLAS doesn't implement the CPU BLAS 
>>> interfaces. I checked the CUDA doc and it seems that to use GPU BLAS 
>>> through the CPU BLAS interface we need to use NVBLAS, which 
>>> intercepts some Level 3 CPU BLAS calls (including GEMM). So we need 
>>> to load nvblas.so first and then some CPU BLAS library in JNI. I 
>>> wonder whether the setup was correct.
>>>
>>> Alexander, could you check whether GPU is used in the netlib-cublas 
>>> experiments? You can tell it by watching CPU/GPU usage.
>>>
>>> Best,
>>> Xiangrui
>>>
>>> On Thu, Feb 26, 2015 at 10:47 PM, Sam Halliday 
>>> <sam.halliday@gmail.com>
>>> wrote:
>>> > Don't use ""big O"" estimates, always measure. It used to work back 
>>> > in the days when double multiplication was a bottleneck. The 
>>> > computation cost is effectively free on both the CPU and GPU and 
>>> > you're seeing pure copying costs. Also, I'm dubious that cublas is 
>>> > doing what you think it is. Can you link me to the source code for 
>>> > DGEMM?
>>> >
>>> > I show all of this in my talk, with explanations, I can't stress 
>>> > enough how much I recommend that you watch it if you want to 
>>> > understand high performance hardware acceleration for linear 
>>> > algebra :-)
>>> >
>>> > On 27 Feb 2015 01:42, ""Xiangrui Meng"" <mengxr@gmail.com> wrote:
>>> >>
>>> >> The copying overhead should be quadratic on n, while the 
>>> >> computation cost is cubic on n. I can understand that 
>>> >> netlib-cublas is slower than netlib-openblas on small problems.
>>> >> But I'm surprised to see that it is still 20x slower on 
>>> >> 10000x10000. I did the following on a g2.2xlarge instance with BIDMat:
>>> >>
>>> >> val n = 10000
>>> >>
>>> >> val f = rand(n, n)
>>> >> flip; f*f; val rf = flop
>>> >>
>>> >> flip; val g = GMat(n, n); g.copyFrom(f); (g*g).toFMat(null); val 
>>> >> rg = flop
>>> >>
>>> >> flip; g*g; val rgg = flop
>>> >>
>>> >> The CPU version finished in 12 seconds.
>>> >> The CPU->GPU->CPU version finished in 2.2 seconds.
>>> >> The GPU version finished in 1.7 seconds.
>>> >>
>>> >> I'm not sure whether my CPU->GPU->CPU code simulates the 
>>> >> netlib-cublas path. But based on the result, the data copying 
>>> >> overhead is definitely not as big as 20x at n = 10000.
>>> >>
>>> >> Best,
>>> >> Xiangrui
>>> >>
>>> >>
>>> >> On Thu, Feb 26, 2015 at 2:21 PM, Sam Halliday 
>>> >> <sam.halliday@gmail.com>
>>> >> wrote:
>>> >> > I've had some email exchanges with the author of BIDMat: it 
>>> >> > does exactly what you need to get the GPU benefit and writes 
>>> >> > higher level algorithms entirely in the GPU kernels so that the 
>>> >> > memory stays there as long as possible. The restriction with 
>>> >> > this approach is that it is only offering high-level algorithms 
>>> >> > so is not a toolkit for applied mathematics research and 
>>> >> > development
>>> >> > --- but it works well as a toolkit for higher level analysis 
>>> >> > (e.g. for analysts and practitioners).
>>> >> >
>>> >> > I believe BIDMat's approach is the best way to get performance 
>>> >> > out of GPU hardware at the moment but I also have strong 
>>> >> > evidence to suggest that the hardware will catch up and the 
>>> >> > memory transfer costs between CPU/GPU will disappear meaning 
>>> >> > that there will be no need for custom GPU kernel 
>>> >> > implementations. i.e. please continue to use BLAS primitives 
>>> >> > when writing new algorithms and only go to the GPU for an 
>>> >> > alternative optimised implementation.
>>> >> >
>>> >> > Note that CUDA and cuBLAS are *not* BLAS. They are BLAS-like, 
>>> >> > and offer an API that looks like BLAS but takes pointers to 
>>> >> > special regions in the GPU memory region. Somebody has written 
>>> >> > a wrapper around CUDA to create a proper BLAS library but it 
>>> >> > only gives marginal performance over the CPU because of the 
>>> >> > memory transfer overhead.
>>> >> >
>>> >> > This slide from my talk
>>> >> >
>>> >> >   http://fommil.github.io/scalax14/#/11/2
>>> >> >
>>> >> > says it all. X axis is matrix size, Y axis is logarithmic time 
>>> >> > to do DGEMM. Black line is the ""cheating"" time for the GPU and 
>>> >> > the green line is after copying the memory to/from the GPU 
>>> >> > memory. APUs have the potential to eliminate the green line.
>>> >> >
>>> >> > Best regards,
>>> >> > Sam
>>> >> >
>>> >> >
>>> >> >
>>> >> > ""Ulanov, Alexander"" <alexander.ulanov@hp.com> writes:
>>> >> >
>>> >> >> Evan, thank you for the summary. I would like to add some more 
>>> >> >> observations. The GPU that I used is 2.5 times cheaper than 
>>> >> >> the CPU
>>> >> >> ($250 vs
>>> >> >> $100). They both are 3 years old. I've also did a small test 
>>> >> >> with modern hardware, and the new GPU nVidia Titan was 
>>> >> >> slightly more than 1 order of magnitude faster than Intel 
>>> >> >> E5-2650 v2 for the same tests. However, it costs as much as 
>>> >> >> CPU ($1200). My takeaway is that GPU is making a better price/value progress.
>>> >> >>
>>> >> >>
>>> >> >>
>>> >> >> Xiangrui, I was also surprised that BIDMat-cuda was faster 
>>> >> >> than netlib-cuda and the most reasonable explanation is that 
>>> >> >> it holds the result in GPU memory, as Sam suggested. At the 
>>> >> >> same time, it is OK because you can copy the result back from 
>>> >> >> GPU only when needed. However, to be sure, I am going to ask 
>>> >> >> the developer of BIDMat on his upcoming talk.
>>> >> >>
>>> >> >>
>>> >> >>
>>> >> >> Best regards, Alexander
>>> >> >>
>>> >> >>
>>> >> >> From: Sam Halliday [mailto:sam.halliday@gmail.com]
>>> >> >> Sent: Thursday, February 26, 2015 1:56 PM
>>> >> >> To: Xiangrui Meng
>>> >> >> Cc: dev@spark.apache.org; Joseph Bradley; Ulanov, Alexander; Evan R.
>>> >> >> Sparks
>>> >> >> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>> >> >>
>>> >> >>
>>> >> >> Btw, I wish people would stop cheating when comparing CPU and 
>>> >> >> GPU timings for things like matrix multiply :-P
>>> >> >>
>>> >> >> Please always compare apples with apples and include the time 
>>> >> >> it takes to set up the matrices, send it to the processing 
>>> >> >> unit, doing the calculation AND copying it back to where you 
>>> >> >> need to see the results.
>>> >> >>
>>> >> >> Ignoring this method will make you believe that your GPU is 
>>> >> >> thousands of times faster than it really is. Again, jump to 
>>> >> >> the end of my talk for graphs and more discussion....  
>>> >> >> especially the bit about me being keen on funding to 
>>> >> >> investigate APU hardware further ;-) (I believe it will solve 
>>> >> >> the
>>> >> >> problem)
>>> >> >> On 26 Feb 2015 21:16, ""Xiangrui Meng""
>>> >> >> <mengxr@gmail.com<mailto:mengxr@gmail.com>> wrote:
>>> >> >> Hey Alexander,
>>> >> >>
>>> >> >> I don't quite understand the part where netlib-cublas is about 
>>> >> >> 20x slower than netlib-openblas. What is the overhead of using 
>>> >> >> a GPU BLAS with netlib-java?
>>> >> >>
>>> >> >> CC'ed Sam, the author of netlib-java.
>>> >> >>
>>> >> >> Best,
>>> >> >> Xiangrui
>>> >> >>
>>> >> >> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley 
>>> >> >> <joseph@databricks.com<mailto:joseph@databricks.com>> wrote:
>>> >> >>> Better documentation for linking would be very helpful!
>>> >> >>> Here's a
>>> >> >>> JIRA:
>>> >> >>> https://issues.apache.org/jira/browse/SPARK-6019
>>> >> >>>
>>> >> >>>
>>> >> >>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks 
>>> >> >>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
>>> >> >>> wrote:
>>> >> >>>
>>> >> >>>> Thanks for compiling all the data and running these 
>>> >> >>>> benchmarks, Alex.
>>> >> >>>> The
>>> >> >>>> big takeaways here can be seen with this chart:
>>> >> >>>>
>>> >> >>>>
>>> >> >>>>
>>> >> >>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh
>>> >> >>>> 4 
>>> >> >>>> StF50uZHl6kmAJeaZZggr0/pubchart?oid=1899767119&format=intera
>>> >> >>>> c
>>> >> >>>> tive
>>> >> >>>>
>>> >> >>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>> >> >>>> BIDMat+GPU) can provide substantial (but less than an order 
>>> >> >>>> BIDMat+of
>>> >> >>>> magnitude)
>>> >> >>>> benefit over a well-tuned CPU implementation (e.g. 
>>> >> >>>> BIDMat+MKL or
>>> >> >>>> netlib-java+openblas-compiled).
>>> >> >>>> 2) A poorly tuned CPU implementation can be 1-2 orders of 
>>> >> >>>> magnitude worse than a well-tuned CPU implementation, 
>>> >> >>>> particularly for larger matrices.
>>> >> >>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib
>>> >> >>>> - this basically agrees with the authors own benchmarks (
>>> >> >>>> https://github.com/fommil/netlib-java)
>>> >> >>>>
>>> >> >>>> I think that most of our users are in a situation where 
>>> >> >>>> using GPUs may not be practical - although we could consider 
>>> >> >>>> having a good GPU backend available as an option. However, 
>>> >> >>>> *ALL* users of MLlib could benefit (potentially 
>>> >> >>>> tremendously) from using a well-tuned CPU-based BLAS 
>>> >> >>>> implementation. Perhaps we should consider updating the 
>>> >> >>>> mllib guide with a more complete section for enabling high 
>>> >> >>>> performance binaries on OSX and Linux? Or better, figure out 
>>> >> >>>> a way for the system to fetch these automatically.
>>> >> >>>>
>>> >> >>>> - Evan
>>> >> >>>>
>>> >> >>>>
>>> >> >>>>
>>> >> >>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander < 
>>> >> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>> >> >>>>
>>> >> >>>>> Just to summarize this thread, I was finally able to make 
>>> >> >>>>> all performance comparisons that we discussed. It turns out
>>> >> >>>>> that:
>>> >> >>>>> BIDMat-cublas>>BIDMat
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-y
>>> >> >>>>> u m-repo==netlib-cublas>netlib-blas>f2jblas
>>> >> >>>>>
>>> >> >>>>> Below is the link to the spreadsheet with full results.
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oe
>>> >> >>>>> o uQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing
>>> >> >>>>>
>>> >> >>>>> One thing still needs exploration: does BIDMat-cublas 
>>> >> >>>>> perform copying to/from machine’s RAM?
>>> >> >>>>>
>>> >> >>>>> -----Original Message-----
>>> >> >>>>> From: Ulanov, Alexander
>>> >> >>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>> >> >>>>> To: Evan R. Sparks
>>> >> >>>>> Cc: Joseph Bradley;
>>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>> >> >>>>> Subject: RE: Using CUDA within Spark / boosting linear 
>>> >> >>>>> algebra
>>> >> >>>>>
>>> >> >>>>> Thanks, Evan! It seems that ticket was marked as duplicate 
>>> >> >>>>> though the original one discusses slightly different topic.
>>> >> >>>>> I was able to link netlib with MKL from BIDMat binaries.
>>> >> >>>>> Indeed, MKL is statically linked inside a 60MB library.
>>> >> >>>>>
>>> >> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>> >> >>>>> Breeze+Netlib-OpenBlas(native system)| 
>>> >> >>>>> Breeze+Breeze+Netlib-f2jblas
>>> >> >>>>> Breeze+|
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> +-----------------------------------------------------------------------+
>>> >> >>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 |
>>> >> >>>>> |0,002556
>>> >> >>>>> |
>>> >> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 |
>>> >> >>>>> |0,51803557
>>> >> >>>>> |1,638475459 |
>>> >> >>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697
>>> >> >>>>> ||445,0935211
>>> >> >>>>> |
>>> >> >>>>> 1569,233228 |
>>> >> >>>>>
>>> >> >>>>> It turn out that pre-compiled MKL is faster than 
>>> >> >>>>> precompiled OpenBlas on my machine. Probably, I’ll add two 
>>> >> >>>>> more columns with locally compiled openblas and cuda.
>>> >> >>>>>
>>> >> >>>>> Alexander
>>> >> >>>>>
>>> >> >>>>> From: Evan R. Sparks
>>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>
>>> >> >>>>> ]
>>> >> >>>>> Sent: Monday, February 09, 2015 6:06 PM
>>> >> >>>>> To: Ulanov, Alexander
>>> >> >>>>> Cc: Joseph Bradley;
>>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear 
>>> >> >>>>> algebra
>>> >> >>>>>
>>> >> >>>>> Great - perhaps we can move this discussion off-list and 
>>> >> >>>>> onto a JIRA ticket? (Here's one:
>>> >> >>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>>> >> >>>>>
>>> >> >>>>> It seems like this is going to be somewhat exploratory for 
>>> >> >>>>> a while (and there's probably only a handful of us who 
>>> >> >>>>> really care about fast linear
>>> >> >>>>> algebra!)
>>> >> >>>>>
>>> >> >>>>> - Evan
>>> >> >>>>>
>>> >> >>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mai
>>> >> >>>>> lto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>
>>> >> >>>>> >>
>>> >> >>>>> wrote:
>>> >> >>>>> Hi Evan,
>>> >> >>>>>
>>> >> >>>>> Thank you for explanation and useful link. I am going to 
>>> >> >>>>> build OpenBLAS, link it with Netlib-java and perform 
>>> >> >>>>> benchmark again.
>>> >> >>>>>
>>> >> >>>>> Do I understand correctly that BIDMat binaries contain 
>>> >> >>>>> statically linked Intel MKL BLAS? It might be the reason 
>>> >> >>>>> why I am able to run BIDMat not having MKL BLAS installed 
>>> >> >>>>> on my server. If it is true, I wonder if it is OK because 
>>> >> >>>>> Intel sells this library. Nevertheless, it seems that in my 
>>> >> >>>>> case precompiled MKL BLAS performs better than precompiled 
>>> >> >>>>> OpenBLAS given that BIDMat and Netlib-java are supposed to 
>>> >> >>>>> be on par with JNI overheads.
>>> >> >>>>>
>>> >> >>>>> Though, it might be interesting to link Netlib-java with 
>>> >> >>>>> Intel MKL, as you suggested. I wonder, are John Canny 
>>> >> >>>>> (BIDMat) and Sam Halliday
>>> >> >>>>> (Netlib-java) interested to compare their libraries.
>>> >> >>>>>
>>> >> >>>>> Best regards, Alexander
>>> >> >>>>>
>>> >> >>>>> From: Evan R. Sparks
>>> >> >>>>>
>>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>> >> >>>>> Sent: Friday, February 06, 2015 5:58 PM
>>> >> >>>>>
>>> >> >>>>> To: Ulanov, Alexander
>>> >> >>>>> Cc: Joseph Bradley;
>>> >> >>>>>
>>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:de
>>> >> >>>>> v@spark.apache.org<mailto:dev@spark.apache.org>>
>>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear 
>>> >> >>>>> algebra
>>> >> >>>>>
>>> >> >>>>> I would build OpenBLAS yourself, since good BLAS 
>>> >> >>>>> performance comes from getting cache sizes, etc. set up 
>>> >> >>>>> correctly for your particular hardware - this is often a 
>>> >> >>>>> very tricky process (see, e.g. ATLAS), but we found that on 
>>> >> >>>>> relatively modern Xeon chips, OpenBLAS builds quickly and 
>>> >> >>>>> yields performance competitive with MKL.
>>> >> >>>>>
>>> >> >>>>> To make sure the right library is getting used, you have to 
>>> >> >>>>> make sure it's first on the search path - export 
>>> >> >>>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>>> >> >>>>>
>>> >> >>>>> For some examples of getting netlib-java setup on an ec2 
>>> >> >>>>> node and some example benchmarking code we ran a while 
>>> >> >>>>> back, see:
>>> >> >>>>> https://github.com/shivaram/matrix-bench
>>> >> >>>>>
>>> >> >>>>> In particular - build-openblas-ec2.sh shows you how to 
>>> >> >>>>> build the library and set up symlinks correctly, and 
>>> >> >>>>> scala/run-netlib.sh shows you how to get the path setup and 
>>> >> >>>>> get that library picked up by netlib-java.
>>> >> >>>>>
>>> >> >>>>> In this way - you could probably get cuBLAS set up to be 
>>> >> >>>>> used by netlib-java as well.
>>> >> >>>>>
>>> >> >>>>> - Evan
>>> >> >>>>>
>>> >> >>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mai
>>> >> >>>>> lto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>
>>> >> >>>>> >>
>>> >> >>>>> wrote:
>>> >> >>>>> Evan, could you elaborate on how to force BIDMat and 
>>> >> >>>>> netlib-java to force loading the right blas? For netlib, I 
>>> >> >>>>> there are few JVM flags, such as 
>>> >> >>>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2
>>> >> >>>>> jBLAS,
>>> >> >>>>> so
>>> >> >>>>> I can
>>> >> >>>>> force it to use Java implementation. Not sure I understand 
>>> >> >>>>> how to force use a specific blas (not specific wrapper for 
>>> >> >>>>> blas).
>>> >> >>>>>
>>> >> >>>>> Btw. I have installed openblas (yum install openblas), so I 
>>> >> >>>>> suppose that netlib is using it.
>>> >> >>>>>
>>> >> >>>>> From: Evan R. Sparks
>>> >> >>>>>
>>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>> >> >>>>> Sent: Friday, February 06, 2015 5:19 PM
>>> >> >>>>> To: Ulanov, Alexander
>>> >> >>>>> Cc: Joseph Bradley;
>>> >> >>>>>
>>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:de
>>> >> >>>>> v@spark.apache.org<mailto:dev@spark.apache.org>>
>>> >> >>>>>
>>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear 
>>> >> >>>>> algebra
>>> >> >>>>>
>>> >> >>>>> Getting breeze to pick up the right blas library is 
>>> >> >>>>> critical for performance. I recommend using OpenBLAS (or 
>>> >> >>>>> MKL, if you already have it).
>>> >> >>>>> It might make sense to force BIDMat to use the same 
>>> >> >>>>> underlying BLAS library as well.
>>> >> >>>>>
>>> >> >>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mai
>>> >> >>>>> lto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>
>>> >> >>>>> >>
>>> >> >>>>> wrote:
>>> >> >>>>> Hi Evan, Joseph
>>> >> >>>>>
>>> >> >>>>> I did few matrix multiplication test and BIDMat seems to be 
>>> >> >>>>> ~10x faster than netlib-java+breeze (sorry for weird table 
>>> >> >>>>> formatting):
>>> >> >>>>>
>>> >> >>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
>>> >> >>>>> native_system_linux_x86-64|
>>> >> >>>>> Breeze+Netlib-java f2jblas |
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> +-----------------------------------------------------------------------+
>>> >> >>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>> >> >>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 
>>> >> >>>>> ||1,638475459 |
>>> >> >>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 |
>>> >> >>>>> 1569,233228 |
>>> >> >>>>>
>>> >> >>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB 
>>> >> >>>>> RAM, Fedora
>>> >> >>>>> 19
>>> >> >>>>> Linux, Scala 2.11.
>>> >> >>>>>
>>> >> >>>>> Later I will make tests with Cuda. I need to install new 
>>> >> >>>>> Cuda version for this purpose.
>>> >> >>>>>
>>> >> >>>>> Do you have any ideas why breeze-netlib with native blas is 
>>> >> >>>>> so much slower than BIDMat MKL?
>>> >> >>>>>
>>> >> >>>>> Best regards, Alexander
>>> >> >>>>>
>>> >> >>>>> From: Joseph Bradley
>>> >> >>>>>
>>> >> >>>>> [mailto:joseph@databricks.com<mailto:joseph@databricks.com><mailto:
>>> >> >>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>>> >> >>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>> >> >>>>> To: Ulanov, Alexander
>>> >> >>>>> Cc: Evan R. Sparks;
>>> >> >>>>>
>>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:de
>>> >> >>>>> v@spark.apache.org<mailto:dev@spark.apache.org>>
>>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear 
>>> >> >>>>> algebra
>>> >> >>>>>
>>> >> >>>>> Hi Alexander,
>>> >> >>>>>
>>> >> >>>>> Using GPUs with Spark would be very exciting.  Small comment:
>>> >> >>>>> Concerning
>>> >> >>>>> your question earlier about keeping data stored on the GPU 
>>> >> >>>>> rather than having to move it between main memory and GPU 
>>> >> >>>>> memory on each iteration, I would guess this would be 
>>> >> >>>>> critical to getting good performance.
>>> >> >>>>> If
>>> >> >>>>> you
>>> >> >>>>> could do multiple local iterations before aggregating 
>>> >> >>>>> results, then the cost of data movement to the GPU could be 
>>> >> >>>>> amortized (and I believe that is done in practice).  Having 
>>> >> >>>>> Spark be aware of the GPU and using it as another part of 
>>> >> >>>>> memory sounds like a much bigger undertaking.
>>> >> >>>>>
>>> >> >>>>> Joseph
>>> >> >>>>>
>>> >> >>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mai
>>> >> >>>>> lto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>
>>> >> >>>>> >>
>>> >> >>>>> wrote:
>>> >> >>>>> Thank you for explanation! I’ve watched the BIDMach 
>>> >> >>>>> presentation by John Canny and I am really inspired by his 
>>> >> >>>>> talk and comparisons with Spark MLlib.
>>> >> >>>>>
>>> >> >>>>> I am very interested to find out what will be better within
>>> >> >>>>> Spark:
>>> >> >>>>> BIDMat
>>> >> >>>>> or netlib-java with CPU or GPU natives. Could you suggest a 
>>> >> >>>>> fair way to benchmark them? Currently I do benchmarks on 
>>> >> >>>>> artificial neural networks in batch mode. While it is not a 
>>> >> >>>>> “pure” test of linear algebra, it involves some other 
>>> >> >>>>> things that are essential to machine learning.
>>> >> >>>>>
>>> >> >>>>> From: Evan R. Sparks
>>> >> >>>>>
>>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>> >> >>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>> >> >>>>> To: Ulanov, Alexander
>>> >> >>>>> Cc:
>>> >> >>>>>
>>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:de
>>> >> >>>>> v@spark.apache.org<mailto:dev@spark.apache.org>>
>>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear 
>>> >> >>>>> algebra
>>> >> >>>>>
>>> >> >>>>> I'd be surprised of BIDMat+OpenBLAS was significantly 
>>> >> >>>>> faster than
>>> >> >>>>> netlib-java+OpenBLAS, but if it is much faster it's 
>>> >> >>>>> netlib-java+probably due
>>> >> >>>>> to
>>> >> >>>>> data
>>> >> >>>>> layout and fewer levels of indirection - it's definitely a 
>>> >> >>>>> worthwhile experiment to run. The main speedups I've seen 
>>> >> >>>>> from using it come from highly optimized GPU code for 
>>> >> >>>>> linear algebra. I know that in the past Canny has gone as 
>>> >> >>>>> far as to write custom GPU kernels for performance-critical 
>>> >> >>>>> regions of code.[1]
>>> >> >>>>>
>>> >> >>>>> BIDMach is highly optimized for single node performance or 
>>> >> >>>>> performance on small clusters.[2] Once data doesn't fit 
>>> >> >>>>> easily in GPU memory (or can be batched in that way) the 
>>> >> >>>>> performance tends to fall off. Canny argues for 
>>> >> >>>>> hardware/software codesign and as such prefers machine 
>>> >> >>>>> configurations that are quite different than what we find 
>>> >> >>>>> in most commodity cluster nodes - e.g. 10 disk cahnnels and 
>>> >> >>>>> 4 GPUs.
>>> >> >>>>>
>>> >> >>>>> In contrast, MLlib was designed for horizontal scalability 
>>> >> >>>>> on commodity clusters and works best on very big datasets - 
>>> >> >>>>> order of terabytes.
>>> >> >>>>>
>>> >> >>>>> For the most part, these projects developed concurrently to 
>>> >> >>>>> address slightly different use cases. That said, there may 
>>> >> >>>>> be bits of BIDMach we could repurpose for MLlib - keep in 
>>> >> >>>>> mind we need to be careful about maintaining cross-language 
>>> >> >>>>> compatibility for our Java and Python-users, though.
>>> >> >>>>>
>>> >> >>>>> - Evan
>>> >> >>>>>
>>> >> >>>>> [1] - http://arxiv.org/abs/1409.5402 [2] - 
>>> >> >>>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>> >> >>>>>
>>> >> >>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mai
>>> >> >>>>> lto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>
>>> >> >>>>> >>>
>>> >> >>>>> wrote:
>>> >> >>>>> Hi Evan,
>>> >> >>>>>
>>> >> >>>>> Thank you for suggestion! BIDMat seems to have terrific 
>>> >> >>>>> speed. Do you know what makes them faster than netlib-java?
>>> >> >>>>>
>>> >> >>>>> The same group has BIDMach library that implements machine 
>>> >> >>>>> learning.
>>> >> >>>>> For
>>> >> >>>>> some examples they use Caffe convolutional neural network 
>>> >> >>>>> library owned by another group in Berkeley. Could you 
>>> >> >>>>> elaborate on how these all might be connected with Spark 
>>> >> >>>>> Mllib? If you take BIDMat for linear algebra why don’t you 
>>> >> >>>>> take BIDMach for optimization and learning?
>>> >> >>>>>
>>> >> >>>>> Best regards, Alexander
>>> >> >>>>>
>>> >> >>>>> From: Evan R. Sparks
>>> >> >>>>>
>>> >> >>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>> >> >>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>> >> >>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>> >> >>>>> To: Ulanov, Alexander
>>> >> >>>>> Cc:
>>> >> >>>>>
>>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:de
>>> >> >>>>> v@spark.apache.org<mailto:dev@spark.apache.org>>>
>>> >> >>>>> Subject: Re: Using CUDA within Spark / boosting linear 
>>> >> >>>>> algebra
>>> >> >>>>>
>>> >> >>>>> I'd expect that we can make GPU-accelerated BLAS faster 
>>> >> >>>>> than CPU blas in many cases.
>>> >> >>>>>
>>> >> >>>>> You might consider taking a look at the codepaths that 
>>> >> >>>>> BIDMat (
>>> >> >>>>> https://github.com/BIDData/BIDMat) takes and comparing them 
>>> >> >>>>> to netlib-java/breeze. John Canny et. al. have done a bunch 
>>> >> >>>>> of work optimizing to make this work really fast from 
>>> >> >>>>> Scala. I've run it on my laptop and compared to MKL and in 
>>> >> >>>>> certain cases it's 10x faster at matrix multiply.
>>> >> >>>>> There are a lot of layers of indirection here and you 
>>> >> >>>>> really want to avoid data copying as much as possible.
>>> >> >>>>>
>>> >> >>>>> We could also consider swapping out BIDMat for Breeze, but 
>>> >> >>>>> that would be a big project and if we can figure out how to 
>>> >> >>>>> get breeze+cublas to comparable performance that would be a 
>>> >> >>>>> big win.
>>> >> >>>>>
>>> >> >>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>> >> >>>>>
>>> >> >>>>>
>>> >> >>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mai
>>> >> >>>>> lto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>
>>> >> >>>>> >>>
>>> >> >>>>> wrote:
>>> >> >>>>> Dear Spark developers,
>>> >> >>>>>
>>> >> >>>>> I am exploring how to make linear algebra operations faster 
>>> >> >>>>> within Spark.
>>> >> >>>>> One way of doing this is to use Scala Breeze library that 
>>> >> >>>>> is bundled with Spark. For matrix operations, it employs 
>>> >> >>>>> Netlib-java that has a Java wrapper for BLAS (basic linear 
>>> >> >>>>> algebra subprograms) and LAPACK native binaries if they are 
>>> >> >>>>> available on the worker node. It also has its own optimized 
>>> >> >>>>> Java implementation of BLAS. It is worth mentioning, that 
>>> >> >>>>> native binaries provide better performance only for BLAS 
>>> >> >>>>> level 3, i.e.
>>> >> >>>>> matrix-matrix operations or general matrix multiplication (GEMM).
>>> >> >>>>> This is
>>> >> >>>>> confirmed by GEMM test on Netlib-java page 
>>> >> >>>>> https://github.com/fommil/netlib-java. I also confirmed it 
>>> >> >>>>> with my experiments with training of artificial neural 
>>> >> >>>>> network 
>>> >> >>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>> >> >>>>> However, I would like to boost performance more.
>>> >> >>>>>
>>> >> >>>>> GPU is supposed to work fast with linear algebra and there 
>>> >> >>>>> is Nvidia CUDA implementation of BLAS, called cublas. I 
>>> >> >>>>> have one Linux server with Nvidia GPU and I was able to do 
>>> >> >>>>> the following. I linked cublas (instead of cpu-based blas) 
>>> >> >>>>> with Netlib-java wrapper and put it into Spark, so "
"
Niranda Perera <niranda.perera@gmail.com>,Tue"," 3 Mar 2015 16:13:13 +0530""",Deploying master and worker programatically in java,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

I want to start a Spark standalone cluster programatically in java.

I have been checking these classes,
- org.apache.spark.deploy.master.Master
- org.apache.spark.deploy.worker.Worker

I successfully started a master with this simple main class.

 public static void main(String[] args) {
        SparkConf conf = new SparkConf();
        Master.startSystemAndActor(""localhost"", 4500, 8080, conf);
}


but I'm finding it hard to carry out a similar approach for the worker.

can anyone give an example of how to pass a value to the workerNumber field
in the Worker.startSystemAndActor constructor (in the java env)?

Cheers
-- 
Niranda
"
Sam Halliday <sam.halliday@gmail.com>,"Tue, 03 Mar 2015 21:54:00 +0000",Re: Using CUDA within Spark / boosting linear algebra,"Xiangrui Meng <mengxr@gmail.com>, Joseph Bradley <joseph@databricks.com>","BTW, is anybody on this list going to the London Meetup in a few weeks?

https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-mapreduce-world#community

Would be nice to meet other people working on the guts of Spark! :-)


Xiangrui Meng <mengxr@gmail.com> writes:

rote:
he
kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
e)
se
not
h a
nce
repo==netlib-cublas>netlib-blas>f2jblas
T9J5r7kwKSPkY/edit?usp=sharing
tlib
 a
--+
on
ompiled
S,
ed
is OK
se
hat
e -
at on
ry
o get
rce
 I can
e use
at
t).
brary
4|
--+
for
ng
, I
t is
on by John
MLlib.
Mat
s in
gebra, it involves
ta
Canny
 on
be
or
that
we
or
d by
be
don’t
in
izing
y.
void
be
rk.
ith
tive
 is
UDA
idia
th
 of
blas
 not
ed.
org

-- 
Best regards,
Sam

---------------------------------------------------------------------


"
Robert Dodier <robert.dodier@gmail.com>,"Tue, 3 Mar 2015 17:51:25 -0800",ideas for MLlib development,dev@spark.apache.org,"Hi,

I have some ideas for MLlib that I think might be of general interest
so I'd like to see what people think and maybe find some collaborators.

(1) Some form of Markov chain Monte Carlo such as Gibbs sampling
or Metropolis-Hastings. Any kind of Monte Carlo method is readily
parallelized so Spark seems like a natural platform for them.
MCMC plays an important role in computational implementations
of Bayesian inference.

(2) A function to compute the calibration of a probabilistic classifier.
The question this answers is, if the classifier outputs 0.x for some
group of examples, is the actual proportion approximately 0.x ?
This is useful to know if the classifier outputs are used to compute
expected loss in some decision procedure.

Of course (1) is much bigger than (2). Perhaps (2) is a one-person
job but (1) will take a lot of teamwork. I am thinking that in the short
term, we could at least make some progress on an outline or
framework for (1).

I am a newcomer to Scala and Spark but I have a lot of experience
in statistical computing. I am thinking that maybe one or the other
of these projects will be a good way for me to learn more about
Spark and make a useful contribution. Thanks for your interest
and I look forward to your comments.

Robert Dodier

---------------------------------------------------------------------


"
"""Evan R. Sparks"" <evan.sparks@gmail.com>","Tue, 3 Mar 2015 18:34:03 -0800",Re: ideas for MLlib development,Robert Dodier <robert.dodier@gmail.com>,"Hi Robert,

There's some work to do LDA via Gibbs sampling in this JIRA:
https://issues.apache.org/jira/browse/SPARK-1405 as well as this one:
https://issues.apache.org/jira/browse/SPARK-5556

It may make sense to have a more general Gibbs sampling framework, but it
might be good to have a few desired applications in mind (e.g. higher level
models that rely on Gibbs) to help API design, parallelization strategy,
etc.

See the guide (
https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-ContributingNewAlgorithmstoMLLib)
for information about contributing to MLlib.

- Evan




"
Patrick Wendell <pwendell@gmail.com>,"Tue, 3 Mar 2015 20:14:34 -0800",[RESULT] [VOTE] Release Apache Spark 1.3.0 (RC1),"""dev@spark.apache.org"" <dev@spark.apache.org>","This vote is cancelled in favor of RC2.


---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Tue, 3 Mar 2015 20:19:19 -0800",[VOTE] Release Apache Spark 1.3.0 (RC2),"""dev@spark.apache.org"" <dev@spark.apache.org>","Please vote on releasing the following candidate as Apache Spark version 1.3.0!

The tag to be voted on is v1.3.0-rc2 (commit 3af2687):
https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=3af26870e5163438868c4eb2df88380a533bb232

The release files, including signatures, digests, etc. can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-rc2/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

Staging repositories for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1074/
(published with version '1.3.0')
https://repository.apache.org/content/repositories/orgapachespark-1075/
(published with version '1.3.0-rc2')

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-rc2-docs/

Please vote on releasing this package as Apache Spark 1.3.0!

The vote is open until Saturday, March 07, at 04:17 UTC and passes if
a majority of at least 3 +1 PMC votes are cast.

[ ] +1 Release this package as Apache Spark 1.3.0
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.apache.org/

== How does this compare to RC1 ==
This patch includes a variety of bug fixes found in RC1.

== How can I help test this release? ==
If you are a Spark user, you can help us test this release by
taking a Spark 1.2 workload and running on this release candidate,
then reporting any regressions.

If you are happy with this release based on your own testing, give a +1 vote.

== What justifies a -1 vote for this release? ==
This vote is happening towards the end of the 1.3 QA period,
so -1 votes should only occur for significant regressions from 1.2.1.
Bugs already present in 1.2.X, minor regressions, or bugs related
to new features will not block this release.

---------------------------------------------------------------------


"
spotvenky <spotvenky@gmail.com>,"Tue, 3 Mar 2015 23:15:36 -0700 (MST)",Sharing SparkContext across multiple Unit Test Scala files,dev@spark.apache.org,"Can someone show me a code snippet on how I can create one SparkContext and
share it across multiple Unit Test files? I want the tests to run in
parallel as well. (i.e. parallelExecution in Test := true) 

I looked up SharedSparkContext, doesnt seem to work when tests are run in
parallel. Can someone guide me here.



--

---------------------------------------------------------------------


"
Krishna Sankar <ksankar42@gmail.com>,"Tue, 3 Mar 2015 23:15:55 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC2),Patrick Wendell <pwendell@gmail.com>,"+1 (non-binding, of course)

1. Compiled OSX 10.10 (Yosemite) OK Total time: 13:53 min
     mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4
-Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11
2. Tested pyspark, mlib - running as well as comp"
Xiangrui Meng <mengxr@gmail.com>,"Tue, 3 Mar 2015 23:28:05 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC2),Krishna Sankar <ksankar42@gmail.com>,"
Could you share the code you used? I don't remember any changes in
linear regression. Thanks! -Xiangrui


---------------------------------------------------------------------


"
Krishna Sankar <ksankar42@gmail.com>,"Wed, 4 Mar 2015 01:17:43 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC2),Xiangrui Meng <mengxr@gmail.com>,"It is the LR over car-data at https://github.com/xsankar/cloaked-ironman.
1.2.0 gives Mean Squared Error = 40.8130551358
1.3.0 gives Mean Squared Error = 105.857603953

I will verify it one more time tomorrow.

Cheers
<k/>


"
"""Haopu Wang"" <HWang@qilinsoft.com>","Wed, 4 Mar 2015 18:04:24 +0800",Spark Streaming and SchemaRDD usage,"""user"" <user@spark.apache.org>,
	<dev@spark.apache.org>","Hi, in the roadmap of Spark in 2015 (link:
http://files.meetup.com/3138542/Spark%20in%202015%20Talk%20-%20Wendell.p
ptx), I saw SchemaRDD is designed to be the basis of BOTH Spark
Streaming and Spark SQL.

My question is: what's the typical usage of SchemaRDD in a Spark
Streaming application? Thank you very much!


---------------------------------------------------------------------


"
Robin East <robin.east@xense.co.uk>,"Wed, 4 Mar 2015 11:49:30 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC2),Patrick Wendell <pwendell@gmail.com>,"+1 (subject to comments on ec2 issues below)

machine 1: Macbook Air, OSX 10.10.2 (Yosemite), Java 8
machine 2: iMac, OSX 10.8.4, Java 7

1. mvn clean package -DskipTests  (33min/13min)
2. ran SVM benchmark https://github.com/insidedctm/spark-mllib-benchm"
=?UTF-8?B?VWxyaWNoIFN0w6Ryaw==?= <uli@spielviel.de>,"Wed, 04 Mar 2015 13:10:32 +0100",Re: Google Summer of Code - Quick Query,"manojkumarsivaraj334@gmail.com, dev@spark.apache.org","Hi Manoj,

this question is best asked on the Spark mailing lists (copied). From a formal point of view all
that counts is your proposal in Melange once applications start but your mentor or the project you
wish to contribute to may have additional requirements.

Cheers,

Uli


---------------------------------------------------------------------


"
Marcelo Vanzin <vanzin@cloudera.com>,"Wed, 4 Mar 2015 09:26:13 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC2),Patrick Wendell <pwendell@gmail.com>,"I haven't tested the rc2 bits yet, but I'd consider
https://issues.apache.org/jira/browse/SPARK-6144 a serious regression
from 1.2 (since it affects existing ""addFile()"" functionality if the
URL is ""hdfs:..."").

Will test other parts separately.




-- 
Marcelo

---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Wed, 4 Mar 2015 09:36:20 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC2),Marcelo Vanzin <vanzin@cloudera.com>,"Hey Marcelo,

Yes - I agree. That one trickled in just as I was packaging this RC.
However, I still put this out here to allow people to test the
existing fixes, etc.

- Patrick


---------------------------------------------------------------------


"
Marcelo Vanzin <vanzin@cloudera.com>,"Wed, 4 Mar 2015 11:09:32 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC2),Patrick Wendell <pwendell@gmail.com>,"-1 (non-binding) because of SPARK-6144.

But aside from that I ran a set of tests on top of standalone and yarn
and things look good.




-- 
Marcelo

---------------------------------------------------------------------


"
shane knapp <sknapp@berkeley.edu>,"Wed, 4 Mar 2015 13:06:50 -0800",short jenkins 7am downtime tomorrow morning (3-5-15),"amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>","the master and workers need some system and package updates, and i'll also
be rebooting the machines as well.

this shouldn't take very long to perform, and i expect jenkins to be back
up and building by 9am at the *latest*.

important note:  i will NOT be updating jenkins or any of the plugins
during this maintenance!

as always, please let me know if you have any questions or concerns.

danke shane
"
Sean Owen <sowen@cloudera.com>,"Wed, 4 Mar 2015 23:22:57 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC2),Marcelo Vanzin <vanzin@cloudera.com>,"I think we will have to fix
https://issues.apache.org/jira/browse/SPARK-5143 as well before the
final 1.3.x.

But yes everything else checks out for me, including sigs and hashes
and building the source release.

I have been following JIRA closely and am not aware of other blockers
besides the ones already identified.


---------------------------------------------------------------------


"
Mingyu Kim <mkim@palantir.com>,"Thu, 5 Mar 2015 00:01:16 +0000",Task result is serialized twice by serializer and closure serializer,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi all,

It looks like the result of task is serialized twice, once by serializer (I.e. Java/Kryo depending on configuration) and once again by closure serializer (I.e. Java). To link the actual code,

The first one: https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L213
The second one: https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L226

This serializes the value, which is the result of task run twice, which affects things like collect(), takeSample(), and toLocalIterator(). Would it make sense to simply serialize the DirectTaskResult once using the regular serializer (as opposed to closure serializer)? Would it cause problems when the Accumulator values are not Kryo-serializable?

Alternatively, if we can assume that Accumator values are small, we can closure-serialize those, put the serialized byte array in DirectTaskResult with the raw task result value, and serialize DirectTaskResult.

What do people think?

Thanks,
Mingyu
"
Patrick Wendell <pwendell@gmail.com>,"Wed, 4 Mar 2015 17:07:13 -0800",Re: Task result is serialized twice by serializer and closure serializer,Mingyu Kim <mkim@palantir.com>,"Hey Mingyu,

I think it's broken out separately so we can record the time taken to
serialization should be really simple since it's just wrapping
something that has already been turned into a byte buffer. Do you see
a specific issue with serializing it twice?

I think you need to have two steps if you want to record the time
taken to serialize the result, since that needs to be sent back to the
driver when the task completes.

- Patrick

(I.e. Java/Kryo depending on configuration) and once again by closure serializer (I.e. Java). To link the actual code,
scala/org/apache/spark/executor/Executor.scala#L213
/scala/org/apache/spark/executor/Executor.scala#L226
 affects things like collect(), takeSample(), and toLocalIterator(). Would it make sense to simply serialize the DirectTaskResult once using the regular ""serializer"" (as opposed to closure serializer)? Would it cause problems when the Accumulator values are not Kryo-serializable?
losure-serialize those, put the serialized byte array in DirectTaskResult with the raw task result ""value"", and serialize DirectTaskResult.

---------------------------------------------------------------------


"
Xiangrui Meng <mengxr@gmail.com>,"Wed, 4 Mar 2015 17:11:01 -0800",enum-like types in Spark,dev <dev@spark.apache.org>,"Hi all,

There are many places where we use enum-like types in Spark, but in
different ways. Every approach has both pros and cons. I wonder
whether there should be an “official” approach for enum-like types in
Spark.

1. Scala’s Enumeration (e.g., SchedulingMode, WorkerState, etc)

* All types show up as Enumeration.Value in Java.
http://spark.apache.org/docs/latest/api/java/org/apache/spark/scheduler/SchedulingMode.html

2. Java’s Enum (e.g., SaveMode, IOMode)

* Implementation must be in a Java file.
* Values doesn’t show up in the ScalaDoc:
http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.network.util.IOMode

3. Static fields in Java (e.g., TripletFields)

* Implementation must be in a Java file.
* Doesn’t need “()” in Java code.
* Values don't show up in the ScalaDoc:
http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.graphx.TripletFields

4. Objects in Scala. (e.g., StorageLevel)

* Needs “()” in Java code.
* Values show up in both ScalaDoc and JavaDoc:
  http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.storage.StorageLevel$
  http://spark.apache.org/docs/latest/api/java/org/apache/spark/storage/StorageLevel.html

It would be great if we have an “official” approach for this as well
as the naming convention for enum-like values (“MEMORY_ONLY” or
NLY”. Any thoughts?

Best,
Xiangrui

---------------------------------------------------------------------


"
Stephen Boesch <javadba@gmail.com>,"Wed, 4 Mar 2015 17:14:03 -0800",Re: enum-like types in Spark,Xiangrui Meng <mengxr@gmail.com>,"
http://docs.scala-lang.org/style/naming-conventions.html

Constants, Values, Variable and Methods

Constant names should be in upper camel case. That is, if the member is
final, immutable and it belongs to a package object or an object, it may be
considered a constant (similar to Java’sstatic final members):


   1. object Container {
   2.     val MyConstant = ...
   3. }


2015-03-04 17:11 GMT-08:00 Xiangrui Meng <mengxr@gmail.com>:

ike types in
chedulingMode.html
til.IOMode
ipletFields
torageLevel$
rageLevel.html
his as well
 or
_ONLY”. Any thoughts?
"
Joseph Bradley <joseph@databricks.com>,"Wed, 4 Mar 2015 17:29:51 -0800",Re: enum-like types in Spark,Stephen Boesch <javadba@gmail.com>,"another vote for #4
People are already used to adding ""()"" in Java.



be
-like types in
chedulingMode.html
til.IOMode
ipletFields
torageLevel$
rageLevel.html
 this as well
 or
RY_ONLY”. Any thoughts?
"
Michael Armbrust <michael@databricks.com>,"Wed, 4 Mar 2015 17:37:24 -0800",Re: enum-like types in Spark,Joseph Bradley <joseph@databricks.com>,"#4 with a preference for CamelCaseEnums


y
um-like types in
c)
chedulingMode.html
til.IOMode
ipletFields
torageLevel$
rageLevel.html
or this as well
” or
MORY_ONLY”. Any thoughts?
"
Mingyu Kim <mkim@palantir.com>,"Thu, 5 Mar 2015 01:47:17 +0000","Re: Task result is serialized twice by serializer and closure
 serializer",Patrick Wendell <pwendell@gmail.com>,"The concern is really just the runtime overhead and memory footprint of
Java-serializing an already-serialized byte array again. We originally
noticed this when we were using RDD.toLocalIterator() which serializes the
entire 64MB partition. We worked around this issue by kryo-serializing and
snappy-compressing the partition on the executor side before returning it
back to the driver, but this operation just felt redundant.

Your explanation about reporting the time taken makes it clearer why its
designed this way. Since the byte array for the serialized task result
shouldnt account for the majority of memory footprint anyways, Im okay
with leaving it as is, then.

Thanks,
Mingyu






sp
=ennQJ
-9
sp
=ennQJ
-9


---------------------------------------------------------------------


"
Aaron Davidson <ilikerps@gmail.com>,"Wed, 4 Mar 2015 18:07:02 -0800",Re: enum-like types in Spark,Michael Armbrust <michael@databricks.com>,"I'm cool with #4 as well, but make sure we dictate that the values should
be defined within an object with the same name as the enumeration (like we
do for StorageLevel). Otherwise we may pollute a higher namespace.

e.g. we SHOULD do:

trait StorageLevel
object StorageLevel {
}


is
:
enum-like types in
etc)
chedulingMode.html
til.IOMode
ipletFields
torageLevel$
rageLevel.html
 for this as well
” or
MEMORY_ONLY”. Any
--
"
Patrick Wendell <pwendell@gmail.com>,"Wed, 4 Mar 2015 20:05:28 -0800",Re: Task result is serialized twice by serializer and closure serializer,Mingyu Kim <mkim@palantir.com>,"Yeah, it will result in a second serialized copy of the array (costing
some memory). But the computational overhead should be very small. The
absolute worst case here will be when doing a collect() or something
similar that just bundles the entire partition.

- Patrick

e
d
s
kay
_sp
c
=ennQJ
H-9
_sp
c
=ennQJ
H-9

---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Wed, 4 Mar 2015 20:10:15 -0800",Re: enum-like types in Spark,Aaron Davidson <ilikerps@gmail.com>,"I like #4 as well and agree with Aaron's suggestion.

- Patrick


---------------------------------------------------------------------


"
Robert Dodier <robert.dodier@gmail.com>,"Wed, 4 Mar 2015 20:40:46 -0800",Re: ideas for MLlib development,"""Evan R. Sparks"" <evan.sparks@gmail.com>","Thanks for your reply, Evan.


I think I'm more interested in a general framework which could
be applied to a variety of models, as opposed to an implementation
tailored to a specific model such as LDA. I'm thinking that such
a framework could be used in model exploration, either as an
end in itself or perhaps to identify promising models that could
then be given optimized, custom implementations. This would
be very much in the spirit of existing packages such as BUGS.
In fact, if we were to go down this road, I would propose that
models be specified in the BUGS modeling language -- no need
to reinvent that wheel, I would say.

At a very high level, the API for this framework would specify
methods to compute conditional distributions, marginalizing
as necessary via MCMC. Other operations could include
computing the expected value of a variable or function.
All this is very reminiscent of BUGS, of course.

best,

Robert Dodier

---------------------------------------------------------------------


"
,"Thu, 5 Mar 2015 10:27:04 +0530",Fwd: Unable to Read/Write Avro RDD on cluster.,dev@spark.apache.org,"I am trying to read RDD avro, transform and write.
I am able to run it locally fine but when i run onto cluster, i see issues
with Avro.


export SPARK_HOME=/home/dvasthimal/spark/spark-1.0.2-bin-2.4.1
export SPARK_YARN_USER_ENV=""CLASSPATH=/apache/hadoop/conf""
export HADOOP_CONF_DIR=/apache/hadoop/conf
export YARN_CONF_DIR=/apache/hadoop/conf
export SPARK_JAR=$SPARK_HOME/lib/spark-assembly-1.0.2-hadoop2.4.1.jar
export SPARK_LIBRARY_PATH=/apache/hadoop/lib/native
export SPARK_YARN_USER_ENV=""CLASSPATH=/apache/hadoop/conf""
export SPARK_YARN_USER_ENV=""CLASSPATH=/apache/hadoop/conf""
export
SPARK_CLASSPATH=/apache/hadoop/share/hadoop/common/hadoop-common-2.4.1-company-2.jar:/apache/hadoop/lib/hadoop-lzo-0.6.0.jar:/home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar:/home/dvasthimal/spark/avro-1.7.7.jar
export SPARK_LIBRARY_PATH=""/apache/hadoop/lib/native""
export YARN_CONF_DIR=/apache/hadoop/conf/

cd $SPARK_HOME

./bin/spark-submit --master yarn-cluster --jars
/home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar,/home/dvasthimal/spark/avro-1.7.7.jar
--num-executors 3 --driver-memory 4g --executor-memory 2g --executor-cores
1  --queue hdmi-spark --class com.company.ep.poc.spark.reporting.SparkApp
/home/dvasthimal/spark/spark_reporting-1.0-SNAPSHOT.jar
startDate=2015-02-16 endDate=2015-02-16
epoutputdirectory=/user/dvasthimal/epdatasets_small/exptsession
subcommand=successevents
outputdir=/user/dvasthimal/epdatasets/successdetail

Spark assembly has been built with Hive, including Datanucleus jars on
classpath
15/03/04 03:20:29 INFO client.ConfiguredRMFailoverProxyProvider: Failing
over to rm2
15/03/04 03:20:30 INFO yarn.Client: Got Cluster metric info from
ApplicationsManager (ASM), number of NodeManagers: 2221
15/03/04 03:20:30 INFO yarn.Client: Queue info ... queueName: hdmi-spark,
queueCurrentCapacity: 0.7162806, queueMaxCapacity: 0.08,
      queueApplicationCount = 7, queueChildQueueCount = 0
15/03/04 03:20:30 INFO yarn.Client: Max mem capabililty of a single
resource in this cluster 16384
15/03/04 03:20:30 INFO yarn.Client: Preparing Local resources
15/03/04 03:20:30 WARN util.NativeCodeLoader: Unable to load native-hadoop
library for your platform... using builtin-java classes where applicable
15/03/04 03:20:30 WARN hdfs.BlockReaderLocal: The short-circuit local reads
feature cannot be used because libhadoop cannot be loaded.


15/03/04 03:20:46 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token
7780745 for dvasthimal on 10.115.206.112:8020
15/03/04 03:20:46 INFO yarn.Client: Uploading
file:/home/dvasthimal/spark/spark_reporting-1.0-SNAPSHOT.jar to hdfs://
apollo-phx-nn.company.com:8020/user/dvasthimal/.sparkStaging/application_1425075571333_61948/spark_reporting-1.0-SNAPSHOT.jar
15/03/04 03:20:47 INFO yarn.Client: Uploading
file:/home/dvasthimal/spark/spark-1.0.2-bin-2.4.1/lib/spark-assembly-1.0.2-hadoop2.4.1.jar
to hdfs://
apollo-phx-nn.company.com:8020/user/dvasthimal/.sparkStaging/application_1425075571333_61948/spark-assembly-1.0.2-hadoop2.4.1.jar
15/03/04 03:20:52 INFO yarn.Client: Uploading
file:/home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar to hdfs://
apollo-phx-nn.company.com:8020/user/dvasthimal/.sparkStaging/application_1425075571333_61948/avro-mapred-1.7.7-hadoop2.jar
15/03/04 03:20:52 INFO yarn.Client: Uploading
file:/home/dvasthimal/spark/avro-1.7.7.jar to hdfs://
apollo-phx-nn.company.com:8020/user/dvasthimal/.sparkStaging/application_1425075571333_61948/avro-1.7.7.jar
15/03/04 03:20:54 INFO yarn.Client: Setting up the launch environment
15/03/04 03:20:54 INFO yarn.Client: Setting up container launch context
15/03/04 03:20:54 INFO yarn.Client: Command for starting the Spark
ApplicationMaster: List($JAVA_HOME/bin/java, -server, -Xmx4096m,
-Djava.io.tmpdir=$PWD/tmp,
-Dspark.app.name=\""com.company.ep.poc.spark.reporting.SparkApp\"",
 -Dlog4j.configuration=log4j-spark-container.properties,
org.apache.spark.deploy.yarn.ApplicationMaster, --class,
com.company.ep.poc.spark.reporting.SparkApp, --jar ,
file:/home/dvasthimal/spark/spark_reporting-1.0-SNAPSHOT.jar,  --args
 'startDate=2015-02-16'  --args  'endDate=2015-02-16'  --args
 'epoutputdirectory=/user/dvasthimal/epdatasets_small/exptsession'  --args
 'subcommand=successevents'  --args
 'outputdir=/user/dvasthimal/epdatasets/successdetail' , --executor-memory,
2048, --executor-cores, 1, --num-executors , 3, 1>, <LOG_DIR>/stdout, 2>,
<LOG_DIR>/stderr)
15/03/04 03:20:54 INFO yarn.Client: Submitting application to ASM
15/03/04 03:20:54 INFO impl.YarnClientImpl: Submitted application
application_1425075571333_61948
15/03/04 03:20:56 INFO yarn.Client: Application report from ASM:
 application identifier: application_1425075571333_61948
 appId: 61948
 clientToAMToken: null
 appDiagnostics:
 appMasterHost: N/A
 appQueue: hdmi-spark
 appMasterRpcPort: -1
 appStartTime: 1425464454263
 yarnAppState: ACCEPTED
 distributedFinalState: UNDEFINED
 appTrackingUrl:
https://apollo-phx-rm-2.company.com:50030/proxy/application_1425075571333_61948/
 appUser: dvasthimal
15/03/04 03:21:18 INFO yarn.Client: Application report from ASM:
 application identifier: application_1425075571333_61948
 appId: 61948
 clientToAMToken: Token { kind: YARN_CLIENT_TOKEN, service:  }
 appDiagnostics:
 appMasterHost: phxaishdc9dn0169.phx.company.com
 appQueue: hdmi-spark
 appMasterRpcPort: 0
 appStartTime: 1425464454263
 yarnAppState: RUNNING
 distributedFinalState: UNDEFINED
 appTrackingUrl:
https://apollo-phx-rm-2.company.com:50030/proxy/application_1425075571333_61948/
 appUser: dvasthimal
….
….
15/03/04 03:21:22 INFO yarn.Client: Application report from ASM:
 application identifier: application_1425075571333_61948
 appId: 61948
 clientToAMToken: Token { kind: YARN_CLIENT_TOKEN, service:  }
 appDiagnostics:
 appMasterHost: phxaishdc9dn0169.phx.company.com
 appQueue: hdmi-spark
 appMasterRpcPort: 0
 appStartTime: 1425464454263
 yarnAppState: FINISHED
 distributedFinalState: FAILED
 appTrackingUrl:
https://apollo-phx-rm-2.company.com:50030/proxy/application_1425075571333_61948/A
 appUser: dvasthimal



AM failed with following exception

/apache/hadoop/bin/yarn logs -applicationId application_1425075571333_61948
15/03/04 03:21:22 INFO NewHadoopRDD: Input split: hdfs://
apollo-phx-nn.company.com:8020/user/dvasthimal/epdatasets_small/exptsession/2015/02/16/part-r-00000.avro:0+13890
15/03/04 03:21:22 ERROR Executor: Exception in task ID 3
java.lang.IncompatibleClassChangeError: Found interface
org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
at
org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:111)
at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:99)
at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:61)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
at org.apache.spark.rdd.FlatMappedRDD.compute(FlatMappedRDD.scala:33)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
at org.apache.spark.scheduler.Task.run(Task.scala:51)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:183)
at
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)



1) Having figured out the error the fix would be to put the right version
of avro libs into AM JVM classpath. Hence i included --jars
/home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar,/home/dvasthimal/spark/avro-1.7.7.jar
in spark-submit command. However i still see the same exception.
2) I tried to include these libs in SPARK_CLASSPATH. However i see the same
exception.


-- 
Deepak
"
Mingyu Kim <mkim@palantir.com>,"Thu, 5 Mar 2015 06:08:06 +0000","Re: Task result is serialized twice by serializer and closure
 serializer",Patrick Wendell <pwendell@gmail.com>,"Yep, that makes sense. Thanks for the clarification!

Mingyu





On 3/4/15, 8:05 PM, ""Patrick Wendell"" <pwendell@gmail.com> wrote:

>Yeah, it will result in a second serialized copy of the array (costing
>some memory). But the computational overhead should be very small. The
>absolute worst case here will be when doing a collect() or something
>similar that just bundles the entire partition.
>
>- Patrick
>
>On Wed, Mar 4, 2015 at 5:47 PM, Mingyu Kim <mkim@palantir.com> wrote:
>> The concern is really just the runtime overhead and memory footprint of
>> Java-serializing an already-serialized byte array again. We originally
>> noticed this when we were using RDD.toLocalIterator() which serializes
>>the
>> entire 64MB partition. We worked around this issue by kryo-serializing
>>and
>> snappy-compressing the partition on the executor side before returning
>>it
>> back to the driver, but this operation just felt redundant.
>>
>> Your explanation about reporting the time taken makes it clearer why
>>its
>> designed this way. Since the byte array for the serialized task result
>> shouldnt account for the majority of memory footprint anyways, Im okay
>> with leaving it as is, then.
>>
>> Thanks,
>> Mingyu
>>
>>
>>
>>
>>
>> On 3/4/15, 5:07 PM, ""Patrick Wendell"" <pwendell@gmail.com> wrote:
>>
>>>Hey Mingyu,
>>>
>>>I think it's broken out separately so we can record the time taken to
>>>serialize the result. Once we serializing it once, the second
>>>serialization should be really simple since it's just wrapping
>>>something that has already been turned into a byte buffer. Do you see
>>>a specific issue with serializing it twice?
>>>
>>>I think you need to have two steps if you want to record the time
>>>taken to serialize the result, since that needs to be sent back to the
>>>driver when the task completes.
>>>
>>>- Patrick
>>>
>>>On Wed, Mar 4, 2015 at 4:01 PM, Mingyu Kim <mkim@palantir.com> wrote:
>>>> Hi all,
>>>>
>>>> It looks like the result of task is serialized twice, once by
>>>>serializer (I.e. Java/Kryo depending on configuration) and once again
>>>>by
>>>>closure serializer (I.e. Java). To link the actual code,
>>>>
>>>> The first one:
>>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_apache_
>>>>sp
>>>>ark_blob_master_core_src_main_scala_org_apache_spark_executor_Executor.
>>>>sc
>>>>ala-23L213&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8&r=enn
>>>>QJ
>>>>q47pNnObsDh-88a9YUrUulcYQoV8giPASqXB84&m=dw_fNvxBZ1DixNDGBTXRZBKn36QFyH
>>>>-9
>>>>WMY_2Z07ulA&s=cSKekTNmnB0g54h6-FaF-zOL46UZC_1_LdKK3p9Q0aA&e=
>>>> The second one:
>>>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_apache_
>>>>sp
>>>>ark_blob_master_core_src_main_scala_org_apache_spark_executor_Executor.
>>>>sc
>>>>ala-23L226&d=AwIFAw&c=izlc9mHr637UR4lpLEZLFFS3Vn2UXBrZ4tFb6oOnmz8&r=enn
>>>>QJ
>>>>q47pNnObsDh-88a9YUrUulcYQoV8giPASqXB84&m=dw_fNvxBZ1DixNDGBTXRZBKn36QFyH
>>>>-9
>>>>WMY_2Z07ulA&s=PFoz0HyINd2XuiqkHPgyMsOh9eFkCwXOdl9zdxfBwxM&e=
>>>>
>>>> This serializes the ""value"", which is the result of task run twice,
>>>>which affects things like collect(), takeSample(), and
>>>>toLocalIterator(). Would it make sense to simply serialize the
>>>>DirectTaskResult once using the regular ""serializer"" (as opposed to
>>>>closure serializer)? Would it cause problems when the Accumulator
>>>>values
>>>>are not Kryo-serializable?
>>>>
>>>> Alternatively, if we can assume that Accumator values are small, we
>>>>can
>>>>closure-serialize those, put the serialized byte array in
>>>>DirectTaskResult with the raw task result ""value"", and serialize
>>>>DirectTaskResult.
>>>>
>>>> What do people think?
>>>>
>>>> Thanks,
>>>> Mingyu
>>

"
Xiangrui Meng <mengxr@gmail.com>,"Wed, 4 Mar 2015 23:35:13 -0800",Re: enum-like types in Spark,Patrick Wendell <pwendell@gmail.com>,"`case object` inside an `object` doesn't show up in Java. This is the
minimal code I found to make everything show up correctly in both
Scala and Java:

sealed abstract class StorageLevel // cannot be a trait

object StorageLevel {

}


---------------------------------------------------------------------


"
Aaron Davidson <ilikerps@gmail.com>,"Wed, 4 Mar 2015 23:45:01 -0800",Re: enum-like types in Spark,Xiangrui Meng <mengxr@gmail.com>,"That's kinda annoying, but it's just a little extra boilerplate. Can you
were case classes with empty constructors, without the field?


"
Mridul Muralidharan <mridul@gmail.com>,"Thu, 5 Mar 2015 00:16:10 -0800",Re: enum-like types in Spark,Aaron Davidson <ilikerps@gmail.com>,"While I dont have any strong opinions about how we handle enum's
either way in spark, I assume the discussion is targetted at (new) api
being designed in spark.
Rewiring what we already have exposed will lead to incompatible api
change (StorageLevel for example, is in 1.0).

Regards,
Mridul


---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Thu, 5 Mar 2015 00:19:18 -0800",Re: enum-like types in Spark,Mridul Muralidharan <mridul@gmail.com>,"Yes - only new or internal API's. I doubt we'd break any exposed APIs for
the purpose of clean up.

Patrick

"
Pei-Lun Lee <pllee@appier.com>,"Thu, 5 Mar 2015 16:28:40 +0800",Re: Which OutputCommitter to use for S3?,"""user@spark.apache.org"" <user@spark.apache.org>, dev@spark.apache.org","Thanks for the DirectOutputCommitter example.
However I found it only works for saveAsHadoopFile. What about
saveAsParquetFile?
It looks like SparkSQL is using ParquetOutputCommitter, which is subclass
of FileOutputCommitter.


e
th
it
d
d
er.
7)
ons
.sc
.sc
a:7
'm
aron
Z4tFb6o
ZRf6sFs
&e=
,
o
h
:
yone using a
r,
a
ent
mz8&r=e
Ovl_-
= .
or
"
Aaron Davidson <ilikerps@gmail.com>,"Thu, 5 Mar 2015 00:32:12 -0800",Re: Which OutputCommitter to use for S3?,Pei-Lun Lee <pllee@appier.com>,"Yes, unfortunately that direct dependency makes this injection much more
difficult for saveAsParquetFile.


.
e.
with
d
r.
)
ns
sc
sc
:7
in
;
ron
4tFb6o
Rf6sFs
e=
op
x
r
anyone
apa
nt
z8&r=e
vl_-
e= .
n
e
"
Akhil Das <akhil@sigmoidanalytics.com>,"Thu, 5 Mar 2015 15:34:07 +0530",Re: Unable to Read/Write Avro RDD on cluster.,,"Here's a workaround:

- Download and put this jar
<http://repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.7.7/
avro-mapred-1.7.7-hadoop2.jar> in the SPARK_CLASSPATH in all workers
- Make sure that jar is present in the same path in all workers.

Thanks
Best Regards


s
company-2.jar:/apache/hadoop/lib/hadoop-lzo-0.6.0.jar:/home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar:/home/dvasthimal/spark/avro-1.7.7.jar
rk/avro-1.7.7.jar
s
p
ds
n
1425075571333_61948/spark_reporting-1.0-SNAPSHOT.jar
2-hadoop2.4.1.jar
1425075571333_61948/spark-assembly-1.0.2-hadoop2.4.1.jar
1425075571333_61948/avro-mapred-1.7.7-hadoop2.jar
1425075571333_61948/avro-1.7.7.jar
rgs
ory,
_61948/
_61948/
_61948/A
48
on/2015/02/16/part-r-00000.avro:0+13890
putFormat.java:47)
1)
:1145)
a:615)
rk/avro-1.7.7.jar
me
"
"java8964 <java8964@hotmail.com>
	""dev@spark.apache.org"" <dev@spark.apache.org>","Thu, 5 Mar 2015 09:28:55 -0500",RE: Unable to Read/Write Avro RDD on cluster.,,"You can give Spark-Avro a try. It works great for our project.
https://github.com/databricks/spark-avro

> From: deepujain@gmail.com
> Date: Thu, 5 Mar 2015 10:27:04 +0530
> Subject: Fwd: Unable to Read/Write Avro RDD on cluster.
> To: dev@spark.apache.org
> 
> I am trying to read RDD avro, transform and write.
> I am able to run it locally fine but when i run onto cluster, i see issues
> with Avro.
> 
> 
> export SPARK_HOME=/home/dvasthimal/spark/spark-1.0.2-bin-2.4.1
> export SPARK_YARN_USER_ENV=""CLASSPATH=/apache/hadoop/conf""
> export HADOOP_CONF_DIR=/apache/hadoop/conf
> export YARN_CONF_DIR=/apache/hadoop/conf
> export SPARK_JAR=$SPARK_HOME/lib/spark-assembly-1.0.2-hadoop2.4.1.jar
> export SPARK_LIBRARY_PATH=/apache/hadoop/lib/native
> export SPARK_YARN_USER_ENV=""CLASSPATH=/apache/hadoop/conf""
> export SPARK_YARN_USER_ENV=""CLASSPATH=/apache/hadoop/conf""
> export
> SPARK_CLASSPATH=/apache/hadoop/share/hadoop/common/hadoop-common-2.4.1-company-2.jar:/apache/hadoop/lib/hadoop-lzo-0.6.0.jar:/home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar:/home/dvasthimal/spark/avro-1.7.7.jar
> export SPARK_LIBRARY_PATH=""/apache/hadoop/lib/native""
> export YARN_CONF_DIR=/apache/hadoop/conf/
> 
> cd $SPARK_HOME
> 
> ./bin/spark-submit --master yarn-cluster --jars
> /home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar,/home/dvasthimal/spark/avro-1.7.7.jar
> --num-executors 3 --driver-memory 4g --executor-memory 2g --executor-cores
> 1  --queue hdmi-spark --class com.company.ep.poc.spark.reporting.SparkApp
> /home/dvasthimal/spark/spark_reporting-1.0-SNAPSHOT.jar
> startDate=2015-02-16 endDate=2015-02-16
> epoutputdirectory=/user/dvasthimal/epdatasets_small/exptsession
> subcommand=successevents
> outputdir=/user/dvasthimal/epdatasets/successdetail
> 
> Spark assembly has been built with Hive, including Datanucleus jars on
> classpath
> 15/03/04 03:20:29 INFO client.ConfiguredRMFailoverProxyProvider: Failing
> over to rm2
> 15/03/04 03:20:30 INFO yarn.Client: Got Cluster metric info from
> ApplicationsManager (ASM), number of NodeManagers: 2221
> 15/03/04 03:20:30 INFO yarn.Client: Queue info ... queueName: hdmi-spark,
> queueCurrentCapacity: 0.7162806, queueMaxCapacity: 0.08,
>       queueApplicationCount = 7, queueChildQueueCount = 0
> 15/03/04 03:20:30 INFO yarn.Client: Max mem capabililty of a single
> resource in this cluster 16384
> 15/03/04 03:20:30 INFO yarn.Client: Preparing Local resources
> 15/03/04 03:20:30 WARN util.NativeCodeLoader: Unable to load native-hadoop
> library for your platform... using builtin-java classes where applicable
> 15/03/04 03:20:30 WARN hdfs.BlockReaderLocal: The short-circuit local reads
> feature cannot be used because libhadoop cannot be loaded.
> 
> 
> 15/03/04 03:20:46 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token
> 7780745 for dvasthimal on 10.115.206.112:8020
> 15/03/04 03:20:46 INFO yarn.Client: Uploading
> file:/home/dvasthimal/spark/spark_reporting-1.0-SNAPSHOT.jar to hdfs://
> apollo-phx-nn.company.com:8020/user/dvasthimal/.sparkStaging/application_1425075571333_61948/spark_reporting-1.0-SNAPSHOT.jar
> 15/03/04 03:20:47 INFO yarn.Client: Uploading
> file:/home/dvasthimal/spark/spark-1.0.2-bin-2.4.1/lib/spark-assembly-1.0.2-hadoop2.4.1.jar
> to hdfs://
> apollo-phx-nn.company.com:8020/user/dvasthimal/.sparkStaging/application_1425075571333_61948/spark-assembly-1.0.2-hadoop2.4.1.jar
> 15/03/04 03:20:52 INFO yarn.Client: Uploading
> file:/home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar to hdfs://
> apollo-phx-nn.company.com:8020/user/dvasthimal/.sparkStaging/application_1425075571333_61948/avro-mapred-1.7.7-hadoop2.jar
> 15/03/04 03:20:52 INFO yarn.Client: Uploading
> file:/home/dvasthimal/spark/avro-1.7.7.jar to hdfs://
> apollo-phx-nn.company.com:8020/user/dvasthimal/.sparkStaging/application_1425075571333_61948/avro-1.7.7.jar
> 15/03/04 03:20:54 INFO yarn.Client: Setting up the launch environment
> 15/03/04 03:20:54 INFO yarn.Client: Setting up container launch context
> 15/03/04 03:20:54 INFO yarn.Client: Command for starting the Spark
> ApplicationMaster: List($JAVA_HOME/bin/java, -server, -Xmx4096m,
> -Djava.io.tmpdir=$PWD/tmp,
> -Dspark.app.name=\""com.company.ep.poc.spark.reporting.SparkApp\"",
>  -Dlog4j.configuration=log4j-spark-container.properties,
> org.apache.spark.deploy.yarn.ApplicationMaster, --class,
> com.company.ep.poc.spark.reporting.SparkApp, --jar ,
> file:/home/dvasthimal/spark/spark_reporting-1.0-SNAPSHOT.jar,  --args
>  'startDate=2015-02-16'  --args  'endDate=2015-02-16'  --args
>  'epoutputdirectory=/user/dvasthimal/epdatasets_small/exptsession'  --args
>  'subcommand=successevents'  --args
>  'outputdir=/user/dvasthimal/epdatasets/successdetail' , --executor-memory,
> 2048, --executor-cores, 1, --num-executors , 3, 1>, <LOG_DIR>/stdout, 2>,
> <LOG_DIR>/stderr)
> 15/03/04 03:20:54 INFO yarn.Client: Submitting application to ASM
> 15/03/04 03:20:54 INFO impl.YarnClientImpl: Submitted application
> application_1425075571333_61948
> 15/03/04 03:20:56 INFO yarn.Client: Application report from ASM:
>  application identifier: application_1425075571333_61948
>  appId: 61948
>  clientToAMToken: null
>  appDiagnostics:
>  appMasterHost: N/A
>  appQueue: hdmi-spark
>  appMasterRpcPort: -1
>  appStartTime: 1425464454263
>  yarnAppState: ACCEPTED
>  distributedFinalState: UNDEFINED
>  appTrackingUrl:
> https://apollo-phx-rm-2.company.com:50030/proxy/application_1425075571333_61948/
>  appUser: dvasthimal
> 15/03/04 03:21:18 INFO yarn.Client: Application report from ASM:
>  application identifier: application_1425075571333_61948
>  appId: 61948
>  clientToAMToken: Token { kind: YARN_CLIENT_TOKEN, service:  }
>  appDiagnostics:
>  appMasterHost: phxaishdc9dn0169.phx.company.com
>  appQueue: hdmi-spark
>  appMasterRpcPort: 0
>  appStartTime: 1425464454263
>  yarnAppState: RUNNING
>  distributedFinalState: UNDEFINED
>  appTrackingUrl:
> https://apollo-phx-rm-2.company.com:50030/proxy/application_1425075571333_61948/
>  appUser: dvasthimal
> ….
> ….
> 15/03/04 03:21:22 INFO yarn.Client: Application report from ASM:
>  application identifier: application_1425075571333_61948
>  appId: 61948
>  clientToAMToken: Token { kind: YARN_CLIENT_TOKEN, service:  }
>  appDiagnostics:
>  appMasterHost: phxaishdc9dn0169.phx.company.com
>  appQueue: hdmi-spark
>  appMasterRpcPort: 0
>  appStartTime: 1425464454263
>  yarnAppState: FINISHED
>  distributedFinalState: FAILED
>  appTrackingUrl:
> https://apollo-phx-rm-2.company.com:50030/proxy/application_1425075571333_61948/A
>  appUser: dvasthimal
> 
> 
> 
> AM failed with following exception
> 
> /apache/hadoop/bin/yarn logs -applicationId application_1425075571333_61948
> 15/03/04 03:21:22 INFO NewHadoopRDD: Input split: hdfs://
> apollo-phx-nn.company.com:8020/user/dvasthimal/epdatasets_small/exptsession/2015/02/16/part-r-00000.avro:0+13890
> 15/03/04 03:21:22 ERROR Executor: Exception in task ID 3
> java.lang.IncompatibleClassChangeError: Found interface
> org.apache.hadoop.mapreduce.TaskAttemptContext, but class was expected
> at
> org.apache.avro.mapreduce.AvroKeyInputFormat.createRecordReader(AvroKeyInputFormat.java:47)
> at org.apache.spark.rdd.NewHadoopRDD$$anon$1.<init>(NewHadoopRDD.scala:111)
> at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:99)
> at org.apache.spark.rdd.NewHadoopRDD.compute(NewHadoopRDD.scala:61)
> at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
> at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
> at org.apache.spark.rdd.FlatMappedRDD.compute(FlatMappedRDD.scala:33)
> at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
> at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
> at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
> at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
> at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
> at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
> at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
> at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
> at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
> at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
> at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
> at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
> at org.apache.spark.scheduler.Task.run(Task.scala:51)
> at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:183)
> at
> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
> at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
> at java.lang.Thread.run(Thread.java:745)
> 
> 
> 
> 1) Having figured out the error the fix would be to put the right version
> of avro libs into AM JVM classpath. Hence i included --jars
> /home/dvasthimal/spark/avro-mapred-1.7.7-hadoop2.jar,/home/dvasthimal/spark/avro-1.7.7.jar
> in spark-submit command. However i still see the same exception.
> 2) I tried to include these libs in SPARK_CLASSPATH. However i see the same
> exception.
> 
> 
> -- 
> Deepak
 		 	   		  "
shane knapp <sknapp@berkeley.edu>,"Thu, 5 Mar 2015 06:57:30 -0800",Re: short jenkins 7am downtime tomorrow morning (3-5-15),"amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>","this is happening now.  i'm waiting for the pull request builders to finish
(~16 mins) before i start.


"
shane knapp <sknapp@berkeley.edu>,"Thu, 5 Mar 2015 08:29:19 -0800",Re: short jenkins 7am downtime tomorrow morning (3-5-15),"amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>","we're all back up and building now...  looks like the package/kernel
updates went off w/o a hitch!


"
"""M. Dale"" <medale94@yahoo.com.INVALID>","Thu, 05 Mar 2015 13:36:34 -0500",Re: Fwd: Unable to Read/Write Avro RDD on cluster.,"=?UTF-8?B?IsOQzp7igqzPgUDSnCAo4LmPzK/NoeC5jyki?=
 <deepujain@gmail.com>, dev@spark.apache.org","There was a avro-mapred version conflict described in 
https://issues.apache.org/jira/browse/SPARK-3039.
Fixed by https://github.com/apache/spark/pull/4315 for Spark 1.3.

Here is a link that describes how to fix Spark 1.2.1 for avro-mapred 
hadoop2: 
https://github.com/medale/spark-mail/blob/master/presentation/CreatingAvroMapred2Spark.md

We had built that 1.2.1 version for a demo for the February MD Apache 
Spark meetup (http://www.meetup.com/Apache-Spark-Maryland/) that was 
hosted at 
https://s3.amazonaws.com/morris-datasets/ENRON/demo/spark-1.2.1.tar.gz.

Hope this helps,
Markus



---------------------------------------------------------------------


"
Imran Rashid <irashid@cloudera.com>,"Thu, 5 Mar 2015 15:08:56 -0600",Re: enum-like types in Spark,dev <dev@spark.apache.org>,"I have a very strong dislike for #1 (scala enumerations).   I'm ok with #4
(with Xiangrui's final suggestion, especially making it sealed & available
in Java), but I really think #2, java enums, are the best option.

Java enums actually have some very real advantages over the other
approaches -- you get values(), valueOf(), EnumSet, and EnumMap.  There has
been endless debate in the Scala community about the problems with the
approaches in Scala.  Very smart, level-headed Scala gurus have complained
about their short-comings (Rex Kerr's name is coming to mind, though I'm
not positive about that); there have been numerous well-thought out
proposals to give Scala a better enum.  But the powers-that-be in Scala
always reject them.  IIRC the explanation for rejecting is basically that
(a) enums aren't important enough for introducing some new special feature,
scala's got bigger things to work on and (b) if you really need a good
enum, just use java's enum.

I doubt it really matters that much for Spark internals, which is why I
think #4 is fine.  But I figured I'd give my spiel, because every developer
loves language wars :)

Imran




"
Reynold Xin <rxin@databricks.com>,"Thu, 5 Mar 2015 13:26:46 -0800",over 10000 commits!,"""dev@spark.apache.org"" <dev@spark.apache.org>","We reached a new milestone today.

https://github.com/apache/spark


10,001 commits now. Congratulations to Xiangrui for making the 10000th
commit!
"
shane knapp <sknapp@berkeley.edu>,"Thu, 5 Mar 2015 13:34:33 -0800",Re: over 10000 commits!,Reynold Xin <rxin@databricks.com>,"WOOT!


"
Patrick Wendell <pwendell@gmail.com>,"Thu, 5 Mar 2015 18:52:34 -0800",[VOTE] Release Apache Spark 1.3.0 (RC3),"""dev@spark.apache.org"" <dev@spark.apache.org>","Please vote on releasing the following candidate as Apache Spark version 1.3.0!

The tag to be voted on is v1.3.0-rc2 (commit 4aaf48d4):
https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=4aaf48d46d13129f0f9bdafd771dd80fe568a7dc

The release files, including signatures, digests, etc. can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-rc3/

Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/pwendell.asc

Staging repositories for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1078

The documentation corresponding to this release can be found at:
http://people.apache.org/~pwendell/spark-1.3.0-rc3-docs/

Please vote on releasing this package as Apache Spark 1.3.0!

The vote is open until Monday, March 09, at 02:52 UTC and passes if
a majority of at least 3 +1 PMC votes are cast.

[ ] +1 Release this package as Apache Spark 1.3.0
[ ] -1 Do not release this package because ...

To learn more about Apache Spark, please see
http://spark.apache.org/

== How does this compare to RC2 ==
This release includes the following bug fixes:

https://issues.apache.org/jira/browse/SPARK-6144
https://issues.apache.org/jira/browse/SPARK-6171
https://issues.apache.org/jira/browse/SPARK-5143
https://issues.apache.org/jira/browse/SPARK-6182
https://issues.apache.org/jira/browse/SPARK-6175

== How can I help test this release? ==
If you are a Spark user, you can help us test this release by
taking a Spark 1.2 workload and running on this release candidate,
then reporting any regressions.

If you are happy with this release based on your own testing, give a +1 vote.

== What justifies a -1 vote for this release? ==
This vote is happening towards the end of the 1.3 QA period,
so -1 votes should only occur for significant regressions from 1.2.1.
Bugs already present in 1.2.X, minor regressions, or bugs related
to new features will not block this release.

---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Thu, 5 Mar 2015 18:52:19 -0800",[RESULT] [VOTE] Release Apache Spark 1.3.0 (RC2),"""dev@spark.apache.org"" <dev@spark.apache.org>","This vote is cancelled in favor of RC3.


---------------------------------------------------------------------


"
Xiangrui Meng <mengxr@gmail.com>,"Thu, 5 Mar 2015 19:58:32 -0800",Re: enum-like types in Spark,Imran Rashid <irashid@cloudera.com>,"For #4, my previous proposal may confuse the IDEs with additional
types generated by the case objects, and their toString contain the
underscore. The following works better:

sealed abstract class StorageLevel

object StorageLevel {
  }

 }
}

okay with this approach, I can add it to the code style guide.

Imran, this is not just for internal APIs, which are relatively more
flexible. It is good to use the same approach to implement public
enum-like types from now on.

Best,
Xiangrui


---------------------------------------------------------------------


"
Mridul Muralidharan <mridul@gmail.com>,"Thu, 5 Mar 2015 20:49:02 -0800",Re: enum-like types in Spark,Imran Rashid <irashid@cloudera.com>,"  I have a strong dislike for java enum's due to the fact that they
are not stable across JVM's - if it undergoes serde, you end up with
unpredictable results at times [1].
highly possible users might depend on it internally and shoot
themselves in the foot.

Would be better to keep away from them in general and use something more stable.

Regards,
Mridul

[1] Having had to debug this issue for 2 weeks - I really really hate it.



---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Thu, 5 Mar 2015 23:59:37 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),"""dev@spark.apache.org"" <dev@spark.apache.org>","I'll kick it off with a +1.


---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Fri, 6 Mar 2015 09:04:34 +0000",Re: enum-like types in Spark,Xiangrui Meng <mengxr@gmail.com>,"This has some disadvantage for Java, I think. You can't switch on an
object defined like this, but you can with an enum. And although the
scala compiler understands that the set of values is fixed because of
'sealed' and so can warn about missing cases, the JVM won't know this,
and can't do the same.


---------------------------------------------------------------------


"
Ewan Higgs <ewan.higgs@ugent.be>,"Fri, 06 Mar 2015 10:41:14 +0100",Fwd: SparkSpark-perf terasort WIP branch,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi all,
I never heard from anyone on this and have received emails in private 
that people would like to add terasort to their spark-perf installs so 
it becomes part of their cluster validation checks.

Yours,
Ewan

-------- Forwarded Message --------
Subject: 	SparkSpark-perf terasort WIP branch
Date: 	Wed, 14 Jan 2015 14:33:45 +0100
From: 	Ewan Higgs <ewan.higgs@ugent.be>
To: 	dev@spark.apache.org <dev@spark.apache.org>



Hi all,
I'm trying to build the Spark-perf WIP code but there are some errors to
do with Hadoop APIs. I presume this is because there is some Hadoop
version set and it's referring to that. But I can't seem to find it.

The errors are as follows:

[info] Compiling 15 Scala sources and 2 Java sources to
/home/ehiggs/src/spark-perf/spark-tests/target/scala-2.10/classes...
[error]
/home/ehiggs/src/spark-perf/spark-tests/src/main/scala/spark/perf/terasort/TeraInputFormat.scala:40:
object task is not a member of package org.apache.hadoop.mapreduce
[error] import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl
[error]                                    ^
[error]
/home/ehiggs/src/spark-perf/spark-tests/src/main/scala/spark/perf/terasort/TeraInputFormat.scala:132:
not found: type TaskAttemptContextImpl
[error]             val context = new TaskAttemptContextImpl(
[error]                               ^
[error]
/home/ehiggs/src/spark-perf/spark-tests/src/main/scala/spark/perf/terasort/TeraScheduler.scala:37:
object TTConfig is not a member of package
org.apache.hadoop.mapreduce.server.tasktracker
[error] import org.apache.hadoop.mapreduce.server.tasktracker.TTConfig
[error]        ^
[error]
/home/ehiggs/src/spark-perf/spark-tests/src/main/scala/spark/perf/terasort/TeraScheduler.scala:91:
not found: value TTConfig
[error]   var slotsPerHost : Int = conf.getInt(TTConfig.TT_MAP_SLOTS, 4)
[error]                                        ^
[error]
/home/ehiggs/src/spark-perf/spark-tests/src/main/scala/spark/perf/terasort/TeraSortAll.scala:7:
value run is not a member of org.apache.spark.examples.terasort.TeraGen
[error]     tg.run(Array[String](""10M"", ""/tmp/terasort_in""))
[error]        ^
[error]
/home/ehiggs/src/spark-perf/spark-tests/src/main/scala/spark/perf/terasort/TeraSortAll.scala:9:
value run is not a member of org.apache.spark.examples.terasort.TeraSort
[error]     ts.run(Array[String](""/tmp/terasort_in"", ""/tmp/terasort_out""))
[error]        ^
[error] 6 errors found
[error] (compile:compile) Compilation failed
[error] Total time: 13 s, completed 05-Jan-2015 12:21:47

I can build the same code if it's in the Spark tree using the following
command:
mvn -Dhadoop.version=2.5.0 -DskipTests=true install

Is there a way I can convince spark-perf to build this code with the
appropriate Hadoop library version? I tried to apply the following to
spark-tests/project/SparkTestsBuild.scala but it didn't seem to work as
I expected:

$ git diff project/SparkTestsBuild.scala
diff --git a/spark-tests/project/SparkTestsBuild.scala
b/spark-tests/project/SparkTestsBuild.scala
index 4116326..4ed5f0c 100644
--- a/spark-tests/project/SparkTestsBuild.scala
+++ b/spark-tests/project/SparkTestsBuild.scala
@@ -16,7 +16,9 @@ object SparkTestsBuild extends Build {
           ""org.scalatest"" %% ""scalatest"" % ""2.2.1"" % ""test"",
           ""com.google.guava"" % ""guava"" % ""14.0.1"",
           ""org.apache.spark"" %% ""spark-core"" % ""1.0.0"" % ""provided"",
-        ""org.json4s"" %% ""json4s-native"" % ""3.2.9""
+        ""org.json4s"" %% ""json4s-native"" % ""3.2.9"",
+        ""org.apache.hadoop"" % ""hadoop-common"" % ""2.5.0"",
+        ""org.apache.hadoop"" % ""hadoop-mapreduce"" % ""2.5.0""
         ),
         test in assembly := {},
         outputPath in assembly :=
file(""target/spark-perf-tests-assembly.jar""),
@@ -36,4 +38,4 @@ object SparkTestsBuild extends Build {
           case _ => MergeStrategy.first
         }
       ))
-}
\ No newline at end of file
+}


Yours,
Ewan



"
Sean Owen <sowen@cloudera.com>,"Fri, 6 Mar 2015 14:03:16 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"There are still three JIRAs marked as blockers for 1.3.0:

SPARK-5310 Update SQL programming guide for 1.3
SPARK-5183 Document data source API
SPARK-6128 Update Spark Streaming Guide for Spark 1.3

As a matter of hygiene, let's either mark them resolved if they're
resolved, or push them / deprioritize them.


Signatures look good, source compiles with a Hadoop-2.6 + YARN +
Hive-flavored build, for me.


first RC, but agree this isn't a blocker:

UISeleniumSuite:
*** RUN ABORTED ***
  java.lang.NoClassDefFoundError: org/w3c/dom/ElementTraversal
  ...



- udf_std *** FAILED ***
  Results do not match for udf_std:
  DESCRIBE FUNCTION EXTENDED std
  == Parsed Logical Plan ==
  HiveNativeCommand DESCRIBE FUNCTION EXTENDED std

  == Analyzed Logical Plan ==
  HiveNativeCommand DESCRIBE FUNCTION EXTENDED std

  == Optimized Logical Plan ==
  HiveNativeCommand DESCRIBE FUNCTION EXTENDED std

  == Physical Plan ==
  ExecutedCommand (HiveNativeCommand DESCRIBE FUNCTION EXTENDED std)

  Code Generation: false
  == RDD ==
  result
  !== HIVE - 2 row(s) ==                                         ==
CATALYST - 2 row(s) ==
   std(x) - Returns the standard deviation of a set of numbers
std(x) - Returns the standard deviation of a set of numbers
  !Synonyms: stddev_pop, stddev
Synonyms: stddev, stddev_pop (HiveComparisonTest.scala:384)


Before I give a +1 I wanted to see if anyone sees these test failures
too, and/or believes they're ignorable for some reason. I also want to
resolve the open blocker JIRAs.



---------------------------------------------------------------------


"
Hector Yee <hector.yee@gmail.com>,"Fri, 6 Mar 2015 10:05:14 -0800",Re: over 10000 commits!,shane knapp <sknapp@berkeley.edu>,"Congrats!





-- 
Yee Yang Li Hector <http://google.com/+HectorYee>
*google.com/+HectorYee <http://google.com/+HectorYee>*
"
Patrick Wendell <pwendell@gmail.com>,"Fri, 6 Mar 2015 10:43:05 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Sean Owen <sowen@cloudera.com>,"Hey Sean,


For these, the issue is that they are documentation JIRA's, which
don't need to be timed exactly with the release vote, since we can
update the documentation on the website whenever we want. In the past
I've just mentally filtered these out when considering RC's. I see a
few options here:

1. We downgrade such issues away from Blocker (more clear, but we risk
loosing them in the fray if they really are things we want to have
before the release is posted).
2. We provide a filter to the community that excludes 'Documentation'
issues and shows all other blockers for 1.3. We can put this on the
wiki, for instance.

Which do you prefer?

- Patrick

---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Fri, 6 Mar 2015 19:02:06 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"Given the title and tagging, it sounds like there could be some
must-have doc changes to go with what is being released as 1.3. It can
be finished later, and published later, but then the docs source
shipped with the release doesn't match the site, and until then, 1.3
is released without some ""must-have"" docs for 1.3 on the site.

The real question to me is: are there any further, absolutely
essential doc changes that need to accompany 1.3 or not?

If not, just resolve these. If there are, then it seems like the
release has to block on them. If there are some docs that should have
gone in for 1.3, but didn't, but aren't essential, well I suppose it
bears thinking about how to not slip as much work, but it doesn't
block.

I think Documentation issues certainly can be a blocker and shouldn't
be specially ignored.


BTW the UISeleniumSuite issue is a real failure, but I do not think it
is serious: http://issues.apache.org/jira/browse/SPARK-6205  It isn't
a regression from 1.2.x, but only affects tests, and only affects a
subset of build profiles.





---------------------------------------------------------------------


"
Marcelo Vanzin <vanzin@cloudera.com>,"Fri, 6 Mar 2015 11:22:29 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"+1 (non-binding, doc issues aside)

Ran batch of tests against yarn and standalone, including tests for
rc2 blockers, all looks fine.




-- 
Marcelo

---------------------------------------------------------------------


"
Krishna Sankar <ksankar42@gmail.com>,"Fri, 6 Mar 2015 12:01:32 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"+1 (non-binding, of course)

1. Compiled OSX 10.10 (Yosemite) OK Total time: 13:55 min
     mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4
-Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11
2. Tested pyspark, mlib - running as well as comp"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Fri, 6 Mar 2015 20:55:18 +0000",Loading previously serialized object to Spark,dev <dev@spark.apache.org>,"Hi,

I've implemented class MyClass in MLlib that does some operation on LabeledPoint. MyClass extends serializable, so I can map this operation on data of RDD[LabeledPoints], such as data.map(lp => MyClass.operate(lp)). I write this class in file with ObjectOutputStream.writeObject. Then I stop and restart Spark. I load this class from file with ObjectInputStream.readObject.asInstanceOf[MyClass]. When I try to map the same operation of this class to RDD, Spark throws not serializable exception:
org.apache.spark.SparkException: Task not serializable
        at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
        at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
        at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
        at org.apache.spark.rdd.RDD.map(RDD.scala:273)

Could you suggest why it throws this exception while MyClass is serializable by definition?

Best regards, Alexander
"
Patrick Wendell <pwendell@gmail.com>,"Fri, 6 Mar 2015 13:17:34 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Sean Owen <sowen@cloudera.com>,"Sean,

The docs are distributed and consumed in a fundamentally different way
than Spark code itself. So we've always considered the ""deadline"" for
doc changes to be when the release is finally posted.

If there are small inconsistencies with the docs present in the source
code for that release tag, IMO that doesn't matter much since we don't
even distribute the docs with Spark's binary releases and virtually no
one builds and hosts the docs on their own (that I am aware of, at
least). Perhaps we can recommend if people want to build the doc
sources that they should always grab the head of the most recent
release branch, to set expectations accordingly.

In the past we haven't considered it worth holding up the release
process for the purpose of the docs. It just doesn't make sense since
they are consumed ""as a service"". If we decide to change this
convention, it would mean shipping our releases later, since we
could't pipeline the doc finalization with voting.

- Patrick


---------------------------------------------------------------------


"
Tathagata Das <tdas@databricks.com>,"Fri, 6 Mar 2015 13:21:21 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"To add to what Patrick said, the only reason that those JIRAs are marked as
Blockers (at least I can say for myself) is so that they are at the top of
the JIRA list signifying that these are more *immediate* issues than all
the Critical issues. To make it less confusing for the community voting, we
can definitely add a filter that ignores Documentation issues from the JIRA
list.



"
Sean Owen <sowen@cloudera.com>,"Fri, 6 Mar 2015 21:36:08 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"Although the problem is small, especially if indeed the essential docs
changes are following just a couple days behind the final release, I
mean, why the rush if they're essential? wait a couple days, finish
them, make the release.

Answer is, I think these changes aren't actually essential given the
comment from tdas, so: just mark these Critical? (although ... they do
say they're changes for the 1.3 release, so kind of funny to get to
them for 1.3.x or 1.4, but that's not important now.)

I thought that Blocker really meant Blocker in this project, as I've
been encouraged to use it to mean ""don't release without this."" I
think we should use it that way. Just thinking of it as ""extra
Critical"" doesn't add anything. I don't think Documentation should be
special-cased as less important, and I don't think there's confusion
if Blocker means what it says, so I'd 'fix' that way.

If nobody sees the Hive failure I observed, and if we can just zap
those ""Blockers"" one way or the other, +1



---------------------------------------------------------------------


"
turp1twin <turp1twin@gmail.com>,"Fri, 6 Mar 2015 17:20:09 -0700 (MST)",Block Transfer Service encryption support,dev@spark.apache.org,"Is there a plan to implement SSL support for the Block Transfer Service
(specifically, the NettyBlockTransferService implementation)? I can
volunteer if needed...

Jeff




--

---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Fri, 6 Mar 2015 23:19:57 -0800",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Sean Owen <sowen@cloudera.com>,"For now, I'll just put this as critical. We can discuss the
documentation stuff offline or in another thread.


---------------------------------------------------------------------


"
Akhil Das <akhil@sigmoidanalytics.com>,"Sun, 8 Mar 2015 15:47:18 +0530",Re: Loading previously serialized object to Spark,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Can you paste the complete code?

Thanks
Best Regards


"
Matei Zaharia <matei.zaharia@gmail.com>,"Sun, 8 Mar 2015 15:42:31 -0400",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"+1

Tested it on Mac OS X.

without Hive, which is kind of weird because people will more likely want Hadoop 2 with Hive. So it would be good to publish a build for that configuration instead. We can do it if we do a new RC, or it might be that binary bui"
Sean Owen <sowen@cloudera.com>,"Sun, 8 Mar 2015 19:46:39 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Matei Zaharia <matei.zaharia@gmail.com>,"Yeah, interesting question of what is the better default for the
single set of artifacts published to Maven. I think there's an
argument for Hadoop 2 and perhaps Hive for the 2.10 build too. Pros
and cons discussed more at

https://issues.apache.org/jira/browse/SPARK-5134
https://github.com/apache/spark/pull/3917

te:
without Hive, which is kind of weird because people will more likely want Hadoop 2 with Hive. So it would be good to publish a build for that configuration instead. We can do it if we do a new RC, or it might be that binary builds may not need to be voted on (I forgot the details there).

---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Sun, 8 Mar 2015 14:11:15 -0700",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Sean Owen <sowen@cloudera.com>,"We probably want to revisit the way we do binaries in general for
1.4+. IMO, something worth forking a separate thread for.

I've been hesitating to add new binaries because people
(understandably) complain if you ever stop packaging older ones, but
on the other hand the ASF has complained that we have too many
binaries already and that we need to pare it down because of the large
volume of files. Doubling the number of binaries we produce for Scala
2.11 seemed like it would be too much.

binaries and encourage users to use these by simply setting
HADOOP_HOME, or have instructions for specific distros. I've heard
that our existing packages don't work well on HDP for instance, since
there are some configuration quirks that differ from the upstream
Hadoop.

If we cut down on the cross building for Hadoop versions, then it is
more tenable to cross build for Scala versions without exploding the
number of binaries.

- Patrick

rote:
 without Hive, which is kind of weird because people will more likely want Hadoop 2 with Hive. So it would be good to publish a build for that configuration instead. We can do it if we do a new RC, or it might be that binary builds may not need to be voted on (I forgot the details there).

---------------------------------------------------------------------


"
Krishna Sankar <ksankar42@gmail.com>,"Sun, 8 Mar 2015 14:42:43 -0700",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"Yep, otherwise this will become an N^2 problem - Scala versions X Hadoop
Distributions X ...

May be one option is to have a minimum basic set (which I know is what we
are discussing) and move the rest to spark-packages.org. There the vendors
can add the latest downloads - for example when 1.4 is released, HDP can
build a release of HDP Spark 1.4 bundle.

Cheers
<k/>


"
Sean Owen <sowen@cloudera.com>,"Sun, 8 Mar 2015 21:56:31 +0000","Release Scala version vs Hadoop version (was: [VOTE] Release Apache
 Spark 1.3.0 (RC3))",Krishna Sankar <ksankar42@gmail.com>,"Ah. I misunderstood that Matei was referring to the Scala 2.11 tarball
at http://people.apache.org/~pwendell/spark-1.3.0-rc3/ and not the
Maven artifacts.

Patrick I see you just commented on SPARK-5134 and will follow up
there. Sounds like this may accidentally not be a problem.

opinion that these shouldn't be distributed for specific Hadoop
*distributions* to begin with. (Won't repeat the argument here yet.)
That resolves this n x m explosion too.

Vendors already provide their own distribution, yes, that's their job.



---------------------------------------------------------------------


"
Matei Zaharia <matei.zaharia@gmail.com>,"Sun, 8 Mar 2015 19:07:59 -0400",Re: Release Scala version vs Hadoop version (was: [VOTE] Release Apache Spark 1.3.0 (RC3)),Sean Owen <sowen@cloudera.com>,"Our goal is to let people use the latest Apache release even if vendors fall behind or don't want to package everything, so that's why we put out releases for vendors' versions. It's fairly low overhead.

Matei

Hadoop
what we
vendors
can
large
Scala
since
<matei.zaharia@gmail.com>
Hadoop
likely want
that
be that
there).
---------------------------------------------------------------------


---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Sun, 8 Mar 2015 16:45:41 -0700","Re: Release Scala version vs Hadoop version (was: [VOTE] Release
 Apache Spark 1.3.0 (RC3))",Matei Zaharia <matei.zaharia@gmail.com>,"I think it's important to separate the goals from the implementation.
I agree with Matei on the goal - I think the goal needs to be to allow
people to download Apache Spark and use it with CDH, HDP, MapR,
whatever... This is the whole reason why HDFS and YARN have stable
API's, so that other projects can build on them in a way that works
across multiple versions. I wouldn't want to force users to upgrade
according only to some vendor timetable, that doesn't seem from the
ASF perspective like a good thing for the project. If users want to
get packages from Bigtop, or the vendors, that's totally fine too.

My point earlier was - I am not sure we are actually accomplishing
that goal now, because I've heard in some cases our ""Hadoop 2.X""
packages actually don't work on certain distributions, even those that
are based on that Hadoop version. So one solution is to move towards
""bring your own Hadoop"" binaries and have users just set HADOOP_HOME
and maybe document any vendor-specific configs that need to be set.
That also happens to solve the ""too many binaries"" problem, but only
incidentally.

- Patrick


---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Mon, 9 Mar 2015 00:02:04 +0000","Re: Release Scala version vs Hadoop version (was: [VOTE] Release
 Apache Spark 1.3.0 (RC3))",Matei Zaharia <matei.zaharia@gmail.com>,"Yeah it's not much overhead, but here's an example of where it causes
a little issue.

I like that reasoning. However, the released builds don't track the
later versions of Hadoop that vendors would be distributing -- there's
no Hadoop 2.6 build for example. CDH4 is here, but not the
far-more-used CDH5. HDP isn't present at all. The CDH4 build doesn't
actually work with many CDH4 versions.

I agree with the goal of maximizing the reach of Spark, but I don't
know how much these builds advance that goal.

Anyone can roll-their-own exactly-right build, and the docs and build
have been set up to make that as simple as can be expected. So these
aren't *required* to let me use latest Spark on distribution X.

I had thought these existed to sorta support 'legacy' distributions,
like CDH4, and that build was justified as a
quasi-Hadoop-2.0.x-flavored build. But then I don't understand what
the MapR profiles are for.

I think it's too much work to correctly, in parallel, maintain any
customizations necessary for any major distro, and it might be best to
do not at all than to do it incompletely. You could say it's also an
enabler for distros to vary in ways that require special
customization.

Maybe there's a concern that, if lots of people consume Spark on
Hadoop, and most people consume Hadoop through distros, and distros
alone manage Spark distributions, then you de facto 'have to' go
through a distro instead of get bits from Spark? Different
conversation but I think this sort of effect does not end up being a
negative.

Well anyway, I like the idea of seeing how far Hadoop-provided
releases can help. It might kill several birds with one stone.


---------------------------------------------------------------------


"
Andrew Ash <andrew@andrewash.com>,"Sun, 8 Mar 2015 17:39:04 -0700",Re: Block Transfer Service encryption support,turp1twin <turp1twin@gmail.com>,"I'm interested in seeing this data transfer occurring over encrypted
communication channels as well.  Many customers require that all network
transfer occur encrypted to prevent the ""soft underbelly"" that's often
found inside a corporate network.


"
Jeff Turpin <turp1twin@gmail.com>,"Sun, 8 Mar 2015 17:42:13 -0700",Re: Block Transfer Service encryption support,Andrew Ash <andrew@andrewash.com>,"I have already written most of the code, just finishing up the unit tests
right now...

Jeff



"
Patrick Wendell <pwendell@gmail.com>,"Sun, 8 Mar 2015 17:51:05 -0700",Re: Block Transfer Service encryption support,Jeff Turpin <turp1twin@gmail.com>,"I think that yes, longer term we want to have encryption of all
communicated data. However Jeff, can you open a JIRA to discuss the
design before opening a pull request (it's fine to link to a WIP
branch if you'd like)? I'd like to better understand the performance
and operational complexity of using SSL for this in comparison with
alternatives. It would also be good to look at how the Hadoop
encryption works for their shuffle service, in terms of the design
decisions made there.

- Patrick


---------------------------------------------------------------------


"
Matei Zaharia <matei.zaharia@gmail.com>,"Sun, 8 Mar 2015 21:33:46 -0400",Re: Release Scala version vs Hadoop version (was: [VOTE] Release Apache Spark 1.3.0 (RC3)),Sean Owen <sowen@cloudera.com>,"Yeah, my concern is that people should get Apache Spark from *Apache*, not from a vendor. It helps everyone use the latest features no matter where they are. In the Hadoop distro case, Hadoop made all this effort to have standard APIs (e.g. YARN), so it should be easy. But it is a problem if we're not packaging for the newest versions of some distros; I think we just fell behind at Hadoop 2.4.

Matei

vendors fall behind or don't want to package everything, so that's why we put out releases for vendors' versions. It's fairly low overhead.
tarball
job.
Hadoop
what we
vendors
HDP can
but
large
Scala
since
is
the
Pros
<matei.zaharia@gmail.com>
Hadoop
likely want
that
might be that
there).
---------------------------------------------------------------------


---------------------------------------------------------------------


"
"""David J. Manglano"" <david.manglano@gmail.com>","Sun, 8 Mar 2015 22:53:58 -0500",GSoC 2015,dev@spark.apache.org,"Hi Spark devs!

I'm writing regarding your GSoC 2015 project idea. I'm a graduate student
with experience in Python and discrete mathematics. I'm interested in
machine learning, and understand some of its basic concepts.

I was wondering if someone might be able to elaborate upon the goals for
Spark with GSoC (it is my understanding that Manoj Kumar is the mentor),
though I may be incorrect. I have been reading the Spark codebase on GitHub
and think I may be able to help develop Spark's Python API.

To get involved, what next steps should I take?

Thanks!

David J. Manglano
Masters Program in Computer Science
University of Chicago
"
Jeff Turpin <turp1twin@gmail.com>,"Sun, 8 Mar 2015 21:00:35 -0700",Re: Block Transfer Service encryption support,Patrick Wendell <pwendell@gmail.com>,"Hey Patrick,

Yes, I will open a Jira tomorrow... For now my implementation is a basic
SSL implementation for the TransportServer and TransportClient.. I will
type up the design and at the same time look at the Hadoop impl for
possible improvements... Cheers!

Jeff



"
Sandy Ryza <sandy.ryza@cloudera.com>,"Sun, 8 Mar 2015 22:51:16 -0700",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Krishna Sankar <ksankar42@gmail.com>,"+1 (non-binding, doc and packaging issues aside)

Built from source, ran jobs and spark-shell against a pseudo-distributed
YARN cluster.


"
Akhil Das <akhil@sigmoidanalytics.com>,"Mon, 9 Mar 2015 12:34:42 +0530",Re: GSoC 2015,"""David J. Manglano"" <david.manglano@gmail.com>","This might help
https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark

Thanks
Best Regards


"
Hui WANG <hedonplay@gmail.com>,"Mon, 9 Mar 2015 10:24:05 +0100",missing explanation of cache in the documentation of cluster overview,dev@spark.apache.org,"Hello Guys,

I'm reading the documentation of cluster mode overview on
https://spark.apache.org/docs/latest/cluster-overview.html.

In the schema, cache is shown aside executor but no explanation is done on
it.

Can someone please help to explain it and improve this page ?

-- 
Hui WANG
Tel : +33 (0) 6 71 33 45 39
Blog : http://www.hui-wang.info
"
Sean Owen <sowen@cloudera.com>,"Mon, 9 Mar 2015 09:29:16 +0000",Re: missing explanation of cache in the documentation of cluster overview,Hui WANG <hedonplay@gmail.com>,"It's explained at
https://spark.apache.org/docs/latest/programming-guide.html and it's
configuration at
https://spark.apache.org/docs/latest/configuration.html  Have a read
over all the docs first.


---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Mon, 9 Mar 2015 09:50:20 +0000","Re: Release Scala version vs Hadoop version (was: [VOTE] Release
 Apache Spark 1.3.0 (RC3))",Matei Zaharia <matei.zaharia@gmail.com>,"Yes, you should always find working bits at Apache no matter what --
though 'no matter what' really means 'as long as you use Hadoop distro
compatible with upstream Hadoop'. Even distros have a strong interest
in that, since the market, the 'pie', is made large by this kind of
freedom at the core.

If tso, then no vendor-specific builds are needed, only some
Hadoop-release-specific ones. So a Hadoop 2.6-specific build could be
good (although I'm not yet clear if there's something about 2.5 or 2.6
that needs a different build.)

I take it that we already believe that, say, the ""Hadoop 2.4"" build
works with CDH5, so no CDH5-specific build is provided by Spark.

If a distro doesn't work with stock Spark, then it's either something
Spark should fix (e.g. use of a private YARN API or something), or
it's something the distro should really fix because it's incompatible.

Could we maybe rename the ""CDH4"" build then, as it doesn't really work
with all CDH4, to be a ""Hadoop 2.0.x build""? That's been floated
before. And can we remove the MapR builds -- or else can someone
explain why these exist separately from a Hadoop 2.3 build? I hope it
is not *because* they are somehow non-standard. And shall we first run
down why Spark doesn't fully work on HDP and see if it's something
that Spark or HDP needs to tweak, rather than contemplate another
binary? or, if so, can it simply be called a ""Hadoop 2.7 + YARN
whatever"" build and not made specific to a vendor, even if the project
has to field another tarball combo for a vendor?

Maybe we are saying almost the same thing.


te:
t from a vendor. It helps everyone use the latest features no matter where they are. In the Hadoop distro case, Hadoop made all this effort to have standard APIs (e.g. YARN), so it should be easy. But it is a problem if we're not packaging for the newest versions of some distros; I think we just fell behind at Hadoop 2.4.
 fall behind or don't want to package everything, so that's why we put out releases for vendors' versions. It's fairly low overhead.
rote:
oop
t we
ndors
can
ge
a
e
e:
com>
doop
kely want
t
 be that
ere).
-

---------------------------------------------------------------------


"
Mridul Muralidharan <mridul@gmail.com>,"Mon, 9 Mar 2015 05:34:50 -0700","Re: Release Scala version vs Hadoop version (was: [VOTE] Release
 Apache Spark 1.3.0 (RC3))",Sean Owen <sowen@cloudera.com>,"In ideal situation, +1 on removing all vendor specific builds and
making just hadoop version specific - that is what we should depend on
anyway.
Though I hope Sean is correct in assuming that vendor specific builds
for hadoop 2.4 are just that; and not 2.4- or 2.4+ which cause
incompatibilities for us or our users !

Regards,
Mridul


rote:
ot from a vendor. It helps everyone use the latest features no matter where they are. In the Hadoop distro case, Hadoop made all this effort to have standard APIs (e.g. YARN), so it should be easy. But it is a problem if we're not packaging for the newest versions of some distros; I think we just fell behind at Hadoop 2.4.
s fall behind or don't want to package everything, so that's why we put out releases for vendors' versions. It's fairly low overhead.
l
.
doop
at we
endors
 can
t
rge
la
ce
s
e
te:
s
.com>
adoop
ikely want
at
t be that
here).
--

---------------------------------------------------------------------


"
Egor Pahomov <pahomov.egor@gmail.com>,"Mon, 9 Mar 2015 15:21:42 +0300",How to implement unsupervised or reinforcement algorithm in new org.apache.spark.ml,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi, I'm redoing my PR <https://github.com/apache/spark/pull/2731> about
genetic algorithm in new org.apache.spark.ml architecture. Do we have
already some code about handling unsupervised or reinforcement algorithm in
new architecture? If no do we have some tickets on this matter? If no do we
have understanding when it would be doing, and how?

-- 



*Sincerely yoursEgor PakhomovScala Developer, Yandex*
"
Sean McNamara <Sean.McNamara@Webtrends.com>,"Mon, 9 Mar 2015 16:17:12 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Sandy Ryza <sandy.ryza@cloudera.com>,"+1

Ran local tests and tested our spark apps on a spark+yarn cluster.

Cheers,

Sean


e:
e
rs
p


---------------------------------------------------------------------


"
Tom Graves <tgraves_cs@yahoo.com.INVALID>,"Mon, 9 Mar 2015 16:13:22 +0000 (UTC)",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),"Patrick Wendell <pwendell@gmail.com>, 
	""dev@spark.apache.org"" <dev@spark.apache.org>","+1. Built from source and ran Spark on yarn on hadoop 2.6 in cluster and client mode.
Tom 

   

 Please vote on releasing the following candidate as Apache Spark version 1.3.0!

The tag to be voted on is v1.3.0-rc2 (commit 4aaf48d4):
https://git-wip-us.a"
Denny Lee <denny.g.lee@gmail.com>,"Mon, 09 Mar 2015 16:36:05 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),"Tom Graves <tgraves_cs@yahoo.com>, Patrick Wendell <pwendell@gmail.com>, 
	""dev@spark.apache.org"" <dev@spark.apache.org>","+1 (non-binding)

Spark Standalone and YARN on Hadoop 2.6 on OSX plus various tests (MLLib,
SparkSQL, etc.)


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Mon, 9 Mar 2015 17:37:25 +0000",RE: Loading previously serialized object to Spark,Akhil Das <akhil@sigmoidanalytics.com>,"Below is the code with standard MLlib class. Apparently this issue can happen in the same Spark instance.

import java.io._

import org.apache.spark.mllib.classification.NaiveBayes
import org.apache.spark.mllib.classification.NaiveBayesModel
import org.apache.spark.mllib.util.MLUtils

val data = MLUtils.loadLibSVMFile(sc, ""hdfs://myserver:9000/data/mnist.scale"")
val nb = NaiveBayes.train(data)
// RDD map works fine
val predictionAndLabels = data.map( lp => (nb.classifierModel.predict(lp.features), lp.label))

// serialize the model to file and immediately load it
val oos = new ObjectOutputStream(new FileOutputStream(""/home/myuser/nb.bin""))
oos.writeObject(nb)
oos.close
val ois = new ObjectInputStream(new FileInputStream(""/home/myuser/nb.bin""))
val nbSerialized = ois.readObject.asInstanceOf[NaiveBayesModel]
ois.close
// RDD map fails
val predictionAndLabels = data.map( lp => (nbSerialized.predict(lp.features), lp.label))
org.apache.spark.SparkException: Task not serializable
        at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
        at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
        at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
        at org.apache.spark.rdd.RDD.map(RDD.scala:273)


From: Akhil Das [mailto:akhil@sigmoidanalytics.com]
Sent: Sunday, March 08, 2015 3:17 AM
To: Ulanov, Alexander
Cc: dev
Subject: Re: Loading previously serialized object to Spark

Can you paste the complete code?

Thanks
Best Regards

On Sat, Mar 7, 2015 at 2:25 AM, Ulanov, Alexander <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
Hi,

I've implemented class MyClass in MLlib that does some operation on LabeledPoint. MyClass extends serializable, so I can map this operation on data of RDD[LabeledPoints], such as data.map(lp => MyClass.operate(lp)). I write this class in file with ObjectOutputStream.writeObject. Then I stop and restart Spark. I load this class from file with ObjectInputStream.readObject.asInstanceOf[MyClass]. When I try to map the same operation of this class to RDD, Spark throws not serializable exception:
org.apache.spark.SparkException: Task not serializable
        at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
        at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
        at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
        at org.apache.spark.rdd.RDD.map(RDD.scala:273)

Could you suggest why it throws this exception while MyClass is serializable by definition?

Best regards, Alexander

"
Joseph Bradley <joseph@databricks.com>,"Mon, 9 Mar 2015 10:54:39 -0700",Re: How to implement unsupervised or reinforcement algorithm in new org.apache.spark.ml,Egor Pahomov <pahomov.egor@gmail.com>,"Hi,

There are no examples currently.  For unsupervised learning, I think the
pattern is straightforward.  It would follow the pattern from supervised
learning, but without the label input column and with a model having a
different transform() behavior.

Reinforcement learning might take a bit more design since I haven't seen
work on it so far.  I'd recommend making a Discussion JIRA to post a set of
requirements and get feedback on a design.  Reinforcement learning would be
great to have in MLlib.

Joseph


"
Patrick Wendell <pwendell@gmail.com>,"Mon, 9 Mar 2015 11:27:18 -0700",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),"""dev@spark.apache.org"" <dev@spark.apache.org>","Hey All,

Today there was a JIRA posted with an observed regression around Spark
Streaming during certain recovery scenarios:

https://issues.apache.org/jira/browse/SPARK-6222

My preference is to go ahead and ship this release (RC3) as-is and if
this issue is isolated resolved soon, we can make a patch release in
the next week or two.

At some point, the cost of continuing to hold the release re/vote is
so high that it's better to just ship the release. We can document
known issues and point users to a fix once it's available. We did this
in 1.2.0 as well (there were two small known issues) and I think as a
point of process, this approach is necessary given the size of the
project.

I wanted to notify this thread though, in case this change anyones
opinion on their release vote. I will leave the thread open at least
until the end of today.

Still +1 on RC3, for me.

- Patrick


---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Mon, 9 Mar 2015 18:52:56 +0000",RE: Loading previously serialized object to Spark,Akhil Das <akhil@sigmoidanalytics.com>,"Just tried, the same happens if I use the internal Spark serializer: 
val serializer = SparkEnv.get.closureSerializer.newInstance


-----Original Message-----
From: Ulanov, Alexander 
Sent: Monday, March 09, 2015 10:37 AM
To: Akhil Das
Cc: dev
Subject: RE: Loading previously serialized object to Spark

Below is the code with standard MLlib class. Apparently this issue can happen in the same Spark instance.

import java.io._

import org.apache.spark.mllib.classification.NaiveBayes
import org.apache.spark.mllib.classification.NaiveBayesModel
import org.apache.spark.mllib.util.MLUtils

val data = MLUtils.loadLibSVMFile(sc, ""hdfs://myserver:9000/data/mnist.scale"")
val nb = NaiveBayes.train(data)
// RDD map works fine
val predictionAndLabels = data.map( lp => (nb.classifierModel.predict(lp.features), lp.label))

// serialize the model to file and immediately load it val oos = new ObjectOutputStream(new FileOutputStream(""/home/myuser/nb.bin""))
oos.writeObject(nb)
oos.close
val ois = new ObjectInputStream(new FileInputStream(""/home/myuser/nb.bin""))
val nbSerialized = ois.readObject.asInstanceOf[NaiveBayesModel]
ois.close
// RDD map fails
val predictionAndLabels = data.map( lp => (nbSerialized.predict(lp.features), lp.label))
org.apache.spark.SparkException: Task not serializable
        at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
        at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
        at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
        at org.apache.spark.rdd.RDD.map(RDD.scala:273)


From: Akhil Das [mailto:akhil@sigmoidanalytics.com]
Sent: Sunday, March 08, 2015 3:17 AM
To: Ulanov, Alexander
Cc: dev
Subject: Re: Loading previously serialized object to Spark

Can you paste the complete code?

Thanks
Best Regards

On Sat, Mar 7, 2015 at 2:25 AM, Ulanov, Alexander <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
Hi,

I've implemented class MyClass in MLlib that does some operation on LabeledPoint. MyClass extends serializable, so I can map this operation on data of RDD[LabeledPoints], such as data.map(lp => MyClass.operate(lp)). I write this class in file with ObjectOutputStream.writeObject. Then I stop and restart Spark. I load this class from file with ObjectInputStream.readObject.asInstanceOf[MyClass]. When I try to map the same operation of this class to RDD, Spark throws not serializable exception:
org.apache.spark.SparkException: Task not serializable
        at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
        at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
        at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
        at org.apache.spark.rdd.RDD.map(RDD.scala:273)

Could you suggest why it throws this exception while MyClass is serializable by definition?

Best regards, Alexander

"
Xiangrui Meng <mengxr@gmail.com>,"Mon, 9 Mar 2015 12:10:03 -0700",Re: Loading previously serialized object to Spark,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Could you try `sc.objectFile` instead?

sc.parallelize(Seq(model), 1).saveAsObjectFile(""path"")
val sameModel = sc.objectFile[NaiveBayesModel](""path"").first()

-Xiangrui

ppen in the same Spark instance.
scale"")
(lp.features), lp.label))
jectOutputStream(new FileOutputStream(""/home/myuser/nb.bin""))
n""))
atures), lp.label))
reCleaner.scala:166)
la:158)
edPoint. MyClass extends serializable, so I can map this operation on data of RDD[LabeledPoints], such as data.map(lp => MyClass.operate(lp)). I write this class in file with ObjectOutputStream.writeObject. Then I stop and restart Spark. I load this class from file with ObjectInputStream.readObject.asInstanceOf[MyClass]. When I try to map the same operation of this class to RDD, Spark throws not serializable exception:
reCleaner.scala:166)
la:158)
ble by definition?

---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Mon, 9 Mar 2015 19:25:34 +0000",RE: Loading previously serialized object to Spark,Xiangrui Meng <mengxr@gmail.com>,"Thanks so much! It works! Is it the standard way for Mllib models to be serialized?

Btw. The example I pasted below works if one implements a TestSuite with MLlibTestSparkContext.

-----Original Message-----
From: Xiangrui Meng [mailto:mengxr@gmail.com] 
Sent: Monday, March 09, 2015 12:10 PM
To: Ulanov, Alexander
Cc: Akhil Das; dev
Subject: Re: Loading previously serialized object to Spark

Could you try `sc.objectFile` instead?

sc.parallelize(Seq(model), 1).saveAsObjectFile(""path"") val sameModel = sc.objectFile[NaiveBayesModel](""path"").first()

-Xiangrui

On Mon, Mar 9, 2015 at 11:52 AM, Ulanov, Alexander <alexander.ulanov@hp.com> wrote:
> Just tried, the same happens if I use the internal Spark serializer:
> val serializer = SparkEnv.get.closureSerializer.newInstance
>
>
> -----Original Message-----
> From: Ulanov, Alexander
> Sent: Monday, March 09, 2015 10:37 AM
> To: Akhil Das
> Cc: dev
> Subject: RE: Loading previously serialized object to Spark
>
> Below is the code with standard MLlib class. Apparently this issue can happen in the same Spark instance.
>
> import java.io._
>
> import org.apache.spark.mllib.classification.NaiveBayes
> import org.apache.spark.mllib.classification.NaiveBayesModel
> import org.apache.spark.mllib.util.MLUtils
>
> val data = MLUtils.loadLibSVMFile(sc, 
> ""hdfs://myserver:9000/data/mnist.scale"")
> val nb = NaiveBayes.train(data)
> // RDD map works fine
> val predictionAndLabels = data.map( lp => 
> (nb.classifierModel.predict(lp.features), lp.label))
>
> // serialize the model to file and immediately load it val oos = new 
> ObjectOutputStream(new FileOutputStream(""/home/myuser/nb.bin""))
> oos.writeObject(nb)
> oos.close
> val ois = new ObjectInputStream(new 
> FileInputStream(""/home/myuser/nb.bin""))
> val nbSerialized = ois.readObject.asInstanceOf[NaiveBayesModel]
> ois.close
> // RDD map fails
> val predictionAndLabels = data.map( lp => 
> (nbSerialized.predict(lp.features), lp.label))
> org.apache.spark.SparkException: Task not serializable
>         at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
>         at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
>         at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
>         at org.apache.spark.rdd.RDD.map(RDD.scala:273)
>
>
> From: Akhil Das [mailto:akhil@sigmoidanalytics.com]
> Sent: Sunday, March 08, 2015 3:17 AM
> To: Ulanov, Alexander
> Cc: dev
> Subject: Re: Loading previously serialized object to Spark
>
> Can you paste the complete code?
>
> Thanks
> Best Regards
>
> On Sat, Mar 7, 2015 at 2:25 AM, Ulanov, Alexander <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
> Hi,
>
> I've implemented class MyClass in MLlib that does some operation on LabeledPoint. MyClass extends serializable, so I can map this operation on data of RDD[LabeledPoints], such as data.map(lp => MyClass.operate(lp)). I write this class in file with ObjectOutputStream.writeObject. Then I stop and restart Spark. I load this class from file with ObjectInputStream.readObject.asInstanceOf[MyClass]. When I try to map the same operation of this class to RDD, Spark throws not serializable exception:
> org.apache.spark.SparkException: Task not serializable
>         at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
>         at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
>         at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
>         at org.apache.spark.rdd.RDD.map(RDD.scala:273)
>
> Could you suggest why it throws this exception while MyClass is serializable by definition?
>
> Best regards, Alexander
>
"
Xiangrui Meng <mengxr@gmail.com>,"Mon, 9 Mar 2015 12:31:43 -0700",Re: Loading previously serialized object to Spark,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Well, it is the standard ""hacky"" way for model save/load in MLlib. We
have SPARK-4587 and SPARK-5991 to provide save/load for all MLlib
models, in an exchangeable format. -Xiangrui

erialized?
MLlibTestSparkContext.
sc.objectFile[NaiveBayesModel](""path"").first()
appen in the same Spark instance.
ureCleaner.scala:166)
ala:158)
ledPoint. MyClass extends serializable, so I can map this operation on data of RDD[LabeledPoints], such as data.map(lp => MyClass.operate(lp)). I write this class in file with ObjectOutputStream.writeObject. Then I stop and restart Spark. I load this class from file with ObjectInputStream.readObject.asInstanceOf[MyClass]. When I try to map the same operation of this class to RDD, Spark throws not serializable exception:
ureCleaner.scala:166)
ala:158)
able by definition?

---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Mon, 9 Mar 2015 19:37:05 +0000",RE: Loading previously serialized object to Spark,Xiangrui Meng <mengxr@gmail.com>,"Looking forward to use those features! 

Can I somehow make the model that I saved with ObjectOutputStream work with RDD map? It took 7 hours to build it :)

-----Original Message-----
From: Xiangrui Meng [mailto:mengxr@gmail.com] 
Sent: Monday, March 09, 2015 12:32 PM
To: Ulanov, Alexander
Cc: Akhil Das; dev
Subject: Re: Loading previously serialized object to Spark

Well, it is the standard ""hacky"" way for model save/load in MLlib. We have SPARK-4587 and SPARK-5991 to provide save/load for all MLlib models, in an exchangeable format. -Xiangrui

On Mon, Mar 9, 2015 at 12:25 PM, Ulanov, Alexander <alexander.ulanov@hp.com> wrote:
> Thanks so much! It works! Is it the standard way for Mllib models to be serialized?
>
> Btw. The example I pasted below works if one implements a TestSuite with MLlibTestSparkContext.
>
> -----Original Message-----
> From: Xiangrui Meng [mailto:mengxr@gmail.com]
> Sent: Monday, March 09, 2015 12:10 PM
> To: Ulanov, Alexander
> Cc: Akhil Das; dev
> Subject: Re: Loading previously serialized object to Spark
>
> Could you try `sc.objectFile` instead?
>
> sc.parallelize(Seq(model), 1).saveAsObjectFile(""path"") val sameModel = 
> sc.objectFile[NaiveBayesModel](""path"").first()
>
> -Xiangrui
>
> On Mon, Mar 9, 2015 at 11:52 AM, Ulanov, Alexander <alexander.ulanov@hp.com> wrote:
>> Just tried, the same happens if I use the internal Spark serializer:
>> val serializer = SparkEnv.get.closureSerializer.newInstance
>>
>>
>> -----Original Message-----
>> From: Ulanov, Alexander
>> Sent: Monday, March 09, 2015 10:37 AM
>> To: Akhil Das
>> Cc: dev
>> Subject: RE: Loading previously serialized object to Spark
>>
>> Below is the code with standard MLlib class. Apparently this issue can happen in the same Spark instance.
>>
>> import java.io._
>>
>> import org.apache.spark.mllib.classification.NaiveBayes
>> import org.apache.spark.mllib.classification.NaiveBayesModel
>> import org.apache.spark.mllib.util.MLUtils
>>
>> val data = MLUtils.loadLibSVMFile(sc,
>> ""hdfs://myserver:9000/data/mnist.scale"")
>> val nb = NaiveBayes.train(data)
>> // RDD map works fine
>> val predictionAndLabels = data.map( lp => 
>> (nb.classifierModel.predict(lp.features), lp.label))
>>
>> // serialize the model to file and immediately load it val oos = new 
>> ObjectOutputStream(new FileOutputStream(""/home/myuser/nb.bin""))
>> oos.writeObject(nb)
>> oos.close
>> val ois = new ObjectInputStream(new
>> FileInputStream(""/home/myuser/nb.bin""))
>> val nbSerialized = ois.readObject.asInstanceOf[NaiveBayesModel]
>> ois.close
>> // RDD map fails
>> val predictionAndLabels = data.map( lp => 
>> (nbSerialized.predict(lp.features), lp.label))
>> org.apache.spark.SparkException: Task not serializable
>>         at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
>>         at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
>>         at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
>>         at org.apache.spark.rdd.RDD.map(RDD.scala:273)
>>
>>
>> From: Akhil Das [mailto:akhil@sigmoidanalytics.com]
>> Sent: Sunday, March 08, 2015 3:17 AM
>> To: Ulanov, Alexander
>> Cc: dev
>> Subject: Re: Loading previously serialized object to Spark
>>
>> Can you paste the complete code?
>>
>> Thanks
>> Best Regards
>>
>> On Sat, Mar 7, 2015 at 2:25 AM, Ulanov, Alexander <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> Hi,
>>
>> I've implemented class MyClass in MLlib that does some operation on LabeledPoint. MyClass extends serializable, so I can map this operation on data of RDD[LabeledPoints], such as data.map(lp => MyClass.operate(lp)). I write this class in file with ObjectOutputStream.writeObject. Then I stop and restart Spark. I load this class from file with ObjectInputStream.readObject.asInstanceOf[MyClass]. When I try to map the same operation of this class to RDD, Spark throws not serializable exception:
>> org.apache.spark.SparkException: Task not serializable
>>         at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)
>>         at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)
>>         at org.apache.spark.SparkContext.clean(SparkContext.scala:1453)
>>         at org.apache.spark.rdd.RDD.map(RDD.scala:273)
>>
>> Could you suggest why it throws this exception while MyClass is serializable by definition?
>>
>> Best regards, Alexander
>>
"
Patrick Wendell <pwendell@gmail.com>,"Mon, 9 Mar 2015 12:53:00 -0700",Cross cutting internal changes to launch scripts,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hey All,

Marcelo Vanzin has been working on a patch for a few months that
performs cross cutting clean-up and fixes to the way that Spark's
launch scripts work (including PySpark, spark submit, the daemon
scripts, etc.). The changes won't modify any public API's in terms of
how those scripts are invoked.

Historically, such patches have been difficult to test due to the
number of interactions between components and interactions with
external environments. I'd like to welcome people to test and/or code
review this patch in their own environment. This patch is the in the
very late stages of review and will likely be merged soon into master
(eventually 1.4).

https://github.com/apache/spark/pull/3916/files

I'll ping this thread again once it is merged and we can establish a
JIRA to encapsulate any issues. Just wanted to give a heads up as this
is one of the larger internal changes we've made to this
infrastructure since Spark 1.0

- Patrick

---------------------------------------------------------------------


"
Kostas Sakellis <kostas@cloudera.com>,"Mon, 9 Mar 2015 13:31:34 -0700",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"+1 on RC3

putting it in a double dot release sounds like a good plan.

Kostas




"
Sean Owen <sowen@cloudera.com>,"Mon, 9 Mar 2015 20:38:09 +0000",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Patrick Wendell <pwendell@gmail.com>,"I'm +1 as I have not heard of any one else seeing the Hive test
failure, which is likely a test issue rather than code issue anyway,
and not a blocker.


---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Mon, 9 Mar 2015 21:07:41 +0000",RE: Using CUDA within Spark / boosting linear algebra,"Sam Halliday <sam.halliday@gmail.com>, Xiangrui Meng <mengxr@gmail.com>,
	Joseph Bradley <joseph@databricks.com>","Hi Everyone, I've updated the benchmark as Xiangrui suggested. Added the comment that BIDMat 0.9.7 uses Float matrices in GPU (although I see the support of Double in the current source code), did the test with BIDMat and CPU Double matrices. BIDMat MKL is indeed on par with netlib MKL.

https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing

Best regards, Alexander

-----Original Message-----
From: Sam Halliday [mailto:sam.halliday@gmail.com] 
Sent: Tuesday, March 03, 2015 1:54 PM
To: Xiangrui Meng; Joseph Bradley
Cc: Evan R. Sparks; Ulanov, Alexander; dev@spark.apache.org
Subject: Re: Using CUDA within Spark / boosting linear algebra

BTW, is anybody on this list going to the London Meetup in a few weeks?

https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-mapreduce-world#community

Would be nice to meet other people working on the guts of Spark! :-)


Xiangrui Meng <mengxr@gmail.com> writes:

> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x 
> slower than netlib-openblas. What is the overhead of using a GPU BLAS 
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com> wrote:
>> Better documentation for linking would be very helpful!  Here's a JIRA:
>> https://issues.apache.org/jira/browse/SPARK-6019
>>
>>
>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks 
>> <evan.sparks@gmail.com>
>> wrote:
>>
>>> Thanks for compiling all the data and running these benchmarks, 
>>> Alex. The big takeaways here can be seen with this chart:
>>>
>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZ
>>> Hl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
>>>
>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>> BIDMat+GPU) can provide substantial (but less than an order of 
>>> BIDMat+magnitude)
>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>>> netlib-java+openblas-compiled).
>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude 
>>> worse than a well-tuned CPU implementation, particularly for larger matrices.
>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this 
>>> basically agrees with the authors own benchmarks (
>>> https://github.com/fommil/netlib-java)
>>>
>>> I think that most of our users are in a situation where using GPUs 
>>> may not be practical - although we could consider having a good GPU 
>>> backend available as an option. However, *ALL* users of MLlib could 
>>> benefit (potentially tremendously) from using a well-tuned CPU-based 
>>> BLAS implementation. Perhaps we should consider updating the mllib 
>>> guide with a more complete section for enabling high performance 
>>> binaries on OSX and Linux? Or better, figure out a way for the 
>>> system to fetch these automatically.
>>>
>>> - Evan
>>>
>>>
>>>
>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander < 
>>> alexander.ulanov@hp.com> wrote:
>>>
>>>> Just to summarize this thread, I was finally able to make all 
>>>> performance comparisons that we discussed. It turns out that:
>>>> BIDMat-cublas>>BIDMat
>>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-repo=
>>>> =netlib-cublas>netlib-blas>f2jblas
>>>>
>>>> Below is the link to the spreadsheet with full results.
>>>>
>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx
>>>> 378T9J5r7kwKSPkY/edit?usp=sharing
>>>>
>>>> One thing still needs exploration: does BIDMat-cublas perform 
>>>> copying to/from machine’s RAM?
>>>>
>>>> -----Original Message-----
>>>> From: Ulanov, Alexander
>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>>> To: Evan R. Sparks
>>>> Cc: Joseph Bradley; dev@spark.apache.org
>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Thanks, Evan! It seems that ticket was marked as duplicate though 
>>>> the original one discusses slightly different topic. I was able to 
>>>> link netlib with MKL from BIDMat binaries. Indeed, MKL is 
>>>> statically linked inside a 60MB library.
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>>> |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>>> 1569,233228 |
>>>>
>>>> It turn out that pre-compiled MKL is faster than precompiled 
>>>> OpenBlas on my machine. Probably, I’ll add two more columns with 
>>>> locally compiled openblas and cuda.
>>>>
>>>> Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
>>>> Sent: Monday, February 09, 2015 6:06 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; dev@spark.apache.org
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Great - perhaps we can move this discussion off-list and onto a 
>>>> JIRA ticket? (Here's one: 
>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>>>>
>>>> It seems like this is going to be somewhat exploratory for a while 
>>>> (and there's probably only a handful of us who really care about 
>>>> fast linear
>>>> algebra!)
>>>>
>>>> - Evan
>>>>
>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for explanation and useful link. I am going to build 
>>>> OpenBLAS, link it with Netlib-java and perform benchmark again.
>>>>
>>>> Do I understand correctly that BIDMat binaries contain statically 
>>>> linked Intel MKL BLAS? It might be the reason why I am able to run 
>>>> BIDMat not having MKL BLAS installed on my server. If it is true, I 
>>>> wonder if it is OK because Intel sells this library. Nevertheless, 
>>>> it seems that in my case precompiled MKL BLAS performs better than 
>>>> precompiled OpenBLAS given that BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>>
>>>> Though, it might be interesting to link Netlib-java with Intel MKL, 
>>>> as you suggested. I wonder, are John Canny (BIDMat) and Sam 
>>>> Halliday
>>>> (Netlib-java) interested to compare their libraries.
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>>>> evan.sparks@gmail.com>]
>>>> Sent: Friday, February 06, 2015 5:58 PM
>>>>
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; 
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I would build OpenBLAS yourself, since good BLAS performance comes 
>>>> from getting cache sizes, etc. set up correctly for your particular 
>>>> hardware - this is often a very tricky process (see, e.g. ATLAS), 
>>>> but we found that on relatively modern Xeon chips, OpenBLAS builds 
>>>> quickly and yields performance competitive with MKL.
>>>>
>>>> To make sure the right library is getting used, you have to make 
>>>> sure it's first on the search path - export 
>>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>>>>
>>>> For some examples of getting netlib-java setup on an ec2 node and 
>>>> some example benchmarking code we ran a while back, see:
>>>> https://github.com/shivaram/matrix-bench
>>>>
>>>> In particular - build-openblas-ec2.sh shows you how to build the 
>>>> library and set up symlinks correctly, and scala/run-netlib.sh 
>>>> shows you how to get the path setup and get that library picked up by netlib-java.
>>>>
>>>> In this way - you could probably get cuBLAS set up to be used by 
>>>> netlib-java as well.
>>>>
>>>> - Evan
>>>>
>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to 
>>>> force loading the right blas? For netlib, I there are few JVM 
>>>> flags, such as 
>>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS, 
>>>> so I can force it to use Java implementation. Not sure I understand how to force use a specific blas (not specific wrapper for blas).
>>>>
>>>> Btw. I have installed openblas (yum install openblas), so I suppose 
>>>> that netlib is using it.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>>>> evan.sparks@gmail.com>]
>>>> Sent: Friday, February 06, 2015 5:19 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; 
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Getting breeze to pick up the right blas library is critical for 
>>>> performance. I recommend using OpenBLAS (or MKL, if you already have it).
>>>> It might make sense to force BIDMat to use the same underlying BLAS 
>>>> library as well.
>>>>
>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>> Hi Evan, Joseph
>>>>
>>>> I did few matrix multiplication test and BIDMat seems to be ~10x 
>>>> faster than netlib-java+breeze (sorry for weird table formatting):
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java 
>>>> |native_system_linux_x86-64|
>>>> Breeze+Netlib-java f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228 
>>>> ||
>>>>
>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora 
>>>> 19 Linux, Scala 2.11.
>>>>
>>>> Later I will make tests with Cuda. I need to install new Cuda 
>>>> version for this purpose.
>>>>
>>>> Do you have any ideas why breeze-netlib with native blas is so much 
>>>> slower than BIDMat MKL?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
>>>> joseph@databricks.com>]
>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Evan R. Sparks; 
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Hi Alexander,
>>>>
>>>> Using GPUs with Spark would be very exciting.  Small comment: 
>>>> Concerning your question earlier about keeping data stored on the 
>>>> GPU rather than having to move it between main memory and GPU 
>>>> memory on each iteration, I would guess this would be critical to 
>>>> getting good performance.  If you could do multiple local 
>>>> iterations before aggregating results, then the cost of data 
>>>> movement to the GPU could be amortized (and I believe that is done 
>>>> in practice).  Having Spark be aware of the GPU and using it as another part of memory sounds like a much bigger undertaking.
>>>>
>>>> Joseph
>>>>
>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>> Thank you for explanation! I’ve watched the BIDMach presentation by 
>>>> John Canny and I am really inspired by his talk and comparisons with Spark MLlib.
>>>>
>>>> I am very interested to find out what will be better within Spark: 
>>>> BIDMat or netlib-java with CPU or GPU natives. Could you suggest a 
>>>> fair way to benchmark them? Currently I do benchmarks on artificial 
>>>> neural networks in batch mode. While it is not a “pure” test of 
>>>> linear algebra, it involves some other things that are essential to machine learning.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>>>> evan.sparks@gmail.com>]
>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to 
>>>> netlib-java+data
>>>> layout and fewer levels of indirection - it's definitely a 
>>>> worthwhile experiment to run. The main speedups I've seen from 
>>>> using it come from highly optimized GPU code for linear algebra. I 
>>>> know that in the past Canny has gone as far as to write custom GPU 
>>>> kernels for performance-critical regions of code.[1]
>>>>
>>>> BIDMach is highly optimized for single node performance or 
>>>> performance on small clusters.[2] Once data doesn't fit easily in 
>>>> GPU memory (or can be batched in that way) the performance tends to 
>>>> fall off. Canny argues for hardware/software codesign and as such 
>>>> prefers machine configurations that are quite different than what 
>>>> we find in most commodity cluster nodes - e.g. 10 disk cahnnels and 4 GPUs.
>>>>
>>>> In contrast, MLlib was designed for horizontal scalability on 
>>>> commodity clusters and works best on very big datasets - order of terabytes.
>>>>
>>>> For the most part, these projects developed concurrently to address 
>>>> slightly different use cases. That said, there may be bits of 
>>>> BIDMach we could repurpose for MLlib - keep in mind we need to be 
>>>> careful about maintaining cross-language compatibility for our Java 
>>>> and Python-users, though.
>>>>
>>>> - Evan
>>>>
>>>> [1] - http://arxiv.org/abs/1409.5402 [2] - 
>>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>>
>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do 
>>>> you know what makes them faster than netlib-java?
>>>>
>>>> The same group has BIDMach library that implements machine 
>>>> learning. For some examples they use Caffe convolutional neural 
>>>> network library owned by another group in Berkeley. Could you 
>>>> elaborate on how these all might be connected with Spark Mllib? If 
>>>> you take BIDMat for linear algebra why don’t you take BIDMach for optimization and learning?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>>>> evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:
>>>> evan.sparks@gmail.com>>]
>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU 
>>>> blas in many cases.
>>>>
>>>> You might consider taking a look at the codepaths that BIDMat (
>>>> https://github.com/BIDData/BIDMat) takes and comparing them to 
>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work 
>>>> optimizing to make this work really fast from Scala. I've run it on 
>>>> my laptop and compared to MKL and in certain cases it's 10x faster at matrix multiply.
>>>> There are a lot of layers of indirection here and you really want 
>>>> to avoid data copying as much as possible.
>>>>
>>>> We could also consider swapping out BIDMat for Breeze, but that 
>>>> would be a big project and if we can figure out how to get 
>>>> breeze+cublas to comparable performance that would be a big win.
>>>>
>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Dear Spark developers,
>>>>
>>>> I am exploring how to make linear algebra operations faster within Spark.
>>>> One way of doing this is to use Scala Breeze library that is 
>>>> bundled with Spark. For matrix operations, it employs Netlib-java 
>>>> that has a Java wrapper for BLAS (basic linear algebra subprograms) 
>>>> and LAPACK native binaries if they are available on the worker 
>>>> node. It also has its own optimized Java implementation of BLAS. It 
>>>> is worth mentioning, that native binaries provide better performance only for BLAS level 3, i.e.
>>>> matrix-matrix operations or general matrix multiplication (GEMM). 
>>>> This is confirmed by GEMM test on Netlib-java page 
>>>> https://github.com/fommil/netlib-java. I also confirmed it with my 
>>>> experiments with training of artificial neural network 
>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>>> However, I would like to boost performance more.
>>>>
>>>> GPU is supposed to work fast with linear algebra and there is 
>>>> Nvidia CUDA implementation of BLAS, called cublas. I have one Linux 
>>>> server with Nvidia GPU and I was able to do the following. I linked 
>>>> cublas (instead of cpu-based blas) with Netlib-java wrapper and put 
>>>> it into Spark, so Breeze/Netlib is using it. Then I did some 
>>>> performance measurements with regards to artificial neural network 
>>>> batch learning in Spark MLlib that involves matrix-matrix 
>>>> multiplications. It turns out that for matrices of size less than 
>>>> ~1000x780 GPU cublas has the same speed as CPU blas. Cublas becomes 
>>>> slower for bigger matrices. It worth mentioning that it is was not a test for ONLY multiplication since there are other operations involved.
>>>> One of the reasons for slowdown might be the overhead of copying 
>>>> the matrices from computer memory to graphic card memory and back.
>>>>
>>>> So, few questions:
>>>> 1) Do these results with CUDA make sense?
>>>> 2) If the problem is with copy overhead, are there any libraries 
>>>> that allow to force intermediate results to stay in graphic card 
>>>> memory thus removing the overhead?
>>>> 3) Any other options to speed-up linear algebra in Spark?
>>>>
>>>> Thank you, Alexander
>>>>
>>>> -------------------------------------------------------------------
>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
>>>> dev-unsubscribe@spark.apache.org><mailto:dev-unsubscribe@spark.apac
>>>> he.org <mailto:dev-unsubscribe@spark.apache.org>>
>>>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:
>>>> dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:
>>>> dev-help@spark.apache.org>>
>>>>
>>>>
>>>>
>>>>
>>>

--
Best regards,
Sam

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
"
Andrew Ash <andrew@andrewash.com>,"Mon, 9 Mar 2015 14:44:12 -0700","Re: Release Scala version vs Hadoop version (was: [VOTE] Release
 Apache Spark 1.3.0 (RC3))",Mridul Muralidharan <mridul@gmail.com>,"Does the Apache project team have any ability to measure download counts of
the various releases?  That data could be useful when it comes time to
sunset vendor-specific releases, like CDH4 for example.


"
Xiangrui Meng <mengxr@gmail.com>,"Mon, 9 Mar 2015 15:30:41 -0700",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Sean Owen <sowen@cloudera.com>,"Krishna, I tested your linear regression example. For linear
regression, we changed its objective function from 1/n * \|A x -
b\|_2^2 to 1/(2n) * \|Ax - b\|_2^2 to be consistent with common least
squares formulations. It means you could re-produce the same result by
multiplying the step size by 2. This is not a problem if both run
until convergence (if not blow up). However, in your example, a very
small step size is chosen and it didn't converge in 100 iterations. In
this case, the step size matters. I will put a note in the migration
guide. Thanks! -Xiangrui


---------------------------------------------------------------------


"
Joseph Bradley <joseph@databricks.com>,"Mon, 9 Mar 2015 17:49:07 -0700",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),"""dev@spark.apache.org"" <dev@spark.apache.org>","+1
Tested on Mac OS X


"
Sam Halliday <sam.halliday@gmail.com>,"Tue, 10 Mar 2015 01:00:42 +0000",RE: Using CUDA within Spark / boosting linear algebra,Alexander Ulanov <alexander.ulanov@hp.com>,"Thanks so much for following up on this!

Hmm, I wonder if we should have a concerted effort to chart performance on
various pieces of hardware...

nd
5r7kwKSPkY/edit?usp=sharing
uce-world#community
:
m-repo=
with
y
tion by
 test of
4
h for
t
"
Imran Rashid <irashid@cloudera.com>,"Mon, 9 Mar 2015 20:15:43 -0500",Re: enum-like types in Spark,Mridul Muralidharan <mridul@gmail.com>,"Can you expand on the serde issues w/ java enum's at all?  I haven't heard
of any problems specific to enums.  The java object serialization rules
seem very clear and it doesn't seem like different jvms should have a
choice on what they do:

http://docs.oracle.com/javase/6/docs/platform/serialization/spec/serial-arch.html#6469

(in a nutshell, serialization must use enum.name())

of course there are plenty of ways the user could screw this up(eg. rename
the enums, or change their meaning, or remove them).  But then again, all
of java serialization has issues w/ serialization the user has to be aware
of.  Eg., if we go with case objects, than java serialization blows up if
you add another helper method, even if that helper method is completely
compatible.

Some prior debate in the scala community:

https://groups.google.com/d/msg/scala-internals/8RWkccSRBxQ/AN5F_ZbdKIsJ

SO post on which version to use in scala:

http://stackoverflow.com/questions/1321745/how-to-model-type-safe-enum-types

SO post about the macro-craziness people try to add to scala to make them
almost as good as a simple java enum:
(NB: the accepted answer doesn't actually work in all cases ...)

http://stackoverflow.com/questions/20089920/custom-scala-enum-most-elegant-version-searched

Another proposal to add better enums built into scala ... but seems to be
dormant:

https://groups.google.com/forum/#!topic/scala-sips/Bf82LxK02Kk




"
Aaron Davidson <ilikerps@gmail.com>,"Mon, 9 Mar 2015 18:25:45 -0700",Re: enum-like types in Spark,Imran Rashid <irashid@cloudera.com>,"Perhaps the problem with Java enums that was brought up was actually that
their hashCode is not stable across JVMs, as it depends on the memory
location of the enum itself.


"
Patrick Wendell <pwendell@gmail.com>,"Mon, 9 Mar 2015 18:39:32 -0700",Re: enum-like types in Spark,Aaron Davidson <ilikerps@gmail.com>,"Does this matter for our own internal types in Spark? I don't think
any of these types are designed to be used in RDD records, for
instance.


---------------------------------------------------------------------


"
Krishna Sankar <ksankar42@gmail.com>,"Mon, 9 Mar 2015 20:01:02 -0700",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Xiangrui Meng <mengxr@gmail.com>,"Excellent, Thanks Xiangrui. The mystery is solved.
Cheers
<k/>



"
Corey Nolet <cjnolet@gmail.com>,"Mon, 9 Mar 2015 23:17:56 -0400",Re: [VOTE] Release Apache Spark 1.3.0 (RC3),Krishna Sankar <ksankar42@gmail.com>,"+1 (non-binding)

- Verified signatures
- Built on Mac OS X and Fedora 21.


"
Pei-Lun Lee <pllee@appier.com>,"Tue, 10 Mar 2015 17:06:16 +0800",SparkSQL 1.3.0 (RC3) failed to read parquet file generated by 1.1.1,dev@spark.apache.org,"Hi,

I found that if I try to read parquet file generated by spark 1.1.1 using
1.3.0-rc3 by default settings, I got this error:

com.fasterxml.jackson.core.JsonParseException: Unrecognized token
'StructType': was expecting ('true', 'false' or 'null')
 at [Source: StructType(List(StructField(a,IntegerType,false))); line: 1,
column: 11]
        at
com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1419)
        at
com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:508)
        at
com.fasterxml.jackson.core.json.ReaderBasedJsonParser._reportInvalidToken(ReaderBasedJsonParser.java:2300)
        at
com.fasterxml.jackson.core.json.ReaderBasedJsonParser._handleOddValue(ReaderBasedJsonParser.java:1459)
        at
com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:683)
        at
com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3105)
        at
com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3051)
        at
com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2161)
        at org.json4s.jackson.JsonMethods$class.parse(JsonMethods.scala:19)
        at org.json4s.jackson.JsonMethods$.parse(JsonMethods.scala:44)
        at org.apache.spark.sql.types.DataType$.fromJson(dataTypes.scala:41)
        at
org.apache.spark.sql.parquet.ParquetRelation2$$anonfun$readSchema$1$$anonfun$25.apply(newParquet.scala:675)
        at
org.apache.spark.sql.parquet.ParquetRelation2$$anonfun$readSchema$1$$anonfun$25.apply(newParquet.scala:675)



this is how I save parquet file with 1.1.1:

sql(""select 1 as a"").saveAsParquetFile(""/tmp/foo"")



and this is the meta data of the 1.1.1 parquet file:

creator:     parquet-mr version 1.4.3
extra:       org.apache.spark.sql.parquet.row.metadata =
StructType(List(StructField(a,IntegerType,false)))



by comparison, this is 1.3.0 meta:

creator:     parquet-mr version 1.6.0rc3
extra:       org.apache.spark.sql.parquet.row.metadata =
{""type"":""struct"",""fields"":[{""name"":""a"",""type"":""integer"",""nullable"":t
[more]...



It looks like now ParquetRelation2 is used to load parquet file by default
and it only recognizes JSON format schema but 1.1.1 schema was case class
string format.

Setting spark.sql.parquet.useDataSourceApi to false will fix it, but I
don't know the differences.
Is this considered a bug? We have a lot of parquet files from 1.1.1, should
we disable data source api in order to read them if we want to upgrade to
1.3?

Thanks,
--
Pei-Lun
"
"""Haopu Wang"" <HWang@qilinsoft.com>","Tue, 10 Mar 2015 18:37:34 +0800",[SparkSQL] Reuse HiveContext to different Hive warehouse?,"""user"" <user@spark.apache.org>,
	<dev@spark.apache.org>","I'm using Spark 1.3.0 RC3 build with Hive support.

 

In Spark Shell, I want to reuse the HiveContext instance to different
warehouse locations. Below are the steps for my test (Assume I have
loaded a file into table ""src"").

 

======

15/03/10 18:22:59 INFO SparkILoop: Created sql context (with Hive
support)..

SQL context available as sqlContext.

scala> sqlContext.sql(""SET hive.metastore.warehouse.dir=/test/w"")

scala> sqlContext.sql(""SELECT * from src"").saveAsTable(""table1"")

scala> sqlContext.sql(""SET hive.metastore.warehouse.dir=/test/w2"")

scala> sqlContext.sql(""SELECT * from src"").saveAsTable(""table2"")

======

After these steps, the tables are stored in ""/test/w"" only. I expect
""table2"" to be stored in ""/test/w2"" folder.

 

Another question is: if I set ""hive.metastore.warehouse.dir"" to a HDFS
folder, I cannot use saveAsTable()? Is this by design? Exception stack
trace is below:

======

15/03/10 18:35:28 INFO BlockManagerMaster: Updated info of block
broadcast_0_piece0

15/03/10 18:35:28 INFO SparkContext: Created broadcast 0 from broadcast
at TableReader.scala:74

java.lang.IllegalArgumentException: Wrong FS:
hdfs://server:8020/space/warehouse/table2, expected: file:///

        at
org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:643)

        at
org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:463)

        at
org.apache.hadoop.fs.FilterFileSystem.makeQualified(FilterFileSystem.jav
a:118)

        at
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.a
pply(newParquet.scala:252)

        at
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.a
pply(newParquet.scala:251)

        at
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.sc
ala:244)

        at
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.sc
ala:244)

        at scala.collection.immutable.List.foreach(List.scala:318)

        at
scala.collection.TraversableLike$class.map(TraversableLike.scala:244)

        at
scala.collection.AbstractTraversable.map(Traversable.scala:105)

        at
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache.refresh(newP
arquet.scala:251)

        at
org.apache.spark.sql.parquet.ParquetRelation2.<init>(newParquet.scala:37
0)

        at
org.apache.spark.sql.parquet.DefaultSource.createRelation(newParquet.sca
la:96)

        at
org.apache.spark.sql.parquet.DefaultSource.createRelation(newParquet.sca
la:125)

        at
org.apache.spark.sql.sources.ResolvedDataSource$.apply(ddl.scala:308)

        at
org.apache.spark.sql.hive.execution.CreateMetastoreDataSourceAsSelect.ru
n(commands.scala:217)

        at
org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompu
te(commands.scala:55)

        at
org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands
.scala:55)

        at
org.apache.spark.sql.execution.ExecutedCommand.execute(commands.scala:65
)

        at
org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLConte
xt.scala:1088)

        at
org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:10
88)

        at
org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:1048)

        at
org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:998)

        at
org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:964)

        at
org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:942)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:20)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:25)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)

        at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)

        at $iwC$$iwC$$iwC$$iwC.<init>(<console>:31)

        at $iwC$$iwC$$iwC.<init>(<console>:33)

        at $iwC$$iwC.<init>(<console>:35)

        at $iwC.<init>(<console>:37)

        at <init>(<console>:39)

 

Thank you very much!

 

"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Tue, 10 Mar 2015 16:25:07 +0000",RE: Using CUDA within Spark / boosting linear algebra,Sam Halliday <sam.halliday@gmail.com>,"I can run benchmark on another machine with GPU nVidia Titan and Intel Xeon E5-2650 v2, although it runs Windows and I have to run Linux tests in VirtualBox.

It would be also interesting to add results on netlib+nvblas, however I am not sure I understand in details how to build this and will appreciate any help from you ☺

From: Sam Halliday [mailto:sam.halliday@gmail.com]
Sent: Monday, March 09, 2015 6:01 PM
To: Ulanov, Alexander
Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
Subject: RE: Using CUDA within Spark / boosting linear algebra


Thanks so much for following up on this!

Hmm, I wonder if we should have a concerted effort to chart performance on various pieces of hardware...
On 9 Mar 2015 21:08, ""Ulanov, Alexander"" <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
Hi Everyone, I've updated the benchmark as Xiangrui suggested. Added the comment that BIDMat 0.9.7 uses Float matrices in GPU (although I see the support of Double in the current source code), did the test with BIDMat and CPU Double matrices. BIDMat MKL is indeed on par with netlib MKL.

https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing

Best regards, Alexander

-----Original Message-----
From: Sam Halliday [mailto:sam.halliday@gmail.com<mailto:sam.halliday@gmail.com>]
Sent: Tuesday, March 03, 2015 1:54 PM
To: Xiangrui Meng; Joseph Bradley
Cc: Evan R. Sparks; Ulanov, Alexander; dev@spark.apache.org<mailto:dev@spark.apache.org>
Subject: Re: Using CUDA within Spark / boosting linear algebra

BTW, is anybody on this list going to the London Meetup in a few weeks?

https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-mapreduce-world#community

Would be nice to meet other people working on the guts of Spark! :-)


Xiangrui Meng <mengxr@gmail.com<mailto:mengxr@gmail.com>> writes:

> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x
> slower than netlib-openblas. What is the overhead of using a GPU BLAS
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com<mailto:joseph@databricks.com>> wrote:
>> Better documentation for linking would be very helpful!  Here's a JIRA:
>> https://issues.apache.org/jira/browse/SPARK-6019
>>
>>
>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks
>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
>> wrote:
>>
>>> Thanks for compiling all the data and running these benchmarks,
>>> Alex. The big takeaways here can be seen with this chart:
>>>
>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZ
>>> Hl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
>>>
>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>> BIDMat+GPU) can provide substantial (but less than an order of
>>> BIDMat+magnitude)
>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>>> netlib-java+openblas-compiled).
>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude
>>> worse than a well-tuned CPU implementation, particularly for larger matrices.
>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
>>> basically agrees with the authors own benchmarks (
>>> https://github.com/fommil/netlib-java)
>>>
>>> I think that most of our users are in a situation where using GPUs
>>> may not be practical - although we could consider having a good GPU
>>> backend available as an option. However, *ALL* users of MLlib could
>>> benefit (potentially tremendously) from using a well-tuned CPU-based
>>> BLAS implementation. Perhaps we should consider updating the mllib
>>> guide with a more complete section for enabling high performance
>>> binaries on OSX and Linux? Or better, figure out a way for the
>>> system to fetch these automatically.
>>>
>>> - Evan
>>>
>>>
>>>
>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>
>>>> Just to summarize this thread, I was finally able to make all
>>>> performance comparisons that we discussed. It turns out that:
>>>> BIDMat-cublas>>BIDMat
>>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-repo=
>>>> =netlib-cublas>netlib-blas>f2jblas
>>>>
>>>> Below is the link to the spreadsheet with full results.
>>>>
>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx
>>>> 378T9J5r7kwKSPkY/edit?usp=sharing
>>>>
>>>> One thing still needs exploration: does BIDMat-cublas perform
>>>> copying to/from machine’s RAM?
>>>>
>>>> -----Original Message-----
>>>> From: Ulanov, Alexander
>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>>> To: Evan R. Sparks
>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Thanks, Evan! It seems that ticket was marked as duplicate though
>>>> the original one discusses slightly different topic. I was able to
>>>> link netlib with MKL from BIDMat binaries. Indeed, MKL is
>>>> statically linked inside a 60MB library.
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>>> |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>>> 1569,233228 |
>>>>
>>>> It turn out that pre-compiled MKL is faster than precompiled
>>>> OpenBlas on my machine. Probably, I’ll add two more columns with
>>>> locally compiled openblas and cuda.
>>>>
>>>> Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>]
>>>> Sent: Monday, February 09, 2015 6:06 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Great - perhaps we can move this discussion off-list and onto a
>>>> JIRA ticket? (Here's one:
>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>>>>
>>>> It seems like this is going to be somewhat exploratory for a while
>>>> (and there's probably only a handful of us who really care about
>>>> fast linear
>>>> algebra!)
>>>>
>>>> - Evan
>>>>
>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for explanation and useful link. I am going to build
>>>> OpenBLAS, link it with Netlib-java and perform benchmark again.
>>>>
>>>> Do I understand correctly that BIDMat binaries contain statically
>>>> linked Intel MKL BLAS? It might be the reason why I am able to run
>>>> BIDMat not having MKL BLAS installed on my server. If it is true, I
>>>> wonder if it is OK because Intel sells this library. Nevertheless,
>>>> it seems that in my case precompiled MKL BLAS performs better than
>>>> precompiled OpenBLAS given that BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>>
>>>> Though, it might be interesting to link Netlib-java with Intel MKL,
>>>> as you suggested. I wonder, are John Canny (BIDMat) and Sam
>>>> Halliday
>>>> (Netlib-java) interested to compare their libraries.
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:58 PM
>>>>
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I would build OpenBLAS yourself, since good BLAS performance comes
>>>> from getting cache sizes, etc. set up correctly for your particular
>>>> hardware - this is often a very tricky process (see, e.g. ATLAS),
>>>> but we found that on relatively modern Xeon chips, OpenBLAS builds
>>>> quickly and yields performance competitive with MKL.
>>>>
>>>> To make sure the right library is getting used, you have to make
>>>> sure it's first on the search path - export
>>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>>>>
>>>> For some examples of getting netlib-java setup on an ec2 node and
>>>> some example benchmarking code we ran a while back, see:
>>>> https://github.com/shivaram/matrix-bench
>>>>
>>>> In particular - build-openblas-ec2.sh shows you how to build the
>>>> library and set up symlinks correctly, and scala/run-netlib.sh
>>>> shows you how to get the path setup and get that library picked up by netlib-java.
>>>>
>>>> In this way - you could probably get cuBLAS set up to be used by
>>>> netlib-java as well.
>>>>
>>>> - Evan
>>>>
>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to
>>>> force loading the right blas? For netlib, I there are few JVM
>>>> flags, such as
>>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS,
>>>> so I can force it to use Java implementation. Not sure I understand how to force use a specific blas (not specific wrapper for blas).
>>>>
>>>> Btw. I have installed openblas (yum install openblas), so I suppose
>>>> that netlib is using it.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:19 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Getting breeze to pick up the right blas library is critical for
>>>> performance. I recommend using OpenBLAS (or MKL, if you already have it).
>>>> It might make sense to force BIDMat to use the same underlying BLAS
>>>> library as well.
>>>>
>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan, Joseph
>>>>
>>>> I did few matrix multiplication test and BIDMat seems to be ~10x
>>>> faster than netlib-java+breeze (sorry for weird table formatting):
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
>>>> |native_system_linux_x86-64|
>>>> Breeze+Netlib-java f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228
>>>> ||
>>>>
>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora
>>>> 19 Linux, Scala 2.11.
>>>>
>>>> Later I will make tests with Cuda. I need to install new Cuda
>>>> version for this purpose.
>>>>
>>>> Do you have any ideas why breeze-netlib with native blas is so much
>>>> slower than BIDMat MKL?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:joseph@databricks.com><mailto:
>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Evan R. Sparks;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Hi Alexander,
>>>>
>>>> Using GPUs with Spark would be very exciting.  Small comment:
>>>> Concerning your question earlier about keeping data stored on the
>>>> GPU rather than having to move it between main memory and GPU
>>>> memory on each iteration, I would guess this would be critical to
>>>> getting good performance.  If you could do multiple local
>>>> iterations before aggregating results, then the cost of data
>>>> movement to the GPU could be amortized (and I believe that is done
>>>> in practice).  Having Spark be aware of the GPU and using it as another part of memory sounds like a much bigger undertaking.
>>>>
>>>> Joseph
>>>>
>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Thank you for explanation! I’ve watched the BIDMach presentation by
>>>> John Canny and I am really inspired by his talk and comparisons with Spark MLlib.
>>>>
>>>> I am very interested to find out what will be better within Spark:
>>>> BIDMat or netlib-java with CPU or GPU natives. Could you suggest a
>>>> fair way to benchmark them? Currently I do benchmarks on artificial
>>>> neural networks in batch mode. While it is not a “pure” test of
>>>> linear algebra, it involves some other things that are essential to machine learning.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to
>>>> netlib-java+data
>>>> layout and fewer levels of indirection - it's definitely a
>>>> worthwhile experiment to run. The main speedups I've seen from
>>>> using it come from highly optimized GPU code for linear algebra. I
>>>> know that in the past Canny has gone as far as to write custom GPU
>>>> kernels for performance-critical regions of code.[1]
>>>>
>>>> BIDMach is highly optimized for single node performance or
>>>> performance on small clusters.[2] Once data doesn't fit easily in
>>>> GPU memory (or can be batched in that way) the performance tends to
>>>> fall off. Canny argues for hardware/software codesign and as such
>>>> prefers machine configurations that are quite different than what
>>>> we find in most commodity cluster nodes - e.g. 10 disk cahnnels and 4 GPUs.
>>>>
>>>> In contrast, MLlib was designed for horizontal scalability on
>>>> commodity clusters and works best on very big datasets - order of terabytes.
>>>>
>>>> For the most part, these projects developed concurrently to address
>>>> slightly different use cases. That said, there may be bits of
>>>> BIDMach we could repurpose for MLlib - keep in mind we need to be
>>>> careful about maintaining cross-language compatibility for our Java
>>>> and Python-users, though.
>>>>
>>>> - Evan
>>>>
>>>> [1] - http://arxiv.org/abs/1409.5402 [2] -
>>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>>
>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do
>>>> you know what makes them faster than netlib-java?
>>>>
>>>> The same group has BIDMach library that implements machine
>>>> learning. For some examples they use Caffe convolutional neural
>>>> network library owned by another group in Berkeley. Could you
>>>> elaborate on how these all might be connected with Spark Mllib? If
>>>> you take BIDMat for linear algebra why don’t you take BIDMach for optimization and learning?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU
>>>> blas in many cases.
>>>>
>>>> You might consider taking a look at the codepaths that BIDMat (
>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work
>>>> optimizing to make this work really fast from Scala. I've run it on
>>>> my laptop and compared to MKL and in certain cases it's 10x faster at matrix multiply.
>>>> There are a lot of layers of indirection here and you really want
>>>> to avoid data copying as much as possible.
>>>>
>>>> We could also consider swapping out BIDMat for Breeze, but that
>>>> would be a big project and if we can figure out how to get
>>>> breeze+cublas to comparable performance that would be a big win.
>>>>
>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Dear Spark developers,
>>>>
>>>> I am exploring how to make linear algebra operations faster within Spark.
>>>> One way of doing this is to use Scala Breeze library that is
>>>> bundled with Spark. For matrix operations, it employs Netlib-java
>>>> that has a Java wrapper for BLAS (basic linear algebra subprograms)
>>>> and LAPACK native binaries if they are available on the worker
>>>> node. It also has its own optimized Java implementation of BLAS. It
>>>> is worth mentioning, that native binaries provide better performance only for BLAS level 3, i.e.
>>>> matrix-matrix operations or general matrix multiplication (GEMM).
>>>> This is confirmed by GEMM test on Netlib-java page
>>>> https://github.com/fommil/netlib-java. I also confirmed it with my
>>>> experiments with training of artificial neural network
>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>>> However, I would like to boost performance more.
>>>>
>>>> GPU is supposed to work fast with linear algebra and there is
>>>> Nvidia CUDA implementation of BLAS, called cublas. I have one Linux
>>>> server with Nvidia GPU and I was able to do the following. I linked
>>>> cublas (instead of cpu-based blas) with Netlib-java wrapper and put
>>>> it into Spark, so Breeze/Netlib is using it. Then I did some
>>>> performance measurements with regards to artificial neural network
>>>> batch learning in Spark MLlib that involves matrix-matrix
>>>> multiplications. It turns out that for matrices of size less than
>>>> ~1000x780 GPU cublas has the same speed as CPU blas. Cublas becomes
>>>> slower for bigger matrices. It worth mentioning that it is was not a test for ONLY multiplication since there are other operations involved.
>>>> One of the reasons for slowdown might be the overhead of copying
>>>> the matrices from computer memory to graphic card memory and back.
>>>>
>>>> So, few questions:
>>>> 1) Do these results with CUDA make sense?
>>>> 2) If the problem is with copy overhead, are there any libraries
>>>> that allow to force intermediate results to stay in graphic card
>>>> memory thus removing the overhead?
>>>> 3) Any other options to speed-up linear algebra in Spark?
>>>>
>>>> Thank you, Alexander
>>>>
>>>> -------------------------------------------------------------------
>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org><mailto:
>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org>><mailto:dev-unsubscribe@spark.apac<mailto:dev-unsubscribe@spark.apac>
>>>> he.org<http://he.org> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org>>>
>>>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
>>>>
>>>>
>>>>
>>>>
>>>

--
Best regards,
Sam
"
Shivaram Venkataraman <shivaram@eecs.berkeley.edu>,"Tue, 10 Mar 2015 11:12:35 -0700",Re: Using CUDA within Spark / boosting linear algebra,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","I have run some BLAS comparison benchmarks on different EC2 instance sizes
and also on NERSC super computers. I can put together a github-backed
website where we can host latest benchmark results and update them over
time.

Sam -- Does that sound like what you had in mind ?

Thanks
Shivaram


n
m
y
n
nd
5r7kwKSPkY/edit?usp=sharing
uce-world#community
:
m-repo=
with
y
tion by
 test of
4
h for
t
"
Nitay Joffe <nitay@actioniq.co>,"Tue, 10 Mar 2015 16:51:03 -0400",Spark 1.3 SQL Type Parser Changes?,"user@spark.apache.org, dev@spark.apache.org","In Spark 1.2 I used to be able to do this:

scala>
org.apache.spark.sql.hive.HiveMetastoreTypes.toDataType(""struct<int:bigint>"")
res30: org.apache.spark.sql.catalyst.types.DataType =
StructType(List(StructField(int,LongType,true)))

That is, the name of a column can be a keyword like ""int"". This is no
longer the case in 1.3:

data-pipeline-shell> HiveTypeHelper.toDataType(""struct<int:bigint>"")
org.apache.spark.sql.sources.DDLException: Unsupported dataType: [1.8]
failure: ``>'' expected but `int' found

struct<int:bigint>
       ^
        at org.apache.spark.sql.sources.DDLParser.parseType(ddl.scala:52)
        at
org.apache.spark.sql.hive.HiveMetastoreTypes$.toDataType(HiveMetastoreCatalog.scala:785)
        at
org.apache.spark.sql.hive.HiveTypeHelper$.toDataType(HiveTypeHelper.scala:9)

Note HiveTypeHelper is simply an object I load in to expose
HiveMetastoreTypes since it was made private. See
https://gist.github.com/nitay/460b41ed5fd7608507f5
<https://app.relateiq.com/r?c=chrome_gmail&url=https%3A%2F%2Fgist.github.com%2Fnitay%2F460b41ed5fd7608507f5&t=AFwhZf262cJFT8YSR54ZotvY2aTmpm_zHTSKNSd4jeT-a6b8q-yMXQ-BqEX9-Ym54J1bkDFiFOXyRKsNxXoDGIh7bhqbBVKsGGq6YTJIfLZxs375XXPdS13KHsE_3Lffk4UIFkRFZ_7c>

This is actually a pretty big problem for us as we have a bunch of legacy
tables with column names like ""timestamp"". They work fine in 1.2, but now
everything throws in 1.3.

Any thoughts?

Thanks,
- Nitay
Founder & CTO
"
Michael Armbrust <michael@databricks.com>,"Tue, 10 Mar 2015 14:43:31 -0700",Re: Spark 1.3 SQL Type Parser Changes?,Nitay Joffe <nitay@actioniq.co>,"Thanks for reporting.  This was a result of a change to our DDL parser that
resulted in types becoming reserved words.  I've filled a JIRA and will
investigate if this is something we can fix.
https://issues.apache.org/jira/browse/SPARK-6250


"
Yin Huai <yhuai@databricks.com>,"Tue, 10 Mar 2015 17:06:21 -0700",Re: Spark 1.3 SQL Type Parser Changes?,Michael Armbrust <michael@databricks.com>,"Hi Nitay,

Can you try using backticks to quote the column name? Like
org.apache.spark.sql.hive.HiveMetastoreTypes.toDataType(
""struct<`int`:bigint>"")?

Thanks,

Yin


"
"""Ganelin, Ilya"" <Ilya.Ganelin@capitalone.com>","Tue, 10 Mar 2015 20:09:47 -0400","Spark tests hang on local machine due to ""testGuavaOptional"" in
 JavaAPISuite",dev <dev@spark.apache.org>,"Hi all  building Spark on my local machine with build/mvn clean package test runs until it hits the JavaAPISuite where it hangs indefinitely. Through some experimentation, Ive narrowed it down to the following test:


/**
 * Test for SPARK-3647. This test needs to use the maven-built assembly to trigger the issue,
 * since that's the only artifact where Guava classes have been relocated.
 */
@Test
public void testGuavaOptional() {
  // Stop the context created in setUp() and start a local-cluster one, to force usage of the
  // assembly.
  sc.stop();
  JavaSparkContext localCluster = new JavaSparkContext(""local-cluster[1,1,512]"", ""JavaAPISuite"");
  try {
    JavaRDD<Integer> rdd1 = localCluster.parallelize(Arrays.asList(1, 2, null), 3);
    JavaRDD<Optional<Integer>> rdd2 = rdd1.map(
      new Function<Integer, Optional<Integer>>() {
        @Override
        public Optional<Integer> call(Integer i) {
          return Optional.fromNullable(i);
        }
      });
    rdd2.collect();
  } finally {
    localCluster.stop();
  }
}


If I remove this test, things work smoothly. Has anyone else seen this? Thanks.
________________________________________________________

The information contained in this e-mail is confidential and/or proprietary is intended only for use by the individual or entity to which it is addressed.  If the reader of this message is not the intended recipient, you are hereby notified that any review, retransmission, dissemination, distribution, copying or other use of, or taking of any action in reliance upon this information is strictly prohibited. If you have received this communication in error, please contact the sender and delete the material from your computer.
"
Sean Owen <sowen@cloudera.com>,"Wed, 11 Mar 2015 00:13:12 +0000","Re: Spark tests hang on local machine due to ""testGuavaOptional"" in JavaAPISuite","""Ganelin, Ilya"" <Ilya.Ganelin@capitalone.com>","Yes and I remember it was caused by ... well something related to the
Guava shading and the fact that you're running a mini cluster and then
talking to it. I can't remember what exactly resolved it but try a
clean build. Somehow I think it had to do with multiple assembly files
or something like that.

package test runs until it hits the JavaAPISuite where it hangs indefinitely. Through some experimentation, I’ve narrowed it down to the following test:
o trigger the issue,
.
o force usage of the
,1,512]"", ""JavaAPISuite"");
, null), 3);
hanks.
th is intended only for use by the individual or entity to which it is addressed.  If the reader of this message is not the intended recipient, you are hereby notified that any review, retransmission, dissemination, distribution, copying or other use of, or taking of any action in reliance upon this information is strictly prohibited. If you have received this communication in error, please contact the sender and delete the material from your computer.

---------------------------------------------------------------------


"
"""Cheng, Hao"" <hao.cheng@intel.com>","Wed, 11 Mar 2015 00:24:54 +0000",RE: [SparkSQL] Reuse HiveContext to different Hive warehouse?,"Haopu Wang <HWang@qilinsoft.com>, user <user@spark.apache.org>,
	""dev@spark.apache.org"" <dev@spark.apache.org>","I am not so sure if Hive supports change the metastore after initialized, I guess not. Spark SQL totally rely on Hive Metastore in HiveContext, probably that's why it doesn't work as expected for Q1.

BTW, in most of cases, people configure the metastore settings in hive-site.xml, and will not change that since then, is there any reason that you want to change that in runtime?

For Q2, probably something wrong in configuration, seems the HDFS run into the pseudo/single node mode, can you double check that? Or can you run the DDL (like create a table) from the spark shell with HiveContext?

From: Haopu Wang [mailto:HWang@qilinsoft.com]
Sent: Tuesday, March 10, 2015 6:38 PM
To: user; dev@spark.apache.org
Subject: [SparkSQL] Reuse HiveContext to different Hive warehouse?


I'm using Spark 1.3.0 RC3 build with Hive support.



In Spark Shell, I want to reuse the HiveContext instance to different warehouse locations. Below are the steps for my test (Assume I have loaded a file into table ""src"").



======

15/03/10 18:22:59 INFO SparkILoop: Created sql context (with Hive support)..

SQL context available as sqlContext.

scala> sqlContext.sql(""SET hive.metastore.warehouse.dir=/test/w"")

scala> sqlContext.sql(""SELECT * from src"").saveAsTable(""table1"")

scala> sqlContext.sql(""SET hive.metastore.warehouse.dir=/test/w2"")

scala> sqlContext.sql(""SELECT * from src"").saveAsTable(""table2"")

======

After these steps, the tables are stored in ""/test/w"" only. I expect ""table2"" to be stored in ""/test/w2"" folder.



Another question is: if I set ""hive.metastore.warehouse.dir"" to a HDFS folder, I cannot use saveAsTable()? Is this by design? Exception stack trace is below:

======

15/03/10 18:35:28 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0

15/03/10 18:35:28 INFO SparkContext: Created broadcast 0 from broadcast at TableReader.scala:74

java.lang.IllegalArgumentException: Wrong FS: hdfs://server:8020/space/warehouse/table2, expected: file:///<file:///\\>

        at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:643)

        at org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:463)

        at org.apache.hadoop.fs.FilterFileSystem.makeQualified(FilterFileSystem.java:118)

        at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.apply(newParquet.scala:252)

        at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.apply(newParquet.scala:251)

        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)

        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)

        at scala.collection.immutable.List.foreach(List.scala:318)

        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)

        at scala.collection.AbstractTraversable.map(Traversable.scala:105)

        at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache.refresh(newParquet.scala:251)

        at org.apache.spark.sql.parquet.ParquetRelation2.<init>(newParquet.scala:370)

        at org.apache.spark.sql.parquet.DefaultSource.createRelation(newParquet.scala:96)

        at org.apache.spark.sql.parquet.DefaultSource.createRelation(newParquet.scala:125)

        at org.apache.spark.sql.sources.ResolvedDataSource$.apply(ddl.scala:308)

        at org.apache.spark.sql.hive.execution.CreateMetastoreDataSourceAsSelect.run(commands.scala:217)

        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:55)

        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:55)

        at org.apache.spark.sql.execution.ExecutedCommand.execute(commands.scala:65)

        at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:1088)

        at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:1088)

        at org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:1048)

        at org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:998)

        at org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:964)

        at org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:942)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:20)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:25)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)

        at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)

        at $iwC$$iwC$$iwC$$iwC.<init>(<console>:31)

        at $iwC$$iwC$$iwC.<init>(<console>:33)

        at $iwC$$iwC.<init>(<console>:35)

        at $iwC.<init>(<console>:37)

        at <init>(<console>:39)



Thank you very much!


"
Michael Armbrust <michael@databricks.com>,"Tue, 10 Mar 2015 18:54:13 -0700",GitHub Syncing Down,"""dev@spark.apache.org"" <dev@spark.apache.org>","FYI: https://issues.apache.org/jira/browse/INFRA-9259
"
Reynold Xin <rxin@databricks.com>,"Tue, 10 Mar 2015 21:16:28 -0700",Re: SparkSpark-perf terasort WIP branch,Ewan Higgs <ewan.higgs@ugent.be>,"Hi Ewan,

Sorry it took a while for us to reply. I don't know spark-perf that well,
but I think this would be problematic if it works with only a specific
version of Hadoop. Maybe we can take a different approach -- just have a
bunch of tasks using the HDFS client API to read data, and not relying on
input formats?



"
Patrick Wendell <pwendell@gmail.com>,"Tue, 10 Mar 2015 22:24:34 -0700",[RESULT] [VOTE] Release Apache Spark 1.3.0 (RC3),"""dev@spark.apache.org"" <dev@spark.apache.org>","This vote passes with 13 +1 votes (6 binding) and no 0 or -1 votes:

+1 (13):
Patrick Wendell*
Marcelo Vanzin
Krishna Sankar
Sean Owen*
Matei Zaharia*
Sandy Ryza
Tom Graves*
Sean McNamara*
Denny Lee
Kostas Sakellis
Joseph Bradley*
Corey Nolet
GuoQiang Li

0:
-1:

I will finalize the release notes and packaging and will post the
release in the next two days.

- Patrick

2:20
f48d46d13129f0f9bdafd771dd80fe568a7dc

---------------------------------------------------------------------


"
"""Haopu Wang"" <HWang@qilinsoft.com>","Wed, 11 Mar 2015 14:36:05 +0800",RE: [SparkSQL] Reuse HiveContext to different Hive warehouse?,"""Cheng, Hao"" <hao.cheng@intel.com>,
	""user"" <user@spark.apache.org>,
	<dev@spark.apache.org>","Hao, thanks for the response.

 

For Q1, in my case, I have a tool on SparkShell which serves multiple
users where they can use different Hive installation. I take a look at
the code of HiveContext. It looks like I cannot do that today because
""catalog"" field cannot be changed after initialize.

 

  /* A catalyst metadata catalog that points to the Hive Metastore. */

  @transient

  override protected[sql] lazy val catalog = new
HiveMetastoreCatalog(this) with OverrideCatalog

 

For Q2, I check HDFS and it is running as a cluster. I can run the DDL
from spark shell with HiveContext as well. To reproduce the exception, I
just run below script. It happens in the last step.

 

15/03/11 14:24:48 INFO SparkILoop: Created sql context (with Hive
support)..

SQL context available as sqlContext.

scala> sqlContext.sql(""SET
hive.metastore.warehouse.dir=hdfs://server:8020/space/warehouse"")

scala> sqlContext.sql(""CREATE TABLE IF NOT EXISTS src(key INT, value
STRING)"")

scala> sqlContext.sql(""LOAD DATA LOCAL INPATH
'examples/src/main/resources/kv1.txt' INTO TABLE src"")

scala> var output = sqlContext.sql(""SELECT key,value FROM src"")

scala> output.saveAsTable(""outputtable"")

 

________________________________

From: Cheng, Hao [mailto:hao.cheng@intel.com] 
Sent: Wednesday, March 11, 2015 8:25 AM
To: Haopu Wang; user; dev@spark.apache.org
Subject: RE: [SparkSQL] Reuse HiveContext to different Hive warehouse?

 

I am not so sure if Hive supports change the metastore after
initialized, I guess not. Spark SQL totally rely on Hive Metastore in
HiveContext, probably that's why it doesn't work as expected for Q1.

 

BTW, in most of cases, people configure the metastore settings in
hive-site.xml, and will not change that since then, is there any reason
that you want to change that in runtime?

 

For Q2, probably something wrong in configuration, seems the HDFS run
into the pseudo/single node mode, can you double check that? Or can you
run the DDL (like create a table) from the spark shell with HiveContext?


 

From: Haopu Wang [mailto:HWang@qilinsoft.com] 
Sent: Tuesday, March 10, 2015 6:38 PM
To: user; dev@spark.apache.org
Subject: [SparkSQL] Reuse HiveContext to different Hive warehouse?

 

I'm using Spark 1.3.0 RC3 build with Hive support.

 

In Spark Shell, I want to reuse the HiveContext instance to different
warehouse locations. Below are the steps for my test (Assume I have
loaded a file into table ""src"").

 

======

15/03/10 18:22:59 INFO SparkILoop: Created sql context (with Hive
support)..

SQL context available as sqlContext.

scala> sqlContext.sql(""SET hive.metastore.warehouse.dir=/test/w"")

scala> sqlContext.sql(""SELECT * from src"").saveAsTable(""table1"")

scala> sqlContext.sql(""SET hive.metastore.warehouse.dir=/test/w2"")

scala> sqlContext.sql(""SELECT * from src"").saveAsTable(""table2"")

======

After these steps, the tables are stored in ""/test/w"" only. I expect
""table2"" to be stored in ""/test/w2"" folder.

 

Another question is: if I set ""hive.metastore.warehouse.dir"" to a HDFS
folder, I cannot use saveAsTable()? Is this by design? Exception stack
trace is below:

======

15/03/10 18:35:28 INFO BlockManagerMaster: Updated info of block
broadcast_0_piece0

15/03/10 18:35:28 INFO SparkContext: Created broadcast 0 from broadcast
at TableReader.scala:74

java.lang.IllegalArgumentException: Wrong FS:
hdfs://server:8020/space/warehouse/table2, expected: file:///
<file:///\\> 

        at
org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:643)

        at
org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:463)

        at
org.apache.hadoop.fs.FilterFileSystem.makeQualified(FilterFileSystem.jav
a:118)

        at
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.a
pply(newParquet.scala:252)

        at
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.a
pply(newParquet.scala:251)

        at
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.sc
ala:244)

        at
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.sc
ala:244)

        at scala.collection.immutable.List.foreach(List.scala:318)

        at
scala.collection.TraversableLike$class.map(TraversableLike.scala:244)

        at
scala.collection.AbstractTraversable.map(Traversable.scala:105)

        at
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache.refresh(newP
arquet.scala:251)

        at
org.apache.spark.sql.parquet.ParquetRelation2.<init>(newParquet.scala:37
0)

        at
org.apache.spark.sql.parquet.DefaultSource.createRelation(newParquet.sca
la:96)

        at
org.apache.spark.sql.parquet.DefaultSource.createRelation(newParquet.sca
la:125)

        at
org.apache.spark.sql.sources.ResolvedDataSource$.apply(ddl.scala:308)

        at
org.apache.spark.sql.hive.execution.CreateMetastoreDataSourceAsSelect.ru
n(commands.scala:217)

        at
org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompu
te(commands.scala:55)

        at
org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands
.scala:55)

        at
org.apache.spark.sql.execution.ExecutedCommand.execute(commands.scala:65
)

        at
org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLConte
xt.scala:1088)

        at
org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:10
88)

        at
org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:1048)

        at
org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:998)

        at
org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:964)

        at
org.apache.spark.sql.DataFrame.saveAsTable(DataFrame.scala:942)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:20)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:25)

        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)

        at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)

        at $iwC$$iwC$$iwC$$iwC.<init>(<console>:31)

        at $iwC$$iwC$$iwC.<init>(<console>:33)

        at $iwC$$iwC.<init>(<console>:35)

        at $iwC.<init>(<console>:37)

        at <init>(<console>:39)

 

Thank you very much!

 

"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Wed, 11 Mar 2015 14:58:27 +0100",Spark Streaming - received block allocation to batch,dev@spark.apache.org,"I'm trying to understand the block allocation mechanism Spark uses to
generate batch jobs and a JobSet.

The JobGenerator.generateJobs tries to allocate received blocks to batch,
effectively in ReceivedBlockTracker.allocateBlocksToBatch creates
a streamIdToBlocks, where steam ID's (Int) mapped to Seq[ReceivedBlockInfo]
using getReceivedBlockQueue. This is where it gets tricky for me.

getReceivedBlockQueue of class ReceivedBlockTracker reads
streamIdToUnallocatedBlockQueues
that should be populated with ReceivedBlockQueues? Who inserts these
ReceivedBlockQueues into streamIdToUnallocatedBlockQueues and where does it
get written? I've found only usages of 'effectively' value read.

At a point streamIdToBlocks get packed into a case class
of AllocatedBlocks. Why is it necessary?

Also, at JobGenerator.generateJobs the line where receivedBlockInfos created,
shouldn't it be empty, because streamIdToUnallocatedBlockQueues never got
written to? Where do I miss the point? How does the JobGenerator.generateJobs
able to retrieve the received block infos?

Thanks,

ZZ
"
Ted Yu <yuzhihong@gmail.com>,"Wed, 11 Mar 2015 07:38:32 -0700",Re: GitHub Syncing Down,Michael Armbrust <michael@databricks.com>,"Looks like github is functioning again (I no longer encounter this problem
when pushing to hbase repo).

Do you want to give it a try ?

Cheers


"
Sean Owen <sowen@cloudera.com>,"Wed, 11 Mar 2015 14:43:35 +0000",Re: GitHub Syncing Down,Ted Yu <yuzhihong@gmail.com>,"(I have been able to push over the last few hours and see the commits in github)


---------------------------------------------------------------------


"
"""lior.c"" <lior.c@taboola.com>","Wed, 11 Mar 2015 08:40:03 -0700 (MST)",Using Log4j2 in spark executors,dev@spark.apache.org,"Hi,

I'd like to allow using log4j2 in executor code.
As spark contains dependencies to log4j 1.2, I would like to support spark
build with log4j2 instead of log4j 1.2. 
To accomplish that, I suggest creating a new profile for log4j2 in
spark-parent.
The default profile (log4j12), would include dependencies for log4j and
slf4j-log4j12 with default scope (I would remove the dependencies from sub
modules of spark-parent).
The log4j2 profile would instead include same dependencies with scope
provided (to avoid the shading plugin add those jars as a result of
transitive dependencies from other jars that depend on log4j 12), and in
addition would include the dependencies required to log4j2.

Already tested it and it seems to work properly, and I would like to offer
it as a pull request.
What do you think of this solution?

Lior



--

---------------------------------------------------------------------


"
Michael Armbrust <michael@databricks.com>,"Wed, 11 Mar 2015 11:24:07 -0700",Re: [SparkSQL] Reuse HiveContext to different Hive warehouse?,Haopu Wang <HWang@qilinsoft.com>,"That val is not really your problem.  In general, there is a lot of global
state throughout the hive codebase that make it unsafe to try and connect
to more than one hive installation from the same JVM.


e
g""
o
e
d
t
:118)
ply(newParquet.scala:252)
ply(newParquet.scala:251)
la:244)
la:244)
)
rquet.scala:251)
)
a:96)
a:125)
(commands.scala:217)
e(commands.scala:55)
scala:55)
t.scala:1088)
8)
8)
)
)
)
"
RJ Nowling <rnowling@gmail.com>,"Wed, 11 Mar 2015 14:56:40 -0500",Re: enum-like types in Spark,Patrick Wendell <pwendell@gmail.com>,"How do these proposals affect PySpark?  I think compatibility with PySpark
through Py4J should be considered.


"
Tamer TAS <tamertas@outlook.com>,"Wed, 11 Mar 2015 22:22:39 +0200",Apache Spark GSOC 2015,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hello Everyone,

I'm a senior year computer engineering student in Turkey.
My main area of interests are cloud computing and machine learning.

I've been working on Apache Spark using Scala API for a few months. My projects involved the use of MLib for a movie recommendation system and a stock prediction model. I would be interested in working on Spark for GSOC 2015. From my experience there a few enhancements that can be done; 
 - Learning models can be standardized in a hierarchical manner to increase code quality and make future algorithm implementations easier. For example, even though it's in graphx library, SVD++ didn't have any model implementations. Currently it only returns the pieces of the calculation. The documentation wasn't clear either (apart from the link to the SVD++ paper). 
 - New algorithms might be implemented to such as restricted Boltzmann machines, tensor models and tensor factorization for recommendation sub-library, svm multi-class classification.
 - Testing documentation was close to none(only a blog post link). Each test creates a new spark context. Work-arounds were necessary to increase testing productivity(e.g. pass,fail,refactor cycle was taking a long time).
But, don't get the idea that I dislike Spark for not having those features. I loved working with Spark and I'd be happy to work on improving it. Mainly the model hierarchy and new machine learning algorithms for Spark MLib and GraphX if there is anyone who would be interested in mentoring. I'll work on a proposal to give more details about algorithms, a timeline. I just wanted to give a heads-up before doing so.
If you have any questions please feel free to ask.
Thanks in advance.

Tamer Tas
 		 	   		  "
Tathagata Das <tdas@databricks.com>,"Wed, 11 Mar 2015 18:57:49 -0700",Re: Spark Streaming - received block allocation to batch,=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"See responses inline.


o]
it
https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ReceivedBlockTracker.scala#L84



Just a container that captures all the blocks allocated to a batch. Used
for both tracking in memory as well as writing it out to the write ahead
log.




"
"""Zhang, Liyun"" <liyun.zhang@intel.com>","Thu, 12 Mar 2015 06:47:30 +0000",is there any api in spark like getInstance(className:String):AnyRef ,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi all:
  I'm a newbie to spark and scala and now I am working on SPARK-5682<https://issues.apache.org/jira/browse/SPARK-5682>(Add encrypted shuffle in spark). I met a problem:is there any api in spark like getInstance(className:String):AnyRef ? I saw org.apache.spark.sql.hive
.thriftserver.ReflectionUtils.scala, but not provide getInstance function in it.

Now i only can implement this function by following code:
object ReflectionUtils1 {
  import scala.reflect.runtime.universe
  abstract case class CryptoCodec() {

  }

  class JceAesCtrCryptoCodec extends CryptoCodec {

  }

  class OpensslAesCtrCryptoCodec extends CryptoCodec {

  }

  def main(args: Array[String]) = {
    val className:String =  ""JceAesCtrCryptoCodec""
    val obj = getInstance(className)
    val codec:CryptoCodec = obj.asInstanceOf[CryptoCodec]
    println(codec)
  }

  def getInstance(className:String):AnyRef={
    val m = universe.runtimeMirror(getClass.getClassLoader)
    var c: CryptoCodec = null
    if (className.equals(""JceAesCtrCryptoCodec"")) {
      val classCryptoCodec = universe.typeOf[JceAesCtrCryptoCodec]
        .typeSymbol.asClass
      val cm = m.reflectClass(classCryptoCodec)
      val ctor = universe.typeOf[JceAesCtrCryptoCodec].declaration(
        universe.nme.CONSTRUCTOR).asMethod
      val ctorm = cm.reflectConstructor(ctor)
      val p = ctorm()
      c = p.asInstanceOf[CryptoCodec]
    } else {
      val classCryptoCodec = universe.typeOf[OpensslAesCtrCryptoCodec]
        .typeSymbol.asClass
      val cm = m.reflectClass(classCryptoCodec)
      val ctor = universe.typeOf[OpensslAesCtrCryptoCodec].declaration(
        universe.nme.CONSTRUCTOR).asMethod
      val ctorm = cm.reflectConstructor(ctor)
      val p = ctorm()
      c = p.asInstanceOf[CryptoCodec]
    }
   c
  }
}


in my getInstance(className:String), i judge classname with ""JceAesCtrCryptoCodec"" and
""OpensslAesCtrCryptoCodec"" and if the name equals ""JceAesCtrCryptoCodec"", it creates the instance by scala.reflect.runtime.universe api. The code can be better like following way but I do not know how to write it:
   def getInstance1(className:String):AnyRef={
       val m = universe.runtimeMirror(getClass.getClassLoader)
       var classLoader: ClassLoader = Thread.currentThread.getContextClassLoader
       val aClass:Class[_] =   Class.forName(className, true, classLoader)
       val aType: scala.reflect.api.TypeTags.TypeTag =  // how to write this line?
       val classCryptoCodec = universe.typeOf[aType]
         .typeSymbol.asClass
       val cm = m.reflectClass(classCryptoCodec)
       val ctor = universe.typeOf[aType].declaration(
         universe.nme.CONSTRUCTOR).asMethod
       val ctorm = cm.reflectConstructor(ctor)
       val p = ctorm()
       p
     }

Guidance/advice appreciated!



Best regards
Kelly Zhang/Zhang,Liyun

"
Chunnan Yao <yaochunnan@gmail.com>,"Thu, 12 Mar 2015 00:13:55 -0700 (MST)","Is this a bug in MLlib.stat.test ? About the mapPartitions API used
 in Chi-Squared test",dev@spark.apache.org,"Hi everyone!
I am digging into MLlib of Spark 1.2.1 currently. When reading codes of
MLlib.stat.test, in the file ChiSqTest.scala under
/spark/mllib/src/main/scala/org/apache/spark/mllib/stat/test, I am confused
by the usage of mapPartitions API in the function  
def chiSquaredFeatures(data: RDD[LabeledPoint],
      methodName: String = PEARSON.name): Array[ChiSqTestResult]

According to my statistical testing knowledge, Chi-Square test requires
large numbers (>5 for 80% entries) in its contingency matrix in order to
satisfy good approximation
(http://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test). Thus the number
of feature & label categories cannot be too large because if otherwise,
there would be too few items in each categories, which fails to meet  the
constraint in usage of Chi-square test. 

I do see in the function above, Spark will throw exceptions when
distinctLabels.size and distinctFeatures.size exceed maxCategories defined
as 10000, but the  two HashSets distinctLabels and distinctFeatures are
initialized inside mapPartition, which means Spark will only be sensitive to
the number of feature & label categories in one partition. This will make
the reduced result---contingency matrix still have exceeded number of
categories and thus small matrix entries which makes Chi-Square inaccurate.
I've made a unit test on this function, which proves the case. 

Maybe I am just being trapped by a misunderstanding. Could any one please
give me a hint on this issue?



-----
Feel the sparking Spark!
--

---------------------------------------------------------------------


"
shane knapp <sknapp@berkeley.edu>,"Thu, 12 Mar 2015 15:10:19 -0700",Re: adding some temporary jenkins worker nodes...,dev <dev@spark.apache.org>,"the big 1.3 push is over, so i'll be reclaiming these three extra workers.
 :)


"
Tom Hubregtsen <thubregtsen@gmail.com>,"Thu, 12 Mar 2015 16:09:11 -0700 (MST)",Spilling when not expected,dev@spark.apache.org,"Hi all,

I'm running the teraSort benchmark with a relative small input set: 5GB.
During profiling, I can see I am using a total of 68GB. I've got a terabyte
of memory in my system, and set
spark.executor.memory 900g
spark.driver.memory 900g
I use the default for 
spark.shuffle.memoryFraction 
spark.storage.memoryFraction
I believe that I now have 0.2*900=180GB for shuffle and 0.6*900=540GB for
storage.

I noticed a lot of variation in runtime (under the same load), and tracked
this down to this function in 
core/src/main/scala/org/apache/spark/util/collection/ExternalSorter.scala
  private def spillToPartitionFiles(collection:
SizeTrackingPairCollection[(Int, K), C]): Unit = {
    spillToPartitionFiles(collection.iterator)
  }
In a slow run, it would loop through this function 12000 times, in a fast
run only 700 times, even though the settings in both runs are the same and
there are no other users on the system. When I look at the function calling
this (insertAll, also in ExternalSorter), I see that spillToPartitionFiles
is only called 700 times in both fast and slow runs, meaning that the
function recursively calls itself very often. Because of the function name,
I assume the system is spilling to disk. As I have sufficient memory, I
assume that I forgot to set a certain memory setting. Anybody any idea which
other setting I have to set, in order to not spill data in this scenario?

Thanks,

Tom



--

---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Fri, 13 Mar 2015 00:34:40 +0000",Profiling Spark: MemoryStore,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

I am working on artificial neural networks for Spark. It is solved with Gradient Descent, so each step the data is read, sum of gradients is calculated for each data partition (on each worker), aggregated (on the driver) and broadcasted back. I noticed that the gradient computation time is few times less than the total time needed for each step. To narrow down my observation, I run the gradient on a single machine with single partition of data of site 100MB that I persist (data.persist). This should minimize the overhead for aggregation at least, but the gradient computation still takes much less time than the whole step. Just in case, data is loaded by MLUtil. loadLibSVMFile in RDD[LabeledPoint], this is my code:

    val conf = new SparkConf().setAppName(""myApp"").setMaster(""local[2]"")
    val train = MLUtils.loadLibSVMFile(new SparkContext(conf), ""/data/mnist/mnist.scale"").repartition(1).persist()
    val model = ANN2Classifier.train(train, 1000, Array[Int](32), 10, 1e-4) //training data, batch size, hidden layer size, iterations, LBFGS tolerance

Profiler shows that there are two threads, one is doing Gradient and the other I don't know what. The Gradient takes 10% of this thread. Almost all other time is spent by MemoryStore. Below is the screenshot (first thread):
https://drive.google.com/file/d/0BzYMzvDiCep5bGp2S2F6eE9TRlk/view?usp=sharing
Second thread:
https://drive.google.com/file/d/0BzYMzvDiCep5OHA0WUtQbXd3WmM/view?usp=sharing

Could Spark developers please elaborate what's going on in MemoryStore? It seems that it does some string operations (parsing libsvm file? Why every step?) and a lot of InputStream reading. It seems that the overall time depends on the size of the data batch (or size of vector) I am processing. However it does not seems linear to me.

Also, I would like to know how to speedup these operations.

Best regards, Alexander

"
Joseph Bradley <joseph@databricks.com>,"Thu, 12 Mar 2015 18:21:09 -0700","Re: Is this a bug in MLlib.stat.test ? About the mapPartitions API
 used in Chi-Squared test",Chunnan Yao <yaochunnan@gmail.com>,"The checks against maxCategories are not for statistical purposes; they are
to make sure communication does not blow up.  There currently are not
checks to make sure that there are enough entries for statistically
significant results.  That is up to the user.

I do like the idea of adding a warning.  A reasonable fix for now might be
JIRA, we could also discuss whether the result should be set to some value
to indicate a meaningless test (e.g., a very bad fixed pValue).

I made a JIRA to track this issue: SPARK-6312

Joseph


"
giive chen <thegiive@gmail.com>,"Fri, 13 Mar 2015 11:25:44 +0800",Re: SparkSQL 1.3.0 (RC3) failed to read parquet file generated by 1.1.1,dev@spark.apache.org,"Hi all

My team has the same issue. It looks like Spark 1.3's sparkSQL cannot read
parquet file generated by Spark 1.1. It will cost a lot of migration work
when we wanna to upgrade Spark 1.3.

Is there  anyone can help me?


Thanks

Wisely Chen



"
jfcanny <canny@berkeley.edu>,"Thu, 12 Mar 2015 20:50:24 -0700 (MST)",Re: Using CUDA within Spark / boosting linear algebra,dev@spark.apache.org,"If you're contemplating GPU acceleration in Spark, its important to look
beyond BLAS. Dense BLAS probably account for only 10% of the cycles in the
datasets we've tested in BIDMach, and we've tried to make them
representative of industry machine learning workloads. Unless you're
crunching images or audio, the majority of data will be very sparse and
power law distributed. You need a good sparse BLAS, and in practice it seems
like you need a sparse BLAS tailored for power-law data. We had to write our
own since the NVIDIA libraries didnt perform well on typical power-law data.
Intel MKL sparse BLAS also have issues and we only use some of them. 

You also need 2D reductions, scan operations, slicing, element-wise
transcendental functions and operators, many kinds of sort, random number
generators etc, and some kind of memory management strategy. Some of this
was layered on top of Thrust in BIDMat, but most had to be written from
scratch. Its all been rooflined, typically to memory throughput of current
GPUs (around 200 GB/s). 

When you have all this you can write Learning Algorithms in the same
high-level primitives available in Breeze or Numpy/Scipy. Its literally the
same in BIDMat, since the generic matrix operations are implemented on both
CPU and GPU, so the same code runs on either platform. 

A lesser known fact is that GPUs are around 10x faster for *all* those
operations, not just dense BLAS. Its mostly due to faster streaming memory
speeds, but some kernels (random number generation and transcendentals) are
more than an order of magnitude thanks to some specialized hardware for
power series on the GPU chip. 

When you have all this there is no need to move data back and forth across
the PCI bus. The CPU only has to pull chunks of data off disk, unpack them,
and feed them to the available GPUs. Most models fit comfortably in GPU
memory these days (4-12 GB). With minibatch algorithms you can push TBs of
data through the GPU this way. 



--

---------------------------------------------------------------------


"
Reynold Xin <rxin@databricks.com>,"Thu, 12 Mar 2015 22:53:52 -0700",Re: Using CUDA within Spark / boosting linear algebra,jfcanny <canny@berkeley.edu>,"Thanks for chiming in, John. I missed your meetup last night - do you have
any writeups or slides about roofline design? In particular, I'm curious
about what optimizations are available for power-law dense * sparse? (I
don't have any background in optimizations)




"
Michael Armbrust <michael@databricks.com>,"Thu, 12 Mar 2015 23:00:51 -0700",Re: SparkSQL 1.3.0 (RC3) failed to read parquet file generated by 1.1.1,giive chen <thegiive@gmail.com>,"We are looking at the issue and will likely fix it for Spark 1.3.1.


"
Mingyu Kim <mkim@palantir.com>,"Fri, 13 Mar 2015 07:04:32 +0000","toLocalIterator creates as many jobs as # of partitions, and it
 ends up spamming Spark UI","""dev@spark.apache.org"" <dev@spark.apache.org>","Hi all,

RDD.toLocalIterator() creates as many jobs as # of partitions and it spams Spark UI especially when the method is used on an RDD with hundreds or thousands of partitions.

Does anyone have a way to work around this issue? What do people think about introducing a SparkContext local property (analogous to spark.scheduler.pool set as a thread-local property) that determines if the job info should be shown on the Spark UI?

Thanks,
Mingyu
"
Reynold Xin <rxin@databricks.com>,"Fri, 13 Mar 2015 00:05:06 -0700",Re: Spilling when not expected,Tom Hubregtsen <thubregtsen@gmail.com>,"How did you run the Spark command? Maybe the memory setting didn't actually
apply? How much memory does the web ui say is available?

BTW - I don't think any JVM can actually handle 700G heap ... (maybe Zing).


"
Sean Owen <sowen@cloudera.com>,"Fri, 13 Mar 2015 10:06:39 +0000",May we merge into branch-1.3 at this point?,dev <dev@spark.apache.org>,"Is the release certain enough that we can resume merging into
branch-1.3 at this point? I have a number of back-ports queued up and
didn't want to merge in case another last RC was needed. I see a few
commits to the branch though.

---------------------------------------------------------------------


"
Dale Richardson <dale__r@hotmail.com>,"Fri, 13 Mar 2015 10:07:57 +0000",Spark config option 'expression language' feedback request,"""dev@spark.apache.org"" <dev@spark.apache.org>","










PR#4937 ( https://github.com/apache/spark/pull/4937) is a feature to allow for Spark configuration options (whether on command line, environment variable or a configuration file) to be specified via a simple expression language.


Such a feature has the following end-user benefits:
- Allows for the flexibility in specifying time intervals or byte quantities in appropriate and easy to follow units e.g. 1 week rather rather then 604800 seconds

- Allows for the scaling of a configuration option in relation to a system attributes. e.g.

SPARK_WORKER_CORES = numCores - 1

SPARK_WORKER_MEMORY = physicalMemoryBytes - 1.5 GB

- Gives the ability to scale multiple configuration options together eg:

spark.driver.memory = 0.75 * physicalMemoryBytes

spark.driver.maxResultSize = spark.driver.memory * 0.8


The following functions are currently supported by this PR:
NumCores:             Number of cores assigned to the JVM (usually == Physical machine cores)
PhysicalMemoryBytes:  Memory size of hosting machine

JVMTotalMemoryBytes:  Current bytes of memory allocated to the JVM

JVMMaxMemoryBytes:    Maximum number of bytes of memory available to the JVM

JVMFreeMemoryBytes:   maxMemoryBytes - totalMemoryBytes


I was wondering if anybody on the mailing list has any further ideas on other functions that could be useful to have when specifying spark configuration options?
Regards,Dale.
 		 	   		  "
Chester At Work <chester@alpinenow.com>,"Fri, 13 Mar 2015 04:31:24 -0700",Re: Using CUDA within Spark / boosting linear algebra,Reynold Xin <rxin@databricks.com>,"Reyonld, 

    Prof Canny gives me the slides yesterday I will posted the link to the slides to both SF BIg Analytics and SF Machine Learning meetups.

Chester

Sent from my iPad



e


t
he
th
y
re
s
m,
f
in-Spark-boosting-linear-algebra-tp10481p11021.html

---------------------------------------------------------------------


"
Mridul Muralidharan <mridul@gmail.com>,"Fri, 13 Mar 2015 08:20:33 -0700",Re: Spark config option 'expression language' feedback request,Dale Richardson <dale__r@hotmail.com>,"I am curious how you are going to support these over mesos and yarn.
Any configure change like this should be applicable to all of them, not
just local and standalone modes.

Regards
Mridul


"
Nicholas Chammas <nicholas.chammas@gmail.com>,"Fri, 13 Mar 2015 16:20:32 +0000",Re: May we merge into branch-1.3 at this point?,"Sean Owen <sowen@cloudera.com>, dev <dev@spark.apache.org>","Looks like the release is out:
http://spark.apache.org/releases/spark-release-1-3-0.html

Though, interestingly, I think we are missing the appropriate v1.3.0 tag:
https://github.com/apache/spark/releases

Nick


"
Sean Owen <sowen@cloudera.com>,"Fri, 13 Mar 2015 16:22:15 +0000",Re: May we merge into branch-1.3 at this point?,Nicholas Chammas <nicholas.chammas@gmail.com>,"Yeah, I'm guessing that is all happening quite literally as we speak.
The Apache git tag is the one of reference:
https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=4aaf48d46d13129f0f9bdafd771dd80fe568a7dc

Open season on 1.3 branch then...


---------------------------------------------------------------------


"
Mridul Muralidharan <mridul@gmail.com>,"Fri, 13 Mar 2015 09:31:58 -0700",Re: May we merge into branch-1.3 at this point?,Sean Owen <sowen@cloudera.com>,"Who is managing 1.3 release ? You might want to coordinate with them before
porting changes to branch.

Regards
Mridul


"
Tom Hubregtsen <thubregtsen@gmail.com>,"Fri, 13 Mar 2015 11:33:38 -0500",Re: Spilling when not expected,Reynold Xin <rxin@databricks.com>,"I use the spark-submit script and the config files in a conf directory. I
see the memory settings reflected in the stdout, as well as in the webUI.
(it prints all variables from spark-default.conf, and metions I have 540GB
free memory available when trying to store a broadcast variable or RDD). I
also run ""ps -aux | grep java | grep th"", which show me that I called java
with ""-Xms1000g -Xmx1000g""

I also tested if these numbers are realistic for the J9 JVM. Outside of
Spark, when setting just the initial heapsize (Xms), it gives an error, but
if I also define the maximum option with it (Xmx), it seems to us that it
is accepting it. Also, in IBM's J9 health center, I see it reserve the
900g, and use up to 68g.

Thanks,

Tom


"
jfcanny <canny@berkeley.edu>,"Fri, 13 Mar 2015 09:43:28 -0700 (MST)",Re: Using CUDA within Spark / boosting linear algebra,dev@spark.apache.org,"Hi Reynold,
I left Chester with a copy of the slides, so I assume they'll be posted 
on the SF ML or Big Data sites. We have a draft paper under review. I 
can ask the co-authors about arxiv'ing it.

feature set sorted by frequency. Power-law data has roughly the same 
mass in each power-of-two range of feature frequency. By keeping the 
most frequent features together, you get a lot more value out of the 
caches on the device (even GPUs have them, albeit smaller ones). e.g. 
with 100 million features, 1/2 of the feature instances will be in the 
range 1...,10,000. If they're consecutive they will all hit a fast 
cache. Another 1/4 will be in 1,...,1,000,000 hitting the next cache etc.

Another is to subdivide sparse matrices using the vector of elements 
rather than rows or columns. Splitting power-law matrices by either rows 
or columns gives very uneven splits. That means we store sparse matrices 
in coordinate form rather than compressed row or column format.

Other than that, rooflining gives you a goal that you should be able to 
reach. If you arent at the limit, just knowing that gives you a target 
to aim at. You can try profiling the kernel to figure out why its slower 
than it should be. There are a few common reasons (low occupancy, 
imbalanced thread blocks, thread divergence) that you can discover with 
the profiler. Then hopefully you can solve them.

-John







--"
Patrick Wendell <pwendell@gmail.com>,"Fri, 13 Mar 2015 10:00:14 -0700",[ANNOUNCE] Announcing Spark 1.3!,"""dev@spark.apache.org"" <dev@spark.apache.org>, ""user@spark.apache.org"" <user@spark.apache.org>","Hi All,

I'm happy to announce the availability of Spark 1.3.0! Spark 1.3.0 is
the fourth release on the API-compatible 1.X line. It is Spark's
largest release ever, with contributions from 172 developers and more
than 1,000 commits!

Visit the release notes [1] to read about the new features, or
download [2] the release today.

For errata in the contributions or release notes, please e-mail me
*directly* (not on-list).

Thanks to everyone who helped work on this release!

[1] http://spark.apache.org/releases/spark-release-1-3-0.html
[2] http://spark.apache.org/downloads.html

---------------------------------------------------------------------


"
Kushal Datta <kushal.datta@gmail.com>,"Fri, 13 Mar 2015 10:12:44 -0700",Re: [ANNOUNCE] Announcing Spark 1.3!,Patrick Wendell <pwendell@gmail.com>,"Kudos to the whole team for such a significant achievement!


"
shane knapp <sknapp@berkeley.edu>,"Fri, 13 Mar 2015 10:12:30 -0700","extended jenkins downtime monday, march 16th, plus some hints at the future","dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>","i'll be taking jenkins down for some much-needed plugin updates, as well as
potentially upgrading jenkins itself.

this will start at 730am PDT, and i'm hoping to have everything up by noon.

the move to the anaconda python will take place in the next couple of weeks
as i'm in the process of rebuilding my staging environment (much needed) to
better reflect production, and allow me to better test the change.

and finally, some teasers for what's coming up in the next month or so:

* move to a fully puppetized environment (yay no more shell script
deployments!)
* virtualized workers (including multiple OSes -- OS X, ubuntu, ...,
profit?)

more details as they come.

happy friday!

shane
"
Patrick Wendell <pwendell@gmail.com>,"Fri, 13 Mar 2015 10:36:29 -0700",Re: May we merge into branch-1.3 at this point?,Mridul Muralidharan <mridul@gmail.com>,"Hey Sean,

merge backports into that release.

- Patrick


---------------------------------------------------------------------


"
Reynold Xin <rxin@databricks.com>,"Fri, 13 Mar 2015 11:26:44 -0700",Re: Spark config option 'expression language' feedback request,Dale Richardson <dale__r@hotmail.com>,"This is an interesting idea.

Are there well known libraries for doing this? Config is the one place
where it would be great to have something ridiculously simple, so it is
more or less bug free. I'm concerned about the complexity in this patch and
subtle bugs that it might introduce to config options that users will have
no workarounds. Also I believe it is fairly hard for nice error messages to
propagate when using Scala's parser combinator.



"
Hari Shreedharan <hshreedharan@cloudera.com>,"Fri, 13 Mar 2015 11:53:16 -0700",PR Builder timing out due to ivy cache lock,"""dev@spark.apache.org"" <dev@spark.apache.org>","Looks like something is causing the PR Builder to timeout since this
morning with the ivy cache being locked.

Any idea what is happening?
"
shane knapp <sknapp@berkeley.edu>,"Fri, 13 Mar 2015 11:58:09 -0700",Re: PR Builder timing out due to ivy cache lock,Hari Shreedharan <hshreedharan@cloudera.com>,"link to a build, please?


"
Hari Shreedharan <hshreedharan@cloudera.com>,"Fri, 13 Mar 2015 12:03:46 -0700",Re: PR Builder timing out due to ivy cache lock,shane knapp <sknapp@berkeley.edu>,"Here you are:
https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/28571/consoleFull


"
shane knapp <sknapp@berkeley.edu>,"Fri, 13 Mar 2015 12:04:17 -0700",jenkins httpd being flaky,"dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>","we just started having issues when visiting jenkins and getting 503 service
unavailable errors.

i'm on it and will report back with an all-clear.
"
Michael Armbrust <michael@databricks.com>,"Fri, 13 Mar 2015 12:31:30 -0700",Re: SparkSQL 1.3.0 (RC3) failed to read parquet file generated by 1.1.1,giive chen <thegiive@gmail.com>,"Here is the JIRA: https://issues.apache.org/jira/browse/SPARK-6315


"
shane knapp <sknapp@berkeley.edu>,"Fri, 13 Mar 2015 12:40:06 -0700",Re: jenkins httpd being flaky,"dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>","ok we have a few different things happening:

1) httpd on the jenkins master is randomly (though not currently) flaking
out and causing visits to the site to return a 503.  nothing in the logs
shows any problems.

2) there are some github timeouts, which i tracked down and think it's a
problem with github themselves (see:  https://status.github.com/ and scroll
down to 'mean hook delivery time')

3) we have one spark job w/a strange ivy lock issue, that i just
retriggered (https://github.com/apache/spark/pull/4964)

4) there's an errant, unkillable pull request builder job (
https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/28574/console
)

more updates forthcoming.


"
Andrew Lee <alee526@hotmail.com>,"Fri, 13 Mar 2015 12:43:44 -0700","Spark ThriftServer encounter java.lang.IllegalArgumentException:
 Unknown auth type: null Allowed values are: [auth-int, auth-conf, auth]","""dev@spark.apache.org"" <dev@spark.apache.org>","When Kerberos is enabled, I get the following exceptions. (Spark 1.2.1 git commit 








b6eaf77d4332bfb0a698849b1f5f917d20d70e97, Hive 0.13.1, Apache Hadoop 2.4.1) when starting Spark ThriftServer.
Command to start thriftserver
./start-thriftserver.sh --hiveconf hive.server2.thrift.port=20000 --hiveconf hive.server2.thrift.bind.host=$(hostname) --master yarn-client
Error message in spark.log

2015-03-13 18:26:05,363 ERROR org.apache.hive.service.cli.thrift.ThriftCLIService (ThriftBinaryCLIService.java:run(93)) - Error: 
java.lang.IllegalArgumentException: Unknown auth type: null Allowed values are: [auth-int, auth-conf, auth]
        at org.apache.hive.service.auth.SaslQOP.fromString(SaslQOP.java:56)
        at org.apache.hive.service.auth.HiveAuthFactory.getSaslProperties(HiveAuthFactory.java:118)
        at org.apache.hive.service.auth.HiveAuthFactory.getAuthTransFactory(HiveAuthFactory.java:133)
        at org.apache.hive.service.cli.thrift.ThriftBinaryCLIService.run(ThriftBinaryCLIService.java:43)
        at java.lang.Thread.run(Thread.java:744)

I'm wondering if this is due to the same problem described in HIVE-8154 HIVE-7620 due to an older code based for the Spark ThriftServer?
Any insights are appreciated. Currently, I can't get Spark ThriftServer to run against a Kerberos cluster (Apache 2.4.1).

My hive-site.xml looks like the following for spark/conf.








<property>
  <name>hive.semantic.analyzer.factory.impl</name>
  <value>org.apache.hcatalog.cli.HCatSemanticAnalyzerFactory</value>
</property>
<property>
  <name>hive.metastore.execute.setugi</name>
  <value>true</value>
</property>
<property>
  <name>hive.stats.autogather</name>
  <value>false</value>
</property>
<property>
  <name>hive.session.history.enabled</name>
  <value>true</value>
</property>
<property>
  <name>hive.querylog.location</name>
  <value>/home/hive/log/${user.name}</value>
</property>
<property>
  <name>hive.exec.local.scratchdir</name>
  <value>/tmp/hive/scratch/${user.name}</value>
</property>
<property>
  <name>hive.metastore.uris</name>
  <value>thrift://somehostname:9083</value>
</property>
<!-- HIVE SERVER 2 -->
<property>
  <name>hive.server2.authentication</name>
  <value>KERBEROS</value>
</property>
<property>
  <name>hive.server2.authentication.kerberos.principal</name>
  <value>***</value>
</property>
<property>
  <name>hive.server2.authentication.kerberos.keytab</name>
  <value>***</value>
</property>
<property>
  <name>hive.server2.thrift.sasl.qop</name>
  <value>auth</value>
  <description>Sasl QOP value; one of 'auth', 'auth-int' and 'auth-conf'</description>
</property>
<property>
  <name>hive.server2.enable.impersonation</name>
  <description>Enable user impersonation for HiveServer2</description>
  <value>true</value>
</property>
<!-- HIVE METASTORE -->
<property>
  <name>hive.metastore.sasl.enabled</name>
  <value>true</value>
</property>
<property>
  <name>hive.metastore.kerberos.keytab.file</name>
  <value>***</value>
</property>
<property>
  <name>hive.metastore.kerberos.principal</name>
  <value>***</value>
</property>
<property>
  <name>hive.metastore.cache.pinobjtypes</name>
  <value>Table,Database,Type,FieldSchema,Order</value>
</property>
<property>
  <name>hdfs_sentinel_file</name>
  <value>***</value>
</property>
<property>
  <name>hive.metastore.warehouse.dir</name>
  <value>/hive</value>
</property>
<property>
  <name>hive.metastore.client.socket.timeout</name>
  <value>600</value>
</property>
<property>
  <name>hive.warehouse.subdir.inherit.perms</name>
  <value>true</value>
</property> 		 	   		  "
shane knapp <sknapp@berkeley.edu>,"Fri, 13 Mar 2015 13:08:49 -0700",Re: jenkins httpd being flaky,"dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>","i tried a couple of things, but will also be doing a jenkins reboot as soon
as the current batch of builds finish.




"
shane knapp <sknapp@berkeley.edu>,"Fri, 13 Mar 2015 13:55:31 -0700",Re: jenkins httpd being flaky,"dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>","ok, things seem to have stabilized...  httpd hasn't flaked since ~noon, the
hanging PRB job on amp-jenkins-worker-06 was removed w/the restart and
things are now building.

i cancelled and retriggered a bunch of PRB builds, btw:
4848 (https://github.com/apache/spark/pull/3699)
5922 (https://github.com/apache/spark/pull/4733)
5987 (https://github.com/apache/spark/pull/4986)
6222 (https://github.com/apache/spark/pull/4964)
6325 (https://github.com/apache/spark/pull/5018)

as well as:
spark-master-maven-with-yarn

sorry for the inconvenience...  i'm still a little stumped as to what
happened, but i think it was a confluence of events (httpd flaking,
problems at github, mercury in retrograde, friday thinking it's monday).

shane


"
shane knapp <sknapp@berkeley.edu>,"Fri, 13 Mar 2015 14:22:23 -0700",Re: PR Builder timing out due to ivy cache lock,Hari Shreedharan <hshreedharan@cloudera.com>,"i'm thinking that this was something transient, and hopefully won't happen
again.  a ton of weird stuff happened around the time of this failure (see
my flaky httpd email), and this was the only build exhibiting this behavior.

i'll keep an eye out for this failure over the weekend...




"
Dale Richardson <dale__r@hotmail.com>,"Fri, 13 Mar 2015 22:52:45 +0000",RE: Spark config option 'expression language' feedback request,Reynold Xin <rxin@databricks.com>,"


Hi Reynold,They are some very good questions.
Re: Known libraries
There are a number of well known libraries that we could use to implement this features, including MVEL, OGNL and JBOSS EL, or even Spring's EL.I looked at using them to prototype this feature in the beginning, but they all ended up bringing in a lot of code to service a pretty small functional requirement.The prime requirement I was trying to meet was:
1. Be able to specify quantities in kb,mb,gb etc transparently.2. Be able to specify some options as fractions of system attributes eg cpuCores * 0.8
By just implementing this functionality and nothing else I figured I was constraining things enough that end-users got useful functionality but not enough functionality to shoot themselves in the foot in new and interesting ways. I couldn't see a nice way of limiting the expressiveness of 3rd party libraries to this extent.
I'd be happy to re-look at the feasibility of pulling in one of the 3rd party libraries if you think this approach has more merit, but I do caution that we may be opening a Pandora's box of potential functionality.  Those 3rd party libraries have a lot of (potentially excess) functionality in them.
Re: Code ComplexityI wrote the bare minimum code I could come up with to service the above mentioned functionality, and then refactored it to use a stacked traits pattern which increased the code size by about a further 30%.  The expression code as it stands is pretty minimal, and has more then 120 unit tests proving its functionality. More then half the code that is there is taken up by utility classes to allow easy reference to byte quantities and time units. The design was deliberately limited to meeting the above requirements and not much more to reduce the chance for other subtleties to raise their heads. 
Re: Work arounds.It would be pretty simple to implement fall back functionality to disable expression parsing by:1. Globally having a configuration option to disable all expression parsing and fall back to simple java property parsing.2. Locally having a known prefix that disables expression parsing for that option.This should give enough workarounds to keep things running in the unlikely event that something crops up no matter what happens.
Re: Error messagesIn regards to your comment about nice error messages I would have to agree with you, it would have been nice.  In the end I just return an option[Double] to the calling code for the parsed expression if the entire string is parsed correctly. Given the additional complexity adding error messages involved I retrospectively justify this by saying how much info do you need debug an expression like 'cpuCores * 0.8'? :)
Thanks for the feedback.
Regards,Dale.
nd
e
to
om>
onment
on
tem
:
=
e

 		 	   		  "
Dale Richardson <dale__r@hotmail.com>,"Fri, 13 Mar 2015 23:06:41 +0000",RE: Spark config option 'expression language' feedback request,Mridul Muralidharan <mridul@gmail.com>,"


Thanks for your questions Mridul.
I assume you are referring to how the functionality to query system state works in Yarn and Mesos?
The API's used are the standard JVM API's so the functionality will work without change. There is no real use case for using 'physicalMemoryBytes' in these cases though, as the JVM size has already been limited by the resource manager.
Regards,Dale.
ote:
onment
on
tem
:
=
e

 		 	   		  "
Mridul Muralidharan <mridul@gmail.com>,"Fri, 13 Mar 2015 17:30:51 -0700",Re: Spark config option 'expression language' feedback request,Dale Richardson <dale__r@hotmail.com>,"Let me try to rephrase my query.
How can a user specify, for example, what the executor memory should
be or number of cores should be.

I dont want a situation where some variables can be specified using
one set of idioms (from this PR for example) and another set cannot
be.


Regards,
Mridul





---------------------------------------------------------------------


"
Dale Richardson <dale__r@hotmail.com>,"Sat, 14 Mar 2015 02:57:33 +0000",RE: Spark config option 'expression language' feedback request,Mridul Muralidharan <mridul@gmail.com>,"Mridul,I may have added some confusion by giving examples in completely different areas. For example the number of cores available for tasking on each worker machine is a resource-controller level configuration variable. In standalone mode (ie using Spark's home-grown resource manager) the configuration variable SPARK_WORKER_CORES is an item that spark admins can set (and we can use expressions for). The equivalent variable for YARN (Yarn.nodemanager.resource.cpu-vcores) is only used by Yarn's node manager setup and is set by Yarn administrators and outside of control of spark (and most users).  If you are not a cluster administrator then both variables are irrelevant to you. The same goes for SPARK_WORKER_MEMORY.

As for spark.executor.memory,  As there is no way to know the attributes of a machine before a task is allocated to it, we cannot use any of the JVMInfo functions. For options like that the expression parser can easily be limited to supporting different byte units of scale (kb/mb/gb etc) and other configuration variables only.  
Regards,Dale.




te works in Yarn and Mesos?
k without change. There is no real use case for using 'physicalMemoryBytes' in these cases though, as the JVM size has already been limited by the resource manager.
t
not
vironment
ssion
r
system
 eg:
==
 the
 on
 		 	   		  "
Yu Ishikawa <yuu.ishikawa+spark@gmail.com>,"Sun, 15 Mar 2015 00:45:22 -0700 (MST)","[mllib] Is there any bugs to divide a Breeze sparse vectors at
 Spark v1.3.0-rc3?",dev@spark.apache.org,"Hi all,

Is there any bugs to divide a Breeze sparse vector at Spark v1.3.0-rc3? When
I tried to divide a sparse vector at Spark v1.3.0-rc3, I got a wrong result
if the target vector has any zero values.

Spark v1.3.0-rc3 depends on Breeze v0.11.1. And Breeze v0.11.1 seems to have
any bugs to divide a sparse vector by a scalar value. When dividing a breeze
sparse vector which has any zero values, the result seems to be a zero
vector. However, we can run the same code on Spark v1.2.x.

However, there is no problem to multiply a breeze sparse vector. I asked the
breeze community this problem on the below issue.
https://github.com/scalanlp/breeze/issues/382

For example,
```
test(""dividing a breeze spark vector"") {
    val vec = Vectors.sparse(6, Array(0, 4), Array(0.0, 10.0)).toBreeze
    val n = 60.0
    val answer1 = vec :/ n
    val answer2 = vec.toDenseVector :/ n
    println(vec)
    println(answer1)
    println(answer2)
    assert(answer1.toDenseVector === answer2)
}

SparseVector((0,0.0), (4,10.0))
SparseVector()
DenseVector(0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0)

DenseVector(0.0, 0.0, 0.0, 0.0, 0.0, 0.0) did not equal DenseVector(0.0,
0.0, 0.0, 0.0, 0.16666666666666666, 0.0)
org.scalatest.exceptions.TestFailedException: DenseVector(0.0, 0.0, 0.0,
0.0, 0.0, 0.0) did not equal DenseVector(0.0, 0.0, 0.0, 0.0,
0.16666666666666666, 0.0)
```

Thanks,
Yu Ishikawa



-----
-- Yu Ishikawa
--

---------------------------------------------------------------------


"
DB Tsai <dbtsai@dbtsai.com>,"Sun, 15 Mar 2015 00:57:27 -0700","Re: [mllib] Is there any bugs to divide a Breeze sparse vectors at
 Spark v1.3.0-rc3?",Yu Ishikawa <yuu.ishikawa+spark@gmail.com>,"maven, we can upgrade to breeze 0.11.2. Please file a jira ticket for
this issue. thanks.

Sincerely,

DB Tsai
-------------------------------------------------------
Blog: https://www.dbtsai.com



---------------------------------------------------------------------


"
Yu Ishikawa <yuu.ishikawa+spark@gmail.com>,"Sun, 15 Mar 2015 01:14:47 -0700 (MST)","Re: [mllib] Is there any bugs to divide a Breeze sparse vectors at
 Spark v1.3.0-rc3?",dev@spark.apache.org,"David Hall who is a breeze creator told me that it's a bug. So, I made a jira
ticket about this issue. We need to upgrade breeze from 0.11.1 to 0.11.2 or
later in order to fix the bug, when the new version of breeze will be
released.

[SPARK-6341] Upgrade breeze from 0.11.1 to 0.11.2 or later - ASF JIRA
https://issues.apache.org/jira/browse/SPARK-6341

Thanks,
Yu Ishikawa



-----
-- Yu Ishikawa
--

---------------------------------------------------------------------


"
Cheng Lian <lian.cs.zju@gmail.com>,"Sun, 15 Mar 2015 21:03:34 +0800","Re: Spark ThriftServer encounter java.lang.IllegalArgumentException:
 Unknown auth type: null Allowed values are: [auth-int, auth-conf, auth]","Andrew Lee <alee526@hotmail.com>, 
 ""dev@spark.apache.org"" <dev@spark.apache.org>","Hey Andrew,

Would you please create a JIRA ticket for this? To preserve 
compatibility with existing Hive JDBC/ODBC drivers, Spark SQL's 
HiveThriftServer intercepts some HiveServer2 components and injects 
Spark stuff into it. This makes the implementation details are somewhat 
hacky (e.g. a bunch of reflection tricks were used). We haven't include 
KRB tests in Spark unit/integration test suites, and it's possible that 
HiveThriftServer2 somehow breaks Hive's KRB feature.

Cheng



---------------------------------------------------------------------


"
Cheng Lian <lian.cs.zju@gmail.com>,"Mon, 16 Mar 2015 01:40:07 +0800",Wrong version on the Spark documentation page,"""dev@spark.apache.org"" <dev@spark.apache.org>","It's still marked as 1.2.1 here http://spark.apache.org/docs/latest/

But this page is updated (1.3.0) 
http://spark.apache.org/docs/latest/index.html

Cheng

---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Sun, 15 Mar 2015 11:12:50 -0700",Re: Wrong version on the Spark documentation page,Cheng Lian <lian.cs.zju@gmail.com>,"Cheng - what if you hold shift+refresh? For me the /latest link
correctly points to 1.3.0


---------------------------------------------------------------------


"
Ted Yu <yuzhihong@gmail.com>,"Sun, 15 Mar 2015 11:31:45 -0700",Re: Wrong version on the Spark documentation page,Patrick Wendell <pwendell@gmail.com>,"When I enter  http://spark.apache.org/docs/latest/ into Chrome address bar,
I saw 1.3.0

Cheers


"
Pei-Lun Lee <pllee@appier.com>,"Mon, 16 Mar 2015 11:01:54 +0800",Re: SparkSQL 1.3.0 (RC3) failed to read parquet file generated by 1.1.1,Michael Armbrust <michael@databricks.com>,"Thanks!


"
lonely Feb <lonely8658@gmail.com>,"Mon, 16 Mar 2015 11:08:14 +0800",broadcast hang out,dev@spark.apache.org,"Hi all, i meet up with a problem that torrent broadcast hang out in my
spark cluster (1.2, standalone) , particularly serious when driver and
executors are cross-region. when i read the code of broadcast i found that
a sync block read here:

  def fetchBlockSync(host: String, port: Int, execId: String, blockId:
String): ManagedBuffer = {
    // A monitor for the thread to wait on.
    val result = Promise[ManagedBuffer]()
    fetchBlocks(host, port, execId, Array(blockId),
      new BlockFetchingListener {
        override def onBlockFetchFailure(blockId: String, exception:
Throwable): Unit = {
          result.failure(exception)
        }
        override def onBlockFetchSuccess(blockId: String, data:
ManagedBuffer): Unit = {
          val ret = ByteBuffer.allocate(data.size.toInt)
          ret.put(data.nioByteBuffer())
          ret.flip()
          result.success(new NioManagedBuffer(ret))
        }
      })

    Await.result(result.future, Duration.Inf)
  }

it seems that fetchBlockSync method does not have a timeout limit but wait
forever ? Anybody can show me how to control the timeout here?
"
Chester Chen <chester@alpinenow.com>,"Sun, 15 Mar 2015 20:27:17 -0700",Re: broadcast hang out,lonely Feb <lonely8658@gmail.com>,"can you just replace ""Duration.Inf"" with a shorter duration  ? how about

      import scala.concurrent.duration._
      val timeout = new Timeout(10 seconds)
      Await.result(result.future, timeout.duration)

      or

      val timeout = new FiniteDuration(10, TimeUnit.SECONDS)
      Await.result(result.future, timeout)

      or simply
      import scala.concurrent.duration._
      Await.result(result.future, 10 seconds)




"
lonely Feb <lonely8658@gmail.com>,"Mon, 16 Mar 2015 11:31:38 +0800",Re: broadcast hang out,Chester Chen <chester@alpinenow.com>,"Thx. But this method is in BlockTransferService.scala of spark which i can
not replace unless i rewrite the core code. I wonder if it is handled
somewhere already.

2015-03-16 11:27 GMT+08:00 Chester Chen <chester@alpinenow.com>:

"
Mridul Muralidharan <mridul@gmail.com>,"Sun, 15 Mar 2015 20:43:04 -0700",Re: broadcast hang out,lonely Feb <lonely8658@gmail.com>,"Cross region as in different data centers ?

- Mridul


---------------------------------------------------------------------


"
lonely Feb <lonely8658@gmail.com>,"Mon, 16 Mar 2015 11:45:07 +0800",Re: broadcast hang out,Mridul Muralidharan <mridul@gmail.com>,"yes

2015-03-16 11:43 GMT+08:00 Mridul Muralidharan <mridul@gmail.com>:

"
David Hall <david.lw.hall@gmail.com>,"Sun, 15 Mar 2015 21:38:32 -0700","Re: [mllib] Is there any bugs to divide a Breeze sparse vectors at
 Spark v1.3.0-rc3?",Yu Ishikawa <yuu.ishikawa+spark@gmail.com>,"snapshot is pushed. If you verify I'll publish the new artifacts.


"
lonely Feb <lonely8658@gmail.com>,"Mon, 16 Mar 2015 13:41:05 +0800",Re: broadcast hang out,Mridul Muralidharan <mridul@gmail.com>,"Anyone can help? Thanks a lot !

2015-03-16 11:45 GMT+08:00 lonely Feb <lonely8658@gmail.com>:

"
Pei-Lun Lee <pllee@appier.com>,"Mon, 16 Mar 2015 16:03:41 +0800",SparkSQL 1.3.0 cannot read parquet files from different file system,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

I am using Spark 1.3.0, where I cannot load parquet files from more than
one file system, say one s3n://... and another hdfs://..., which worked in
older version, or if I set spark.sql.parquet.useDataSourceApi=false in 1.3.

configuration in ParquetRelation2, call Path.getFileSystem for each path.

Here's the JIRA link and pull request:
https://issues.apache.org/jira/browse/SPARK-6351
https://github.com/apache/spark/pull/5039

Thanks,
--
Pei-Lun
"
Pei-Lun Lee <pllee@appier.com>,"Mon, 16 Mar 2015 17:23:17 +0800",Re: Which OutputCommitter to use for S3?,"""user@spark.apache.org"" <user@spark.apache.org>, ""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

I created a JIRA and PR for supporting a s3 friendly output committer for
saveAsParquetFile:
https://issues.apache.org/jira/browse/SPARK-6352
https://github.com/apache/spark/pull/5042

My approach is add a DirectParquetOutputCommitter class in spark-sql
package and use a boolean config variable
spark.sql.parquet.useDirectParquetOutputCommitter to choose between default
output committer.
This may not be the smartest solution but it works for me.
Tested on spark 1.1, 1.3 with hadoop 1.0.4.



s
d.
m
 with
d
er.
7)
ons
.sc
.sc
a:7
aron
Z4tFb6o
ZRf6sFs
&e=
e
ix
or
 anyone
a
ent
mz8&r=e
Ovl_-
&e=
le
-
"
Cheng Lian <lian.cs.zju@gmail.com>,"Mon, 16 Mar 2015 18:39:31 +0800","Re: SparkSQL 1.3.0 cannot read parquet files from different file
 system","Pei-Lun Lee <pllee@appier.com>, 
 ""dev@spark.apache.org"" <dev@spark.apache.org>","Hi Pei-Lun,

We intentionally disallowed passing multiple comma separated paths in 
path contain an actual comma in it. In your case, you may do something 
like this:

|val  s3nDF  =  parquetFile(""s3n://..."")
val  hdfsDF  =  parquetFile(""hdfs://..."")
val  finalDF  =  s3nDF.union(finalDF)
|

Cheng


​
"
Cheng Lian <lian.cs.zju@gmail.com>,"Mon, 16 Mar 2015 18:43:23 +0800","Re: SparkSQL 1.3.0 cannot read parquet files from different file
 system","Pei-Lun Lee <pllee@appier.com>, 
 ""dev@spark.apache.org"" <dev@spark.apache.org>","Oh sorry, I misread your question. I thought you were trying something 
like |parquetFile(“s3n://file1,hdfs://file2”)|. Yeah, it’s a valid bug. 
Thanks for opening the JIRA ticket and the PR!


Cheng



​
​

​
"
Cheng Lian <lian.cs.zju@gmail.com>,"Mon, 16 Mar 2015 20:06:07 +0800",Re: Wrong version on the Spark documentation page,"Ted Yu <yuzhihong@gmail.com>, Patrick Wendell <pwendell@gmail.com>","Patrick, Ted - My bad, yeah, it's because of browser cache.


"
Gil Vernik <GILV@il.ibm.com>,"Mon, 16 Mar 2015 14:09:44 +0200",problems with Parquet in Spark 1.3.0,dev <dev@spark.apache.org>,"Hi,

I am storing Parquet files in the OpenStack Swift and access those files 
from Spark.

This works perfectly in Spark prior 1.3.0, but in 1.3.0 I  am getting this 
error:
Is there some configuration i missed? I am not sure where this error get 
from, does Spark 1.3.0 requires Parquet files to be accessed via ""file://"" 
?
I will be glad to dig into this in case it's a bug, but would like to know 
if this is something intentionally in Spark 1.3.0
( I do can access swift:// names pace from SparkContext, only sqlContext 
has this issue )

Thanks,
Gil Vernik.

scala> val parquetFile = 
sqlContext.parquetFile(""swift://ptest.localSwift12/SF311new3.parquet"")

java.lang.IllegalArgumentException: Wrong FS: 
swift://ptest.localSwift12/SF311new3.parquet, expected: file:///
        at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645)
        at 
org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:465)
        at 
org.apache.hadoop.fs.FilterFileSystem.makeQualified(FilterFileSystem.java:119)
        at 
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.apply(newParquet.scala:252)
        at 
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.apply(newParquet.scala:251)
        at 
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at 
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at 
scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
        at 
scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
        at 
scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at 
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache.refresh(newParquet.scala:251)
        at 
org.apache.spark.sql.parquet.ParquetRelation2.<init>(newParquet.scala:370)
        at 
org.apache.spark.sql.SQLContext.parquetFile(SQLContext.scala:522)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:19)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:24)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
        at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:28)
        at $iwC$$iwC$$iwC$$iwC.<init>(<console>:30)
        at $iwC$$iwC$$iwC.<init>(<console>:32)
        at $iwC$$iwC.<init>(<console>:34)
        at $iwC.<init>(<console>:36)
        at <init>(<console>:38)
        at .<init>(<console>:42)
        at .<clinit>(<console>)
        at .<init>(<console>:7)
        at .<clinit>(<console>)
        at $print(<console>)"
Gil Vernik <GILV@il.ibm.com>,"Mon, 16 Mar 2015 14:33:09 +0200",Re: problems with Parquet in Spark 1.3.0,Gil Vernik <GILV@il.ibm.com>,"I just noticed about this one

https://issues.apache.org/jira/browse/SPARK-6351
https://github.com/apache/spark/pull/5039


I verified it and this resolves my issues with Parquet and swift:// name 
space.





From:   Gil Vernik/Haifa/IBM@IBMIL
To:     dev <dev@spark.apache.org>
Date:   16/03/2015 02:11 PM
Subject:        problems with Parquet in Spark 1.3.0



Hi,

I am storing Parquet files in the OpenStack Swift and access those files 
from Spark.

This works perfectly in Spark prior 1.3.0, but in 1.3.0 I  am getting this 

error:
Is there some configuration i missed? I am not sure where this error get 
from, does Spark 1.3.0 requires Parquet files to be accessed via ""file://"" 

?
I will be glad to dig into this in case it's a bug, but would like to know 

if this is something intentionally in Spark 1.3.0
( I do can access swift:// names pace from SparkContext, only sqlContext 
has this issue )

Thanks,
Gil Vernik.

scala> val parquetFile = 
sqlContext.parquetFile(""swift://ptest.localSwift12/SF311new3.parquet"")

java.lang.IllegalArgumentException: Wrong FS: 
swift://ptest.localSwift12/SF311new3.parquet, expected: file:///
        at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:645)
        at 
org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:465)
        at 
org.apache.hadoop.fs.FilterFileSystem.makeQualified(FilterFileSystem.java:119)
        at 
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.apply(newParquet.scala:252)
        at 
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.apply(newParquet.scala:251)
        at 
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at 
scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at 
scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
        at 
scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
        at 
scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at 
org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache.refresh(newParquet.scala:251)
        at 
org.apache.spark.sql.parquet.ParquetRelation2.<init>(newParquet.scala:370)
        at 
org.apache.spark.sql.SQLContext.parquetFile(SQLContext.scala:522)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:19)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:24)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:26)
        at $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:28)
        at $iwC$$iwC$$iwC$$iwC.<init>(<console>:30)
        at $iwC$$iwC$$iwC.<init>(<console>:32)
        at $iwC$$iwC.<init>(<console>:34)
        at $iwC.<init>(<console>:36)
        at <init>(<console>:38)
        at .<init>(<console>:42)
        at .<clinit>(<console>)
        at .<init>(<console>:7)
        at .<clinit>(<console>)
        at $print(<console>)
"
"""Joe Halliwell"" <joe.halliwell@gmail.com>","Mon, 16 Mar 2015 06:18:29 -0700 (PDT)",Typo in 1.3.0 release notes: s/extended renamed/renamed/,dev@spark.apache.org,"Cheers,
Joe

Best regards, Joe"
Sean Owen <sowen@cloudera.com>,"Mon, 16 Mar 2015 13:21:49 +0000",Re: Typo in 1.3.0 release notes: s/extended renamed/renamed/,Joe Halliwell <joe.halliwell@gmail.com>,"Here's the sentence:

As part of stabilizing the Spark SQL API, the SchemaRDD class has been
extended renamed to DataFrame.

Yes, I can remove the word 'extended'



---------------------------------------------------------------------


"
shane knapp <sknapp@berkeley.edu>,"Mon, 16 Mar 2015 07:51:45 -0700","Re: extended jenkins downtime monday, march 16th, plus some hints at
 the future","dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>","this is starting now.


"
shane knapp <sknapp@berkeley.edu>,"Mon, 16 Mar 2015 09:06:12 -0700","Re: extended jenkins downtime monday, march 16th, plus some hints at
 the future","dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>","looks like we're having some issues w/the pull request builder and cron
stacktraces in the logs.  i'll be investigating further and will update
when i figure out what's going on.


"
shane knapp <sknapp@berkeley.edu>,"Mon, 16 Mar 2015 09:42:33 -0700","Re: extended jenkins downtime monday, march 16th, plus some hints at
 the future","dev <dev@spark.apache.org>, amp-infra <amp-infra@googlegroups.com>","ok, we're back up and building.  upgrading the github plugin (and possibly
EnvInject) caused the stacktraces, so i've kept those at the old versions
that were working before.  jenkins and the rest of the plugins are updated
and we're g2g.

i'll be, of course, keeping an eye on things today and will squash anything
else that pops up.


"
Xiangrui Meng <mengxr@gmail.com>,"Mon, 16 Mar 2015 11:38:03 -0700",Re: enum-like types in Spark,RJ Nowling <rnowling@gmail.com>,"In MLlib, we use strings for emu-like types in Python APIs, which is
implement `fromString` to convert them back to enums. -Xiangrui


---------------------------------------------------------------------


"
Kevin Markey <kevin.markey@oracle.com>,"Mon, 16 Mar 2015 13:12:26 -0600",Re: enum-like types in Spark,dev@spark.apache.org,"In some applications, I have rather heavy use of Java enums which are 
needed for related Java APIs that the application uses.  And 
unfortunately, they are also used as keys.  As such, using the native 
hashcodes makes any function over keys unstable and unpredictable, so we 
now use Enum.name() as the key instead.  Oh well.  But it works and 
seems to work well.

Kevin



---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Mon, 16 Mar 2015 13:54:39 -0700",Re: enum-like types in Spark,Kevin Markey <kevin.markey@oracle.com>,"Hey Xiangrui,

Do you want to write up a straw man proposal based on this line of discussion?

- Patrick


---------------------------------------------------------------------


"
Aaron Davidson <ilikerps@gmail.com>,"Mon, 16 Mar 2015 15:04:40 -0700",Re: enum-like types in Spark,Kevin Markey <kevin.markey@oracle.com>,"It's unrelated to the proposal, but Enum#ordinal() should be much faster,
assuming it's not serialized to JVMs with different versions of the enum :)


"
Reynold Xin <rxin@databricks.com>,"Mon, 16 Mar 2015 19:45:52 -0700",Re: broadcast hang out,lonely Feb <lonely8658@gmail.com>,"It would be great to add a timeout. Do you mind submitting a pull request?



"
Pei-Lun Lee <pllee@appier.com>,"Tue, 17 Mar 2015 10:50:07 +0800",Re: SparkSQL 1.3.0 cannot read parquet files from different file system,Cheng Lian <lian.cs.zju@gmail.com>,"Looks like this is already solved in
https://issues.apache.org/jira/browse/SPARK-6330


s a valid bug.
ke
alDF)
n
1.3.
se/SPARK-6351https://github.com/apache/spark/pull/5039
"
turp1twin <turp1twin@gmail.com>,"Mon, 16 Mar 2015 19:56:50 -0700 (MST)",Re: Block Transfer Service encryption support,dev@spark.apache.org,"Hey Patrick,

Sorry for the delay, I was at Elastic{ON} last week and well, my day job has
been keeping me busy... I went ahead and opened a Jira feature request,
https://issues.apache.org/jira/browse/SPARK-6373. In it I reference a commit
I made in my fork which is a ""rough"" implementation, definitely still a WIP.
Would like to iterate the design if possible, as there are some performance
trade offs for using SSL for sure.. Zero copy will not be possible with SSL,
so there will definitely be a hit there.. That being said, for my use case,
which is health care related and involves processing personal health
information, I have no choice, as all data must be encrypted in transit and
at rest... Cheers!

Jeff

https://github.com/turp1twin/spark/commit/024b559f27945eb63068d1badf7f82e4e7c3621c




--

---------------------------------------------------------------------


"
Aaron Davidson <ilikerps@gmail.com>,"Mon, 16 Mar 2015 20:27:03 -0700",Re: Block Transfer Service encryption support,turp1twin <turp1twin@gmail.com>,"Out of curiosity, why could we not use Netty's SslHandler injected into the
TransportContext pipeline?


"
turp1twin <turp1twin@gmail.com>,"Mon, 16 Mar 2015 20:37:29 -0700 (MST)",Re: Block Transfer Service encryption support,dev@spark.apache.org,"Hey Aaron,

That is what I do, except I add the Netty SslHandler in the TransportServer
and the TransportClientFactory.... I do this because the Server pipeline is
a bit different as I have to add a Netty ChunkedWriteHandler... Again, this
is a ""rough"" prototype, just to get something working... Cheers!

Jeff




--

---------------------------------------------------------------------


"
Kay Ousterhout <keo@eecs.berkeley.edu>,"Tue, 17 Mar 2015 10:52:43 -0700",Re: Profiling Spark: MemoryStore,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Hi Alexander,

The stack trace is a little misleading here: all of the time is spent in
MemoryStore, but that's because MemoryStore is unrolling an iterator (note
the iterator.next()) call so that it can be stored in-memory.  Essentially
all of the computation for the tasks happens as part of that
iterator.next() call, which is why you're seeing a combination of
deserializing input data with Snappy (the InputStream reading) and some
MLLib processing.

-Kay


"
David Hall <david.lw.hall@gmail.com>,"Tue, 17 Mar 2015 11:56:52 -0700","Re: [mllib] Is there any bugs to divide a Breeze sparse vectors at
 Spark v1.3.0-rc3?",Yu Ishikawa <yuu.ishikawa+spark@gmail.com>,"ping?


"
Xiangrui Meng <mengxr@gmail.com>,"Tue, 17 Mar 2015 12:07:12 -0700",Re: enum-like types in Spark,Aaron Davidson <ilikerps@gmail.com>,"Let me put a quick summary. #4 got majority vote with CamelCase but
not UPPERCASE. The following is a minimal implementation that works
for both Scala and Java. In Python, we use string for enums. This
proposal is only for new public APIs. We are not going to change
existing ones. -Xiangrui

~~~
sealed abstract class StorageLevel

object StorageLevel {

  def fromString(name: String): StorageLevel = ???

  }

 }
}
~~~


---------------------------------------------------------------------


"
"""Kelly, Jonathan"" <jonathak@amazon.com>","Wed, 18 Mar 2015 00:15:16 +0000",Using Spark with a SOCKS proxy,"""user@spark.apache.org"" <user@spark.apache.org>,
        ""dev@spark.apache.org""
	<dev@spark.apache.org>","I'm trying to figure out how I might be able to use Spark with a SOCKS proxy.  That is, my dream is to be able to write code in my IDE then run it without much trouble on a remote cluster, accessible only via a SOCKS proxy between the local development machine and the master node of the cluster (ignoring, for now, any dependencies that would need to be transferred--assume it's a very simple app with no dependencies that aren't part of the Spark classpath on the cluster).  This is possible with Hadoop by setting hadoop.rpc.socket.factory.class.default to org.apache.hadoop.net.SocksSocketFactory and hadoop.socks.server to localhost:<port on which a SOCKS proxy has been opened via ""ssh -D"" to the master node>.  However, I can't seem to find anything like this for Spark, and I only see very few mentions of it on the user list and on stackoverflow, with no real answers.  (See links below.)

I thought I might be able to use the JVM's -DsocksProxyHost and -DsocksProxyPort system properties, but it still does not seem to work.  That is, if I start a SOCKS proxy to my master node using something like ""ssh -D 2600 <master node public name>"" then run a simple Spark app that calls SparkConf.setMaster(""spark://<master node private IP>:7077""), passing in JVM args of ""-DsocksProxyHost=locahost -DsocksProxyPort=2600"", the driver hangs for a while before finally giving up (""Application has been killed. Reason: All masters are unresponsive! Giving up."").  It seems like it is not even attempting to use the SOCKS proxy.  Do -DsocksProxyHost/-DsocksProxyPort not even work for Spark?

http://stackoverflow.com/questions/28047000/connect-to-spark-through-a-socks-proxy (unanswered similar question from somebody else about a month ago)
https://issues.apache.org/jira/browse/SPARK-5004 (unresolved, somewhat related JIRA from a few months ago)

Thanks,
Jonathan
"
"""=?utf-8?B?U2Vh?="" <261810726@qq.com>","Wed, 18 Mar 2015 10:07:05 +0800",InvalidAuxServiceException in dynamicAllocation,"""=?utf-8?B?ZGV2?="" <dev@spark.apache.org>, ""=?utf-8?B?dXNlcg==?="" <user@spark.apache.org>","Hi, all:


Spark1.3.0 hadoop2.2.0


I put the following params in the spark-defaults.conf 


spark.dynamicAllocation.enabled true
spark.dynamicAllocation.minExecutors 20
spark.dynamicAllocation.maxExecutors 300
spark.dynamicAllocation.executorIdleTimeout 300
spark.shuffle.service.enabled true‍



I started the thriftserver and do a query. Exception happened!
I find it in JIRA https://issues.apache.org/jira/browse/SPARK-5759‍ 
It says fixed version 1.3.0


Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuot exist 	at sun.reflect.GeneratedConstructorAccessor28.newInstance(Unknown Source) 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) 	at java.lang.reflect.Constructor.newInstance(Constructor.java:513) 	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:152) 	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106) 	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:203) 	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:113) 	... 4 more‍"
"""=?utf-8?B?U2Vh?="" <261810726@qq.com>","Wed, 18 Mar 2015 10:15:18 +0800",InvalidAuxServiceException in dynamicAllocation,"""=?utf-8?B?ZGV2QHNwYXJrLmFwYWNoZS5vcmc=?="" <dev@spark.apache.org>, ""=?utf-8?B?dXNlckBzcGFyay5hcGFjaGUub3Jn?="" <user@spark.apache.org>","Hi, all:


Spark1.3.0 hadoop2.2.0


I put the following params in the spark-defaults.conf 


spark.dynamicAllocation.enabled true
spark.dynamicAllocation.minExecutors 20
spark.dynamicAllocation.maxExecutors 300
spark.dynamicAllocation.executorIdleTimeout 300
spark.shuffle.service.enabled true‍



I started the thriftserver and do a query. Exception happened!
I find it in JIRA https://issues.apache.org/jira/browse/SPARK-5759‍ 
It says fixed version 1.3.0


Caused by: org.apache.hadoop.yarn.exceptions.InvalidAuot exist 	at sun.reflect.GeneratedConstructorAccessor28.newInstance(Unknown Source) 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) 	at java.lang.reflect.Constructor.newInstance(Constructor.java:513) 	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException(SerializedExceptionPBImpl.java:152) 	at org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.deSerialize(SerializedExceptionPBImpl.java:106) 	at org.apache.hadoop.yarn.client.api.impl.NMClientImpl.startContainer(NMClientImpl.java:203) 	at org.apache.spark.deploy.yarn.ExecutorRunnable.startContainer(ExecutorRunnable.scala:113) 	... 4 more‍"
Reynold Xin <rxin@databricks.com>,"Tue, 17 Mar 2015 23:34:23 -0400",Re: Spilling when not expected,Tom Hubregtsen <thubregtsen@gmail.com>,"Tom - sorry for the delay. If you try OpenJDK (on a smaller heap), do you
see the same problem? Would be great to isolate whether the problem is
related to J9 or not. In either case we should fix it though.


"
Niranda Perera <niranda.perera@gmail.com>,"Wed, 18 Mar 2015 11:10:21 +0530",Fixed worker ports in the spark worker,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi all,

I see that spark server opens up random ports, especially in the workers.

is there any way to fix these ports or give an set of ports for the worker
to choose from?

cheers

-- 
Niranda
"
Debasish Das <debasish.das83@gmail.com>,"Wed, 18 Mar 2015 00:19:35 -0700","Re: [mllib] Is there any bugs to divide a Breeze sparse vectors at
 Spark v1.3.0-rc3?",David Hall <david.lw.hall@gmail.com>,"Hi David,

We are stress testing breeze.optimize.proximal and nnls...if you are
cutting a release now, we will need another release soon once we get the
runtime optimizations in place and merged to breeze.

Thanks.
Deb

"
Arush Kharbanda <arush@sigmoidanalytics.com>,"Wed, 18 Mar 2015 13:30:40 +0530",Re: Fixed worker ports in the spark worker,Niranda Perera <niranda.perera@gmail.com>,"You can fix the ports in the configuration -

http://spark.apache.org/docs/1.2.0/configuration.html#networking





-- 

[image: Sigmoid Analytics] <http://htmlsig.com/www.sigmoidanalytics.com>

*Arush Kharbanda* || Technical Teamlead

arush@sigmoidanalytics.com || www.sigmoidanalytics.com
"
David Hall <david.lw.hall@gmail.com>,"Wed, 18 Mar 2015 01:04:40 -0700","Re: [mllib] Is there any bugs to divide a Breeze sparse vectors at
 Spark v1.3.0-rc3?",Debasish Das <debasish.das83@gmail.com>,"sure.


"
Niranda Perera <niranda.perera@gmail.com>,"Wed, 18 Mar 2015 13:35:07 +0530",Re: Fixed worker ports in the spark worker,Arush Kharbanda <arush@sigmoidanalytics.com>,"Thanks Arush.

this is governed by the conf/spark-defaults.conf config, is it?





-- 
Niranda
"
Arush Kharbanda <arush@sigmoidanalytics.com>,"Wed, 18 Mar 2015 13:53:13 +0530",Re: Fixed worker ports in the spark worker,Niranda Perera <niranda.perera@gmail.com>,"Yes





-- 

[image: Sigmoid Analytics] <http://htmlsig.com/www.sigmoidanalytics.com>

*Arush Kharbanda* || Technical Teamlead

arush@sigmoidanalytics.com || www.sigmoidanalytics.com
"
Akhil Das <akhil@sigmoidanalytics.com>,"Wed, 18 Mar 2015 16:17:59 +0530",Re: Using Spark with a SOCKS proxy,"""Kelly, Jonathan"" <jonathak@amazon.com>","Did you try ssh tunneling instead of SOCKS?

Thanks
Best Regards


"
Yu Ishikawa <yuu.ishikawa+spark@gmail.com>,"Wed, 18 Mar 2015 05:15:15 -0700 (MST)","Re: [mllib] Is there any bugs to divide a Breeze sparse vectors at
 Spark v1.3.0-rc3?",dev@spark.apache.org,"Sorry for the delay in replying. I moved from Tokyo to New York in order to
attend Spark Summit East.
I verified the snapshot and the difference.
https://github.com/scalanlp/breeze/commit/f61d2f61137807651fc860404a244640e213f6d3

Thank you for your great work!
Yu Ishikawa



-----
-- Yu Ishikawa
--

---------------------------------------------------------------------


"
Gil Vernik <GILV@il.ibm.com>,"Wed, 18 Mar 2015 15:46:21 +0200",parquet support  - some questions about code,dev <dev@spark.apache.org>,"Hi,

I am trying to better understand the code for  Parquet support.
In particular i got lost trying to understand ParquetRelation and 
ParquetRelation2. Does ParquetRelation2 is the new code that should 
completely remove ParquetRelation? ( I think there is some remark in the 
code notifying this )

Assuming i am using 
spark.sql.parquet.filterPushdown = true
spark.sql.parquet.useDataSourceApi = true

I saw that method buildScan from newParquet.scala has filtering push down 
into Parquet, but i also saw that there is filtering and projection push 
down from ParquetOperations inside SparkStrategies.scala
However every time i debug it, the 
 object ParquetOperations extends Strategy {
    def apply(plan: LogicalPlan): Seq[SparkPlan] = plan match {
..........
Never evaluated to  case PhysicalOperation(projectList, filters: 
Seq[Expression], relation: ParquetRelation) =>

In which cases it will match this case?

Also, where is the code for Parquet projection and filter push down, is it 
inside ParquetOperations in SparkStrategies.scala or inside buildScan of 
newParquet.scala? Or both? If so i am not sure how it works...

Thanks,
Gil.
"
Cheng Lian <lian.cs.zju@gmail.com>,"Wed, 18 Mar 2015 22:05:43 +0800",Re: parquet support  - some questions about code,"Gil Vernik <GILV@il.ibm.com>, dev <dev@spark.apache.org>","Hey Gil,

ParquetRelation2 is based on the external data sources API, which is a 
more modular and non-intrusive way to add external data sources to Spark 
SQL. We are planning to replace ParquetRelation with ParquetRelation2 
entirely after the latter is more mature and stable. That's why you see 
two separate sets of Parquet code in the code base, and currently they 
also share part of the code.

In Spark 1.3, the new Parquet data source (ParquetRelation2) is enabled 
by default. So you can find entries of projection and filter push-down 
code in newParquet.scala.

Cheng



---------------------------------------------------------------------


"
turp1twin <turp1twin@gmail.com>,"Wed, 18 Mar 2015 12:15:18 -0700 (MST)",Re: Block Transfer Service encryption support,dev@spark.apache.org,"Still looking for feedback... I opened the ticket as a minor, thinking of
changing it to a major? Anyone object. I did see that a related ticket
(https://issues.apache.org/jira/browse/SPARK-6229) is marked as a major...
Cheers!

Jeff




--

---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Thu, 19 Mar 2015 03:09:17 +0000",Which linear algebra interface to use within Spark MLlib?,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

Currently I am using Breeze within Spark MLlib for linear algebra. I would like to reuse previously allocated matrices for storing the result of matrices multiplication, i.e. I need to use ""gemm"" function C:=q*A*B+p*C, which is missing in Breeze (Breeze automatically allocates a new matrix to store the result of multiplication). Also, I would like to minimize gemm calls that Breeze does. Should I use mllib.linalg.BLAS functions instead? While it has gemm and axpy, it has rather limited number of operations. For example, I need sum of the matrix by row or by columns, or applying a function to all elements in a matrix. Also, MLlib Vector and Matrix interfaces that linalg.BLAS operates seems to be rather undeveloped. Should I use plain netlib-java instead (will it remain in MLlib in future releases)?

Best regards, Alexander
"
Pei-Lun Lee <pllee@appier.com>,"Thu, 19 Mar 2015 12:20:59 +0800",SparkSQL 1.3.0 JDBC data source issues,"""user@spark.apache.org"" <user@spark.apache.org>, ""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

I am trying jdbc data source in spark sql 1.3.0 and found some issues.

First, the syntax ""where str_col='value'"" will give error for both
postgresql and mysql:

psql> create table foo(id int primary key,name text,age int);
bash> SPARK_CLASSPATH=postgresql-9.4-1201-jdbc41.jar spark/bin/spark-shell
scala>
sqlContext.load(""jdbc"",Map(""url""->""jdbc:postgresql://XXX"",""dbtable""->""foo"")).registerTempTable(""foo"")
scala> sql(""select * from foo where name='bar'"").collect
org.postgresql.util.PSQLException: ERROR: operator does not exist: text =
bar
  Hint: No operator matches the given name and argument type(s). You might
need to add explicit type casts.
  Position: 40
scala> sql(""select * from foo where name like '%foo'"").collect

bash> SPARK_CLASSPATH=mysql-connector-java-5.1.34.jar spark/bin/spark-shell
scala>
sqlContext.load(""jdbc"",Map(""url""->""jdbc:mysql://XXX"",""dbtable""->""foo"")).registerTempTable(""foo"")
scala> sql(""select * from foo where name='bar'"").collect
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column
'bar' in 'where clause'



Second, postgresql table with json data type does not work:

psql> create table foo(id int primary key, data json);
scala>
sqlContext.load(""jdbc"",Map(""url""->""jdbc:mysql://XXX"",""dbtable""->""foo"")).registerTempTable(""foo"")
java.sql.SQLException: Unsupported type 1111



Not sure these are bug in spark sql or jdbc. I can file JIRA ticket if
needed.

Thanks,
--
Pei-Lun
"
Debasish Das <debasish.das83@gmail.com>,"Wed, 18 Mar 2015 23:21:53 -0700",Re: Which linear algebra interface to use within Spark MLlib?,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","dgemm dgemv and dot come to Breeze and Spark through netlib-java....

Right now both in dot and dgemv Breeze does a extra memory allocate but we
already found the issue and we are working on adding a common trait that
will provide a sink operation (basically memory will be allocated by
user)...adding more BLAS operators in breeze will also help in general as
lot more operations are defined over there...



"
Pei-Lun Lee <pllee@appier.com>,"Thu, 19 Mar 2015 16:29:47 +0800",Re: SparkSQL 1.3.0 JDBC data source issues,"""user@spark.apache.org"" <user@spark.apache.org>, ""dev@spark.apache.org"" <dev@spark.apache.org>","JIRA and PR for first issue:
https://issues.apache.org/jira/browse/SPARK-6408
https://github.com/apache/spark/pull/5087


"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Thu, 19 Mar 2015 11:20:25 +0100","Spark scheduling, data locality",dev@spark.apache.org,"I'm trying to understand the task scheduling mechanism of Spark, and I'm
curious about where does locality preferences get evaluated? I'm trying to
determine if locality preferences are fetchable before the task get
serialized. A HintSet would be most appreciated!

Have nice day!

Zvara Zoltán



mail, hangout, skype: zoltan.zvara@gmail.com

mobile, viber: +36203129543

bank: 10918001-00000021-50480008

address: Hungary, 2475 Kápolnásnyék, Kossuth 6/a

elte: HSKSJZ (ZVZOAAI.ELTE)
"
Michael Allman <michael@videoamp.com>,"Thu, 19 Mar 2015 10:51:14 -0700",Spark SQL ExternalSorter not stopped,dev@spark.apache.org,"I've examined the experimental support for ExternalSorter in Spark SQL, and it does not appear that the external sorted is ever stopped (ExternalSorter.stop). According to the API documentation, this suggests a resource leak. Before I file a bug report in Jira, can someone familiar with the codebase confirm this is indeed a bug?

Thanks,

Michael
---------------------------------------------------------------------


"
Alberto Rodriguez <ardlema@gmail.com>,"Thu, 19 Mar 2015 20:10:18 +0100",Exception using the new createDirectStream util method,dev@spark.apache.org,"Hi all,

I am trying to make the new kafka and spark streaming integration work (direct
approach ""no receivers""
<http://spark.apache.org/docs/1.3.0/streaming-kafka-integration.html>). I
have created an unit test where I configure and start both zookeeper and
kafka.

When I try to create the InputDStream using the createDirectStream method
of the KafkaUtils class I am getting the following error:

org.apache.spark.SparkException:* Couldn't find leader offsets for Set()*
org.apache.spark.SparkException: org.apache.spark.SparkException: Couldn't
find leader offsets for Set()
at
org.apache.spark.streaming.kafka.KafkaUtils$$anonfun$createDirectStream$2.apply(KafkaUtils.scala:413)

Following is the code that tries to create the DStream:

val messages: InputDStream[(String, String)] =
KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](
        ssc, kafkaParams, topics)

Does anyone faced this problem?

Thank you in advance.

Kind regards,

Alberto
"
Ted Yu <yuzhihong@gmail.com>,"Thu, 19 Mar 2015 13:10:38 -0700",Re: Exception using the new createDirectStream util method,Alberto Rodriguez <ardlema@gmail.com>,"Looking at KafkaCluster#getLeaderOffsets():

          respMap.get(tp).foreach { por: PartitionOffsetsResponse =>
            if (por.error == ErrorMapping.NoError) {
...
            } else {
              errs.append(ErrorMapping.exceptionFor(por.error))
            }
There should be some error other than ""Couldn't find leader offsets for
Set()""

Can you check again ?

Thanks


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Thu, 19 Mar 2015 20:49:23 +0000",Re: Which linear algebra interface to use within Spark MLlib?,Debasish Das <debasish.das83@gmail.com>,"Thank you! When do you expect to have gemm in Breeze and that version of Breeze to ship with MLlib?

Also, could someone please elaborate on the linalg.BLAS and Matrix? Are they going to be developed further, should in long term all developers use them?

Best regards, Alexander

18.03.2015,  23:21, ""Debasish Das"" <debasish.das83@gmail.com<mailto:debasish.das83@gmail.com>> ():

dgemm dgemv and dot come to Breeze and Spark through netlib-java....

Right now both in dot and dgemv Breeze does a extra memory allocate but we already found the issue and we are working on adding a common trait that will provide a sink operation (basically memory will be allocated by user)...adding more BLAS operators in breeze will also help in general as lot more operations are defined over there...


Hi,

Currently I am using Breeze within Spark MLlib for linear algebra. I would like to reuse previously allocated matrices for storing the result of matrices multiplication, i.e. I need to use ""gemm"" function C:=q*A*B+p*C, which is missing in Breeze (Breeze automatically allocates a new matrix to store the result of multiplication). Also, I would like to minimize gemm calls that Breeze does. Should I use mllib.linalg.BLAS functions instead? While it has gemm and axpy, it has rather limited number of operations. For example, I need sum of the matrix by row or by columns, or applying a function to all elements in a matrix. Also, MLlib Vector and Matrix interfaces that linalg.BLAS operates seems to be rather undeveloped. Should I use plain netlib-java instead (will it remain in MLlib in future releases)?

Best regards, Alexander


---------------------------------------------------------------------


"
Cody Koeninger <cody@koeninger.org>,"Thu, 19 Mar 2015 16:13:00 -0500",Re: Exception using the new createDirectStream util method,,"What is the value of your topics variable, and does it correspond to topics
that already exist on the cluster and have messages in them?


"
Debasish Das <debasish.das83@gmail.com>,"Thu, 19 Mar 2015 14:16:01 -0700",Re: Which linear algebra interface to use within Spark MLlib?,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","I think for Breeze we are focused on dot and dgemv right now (along with
several other matrix vector style operations)...

For dgemm it is tricky since you need to do add dgemm for both DenseMatrix
and CSCMatrix...and for CSCMatrix you need to get something like
SuiteSparse which is under lgpl...so we have to think more on it..

For now can't you use dgemm directly from mllib.linalg.BLAS ? It's in
master...



e
аписал(а):
at
 of
*C,
to
?
For
uld
"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Thu, 19 Mar 2015 21:25:29 +0000",Re: Which linear algebra interface to use within Spark MLlib?,Debasish Das <debasish.das83@gmail.com>,"Thanks for quick response.

I can use linealg.BLAS.gemm, and this means that I have to use MLlib Matrix. The latter does not support some useful functionality needed for optimization. For example, creation of Matrix given matrix size, array and offset in this array. This means that I will need to create matrix in Breeze and convert it to MLlib. Also, linalg.BLAS misses some useful BLAS functions I need, that can be found in Breeze (and netlib-java). The same concerns are applicable to MLlib Vector.

Best regards, Alexander

19.03.2015,  14:16, ""Debasish Das"" <debasish.das83@gmail.com<mailto:debasish.das83@gmail.com>> ():

I think for Breeze we are focused on dot and dgemv right now (along with several other matrix vector style operations)...

For dgemm it is tricky since you need to do add dgemm for both DenseMatrix and CSCMatrix...and for CSCMatrix you need to get something like SuiteSparse which is under lgpl...so we have to think more on it..

For now can't you use dgemm directly from mllib.linalg.BLAS ? It's in master...


Thank you! When do you expect to have gemm in Breeze and that version of Breeze to ship with MLlib?

Also, could someone please elaborate on the linalg.BLAS and Matrix? Are they going to be developed further, should in long term all developers use them?

Best regards, Alexander

18.03.2015,  23:21, ""Debasish Das"" <debasish.das83@gmail.com<mailto:debasish.das83@gmail.com>> ():

dgemm dgemv and dot come to Breeze and Spark through netlib-java....

Right now both in dot and dgemv Breeze does a extra memory allocate but we already found the issue and we are working on adding a common trait that will provide a sink operation (basically memory will be allocated by user)...adding more BLAS operators in breeze will also help in general as lot more operations are defined over there...


Hi,

Currently I am using Breeze within Spark MLlib for linear algebra. I would like to reuse previously allocated matrices for storing the result of matrices multiplication, i.e. I need to use ""gemm"" function C:=q*A*B+p*C, which is missing in Breeze (Breeze automatically allocates a new matrix to store the result of multiplication). Also, I would like to minimize gemm calls that Breeze does. Should I use mllib.linalg.BLAS functions instead? While it has gemm and axpy, it has rather limited number of operations. For example, I need sum of the matrix by row or by columns, or applying a function to all elements in a matrix. Also, MLlib Vector and Matrix interfaces that linalg.BLAS operates seems to be rather undeveloped. Should I use plain netlib-java instead (will it remain in MLlib in future releases)?

Best regards, Alexander



---------------------------------------------------------------------


"
Alberto Rodriguez <ardlema@gmail.com>,"Thu, 19 Mar 2015 22:38:08 +0100",Re: Exception using the new createDirectStream util method,,"Thank you for replying,

Ted, I have been debuging and the getLeaderOffsets method is not appending
errors because the method findLeaders that is called at the first line of
getLeaderOffsets is not returning leaders.

Cody, the topics do not have any messages yet. Could this be an issue??

If you guys want to have a look at the code I've just uploaded it to my
github account: big-brother <https://github.com/ardlema/big-brother> (see
DirectKafkaWordCountTest.scala).

Thank you again!!

2015-03-19 22:13 GMT+01:00 Cody Koeninger <cody@koeninger.org>:

"
Debasish Das <debasish.das83@gmail.com>,"Thu, 19 Mar 2015 15:06:59 -0700",Re: Which linear algebra interface to use within Spark MLlib?,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Yeah it will be better if we consolidate the development on one of
them...either Breeze or mllib.BLAS...


d
аписал(а):
se
hat
s
t of
p*C,
 to
m
d?
 For
ould
"
Cody Koeninger <cody@koeninger.org>,"Thu, 19 Mar 2015 17:08:47 -0500",Re: Exception using the new createDirectStream util method,Alberto Rodriguez <ardlema@gmail.com>,"Yeah, I wouldn't be shocked if Kafka's metadata apis didn't return results
for topics that don't have any messages.  (sorry about the triple negative,
but I think you get my meaning).

Try putting a message in the topic and seeing what happens.


"
"""A.M.Chan"" <kaka_1992@163.com>","Fri, 20 Mar 2015 09:56:10 +0800 (CST)",Add Char support in SQL dataTypes,spark-dev <dev@spark.apache.org>,"case class PrimitiveData(
    charField: Char, // Can't get the char schema info
    intField: Int,
    longField: Long,
    doubleField: Double,
    floatField: Float,
    shortField: Short,
    byteField: Byte,

    booleanField: Boolean)
I can't get the schema from case class PrimitiveData.
An error occurred while I use schemaFor[PrimitiveData]
Char (of class scala.reflect.internal.Types$TypeRef$$anon$6)
scala.MatchError: Char (of class scala.reflect.internal.Types$TypeRef$$anon$6)
at org.apache.spark.sql.catalyst.ScalaReflection$class.schemaFor(ScalaReflection.scala:112)





--

kaka1992"
"""Cheng, Hao"" <hao.cheng@intel.com>","Fri, 20 Mar 2015 04:20:49 +0000",RE: Add Char support in SQL dataTypes,"A.M.Chan <kaka_1992@163.com>, spark-dev <dev@spark.apache.org>","Can you use the Varchar or String instead? Currently, Spark SQL will convert the varchar into string type internally(without max length limitation). However, ""char"" type is not supported yet.

    charField: Char, // Can't get the char schema info
    intField: Int,
    longField: Long,
    doubleField: Double,
    floatField: Float,
    shortField: Short,
    byteField: Byte,

    booleanField: Boolean)
I can't get the schema from case class PrimitiveData.
An error occurred while I use schemaFor[PrimitiveData] Char (of class scala.reflect.internal.Types$TypeRef$$anon$6)
scala.MatchError: Char (of class scala.reflect.internal.Types$TypeRef$$anon$6)
at org.apache.spark.sql.catalyst.ScalaReflection$class.schemaFor(ScalaReflection.scala:112)





--

kaka1992

---------------------------------------------------------------------


"
Alberto Rodriguez <ardlema@gmail.com>,"Fri, 20 Mar 2015 08:44:53 +0100",Re: Exception using the new createDirectStream util method,,"You were absolutely right Cody!! I have just put a message in the kafka
topic before creating the DirectStream and now is working fine!

Do you think that I should open an issue to warn that the kafka topic must
contain at least one message before the DirectStream creation?

Thank you very much! You've just made my day ;)

2015-03-19 23:08 GMT+01:00 Cody Koeninger <cody@koeninger.org>:

"
"""vikas.v.iitr@gmail.com"" <vikas.v.iitr@gmail.com>","Fri, 20 Mar 2015 13:20:18 +0530",Contributing to Spark,dev@spark.apache.org,"Hi ,

I have read and gone through most Spark tutorials and materials out there.
I have also downloaded and build the spark code base .

Can someone point me to some existing Jira where I can start contributing ?
Eventually I want to do some good contribution to mlLib .

Thanks,
Vikas
"
Tanyinyan <tanyinyan@huawei.com>,"Fri, 20 Mar 2015 08:42:22 +0000",=?utf-8?B?562U5aSNOiBDb250cmlidXRpbmcgdG8gU3Bhcms=?=,"""vikas.v.iitr@gmail.com"" <vikas.v.iitr@gmail.com>,
        ""dev@spark.apache.org""
	<dev@spark.apache.org>","Hello Vikas,

These two links maybe what you want.

jira:  https://issues.apache.org/jira/browse/SPARK/?selectel

pull request:  https://github.com/apache/spark/pulls

Regards,

Jessica


-----邮件原件-----
发件人: vikas.v.iitr@gmail.com [mailto:vikas.v.iitr@gmail.com] 
发送时间: 2015年3月20日 15:50
收件人: dev@spark.apache.org
主题: Contributing to Spark

Hi ,

I have read and gone through most Spark tutorials and materials out there.
I have also downloaded and build the spark code base .

Can someone point me to some existing Jira where I can start contributing ?
Eventually I want to do some good contribution to mlLib .

Thanks,
Vikas

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
"
Niranda Perera <niranda.perera@gmail.com>,"Fri, 20 Mar 2015 14:43:29 +0530",Connecting a worker to the master after a spark context is made,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

Please consider the following scenario.

I've started the spark master by invoking
the org.apache.spark.deploy.master.Master.startSystemAndActor method in a
java code and connected a worker to it using
the org.apache.spark.deploy.worker.Worker.startSystemAndActor method. and
then I have successfully created a java spark & SQL contexts and performed
SQL queries.

My question is, can I change this order?
Can I start the master first, then create a spark context... and later on
connect a worker to the master?

While trying out this scenario, I have successfully started the master.
Please see the screenshot here.



But when I create an spark context, it terminates automatically. is it
because the master not being connected to a worker?

cheers


-- 
Niranda
​
"
"""vikas.v.iitr@gmail.com"" <vikas.v.iitr@gmail.com>","Fri, 20 Mar 2015 14:48:29 +0530",=?UTF-8?B?UmU6IOetlOWkjTogQ29udHJpYnV0aW5nIHRvIFNwYXJr?=,Tanyinyan <tanyinyan@huawei.com>,"Jessica, thanks for links. I am aware of these but am looking for some ml
related jira issues which I can contribute as starting point.

Thanks,
Vikas

jira.jira-projects-plugin:summary-panel
gmail.com]
15:50
.
 ?
"
Cody Koeninger <cody@koeninger.org>,"Fri, 20 Mar 2015 08:56:54 -0500",Re: Exception using the new createDirectStream util method,Alberto Rodriguez <ardlema@gmail.com>,"I went ahead and created

https://issues.apache.org/jira/browse/SPARK-6434

to track this


"
Karlson <ksonspark@siberie.de>,"Fri, 20 Mar 2015 20:09:07 +0100",Storage of RDDs created via sc.parallelize,dev@spark.apache.org,"
Hi all,

where is the data stored that is passed to sc.parallelize? Or put 
differently, where is the data for the base RDD fetched from when the 
DAG is executed, if the base RDD is constructed via sc.parallelize?

I am reading a csv file via the Python csv module and am feeding the 
parsed data chunkwise to sc.parallelize, because the whole file would 
not fit into memory on the driver. Reading the file with sc.textfile 
first is not an option, as there might be linebreaks inside the csv 
fields, preventing me from parsing the file line by line.

The problem I am facing right now is that even though I am feeding only 
one chunk at a time to Spark, I will eventually run out of memory on the 
driver.

Thanks in advance!

---------------------------------------------------------------------


"
Yin Huai <yhuai@databricks.com>,"Fri, 20 Mar 2015 14:00:27 -0700",Re: Spark SQL ExternalSorter not stopped,Michael Allman <michael@videoamp.com>,"Hi Michael,

Thanks for reporting it. Yes, it is a bug. I have created
https://issues.apache.org/jira/browse/SPARK-6437 to track it.

Thanks,

Yin


"
"""Muttineni, Vinay"" <vmuttineni@ebay.com>","Fri, 20 Mar 2015 21:53:38 +0000",Minor Edit in the programming guide,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hey guys,
In the Spark 1.3.0 documentation provided here, http://spark.apache.org/docs/latest/sql-programming-guide.html ,
Under the ""Programmatically Specifying the Schema"" section , it's mentioned that SQL data types are in the following package org.apache.spark.sql, but I guess it has changed to org.apache.spark.sql.types
Great work with the Data Frames btw! :)
Thanks,
Vinay


"
Guillaume Pitel <guillaume.pitel@exensa.com>,"Fri, 20 Mar 2015 23:24:40 +0100",Directly broadcasting (sort of) RDDs,dev@spark.apache.org,"Hi,

I have an idea that I would like to discuss with the Spark devs. The 
idea comes from a very real problem that I have struggled with since 
almost a year. My problem is very simple, it's a dense matrix * sparse 
matrix  operation. I have a dense matrix RDD[(Int,FloatMatrix)] which is 
divided in X large blocks (one block per partition), and a sparse matrix 
RDD[((Int,Int),Array[Array[(Int,Float)]]] , divided in X * Y blocks. The 
most efficient way to perform the operation is to collectAsMap() the 
dense matrix and broadcast it, then perform the block-local 
mutliplications, and combine the results by column.

This is quite fine, unless the matrix is too big to fit in memory 
(especially since the multiplication is performed several times 
iteratively, and the broadcasts are not always cleaned from memory as I 
would naively expect).

When the dense matrix is too big, a second solution is to split the big 
sparse matrix in several RDD, and do several broadcasts. Doing this 
creates quite a big overhead, but it mostly works, even though I often 
face some problems with unaccessible broadcast files, for instance.

Then there is the terrible but apparently very effective good old join. 
Since X blocks of the sparse matrix use the same block from the dense 
matrix, I suspect that the dense matrix is somehow replicated X times 
(either on disk or in the network), which is the reason why the join 
takes so much time.

After this bit of a context, here is my idea : would it be possible to 
somehow ""broadcast"" (or maybe more accurately, share or serve) a 
persisted RDD which is distributed on all workers, in a way that would, 
a bit like the IndexedRDD, allow a task to access a partition or an 
element of a partition in the closure, with a worker-local memory cache 
. i.e. the information about where each block resides would be 
distributed on the workers, to allow them to access parts of the RDD 
directly. I think that's already a bit how RDD are shuffled ?

The RDD could stay distributed (no need to collect then broadcast), and 
only necessary transfers would be required.

Is this a bad idea, is it already implemented somewhere (I would love it 
!) ?or is it something that could add efficiency not only for my use 
case, but maybe for others ? Could someone give me some hint about how I 
could add this possibility to Spark ? I would probably try to extend a 
RDD into a specific SharedIndexedRDD with a special lookup that would be 
allowed from tasks as a special case, and that would try to contact the 
blockManager and reach the corresponding data from the right worker.

Thanks in advance for your advices

Guillaume
-- 
eXenSa

	
*Guillaume PITEL, Président*
+33(0)626 222 431

eXenSa S.A.S. <http://www.exensa.com/>
41, rue Périer - 92120 Montrouge - FRANCE
Tel +33(0)184 163 677 / Fax +33(0)972 283 705

"
xing <ehomecity@gmail.com>,"Fri, 20 Mar 2015 15:59:09 -0700 (MST)","Re: Error:  'SparkContext' object has no attribute
 'getActiveStageIds'",dev@spark.apache.org,"getStageInfo in self._jtracker.getStageInfo below seems not
implemented/included in the current python library.

   def getStageInfo(self, stageId):
        """"""
        Returns a :class:`SparkStageInfo` object, or None if the stage
        info could not be found or was garbage collected.
        """"""
        stage = self._jtracker.getStageInfo(stageId)
        if stage is not None:
            # TODO: fetch them in batch for better performance
            attrs = [getattr(stage, f)() for f in
SparkStageInfo._fields[1:]]
            return SparkStageInfo(stageId, *attrs)



--

---------------------------------------------------------------------


"
Joseph Bradley <joseph@databricks.com>,"Fri, 20 Mar 2015 21:02:06 -0400",Re: Minor Edit in the programming guide,"""Muttineni, Vinay"" <vmuttineni@ebay.com>","Thanks!  I added it to a few other items:
https://issues.apache.org/jira/browse/SPARK-6337


"
Ted Yu <yuzhihong@gmail.com>,"Fri, 20 Mar 2015 18:03:19 -0700",Re: Error: 'SparkContext' object has no attribute 'getActiveStageIds',xing <ehomecity@gmail.com>,"Please take a look
at core/src/main/scala/org/apache/spark/SparkStatusTracker.scala, around
line 58:
  def getActiveStageIds(): Array[Int] = {

Cheers


"
Burak Yavuz <brkyvz@gmail.com>,"Fri, 20 Mar 2015 18:54:30 -0700",Re: Which linear algebra interface to use within Spark MLlib?,Debasish Das <debasish.das83@gmail.com>,"Hi,

We plan to add a more comprehensive local linear algebra package for MLlib
1.4. This local linear algebra package can then easily be extended to
BlockMatrix to support the same operations in a distributed fashion.

You may find the JIRA to track this here: SPARK-6442
<https://issues.apache.org/jira/browse/SPARK-6442>

The design doc is here: http://goo.gl/sf5LCE

We would very much appreciate your feedback and input.

Best,
Burak


r
AS
me
re
.
ut
"
"""=?utf-8?B?U2Vh?="" <261810726@qq.com>","Sat, 21 Mar 2015 13:35:01 +0800",Filesystem closed Exception,"""=?utf-8?B?dXNlcg==?="" <user@spark.apache.org>, ""=?utf-8?B?ZGV2?="" <dev@spark.apache.org>","Hi, all:




When I exit the console of spark-sql， the following exception throwed......


Exception in thread ""Thread-3"" java.io.IOException: Filesystem closed
        at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:629)
        at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1677)
        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1106)
        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1102)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1102)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1397)
        at org.apache.spark.scheduler.EventLoggingListener.stop(EventLoggingListener.scala:196)
        at org.apache.spark.SparkContext$$anonfun$stop$4.apply(SparkContext.scala:1388)
        at org.apache.spark.SparkContext$$anonfun$stop$4.apply(SparkContext.scala:1388)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.stop(SparkContext.scala:1388)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.stop(SparkSQLEnv.scala:66)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$$anon$1.run(SparkSQLCLIDriver.scala:107)‍"
"""=?utf-8?B?U2Vh?="" <261810726@qq.com>","Sat, 21 Mar 2015 13:35:40 +0800",Filesystem closed Exception,"""=?utf-8?B?dXNlckBzcGFyay5hcGFjaGUub3Jn?="" <user@spark.apache.org>, ""=?utf-8?B?ZGV2QHNwYXJrLmFwYWNoZS5vcmc=?="" <dev@spark.apache.org>","Hi, all:




When I exit the console of spark-sql， the following exception throwed......


My spark version is 1.3.0, hadoop version is 2.2.0


Exception in thread ""Thread-3"" java.io.IOException: Filesystem closed
        at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:629)
        at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1677)
        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1106)
        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1102)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1102)
        at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1397)
        at org.apache.spark.scheduler.EventLoggingListener.stop(EventLoggingListener.scala:196)
        at org.apache.spark.SparkContext$$anonfun$stop$4.apply(SparkContext.scala:1388)
        at org.apache.spark.SparkContext$$anonfun$stop$4.apply(SparkContext.scala:1388)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.stop(SparkContext.scala:1388)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.stop(SparkSQLEnv.scala:66)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$$anon$1.run(SparkSQLCLIDriver.scala:107)‍"
"""Nick Pentreath"" <nick.pentreath@gmail.com>","Fri, 20 Mar 2015 23:29:38 -0700 (PDT)",Re: Directly broadcasting (sort of) RDDs,"""Guillaume Pitel"" <guillaume.pitel@exensa.com>","There is block matrix in Spark 1.3 - http://spark.apache.org/docs/latest/mllib-data-types.html#blockmatrix





However I believe it only supports dense matrix blocks.




Still, might be possible to use it or exetend 




JIRAs:


https://issues.apache.org/jira/plugins/servlet/mobile#issue/SPARK-3434





Was based on 


https://github.com/amplab/ml-matrix





Another lib:


https://github.com/PasaLab/marlin/blob/master/README.md







—
Sent from Mailbox


sparse 
is 
matrix 
The 
I 
big 
often 
 
to 
 
cache 
and 
it 
use 
I 
a 
be 
the "
Guillaume Pitel <guillaume.pitel@exensa.com>,"Sat, 21 Mar 2015 08:11:01 +0100",Re: Directly broadcasting (sort of) RDDs,dev@spark.apache.org,"Hi,

Thanks for your answer. This is precisely the use case I'm interested 
in, but I know it already, I should have mentionned it. Unfortunately 
this implementation of BlockMatrix has (in my opinion) some 
disadvantages (the fact that it split the matrix by range instead of 
using a modulo is bad for block skewness). Besides, and more 
importantly, as I was writing, it uses the join solution (actually a 
cogroup : 
https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/linalg/distributed/BlockMatrix.scala, 
line 361). The reduplication of the elements of the dense matrix is thus 
dependent on the block size.

Actually I'm wondering if what I want to achieve could be made with a 
simple modification to the join, allowing a partition to be weakly 
cached wafter being retrieved.

Guillaume




-- 
eXenSa

	
*Guillaume PITEL, Président*
+33(0)626 222 431

eXenSa S.A.S. <http://www.exensa.com/>
41, rue Périer - 92120 Montrouge - FRANCE
Tel +33(0)184 163 677 / Fax +33(0)972 283 705

"
vinodkc <vinod.kc.in@gmail.com>,"Sat, 21 Mar 2015 01:52:24 -0700 (MST)",Re: Filesystem closed Exception,dev@spark.apache.org,"Hi Sea,

I've raised a  JIRA Issue on this :
https://issues.apache.org/jira/browse/SPARK-6445 . Making a PR  now


tem.java:1106)
tem.java:1102)
r.java:81)
eSystem.java:1102)
.scala:196)
88)
88)
a:66)
kSQLCLIDriver.scala:107)‍
ed-Exception-tp11145.html
ervlet.jtp?macro=unsubscribe_by_code&node=1&code=dmlub2Qua2MuaW5AZ21haWwuY29tfDF8MTk2Mjg4MTAzOA==>
ervlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>




--
3.nabble.com/Filesystem-closed-Exception-tp11145p11148.html
om."
"""=?utf-8?B?U2Vh?="" <261810726@qq.com>","Sat, 21 Mar 2015 23:38:34 +0800","=?utf-8?B?5Zue5aSN77yaIEZpbGVzeXN0ZW0gY2xvc2VkIEV4?=
 =?utf-8?B?Y2VwdGlvbg==?=","""=?utf-8?B?dmlub2RrYw==?="" <vinod.kc.in@gmail.com>, ""=?utf-8?B?ZGV2QHNwYXJrLmFwYWNoZS5vcmc=?="" <dev@spark.apache.org>","Hi, Vinodkc‍
Yes, I found another solution, https://github.com/apache/spark/pull/4771/
I will test it later.‍




------------------ 原始邮件 ------------------
发件人: ""vinodkc"";<vinod.kc.in@gmail.com>;
发送时间: 2015年3月21日(星期六) 下午4:52
收件人: ""dev""<dev@spark.apache.org>; 

主题: Re: Filesystem closed Exception



Hi Sea,

I've raised a  JIRA Issue on this :
https://issues.apache.org/jira/browse/SPARK-6445 . Making a PR  now

On Sat, Mar 21, 2015 at 11:06 AM, Sea [via Apache Spark Developers List] <
ml-node+s1001551n11145h68@n3.nabble.com> wrote:

> Hi, all:
>
>
>
>
> When I exit the console of spark-sql， the following exception
> throwed......
>
>
> My spark version is 1.3.0, hadoop version is 2.2.0
>
>
> Exception in thread ""Thread-3"" java.io.IOException: Filesystem closed
>         at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:629)
>         at
> org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1677)
>         at
> org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1106)
>
>         at
> org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1102)
>
>         at
> org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
>
>         at
> org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1102)
>
>         at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1397)
>         at
> org.apache.spark.scheduler.EventLoggingListener.stop(EventLoggingListener.scala:196)
>
>         at
> org.apache.spark.SparkContext$$anonfun$stop$4.apply(SparkContext.scala:1388)
>
>         at
> org.apache.spark.SparkContext$$anonfun$stop$4.apply(SparkContext.scala:1388)
>
>         at scala.Option.foreach(Option.scala:236)
>         at org.apache.spark.SparkContext.stop(SparkContext.scala:1388)
>         at
> org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.stop(SparkSQLEnv.scala:66)
>
>         at
> org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$$anon$1.run(SparkSQLCLIDriver.scala:107)‍
>
>
> ------------------------------
>  If you reply to this email, your message will be added to the discussion
> below:
>
> http://apache-spark-developers-list.1001551.n3.nabble.com/Filesystem-closed-Exception-tp11145.html
>  To start a new topic under Apache Spark Developers List, email
> ml-node+s1001551n1h4@n3.nabble.com
> To unsubscribe from Apache Spark Developers List, click here
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=1&code=dmlub2Qua2MuaW5AZ21haWwuY29tfDF8MTk2Mjg4MTAzOA==>
> .
> NAML
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Filesystem-closed-Exception-tp11145p11148.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com."
Debasish Das <debasish.das83@gmail.com>,"Sat, 21 Mar 2015 09:50:11 -0700",Re: Which linear algebra interface to use within Spark MLlib?,Burak Yavuz <brkyvz@gmail.com>,"Hi Burak,

For local linear algebra package why are we not extending breeze ?

Breeze is a mllib dependency...Also that way the local linear algebra
package will be used by other scala based frontend APIs as well that do not
necessarily pull in Spark dependencies...

Thanks.
Deb



b
or
g
.
n
s
..
t
l
a
"
Marek Wiewiorka <marek.wiewiorka@gmail.com>,"Sun, 22 Mar 2015 16:39:51 +0100",lower&upperBound not working/spark 1/3,dev@spark.apache.org,"Hi All - I try to use the new SQLContext API for populating DataFrame from
jdbc data source.
like this:

val jdbcDF = sqlContext.jdbc(url =
""jdbc:postgresql://localhost:5430/dbname?user=user&password=111"", table =
""se_staging.exp_table3"" ,columnName=""cs_id"",lowerBound=1 ,upperBound =
10000, numPartitions=12 )

No matter how I set lower and upper bounds I always get all the rows from
my table.
The API is marked as experimental so I assume there might by some bugs in
it but
did anybody come across a similar issue?

Thanks!
Marek
"
Michael Armbrust <michael@databricks.com>,"Sun, 22 Mar 2015 14:19:45 -0700",Re: lower&upperBound not working/spark 1/3,Marek Wiewiorka <marek.wiewiorka@gmail.com>,"I have not heard this reported yet, but your invocation looks correct to
me.  Can you open a JIRA?


"
Sandy Ryza <sandy.ryza@cloudera.com>,"Sun, 22 Mar 2015 18:56:04 -0400",Re: Directly broadcasting (sort of) RDDs,Guillaume Pitel <guillaume.pitel@exensa.com>,"Hi Guillaume,

I've long thought something like this would be useful - i.e. the ability to
broadcast RDDs directly without first pulling data through the driver.  If
I understand correctly, your requirement to ""block"" a matrix up and only
fetch the needed parts could be implemented on top of this by splitting an
RDD into a set of smaller RDDs and then broadcasting each one on its own.

Unfortunately nobody is working on this currently (and I couldn't promise
to have bandwidth to review it at the moment either), but I suspect we'll
eventually need to add something like this for map joins in Hive on Spark
and Spark SQL.

-Sandy



m

or
he/spark/mllib/linalg/distributed/BlockMatrix.scala,
/mllib-data-types.html#blockmatrix
"
Sean Owen <sowen@cloudera.com>,"Mon, 23 Mar 2015 00:42:10 +0000",Re: Directly broadcasting (sort of) RDDs,Sandy Ryza <sandy.ryza@cloudera.com>,"In a sentence, is this the idea of collecting an RDD to memory on each
executor directly?

e:
to
f I
tch
 to
,
e
for
s
che/spark/mllib/linalg/distributed/BlockMatrix.scala,
d

---------------------------------------------------------------------


"
Akhil Das <akhil@sigmoidanalytics.com>,"Mon, 23 Mar 2015 12:22:38 +0530",Re: Storage of RDDs created via sc.parallelize,Karlson <ksonspark@siberie.de>,"You can use sc.newAPIHadoopFile
<http://spark.apache.org/docs/1.2.0/api/scala/index.html#org.apache.spark.SparkContext>
with CSVInputFormat <https://github.com/mvallebr/CSVInputFormat> so that it
will read the csv file properly.

Thanks
Best Regards


"
lonely Feb <lonely8658@gmail.com>,"Mon, 23 Mar 2015 15:43:59 +0800",Spark Sql with python udf fail,"dev@spark.apache.org, user@spark.apache.org","Hi all, I tried to transfer some hive jobs into spark-sql. When i ran a sql
job with python udf i got a exception:

java.lang.ArrayIndexOutOfBoundsException: 9
        at
org.apache.spark.sql.catalyst.expressions.GenericRow.apply(Row.scala:142)
        at
org.apache.spark.sql.catalyst.expressions.BoundReference.eval(BoundAttribute.scala:37)
        at
org.apache.spark.sql.catalyst.expressions.EqualTo.eval(predicates.scala:166)
        at
org.apache.spark.sql.catalyst.expressions.InterpretedPredicate$$anonfun$apply$1.apply(predicates.scala:30)
        at
org.apache.spark.sql.catalyst.expressions.InterpretedPredicate$$anonfun$apply$1.apply(predicates.scala:30)
        at scala.collection.Iterator$$anon$14.hasNext(Iterator.scala:390)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
        at
org.apache.spark.sql.execution.Aggregate$$anonfun$execute$1$$anonfun$7.apply(Aggregate.scala:156)
        at
org.apache.spark.sql.execution.Aggregate$$anonfun$execute$1$$anonfun$7.apply(Aggregate.scala:151)
        at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:601)
        at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:601)
        at
org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:263)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:230)
        at
org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:263)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:230)
        at
org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)
        at
org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
        at org.apache.spark.scheduler.Task.run(Task.scala:56)
        at
org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:197)
        at
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)

I suspected there was an odd line in the input file. But the input file is
so large and i could not found any abnormal lines with several jobs to
check. How can i get the abnormal line here ?
"
Hui WANG <hedonplay@gmail.com>,"Mon, 23 Mar 2015 10:02:48 +0100","Re: Spark scheduling, data locality",=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Hello Zoltan,

I'm a spark beginner but i think that the locality preferences should be
prepared before the sending of
tasks.
of its partitions. Tasks created in the driver program should be based on
this information.

I'm also interested by a detailed answer of this question. Could someone
please provide a few more hints on it ?

Regards,
Hui


o



-- 
Hui WANG
Tel : +33 (0) 6 71 33 45 39
Blog : http://www.hui-wang.info
"
Marek Wiewiorka <marek.wiewiorka@gmail.com>,"Mon, 23 Mar 2015 10:32:35 +0100",Re: lower&upperBound not working/spark 1/3,"Michael Armbrust <michael@databricks.com>, dev@spark.apache.org","Ok- thanks Michael I will do another series of tests to confirm this and
then report an issue.

Regards,
Marek

2015-03-22 22:19 GMT+01:00 Michael Armbrust <michael@databricks.com>:

"
Guillaume Pitel <guillaume.pitel@exensa.com>,"Mon, 23 Mar 2015 13:00:36 +0100",Re: Directly broadcasting (sort of) RDDs,dev@spark.apache.org,"Not far, but not exactly. The RDD could be too big to fit in memory,

The idea is more like a worker-side rdd.lookup() with local cache.

Guillaume


-- 
eXenSa

	
*Guillaume PITEL, Président*
+33(0)626 222 431

eXenSa S.A.S. <http://www.exensa.com/>
41, rue Périer - 92120 Montrouge - FRANCE
Tel +33(0)184 163 677 / Fax +33(0)972 283 705

"
Sean Owen <sowen@cloudera.com>,"Mon, 23 Mar 2015 12:05:38 +0000",Re: Directly broadcasting (sort of) RDDs,Guillaume Pitel <guillaume.pitel@exensa.com>,"Since RDDs aren't designed as random-access maps, and are basically
bits of bookkeeping that make sense only on the driver, I think the
realization of something like this in Spark would realistically be
""collect RDD to local data structure"" if anything.

It sounds like you're looking for a distributed cache, and there are
frameworks for that that can be used with Spark without Spark
rebuilding that too.

to
f I
tch
 to
or
he/spark/mllib/linalg/distributed/BlockMatrix.scala,

---------------------------------------------------------------------


"
Neil Dev <neilkdev@gmail.com>,"Mon, 23 Mar 2015 11:37:19 -0400",Starting sparkthrift server,dev@spark.apache.org,"Hi,

I am having issues starting spark-thriftserver. I'm running spark 1.3.o
with Hadoop 2.4.0. I would like to be able to change its port too so, I can
hive hive-thriftserver as well as spark-thriftserver running at the same
time.

Starting sparkthrift server:-
sudo ./start-thriftserver.sh --master spark://ip-172-31-10-124:7077
--executor-memory 2G

Error:-
I created the folder manually but still getting the following error----
Exception in thread ""main"" java.lang.IllegalArgumentException: Log
directory /tmp/spark-events does not exist.


I am getting the following error
15/03/23 15:07:02 ERROR thrift.ThriftCLIService: Error:
org.apache.thrift.transport.TTransportException: Could not create
ServerSocket on address0.0.0.0/0.0.0.0:10000.
        at
org.apache.thrift.transport.TServerSocket.<init>(TServerSocket.java:93)
        at
org.apache.thrift.transport.TServerSocket.<init>(TServerSocket.java:79)
        at
org.apache.hive.service.auth.HiveAuthFactory.getServerSocket(HiveAuthFactory.java:236)
        at
org.apache.hive.service.cli.thrift.ThriftBinaryCLIService.run(ThriftBinaryCLIService.java:69)
        at java.lang.Thread.run(Thread.java:745)

Thanks
Neil
"
Neil Dev <neilkdev@gmail.com>,"Mon, 23 Mar 2015 15:01:29 -0400",Spark-thriftserver Issue,"user@spark.apache.org, dev@spark.apache.org","Hi,

I am having issue starting spark-thriftserver. I'm running spark 1.3.with
Hadoop 2.4.0. I would like to be able to change its port too so, I can hive
hive-thriftserver as well as spark-thriftserver running at the same time.

Starting sparkthrift server:-
sudo ./start-thriftserver.sh --master spark://ip-172-31-10-124:7077
--executor-memory 2G

Error:-
I created the folder manually but still getting the following error----
Exception in thread ""main"" java.lang.IllegalArgumentException: Log
directory /tmp/spark-events does not exist.


I am getting the following error
15/03/23 15:07:02 ERROR thrift.ThriftCLIService: Error:
org.apache.thrift.transport.TTransportException: Could not create
ServerSocket on address0.0.0.0/0.0.0.0:10000.
        at
org.apache.thrift.transport.TServerSocket.<init>(TServerSocket.java:93)
        at
org.apache.thrift.transport.TServerSocket.<init>(TServerSocket.java:79)
        at
org.apache.hive.service.auth.HiveAuthFactory.getServerSocket(HiveAuthFactory.java:236)
        at
org.apache.hive.service.cli.thrift.ThriftBinaryCLIService.run(ThriftBinaryCLIService.java:69)
        at java.lang.Thread.run(Thread.java:745)

Thanks
Neil
"
Denny Lee <denny.g.lee@gmail.com>,"Mon, 23 Mar 2015 19:38:05 +0000",Re: Starting sparkthrift server,"Neil Dev <neilkdev@gmail.com>, dev@spark.apache.org","It appears that you are running the thrift-server using the spark-events
account but the /tmp/spark-events folder doesn't exist or the user running
thrift-server does not have access to it.  Have you been able to run Hive
using the spark-events user so that way the /tmp/spark-events folder has
been created.  If you need to reassign the scratch dir / log dir to another
folder (instead of /tmp/spark-events), you could use  --hiveconf to assign
those to another folder.



"
Neil Dev <neilkdev@gmail.com>,"Mon, 23 Mar 2015 16:02:07 -0400",Re: Starting sparkthrift server,Denny Lee <denny.g.lee@gmail.com>,"we are running this right now as root user and the folder /tmp/spark-events
was manually created and the Job has access to this folder


"
Imran Rashid <irashid@cloudera.com>,"Mon, 23 Mar 2015 15:33:27 -0500",Re: enum-like types in Spark,Xiangrui Meng <mengxr@gmail.com>,"I've just switched some of my code over to the new format, and I just want
to make sure everyone realizes what we are getting into.  I went from 10
lines as java enums

https://github.com/squito/spark/blob/fef66058612ebf225e58dd5f5fea6bae1afd5b31/core/src/main/java/org/apache/spark/status/api/StageStatus.java#L20

to 30 lines with the new format:

https://github.com/squito/spark/blob/SPARK-3454_w_jersey/core/src/main/scala/org/apache/spark/status/api/v1/api.scala#L250

its not just that its verbose.  each name has to be repeated 4 times, with
potential typos in some locations that won't be caught by the compiler.
Also, you have to manually maintain the ""values"" as you update the set of
enums, the compiler won't do it for you.

The only downside I've heard for java enums is enum.hashcode().  OTOH, the
downsides for this version are: maintainability / verbosity, no values(),
more cumbersome to use from java, no enum map / enumset.

I did put together a little util to at least get back the equivalent of
enum.valueOf() with this format

https://github.com/squito/spark/blob/SPARK-3454_w_jersey/core/src/main/scala/org/apache/spark/util/SparkEnum.scala

I'm not trying to prevent us from moving forward on this, its fine if this
is still what everyone wants, but I feel pretty strongly java enums make
more sense.

thanks,
Imran



"
Sean Owen <sowen@cloudera.com>,"Mon, 23 Mar 2015 20:46:16 +0000",Re: enum-like types in Spark,Imran Rashid <irashid@cloudera.com>,"Yeah the fully realized #4, which gets back the ability to use it in
switch statements (? in Scala but not Java?) does end up being kind of
huge.

I confess I'm swayed a bit back to Java enums, seeing what it
involves. The hashCode() issue can be 'solved' with the hash of the
String representation.


---------------------------------------------------------------------


"
Denny Lee <denny.g.lee@gmail.com>,"Mon, 23 Mar 2015 20:50:23 +0000",Re: Starting sparkthrift server,Neil Dev <neilkdev@gmail.com>,"When you say the job has access, do you mean that when you run spark-submit
or spark-shell (for example), it is able to write to the /tmp/spark-events
folder?



"
Koert Kuipers <koert@tresata.com>,"Mon, 23 Mar 2015 16:52:10 -0400",Fwd: hadoop input/output format advanced control,"""dev@spark.apache.org"" <dev@spark.apache.org>","see email below. reynold suggested i send it to dev instead of user

---------- Forwarded message ----------
From: Koert Kuipers <koert@tresata.com>
Date: Mon, Mar 23, 2015 at 4:36 PM
Subject: hadoop input/output format advanced control
To: ""user@spark.apache.org"" <user@spark.apache.org>


currently its pretty hard to control the Hadoop Input/Output formats used
in Spark. The conventions seems to be to add extra parameters to all
methods and then somewhere deep inside the code (for example in
PairRDDFunctions.saveAsHadoopFile) all these parameters get translated into
settings on the Hadoop Configuration object.

for example for compression i see ""codec: Option[Class[_ <:
CompressionCodec]] = None"" added to a bunch of methods.

how scalable is this solution really?

for example i need to read from a hadoop dataset and i dont want the input
(part) files to get split up. the way to do this is to set
""mapred.min.split.size"". now i dont want to set this at the level of the
SparkContext (which can be done), since i dont want it to apply to input
formats in general. i want it to apply to just this one specific input
dataset i need to read. which leaves me with no options currently. i could
go add yet another input parameter to all the methods
(SparkContext.textFile, SparkContext.hadoopFile, SparkContext.objectFile,
etc.). but that seems ineffective.

why can we not expose a Map[String, String] or some other generic way to
manipulate settings for hadoop input/output formats? it would require
adding one more parameter to all methods to deal with hadoop input/output
formats, but after that its done. one parameter to rule them all....

then i could do:
val x = sc.textFile(""/some/path"", formatSettings =
Map(""mapred.min.split.size"" -> ""12345""))

or
rdd.saveAsTextFile(""/some/path, formatSettings =
Map(mapred.output.compress"" -> ""true"", ""mapred.output.compression.codec"" ->
""somecodec""))
"
Anubhav Agarwal <anubhav33@gmail.com>,"Mon, 23 Mar 2015 17:00:19 -0400",Re: Starting sparkthrift server,Denny Lee <denny.g.lee@gmail.com>,"When I start spark-shell (for example) it does not write to the
/tmp/spark-events folder. It remains empty. I have even tried it after
giving that folder rwx permission for user, group and others.

Neil's colleague,
Anu


"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Mon, 23 Mar 2015 22:08:33 +0100",Spark Executor resources,dev@spark.apache.org,"Let's say I'm an Executor instance in a Spark system. Who started me and
where, when I run on a worker node supervised by (a) Mesos, (b) YARN? I
suppose I'm the only one Executor on a worker node for a given framework
scheduler (driver). If I'm an Executor instance, who is the closest object
to me who can tell me how many resources do I have on (a) Mesos, (b) YARN?

Thank you for your kind input!

Zvara Zoltán



mail, hangout, skype: zoltan.zvara@gmail.com

mobile, viber: +36203129543

bank: 10918001-00000021-50480008

address: Hungary, 2475 Kápolnásnyék, Kossuth 6/a

elte: HSKSJZ (ZVZOAAI.ELTE)
"
Aaron Davidson <ilikerps@gmail.com>,"Mon, 23 Mar 2015 14:09:31 -0700",Re: enum-like types in Spark,Sean Owen <sowen@cloudera.com>,"The only issue I knew of with Java enums was that it does not appear in the
Scala documentation.


"
Patrick Wendell <pwendell@gmail.com>,"Mon, 23 Mar 2015 14:11:33 -0700",Re: enum-like types in Spark,Sean Owen <sowen@cloudera.com>,"If the official solution from the Scala community is to use Java
enums, then it seems strange they aren't generated in scaldoc? Maybe
we can just fix that w/ Typesafe's help and then we can use them.


---------------------------------------------------------------------


"
Reynold Xin <rxin@databricks.com>,"Mon, 23 Mar 2015 14:13:41 -0700",Re: enum-like types in Spark,Patrick Wendell <pwendell@gmail.com>,"If scaladoc can show the Java enum types, I do think the best way is then
just Java enum types.



"
Bijay Pathak <bijay.pathak@cloudwick.com>,"Mon, 23 Mar 2015 14:25:11 -0700",Shuffle Spill Memory and Shuffle Spill Disk,dev@spark.apache.org,"Hello,

I am running  TeraSort <https://github.com/ehiggs/spark-terasort> on 100GB
of data. The final metrics I am getting on Shuffle Spill are:

Shuffle Spill(Memory): 122.5 GB
Shuffle Spill(Disk): 3.4 GB

What's the difference and relation between these two metrics? Does these
mean 122.5 GB was spill from memory during the shuffle?

thank you,
bijay
"
Imran Rashid <irashid@cloudera.com>,"Mon, 23 Mar 2015 16:50:06 -0500",Re: enum-like types in Spark,Patrick Wendell <pwendell@gmail.com>,"well, perhaps I overstated things a little, I wouldn't call it the
""official"" solution, just a recommendation in the never-ending debate (and
the recommendation from folks with their hands on scala itself).

Even if we do get this fixed in scaladoc eventually -- as its not in the
current versions, where does that leave this proposal?  personally I'd
*still* prefer java enums, even if it doesn't get into scaladoc.  btw, even
with sealed traits, the scaladoc still isn't great -- you don't see the
values from the class, you only see them listed from the companion object.
 (though, that is somewhat standard for scaladoc, so maybe I'm reaching a
little)




"
Bijay Pathak <bijay.pathak@cloudwick.com>,"Mon, 23 Mar 2015 14:52:30 -0700",Re: Shuffle Spill Memory and Shuffle Spill Disk,dev@spark.apache.org,"It looks this is not the right place for this question, I have send the
question to user group.

thank you,
bijay


"
Zhan Zhang <zzhang@hortonworks.com>,"Mon, 23 Mar 2015 22:47:51 +0000","Review request for SPARK-6112:Provide OffHeap support through HDFS
 RAM_DISK",dev <dev@spark.apache.org>,"Hi Folks,

I am planning to implement hdfs off heap support for spark, and have uploaded the design doc for the off heap support through hdfs ramdisk in jira SPARK-6112. Please review it and provide your feedback if anybody are interested.

https://issues.apache.org/jira/browse/SPARK-6112

Thanks.

Zhan Zhang
"
Zhan Zhang <zzhang@hortonworks.com>,"Mon, 23 Mar 2015 22:51:05 +0000",Re: Spark-thriftserver Issue,Neil Dev <neilkdev@gmail.com>,"Probably the port is already used by others, e.g., hive. You can change the port similar to below


 ./sbin/start-thriftserver.sh --master yarn --executor-memory 512m --hiveconf hive.server2.thrift.port=10001

Thanks.

Zhan Zhang


Hi,

I am having issue starting spark-thriftserver. I'm running spark 1.3.with
Hadoop 2.4.0. I would like to be able to change its port too so, I can hive
hive-thriftserver as well as spark-thriftserver running at the same time.

Starting sparkthrift server:-
sudo ./start-thriftserver.sh --master spark://ip-172-31-10-124:7077
--executor-memory 2G

Error:-
I created the folder manually but still getting the following error----
Exception in thread ""main"" java.lang.IllegalArgumentException: Log
directory /tmp/spark-events does not exist.


I am getting the following error
15/03/23 15:07:02 ERROR thrift.ThriftCLIService: Error:
org.apache.thrift.transport.TTransportException: Could not create
ServerSocket on address0.0.0.0/0.0.0.0:10000.
       at
org.apache.thrift.transport.TServerSocket.<init>(TServerSocket.java:93)
       at
org.apache.thrift.transport.TServerSocket.<init>(TServerSocket.java:79)
       at
org.apache.hive.service.auth.HiveAuthFactory.getServerSocket(HiveAuthFactory.java:236)
       at
org.apache.hive.service.cli.thrift.ThriftBinaryCLIService.run(ThriftBinaryCLIService.java:69)
       at java.lang.Thread.run(Thread.java:745)

Thanks
Neil

"
Reynold Xin <rxin@databricks.com>,"Mon, 23 Mar 2015 16:03:08 -0700","Re: Review request for SPARK-6112:Provide OffHeap support through
 HDFS RAM_DISK",Zhan Zhang <zzhang@hortonworks.com>,"I created a ticket to separate the API refactoring from the implementation.
Would be great to have these as two separate patches to make it easier to
review (similar to the way we are doing RPC refactoring -- first
introducing an internal RPC api, port akka to it, and then add an
alternative implementation).

https://issues.apache.org/jira/browse/SPARK-6479

Can you upload your design doc there so we can discuss the block store api?
Thanks.



"
Zhan Zhang <zzhang@hortonworks.com>,"Mon, 23 Mar 2015 23:14:20 +0000","Re: Review request for SPARK-6112:Provide OffHeap support through
 HDFS RAM_DISK",Reynold Xin <rxin@databricks.com>,"Thanks Reynold,

Agree with you to open another JIRA to unify the block storage API.  I have upload the design doc to SPARK-6479 as well.

Thanks.

Zhan Zhang


I created a ticket to separate the API refactoring from the implementation. Would be great to have these as two separate patches to make it easier to review (similar to the way we are doing RPC refactoring -- first introducing an internal RPC api, port akka to it, and then add an alternative implementation).

https://issues.apache.org/jira/browse/SPARK-6479

Can you upload your design doc there so we can discuss the block store api? Thanks.


Hi Folks,

I am planning to implement hdfs off heap support for spark, and have uploaded the design doc for the off heap support through hdfs ramdisk in jira SPARK-6112. Please review it and provide your feedback if anybody are interested.

https://issues.apache.org/jira/browse/SPARK-6112

Thanks.

Zhan Zhang


"
Denny Lee <denny.g.lee@gmail.com>,"Tue, 24 Mar 2015 00:41:18 +0000",Re: Starting sparkthrift server,Anubhav Agarwal <anubhav33@gmail.com>,"In that case, can you use the configurations to specify the folders?  I'm
wondering if this actually Hive in play here and somehow the
/tmp/spark-events is being specified for the logs for Hive?


"
Bin Wang <wbin00@gmail.com>,"Tue, 24 Mar 2015 08:08:26 +0000",Optimize the first map reduce of DStream,dev@spark.apache.org,"Hi,

I'm learning Spark and I find there could be some optimize for the current
streaming implementation. Correct me if I'm wrong.

The current streaming implementation put the data of one batch into memory
(as RDD). But it seems not necessary.

For example, if I want to count the lines which contains word ""Spark"", I
just need to map every line to see if it contains word, then reduce it with
a sum function. After that, this line is no longer useful to keep it in
memory.

That is said, if the DStream only have one map and/or reduce operation on
it. It is not necessary to keep all the batch data in the memory. Something
like a pipeline should be OK.

Is it difficult to implement on top of the current implementation?

Thanks.

---
Bin Wang
"
Arush Kharbanda <arush@sigmoidanalytics.com>,"Tue, 24 Mar 2015 16:25:14 +0530",Re: Optimize the first map reduce of DStream,Bin Wang <wbin00@gmail.com>,"The block size is configurable and that way I think you can reduce the
block interval, to keep the block in memory only for the limiter interval?
Is that what you are looking for?





-- 

[image: Sigmoid Analytics] <http://htmlsig.com/www.sigmoidanalytics.com>

*Arush Kharbanda* || Technical Teamlead

arush@sigmoidanalytics.com || www.sigmoidanalytics.com
"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Tue, 24 Mar 2015 12:04:22 +0100",Re: Optimize the first map reduce of DStream,Bin Wang <wbin00@gmail.com>,"There is a BlockGenerator on each worker node next to the
ReceiverSupervisorImpl, which generates Blocks out of an ArrayBuffer in
each interval (block_interval). These Blocks are passed to
ReceiverSupervisorImpl, which throws these blocks to into the BlockManager
for storage. BlockInfos are passed to the driver. Mini-batches are created
by the JobGenerator component on the driver each batch_interval. I guess
what you are looking for is provided by a continuous model like Flink's. We
are creating mini-batches to provide fault tolerance.

Zvara Zoltán



mail, hangout, skype: zoltan.zvara@gmail.com

mobile, viber: +36203129543

bank: 10918001-00000021-50480008

address: Hungary, 2475 Kápolnásnyék, Kossuth 6/a

elte: HSKSJZ (ZVZOAAI.ELTE)

2015-03-24 11:55 GMT+01:00 Arush Kharbanda <arush@sigmoidanalytics.com>:

?
I
on
"
Sean Owen <sowen@cloudera.com>,"Tue, 24 Mar 2015 13:13:11 +0000",Any guidance on when to back port and how far?,dev <dev@spark.apache.org>,"So far, my rule of thumb has been:

- Don't back-port new features or improvements in general, only bug fixes
- Don't back-port minor bug fixes
- Back-port bug fixes that seem important enough to not wait for the
next minor release
- Back-port site doc changes to the release most likely to go out
next, to make it a part of the next site publish

But, how far should back-ports go, in general? If the last minor
release was 1.N, then to branch 1.N surely. Farther back is a question
of expectation for support of past minor releases. Given the pace of
change and time available, I assume there's not much support for
continuing to use release 1.(N-1) and very little for 1.(N-2).

Concretely: does anyone expect a 1.1.2 release ever? a 1.2.2 release?
It'd be good to hear the received wisdom explicitly.

---------------------------------------------------------------------


"
Bin Wang <wbin00@gmail.com>,"Tue, 24 Mar 2015 14:03:52 +0000",Re: Optimize the first map reduce of DStream,=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"I'm not looking for limit the block size.

Here is another example. Say we want to count the lines from the stream in
one hour. In a normal program, we may write it like this:

int sum = 0
while (line = getFromStream()) {
    store(line) // store the line into storage instead of memory.
    sum++
}

This could be seen as a reduce. The only memory used here is just the
variable named ""line"", need not store all the lines into memory (if lines
would not use in other places). If we want to provide fault tolerance, we
may just store lines into storage instead of in the memory. Could Spark
streaming work like this way? Dose Flink work like this?






r
d
We
l?
 I
n
"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Tue, 24 Mar 2015 15:21:29 +0100",Re: Optimize the first map reduce of DStream,Bin Wang <wbin00@gmail.com>,"​AFAIK Spark Streaming can not work in a way like this. Transformations are
made on DStreams, where DStreams are basically hold (time,
allocatedBlocksForBatch) pairs.​ Allocated blocks are allocated by the
JobGenerator, unallocated blocks (infos) are collected by
ReceivedBlockTracker. In Spark Streaming you define transformations and
actions on DStreams. The operators define RDD chains, tasks are created by
spark-core. You manipulate DStreams, not single unit of data. Flink for
example uses a continuous model. It optimizes for memory usage and latency.
Read the Spark Streaming paper and Spark paper for more reference.

Zvara Zoltán



mail, hangout, skype: zoltan.zvara@gmail.com

mobile, viber: +36203129543

bank: 10918001-00000021-50480008

address: Hungary, 2475 Kápolnásnyék, Kossuth 6/a

elte: HSKSJZ (ZVZOAAI.ELTE)

2015-03-24 15:03 GMT+01:00 Bin Wang <wbin00@gmail.com>:

n
er
ed
 We
,
t
in
n
"
Imran Rashid <irashid@cloudera.com>,"Tue, 24 Mar 2015 10:28:45 -0500",Re: hadoop input/output format advanced control,Koert Kuipers <koert@tresata.com>,"I think this would be a great addition, I totally agree that you need to be
able to set these at a finer context than just the SparkContext.

Just to play devil's advocate, though -- the alternative is for you just
subclass HadoopRDD yourself, or make a totally new RDD, and then you could
expose whatever you need.  Why is this solution better?  IMO the criteria
are:
(a) common operations
(b) error-prone / difficult to implement
(c) non-obvious, but important for performance

I think this case fits (a) & (c), so I think its still worthwhile.  But its
also worth asking whether or not its too difficult for a user to extend
HadoopRDD right now.  There have been several cases in the past week where
we've suggested that a user should read from hdfs themselves (eg., to read
multiple files together in one partition) -- with*out* reusing the code in
HadoopRDD, though they would lose things like the metric tracking &
preferred locations you get from HadoopRDD.  Does HadoopRDD need to some
refactoring to make that easier to do?  Or do we just need a good example?

Imran

(sorry for hijacking your thread, Koert)




"
Sandy Ryza <sandy.ryza@cloudera.com>,"Tue, 24 Mar 2015 11:30:05 -0400",Re: Spark Executor resources,=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Hi Zoltan,

If running on YARN, the YARN NodeManager starts executors.  I don't think
there's a 100% precise way for the Spark executor way to know how many
resources are allotted to it.  It can come close by looking at the Spark
configuration options used to request it (spark.executor.memory and
spark.yarn.executor.memoryOverhead), but it can't necessarily for the
amount that YARN has rounded up if those configuration properties
(yarn.scheduler.minimum-allocation-mb and
yarn.scheduler.increment-allocation-mb) are not present on the node.

-Sandy

-Sandy


t
?
"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Tue, 24 Mar 2015 16:41:43 +0100",Re: Spark Executor resources,Sandy Ryza <sandy.ryza@cloudera.com>,"Thank you for your response!

I guess the (Spark)AM, who gives the container leash to the NM (along with
the executor JAR and command to run) must know how many CPU or RAM that
container capped, isolated at. There must be a resource vector along the
encrypted container leash if I'm right that describes this. Or maybe is
there a way for the ExecutorBackend to fetch this information directly from
the environment? Then, the ExecutorBackend would be able to hand over this
information to the actual Executor who creates the TaskRunner.

Zvara Zoltán



mail, hangout, skype: zoltan.zvara@gmail.com

mobile, viber: +36203129543

bank: 10918001-00000021-50480008

address: Hungary, 2475 Kápolnásnyék, Kossuth 6/a

elte: HSKSJZ (ZVZOAAI.ELTE)

2015-03-24 16:30 GMT+01:00 Sandy Ryza <sandy.ryza@cloudera.com>:

m>
ct
N?
"
Sandy Ryza <sandy.ryza@cloudera.com>,"Tue, 24 Mar 2015 11:42:34 -0400",Re: Spark Executor resources,=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"That's correct.  What's the reason this information is needed?

-Sandy


h
om
s
k
om>
d
k
"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Tue, 24 Mar 2015 16:48:41 +0100",Re: Spark Executor resources,Sandy Ryza <sandy.ryza@cloudera.com>,"I'm trying to log Tasks to understand physical plan and to visualize which
RDD's which partition is currently computed from which creation site along
with other information. I want to charge the TaskRunner to do this before
actually invoking runTask() on Task and again just before giving the Task
to the GC when metrics are collected. Along with the information I wish to
log, I want to report, log the resources the Executor allocates to run its
Tasks.

Zvara Zoltán



mail, hangout, skype: zoltan.zvara@gmail.com

mobile, viber: +36203129543

bank: 10918001-00000021-50480008

address: Hungary, 2475 Kápolnásnyék, Kossuth 6/a

elte: HSKSJZ (ZVZOAAI.ELTE)

2015-03-24 16:42 GMT+01:00 Sandy Ryza <sandy.ryza@cloudera.com>:

om>
g
 is
rom
is
nd
com>
nd
I
rk
"
Kannan Rajah <krajah@maprtech.com>,"Tue, 24 Mar 2015 10:56:26 -0700",Understanding shuffle file name conflicts,dev@spark.apache.org,"I am working on SPARK-1529. I ran into an issue with my change, where the
same shuffle file was being reused across 2 jobs. Please note this only
happens when I use a hard coded location to use for shuffle files, say
""/tmp"". It does not happen with normal code path that uses DiskBlockManager
to pick different directories for each run. So I want to understand how
DiskBlockManager guarantees that such a conflict will never happen.

Let's say the shuffle block id has a value of shuffle_0_0_0. So the data
file name is shuffle_0_0_0.data and index file name is shuffle_0_0_0.index.
If I run a spark job twice, one after another, these files get created
under different directories because of the hashing logic in
DiskBlockManager. But the hash is based off the file name, so how are we
sure that there won't be a conflict ever?

--
Kannan
"
Michael Armbrust <michael@databricks.com>,"Tue, 24 Mar 2015 11:23:27 -0700",Re: Any guidance on when to back port and how far?,Sean Owen <sowen@cloudera.com>,"Two other criteria that I use when deciding what to backport:
 - Is it a regression from a previous minor release?  I'm much more likely
to backport fixes in this case, as I'd love for most people to stay up to
date.
 - How scary is the change?  I think the primary goal is stability of the
maintenance branches.  When I am confident that something is isolated and
unlikely to break things (i.e. I'm fixing a confusing error message), then
i'm much more likely to backport it.

Regarding the length of time to continue backporting, I mostly don't
backport to N-1, but this is partially because SQL is changing too fast for
that to generally be useful.  These old branches usually only get attention
from me when there is an explicit request.

I'd love to hear more feedback from others.

Michael


"
Nick Pentreath <nick.pentreath@gmail.com>,"Tue, 24 Mar 2015 20:50:11 +0200",Re: hadoop input/output format advanced control,"""dev@spark.apache.org"" <dev@spark.apache.org>","Imran, on your point to read multiple files together in a partition, is it
not simpler to use the approach of copy Hadoop conf and set per-RDD
settings for min split to control the input size per partition, together
with something like CombineFileInputFormat?


"
Patrick Wendell <pwendell@gmail.com>,"Tue, 24 Mar 2015 11:55:27 -0700",Re: Any guidance on when to back port and how far?,Michael Armbrust <michael@databricks.com>,"you didn't mention though is if a bug fix seems complicated, I will
think very hard before back-porting it. This is because ""fixes"" can
introduce their own new bugs, in some cases worse than the original
issue. It's really bad to have some upgrade to a patch release and see
a regression - with our current approach this almost never happens.

I will usually try to backport up to N-2, if it can be back-ported
reasonably easily (for instance, with minor or no code changes). The
reason I do this is that vendors do end up supporting older versions,
and it's nice for them if some committer has backported a fix that
they can then pull in, even if we never ship it.

In terms of doing older maintenance releases, this one I think we
should do according to severity of issues (for instance, if there is a
security issue) or based on general command from the community. I
haven't initiated many 1.X.2 releases recently because I didn't see
huge demand. However, personally I don't mind doing these if there is
a lot of demand, at least for releases where "".0"" has gone out in the
last six months.


---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Tue, 24 Mar 2015 11:59:10 -0700",Re: hadoop input/output format advanced control,Nick Pentreath <nick.pentreath@gmail.com>,"Yeah - to Nick's point, I think the way to do this is to pass in a
custom conf when you create a Hadoop RDD (that's AFAIK why the conf
field is there). Is there anything you can't do with that feature?


---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Tue, 24 Mar 2015 12:05:03 -0700",Experience using binary packages on various Hadoop distros,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hey All,

For a while we've published binary packages with different Hadoop
client's pre-bundled. We currently have three interfaces to a Hadoop
cluster (a) the HDFS client (b) the YARN client (c) the Hive client.

Because (a) and (b) are supposed to be backwards compatible
interfaces. My working assumption was that for the most part (modulo
Hive) our packages work with *newer* Hadoop versions. For instance,
our Hadoop 2.4 package should work with HDFS 2.6 and YARN 2.6.
However, I have heard murmurings that these are not compatible in
practice.

So I have three questions I'd like to put out to the community:

1. Have people had difficulty using 2.4 packages with newer Hadoop
versions? If so, what specific incompatibilities have you hit?
2. Have people had issues using our binary Hadoop packages in general
with commercial or Apache Hadoop distro's, such that you have to build
from source?
3. How would people feel about publishing a ""bring your own Hadoop""
binary, where you are required to point us to a local Hadoop
distribution by setting HADOOP_HOME? This might be better for ensuring
full compatibility:
https://issues.apache.org/jira/browse/SPARK-6511

- Patrick

---------------------------------------------------------------------


"
Anubhav Agarwal <anubhav33@gmail.com>,"Tue, 24 Mar 2015 15:10:18 -0400",Re: Spark-thriftserver Issue,Zhan Zhang <zzhang@hortonworks.com>,"Zhan specifying port fixed the port issue.

Is it possible to specify the log directory while starting the spark
thriftserver?
Still getting this error even through the folder exists and everyone has
permission to use that directory.
drwxr-xr-x  2 root         root          4096 Mar 24 19:04 spark-events


Exception in thread ""main"" java.lang.IllegalArgumentException: Log
directory /tmp/spark-events does not exist.
        at
org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:99)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:399)
        at
org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.init(SparkSQLEnv.scala:49)
        at
org.apache.spark.sql.hive.thriftserver.HiveThriftServer2$.main(HiveThriftServer2.scala:58)
        at
org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at
org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
        at
org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
        at
org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)




"
Zhan Zhang <zzhang@hortonworks.com>,"Tue, 24 Mar 2015 19:50:06 +0000",Re: Spark-thriftserver Issue,Anubhav Agarwal <anubhav33@gmail.com>,"You can try to set it in spark-env.sh.

# - SPARK_LOG_DIR       Where log files are stored.  (Default: ${SPARK_HOME}/logs)
# - SPARK_PID_DIR       Where the pid file is stored. (Default: /tmp)

Thanks.

Zhan Zhang


Zhan specifying port fixed the port issue.

Is it possible to specify the log directory while starting the spark thriftserver?
Still getting this error even through the folder exists and everyone has permission to use that directory.
drwxr-xr-x  2 root         root          4096 Mar 24 19:04 spark-events


Exception in thread ""main"" java.lang.IllegalArgumentException: Log directory /tmp/spark-events does not exist.
        at org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:99)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:399)
        at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.init(SparkSQLEnv.scala:49)
        at org.apache.spark.sql.hive.thriftserver.HiveThriftServer2$.main(HiveThriftServer2.scala:58)
        at org.apache.spark.sql.hive.thriftserver.HiveThriftServer2.main(HiveThriftServer2.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:569)
        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:166)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:189)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:110)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)



Probably the port is already used by others, e.g., hive. You can change the port similar to below


 ./sbin/start-thriftserver.sh --master yarn --executor-memory 512m --hiveconf hive.server2.thrift.port=10001

Thanks.

Zhan Zhang


Hi,

I am having issue starting spark-thriftserver. I'm running spark 1.3.with
Hadoop 2.4.0. I would like to be able to change its port too so, I can hive
hive-thriftserver as well as spark-thriftserver running at the same time.

Starting sparkthrift server:-
sudo ./start-thriftserver.sh --master spark://ip-172-31-10-124:7077
--executor-memory 2G

Error:-
I created the folder manually but still getting the following error----
Exception in thread ""main"" java.lang.IllegalArgumentException: Log
directory /tmp/spark-events does not exist.


I am getting the following error
15/03/23 15:07:02 ERROR thrift.ThriftCLIService: Error:
org.apache.thrift.transport.TTransportException: Could not create
ServerSocket on address0.0.0.0/0.0.0.0:10000<http://0.0.0.0:10000/>.
       at
org.apache.thrift.transport.TServerSocket.<init>(TServerSocket.java:93)
       at
org.apache.thrift.transport.TServerSocket.<init>(TServerSocket.java:79)
       at
org.apache.hive.service.auth.HiveAuthFactory.getServerSocket(HiveAuthFactory.java:236)
       at
org.apache.hive.service.cli.thrift.ThriftBinaryCLIService.run(ThriftBinaryCLIService.java:69)
       at java.lang.Thread.run(Thread.java:745)

Thanks
Neil



"
Matei Zaharia <matei.zaharia@gmail.com>,"Tue, 24 Mar 2015 17:28:24 -0400",Re: Experience using binary packages on various Hadoop distros,Patrick Wendell <pwendell@gmail.com>,"Just a note, one challenge with the BYOH version might be that users who download that can't run in local mode without also having Hadoop. But if we describe it correctly then hopefully it's okay.

Matei



---------------------------------------------------------------------


"
Koert Kuipers <koert@tresata.com>,"Tue, 24 Mar 2015 18:40:43 -0400",Re: hadoop input/output format advanced control,Patrick Wendell <pwendell@gmail.com>,"i would like to use objectFile with some tweaks to the hadoop conf.
currently there is no way to do that, except recreating objectFile myself.
and some of the code objectFile uses i have no access to, since its private
to spark.



"
Koert Kuipers <koert@tresata.com>,"Tue, 24 Mar 2015 18:46:19 -0400",Re: hadoop input/output format advanced control,Patrick Wendell <pwendell@gmail.com>,"the (compression) codec parameter that is now part of many saveAs...
methods came from a similar need. see SPARK-763
<https://issues.apache.org/jira/browse/SPARK-763>
hadoop has many options like this. you either going to have to allow many
more of these optional arguments to all the methods that read from hadoop
inputformats and write to hadoop outputformats, or you force people to
re-create these methods using HadoopRDD, i think (if thats even possible).


"
Jey Kottalam <jey@cs.berkeley.edu>,"Tue, 24 Mar 2015 16:16:32 -0700",Re: Experience using binary packages on various Hadoop distros,Matei Zaharia <matei.zaharia@gmail.com>,"Could we gracefully fallback to an in-tree Hadoop binary (e.g. 1.0.4)
in that case? I think many new Spark users are confused about why
Spark has anything to do with Hadoop, e.g. I could see myself being
confused when the download page asks me to select a ""package type"". I
know that what I want is not ""source code"", but I'd have no idea how
to choose amongst the apparently multiple types of binaries.


---------------------------------------------------------------------


"
Patrick Wendell <pwendell@gmail.com>,"Tue, 24 Mar 2015 16:30:46 -0700",Re: Experience using binary packages on various Hadoop distros,Jey Kottalam <jey@cs.berkeley.edu>,"We can probably better explain that if you are not using HDFS or YARN,
you can download any binary.

However, my question was about if the existing binaries do not work
well with newer Hadoop versions, which I heard some people suggest but
I'm looking for more specific issues.


---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Wed, 25 Mar 2015 01:56:52 +0000",RE: Using CUDA within Spark / boosting linear algebra,Sam Halliday <sam.halliday@gmail.com>,"Hi,

I am trying to use nvblas with netlib-java from Spark. nvblas functions should replace current blas functions calls after executing LD_PRELOAD as suggested in http://docs.nvidia.com/cuda/nvblas/#Usage without any changes to netlib-java. It seems to work for simple Java example, but I cannot make it work with Spark. I run the following:
export LD_LIBRARY_PATH=/usr/local/cuda-6.5/lib64
env LD_PRELOAD=/usr/local/cuda-6.5/lib64/libnvblas.so ./spark-shell --driver-memory 4G
In nvidia-smi I observe that Java is to use GPU:
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      8873    C   bash                                            39MiB |
|    0      8910    C   /usr/lib/jvm/java-1.7.0/bin/java                39MiB |
+-----------------------------------------------------------------------------+

In Spark shell I do matrix multiplication and see the following:
15/03/25 06:48:01 INFO JniLoader: successfully loaded /tmp/jniloader8192964377009965483netlib-native_system-linux-x86_64.so
So I am sure that netlib-native is loaded and cblas supposedly used. However, matrix multiplication does executes on CPU since I see 16% of CPU used and 0% of GPU used. I also checked different matrix sizes, from 100x100 to 12000x12000

Could you suggest might the LD_PRELOAD not affect Spark shell?

Best regards, Alexander



From: Sam Halliday [mai 6:01 PM
To: Ulanov, Alexander
Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
Subject: RE: Using CUDA within Spark / boosting linear algebra


Thanks so much for following up on this!

Hmm, I wonder if we should have a concerted effort to chart performance on various pieces of hardware...
On 9 Mar 2015 21:08, ""Ulanov, Alexander"" <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
Hi Everyone, I've updated the benchmark as Xiangrui suggested. Added the comment that BIDMat 0.9.7 uses Float matrices in GPU (although I see the support of Double in the current source code), did the test with BIDMat and CPU Double matrices. BIDMat MKL is indeed on par with netlib MKL.

https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing

Best regards, Alexander

-----Original Message-----
From: Sam Halliday [mailto:sam.halliday@gmail.com<mailto:sam.halliday@gmail.com>]
Sent: Tuesday, March 03, 2015 1:54 PM
To: Xiangrui Meng; Joseph Bradley
Cc: Evan R. Sparks; Ulanov, Alexander; dev@spark.apache.org<mailto:dev@spark.apache.org>
Subject: Re: Using CUDA within Spark / boosting linear algebra

BTW, is anybody on this list going to the London Meetup in a few weeks?

https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-mapreduce-world#community

Would be nice to meet other people working on the guts of Spark! :-)


Xiangrui Meng <mengxr@gmail.com<mailto:mengxr@gmail.com>> writes:

> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x
> slower than netlib-openblas. What is the overhead of using a GPU BLAS
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com<mailto:joseph@databricks.com>> wrote:
>> Better documentation for linking would be very helpful!  Here's a JIRA:
>> https://issues.apache.org/jira/browse/SPARK-6019
>>
>>
>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks
>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
>> wrote:
>>
>>> Thanks for compiling all the data and running these benchmarks,
>>> Alex. The big takeaways here can be seen with this chart:
>>>
>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZ
>>> Hl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
>>>
>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>> BIDMat+GPU) can provide substantial (but less than an order of
>>> BIDMat+magnitude)
>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>>> netlib-java+openblas-compiled).
>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude
>>> worse than a well-tuned CPU implementation, particularly for larger matrices.
>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
>>> basically agrees with the authors own benchmarks (
>>> https://github.com/fommil/netlib-java)
>>>
>>> I think that most of our users are in a situation where using GPUs
>>> may not be practical - although we could consider having a good GPU
>>> backend available as an option. However, *ALL* users of MLlib could
>>> benefit (potentially tremendously) from using a well-tuned CPU-based
>>> BLAS implementation. Perhaps we should consider updating the mllib
>>> guide with a more complete section for enabling high performance
>>> binaries on OSX and Linux? Or better, figure out a way for the
>>> system to fetch these automatically.
>>>
>>> - Evan
>>>
>>>
>>>
>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>
>>>> Just to summarize this thread, I was finally able to make all
>>>> performance comparisons that we discussed. It turns out that:
>>>> BIDMat-cublas>>BIDMat
>>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-repo=
>>>> =netlib-cublas>netlib-blas>f2jblas
>>>>
>>>> Below is the link to the spreadsheet with full results.
>>>>
>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx
>>>> 378T9J5r7kwKSPkY/edit?usp=sharing
>>>>
>>>> One thing still needs exploration: does BIDMat-cublas perform
>>>> copying to/from machine’s RAM?
>>>>
>>>> -----Original Message-----
>>>> From: Ulanov, Alexander
>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>>> To: Evan R. Sparks
>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Thanks, Evan! It seems that ticket was marked as duplicate though
>>>> the original one discusses slightly different topic. I was able to
>>>> link netlib with MKL from BIDMat binaries. Indeed, MKL is
>>>> statically linked inside a 60MB library.
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>>> |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>>> 1569,233228 |
>>>>
>>>> It turn out that pre-compiled MKL is faster than precompiled
>>>> OpenBlas on my machine. Probably, I’ll add two more columns with
>>>> locally compiled openblas and cuda.
>>>>
>>>> Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>]
>>>> Sent: Monday, February 09, 2015 6:06 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Great - perhaps we can move this discussion off-list and onto a
>>>> JIRA ticket? (Here's one:
>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>>>>
>>>> It seems like this is going to be somewhat exploratory for a while
>>>> (and there's probably only a handful of us who really care about
>>>> fast linear
>>>> algebra!)
>>>>
>>>> - Evan
>>>>
>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for explanation and useful link. I am going to build
>>>> OpenBLAS, link it with Netlib-java and perform benchmark again.
>>>>
>>>> Do I understand correctly that BIDMat binaries contain statically
>>>> linked Intel MKL BLAS? It might be the reason why I am able to run
>>>> BIDMat not having MKL BLAS installed on my server. If it is true, I
>>>> wonder if it is OK because Intel sells this library. Nevertheless,
>>>> it seems that in my case precompiled MKL BLAS performs better than
>>>> precompiled OpenBLAS given that BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>>
>>>> Though, it might be interesting to link Netlib-java with Intel MKL,
>>>> as you suggested. I wonder, are John Canny (BIDMat) and Sam
>>>> Halliday
>>>> (Netlib-java) interested to compare their libraries.
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:58 PM
>>>>
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I would build OpenBLAS yourself, since good BLAS performance comes
>>>> from getting cache sizes, etc. set up correctly for your particular
>>>> hardware - this is often a very tricky process (see, e.g. ATLAS),
>>>> but we found that on relatively modern Xeon chips, OpenBLAS builds
>>>> quickly and yields performance competitive with MKL.
>>>>
>>>> To make sure the right library is getting used, you have to make
>>>> sure it's first on the search path - export
>>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>>>>
>>>> For some examples of getting netlib-java setup on an ec2 node and
>>>> some example benchmarking code we ran a while back, see:
>>>> https://github.com/shivaram/matrix-bench
>>>>
>>>> In particular - build-openblas-ec2.sh shows you how to build the
>>>> library and set up symlinks correctly, and scala/run-netlib.sh
>>>> shows you how to get the path setup and get that library picked up by netlib-java.
>>>>
>>>> In this way - you could probably get cuBLAS set up to be used by
>>>> netlib-java as well.
>>>>
>>>> - Evan
>>>>
>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to
>>>> force loading the right blas? For netlib, I there are few JVM
>>>> flags, such as
>>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS,
>>>> so I can force it to use Java implementation. Not sure I understand how to force use a specific blas (not specific wrapper for blas).
>>>>
>>>> Btw. I have installed openblas (yum install openblas), so I suppose
>>>> that netlib is using it.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:19 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Getting breeze to pick up the right blas library is critical for
>>>> performance. I recommend using OpenBLAS (or MKL, if you already have it).
>>>> It might make sense to force BIDMat to use the same underlying BLAS
>>>> library as well.
>>>>
>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan, Joseph
>>>>
>>>> I did few matrix multiplication test and BIDMat seems to be ~10x
>>>> faster than netlib-java+breeze (sorry for weird table formatting):
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
>>>> |native_system_linux_x86-64|
>>>> Breeze+Netlib-java f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228
>>>> ||
>>>>
>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora
>>>> 19 Linux, Scala 2.11.
>>>>
>>>> Later I will make tests with Cuda. I need to install new Cuda
>>>> version for this purpose.
>>>>
>>>> Do you have any ideas why breeze-netlib with native blas is so much
>>>> slower than BIDMat MKL?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:joseph@databricks.com><mailto:
>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Evan R. Sparks;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Hi Alexander,
>>>>
>>>> Using GPUs with Spark would be very exciting.  Small comment:
>>>> Concerning your question earlier about keeping data stored on the
>>>> GPU rather than having to move it between main memory and GPU
>>>> memory on each iteration, I would guess this would be critical to
>>>> getting good performance.  If you could do multiple local
>>>> iterations before aggregating results, then the cost of data
>>>> movement to the GPU could be amortized (and I believe that is done
>>>> in practice).  Having Spark be aware of the GPU and using it as another part of memory sounds like a much bigger undertaking.
>>>>
>>>> Joseph
>>>>
>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Thank you for explanation! I’ve watched the BIDMach presentation by
>>>> John Canny and I am really inspired by his talk and comparisons with Spark MLlib.
>>>>
>>>> I am very interested to find out what will be better within Spark:
>>>> BIDMat or netlib-java with CPU or GPU natives. Could you suggest a
>>>> fair way to benchmark them? Currently I do benchmarks on artificial
>>>> neural networks in batch mode. While it is not a “pure” test of
>>>> linear algebra, it involves some other things that are essential to machine learning.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to
>>>> netlib-java+data
>>>> layout and fewer levels of indirection - it's definitely a
>>>> worthwhile experiment to run. The main speedups I've seen from
>>>> using it come from highly optimized GPU code for linear algebra. I
>>>> know that in the past Canny has gone as far as to write custom GPU
>>>> kernels for performance-critical regions of code.[1]
>>>>
>>>> BIDMach is highly optimized for single node performance or
>>>> performance on small clusters.[2] Once data doesn't fit easily in
>>>> GPU memory (or can be batched in that way) the performance tends to
>>>> fall off. Canny argues for hardware/software codesign and as such
>>>> prefers machine configurations that are quite different than what
>>>> we find in most commodity cluster nodes - e.g. 10 disk cahnnels and 4 GPUs.
>>>>
>>>> In contrast, MLlib was designed for horizontal scalability on
>>>> commodity clusters and works best on very big datasets - order of terabytes.
>>>>
>>>> For the most part, these projects developed concurrently to address
>>>> slightly different use cases. That said, there may be bits of
>>>> BIDMach we could repurpose for MLlib - keep in mind we need to be
>>>> careful about maintaining cross-language compatibility for our Java
>>>> and Python-users, though.
>>>>
>>>> - Evan
>>>>
>>>> [1] - http://arxiv.org/abs/1409.5402 [2] -
>>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>>
>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do
>>>> you know what makes them faster than netlib-java?
>>>>
>>>> The same group has BIDMach library that implements machine
>>>> learning. For some examples they use Caffe convolutional neural
>>>> network library owned by another group in Berkeley. Could you
>>>> elaborate on how these all might be connected with Spark Mllib? If
>>>> you take BIDMat for linear algebra why don’t you take BIDMach for optimization and learning?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU
>>>> blas in many cases.
>>>>
>>>> You might consider taking a look at the codepaths that BIDMat (
>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work
>>>> optimizing to make this work really fast from Scala. I've run it on
>>>> my laptop and compared to MKL and in certain cases it's 10x faster at matrix multiply.
>>>> There are a lot of layers of indirection here and you really want
>>>> to avoid data copying as much as possible.
>>>>
>>>> We could also consider swapping out BIDMat for Breeze, but that
>>>> would be a big project and if we can figure out how to get
>>>> breeze+cublas to comparable performance that would be a big win.
>>>>
>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Dear Spark developers,
>>>>
>>>> I am exploring how to make linear algebra operations faster within Spark.
>>>> One way of doing this is to use Scala Breeze library that is
>>>> bundled with Spark. For matrix operations, it employs Netlib-java
>>>> that has a Java wrapper for BLAS (basic linear algebra subprograms)
>>>> and LAPACK native binaries if they are available on the worker
>>>> node. It also has its own optimized Java implementation of BLAS. It
>>>> is worth mentioning, that native binaries provide better performance only for BLAS level 3, i.e.
>>>> matrix-matrix operations or general matrix multiplication (GEMM).
>>>> This is confirmed by GEMM test on Netlib-java page
>>>> https://github.com/fommil/netlib-java. I also confirmed it with my
>>>> experiments with training of artificial neural network
>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>>> However, I would like to boost performance more.
>>>>
>>>> GPU is supposed to work fast with linear algebra and there is
>>>> Nvidia CUDA implementation of BLAS, called cublas. I have one Linux
>>>> server with Nvidia GPU and I was able to do the following. I linked
>>>> cublas (instead of cpu-based blas) with Netlib-java wrapper and put
>>>> it into Spark, so Breeze/Netlib is using it. Then I did some
>>>> performance measurements with regards to artificial neural network
>>>> batch learning in Spark MLlib that involves matrix-matrix
>>>> multiplications. It turns out that for matrices of size less than
>>>> ~1000x780 GPU cublas has the same speed as CPU blas. Cublas becomes
>>>> slower for bigger matrices. It worth mentioning that it is was not a test for ONLY multiplication since there are other operations involved.
>>>> One of the reasons for slowdown might be the overhead of copying
>>>> the matrices from computer memory to graphic card memory and back.
>>>>
>>>> So, few questions:
>>>> 1) Do these results with CUDA make sense?
>>>> 2) If the problem is with copy overhead, are there any libraries
>>>> that allow to force intermediate results to stay in graphic card
>>>> memory thus removing the overhead?
>>>> 3) Any other options to speed-up linear algebra in Spark?
>>>>
>>>> Thank you, Alexander
>>>>
>>>> -------------------------------------------------------------------
>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org><mailto:
>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org>><mailto:dev-unsubscribe@spark.apac<mailto:dev-unsubscribe@spark.apac>
>>>> he.org<http://he.org> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org>>>
>>>> For additional commands, e-mail: dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
>>>>
>>>>
>>>>
>>>>
>>>

--
Best regards,
Sam
"
Saisai Shao <sai.sai.shao@gmail.com>,"Wed, 25 Mar 2015 10:35:23 +0800",Re: Understanding shuffle file name conflicts,Kannan Rajah <krajah@maprtech.com>,"Hi Kannan,

As I know the shuffle Id in ShuffleDependency will be increased, so even if
you run the same job twice, the shuffle dependency as well as shuffle id is
different, so the shuffle file name which is combined by
(shuffleId+mapId+reduceId) will be changed, so there's no name conflict
even in the same directory as I know.

Thanks
Jerry


2015-03-25 1:56 GMT+08:00 Kannan Rajah <krajah@maprtech.com>:

"
Zhiwei Chan <z.w.chan.jason@gmail.com>,"Wed, 25 Mar 2015 11:46:24 +0800","Spark SQL(1.3.0) ""import sqlContext.implicits._"" seems not work for
 converting a case class RDD to DataFrame",dev@spark.apache.org,"Hi all,

  I just upgraded spark from 1.2.1 to 1.3.0, and changed the ""import
sqlContext.createSchemaRDD"" to ""import sqlContext.implicits._"" in my code.
(I scan the programming guide and it seems this is the only change I need
to do). But it come to an error when run compile as following:
[ERROR] ...\magic.scala:527: error: value registerTempTable is not a member
of org.apache.spark.rdd.RDD[com.yhd.ycache.magic.Table]
[INFO]     tableRdd.registerTempTable(tableName)
<<<

Then I try the exactly example in the programming guide of 1.3  in
spark-shell, it come to the same error.
scala> sys.env.get(""CLASSPATH"")
res7: Option[String] =
Some(:/root/scala/spark-1.3.0-bin-hadoop2.4/conf:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/spark-assembly-1.3.0-hadoop2.4.0.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-core-3.2.10.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-rdbms-3.2.9.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-api-jdo-3.2.6.jar)

scala>  val sqlContext = new org.apache.spark.sql.SQLContext(sc)
sqlContext: org.apache.spark.sql.SQLContext =
org.apache.spark.sql.SQLContext@4b05b3ff

scala>  import sqlContext.implicits._
import sqlContext.implicits._

scala>  case class Person(name: String, age: Int)
defined class Person

scala>   val t1 =
sc.textFile(""hdfs://heju:8020/user/root/magic/poolInfo.txt"")
15/03/25 11:13:35 INFO MemoryStore: ensureFreeSpace(81443) called with
curMem=186397, maxMem=278302556
15/03/25 11:13:35 INFO MemoryStore: Block broadcast_3 stored as values in
memory (estimated size 79.5 KB, free 265.2 MB)
15/03/25 11:13:35 INFO MemoryStore: ensureFreeSpace(31262) called with
curMem=267840, maxMem=278302556
15/03/25 11:13:35 INFO MemoryStore: Block broadcast_3_piece0 stored as
bytes in memory (estimated size 30.5 KB, free 265.1 MB)
15/03/25 11:13:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory
on heju:48885 (size: 30.5 KB, free: 265.4 MB)
15/03/25 11:13:35 INFO BlockManagerMaster: Updated info of block
broadcast_3_piece0
15/03/25 11:13:35 INFO SparkContext: Created broadcast 3 from textFile at
<console>:34
t1: org.apache.spark.rdd.RDD[String] =
hdfs://heju:8020/user/root/magic/poolInfo.txt MapPartitionsRDD[9] at
textFile at <console>:34

scala>  val t2 = t1.flatMap(_.split(""\n"")).map(_.split("" "")).map(p =>
Person(p(0),1))
t2: org.apache.spark.rdd.RDD[Person] = MapPartitionsRDD[12] at map at
<console>:38

scala>  t2.registerTempTable(""people"")
<console>:41: error: value registerTempTable is not a member of
org.apache.spark.rdd.RDD[Person]
               t2.registerTempTable(""people"")
                  ^
<<<

I found the following explanation in programming guide about implicit
convert case class to DataFrams, but I don't understand what I should do.
Could any one tell me how should I do if I want to convert a case class RDD
to DataFrame?

Isolation of Implicit Conversions and Removal of dsl Package (Scala-only)

Many of the code examples prior to Spark 1.3 started with import
sqlContext._, which brought all of the functions from sqlContext into
scope. In Spark 1.3 we have isolated the implicit conversions for
converting RDDs into DataFrames into an object inside of the SQLContext.
Users should now write import sqlContext.implicits._.

Additionally, the implicit conversions now only augment RDDs that are
composed of Products (i.e., case classes or tuples) with a method toDF,
instead of applying automatically.

<<<
Thanks
Jason
"
Ted Yu <yuzhihong@gmail.com>,"Tue, 24 Mar 2015 21:07:10 -0700","Re: Spark SQL(1.3.0) ""import sqlContext.implicits._"" seems not work
 for converting a case class RDD to DataFrame",Zhiwei Chan <z.w.chan.jason@gmail.com>,"Please take a look at:
./sql/core/src/main/scala/org/apache/spark/sql/DataFrameHolder.scala
./sql/core/src/main/scala/org/apache/spark/sql/GroupedData.scala

Cheers


.
er
bin-hadoop2.4/lib/spark-assembly-1.3.0-hadoop2.4.0.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-core-3.2.10.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-rdbms-3.2.9.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-api-jdo-3.2.6.jar)
ry
DD
"
Reynold Xin <rxin@databricks.com>,"Tue, 24 Mar 2015 21:20:27 -0700","Re: Spark SQL(1.3.0) ""import sqlContext.implicits._"" seems not work
 for converting a case class RDD to DataFrame",Ted Yu <yuzhihong@gmail.com>,"In particular:

http://spark.apache.org/docs/latest/sql-programming-guide.html


""Additionally, the implicit conversions now only augment RDDs that are
composed of Products (i.e., case classes or tuples) with a method toDF,
instead of applying automatically.""




ed
bin-hadoop2.4/lib/spark-assembly-1.3.0-hadoop2.4.0.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-core-3.2.10.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-rdbms-3.2.9.jar:/root/scala/spark-1.3.0-bin-hadoop2.4/lib/datanucleus-api-jdo-3.2.6.jar)
in
at
=>
o.
y)
.
"
Patrick Wendell <pwendell@gmail.com>,"Tue, 24 Mar 2015 22:23:54 -0700",Re: hadoop input/output format advanced control,Koert Kuipers <koert@tresata.com>,"I see - if you look, in the saving functions we have the option for
the user to pass an arbitrary Configuration.

https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/PairRDDFunctions.scala#L894

It seems fine to have the same option for the loading functions, if
it's easy to just pass this config into the input format.




---------------------------------------------------------------------


"
Kannan Rajah <krajah@maprtech.com>,"Tue, 24 Mar 2015 23:04:32 -0700",Re: Understanding shuffle file name conflicts,Saisai Shao <sai.sai.shao@gmail.com>,"Saisai,
This is the not the case when I use spark-submit to run 2 jobs, one after
another. The shuffle id remains the same.


--
Kannan


"
Josh Rosen <rosenville@gmail.com>,"Tue, 24 Mar 2015 23:22:32 -0700",Re: Understanding shuffle file name conflicts,Kannan Rajah <krajah@maprtech.com>,"Which version of Spark are you using?  What do you mean when you say that
you used a hardcoded location for shuffle files?

If you look at the current DiskBlockManager code, it looks like it will
create a per-application subdirectory in each of the local root directories.

Here's the call to create a subdirectory in each root dir:
https://github.com/apache/spark/blob/c5cc41468e8709d09c09289bb55bc8edc99404b1/core/src/main/scala/org/apache/spark/storage/DiskBlockManager.scala#L126

This call to Utils.createDirectory() should result in a fresh subdirectory
being created for just this application (note the use of random UUIDs, plus
the check to ensure that the directory doesn't already exist):
https://github.com/apache/spark/blob/c5cc41468e8709d09c09289bb55bc8edc99404b1/core/src/main/scala/org/apache/spark/util/Utils.scala#L273

So, although the filenames for shuffle files are not globally unique, their
full paths should be unique due to these unique per-application
subdirectories.  Have you observed an instance where this isn't the case?

- Josh


"
Saisai Shao <sai.sai.shao@gmail.com>,"Wed, 25 Mar 2015 14:56:40 +0800",Re: Understanding shuffle file name conflicts,Kannan Rajah <krajah@maprtech.com>,"Yes as Josh said, when application is started, Spark will create a unique
application-wide folder for related temporary files. And jobs in this
application will have a unique shuffle id with unique file names, so
shuffle stages within app will not meet name conflicts.

Also shuffle files between applications are separated by application
folder, so the name conflicts cannot be happened.

Maybe you changed some parts of the code while do the patch.

Thanks
Jerry


2015-03-25 14:22 GMT+08:00 Josh Rosen <rosenville@gmail.com>:

"
Kannan Rajah <krajah@maprtech.com>,"Wed, 25 Mar 2015 00:03:38 -0700",Re: Understanding shuffle file name conflicts,Saisai Shao <sai.sai.shao@gmail.com>,"Josh & Saisai,
When I say I am using a hardcoded location for shuffle files, I mean that I
am not using DiskBlockManager.getFile API because that uses the directories
created locally on the node. But for my use case, I need to look at
creating those shuffle files on HDFS.

I will take a closer look at this. But I have a couple of questions. From
what I understand, DiskBlockManager code does not know about any
application ID. It seems to pick up the top root temp dir location from
SparkConf and then creates a bunch of sub dir under it. When a shuffle file
needs to be created using getFile API, it hashes it to one of the existing
dir. At this point, I don't see any app specific directory. Can you point
out what I am missing here? The getFile API does not involve the random
UUIDs. The random UUID generation happens inside createTempShuffleBlock and
DiskBlockManager.getFile is used to create the shuffle index and data file.


--
Kannan


"
Saisai Shao <sai.sai.shao@gmail.com>,"Wed, 25 Mar 2015 15:12:34 +0800",Re: Understanding shuffle file name conflicts,Kannan Rajah <krajah@maprtech.com>,"DIskBlockManager doesn't need to know the app id, all it need to do is to
create a folder with a unique name (UUID based) and then put all the
shuffle files into it.

you can see the code in DiskBlockManager as below, it will create a bunch
unique folders when initialized, these folders are app specific

private[spark] val localDirs: Array[File] = createLocalDirs(conf)

UUID is for creating an app specific folder. and shuffle file hashed by
shuffle block id, which is deterministic by using getFile as you mentioned.



2015-03-25 15:03 GMT+08:00 Kannan Rajah <krajah@maprtech.com>:

"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Wed, 25 Mar 2015 09:45:25 +0100",Can't assembly YARN project with SBT,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi!

I'm using the latest IntelliJ and I can't compile the yarn project into the
Spark assembly fat JAR. That is why I'm getting a SparkException with
message ""Unable to load YARN support"". The yarn project is also missing
from SBT tasks and I can't add it. How can I force sbt to include?

Thanks!

Zvara Zoltán



mail, hangout, skype: zoltan.zvara@gmail.com

mobile, viber: +36203129543

bank: 10918001-00000021-50480008

address: Hungary, 2475 Kápolnásnyék, Kossuth 6/a

elte: HSKSJZ (ZVZOAAI.ELTE)
"
Cheng Lian <lian.cs.zju@gmail.com>,"Wed, 25 Mar 2015 19:40:19 +0800",Re: Understanding shuffle file name conflicts,"Saisai Shao <sai.sai.shao@gmail.com>, 
 Kannan Rajah <krajah@maprtech.com>","Hi Jerry & Josh

It has been a while since the last time I looked into Spark core shuffle 
code, maybe I’m wrong here. But the shuffle ID is created along with 
ShuffleDependency, which is part of the RDD DAG. So if we submit 
multiple jobs over the same RDD DAG, I think the shuffle IDs in these 
jobs should duplicate. For example:

|val  dag  =  sc.parallelize(Array(1,2,3)).map(i => i -> i).reduceByKey(_ + _)
dag.collect()
dag.collect()
|

 From the debug log output, I did see duplicated shuffle IDs in both 
jobs. Something like this:

|# Job 1
15/03/25 19:26:34 DEBUG BlockStoreShuffleFetcher: Fetching outputs for shuffle 0, reduce 2

# Job 2
15/03/25 19:26:36 DEBUG BlockStoreShuffleFetcher: Fetching outputs for shuffle 0, reduce 5
|

So it’s also possible that some shuffle output files get reused in 
different jobs. But Kannan, did you submit separate jobs over the same 
RDD DAG as I did above? If not, I’d agree with Jerry and Josh.

(Did I miss something here?)

Cheng


​
"
=?UTF-8?Q?Zolt=C3=A1n_Zvara?= <zoltan.zvara@gmail.com>,"Wed, 25 Mar 2015 12:43:47 +0100",Re: Can't assembly YARN project with SBT,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi!

It seems that the problem of ""unable to load YARN support"" present only
when I run my job from code and by not using the spark-submit script. IMO
this is related to SPARK-5144
<https://issues.apache.org/jira/browse/SPARK-5144>. I'm running QueueStream
example with a single change: sparkConf.setMaster(""yarn-client"").

I'm building Spark with: sbt/sbt -Pyarn -Dhadoop.version=2.6.0 assembly

Zvara Zoltán



mail, hangout, skype: zoltan.zvara@gmail.com

mobile, viber: +36203129543

bank: 10918001-00000021-50480008

address: Hungary, 2475 Kápolnásnyék, Kossuth 6/a

elte: HSKSJZ (ZVZOAAI.ELTE)

2015-03-25 9:45 GMT+01:00 Zoltán Zvara <zoltan.zvara@gmail.com>:

"
Karlson <ksonspark@siberie.de>,"Wed, 25 Mar 2015 13:42:32 +0100",functools.partial as UserDefinedFunction,dev@spark.apache.org,"
Hi all,

passing a functools.partial-function as a UserDefinedFunction to 
DataFrame.select raises an AttributeException, because functools.partial 
does not have the attribute __name__. Is there any alternative to 
relying on __name__ in pyspark/sql/functions.py:126 ?


---------------------------------------------------------------------


"
"""Shao, Saisai"" <saisai.shao@intel.com>","Wed, 25 Mar 2015 13:31:25 +0000",RE: Understanding shuffle file name conflicts,"Cheng Lian <lian.cs.zju@gmail.com>, Saisai Shao <sai.sai.shao@gmail.com>,
	Kannan Rajah <krajah@maprtech.com>","Hi Cheng,

I think your scenario is acceptable for Spark's shuffle mechanism and will not occur shuffle file name conflicts. 

From my understanding I think the code snippet you mentioned is the same RDD graph, just running twice, these two jobs will generate 3 stages, map stage and collect stage for the first job, only collect stage for the second job (map stage is the same as previous job). So these two jobs will only generate one copy of shuffle files in the first job, and fetch the shuffle data twice for each job. So name conflicts will not be occurred, since these two jobs rely on the same ShuffledRDD. 

I think only shuffle write which generates shuffle files will have chance to meet name conflicts, multiple times of shuffle read is acceptable as the code snippet shows.

Thanks
Jerry



-----Original Message-----
From: Cheng Lian [mailto:lian.cs.zju@gmail.com] 
Sent: Wednesday, March 25, 2015 7:40 PM
To: Saisai Shao; Kannan Rajah
Cc: dev@spark.apache.org
Subject: Re: Understanding shuffle file name conflicts

Hi Jerry & Josh

It has been a while since the last time I looked into Spark core shuffle code, maybe I’m wrong here. But the shuffle ID is created along with ShuffleDependency, which is part of the RDD DAG. So if we submit multiple jobs over the same RDD DAG, I think the shuffle IDs in these jobs should duplicate. For example:

|val  dag  =  sc.parallelize(Array(1,2,3)).map(i => i -> 
|i).reduceByKey(_ + _)
dag.collect()
dag.collect()
|

 From the debug log output, I did see duplicated shuffle IDs in both jobs. Something like this:

|# Job 1
15/03/25 19:26:34 DEBUG BlockStoreShuffleFetcher: Fetching outputs for shuffle 0, reduce 2

# Job 2
15/03/25 19:26:36 DEBUG BlockStoreShuffleFetcher: Fetching outputs for shuffle 0, reduce 5
|

So it’s also possible that some shuffle output files get reused in different jobs. But Kannan, did you submit separate jobs over the same RDD DAG as I did above? If not, I’d agree with Jerry and Josh.

(Did I miss something here?)

Cheng

On 3/25/15 10:35 AM, Saisai Shao wrote:

> Hi Kannan,
>
> As I know the shuffle Id in ShuffleDependency will be increased, so 
> even if you run the same job twice, the shuffle dependency as well as 
> shuffle id is different, so the shuffle file name which is combined by
> (shuffleId+mapId+reduceId) will be changed, so there's no name 
> conflict even in the same directory as I know.
>
> Thanks
> Jerry
>
>
> 2015-03-25 1:56 GMT+08:00 Kannan Rajah <krajah@maprtech.com>:
>
>> I am working on SPARK-1529. I ran into an issue with my change, where 
>> the same shuffle file was being reused across 2 jobs. Please note 
>> this only happens when I use a hard coded location to use for shuffle 
>> files, say ""/tmp"". It does not happen with normal code path that uses 
>> DiskBlockManager to pick different directories for each run. So I 
>> want to understand how DiskBlockManager guarantees that such a conflict will never happen.
>>
>> Let's say the shuffle block id has a value of shuffle_0_0_0. So the 
>> data file name is shuffle_0_0_0.data and index file name is shuffle_0_0_0.index.
>> If I run a spark job twice, one after another, these files get 
>> created under different directories because of the hashing logic in 
>> DiskBlockManager. But the hash is based off the file name, so how are 
>> we sure that there won't be a conflict ever?
>>
>> --
>> Kannan
>>
​

---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
"
Koert Kuipers <koert@tresata.com>,"Wed, 25 Mar 2015 09:34:24 -0400",Re: hadoop input/output format advanced control,Patrick Wendell <pwendell@gmail.com>,"my personal preference would be something like a Map[String, String] that
only reflects the changes you want to make the Configuration for the given
input/output format (so system wide defaults continue to come from
sc.hadoopConfiguration), similarly to what cascading/scalding did, but am
arbitrary Configuration will work too.

i will make a jira and pullreq when i have some time.




"
Cheng Lian <lian.cs.zju@gmail.com>,"Wed, 25 Mar 2015 22:33:57 +0800",Re: Understanding shuffle file name conflicts,"""Shao, Saisai"" <saisai.shao@intel.com>, 
 Saisai Shao <sai.sai.shao@gmail.com>,
 Kannan Rajah <krajah@maprtech.com>","Ah, I see where I'm wrong here. What are reused here are the shuffle map 
output files themselves, rather than the file paths. No new shuffle map 
output files are generated for the 2nd job. Thanks! Really need to walk 
through Spark core code again :)

Cheng



---------------------------------------------------------------------


"
Debasish Das <debasish.das83@gmail.com>,"Wed, 25 Mar 2015 07:59:59 -0700",Re: mllib.recommendation Design,Xiangrui Meng <mengxr@gmail.com>,"Hi Xiangrui,

I am facing some minor issues in implementing Alternating Nonlinear
Minimization as documented in this JIRA due to the ALS code being in ml
package: https://issues.apache.org/jira/browse/SPARK-6323

I need to use Vectors.fromBreeze / Vectors.toBreeze but they are package
private on mllib. For now I removed private but not sure that's the correct
way...

I also need to re-use lot of building blocks from ml.ALS and so I am
writing ALM in ml package...

I thought the plan was to still write core algorithms in mllib and pipeline
integration in ml...It will be great if you can move the ALS object from ml
to mllib and that way I can also move ALM to mllib (which I feel is the
right place)...Of course the Pipeline based flow will stay in ml package...

We can decide later if ALM needs to be in recommendation or a better place
is package called factorization but the idea is that ALM will support MAP
(and may be KL divergence loss) with sparsity constraints (probability
simplex and bounds are fine for what I am focused at right now)...

Thanks.
Deb


"
Debasish Das <debasish.das83@gmail.com>,"Wed, 25 Mar 2015 08:15:09 -0700",LogisticGradient Design,dev <dev@spark.apache.org>,"Hi,

Right now LogisticGradient implements both binary and multi-class in the
same class using an if-else statement which is a bit convoluted.

For Generalized matrix factorization, if the data has distinct ratings I
want to use LeastSquareGradient (regression has given best results to date)
but if the data has binary labels 0/1 based on domain knowledge (implicit
for example, visits no-visits) I want to use a LogisticGradient without any
overhead for multi-class if-else...

I can compare the performance of LeastSquareGradient and multi-class
LogisticGradient on the recommendation metrics but it will be great if we
can separate binary and multi-class in Separate
classes....MultiClassLogistic can extend BinaryLogistic but mixing them in
the same class is an overhead for users (like me) who wants to use
BinaryLogistic for his application..

Thanks.
Deb
"
shane knapp <sknapp@berkeley.edu>,"Wed, 25 Mar 2015 10:02:57 -0700",jenkins upgraded to 1.606....,"amp-infra <amp-infra@googlegroups.com>, dev <dev@spark.apache.org>","...due to some big security fixes:

https://wiki.jenkins-ci.org/display/SECURITY/Jenkins+Security+Advisory+2015-03-23

:)

shane
"
Patrick Wendell <pwendell@gmail.com>,"Wed, 25 Mar 2015 11:41:46 -0700",Re: hadoop input/output format advanced control,Koert Kuipers <koert@tresata.com>,"Yeah I agree that might have been nicer, but I think for consistency
with the input API's maybe we should do the same thing. We can also
give an example of how to clone sc.hadoopConfiguration and then set
some new values:

val conf = sc.hadoopConfiguration.clone()
  .set(""k1"", ""v1"")
  .set(""k2"", ""v2"")

val rdd = sc.objectFile(..., conf)

I have no idea if that's the correct syntax, but something like that
seems almost as easy as passing a hashmap with deltas.

- Patrick


---------------------------------------------------------------------


"
Davies Liu <davies@databricks.com>,"Wed, 25 Mar 2015 11:49:08 -0700",Re: functools.partial as UserDefinedFunction,Karlson <ksonspark@siberie.de>,"It’s good to support functools.partial, could you file a JIRA for it?



ial  
to  
unsubscribe@spark.apache.org)
dev-help@spark.apache.org)


"
Marcelo Vanzin <vanzin@cloudera.com>,"Wed, 25 Mar 2015 11:51:36 -0700",Re: Experience using binary packages on various Hadoop distros,Patrick Wendell <pwendell@gmail.com>,"Hey Patrick,

The only issue I've seen so far has been the YARN container ID issue.
That can be technically be described as a breakage in forwards
compatibility in YARN. The APIs didn't break, but the data transferred
through YARN's protocol has, and the old library cannot understand the
data sent by a new service (the new container ID).

The main issue with publishing BYOH is what Matei already mentioned.
It would be worth it to take a look at what projects that depend on
Hadoop do, though.

Speaking with the Cloudera hat on, Spark in CDH is already ""BYOH"",
except Hadoop is already there with the rest of CDH.





-- 
Marcelo

---------------------------------------------------------------------


"
Joseph Bradley <joseph@databricks.com>,"Wed, 25 Mar 2015 11:57:15 -0700",Re: LogisticGradient Design,Debasish Das <debasish.das83@gmail.com>,"It would be nice to see how big a performance hit we take from combining
binary & multiclass logistic loss/gradient.  If it's not a big hit, then it
might be simpler from an outside API perspective to keep them in 1 class
(even if it's more complicated within).
Joseph


"
Koert Kuipers <koert@tresata.com>,"Wed, 25 Mar 2015 14:58:03 -0400",Re: hadoop input/output format advanced control,Patrick Wendell <pwendell@gmail.com>,"yeah fair enough


"
Imran Rashid <irashid@cloudera.com>,"Wed, 25 Mar 2015 15:42:32 -0500",Re: hadoop input/output format advanced control,Nick Pentreath <nick.pentreath@gmail.com>,"Hi Nick,

I don't remember the exact details of these scenarios, but I think the user
wanted a lot more control over how the files got grouped into partitions,
to group the files together by some arbitrary function.  I didn't think
that was possible w/ CombineFileInputFormat, but maybe there is a way?

thanks


"
Igor Costa <igorcosta@apache.org>,"Wed, 25 Mar 2015 17:51:31 -0300",Jira Issues,dev@spark.apache.org,"Hi there Guys.

I want to be more collaborative to Spark, but I have two questions.


Issues are used in Github or jira Issues?

If so on Jira, Is there a way I can get in to see the issues?

I've tried to login but no success.


I'm PMC from another Apache project, flex.apache.org


Best Regards
Igor
"
Reynold Xin <rxin@databricks.com>,"Wed, 25 Mar 2015 13:52:54 -0700",Re: Jira Issues,Igor Costa <igorcosta@apache.org>,"Igor,

Welcome -- everything is open here:
https://issues.apache.org/jira/browse/SPARK

You should be able to see them even if you are not an ASF member.



"
Ted Yu <yuzhihong@gmail.com>,"Wed, 25 Mar 2015 13:53:27 -0700",Re: Jira Issues,Igor Costa <igorcosta@apache.org>,"Issues are tracked on Apache JIRA:
https://issues.apache.org/jira/browse/SPARK/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel

Cheers


"
Sean Owen <sowen@cloudera.com>,"Wed, 25 Mar 2015 20:58:21 +0000",Re: Jira Issues,Igor Costa <igorcosta@apache.org>,"It's just the standard Apache JIRA, nothing separate.

I'd say JIRA is used to track issues, bugs, features, but Github is
where the concrete changes to implement those things are discussed and
merged. So for a non-trivial issue, you'd want to describe the issue
in general in JIRA, and then open a PR with the JIRA name in the title
to propose the code change, rather than submit a patch or something.


---------------------------------------------------------------------


"
Igor Costa <igorcosta@gmail.com>,"Wed, 25 Mar 2015 18:03:04 -0300",Re: Jira Issues,Sean Owen <sowen@cloudera.com>,"Thank you guys for the info.

Actually was a problem with my id on apache. Rather than need to be logged
in to view issues.

I'm browsing some issues now.


Best Regards

----------------------------
Igor Costa
www.igorcosta.com
www.igorcosta.org


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Wed, 25 Mar 2015 21:31:18 +0000",RE: Using CUDA within Spark / boosting linear algebra,Sam Halliday <sam.halliday@gmail.com>,"Hi again,

I finally managed to use nvblas within Spark+netlib-java. It has exceptional performance for big matrices with Double, faster than BIDMat-cuda with Float. But for smaller matrices, if you will copy them to/from GPU, OpenBlas or MKL might be a better choice. This correlates with original nvblas presentation on GPU conf 2013 (slide 21): http://on-demand.gputechconf.com/supercomputing/2013/presentation/SC3108-New-Features-CUDA%206%20-GPU-Acceleration.pdf
 
My results:
https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing 

Just in case, these tests are not for generalization of performance of different libraries. I just want to pick a library that does at best dense matrices multiplication for my task.

P.S. My previous issue with nvblas was the following: it has Fortran blas functions, at the same time netlib-java uses C cblas functions. So, one needs cblas shared library to use nvblas through netlib-java. Fedora does not have cblas (but Debian and Ubuntu have), so I needed to compile it. I could not use cblas from Atlas or Openblas because they link to their implementation and not to Fortran blas.

Best regards, Alexander

-----Original Message-----
From: Ulanov, Alexander 
Sent: Tuesday, March 24, 2015 6:57 PM
To: Sam Halliday
Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
Subject: RE: Using CUDA within Spark / boosting linear algebra

Hi,

I am trying to use nvblas with netlib-java from Spark. nvblas functions should replace current blas functions calls after executing LD_PRELOAD as suggested in http://docs.nvidia.com/cuda/nvblas/#Usage without any changes to netlib-java. It seems to work for simple Java example, but I cannot make it work with Spark. I run the following:
export LD_LIBRARY_PATH=/usr/local/cuda-6.5/lib64
env LD_PRELOAD=/usr/local/cuda-6.5/lib64/libnvblas.so ./spark-shell --driver-memory 4G In nvidia-smi I observe that Java is to use GPU:
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      8873    C   bash                                            39MiB |
|    0      8910    C   /usr/lib/jvm/java-1.7.0/bin/java                39MiB |
+-----------------------------------------------------------------------------+

In Spark shell I do matrix multiplication and see the following:
15/03/25 06:48:01 INFO JniLoader: successfully loaded /tmp/jniloader8192964377009965483netlib-native_system-linux-x86_64.so
So I am sure that netlib-native is loaded and cblas supposedly used. However, matrix multiplication does executes on CPU since I see 16% of CPU used and 0% of GPU used. I also checked different matrix sizes, from 100x100 to 12000x12000

Could you suggest might the LD_PRELOAD not affect Spark shell?

Best regards, Alexander



From: Sam Halliday [mailto:sam.halliday@gmail.com]
Sent: Monday, March 09, 2015 6:01 PM
To: Ulanov, Alexander
Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
Subject: RE: Using CUDA within Spark / boosting linear algebra


Thanks so much for following up on this!

Hmm, I wonder if we should have a concerted effort to chart performance on various pieces of hardware...
On 9 Mar 2015 21:08, ""Ulanov, Alexander"" <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
Hi Everyone, I've updated the benchmark as Xiangrui suggested. Added the comment that BIDMat 0.9.7 uses Float matrices in GPU (although I see the support of Double in the current source code), did the test with BIDMat and CPU Double matrices. BIDMat MKL is indeed on par with netlib MKL.

https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing

Best regards, Alexander

-----Original Message---15 1:54 PM
To: Xiangrui Meng; Joseph Bradley
Cc: Evan R. Sparks; Ulanov, Alexander; dev@spark.apache.org<mailto:dev@spark.apache.org>
Subject: Re: Using CUDA within Spark / boosting linear algebra

BTW, is anybody on this list going to the London Meetup in a few weeks?

https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-mapreduce-world#community

Would be nice to meet other people working on the guts of Spark! :-)


Xiangrui Meng <mengxr@gmail.com<mailto:mengxr@gmail.com>> writes:

> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x 
> slower than netlib-openblas. What is the overhead of using a GPU BLAS 
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com<mailto:joseph@databricks.com>> wrote:
>> Better documentation for linking would be very helpful!  Here's a JIRA:
>> https://issues.apache.org/jira/browse/SPARK-6019
>>
>>
>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks 
>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
>> wrote:
>>
>>> Thanks for compiling all the data and running these benchmarks, 
>>> Alex. The big takeaways here can be seen with this chart:
>>>
>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZ
>>> Hl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
>>>
>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>> BIDMat+GPU) can provide substantial (but less than an order of
>>> BIDMat+magnitude)
>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>>> netlib-java+openblas-compiled).
>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude 
>>> worse than a well-tuned CPU implementation, particularly for larger matrices.
>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this 
>>> basically agrees with the authors own benchmarks (
>>> https://github.com/fommil/netlib-java)
>>>
>>> I think that most of our users are in a situation where using GPUs 
>>> may not be practical - although we could consider having a good GPU 
>>> backend available as an option. However, *ALL* users of MLlib could 
>>> benefit (potentially tremendously) from using a well-tuned CPU-based 
>>> BLAS implementation. Perhaps we should consider updating the mllib 
>>> guide with a more complete section for enabling high performance 
>>> binaries on OSX and Linux? Or better, figure out a way for the 
>>> system to fetch these automatically.
>>>
>>> - Evan
>>>
>>>
>>>
>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander < 
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>
>>>> Just to summarize this thread, I was finally able to make all 
>>>> performance comparisons that we discussed. It turns out that:
>>>> BIDMat-cublas>>BIDMat
>>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-repo=
>>>> =netlib-cublas>netlib-blas>f2jblas
>>>>
>>>> Below is the link to the spreadsheet with full results.
>>>>
>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx
>>>> 378T9J5r7kwKSPkY/edit?usp=sharing
>>>>
>>>> One thing still needs exploration: does BIDMat-cublas perform 
>>>> copying to/from machine’s RAM?
>>>>
>>>> -----Original Message-----
>>>> From: Ulanov, Alexander
>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>>> To: Evan R. Sparks
>>>> Cc: Joseph Bradley; 
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Thanks, Evan! It seems that ticket was marked as duplicate though 
>>>> the original one discusses slightly different topic. I was able to 
>>>> link netlib with MKL from BIDMat binaries. Indeed, MKL is 
>>>> statically linked inside a 60MB library.
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>>> |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>>> 1569,233228 |
>>>>
>>>> It turn out that pre-compiled MKL is faster than precompiled 
>>>> OpenBlas on my machine. Probably, I’ll add two more columns with 
>>>> locally compiled openblas and cuda.
>>>>
>>>> Alexander
>>>>
>>>> From: Evan R. Sparks 
>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>]
>>>> Sent: Monday, February 09, 2015 6:06 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley; 
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Great - perhaps we can move this discussion off-list and onto a 
>>>> JIRA ticket? (Here's one:
>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>>>>
>>>> It seems like this is going to be somewhat exploratory for a while 
>>>> (and there's probably only a handful of us who really care about 
>>>> fast linear
>>>> algebra!)
>>>>
>>>> - Evan
>>>>
>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for explanation and useful link. I am going to build 
>>>> OpenBLAS, link it with Netlib-java and perform benchmark again.
>>>>
>>>> Do I understand correctly that BIDMat binaries contain statically 
>>>> linked Intel MKL BLAS? It might be the reason why I am able to run 
>>>> BIDMat not having MKL BLAS installed on my server. If it is true, I 
>>>> wonder if it is OK because Intel sells this library. Nevertheless, 
>>>> it seems that in my case precompiled MKL BLAS performs better than 
>>>> precompiled OpenBLAS given that BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>>
>>>> Though, it might be interesting to link Netlib-java with Intel MKL, 
>>>> as you suggested. I wonder, are John Canny (BIDMat) and Sam 
>>>> Halliday
>>>> (Netlib-java) interested to compare their libraries.
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:58 PM
>>>>
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I would build OpenBLAS yourself, since good BLAS performance comes 
>>>> from getting cache sizes, etc. set up correctly for your particular 
>>>> hardware - this is often a very tricky process (see, e.g. ATLAS), 
>>>> but we found that on relatively modern Xeon chips, OpenBLAS builds 
>>>> quickly and yields performance competitive with MKL.
>>>>
>>>> To make sure the right library is getting used, you have to make 
>>>> sure it's first on the search path - export 
>>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>>>>
>>>> For some examples of getting netlib-java setup on an ec2 node and 
>>>> some example benchmarking code we ran a while back, see:
>>>> https://github.com/shivaram/matrix-bench
>>>>
>>>> In particular - build-openblas-ec2.sh shows you how to build the 
>>>> library and set up symlinks correctly, and scala/run-netlib.sh 
>>>> shows you how to get the path setup and get that library picked up by netlib-java.
>>>>
>>>> In this way - you could probably get cuBLAS set up to be used by 
>>>> netlib-java as well.
>>>>
>>>> - Evan
>>>>
>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to 
>>>> force loading the right blas? For netlib, I there are few JVM 
>>>> flags, such as 
>>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS,
>>>> so I can force it to use Java implementation. Not sure I understand how to force use a specific blas (not specific wrapper for blas).
>>>>
>>>> Btw. I have installed openblas (yum install openblas), so I suppose 
>>>> that netlib is using it.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:19 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>
>>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Getting breeze to pick up the right blas library is critical for 
>>>> performance. I recommend using OpenBLAS (or MKL, if you already have it).
>>>> It might make sense to force BIDMat to use the same underlying BLAS 
>>>> library as well.
>>>>
>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan, Joseph
>>>>
>>>> I did few matrix multiplication test and BIDMat seems to be ~10x 
>>>> faster than netlib-java+breeze (sorry for weird table formatting):
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java 
>>>> |native_system_linux_x86-64|
>>>> Breeze+Netlib-java f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228
>>>> ||
>>>>
>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora
>>>> 19 Linux, Scala 2.11.
>>>>
>>>> Later I will make tests with Cuda. I need to install new Cuda 
>>>> version for this purpose.
>>>>
>>>> Do you have any ideas why breeze-netlib with native blas is so much 
>>>> slower than BIDMat MKL?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:joseph@databricks.com><mailto:
>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Evan R. Sparks;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Hi Alexander,
>>>>
>>>> Using GPUs with Spark would be very exciting.  Small comment:
>>>> Concerning your question earlier about keeping data stored on the 
>>>> GPU rather than having to move it between main memory and GPU 
>>>> memory on each iteration, I would guess this would be critical to 
>>>> getting good performance.  If you could do multiple local 
>>>> iterations before aggregating results, then the cost of data 
>>>> movement to the GPU could be amortized (and I believe that is done 
>>>> in practice).  Having Spark be aware of the GPU and using it as another part of memory sounds like a much bigger undertaking.
>>>>
>>>> Joseph
>>>>
>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Thank you for explanation! I’ve watched the BIDMach presentation by 
>>>> John Canny and I am really inspired by his talk and comparisons with Spark MLlib.
>>>>
>>>> I am very interested to find out what will be better within Spark:
>>>> BIDMat or netlib-java with CPU or GPU natives. Could you suggest a 
>>>> fair way to benchmark them? Currently I do benchmarks on artificial 
>>>> neural networks in batch mode. While it is not a “pure” test of 
>>>> linear algebra, it involves some other things that are essential to machine learning.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: 
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to 
>>>> netlib-java+data
>>>> layout and fewer levels of indirection - it's definitely a 
>>>> worthwhile experiment to run. The main speedups I've seen from 
>>>> using it come from highly optimized GPU code for linear algebra. I 
>>>> know that in the past Canny has gone as far as to write custom GPU 
>>>> kernels for performance-critical regions of code.[1]
>>>>
>>>> BIDMach is highly optimized for single node performance or 
>>>> performance on small clusters.[2] Once data doesn't fit easily in 
>>>> GPU memory (or can be batched in that way) the performance tends to 
>>>> fall off. Canny argues for hardware/software codesign and as such 
>>>> prefers machine configurations that are quite different than what 
>>>> we find in most commodity cluster nodes - e.g. 10 disk cahnnels and 4 GPUs.
>>>>
>>>> In contrast, MLlib was designed for horizontal scalability on 
>>>> commodity clusters and works best on very big datasets - order of terabytes.
>>>>
>>>> For the most part, these projects developed concurrently to address 
>>>> slightly different use cases. That said, there may be bits of 
>>>> BIDMach we could repurpose for MLlib - keep in mind we need to be 
>>>> careful about maintaining cross-language compatibility for our Java 
>>>> and Python-users, though.
>>>>
>>>> - Evan
>>>>
>>>> [1] - http://arxiv.org/abs/1409.5402 [2] - 
>>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>>
>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do 
>>>> you know what makes them faster than netlib-java?
>>>>
>>>> The same group has BIDMach library that implements machine 
>>>> learning. For some examples they use Caffe convolutional neural 
>>>> network library owned by another group in Berkeley. Could you 
>>>> elaborate on how these all might be connected with Spark Mllib? If 
>>>> you take BIDMat for linear algebra why don’t you take BIDMach for optimization and learning?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU 
>>>> blas in many cases.
>>>>
>>>> You might consider taking a look at the codepaths that BIDMat (
>>>> https://github.com/BIDData/BIDMat) takes and comparing them to 
>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work 
>>>> optimizing to make this work really fast from Scala. I've run it on 
>>>> my laptop and compared to MKL and in certain cases it's 10x faster at matrix multiply.
>>>> There are a lot of layers of indirection here and you really want 
>>>> to avoid data copying as much as possible.
>>>>
>>>> We could also consider swapping out BIDMat for Breeze, but that 
>>>> would be a big project and if we can figure out how to get
>>>> breeze+cublas to comparable performance that would be a big win.
>>>>
>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Dear Spark developers,
>>>>
>>>> I am exploring how to make linear algebra operations faster within Spark.
>>>> One way of doing this is to use Scala Breeze library that is 
>>>> bundled with Spark. For matrix operations, it employs Netlib-java 
>>>> that has a Java wrapper for BLAS (basic linear algebra subprograms) 
>>>> and LAPACK native binaries if they are available on the worker 
>>>> node. It also has its own optimized Java implementation of BLAS. It 
>>>> is worth mentioning, that native binaries provide better performance only for BLAS level 3, i.e.
>>>> matrix-matrix operations or general matrix multiplication (GEMM).
>>>> This is confirmed by GEMM test on Netlib-java page 
>>>> https://github.com/fommil/netlib-java. I also confirmed it with my 
>>>> experiments with training of artificial neural network 
>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>>> However, I would like to boost performance more.
>>>>
>>>> GPU is supposed to work fast with linear algebra and there is 
>>>> Nvidia CUDA implementation of BLAS, called cublas. I have one Linux 
>>>> server with Nvidia GPU and I was able to do the following. I linked 
>>>> cublas (instead of cpu-based blas) with Netlib-java wrapper and put 
>>>> it into Spark, so Breeze/Netlib is using it. Then I did some 
>>>> performance measurements with regards to artificial neural network 
>>>> batch learning in Spark MLlib that involves matrix-matrix 
>>>> multiplications. It turns out that for matrices of size less than
>>>> ~1000x780 GPU cublas has the same speed as CPU blas. Cublas becomes 
>>>> slower for bigger matrices. It worth mentioning that it is was not a test for ONLY multiplication since there are other operations involved.
>>>> One of the reasons for slowdown might be the overhead of copying 
>>>> the matrices from computer memory to graphic card memory and back.
>>>>
>>>> So, few questions:
>>>> 1) Do these results with CUDA make sense?
>>>> 2) If the problem is with copy overhead, are there any libraries 
>>>> that allow to force intermediate results to stay in graphic card 
>>>> memory thus removing the overhead?
>>>> 3) Any other options to speed-up linear algebra in Spark?
>>>>
>>>> Thank you, Alexander
>>>>
>>>> -------------------------------------------------------------------
>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org><mailto:
>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apach
>>>> e.org>><mailto:dev-unsubscribe@spark.apac<mailto:dev-unsubscribe@sp
>>>> ark.apac> he.org<http://he.org> 
>>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spa
>>>> rk.apache.org>>> For additional commands, e-mail: 
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
>>>>
>>>>
>>>>
>>>>
>>>

--
Best regards,
Sam
"
DB Tsai <dbtsai@dbtsai.com>,"Wed, 25 Mar 2015 14:37:54 -0700",Re: LogisticGradient Design,Joseph Bradley <joseph@databricks.com>,"I did the benchmark when I used the if-else statement to switch the
binary & multinomial logistic loss and gradient, and there is no
performance hit at all. However, I'm refactoring the LogisticGradient
code so the addBias and scaling can be done in LogisticGradient
instead of the input dataset to avoid the second cache. In this case,
the code will be more complicated, so I will split the code into two
paths. Will be done in another PR.

Sincerely,

DB Tsai
-------------------------------------------------------
Blog: https://www.dbtsai.com



---------------------------------------------------------------------


"
Debasish Das <debasish.das83@gmail.com>,"Wed, 25 Mar 2015 14:46:50 -0700",Re: LogisticGradient Design,DB Tsai <dbtsai@dbtsai.com>,"Cool...Thanks...It will be great if they move in two code paths just for
the sake of code clean-up


"
Dmitriy Lyubimov <dlieu.7@gmail.com>,"Wed, 25 Mar 2015 14:55:03 -0700",Re: Using CUDA within Spark / boosting linear algebra,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Alexander,

does using netlib imply that one cannot switch between CPU and GPU blas
alternatives at will at the same time? the choice is always determined by
linking aliternatives to libblas.so, right?


th
New-Features-CUDA%206%20-GPU-Acceleration.pdf
5r7kwKSPkY/edit?usp=sharing
e
-----+
=====================================================|
-----+
U
n
nd
5r7kwKSPkY/edit?usp=sharing
uce-world#community
:
m-repo=
with
y
tion by
 test of
4
h for
t
"
"""Evan R. Sparks"" <evan.sparks@gmail.com>","Wed, 25 Mar 2015 14:59:51 -0700",Re: Using CUDA within Spark / boosting linear algebra,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Alex - great stuff, and the nvblas numbers are pretty remarkable (almost
too good... did you check the results for correctness? - also, is it
possible that the ""unified memory model"" of nvblas is somehow hiding pci
transfer time?)

this last bit (getting nvblas + netlib-java to play together) sounds like
it's non-trivial and took you a while to figure out! Would you mind posting
a gist or something of maybe the shell scripts/exports you used to make
this work - I can imagine it being highly useful for others in the future.

Thanks!
Evan


th
New-Features-CUDA%206%20-GPU-Acceleration.pdf
5r7kwKSPkY/edit?usp=sharing
e
-----+
=====================================================|
-----+
U
n
nd
5r7kwKSPkY/edit?usp=sharing
uce-world#community
:
m-repo=
with
y
tion by
 test of
4
h for
t
"
Sam Halliday <sam.halliday@gmail.com>,"Wed, 25 Mar 2015 22:04:10 +0000",Re: Using CUDA within Spark / boosting linear algebra,"""Evan R. Sparks"" <evan.sparks@gmail.com>, dev@spark.apache.org","If you write it up I'll add it to the netlib-java wiki :-)

BTW, does it automatically flip between cpu/GPU? I've a project called
MultiBLAS which was going to do this, it should be easy (but boring to
write)

ng
.
ith
-New-Features-CUDA%206%20-GPU-Acceleration.pdf
J5r7kwKSPkY/edit?usp=sharing
se
s
s
I
s
------+
======================================================|
------+
PU
:
and
J5r7kwKSPkY/edit?usp=sharing
duce-world#community
A:
um-repo=
+
 with
e
+
ation by
h
 test of
ch for
e
a
:
"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Wed, 25 Mar 2015 22:04:30 +0000",RE: Using CUDA within Spark / boosting linear algebra,Dmitriy Lyubimov <dlieu.7@gmail.com>,"Netlib knows nothing about GPU (or CPU), it just uses cblas symbols from the provided libblas.so.3 library at the runtime. So, you can switch at the runtime by providing another library. Sam, please suggest if there is another way.

From: Dmitriy Lyubimov [mailto:dlieu.7@gmail.com]
Sent: Wednesday, March 25, 2015 2:55 PM
To: Ulanov, Alexander
Cc: Sam Halliday; dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. Sparks; jfcanny
Subject: Re: Using CUDA within Spark / boosting linear algebra

Alexander,

does using netlib imply that one cannot switch between CPU and GPU blas alternatives at will at the same time? the choice is always determined by linking aliternatives to libblas.so, right?

On Wed, Mar 25, 2015 at 2:31 PM, Ulanov, Alexander <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
Hi again,

I finally managed to use nvblas within Spark+netlib-java. It has exceptional performance for big matrices with Double, faster than BIDMat-cuda with Float. But for smaller matrices, if you will copy them to/from GPU, OpenBlas or MKL might be a better choice. This correlates with original nvblas presentation on GPU conf 2013 (slide 21): http://on-demand.gputechconf.com/supercomputing/2013/presentation/SC3108-New-Features-CUDA%206%20-GPU-Acceleration.pdf

My results:
https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing

Just in case, these tests are not for generalization of performance of different libraries. I just want to pick a library that does at best dense matrices multiplication for my task.

P.S. My previous issue with nvblas was the following: it has Fortran blas functions, at the same time netlib-java uses C cblas functions. So, one needs cblas shared library to use nvblas through netlib-java. Fedora does not have cblas (but Debian and Ubuntu have), so I needed to compile it. I could not use cblas from Atlas or Openblas because they link to their implementation and not to Fortran blas.

Best regards, Alexander

-----Original Message-----
From: Ulanov, Alexander
Sent: Tuesday, March 24, 2015 6:57 PM
To: Sam Halliday
Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
Subject: RE: Using CUDA within Spark / boosting linear algebra

Hi,

I am trying to use nvblas with netlib-java from Spark. nvblas functions should replace current blas functions calls after executing LD_PRELOAD as suggested in http://docs.nvidia.com/cuda/nvblas/#Usage without any changes to netlib-java. It seems to work for simple Java example, but I cannot make it work with Spark. I run the following:
export LD_LIBRARY_PATH=/usr/local/cuda-6.5/lib64
env LD_PRELOAD=/usr/local/cuda-6.5/lib64/libnvblas.so ./spark-shell --driver-memory 4G In nvidia-smi I observe that Java is to use GPU:
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      8873    C   bash                                            39MiB |
|    0      8910    C   /usr/lib/jvm/java-1.7.0/bin/java                39MiB |
+-----------------------------------------------------------------------------+

In Spark shell I do matrix multiplication and see the following:
15/03/25 06:48:01 INFO JniLoader: successfully loaded /tmp/jniloader8192964377009965483netlib-native_system-linux-x86_64.so
So I am sure that netlib-native is loaded and cblas supposedly used. However, matrix multiplication does executes on CPU since I see 16% of CPU used and 0% of GPU used. I also checked different matrix sizes, from 100x100 to 12000x12000

Could you suggest might the LD_PRELOAD not affect Spark shell?

Best regards, March 09, 2015 6:01 PM
To: Ulanov, Alexander
Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
Subject: RE: Using CUDA within Spark / boosting linear algebra


Thanks so much for following up on this!

Hmm, I wonder if we should have a concerted effort to chart performance on various pieces of hardware...
On 9 Mar 2015 21:08, ""Ulanov, Alexander"" <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
Hi Everyone, I've updated the benchmark as Xiangrui suggested. Added the comment that BIDMat 0.9.7 uses Float matrices in GPU (although I see the support of Double in the current source code), did the test with BIDMat and CPU Double matrices. BIDMat MKL is indeed on par with netlib MKL.

https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing

Best regards, Alexander

-----Original Message-----
From: Sam Halliday [mailto:sam.halli Tuesday, March 03, 2015 1:54 PM
To: Xiangrui Meng; Joseph Bradley
Cc: Evan R. Sparks; Ulanov, Alexander; dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
Subject: Re: Using CUDA within Spark / boosting linear algebra

BTW, is anybody on this list going to the London Meetup in a few weeks?

https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-mapreduce-world#community

Would be nice to meet other people working on the guts of Spark! :-)


Xiangrui Meng <mengxr@gmail.com<mailto:mengxr@gmail.com><mailto:mengxr@gmail.com<mailto:mengxr@gmail.com>>> writes:

> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x
> slower than netlib-openblas. What is the overhead of using a GPU BLAS
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com<mailto:joseph@databricks.com><mailto:joseph@databricks.com<mailto:joseph@databricks.com>>> wrote:
>> Better documentation for linking would be very helpful!  Here's a JIRA:
>> https://issues.apache.org/jira/browse/SPARK-6019
>>
>>
>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks
>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>
>> wrote:
>>
>>> Thanks for compiling all the data and running these benchmarks,
>>> Alex. The big takeaways here can be seen with this chart:
>>>
>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZ
>>> Hl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
>>>
>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>> BIDMat+GPU) can provide substantial (but less than an order of
>>> BIDMat+magnitude)
>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>>> netlib-java+openblas-compiled).
>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude
>>> worse than a well-tuned CPU implementation, particularly for larger matrices.
>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this
>>> basically agrees with the authors own benchmarks (
>>> https://github.com/fommil/netlib-java)
>>>
>>> I think that most of our users are in a situation where using GPUs
>>> may not be practical - although we could consider having a good GPU
>>> backend available as an option. However, *ALL* users of MLlib could
>>> benefit (potentially tremendously) from using a well-tuned CPU-based
>>> BLAS implementation. Perhaps we should consider updating the mllib
>>> guide with a more complete section for enabling high performance
>>> binaries on OSX and Linux? Or better, figure out a way for the
>>> system to fetch these automatically.
>>>
>>> - Evan
>>>
>>>
>>>
>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander <
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>
>>>> Just to summarize this thread, I was finally able to make all
>>>> performance comparisons that we discussed. It turns out that:
>>>> BIDMat-cublas>>BIDMat
>>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-repo=
>>>> =netlib-cublas>netlib-blas>f2jblas
>>>>
>>>> Below is the link to the spreadsheet with full results.
>>>>
>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx
>>>> 378T9J5r7kwKSPkY/edit?usp=sharing
>>>>
>>>> One thing still needs exploration: does BIDMat-cublas perform
>>>> copying to/from machine’s RAM?
>>>>
>>>> -----Original Message-----
>>>> From: Ulanov, Alexander
>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>>> To: Evan R. Sparks
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Thanks, Evan! It seems that ticket was marked as duplicate though
>>>> the original one discusses slightly different topic. I was able to
>>>> link netlib with MKL from BIDMat binaries. Indeed, MKL is
>>>> statically linked inside a 60MB library.
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>>> |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>>> 1569,233228 |
>>>>
>>>> It turn out that pre-compiled MKL is faster than precompiled
>>>> OpenBlas on my machine. Probably, I’ll add two more columns with
>>>> locally compiled openblas and cuda.
>>>>
>>>> Alexander
>>>>
>>>> From: Evan R. Sparks
>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Monday, February 09, 2015 6:06 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Great - perhaps we can move this discussion off-list and onto a
>>>> JIRA ticket? (Here's one:
>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>>>>
>>>> It seems like this is going to be somewhat exploratory for a while
>>>> (and there's probably only a handful of us who really care about
>>>> fast linear
>>>> algebra!)
>>>>
>>>> - Evan
>>>>
>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for explanation and useful link. I am going to build
>>>> OpenBLAS, link it with Netlib-java and perform benchmark again.
>>>>
>>>> Do I understand correctly that BIDMat binaries contain statically
>>>> linked Intel MKL BLAS? It might be the reason why I am able to run
>>>> BIDMat not having MKL BLAS installed on my server. If it is true, I
>>>> wonder if it is OK because Intel sells this library. Nevertheless,
>>>> it seems that in my case precompiled MKL BLAS performs better than
>>>> precompiled OpenBLAS given that BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>>
>>>> Though, it might be interesting to link Netlib-java with Intel MKL,
>>>> as you suggested. I wonder, are John Canny (BIDMat) and Sam
>>>> Halliday
>>>> (Netlib-java) interested to compare their libraries.
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>> Sent: Friday, February 06, 2015 5:58 PM
>>>>
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:dev@spark<mailto:dev@spark>.
>>>> apache.org<http://apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I would build OpenBLAS yourself, since good BLAS performance comes
>>>> from getting cache sizes, etc. set up correctly for your particular
>>>> hardware - this is often a very tricky process (see, e.g. ATLAS),
>>>> but we found that on relatively modern Xeon chips, OpenBLAS builds
>>>> quickly and yields performance competitive with MKL.
>>>>
>>>> To make sure the right library is getting used, you have to make
>>>> sure it's first on the search path - export
>>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>>>>
>>>> For some examples of getting netlib-java setup on an ec2 node and
>>>> some example benchmarking code we ran a while back, see:
>>>> https://github.com/shivaram/matrix-bench
>>>>
>>>> In particular - build-openblas-ec2.sh shows you how to build the
>>>> library and set up symlinks correctly, and scala/run-netlib.sh
>>>> shows you how to get the path setup and get that library picked up by netlib-java.
>>>>
>>>> In this way - you could probably get cuBLAS set up to be used by
>>>> netlib-java as well.
>>>>
>>>> - Evan
>>>>
>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to
>>>> force loading the right blas? For netlib, I there are few JVM
>>>> flags, such as
>>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS,
>>>> so I can force it to use Java implementation. Not sure I understand how to force use a specific blas (not specific wrapper for blas).
>>>>
>>>> Btw. I have installed openblas (yum install openblas), so I suppose
>>>> that netlib is using it.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>> Sent: Friday, February 06, 2015 5:19 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:dev@spark<mailto:dev@spark>.
>>>> apache.org<http://apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>>
>>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Getting breeze to pick up the right blas library is critical for
>>>> performance. I recommend using OpenBLAS (or MKL, if you already have it).
>>>> It might make sense to force BIDMat to use the same underlying BLAS
>>>> library as well.
>>>>
>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Hi Evan, Joseph
>>>>
>>>> I did few matrix multiplication test and BIDMat seems to be ~10x
>>>> faster than netlib-java+breeze (sorry for weird table formatting):
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java
>>>> |native_system_linux_x86-64|
>>>> Breeze+Netlib-java f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228
>>>> ||
>>>>
>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora
>>>> 19 Linux, Scala 2.11.
>>>>
>>>> Later I will make tests with Cuda. I need to install new Cuda
>>>> version for this purpose.
>>>>
>>>> Do you have any ideas why breeze-netlib with native blas is so much
>>>> slower than BIDMat MKL?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:joseph@databricks.com><mailto:joseph@databricks.com<mailto:joseph@databricks.com>><mailto:
>>>> joseph@databricks.com<mailto:joseph@databricks.com><mailto:joseph@databricks.com<mailto:joseph@databricks.com>>>]
>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Evan R. Sparks;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:dev@spark<mailto:dev@spark>.
>>>> apache.org<http://apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Hi Alexander,
>>>>
>>>> Using GPUs with Spark would be very exciting.  Small comment:
>>>> Concerning your question earlier about keeping data stored on the
>>>> GPU rather than having to move it between main memory and GPU
>>>> memory on each iteration, I would guess this would be critical to
>>>> getting good performance.  If you could do multiple local
>>>> iterations before aggregating results, then the cost of data
>>>> movement to the GPU could be amortized (and I believe that is done
>>>> in practice).  Having Spark be aware of the GPU and using it as another part of memory sounds like a much bigger undertaking.
>>>>
>>>> Joseph
>>>>
>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Thank you for explanation! I’ve watched the BIDMach presentation by
>>>> John Canny and I am really inspired by his talk and comparisons with Spark MLlib.
>>>>
>>>> I am very interested to find out what will be better within Spark:
>>>> BIDMat or netlib-java with CPU or GPU natives. Could you suggest a
>>>> fair way to benchmark them? Currently I do benchmarks on artificial
>>>> neural networks in batch mode. While it is not a “pure” test of
>>>> linear algebra, it involves some other things that are essential to machine learning.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc:
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:dev@spark<mailto:dev@spark>.
>>>> apache.org<http://apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to
>>>> netlib-java+data
>>>> layout and fewer levels of indirection - it's definitely a
>>>> worthwhile experiment to run. The main speedups I've seen from
>>>> using it come from highly optimized GPU code for linear algebra. I
>>>> know that in the past Canny has gone as far as to write custom GPU
>>>> kernels for performance-critical regions of code.[1]
>>>>
>>>> BIDMach is highly optimized for single node performance or
>>>> performance on small clusters.[2] Once data doesn't fit easily in
>>>> GPU memory (or can be batched in that way) the performance tends to
>>>> fall off. Canny argues for hardware/software codesign and as such
>>>> prefers machine configurations that are quite different than what
>>>> we find in most commodity cluster nodes - e.g. 10 disk cahnnels and 4 GPUs.
>>>>
>>>> In contrast, MLlib was designed for horizontal scalability on
>>>> commodity clusters and works best on very big datasets - order of terabytes.
>>>>
>>>> For the most part, these projects developed concurrently to address
>>>> slightly different use cases. That said, there may be bits of
>>>> BIDMach we could repurpose for MLlib - keep in mind we need to be
>>>> careful about maintaining cross-language compatibility for our Java
>>>> and Python-users, though.
>>>>
>>>> - Evan
>>>>
>>>> [1] - http://arxiv.org/abs/1409.5402 [2] -
>>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>>
>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do
>>>> you know what makes them faster than netlib-java?
>>>>
>>>> The same group has BIDMach library that implements machine
>>>> learning. For some examples they use Caffe convolutional neural
>>>> network library owned by another group in Berkeley. Could you
>>>> elaborate on how these all might be connected with Spark Mllib? If
>>>> you take BIDMat for linear algebra why don’t you take BIDMach for optimization and learning?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>>]
>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>><mailto:
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:dev@spark<mailto:dev@spark>.
>>>> apache.org<http://apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU
>>>> blas in many cases.
>>>>
>>>> You might consider taking a look at the codepaths that BIDMat (
>>>> https://github.com/BIDData/BIDMat) takes and comparing them to
>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work
>>>> optimizing to make this work really fast from Scala. I've run it on
>>>> my laptop and compared to MKL and in certain cases it's 10x faster at matrix multiply.
>>>> There are a lot of layers of indirection here and you really want
>>>> to avoid data copying as much as possible.
>>>>
>>>> We could also consider swapping out BIDMat for Breeze, but that
>>>> would be a big project and if we can figure out how to get
>>>> breeze+cublas to comparable performance that would be a big win.
>>>>
>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>>> wrote:
>>>> Dear Spark developers,
>>>>
>>>> I am exploring how to make linear algebra operations faster within Spark.
>>>> One way of doing this is to use Scala Breeze library that is
>>>> bundled with Spark. For matrix operations, it employs Netlib-java
>>>> that has a Java wrapper for BLAS (basic linear algebra subprograms)
>>>> and LAPACK native binaries if they are available on the worker
>>>> node. It also has its own optimized Java implementation of BLAS. It
>>>> is worth mentioning, that native binaries provide better performance only for BLAS level 3, i.e.
>>>> matrix-matrix operations or general matrix multiplication (GEMM).
>>>> This is confirmed by GEMM test on Netlib-java page
>>>> https://github.com/fommil/netlib-java. I also confirmed it with my
>>>> experiments with training of artificial neural network
>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>>> However, I would like to boost performance more.
>>>>
>>>> GPU is supposed to work fast with linear algebra and there is
>>>> Nvidia CUDA implementation of BLAS, called cublas. I have one Linux
>>>> server with Nvidia GPU and I was able to do the following. I linked
>>>> cublas (instead of cpu-based blas) with Netlib-java wrapper and put
>>>> it into Spark, so Breeze/Netlib is using it. Then I did some
>>>> performance measurements with regards to artificial neural network
>>>> batch learning in Spark MLlib that involves matrix-matrix
>>>> multiplications. It turns out that for matrices of size less than
>>>> ~1000x780 GPU cublas has the same speed as CPU blas. Cublas becomes
>>>> slower for bigger matrices. It worth mentioning that it is was not a test for ONLY multiplication since there are other operations involved.
>>>> One of the reasons for slowdown might be the overhead of copying
>>>> the matrices from computer memory to graphic card memory and back.
>>>>
>>>> So, few questions:
>>>> 1) Do these results with CUDA make sense?
>>>> 2) If the problem is with copy overhead, are there any libraries
>>>> that allow to force intermediate results to stay in graphic card
>>>> memory thus removing the overhead?
>>>> 3) Any other options to speed-up linear algebra in Spark?
>>>>
>>>> Thank you, Alexander
>>>>
>>>> -------------------------------------------------------------------
>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org><mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org>><mailto:
>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org><mailto:dev-unsubscribe@spark.apach<mailto:dev-unsubscribe@spark.apach>
>>>> e.org<http://e.org>>><mailto:dev-unsubscribe@spark.apac<mailto:dev-unsubscribe@spark.apac><mailto:dev-unsubscribe@sp<mailto:dev-unsubscribe@sp>
>>>> ark.apac> he.org<http://he.org><http://he.org>
>>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org><mailto:dev-unsubscribe@spa<mailto:dev-unsubscribe@spa>
>>>> rk.apache.org<http://rk.apache.org>>>> For additional commands, e-mail:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>>
>>>>
>>>>
>>>>
>>>>
>>>

--
Best regards,
Sam

"
Sam Halliday <sam.halliday@gmail.com>,"Wed, 25 Mar 2015 22:07:54 +0000",RE: Using CUDA within Spark / boosting linear algebra,Alexander Ulanov <alexander.ulanov@hp.com>,"Yeah, MultiBLAS... it is dynamic.

Except, I haven't written it yet :-P

he
th
New-Features-CUDA%206%20-GPU-Acceleration.pdf
5r7kwKSPkY/edit?usp=sharing
e
-----+
=====================================================|
-----+
U
n
nd
5r7kwKSPkY/edit?usp=sharing
uce-world#community
:
m-repo=
with
y
tion by
 test of
4
h for
t
"
jfcanny <canny@berkeley.edu>,"Wed, 25 Mar 2015 15:08:56 -0700 (MST)",Re: Using CUDA within Spark / boosting linear algebra,dev@spark.apache.org,"Alex,
I think you should recheck your numbers. Both BIDMat and nvblas are 
wrappers for cublas. The speeds are identical, except on machines that 
have multiple GPUs which nvblas exploits and cublas doesnt.

It would be a good idea to add a column with Gflop throughput. Your 
numbers for BIDMat 10kx10k multiply give about 300 single float gflops, 
which seems about right for a Quadro 4000 (current generation devices 
are > 10x faster than a 4000).

Your numbers for netlib-nvblas would indicate a double float throughput 
of 8 tflops, which is physically impossible on that device.

It shouldnt matter which interface you use if you have a single GPU.

-John

New-Features-CUDA%206%20-GPU-Acceleration.pdf
5r7kwKSPkY/edit?usp=sharing 
-----+ 
=====================================================| 
-----+ 
5r7kwKSPkY/edit?usp=sharing
uce-world#community
m-repo=
with
tion by
 test of
h for 
in-Spark-boosting-linear-algebra-tp10481p11238.html 
ervlet.jtp?macro=unsubscribe_by_code&node=10481&code=Y2FubnlAYmVya2VsZXkuZWR1fDEwNDgxfC00MzIwNjcxNzY=>.
ervlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml> 





--
3.nabble.com/Using-CUDA-within-Spark-boosting-linear-algebra-tp10481p11246.html
om."
Dmitriy Lyubimov <dlieu.7@gmail.com>,"Wed, 25 Mar 2015 15:16:50 -0700",Re: Using CUDA within Spark / boosting linear algebra,Sam Halliday <sam.halliday@gmail.com>,"Sam,

whould it be easier to hack netlib-java to allow multiple (configurable)
 library contexts? And so enable 3rd party configurations and optimizers to
make their own choices until then?


:
h
e
y
ith
-New-Features-CUDA%206%20-GPU-Acceleration.pdf
J5r7kwKSPkY/edit?usp=sharing
se
s
s
I
s
------+
======================================================|
------+
PU
:
and
J5r7kwKSPkY/edit?usp=sharing
duce-world#community
A:
um-repo=
+
 with
e
+
ation by
h
 test of
ch for
e
a
:
"
Sam Halliday <sam.halliday@gmail.com>,"Wed, 25 Mar 2015 22:20:45 +0000",Re: Using CUDA within Spark / boosting linear algebra,Dmitriy Lyubimov <dlieu.7@gmail.com>,"That would be a difficult task that would only benefit users of
netlib-java. MultiBLAS is easily implemented (although a lot of
boilerplate) and benefits all BLAS users on the system.

If anyone knows of a funding route for it, I'd love to hear from them,
because it's too much work for me to take on at the moment as hobby.

to
ch
re
by
with
8-New-Features-CUDA%206%20-GPU-Acceleration.pdf
9J5r7kwKSPkY/edit?usp=sharing
nse
,
a
e
heir
as
-------+
======================================================|
-------+
CPU
e
e
 and
9J5r7kwKSPkY/edit?usp=sharing
educe-world#community
m
Z
d
yum-repo=
x
-+
|
s with
I
d
,
.
r
o
,
d
e
.
S
-+
a
h
.
tation by
l
 test of
o
.
o
o
d
s
a
ach for
.
n
)
t
x
d
t
s
d.
-
:
h
p
a
:
"
Reza Zadeh <reza@databricks.com>,"Wed, 25 Mar 2015 15:28:21 -0700",Re: Using CUDA within Spark / boosting linear algebra,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","These are awesome (and surprising) results, Alex. I've been following this
thread and really surprised by the improvement over BIDMat-cuda, almost 20x
faster.

Any chance you could send scripts or github gist for reproduction?

Thanks,
Reza


th
New-Features-CUDA%206%20-GPU-Acceleration.pdf
5r7kwKSPkY/edit?usp=sharing
e
-----+
=====================================================|
-----+
U
n
nd
5r7kwKSPkY/edit?usp=sharing
uce-world#community
:
m-repo=
with
y
tion by
 test of
4
h for
t
"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Wed, 25 Mar 2015 22:27:47 +0000",RE: Using CUDA within Spark / boosting linear algebra,"Sam Halliday <sam.halliday@gmail.com>, ""Evan R. Sparks""
	<evan.sparks@gmail.com>, ""dev@spark.apache.org"" <dev@spark.apache.org>","Sure, I will write a how-to after I re-check the results.

-----Original Message-----
From: Sam Halliday [mailto:sam.halliday@gmail.com] 
Sent: Wednesday, March 25, 2015 3:04 PM
To: Evan R. Sparks; dev@spark.apache.org
Subject: Re: Using CUDA within Spark / boosting linear algebra

If you write it up I'll add it to the netlib-java wiki :-)

BTW, does it automatically flip between cpu/GPU? I've a project called MultiBLAS which was going to do this, it should be easy (but boring to
write)
On 25 Mar 2015 22:00, ""Evan R. Sparks"" <evan.sparks@gmail.com> wrote:

> Alex - great stuff, and the nvblas numbers are pretty remarkable 
> (almost too good... did you check the results for correctness? - also, 
> is it possible that the ""unified memory model"" of nvblas is somehow 
> hiding pci transfer time?)
>
> this last bit (getting nvblas + netlib-java to play together) sounds 
> like it's non-trivial and took you a while to figure out! Would you 
> mind posting a gist or something of maybe the shell scripts/exports 
> you used to make this work - I can imagine it being highly useful for others in the future.
>
> Thanks!
> Evan
>
> On Wed, Mar 25, 2015 at 2:31 PM, Ulanov, Alexander < 
> alexander.ulanov@hp.com> wrote:
>
>> Hi again,
>>
>> I finally managed to use nvblas within Spark+netlib-java. It has 
>> exceptional performance for big matrices with Double, faster than 
>> BIDMat-cuda with Float. But for smaller matrices, if you will copy 
>> them to/from GPU, OpenBlas or MKL might be a better choice. This 
>> correlates with original nvblas presentation on GPU conf 2013 (slide 21):
>> http://on-demand.gputechconf.com/supercomputing/2013/presentation/SC3
>> 108-New-Features-CUDA%206%20-GPU-Acceleration.pdf
>>
>> My results:
>>
>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx37
>> 8T9J5r7kwKSPkY/edit?usp=sharing
>>
>> Just in case, these tests are not for generalization of performance 
>> of different libraries. I just want to pick a library that does at 
>> best dense matrices multiplication for my task.
>>
>> P.S. My previous issue with nvblas was the following: it has Fortran 
>> blas functions, at the same time netlib-java uses C cblas functions. 
>> So, one needs cblas shared library to use nvblas through netlib-java. 
>> Fedora does not have cblas (but Debian and Ubuntu have), so I needed 
>> to compile it. I could not use cblas from Atlas or Openblas because 
>> they link to their implementation and not to Fortran blas.
>>
>> Best regards, Alexander
>>
>> -----Original Message-----
>> From: Ulanov, Alexander
>> Sent: Tuesday, March 24, 2015 6:57 PM
>> To: Sam Halliday
>> Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. 
>> Sparks
>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>
>> Hi,
>>
>> I am trying to use nvblas with netlib-java from Spark. nvblas 
>> functions should replace current blas functions calls after executing 
>> LD_PRELOAD as suggested in http://docs.nvidia.com/cuda/nvblas/#Usage 
>> without any changes to netlib-java. It seems to work for simple Java 
>> example, but I cannot make it work with Spark. I run the following:
>> export LD_LIBRARY_PATH=/usr/local/cuda-6.5/lib64
>> env LD_PRELOAD=/usr/local/cuda-6.5/lib64/libnvblas.so ./spark-shell 
>> --driver-memory 4G In nvidia-smi I observe that Java is to use GPU:
>>
>> +-----------------------------------------------------------------------------+
>> | Processes:                                                       GPU
>> Memory |
>> |  GPU       PID  Type  Process name                               Usage
>>     |
>>
>> |=============================================================================|
>> |    0      8873    C   bash
>> 39MiB |
>> |    0      8910    C   /usr/lib/jvm/java-1.7.0/bin/java
>> 39MiB |
>>
>> +-----------------------------------------------------------------------------+
>>
>> In Spark shell I do matrix multiplication and see the following:
>> 15/03/25 06:48:01 INFO JniLoader: successfully loaded 
>> /tmp/jniloader8192964377009965483netlib-native_system-linux-x86_64.so
>> So I am sure that netlib-native is loaded and cblas supposedly used.
>> However, matrix multiplication does executes on CPU since I see 16% 
>> of CPU used and 0% of GPU used. I also checked different matrix 
>> sizes, from
>> 100x100 to 12000x12000
>>
>> Could you suggest might the LD_PRELOAD not affect Spark shell?
>>
>> Best regards, Alexander
>>
>>
>>
>> Fr: Monday, March 09, 2015 6:01 PM
>> To: Ulanov, Alexander
>> Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. 
>> Sparks
>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>
>>
>> Thanks so much for following up on this!
>>
>> Hmm, I wonder if we should have a concerted effort to chart 
>> performance on various pieces of hardware...
>> On 9 Mar 2015 21:08, ""Ulanov, Alexander"" <alexander.ulanov@hp.com<mailto:
>> alexander.ulanov@hp.com>> wrote:
>> Hi Everyone, I've updated the benchmark as Xiangrui suggested. Added 
>> the comment that BIDMat 0.9.7 uses Float matrices in GPU (although I 
>> see the support of Double in the current source code), did the test 
>> with BIDMat and CPU Double matrices. BIDMat MKL is indeed on par with netlib MKL.
>>
>>
>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx37
>> 8T9J5r7kwKSPkY/edit?usp=sharing
>>
>> Best regards, Alexander
>>
>> -----Original Message-----
>> From: Sam Halliday [mailto:sam.halliday@gmail.com<mailto:
>> sam.halliday@gmail.com>]
>> Sent: Tuesday, March 03, 2015 1:54 PM
>> To: Xiangrui Meng; Joseph Bradley
>> Cc: Evan R. Sparks; Ulanov, Alexander; dev@spark.apache.org<mailto:
>> dev@spark.apache.org>
>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>
>> BTW, is anybody on this list going to the London Meetup in a few weeks?
>>
>>
>> https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-ma
>> preduce-world#community
>>
>> Would be nice to meet other people working on the guts of Spark! :-)
>>
>>
>> Xiangrui Meng <mengxr@gmail.com<mailto:mengxr@gmail.com>> writes:
>>
>> > Hey Alexander,
>> >
>> > I don't quite understand the part where netlib-cublas is about 20x 
>> > slower than netlib-openblas. What is the overhead of using a GPU 
>> > BLAS with netlib-java?
>> >
>> > CC'ed Sam, the author of netlib-java.
>> >
>> > Best,
>> > Xiangrui
>> >
>> > On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley 
>> > <joseph@databricks.com
>> <mailto:joseph@databricks.com>> wrote:
>> >> Better documentation for linking would be very helpful!  Here's a JIRA:
>> >> https://issues.apache.org/jira/browse/SPARK-6019
>> >>
>> >>
>> >> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks 
>> >> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
>> >> wrote:
>> >>
>> >>> Thanks for compiling all the data and running these benchmarks, 
>> >>> Alex. The big takeaways here can be seen with this chart:
>> >>>
>> >>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF5
>> >>> 0uZ Hl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
>> >>>
>> >>> 1) A properly configured GPU matrix multiply implementation (e.g.
>> >>> BIDMat+GPU) can provide substantial (but less than an order of
>> >>> BIDMat+magnitude)
>> >>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>> >>> netlib-java+openblas-compiled).
>> >>> 2) A poorly tuned CPU implementation can be 1-2 orders of 
>> >>> magnitude worse than a well-tuned CPU implementation, 
>> >>> particularly for larger
>> matrices.
>> >>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - 
>> >>> this basically agrees with the authors own benchmarks (
>> >>> https://github.com/fommil/netlib-java)
>> >>>
>> >>> I think that most of our users are in a situation where using 
>> >>> GPUs may not be practical - although we could consider having a 
>> >>> good GPU backend available as an option. However, *ALL* users of 
>> >>> MLlib could benefit (potentially tremendously) from using a 
>> >>> well-tuned CPU-based BLAS implementation. Perhaps we should 
>> >>> consider updating the mllib guide with a more complete section 
>> >>> for enabling high performance binaries on OSX and Linux? Or 
>> >>> better, figure out a way for the system to fetch these automatically.
>> >>>
>> >>> - Evan
>> >>>
>> >>>
>> >>>
>> >>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander < 
>> >>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>> >>>
>> >>>> Just to summarize this thread, I was finally able to make all 
>> >>>> performance comparisons that we discussed. It turns out that:
>> >>>> BIDMat-cublas>>BIDMat
>> >>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-re
>> >>>> po= =netlib-cublas>netlib-blas>f2jblas
>> >>>>
>> >>>> Below is the link to the spreadsheet with full results.
>> >>>>
>> >>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgH
>> >>>> UMx 378T9J5r7kwKSPkY/edit?usp=sharing
>> >>>>
>> >>>> One thing still needs exploration: does BIDMat-cublas perform 
>> >>>> copying to/from machine’s RAM?
>> >>>>
>> >>>> -----Original Message-----
>> >>>> From: Ulanov, Alexander
>> >>>> Sent: Tuesday, February 10, 2015 2:12 PM
>> >>>> To: Evan R. Sparks
>> >>>> Cc: Joseph Bradley;
>> >>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>> >>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>> >>>>
>> >>>> Thanks, Evan! It seems that ticket was marked as duplicate 
>> >>>> though the original one discusses slightly different topic. I 
>> >>>> was able to link netlib with MKL from BIDMat binaries. Indeed, 
>> >>>> MKL is statically linked inside a 60MB library.
>> >>>>
>> >>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>> >>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>> >>>>
>> +-----------------------------------------------------------------------+
>> >>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 
>> >>>> ||
>> >>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>> >>>> |1,638475459 |
>> >>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 
>> >>>> ||445,0935211 |
>> >>>> 1569,233228 |
>> >>>>
>> >>>> It turn out that pre-compiled MKL is faster than precompiled 
>> >>>> OpenBlas on my machine. Probably, I’ll add two more columns with 
>> >>>> locally compiled openblas and cuda.
>> >>>>
>> >>>> Alexander
>> >>>>
>> >>>> From: Evan R. Sparks
>> >>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>]
>> >>>> Sent: Monday, February 09, 2015 6:06 PM
>> >>>> To: Ulanov, Alexander
>> >>>> Cc: Joseph Bradley;
>> >>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>
>> >>>> Great - perhaps we can move this discussion off-list and onto a 
>> >>>> JIRA ticket? (Here's one:
>> >>>> https://issues.apache.org/jira/browse/SPARK-5705)
>> >>>>
>> >>>> It seems like this is going to be somewhat exploratory for a 
>> >>>> while (and there's probably only a handful of us who really care 
>> >>>> about fast linear
>> >>>> algebra!)
>> >>>>
>> >>>> - Evan
>> >>>>
>> >>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander <
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>> >>>> Hi Evan,
>> >>>>
>> >>>> Thank you for explanation and useful link. I am going to build 
>> >>>> OpenBLAS, link it with Netlib-java and perform benchmark again.
>> >>>>
>> >>>> Do I understand correctly that BIDMat binaries contain 
>> >>>> statically linked Intel MKL BLAS? It might be the reason why I 
>> >>>> am able to run BIDMat not having MKL BLAS installed on my 
>> >>>> server. If it is true, I wonder if it is OK because Intel sells 
>> >>>> this library. Nevertheless, it seems that in my case precompiled 
>> >>>> MKL BLAS performs better than precompiled OpenBLAS given that 
>> >>>> BIDMat and Netlib-java are supposed
>> to be on par with JNI overheads.
>> >>>>
>> >>>> Though, it might be interesting to link Netlib-java with Intel 
>> >>>> MKL, as you suggested. I wonder, are John Canny (BIDMat) and Sam 
>> >>>> Halliday
>> >>>> (Netlib-java) interested to compare their libraries.
>> >>>>
>> >>>> Best regards, Alexander
>> >>>>
>> >>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com><mailto:
>> >>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >>>> Sent: Friday, February 06, 2015 5:58 PM
>> >>>>
>> >>>> To: Ulanov, Alexander
>> >>>> Cc: Joseph Bradley;
>> >>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>> >>>> apache.org<mailto:dev@spark.apache.org>>
>> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>
>> >>>> I would build OpenBLAS yourself, since good BLAS performance 
>> >>>> comes from getting cache sizes, etc. set up correctly for your 
>> >>>> particular hardware - this is often a very tricky process (see, 
>> >>>> e.g. ATLAS), but we found that on relatively modern Xeon chips, 
>> >>>> OpenBLAS builds quickly and yields performance competitive with MKL.
>> >>>>
>> >>>> To make sure the right library is getting used, you have to make 
>> >>>> sure it's first on the search path - export 
>> >>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>> >>>>
>> >>>> For some examples of getting netlib-java setup on an ec2 node 
>> >>>> and some example benchmarking code we ran a while back, see:
>> >>>> https://github.com/shivaram/matrix-bench
>> >>>>
>> >>>> In particular - build-openblas-ec2.sh shows you how to build the 
>> >>>> library and set up symlinks correctly, and scala/run-netlib.sh 
>> >>>> shows you how to get the path setup and get that library picked 
>> >>>> up
>> by netlib-java.
>> >>>>
>> >>>> In this way - you could probably get cuBLAS set up to be used by 
>> >>>> netlib-java as well.
>> >>>>
>> >>>> - Evan
>> >>>>
>> >>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander <
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>> >>>> Evan, could you elaborate on how to force BIDMat and netlib-java 
>> >>>> to force loading the right blas? For netlib, I there are few JVM 
>> >>>> flags, such as 
>> >>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS
>> >>>> , so I can force it to use Java implementation. Not sure I 
>> >>>> understand
>> how to force use a specific blas (not specific wrapper for blas).
>> >>>>
>> >>>> Btw. I have installed openblas (yum install openblas), so I 
>> >>>> suppose that netlib is using it.
>> >>>>
>> >>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com><mailto:
>> >>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >>>> Sent: Friday, February 06, 2015 5:19 PM
>> >>>> To: Ulanov, Alexander
>> >>>> Cc: Joseph Bradley;
>> >>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>> >>>> apache.org<mailto:dev@spark.apache.org>>
>> >>>>
>> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>
>> >>>> Getting breeze to pick up the right blas library is critical for 
>> >>>> performance. I recommend using OpenBLAS (or MKL, if you already 
>> >>>> have
>> it).
>> >>>> It might make sense to force BIDMat to use the same underlying 
>> >>>> BLAS library as well.
>> >>>>
>> >>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander <
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>> >>>> Hi Evan, Joseph
>> >>>>
>> >>>> I did few matrix multiplication test and BIDMat seems to be ~10x 
>> >>>> faster than netlib-java+breeze (sorry for weird table formatting):
>> >>>>
>> >>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java 
>> >>>> |native_system_linux_x86-64|
>> >>>> Breeze+Netlib-java f2jblas |
>> >>>>
>> +-----------------------------------------------------------------------+
>> >>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>> >>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>> >>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 
>> >>>> |1569,233228
>> >>>> ||
>> >>>>
>> >>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, 
>> >>>> Fedora
>> >>>> 19 Linux, Scala 2.11.
>> >>>>
>> >>>> Later I will make tests with Cuda. I need to install new Cuda 
>> >>>> version for this purpose.
>> >>>>
>> >>>> Do you have any ideas why breeze-netlib with native blas is so 
>> >>>> much slower than BIDMat MKL?
>> >>>>
>> >>>> Best regards, Alexander
>> >>>>
>> >>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:
>> joseph@databricks.com><mailto:
>> >>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>> >>>> Sent: Thursday, February 05, 2015 5:29 PM
>> >>>> To: Ulanov, Alexander
>> >>>> Cc: Evan R. Sparks;
>> >>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>> >>>> apache.org<mailto:dev@spark.apache.org>>
>> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>
>> >>>> Hi Alexander,
>> >>>>
>> >>>> Using GPUs with Spark would be very exciting.  Small comment:
>> >>>> Concerning your question earlier about keeping data stored on 
>> >>>> the GPU rather than having to move it between main memory and 
>> >>>> GPU memory on each iteration, I would guess this would be 
>> >>>> critical to getting good performance.  If you could do multiple 
>> >>>> local iterations before aggregating results, then the cost of 
>> >>>> data movement to the GPU could be amortized (and I believe that 
>> >>>> is done in practice).  Having Spark be aware of the GPU and 
>> >>>> using it as
>> another part of memory sounds like a much bigger undertaking.
>> >>>>
>> >>>> Joseph
>> >>>>
>> >>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander <
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>> >>>> Thank you for explanation! I’ve watched the BIDMach presentation 
>> >>>> by John Canny and I am really inspired by his talk and 
>> >>>> comparisons with
>> Spark MLlib.
>> >>>>
>> >>>> I am very interested to find out what will be better within Spark:
>> >>>> BIDMat or netlib-java with CPU or GPU natives. Could you suggest 
>> >>>> a fair way to benchmark them? Currently I do benchmarks on 
>> >>>> artificial neural networks in batch mode. While it is not a 
>> >>>> “pure” test of linear algebra, it involves some other things 
>> >>>> that are essential to
>> machine learning.
>> >>>>
>> >>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com><mailto:
>> >>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>> >>>> Sent: Thursday, February 05, 2015 1:29 PM
>> >>>> To: Ulanov, Alexander
>> >>>> Cc:
>> >>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>> >>>> apache.org<mailto:dev@spark.apache.org>>
>> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>
>> >>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster 
>> >>>> than
>> >>>> netlib-java+OpenBLAS, but if it is much faster it's probably due 
>> >>>> netlib-java+to data
>> >>>> layout and fewer levels of indirection - it's definitely a 
>> >>>> worthwhile experiment to run. The main speedups I've seen from 
>> >>>> using it come from highly optimized GPU code for linear algebra. 
>> >>>> I know that in the past Canny has gone as far as to write custom 
>> >>>> GPU kernels for performance-critical regions of code.[1]
>> >>>>
>> >>>> BIDMach is highly optimized for single node performance or 
>> >>>> performance on small clusters.[2] Once data doesn't fit easily 
>> >>>> in GPU memory (or can be batched in that way) the performance 
>> >>>> tends to fall off. Canny argues for hardware/software codesign 
>> >>>> and as such prefers machine configurations that are quite 
>> >>>> different than what we find in most commodity cluster nodes - 
>> >>>> e.g. 10 disk cahnnels and
>> 4 GPUs.
>> >>>>
>> >>>> In contrast, MLlib was designed for horizontal scalability on 
>> >>>> commodity clusters and works best on very big datasets - order 
>> >>>> of
>> terabytes.
>> >>>>
>> >>>> For the most part, these projects developed concurrently to 
>> >>>> address slightly different use cases. That said, there may be 
>> >>>> bits of BIDMach we could repurpose for MLlib - keep in mind we 
>> >>>> need to be careful about maintaining cross-language 
>> >>>> compatibility for our Java and Python-users, though.
>> >>>>
>> >>>> - Evan
>> >>>>
>> >>>> [1] - http://arxiv.org/abs/1409.5402 [2] - 
>> >>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>> >>>>
>> >>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>> >>>> Hi Evan,
>> >>>>
>> >>>> Thank you for suggestion! BIDMat seems to have terrific speed. 
>> >>>> Do you know what makes them faster than netlib-java?
>> >>>>
>> >>>> The same group has BIDMach library that implements machine 
>> >>>> learning. For some examples they use Caffe convolutional neural 
>> >>>> network library owned by another group in Berkeley. Could you 
>> >>>> elaborate on how these all might be connected with Spark Mllib? 
>> >>>> If you take BIDMat for linear algebra why don’t you take BIDMach 
>> >>>> for
>> optimization and learning?
>> >>>>
>> >>>> Best regards, Alexander
>> >>>>
>> >>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:
>> evan.sparks@gmail.com><mailto:
>> >>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:
>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>> >>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>> >>>> Sent: Thursday, February 05, 2015 12:09 PM
>> >>>> To: Ulanov, Alexander
>> >>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:
>> dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
>> >>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>> >>>> apache.org<mailto:dev@spark.apache.org>>>
>> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>> >>>>
>> >>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU 
>> >>>> blas in many cases.
>> >>>>
>> >>>> You might consider taking a look at the codepaths that BIDMat (
>> >>>> https://github.com/BIDData/BIDMat) takes and comparing them to 
>> >>>> netlib-java/breeze. John Canny et. al. have done a bunch of work 
>> >>>> optimizing to make this work really fast from Scala. I've run it 
>> >>>> on my laptop and compared to MKL and in certain cases it's 10x 
>> >>>> faster
>> at matrix multiply.
>> >>>> There are a lot of layers of indirection here and you really 
>> >>>> want to avoid data copying as much as possible.
>> >>>>
>> >>>> We could also consider swapping out BIDMat for Breeze, but that 
>> >>>> would be a big project and if we can figure out how to get
>> >>>> breeze+cublas to comparable performance that would be a big win.
>> >>>>
>> >>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>> >>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:
>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>> >>>> Dear Spark developers,
>> >>>>
>> >>>> I am exploring how to make linear algebra operations faster 
>> >>>> within
>> Spark.
>> >>>> One way of doing this is to use Scala Breeze library that is 
>> >>>> bundled with Spark. For matrix operations, it employs 
>> >>>> Netlib-java that has a Java wrapper for BLAS (basic linear 
>> >>>> algebra subprograms) and LAPACK native binaries if they are 
>> >>>> available on the worker node. It also has its own optimized Java 
>> >>>> implementation of BLAS. It is worth mentioning, that native 
>> >>>> binaries provide better performance
>> only for BLAS level 3, i.e.
>> >>>> matrix-matrix operations or general matrix multiplication (GEMM).
>> >>>> This is confirmed by GEMM test on Netlib-java page 
>> >>>> https://github.com/fommil/netlib-java. I also confirmed it with 
>> >>>> my experiments with training of artificial neural network 
>> >>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>> >>>> However, I would like to boost performance more.
>> >>>>
>> >>>> GPU is supposed to work fast with linear algebra and there is 
>> >>>> Nvidia CUDA implementation of BLAS, called cublas. I have one 
>> >>>> Linux server with Nvidia GPU and I was able to do the following. 
>> >>>> I linked cublas (instead of cpu-based blas) with Netlib-java 
>> >>>> wrapper and put it into Spark, so Breeze/Netlib is using it. 
>> >>>> Then I did some performance measurements with regards to 
>> >>>> artificial neural network batch learning in Spark MLlib that 
>> >>>> involves matrix-matrix multiplications. It turns out that for 
>> >>>> matrices of size less than
>> >>>> ~1000x780 GPU cublas has the same speed as CPU blas. Cublas 
>> >>>> becomes slower for bigger matrices. It worth mentioning that it 
>> >>>> is was not a
>> test for ONLY multiplication since there are other operations involved.
>> >>>> One of the reasons for slowdown might be the overhead of copying 
>> >>>> the matrices from computer memory to graphic card memory and back.
>> >>>>
>> >>>> So, few questions:
>> >>>> 1) Do these results with CUDA make sense?
>> >>>> 2) If the problem is with copy overhead, are there any libraries 
>> >>>> that allow to force intermediate results to stay in graphic card 
>> >>>> memory thus removing the overhead?
>> >>>> 3) Any other options to speed-up linear algebra in Spark?
>> >>>>
>> >>>> Thank you, Alexander
>> >>>>
>> >>>> ----------------------------------------------------------------
>> >>>> ---
>> >>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:
>> dev-unsubscribe@spark.apache.org><mailto:
>> >>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.ap
>> >>>> ach 
>> >>>> e.org>><mailto:dev-unsubscribe@spark.apac<mailto:dev-unsubscribe
>> >>>> @sp
>> >>>> ark.apac> he.org<http://he.org>
>> >>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@
>> >>>> spa rk.apache.org>>> For additional commands, e-mail:
>> >>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>> >>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:
>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>> >>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>
>>
>> --
>> Best regards,
>> Sam
>>
>
>
"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Wed, 25 Mar 2015 22:29:16 +0000",RE: Using CUDA within Spark / boosting linear algebra,"jfcanny <canny@berkeley.edu>, ""dev@spark.apache.org""
	<dev@spark.apache.org>","John,

Thanks for your suggestion, it really seems strange. Though right now I have no idea what's wrong since I use exactly the same script for testing. I will appreciate any suggestions.

Best regards, Alexander

-----Original Message-----
From: jfcanny [mailto:canny@berkeley.edu] 
Sent: Wednesday, March 25, 2015 3:09 PM
To: dev@spark.apache.org
Subject: Re: Using CUDA within Spark / boosting linear algebra

Alex,
I think you should recheck your numbers. Both BIDMat and nvblas are wrappers for cublas. The speeds are identical, except on machines that have multiple GPUs which nvblas exploits and cublas doesnt.

It would be a good idea to add a column with Gflop throughput. Your numbers for BIDMat 10kx10k multiply give about 300 single float gflops, which seems about right for a Quadro 4000 (current generation devices are > 10x faster than a 4000).

Your numbers for netlib-nvblas would indicate a double float throughput of 8 tflops, which is physically impossible on that device.

It shouldnt matter which interface you use if you have a single GPU.

-John

On 3/25/2015 2:34 PM, Ulanov, Alexander [via Apache Spark Developers List] wrote:
> Hi again,
>
> I finally managed to use nvblas within Spark+netlib-java. It has 
> exceptional performance for big matrices with Double, faster than 
> BIDMat-cuda with Float. But for smaller matrices, if you will copy 
> them to/from GPU, OpenBlas or MKL might be a better choice. This 
> correlates with original nvblas presentation on GPU conf 2013 (slide
> 21): 
> http://on-demand.gputechconf.com/supercomputing/2013/presentation/SC31
> 08-New-Features-CUDA%206%20-GPU-Acceleration.pdf
>
> My results:
> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378
> T9J5r7kwKSPkY/edit?usp=sharing
>
>
> Just in case, these tests are not for generalization of performance of 
> different libraries. I just want to pick a library that does at best 
> dense matrices multiplication for my task.
>
> P.S. My previous issue with nvblas was the following: it has Fortran 
> blas functions, at the same time netlib-java uses C cblas functions.
> So, one needs cblas shared library to use nvblas through netlib-java. 
> Fedora does not have cblas (but Debian and Ubuntu have), so I needed 
> to compile it. I could not use cblas from Atlas or Openblas because 
> they link to their implementation and not to Fortran blas.
>
> Best regards, Alexander
>
> -----Original Message-----
> From: Ulanov, Alexander
> Sent: Tuesday, March 24, 2015 6:57 PM
> To: Sam Halliday
> Cc: [hidden email]; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
> Subject: RE: Using CUDA within Spark / boosting linear algebra
>
> Hi,
>
> I am trying to use nvblas with netlib-java from Spark. nvblas 
> functions should replace current blas functions calls after executing 
> LD_PRELOAD as suggested in http://docs.nvidia.com/cuda/nvblas/#Usage 
> without any changes to netlib-java. It seems to work for simple Java 
> example, but I cannot make it work with Spark. I run the following:
> export LD_LIBRARY_PATH=/usr/local/cuda-6.5/lib64
> env LD_PRELOAD=/usr/local/cuda-6.5/lib64/libnvblas.so ./spark-shell 
> --driver-memory 4G In nvidia-smi I observe that Java is to use GPU:
> +-----------------------------------------------------------------------------+ 
>
> | Processes: GPU Memory |
> |  GPU       PID  Type  Process name Usage      |
> |=====================================================================
> |========|
>
> |    0      8873    C   bash      39MiB |
> |    0      8910    C   /usr/lib/jvm/java-1.7.0/bin/java      39MiB |
> +-----------------------------------------------------------------------------+ 
>
>
> In Spark shell I do matrix multiplication and see the following:
> 15/03/25 06:48:01 INFO JniLoader: successfully loaded 
> /tmp/jniloader8192964377009965483netlib-native_system-linux-x86_64.so
> So I am sure that netlib-native is loaded and cblas supposedly used. 
> However, matrix multiplication does executes on CPU since I see 16% of 
> CPU used and 0% of GPU used. I also checked different matrix sizes, 
> from 100x100 to 12000x12000
>
> Could you suggest might the LD_PRELOAD not affect Spark shell?
>
> Best regards, Alexander
>
>
>
> From: Sam Halliday [mailto:[hidden email]]
> Sent: Monday, March 09, 2015 6:01 PM
> To: Ulanov, Alexander
> Cc: [hidden email]; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
> Subject: RE: Using CUDA within Spark / boosting linear algebra
>
>
> Thanks so much for following up on this!
>
> Hmm, I wonder if we should have a concerted effort to chart 
> performance on various pieces of hardware...
> On 9 Mar 2015 21:08, ""Ulanov, Alexander"" <[hidden 
> email]<mailto:[hidden email]>> wrote:
> Hi Everyone, I've updated the benchmark as Xiangrui suggested. Added 
> the comment that BIDMat 0.9.7 uses Float matrices in GPU (although I 
> see the support of Double in the current source code), did the test 
> with BIDMat and CPU Double matrices. BIDMat MKL is indeed on par with 
> netlib MKL.
>
> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378
> T9J5r7kwKSPkY/edit?usp=sharing
>
> Best regards, Alexander
>
> -----Original Message-----
> From: Sam Halliday [mailto:[hidden email]<mailto:[hidden email]>]
> Sent: Tuesday, March 03, 2015 1:54 PM
> To: Xiangrui Meng; Joseph Bradley
> Cc: Evan R. Sparks; Ulanov, Alexander; [hidden email]<mailto:[hidden 
> email]>
> Subject: Re: Using CUDA within Spark / boosting linear algebra
>
> BTW, is anybody on this list going to the London Meetup in a few weeks?
>
> https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-map
> reduce-world#community
>
> Would be nice to meet other people working on the guts of Spark! :-)
>
>
> Xiangrui Meng <[hidden email]<mailto:[hidden email]>> writes:
>
> > Hey Alexander,
> >
> > I don't quite understand the part where netlib-cublas is about 20x 
> > slower than netlib-openblas. What is the overhead of using a GPU 
> > BLAS with netlib-java?
> >
> > CC'ed Sam, the author of netlib-java.
> >
> > Best,
> > Xiangrui
> >
> > On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <[hidden
> email]<mailto:[hidden email]>> wrote:
> >> Better documentation for linking would be very helpful!  Here's a
> JIRA:
> >> https://issues.apache.org/jira/browse/SPARK-6019
> >>
> >>
> >> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks <[hidden 
> >> email]<mailto:[hidden email]>>
> >> wrote:
> >>
> >>> Thanks for compiling all the data and running these benchmarks, 
> >>> Alex. The big takeaways here can be seen with this chart:
> >>>
> >>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50
> >>> uZ Hl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
> >>>
> >>> 1) A properly configured GPU matrix multiply implementation (e.g.
> >>> BIDMat+GPU) can provide substantial (but less than an order of
> >>> BIDMat+magnitude)
> >>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
> >>> netlib-java+openblas-compiled).
> >>> 2) A poorly tuned CPU implementation can be 1-2 orders of 
> >>> magnitude worse than a well-tuned CPU implementation, particularly 
> >>> for
> larger matrices.
> >>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - 
> >>> this basically agrees with the authors own benchmarks (
> >>> https://github.com/fommil/netlib-java)
> >>>
> >>> I think that most of our users are in a situation where using GPUs 
> >>> may not be practical - although we could consider having a good 
> >>> GPU backend available as an option. However, *ALL* users of MLlib 
> >>> could benefit (potentially tremendously) from using a well-tuned 
> >>> CPU-based BLAS implementation. Perhaps we should consider updating 
> >>> the mllib guide with a more complete section for enabling high 
> >>> performance binaries on OSX and Linux? Or better, figure out a way 
> >>> for the system to fetch these automatically.
> >>>
> >>> - Evan
> >>>
> >>>
> >>>
> >>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander < [hidden 
> >>> email]<mailto:[hidden email]>> wrote:
> >>>
> >>>> Just to summarize this thread, I was finally able to make all 
> >>>> performance comparisons that we discussed. It turns out that:
> >>>> BIDMat-cublas>>BIDMat
> >>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-rep
> >>>> o= =netlib-cublas>netlib-blas>f2jblas
> >>>>
> >>>> Below is the link to the spreadsheet with full results.
> >>>>
> >>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHU
> >>>> Mx 378T9J5r7kwKSPkY/edit?usp=sharing
> >>>>
> >>>> One thing still needs exploration: does BIDMat-cublas perform 
> >>>> copying to/from machine’s RAM?
> >>>>
> >>>> -----Original Message-----
> >>>> From: Ulanov, Alexander
> >>>> Sent: Tuesday, February 10, 2015 2:12 PM
> >>>> To: Evan R. Sparks
> >>>> Cc: Joseph Bradley;
> >>>> [hidden email]<mailto:[hidden email]>
> >>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
> >>>>
> >>>> Thanks, Evan! It seems that ticket was marked as duplicate though 
> >>>> the original one discusses slightly different topic. I was able 
> >>>> to link netlib with MKL from BIDMat binaries. Indeed, MKL is 
> >>>> statically linked inside a 60MB library.
> >>>>
> >>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
> >>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
> >>>> 
> +-----------------------------------------------------------------------+
> >>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 
> >>>> ||
> >>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
> >>>> |1,638475459 |
> >>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 
> >>>> ||
> >>>> 1569,233228 |
> >>>>
> >>>> It turn out that pre-compiled MKL is faster than precompiled 
> >>>> OpenBlas on my machine. Probably, I’ll add two more columns with 
> >>>> locally compiled openblas and cuda.
> >>>>
> >>>> Alexander
> >>>>
> >>>> From: Evan R. Sparks
> >>>> [mailto:[hidden email]<mailto:[hidden email]>]
> >>>> Sent: Monday, February 09, 2015 6:06 PM
> >>>> To: Ulanov, Alexander
> >>>> Cc: Joseph Bradley;
> >>>> [hidden email]<mailto:[hidden email]>
> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>
> >>>> Great - perhaps we can move this discussion off-list and onto a 
> >>>> JIRA ticket? (Here's one:
> >>>> https://issues.apache.org/jira/browse/SPARK-5705)
> >>>>
> >>>> It seems like this is going to be somewhat exploratory for a 
> >>>> while (and there's probably only a handful of us who really care 
> >>>> about fast linear
> >>>> algebra!)
> >>>>
> >>>> - Evan
> >>>>
> >>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander < [hidden 
> >>>> email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>>> wrote:
> >>>> Hi Evan,
> >>>>
> >>>> Thank you for explanation and useful link. I am going to build 
> >>>> OpenBLAS, link it with Netlib-java and perform benchmark again.
> >>>>
> >>>> Do I understand correctly that BIDMat binaries contain statically 
> >>>> linked Intel MKL BLAS? It might be the reason why I am able to 
> >>>> run BIDMat not having MKL BLAS installed on my server. If it is 
> >>>> true, I wonder if it is OK because Intel sells this library. 
> >>>> Nevertheless, it seems that in my case precompiled MKL BLAS 
> >>>> performs better than precompiled OpenBLAS given that BIDMat and 
> >>>> Netlib-java are
> supposed to be on par with JNI overheads.
> >>>>
> >>>> Though, it might be interesting to link Netlib-java with Intel 
> >>>> MKL, as you suggested. I wonder, are John Canny (BIDMat) and Sam 
> >>>> Halliday
> >>>> (Netlib-java) interested to compare their libraries.
> >>>>
> >>>> Best regards, Alexander
> >>>>
> >>>> From: Evan R. Sparks [mailto:[hidden email]<mailto:[hidden
> email]><mailto:
> >>>> [hidden email]<mailto:[hidden email]>>]
> >>>> Sent: Friday, February 06, 2015 5:58 PM
> >>>>
> >>>> To: Ulanov, Alexander
> >>>> Cc: Joseph Bradley;
> >>>> [hidden email]<mailto:[hidden email]><mailto:dev@spark.
> >>>> apache.org<mailto:[hidden email]>>
> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>
> >>>> I would build OpenBLAS yourself, since good BLAS performance 
> >>>> comes from getting cache sizes, etc. set up correctly for your 
> >>>> particular hardware - this is often a very tricky process (see, 
> >>>> e.g. ATLAS), but we found that on relatively modern Xeon chips, 
> >>>> OpenBLAS builds quickly and yields performance competitive with MKL.
> >>>>
> >>>> To make sure the right library is getting used, you have to make 
> >>>> sure it's first on the search path - export 
> >>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
> >>>>
> >>>> For some examples of getting netlib-java setup on an ec2 node and 
> >>>> some example benchmarking code we ran a while back, see:
> >>>> https://github.com/shivaram/matrix-bench
> >>>>
> >>>> In particular - build-openblas-ec2.sh shows you how to build the 
> >>>> library and set up symlinks correctly, and scala/run-netlib.sh 
> >>>> shows you how to get the path setup and get that library picked
> up by netlib-java.
> >>>>
> >>>> In this way - you could probably get cuBLAS set up to be used by 
> >>>> netlib-java as well.
> >>>>
> >>>> - Evan
> >>>>
> >>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander < [hidden 
> >>>> email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>>> wrote:
> >>>> Evan, could you elaborate on how to force BIDMat and netlib-java 
> >>>> to force loading the right blas? For netlib, I there are few JVM 
> >>>> flags, such as 
> >>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS,
> >>>> so I can force it to use Java implementation. Not sure I
> understand how to force use a specific blas (not specific wrapper for 
> blas).
> >>>>
> >>>> Btw. I have installed openblas (yum install openblas), so I 
> >>>> suppose that netlib is using it.
> >>>>
> >>>> From: Evan R. Sparks [mailto:[hidden email]<mailto:[hidden
> email]><mailto:
> >>>> [hidden email]<mailto:[hidden email]>>]
> >>>> Sent: Friday, February 06, 2015 5:19 PM
> >>>> To: Ulanov, Alexander
> >>>> Cc: Joseph Bradley;
> >>>> [hidden email]<mailto:[hidden email]><mailto:dev@spark.
> >>>> apache.org<mailto:[hidden email]>>
> >>>>
> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>
> >>>> Getting breeze to pick up the right blas library is critical for 
> >>>> performance. I recommend using OpenBLAS (or MKL, if you already
> have it).
> >>>> It might make sense to force BIDMat to use the same underlying 
> >>>> BLAS library as well.
> >>>>
> >>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander < [hidden 
> >>>> email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>>> wrote:
> >>>> Hi Evan, Joseph
> >>>>
> >>>> I did few matrix multiplication test and BIDMat seems to be ~10x 
> >>>> faster than netlib-java+breeze (sorry for weird table formatting):
> >>>>
> >>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java 
> >>>> |native_system_linux_x86-64|
> >>>> Breeze+Netlib-java f2jblas |
> >>>> 
> +-----------------------------------------------------------------------+
> >>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
> >>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
> >>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 
> >>>> |1569,233228
> >>>> ||
> >>>>
> >>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, 
> >>>> Fedora
> >>>> 19 Linux, Scala 2.11.
> >>>>
> >>>> Later I will make tests with Cuda. I need to install new Cuda 
> >>>> version for this purpose.
> >>>>
> >>>> Do you have any ideas why breeze-netlib with native blas is so 
> >>>> much slower than BIDMat MKL?
> >>>>
> >>>> Best regards, Alexander
> >>>>
> >>>> From: Joseph Bradley [mailto:[hidden email]<mailto:[hidden
> email]><mailto:
> >>>> [hidden email]<mailto:[hidden email]>>]
> >>>> Sent: Thursday, February 05, 2015 5:29 PM
> >>>> To: Ulanov, Alexander
> >>>> Cc: Evan R. Sparks;
> >>>> [hidden email]<mailto:[hidden email]><mailto:dev@spark.
> >>>> apache.org<mailto:[hidden email]>>
> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>
> >>>> Hi Alexander,
> >>>>
> >>>> Using GPUs with Spark would be very exciting.  Small comment:
> >>>> Concerning your question earlier about keeping data stored on the 
> >>>> GPU rather than having to move it between main memory and GPU 
> >>>> memory on each iteration, I would guess this would be critical to 
> >>>> getting good performance.  If you could do multiple local 
> >>>> iterations before aggregating results, then the cost of data 
> >>>> movement to the GPU could be amortized (and I believe that is 
> >>>> done in practice).  Having Spark be aware of the GPU and using it 
> >>>> as
> another part of memory sounds like a much bigger undertaking.
> >>>>
> >>>> Joseph
> >>>>
> >>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander < [hidden 
> >>>> email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>>> wrote:
> >>>> Thank you for explanation! I’ve watched the BIDMach presentation 
> >>>> by John Canny and I am really inspired by his talk and 
> >>>> comparisons
> with Spark MLlib.
> >>>>
> >>>> I am very interested to find out what will be better within Spark:
> >>>> BIDMat or netlib-java with CPU or GPU natives. Could you suggest 
> >>>> a fair way to benchmark them? Currently I do benchmarks on 
> >>>> artificial neural networks in batch mode. While it is not a 
> >>>> “pure” test of linear algebra, it involves some other things that 
> >>>> are essential
> to machine learning.
> >>>>
> >>>> From: Evan R. Sparks [mailto:[hidden email]<mailto:[hidden
> email]><mailto:
> >>>> [hidden email]<mailto:[hidden email]>>]
> >>>> Sent: Thursday, February 05, 2015 1:29 PM
> >>>> To: Ulanov, Alexander
> >>>> Cc:
> >>>> [hidden email]<mailto:[hidden email]><mailto:dev@spark.
> >>>> apache.org<mailto:[hidden email]>>
> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>
> >>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
> >>>> netlib-java+OpenBLAS, but if it is much faster it's probably due 
> >>>> netlib-java+to data
> >>>> layout and fewer levels of indirection - it's definitely a 
> >>>> worthwhile experiment to run. The main speedups I've seen from 
> >>>> using it come from highly optimized GPU code for linear algebra. 
> >>>> I know that in the past Canny has gone as far as to write custom 
> >>>> GPU kernels for performance-critical regions of code.[1]
> >>>>
> >>>> BIDMach is highly optimized for single node performance or 
> >>>> performance on small clusters.[2] Once data doesn't fit easily in 
> >>>> GPU memory (or can be batched in that way) the performance tends 
> >>>> to fall off. Canny argues for hardware/software codesign and as 
> >>>> such prefers machine configurations that are quite different than 
> >>>> what we find in most commodity cluster nodes - e.g. 10 disk 
> >>>> cahnnels
> and 4 GPUs.
> >>>>
> >>>> In contrast, MLlib was designed for horizontal scalability on 
> >>>> commodity clusters and works best on very big datasets - order of
> terabytes.
> >>>>
> >>>> For the most part, these projects developed concurrently to 
> >>>> address slightly different use cases. That said, there may be 
> >>>> bits of BIDMach we could repurpose for MLlib - keep in mind we 
> >>>> need to be careful about maintaining cross-language compatibility 
> >>>> for our Java and Python-users, though.
> >>>>
> >>>> - Evan
> >>>>
> >>>> [1] - http://arxiv.org/abs/1409.5402 [2] - 
> >>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
> <http://eecs.berkeley.edu/%7Ehzhao/papers/BD.pdf>
> >>>>
> >>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander < [hidden 
> >>>> email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>><mailto:
> >>>> [hidden email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>>>> wrote:
> >>>> Hi Evan,
> >>>>
> >>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do 
> >>>> you know what makes them faster than netlib-java?
> >>>>
> >>>> The same group has BIDMach library that implements machine 
> >>>> learning. For some examples they use Caffe convolutional neural 
> >>>> network library owned by another group in Berkeley. Could you 
> >>>> elaborate on how these all might be connected with Spark Mllib? 
> >>>> If you take BIDMat for linear algebra why don’t you take BIDMach 
> >>>> for
> optimization and learning?
> >>>>
> >>>> Best regards, Alexander
> >>>>
> >>>> From: Evan R. Sparks [mailto:[hidden email]<mailto:[hidden
> email]><mailto:
> >>>> [hidden email]<mailto:[hidden email]>><mailto:[hidden
> email]<mailto:[hidden email]><mailto:
> >>>> [hidden email]<mailto:[hidden email]>>>]
> >>>> Sent: Thursday, February 05, 2015 12:09 PM
> >>>> To: Ulanov, Alexander
> >>>> Cc: [hidden email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>><mailto:
> >>>> [hidden email]<mailto:[hidden email]><mailto:dev@spark.
> >>>> apache.org<mailto:[hidden email]>>>
> >>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
> >>>>
> >>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU 
> >>>> blas in many cases.
> >>>>
> >>>> You might consider taking a look at the codepaths that BIDMat (
> >>>> https://github.com/BIDData/BIDMat) takes and comparing them to 
> >>>> netlib-java/breeze. John Canny et. al. have done a bunch of work 
> >>>> optimizing to make this work really fast from Scala. I've run it 
> >>>> on my laptop and compared to MKL and in certain cases it's 10x
> faster at matrix multiply.
> >>>> There are a lot of layers of indirection here and you really want 
> >>>> to avoid data copying as much as possible.
> >>>>
> >>>> We could also consider swapping out BIDMat for Breeze, but that 
> >>>> would be a big project and if we can figure out how to get
> >>>> breeze+cublas to comparable performance that would be a big win.
> >>>>
> >>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander < [hidden 
> >>>> email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>><mailto:
> >>>> [hidden email]<mailto:[hidden email]><mailto:[hidden
> email]<mailto:[hidden email]>>>> wrote:
> >>>> Dear Spark developers,
> >>>>
> >>>> I am exploring how to make linear algebra operations faster
> within Spark.
> >>>> One way of doing this is to use Scala Breeze library that is 
> >>>> bundled with Spark. For matrix operations, it employs Netlib-java 
> >>>> that has a Java wrapper for BLAS (basic linear algebra 
> >>>> subprograms) and LAPACK native binaries if they are available on 
> >>>> the worker node. It also has its own optimized Java 
> >>>> implementation of BLAS. It is worth mentioning, that native 
> >>>> binaries provide better
> performance only for BLAS level 3, i.e.
> >>>> matrix-matrix operations or general matrix multiplication (GEMM).
> >>>> This is confirmed by GEMM test on Netlib-java page 
> >>>> https://github.com/fommil/netlib-java. I also confirmed it with 
> >>>> my experiments with training of artificial neural network 
> >>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
> >>>> However, I would like to boost performance more.
> >>>>
> >>>> GPU is supposed to work fast with linear algebra and there is 
> >>>> Nvidia CUDA implementation of BLAS, called cublas. I have one 
> >>>> Linux server with Nvidia GPU and I was able to do the following. 
> >>>> I linked cublas (instead of cpu-based blas) with Netlib-java 
> >>>> wrapper and put it into Spark, so Breeze/Netlib is using it. Then 
> >>>> I did some performance measurements with regards to artificial 
> >>>> neural network batch learning in Spark MLlib that involves 
> >>>> matrix-matrix multiplications. It turns out that for matrices of 
> >>>> size less than
> >>>> ~1000x780 GPU cublas has the same speed as CPU blas. Cublas 
> >>>> becomes slower for bigger matrices. It worth mentioning that it 
> >>>> is was
> not a test for ONLY multiplication since there are other operations 
> involved.
> >>>> One of the reasons for slowdown might be the overhead of copying 
> >>>> the matrices from computer memory to graphic card memory and back.
> >>>>
> >>>> So, few questions:
> >>>> 1) Do these results with CUDA make sense?
> >>>> 2) If the problem is with copy overhead, are there any libraries 
> >>>> that allow to force intermediate results to stay in graphic card 
> >>>> memory thus removing the overhead?
> >>>> 3) Any other options to speed-up linear algebra in Spark?
> >>>>
> >>>> Thank you, Alexander
> >>>>
> >>>> -----------------------------------------------------------------
> >>>> --
> >>>> -- To unsubscribe, e-mail: [hidden email]<mailto:[hidden
> email]><mailto:
> >>>> [hidden email]<mailto:[hidden email] e.org>><mailto:[hidden 
> >>>> email]<mailto:dev-unsubscribe@sp ark.apac> he.org<http://he.org> 
> >>>> <mailto:[hidden email]<mailto:dev-unsubscribe@spa 
> >>>> rk.apache.org>>> For additional commands, e-mail:
> >>>> [hidden email]<mailto:[hidden email]><mailto:
> >>>> [hidden email]<mailto:[hidden email]>><mailto:[hidden
> email]<mailto:[hidden email]><mailto:
> >>>> [hidden email]<mailto:[hidden email]>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>
>
> --
> Best regards,
> Sam
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: [hidden email] For additional commands, 
> e-mail: [hidden email]
>
>
> ----------------------------------------------------------------------
> -- If you reply to this email, your message will be added to the 
> discussion below:
> http://apache-spark-developers-list.1001551.n3.nabble.com/Using-CUDA-w
> ithin-Spark-boosting-linear-algebra-tp10481p11238.html
>
> To unsubscribe from Using CUDA within Spark / boosting linear algebra, 
> click here 
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=10481&code=Y2FubnlAYmVya2VsZXkuZWR1fDEwNDgxfC00MzIwNjcxNzY=>.
> NAML
> <http://apache-spark-developers-list.1001551.n3.nabble.com/template/Na
> mlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml
> &base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.N
> abbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.t
> emplate.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcr
> umbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%
> 3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>





--
View this message in context: http://apache-spark-developers-list.1001551.n3.nabble.com/Using-CUDA-within-Spark-boosting-linear-algebra-tp10481p11246.html
Sent from the Apache Spark Developers List mailing list archive at Nabble.com.
"
"""alessandro.andrioni"" <alessandro.andrioni@dafiti.com.br>","Wed, 25 Mar 2015 16:35:33 -0700 (MST)",Re: lower&upperBound not working/spark 1/3,dev@spark.apache.org,"If I'm reading this comment[1] correctly, this is expected behavior: the
lower and upper bounds are used to make the partitioning more efficient, not
to limit the data returned.


I also got bit by this recently.

[1]:
https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/jdbc/JDBCRelation.scala#L49-L56


Marek Wiewiorka wrote









--

---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Thu, 26 Mar 2015 01:03:03 +0000",RE: Using CUDA within Spark / boosting linear algebra,Sam Halliday <sam.halliday@gmail.com>,"As everyone suggested, the results were too good to be true, so I double-checked them. It turns that nvblas did not do multiplication due to parameter NVBLAS_TILE_DIM from ""nvblas.conf"" and returned zero matrix. My previously posted results with nvblas are matrices copying only. The default NVBLAS_TILE_DIM==2048 is too big for my graphic card/matrix size. I handpicked other values that worked. As a result, netlib+nvblas is on par with BIDMat-cuda. As promised, I am going to post a how-to for nvblas configuration.

https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing



-----Original Message-----
From: Ulanov, Alexander 
Sent: Wednesday, March 25, 2015 2:31 PM
To: Sam Halliday
Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. Sparks; jfcanny
Subject: RE: Using CUDA within Spark / boosting linear algebra

Hi again,

I finally managed to use nvblas within Spark+netlib-java. It has exceptional performance for big matrices with Double, faster than BIDMat-cuda with Float. But for smaller matrices, if you will copy them to/from GPU, OpenBlas or MKL might be a better choice. This correlates with original nvblas presentation on GPU conf 2013 (slide 21): http://on-demand.gputechconf.com/supercomputing/2013/presentation/SC3108-New-Features-CUDA%206%20-GPU-Acceleration.pdf
 
My results:
https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing 

Just in case, these tests are not for generalization of performance of different libraries. I just want to pick a library that does at best dense matrices multiplication for my task.

P.S. My previous issue with nvblas was the following: it has Fortran blas functions, at the same time netlib-java uses C cblas functions. So, one needs cblas shared library to use nvblas through netlib-java. Fedora does not have cblas (but Debian and Ubuntu have), so I needed to compile it. I could not use cblas from Atlas or Openblas because they link to their implementation and not to Fortran blas.

Best regards, Alexander

-----Original Message-----
From: Ulanov, Alexander
Sent: Tuesday, March 24, 2015 6:57 PM
To: Sam Halliday
Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
Subject: RE: Using CUDA within Spark / boosting linear algebra

Hi,

I am trying to use nvblas with netlib-java from Spark. nvblas functions should replace current blas functions calls after executing LD_PRELOAD as suggested in http://docs.nvidia.com/cuda/nvblas/#Usage without any changes to netlib-java. It seems to work for simple Java example, but I cannot make it work with Spark. I run the following:
export LD_LIBRARY_PATH=/usr/local/cuda-6.5/lib64
env LD_PRELOAD=/usr/local/cuda-6.5/lib64/libnvblas.so ./spark-shell --driver-memory 4G In nvidia-smi I observe that Java is to use GPU:
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      8873    C   bash                                            39MiB |
|    0      8910    C   /usr/lib/jvm/java-1.7.0/bin/java                39MiB |
+-----------------------------------------------------------------------------+

In Spark shell I do matrix multiplication and see the following:
15/03/25 06:48:01 INFO JniLoader: successfully loaded /tmp/jniloader8192964377009965483netlib-native_system-linux-x86_64.so
So I am sure that netlib-native is loaded and cblas supposedly used. However, matrix multiplication does executes on CPU since I see 16% of CPU used and 0% of GPU used. I also checked different matrix sizes, from 100x100 to 12000x12000

Could you suggest might the LD_PRELOAD not affect Spark shell?

Best regards, Alexander



From: Sam Halliday [mailto:sam.halliday@gmail.com]
Sent: Monday, March 09, 2015 6:01 PM
To: Ulanov, Alexander
Cc: dev@spark.apache.org; Xiangrui Meng; Joseph Bradley; Evan R. Sparks
Subject: RE: Using CUDA within Spark / boosting linear algebra


Thanks so much for following up on this!

Hmm, I wonder if we should have a concerted effort to chart performance on various pieces of hardware...
On 9 Mar 2015 21:08, ""Ulanov, Alexander"" <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
Hi Everyone, I've updated the benchmark as Xiangrui suggested. Added the comment that BIDMat 0.9.7 uses Float matrices in GPU (although I see the support of Double in the current source code), did the test with BIDMat and CPU Double matrices. BIDMat MKL is indeed on par with netlib MKL.

https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing

Best regards, Alexander

-----Original Message-----
From: Sam Halliday [mailto:sam.halliday@gmail.com<mailto:sam.halliday@gmail.com>]
Sent: Tuesday, March 03, 2015 1:54 PM
To: Xiangrui Meng; Joseph Bradley
Cc: Evan R. Sparks; Ulanov, Alexander; dev@spark.apache.org<mailto:dev@spark.apache.org>
Subject: Re: Using CUDA within Spark / boosting linear algebra

BTW, is anybody on this list going to the London Meetup in a few weeks?

https://skillsmatter.com/meetups/6987-apache-spark-living-the-post-mapreduce-world#community

Would be nice to meet other people working on the guts of Spark! :-)


Xiangrui Meng <mengxr@gmail.com<mailto:mengxr@gmail.com>> writes:

> Hey Alexander,
>
> I don't quite understand the part where netlib-cublas is about 20x 
> slower than netlib-openblas. What is the overhead of using a GPU BLAS 
> with netlib-java?
>
> CC'ed Sam, the author of netlib-java.
>
> Best,
> Xiangrui
>
> On Wed, Feb 25, 2015 at 3:36 PM, Joseph Bradley <joseph@databricks.com<mailto:joseph@databricks.com>> wrote:
>> Better documentation for linking would be very helpful!  Here's a JIRA:
>> https://issues.apache.org/jira/browse/SPARK-6019
>>
>>
>> On Wed, Feb 25, 2015 at 2:53 PM, Evan R. Sparks 
>> <evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>
>> wrote:
>>
>>> Thanks for compiling all the data and running these benchmarks, 
>>> Alex. The big takeaways here can be seen with this chart:
>>>
>>> https://docs.google.com/spreadsheets/d/1aRm2IADRfXQV7G2vrcVh4StF50uZ
>>> Hl6kmAJeaZZggr0/pubchart?oid=1899767119&format=interactive
>>>
>>> 1) A properly configured GPU matrix multiply implementation (e.g.
>>> BIDMat+GPU) can provide substantial (but less than an order of
>>> BIDMat+magnitude)
>>> benefit over a well-tuned CPU implementation (e.g. BIDMat+MKL or
>>> netlib-java+openblas-compiled).
>>> 2) A poorly tuned CPU implementation can be 1-2 orders of magnitude 
>>> worse than a well-tuned CPU implementation, particularly for larger matrices.
>>> (netlib-f2jblas or netlib-ref) This is not to pick on netlib - this 
>>> basically agrees with the authors own benchmarks (
>>> https://github.com/fommil/netlib-java)
>>>
>>> I think that most of our users are in a situation where using GPUs 
>>> may not be practical - although we could consider having a good GPU 
>>> backend available as an option. However, *ALL* users of MLlib could 
>>> benefit (potentially tremendously) from using a well-tuned CPU-based 
>>> BLAS implementation. Perhaps we should consider updating the mllib 
>>> guide with a more complete section for enabling high performance 
>>> binaries on OSX and Linux? Or better, figure out a way for the 
>>> system to fetch these automatically.
>>>
>>> - Evan
>>>
>>>
>>>
>>> On Thu, Feb 12, 2015 at 4:18 PM, Ulanov, Alexander < 
>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>> wrote:
>>>
>>>> Just to summarize this thread, I was finally able to make all 
>>>> performance comparisons that we discussed. It turns out that:
>>>> BIDMat-cublas>>BIDMat
>>>> MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-repo=
>>>> =netlib-cublas>netlib-blas>f2jblas
>>>>
>>>> Below is the link to the spreadsheet with full results.
>>>>
>>>> https://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx
>>>> 378T9J5r7kwKSPkY/edit?usp=sharing
>>>>
>>>> One thing still needs exploration: does BIDMat-cublas perform 
>>>> copying to/from machine’s RAM?
>>>>
>>>> -----Original Message-----
>>>> From: Ulanov, Alexander
>>>> Sent: Tuesday, February 10, 2015 2:12 PM
>>>> To: Evan R. Sparks
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: RE: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Thanks, Evan! It seems that ticket was marked as duplicate though 
>>>> the original one discusses slightly different topic. I was able to 
>>>> link netlib with MKL from BIDMat binaries. Indeed, MKL is 
>>>> statically linked inside a 60MB library.
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-MKL  from BIDMat|
>>>> Breeze+Netlib-OpenBlas(native system)| Breeze+Netlib-f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,000381 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,038316857 | 0,51803557
>>>> |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 32,94546697 |445,0935211 |
>>>> 1569,233228 |
>>>>
>>>> It turn out that pre-compiled MKL is faster than precompiled 
>>>> OpenBlas on my machine. Probably, I’ll add two more columns with 
>>>> locally compiled openblas and cuda.
>>>>
>>>> Alexander
>>>>
>>>> From: Evan R. Sparks
>>>> [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>]
>>>> Sent: Monday, February 09, 2015 6:06 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Great - perhaps we can move this discussion off-list and onto a 
>>>> JIRA ticket? (Here's one:
>>>> https://issues.apache.org/jira/browse/SPARK-5705)
>>>>
>>>> It seems like this is going to be somewhat exploratory for a while 
>>>> (and there's probably only a handful of us who really care about 
>>>> fast linear
>>>> algebra!)
>>>>
>>>> - Evan
>>>>
>>>> On Mon, Feb 9, 2015 at 4:48 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for explanation and useful link. I am going to build 
>>>> OpenBLAS, link it with Netlib-java and perform benchmark again.
>>>>
>>>> Do I understand correctly that BIDMat binaries contain statically 
>>>> linked Intel MKL BLAS? It might be the reason why I am able to run 
>>>> BIDMat not having MKL BLAS installed on my server. If it is true, I 
>>>> wonder if it is OK because Intel sells this library. Nevertheless, 
>>>> it seems that in my case precompiled MKL BLAS performs better than 
>>>> precompiled OpenBLAS given that BIDMat and Netlib-java are supposed to be on par with JNI overheads.
>>>>
>>>> Though, it might be interesting to link Netlib-java with Intel MKL, 
>>>> as you suggested. I wonder, are John Canny (BIDMat) and Sam 
>>>> Halliday
>>>> (Netlib-java) interested to compare their libraries.
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:58 PM
>>>>
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I would build OpenBLAS yourself, since good BLAS performance comes 
>>>> from getting cache sizes, etc. set up correctly for your particular 
>>>> hardware - this is often a very tricky process (see, e.g. ATLAS), 
>>>> but we found that on relatively modern Xeon chips, OpenBLAS builds 
>>>> quickly and yields performance competitive with MKL.
>>>>
>>>> To make sure the right library is getting used, you have to make 
>>>> sure it's first on the search path - export 
>>>> LD_LIBRARY_PATH=/path/to/blas/library.so will do the trick here.
>>>>
>>>> For some examples of getting netlib-java setup on an ec2 node and 
>>>> some example benchmarking code we ran a while back, see:
>>>> https://github.com/shivaram/matrix-bench
>>>>
>>>> In particular - build-openblas-ec2.sh shows you how to build the 
>>>> library and set up symlinks correctly, and scala/run-netlib.sh 
>>>> shows you how to get the path setup and get that library picked up by netlib-java.
>>>>
>>>> In this way - you could probably get cuBLAS set up to be used by 
>>>> netlib-java as well.
>>>>
>>>> - Evan
>>>>
>>>> On Fri, Feb 6, 2015 at 5:43 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Evan, could you elaborate on how to force BIDMat and netlib-java to 
>>>> force loading the right blas? For netlib, I there are few JVM 
>>>> flags, such as 
>>>> -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS,
>>>> so I can force it to use Java implementation. Not sure I understand how to force use a specific blas (not specific wrapper for blas).
>>>>
>>>> Btw. I have installed openblas (yum install openblas), so I suppose 
>>>> that netlib is using it.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Friday, February 06, 2015 5:19 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Joseph Bradley;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>
>>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Getting breeze to pick up the right blas library is critical for 
>>>> performance. I recommend using OpenBLAS (or MKL, if you already have it).
>>>> It might make sense to force BIDMat to use the same underlying BLAS 
>>>> library as well.
>>>>
>>>> On Fri, Feb 6, 2015 at 4:42 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Hi Evan, Joseph
>>>>
>>>> I did few matrix multiplication test and BIDMat seems to be ~10x 
>>>> faster than netlib-java+breeze (sorry for weird table formatting):
>>>>
>>>> |A*B  size | BIDMat MKL | Breeze+Netlib-java 
>>>> |native_system_linux_x86-64|
>>>> Breeze+Netlib-java f2jblas |
>>>> +-----------------------------------------------------------------------+
>>>> |100x100*100x100 | 0,00205596 | 0,03810324 | 0,002556 |
>>>> |1000x1000*1000x1000 | 0,018320947 | 0,51803557 |1,638475459 |
>>>> |10000x10000*10000x10000 | 23,78046632 | 445,0935211 | 1569,233228
>>>> ||
>>>>
>>>> Configuration: Intel(R) Xeon(R) CPU E31240 3.3 GHz, 6GB RAM, Fedora
>>>> 19 Linux, Scala 2.11.
>>>>
>>>> Later I will make tests with Cuda. I need to install new Cuda 
>>>> version for this purpose.
>>>>
>>>> Do you have any ideas why breeze-netlib with native blas is so much 
>>>> slower than BIDMat MKL?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Joseph Bradley [mailto:joseph@databricks.com<mailto:joseph@databricks.com><mailto:
>>>> joseph@databricks.com<mailto:joseph@databricks.com>>]
>>>> Sent: Thursday, February 05, 2015 5:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: Evan R. Sparks;
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> Hi Alexander,
>>>>
>>>> Using GPUs with Spark would be very exciting.  Small comment:
>>>> Concerning your question earlier about keeping data stored on the 
>>>> GPU rather than having to move it between main memory and GPU 
>>>> memory on each iteration, I would guess this would be critical to 
>>>> getting good performance.  If you could do multiple local 
>>>> iterations before aggregating results, then the cost of data 
>>>> movement to the GPU could be amortized (and I believe that is done 
>>>> in practice).  Having Spark be aware of the GPU and using it as another part of memory sounds like a much bigger undertaking.
>>>>
>>>> Joseph
>>>>
>>>> On Thu, Feb 5, 2015 at 4:59 PM, Ulanov, Alexander < 
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>> wrote:
>>>> Thank you for explanation! I’ve watched the BIDMach presentation by 
>>>> John Canny and I am really inspired by his talk and comparisons with Spark MLlib.
>>>>
>>>> I am very interested to find out what will be better within Spark:
>>>> BIDMat or netlib-java with CPU or GPU natives. Could you suggest a 
>>>> fair way to benchmark them? Currently I do benchmarks on artificial 
>>>> neural networks in batch mode. While it is not a “pure” test of 
>>>> linear algebra, it involves some other things that are essential to machine learning.
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>]
>>>> Sent: Thursday, February 05, 2015 1:29 PM
>>>> To: Ulanov, Alexander
>>>> Cc: 
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd be surprised of BIDMat+OpenBLAS was significantly faster than
>>>> netlib-java+OpenBLAS, but if it is much faster it's probably due to 
>>>> netlib-java+data
>>>> layout and fewer levels of indirection - it's definitely a 
>>>> worthwhile experiment to run. The main speedups I've seen from 
>>>> using it come from highly optimized GPU code for linear algebra. I 
>>>> know that in the past Canny has gone as far as to write custom GPU 
>>>> kernels for performance-critical regions of code.[1]
>>>>
>>>> BIDMach is highly optimized for single node performance or 
>>>> performance on small clusters.[2] Once data doesn't fit easily in 
>>>> GPU memory (or can be batched in that way) the performance tends to 
>>>> fall off. Canny argues for hardware/software codesign and as such 
>>>> prefers machine configurations that are quite different than what 
>>>> we find in most commodity cluster nodes - e.g. 10 disk cahnnels and 4 GPUs.
>>>>
>>>> In contrast, MLlib was designed for horizontal scalability on 
>>>> commodity clusters and works best on very big datasets - order of terabytes.
>>>>
>>>> For the most part, these projects developed concurrently to address 
>>>> slightly different use cases. That said, there may be bits of 
>>>> BIDMach we could repurpose for MLlib - keep in mind we need to be 
>>>> careful about maintaining cross-language compatibility for our Java 
>>>> and Python-users, though.
>>>>
>>>> - Evan
>>>>
>>>> [1] - http://arxiv.org/abs/1409.5402 [2] - 
>>>> http://eecs.berkeley.edu/~hzhao/papers/BD.pdf
>>>>
>>>> On Thu, Feb 5, 2015 at 1:00 PM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Hi Evan,
>>>>
>>>> Thank you for suggestion! BIDMat seems to have terrific speed. Do 
>>>> you know what makes them faster than netlib-java?
>>>>
>>>> The same group has BIDMach library that implements machine 
>>>> learning. For some examples they use Caffe convolutional neural 
>>>> network library owned by another group in Berkeley. Could you 
>>>> elaborate on how these all might be connected with Spark Mllib? If 
>>>> you take BIDMat for linear algebra why don’t you take BIDMach for optimization and learning?
>>>>
>>>> Best regards, Alexander
>>>>
>>>> From: Evan R. Sparks [mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>><mailto:evan.sparks@gmail.com<mailto:evan.sparks@gmail.com><mailto:
>>>> evan.sparks@gmail.com<mailto:evan.sparks@gmail.com>>>]
>>>> Sent: Thursday, February 05, 2015 12:09 PM
>>>> To: Ulanov, Alexander
>>>> Cc: dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.apache.org<mailto:dev@spark.apache.org>><mailto:
>>>> dev@spark.apache.org<mailto:dev@spark.apache.org><mailto:dev@spark.
>>>> apache.org<mailto:dev@spark.apache.org>>>
>>>> Subject: Re: Using CUDA within Spark / boosting linear algebra
>>>>
>>>> I'd expect that we can make GPU-accelerated BLAS faster than CPU 
>>>> blas in many cases.
>>>>
>>>> You might consider taking a look at the codepaths that BIDMat (
>>>> https://github.com/BIDData/BIDMat) takes and comparing them to 
>>>> netlib-java/breeze. John Canny et. al. have done a bunch of work 
>>>> optimizing to make this work really fast from Scala. I've run it on 
>>>> my laptop and compared to MKL and in certain cases it's 10x faster at matrix multiply.
>>>> There are a lot of layers of indirection here and you really want 
>>>> to avoid data copying as much as possible.
>>>>
>>>> We could also consider swapping out BIDMat for Breeze, but that 
>>>> would be a big project and if we can figure out how to get
>>>> breeze+cublas to comparable performance that would be a big win.
>>>>
>>>> On Thu, Feb 5, 2015 at 11:55 AM, Ulanov, Alexander <
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>><mailto:
>>>> alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>>> wrote:
>>>> Dear Spark developers,
>>>>
>>>> I am exploring how to make linear algebra operations faster within Spark.
>>>> One way of doing this is to use Scala Breeze library that is 
>>>> bundled with Spark. For matrix operations, it employs Netlib-java 
>>>> that has a Java wrapper for BLAS (basic linear algebra subprograms) 
>>>> and LAPACK native binaries if they are available on the worker 
>>>> node. It also has its own optimized Java implementation of BLAS. It 
>>>> is worth mentioning, that native binaries provide better performance only for BLAS level 3, i.e.
>>>> matrix-matrix operations or general matrix multiplication (GEMM).
>>>> This is confirmed by GEMM test on Netlib-java page 
>>>> https://github.com/fommil/netlib-java. I also confirmed it with my 
>>>> experiments with training of artificial neural network 
>>>> https://github.com/apache/spark/pull/1290#issuecomment-70313952.
>>>> However, I would like to boost performance more.
>>>>
>>>> GPU is supposed to work fast with linear algebra and there is 
>>>> Nvidia CUDA implementation of BLAS, called cublas. I have one Linux 
>>>> server with Nvidia GPU and I was able to do the following. I linked 
>>>> cublas (instead of cpu-based blas) with Netlib-java wrapper and put 
>>>> it into Spark, so Breeze/Netlib is using it. Then I did some 
>>>> performance measurements with regards to artificial neural network 
>>>> batch learning in Spark MLlib that involves matrix-matrix 
>>>> multiplications. It turns out that for matrices of size less than
>>>> ~1000x780 GPU cublas has the same speed as CPU blas. Cublas becomes 
>>>> slower for bigger matrices. It worth mentioning that it is was not a test for ONLY multiplication since there are other operations involved.
>>>> One of the reasons for slowdown might be the overhead of copying 
>>>> the matrices from computer memory to graphic card memory and back.
>>>>
>>>> So, few questions:
>>>> 1) Do these results with CUDA make sense?
>>>> 2) If the problem is with copy overhead, are there any libraries 
>>>> that allow to force intermediate results to stay in graphic card 
>>>> memory thus removing the overhead?
>>>> 3) Any other options to speed-up linear algebra in Spark?
>>>>
>>>> Thank you, Alexander
>>>>
>>>> -------------------------------------------------------------------
>>>> -- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apache.org><mailto:
>>>> dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spark.apach
>>>> e.org>><mailto:dev-unsubscribe@spark.apac<mailto:dev-unsubscribe@sp
>>>> ark.apac> he.org<http://he.org>
>>>> <mailto:dev-unsubscribe@spark.apache.org<mailto:dev-unsubscribe@spa
>>>> rk.apache.org>>> For additional commands, e-mail: 
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>><mailto:dev-help@spark.apache.org<mailto:dev-help@spark.apache.org><mailto:
>>>> dev-help@spark.apache.org<mailto:dev-help@spark.apache.org>>>
>>>>
>>>>
>>>>
>>>>
>>>

--
Best regards,
Sam
"
"""Evan R. Sparks"" <evan.sparks@gmail.com>","Wed, 25 Mar 2015 18:23:30 -0700",Re: Using CUDA within Spark / boosting linear algebra,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Yeah, much more reasonable - nice to know that we can get full GPU
performance from breeze/netlib-java - meaning there's no compelling
performance reason to switch out our current linear algebra library (at
least as far as this benchmark is concerned).

Instead, it looks like a user guide for configuring Spark/MLlib to use the
right BLAS library will get us most of the way there. Or, would it make
sense to finally ship openblas compiled for some common platforms (64-bit
linux, windows, mac) directly with Spark - hopefully eliminating the jblas
warnings once and for all for most users? (Licensing is BSD) Or am I
missing something?


o
ize. I
5r7kwKSPkY/edit?usp=sharing
th
New-Features-CUDA%206%20-GPU-Acceleration.pdf
5r7kwKSPkY/edit?usp=sharing
e
-----+
=====================================================|
-----+
U
n
nd
5r7kwKSPkY/edit?usp=sharing
uce-world#community
:
m-repo=
with
y
tion by
 test of
4
h for
t
"
Sandy Ryza <sandy.ryza@cloudera.com>,"Wed, 25 Mar 2015 22:06:44 -0400",Re: hadoop input/output format advanced control,Imran Rashid <irashid@cloudera.com>,"Regarding Patrick's question, you can just do ""new Configuration(oldConf)""
to get a cloned Configuration object and add any new properties to it.

-Sandy


"
Patrick Wendell <pwendell@gmail.com>,"Wed, 25 Mar 2015 19:16:54 -0700",Re: hadoop input/output format advanced control,Sandy Ryza <sandy.ryza@cloudera.com>,"Great - that's even easier. Maybe we could have a simple example in the doc.


---------------------------------------------------------------------


"
danilo2 <wojciech.danilo@gmail.com>,"Wed, 25 Mar 2015 19:35:36 -0700 (MST)",Haskell language Spark support,dev@spark.apache.org,"Hi!
I'm a haskell developer and I have created many haskell libraries in my life
and some GHC extensions.
I would like to create Haskell binding for Spark. Where can I find any
documentation / sources describing the first steps in creation of a new
language binding?

I would be very thankful for any help! :)

Al the best,
Wojciech



--

---------------------------------------------------------------------


"
Aaron Davidson <ilikerps@gmail.com>,"Wed, 25 Mar 2015 21:36:57 -0700",Re: hadoop input/output format advanced control,Patrick Wendell <pwendell@gmail.com>,"Should we mention that you should synchronize
on HadoopRDD.CONFIGURATION_INSTANTIATION_LOCK to avoid a possible race
condition in cloning Hadoop Configuration objects prior to Hadoop 2.7.0? :)


"
Pei-Lun Lee <pllee@appier.com>,"Thu, 26 Mar 2015 13:54:28 +0800",Re: Which OutputCommitter to use for S3?,"""user@spark.apache.org"" <user@spark.apache.org>, ""dev@spark.apache.org"" <dev@spark.apache.org>","I updated the PR for SPARK-6352 to be more like SPARK-3595.
I added a new setting ""spark.sql.parquet.output.committer.class"" in hadoop
configuration to allow custom implementation of ParquetOutputCommitter.
Can someone take a look at the PR?


lt
:
ss
2
d with
d
d
e
ed
ter.
27)
ions
s.sc
s.sc
la:7
p
m
aaron
rZ4tFb6o
KZRf6sFs
8&e=
he
t
r
e
f anyone
pa
0ent
nmz8&r=e
zOvl_-
= .
I
--
-
-
"
"""Haopu Wang"" <HWang@qilinsoft.com>","Thu, 26 Mar 2015 15:37:17 +0800",Can I call aggregate UDF in DataFrame?,"""user"" <user@spark.apache.org>,
	<dev@spark.apache.org>","Specifically there are only 5 aggregate functions in class
org.apache.spark.sql.GroupedData: sum/max/min/mean/count.

Can I plugin a function to calculate stddev?

Thank you!


---------------------------------------------------------------------


"
Sam Halliday <sam.halliday@gmail.com>,"Thu, 26 Mar 2015 07:43:02 +0000",Re: Using CUDA within Spark / boosting linear algebra,"""Evan R. Sparks"" <evan.sparks@gmail.com>","I'm not at all surprised ;-) I fully expect the GPU performance to get
better automatically as the hardware improves.

Netlib natives still need to be shipped separately. I'd also oppose any
move to make Open BLAS the default - is not always better and I think
natives really need DevOps buy-in. It's not the right solution for
everybody.

e
s
to
y
size. I
r
J5r7kwKSPkY/edit?usp=sharing
ith
-New-Features-CUDA%206%20-GPU-Acceleration.pdf
J5r7kwKSPkY/edit?usp=sharing
se
s
s
I
s
------+
======================================================|
------+
PU
:
and
J5r7kwKSPkY/edit?usp=sharing
duce-world#community
A:
um-repo=
+
 with
e
+
ation by
h
 test of
ch for
e
a
:
"
Sam Halliday <sam.halliday@gmail.com>,"Thu, 26 Mar 2015 07:54:47 +0000",Re: Using CUDA within Spark / boosting linear algebra,"""Evan R. Sparks"" <evan.sparks@gmail.com>","Btw, OpenBLAS requires GPL runtime binaries which are typically considered
""system libraries"" (and these fall under something similar to the Java
classpath exception rule)... so it's basically impossible to distribute
OpenBLAS the way you're suggesting, sorry. Indeed, there is work ongoing in
Spark right now to clear up something of this nature.

explains in detail why high performance only comes from machine optimised
binaries, which requires DevOps buy-in (and, I'd recommend using MKL anyway
on the CPU, not OpenBLAS).

isn't suitable for everybody and we'd really like people to go into that
with their eyes wide open.

ake
t
as
 to
My
 size. I
ar
9J5r7kwKSPkY/edit?usp=sharing
with
8-New-Features-CUDA%206%20-GPU-Acceleration.pdf
9J5r7kwKSPkY/edit?usp=sharing
nse
,
a
e
heir
as
-------+
======================================================|
-------+
CPU
e
e
 and
9J5r7kwKSPkY/edit?usp=sharing
educe-world#community
m
Z
d
yum-repo=
x
-+
|
s with
I
d
,
.
r
o
,
d
e
.
S
-+
a
h
.
tation by
l
 test of
o
.
o
o
d
s
a
ach for
.
n
)
t
x
d
t
s
d.
-
:
h
p
a
:
"
Karlson <ksonspark@siberie.de>,"Thu, 26 Mar 2015 10:30:12 +0100",Re: functools.partial as UserDefinedFunction,Davies Liu <davies@databricks.com>,"Hi,

I've filed a JIRA (https://issues.apache.org/jira/browse/SPARK-6553) and 
suggested a fix (https://github.com/apache/spark/pull/5206).



---------------------------------------------------------------------


"
"""Evan R. Sparks"" <evan.sparks@gmail.com>","Thu, 26 Mar 2015 09:07:09 -0700",Re: Using CUDA within Spark / boosting linear algebra,Sam Halliday <sam.halliday@gmail.com>,"Alright Sam - you are the expert here. If the GPL issues are unavoidable,
that's fine - what is the exact bit of code that is GPL?

The suggestion to use OpenBLAS is not to say it's the best option, but that
it's a *free, reasonable default* for many users - keep in mind the most
common deployment for Spark/MLlib is on 64-bit linux on EC2[1].
Additionally, for many of the problems we're targeting, this reasonable
default can provide a 1-2 orders of magnitude improvement in performance
over the f2jblas implementation that netlib-java falls back on.

The JVM issues are trickier, I agree - so it sounds like a good user guide
explaining the tradeoffs and configurations procedures as they relate to
spark is a reasonable way forward.

[1] -
https://gigaom.com/2015/01/27/a-few-interesting-numbers-about-apache-spark/


d
in
ay
make
it
las
e to
 My
x size. I
par
T9J5r7kwKSPkY/edit?usp=sharing
m
 with
08-New-Features-CUDA%206%20-GPU-Acceleration.pdf
T9J5r7kwKSPkY/edit?usp=sharing
ense
o,
ra
le
their
s
s
 as
I
--------+
======================================================|
--------+
 CPU
s
e
ee
IDMat
T9J5r7kwKSPkY/edit?usp=sharing
?
reduce-world#community
S
e
r
s
U
d
ed
-yum-repo=
o
--+
|
 |
ns with
e
n
 I
,
n
L,
k
s
ar
s
.
p
to
S,
blas).
se
k
AS
:
--+
8
ra
ch
k
e
ntation by
:
a
al
 test of
k
to
I
U
to
ss
va
f
Mach for
k
on
r
n
s)
It
y
ux
ed
ut
k
es
t
ed.
.
--
"
John Canny <canny@berkeley.edu>,"Thu, 26 Mar 2015 09:20:16 -0700",Re: Using CUDA within Spark / boosting linear algebra,"""Evan R. Sparks"" <evan.sparks@gmail.com>, 
 ""Ulanov, Alexander"" <alexander.ulanov@hp.com>","I mentioned this earlier in the thread, but I'll put it out again. Dense 
BLAS are not very important for most machine learning workloads: at 
least for non-image workloads in industry (and for image processing you 
would probably want a deep learning/SGD solution with convolution 
kernels). e.g. it was only relevant for 1/7 of our recent benchmarks, 
which should be a reasonable sample. What really matters is sparse BLAS 
performance. BIDMat is still an order of magnitude faster there. Those 
kernels are only in BIDMat, since NVIDIAs sparse BLAS dont perform well 
on power-law data.

Its also the case that the overall performance of an algorithm is 
determined by the slowest kernel, not the fastest. If the goal is to get 
closer to BIDMach's performance on typical problems, you need to make 
sure that every kernel goes at comparable speed. So the real question is 
how much faster MLLib routines do on a complete problem with/without GPU 
acceleration. For BIDMach, its close to a factor of 10. But that 
required running entirely on the GPU, and making sure every kernel is 
close to its limit.

-John

If you think nvblas would be helpful, you should try it in some 
end-to-end benchmarks.

"
Sam Halliday <sam.halliday@gmail.com>,"Thu, 26 Mar 2015 16:26:52 +0000",Re: Using CUDA within Spark / boosting linear algebra,John Canny <canny@berkeley.edu>,"John, I have to disagree with you there. Dense matrices come up a lot in
industry,  although your personal experience may be different.

.
e
d
ke
s
to
y
size. I
r
J5r7kwKSPkY/edit?usp=sharing
ith
-New-Features-CUDA%206%20-GPU-Acceleration.pdf
J5r7kwKSPkY/edit?usp=sharing
se
s
s
I
s
------+
======================================================|
------+
PU
:
and
J5r7kwKSPkY/edit?usp=sharing
duce-world#community
A:
um-repo=
+
 with
e
+
ation by
h
 test of
ch for
e
a
:
"
Sean Owen <sowen@cloudera.com>,"Thu, 26 Mar 2015 16:54:57 +0000",Re: Using CUDA within Spark / boosting linear algebra,"""Evan R. Sparks"" <evan.sparks@gmail.com>","The license issue is with libgfortran, rather than OpenBLAS.

(FWIW I am going through the motions to get OpenBLAS set up by default
on CDH in the near future, and the hard part is just handling
libgfortran.)


---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Thu, 26 Mar 2015 21:16:26 +0000",Storing large data for MLlib machine learning,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

Could you suggest what would be the reasonable file format to store feature vector data for machine learning in Spark MLlib? Are there any best practices for Spark?

My data is dense feature vectors with labels. Some of the requirements are that the format should be easy loaded/serialized, randomly accessible, with a small footprint (binary). I am considering Parquet, hdf5, protocol buffer (protobuf), but I have little to no experience with them, so any suggestions would be really appreciated.

Best regards, Alexander
"
Stephen Boesch <javadba@gmail.com>,"Thu, 26 Mar 2015 14:26:33 -0700",Re: Storing large data for MLlib machine learning,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","There are some convenience methods you might consider including:

           MLUtils.loadLibSVMFile

and   MLUtils.loadLabeledPoint

2015-03-26 14:16 GMT-07:00 Ulanov, Alexander <alexander.ulanov@hp.com>:

"
"""Evan R. Sparks"" <evan.sparks@gmail.com>","Thu, 26 Mar 2015 14:33:34 -0700",Re: Storing large data for MLlib machine learning,Stephen Boesch <javadba@gmail.com>,"found it barely JVM-friendly and very Hadoop-unfriendly (e.g. the APIs
needed filenames as input, you couldn't pass it anything like an
InputStream). I don't know if it has gotten any better.

Parquet plays much more nicely and there are lots of spark-related projects
using it already. Keep in mind that it's column-oriented which might impact
performance - but basically you're going to want your features in a byte
array and deser should be pretty straightforward.


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Thu, 26 Mar 2015 21:33:08 +0000",RE: Storing large data for MLlib machine learning,Stephen Boesch <javadba@gmail.com>,"Thanks for suggestion, but libsvm is a format for sparse data storing in text file and I have dense vectors. In my opinion, text format is not appropriate for storing large dense vectors due to overhead related to parsing from string to digits and also storing digits as strings is not efficient.

From: Stephen Boesch [mailto:javadba@gmail.com]
Sent: Thursday, March 26, 2015 2:27 PM
To: Ulanov, Alexander
Cc: dev@spark.apache.org
Subject: Re: Storing large data for MLlib machine learning

There are some convenience methods you might consider including:

           MLUtils.loadLibSVMFile

and   MLUtils.loadLabeledPoint

2015-03-26 14:16 GMT-07:00 Ulanov, Alexander <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>:
Hi,

Could you suggest what would be the reasonable file format to store feature vector data for machine learning in Spark MLlib? Are there any best practices for Spark?

My data is dense feature vectors with labels. Some of the requirements are that the format should be easy loaded/serialized, randomly accessible, with a small footprint (binary). I am considering Parquet, hdf5, protocol buffer (protobuf), but I have little to no experience with them, so any suggestions would be really appreciated.

Best regards, Alexander

"
Zhan Zhang <zzhang@hortonworks.com>,"Thu, 26 Mar 2015 21:44:23 +0000",RDD.map does not allowed to preservesPartitioning?,"dev <dev@spark.apache.org>, user <user@spark.apache.org>","Hi Folks,

Does anybody know what is the reason not allowing preserverPartitioning in RDD.map? Do I miss something here?

Following example involves two shuffles. I think if preservePartitioning is allowed, we can avoid the second one, right?

 val r1 = sc.parallelize(List(1,2,3,4,5,5,6,6,7,8,9,10,2,4))
 val r2 = r1.map((_, 1))
 val r3 = r2.reduceByKey(_+_)
 val r4 = r3.map(x=>(x._1, x._2 + 1))
 val r5 = r4.reduceByKey(_+_)
 r5.collect.foreach(println)

scala> r5.toDebugString
res2: String =
(8) ShuffledRDD[4] at reduceByKey at <console>:29 []
 +-(8) MapPartitionsRDD[3] at map at <console>:27 []
    |  ShuffledRDD[2] at reduceByKey at <console>:25 []
    +-(8) MapPartitionsRDD[1] at map at <console>:23 []
       |  ParallelCollectionRDD[0] at parallelize at <console>:21 []

Thanks.

Zhan Zhang

---------------------------------------------------------------------


"
Jonathan Coveney <jcoveney@gmail.com>,"Thu, 26 Mar 2015 17:49:30 -0400",Re: RDD.map does not allowed to preservesPartitioning?,Zhan Zhang <zzhang@hortonworks.com>,"I believe if you do the following:

sc.parallelize(List(1,2,3,4,5,5,6,6,7,8,9,10,2,4)).map((_,1)).reduceByKey(_+_).mapValues(_+1).reduceByKey(_+_).toDebugString

(8) MapPartitionsRDD[34] at reduceByKey at <console>:23 []
 |  MapPartitionsRDD[33] at mapValues at <console>:23 []
 |  ShuffledRDD[32] at reduceByKey at <console>:23 []
 +-(8) MapPartitionsRDD[31] at map at <console>:23 []
    |  ParallelCollectionRDD[30] at parallelize at <console>:23 []

The difference is that spark has no way to know that your map closure
doesn't change the key. if you only use mapValues, it does. Pretty cool
that they optimized that :)

2015-03-26 17:44 GMT-04:00 Zhan Zhang <zzhang@hortonworks.com>:

"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Thu, 26 Mar 2015 21:51:12 +0000",RE: Storing large data for MLlib machine learning,"""Evan R. Sparks"" <evan.sparks@gmail.com>, Stephen Boesch
	<javadba@gmail.com>","Thanks, Evan. What do you think about Protobuf? Twitter has a library to manage protobuf files in hdfs https://github.com/twitter/elephant-bird


From: Evan R. Sparks [mailto:evan.sparks@gmail.com]
Sent: Thursday, March 26, 2015 2:34 PM
To: Stephen Boesch
Cc: Ulanov, Alexander; dev@spark.apache.org
Subject: Re: Storing large data for MLlib machine learning

On binary file formats - I looked at HDF5+Spark a couple of years ago and found it barely JVM-friendly and very Hadoop-unfriendly (e.g. the APIs needed filenames as input, you couldn't pass it anything like an InputStream). I don't know if it has gotten any better.

Parquet plays much more nicely and there are lots of spark-related projects using it already. Keep in mind that it's column-oriented which might impact performance - but basically you're going to want your features in a byte array and deser should be pretty straightforward.

On Thu, Mar 26, 2015 at 2:26 PM, Stephen Boesch <javadba@gmail.com<mailto:javadba@gmail.com>> wrote:
There are some convenience methods you might consider including:

           MLUtils.loadLibSVMFile

and   MLUtils.loadLabeledPoint

2015-03-26 14:16 GMT-07:00 Ulanov, Alexander <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>:

> Hi,
>
> Could you suggest what would be the reasonable file format to store
> feature vector data for machine learning in Spark MLlib? Are there any best
> practices for Spark?
>
> My data is dense feature vectors with labels. Some of the requirements are
> that the format should be easy loaded/serialized, randomly accessible, with
> a small footprint (binary). I am considering Parquet, hdf5, protocol buffer
> (protobuf), but I have little to no experience with them, so any
> suggestions would be really appreciated.
>
> Best regards, Alexander
>

"
Zhan Zhang <zzhang@hortonworks.com>,"Thu, 26 Mar 2015 21:54:44 +0000",Re: RDD.map does not allowed to preservesPartitioning?,Jonathan Coveney <jcoveney@gmail.com>,"Thanks Jonathan. You are right regarding rewrite the example.

I mean providing such option to developer so that it is controllable. The example may seems silly, and I dont know the use cases.

But for example, if I also want to operate both the key and value part to generate some new value with keeping key part untouched. Then mapValues may not be able to  do this.

Changing the code to allow this is trivial, but I dont know whether there is some special reason behind this.

Thanks.

Zhan Zhang




I believe if you do the following:

sc.parallelize(List(1,2,3,4,5,5,6,6,7,8,9,10,2,4)).map((_,1)).reduceByKey(_+_).mapValues(_+1).reduceByKey(_+_).toDebugString

(8) MapPartitionsRDD[34] at reduceByKey at <console>:23 []
 |  MapPartitionsRDD[33] at mapValues at <console>:23 []
 |  ShuffledRDD[32] at reduceByKey at <console>:23 []
 +-(8) MapPartitionsRDD[31] at map at <console>:23 []
    |  ParallelCollectionRDD[30] at parallelize at <console>:23 []

The difference is that spark has no way to know that your map closure doesn't change the key. if you only use mapValues, it does. Pretty cool that they optimized that :)

2015-03-26 17:44 GMT-04:00 Zhan Zhang <zzhang@hortonworks.com<mailto:zzhang@hortonworks.com>>:
Hi Folks,

Does anybody know what is the reason not allowing preserverPartitioning in RDD.map? Do I miss something here?

Following example involves two shuffles. I think if preservePartitioning is allowed, we can avoid the second one, right?

 val r1 = sc.parallelize(List(1,2,3,4,5,5,6,6,7,8,9,10,2,4))
 val r2 = r1.map((_, 1))
 val r3 = r2.reduceByKey(_+_)
 val r4 = r3.map(x=>(x._1, x._2 + 1))
 val r5 = r4.reduceByKey(_+_)
 r5.collect.foreach(println)

scala> r5.toDebugString
res2: String =
(8) ShuffledRDD[4] at reduceByKey at <console>:29 []
 +-(8) MapPartitionsRDD[3] at map at <console>:27 []
    |  ShuffledRDD[2] at reduceByKey at <console>:25 []
    +-(8) MapPartitionsRDD[1] at map at <console>:23 []
       |  ParallelCollectionRDD[0] at parallelize at <console>:21 []

Thanks.

Zhan Zhang

---------------------------------------------------------------------
scribe@spark.apache.org>
p@spark.apache.org>



"
Jeremy Freeman <freeman.jeremy@gmail.com>,"Thu, 26 Mar 2015 15:01:12 -0700",Re: Storing large data for MLlib machine learning,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Hi Ulvanov, great question, weve encountered it frequently with scientific data (e.g. time series). Agreed text is inefficient for dense arrays, and we also found HDF5+Spark to be a pain.
 
Our strategy has been flat binary files with fixed length records. Loading these is now supported in Spark via the binaryRecords method, which wraps a custom Hadoop InputFormat we wrote.

An example (in python):


'float'))


Compared to something like Parquet, this is a little lighter-weight, and plays nicer with non-distributed data science tools (e.g. numpy). It also scales great (we use it routinely to process TBs of time series). And handles single files or directories. But it's extremely simple!

-------------------------
jeremyfreeman.net
@thefreemanlab


in text file and I have dense vectors. In my opinion, text format is not appropriate for storing large dense vectors due to overhead related to parsing from string to digits and also storing digits as strings is not efficient.
<alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com>>:
feature vector data for machine learning in Spark MLlib? Are there any best practices for Spark?
are that the format should be easy loaded/serialized, randomly accessible, with a small footprint (binary). I am considering Parquet, hdf5, protocol buffer (protobuf), but I have little to no experience with them, so any suggestions would be really appreciated.

"
"""Evan R. Sparks"" <evan.sparks@gmail.com>","Thu, 26 Mar 2015 15:02:15 -0700",Re: Storing large data for MLlib machine learning,"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Protobufs are great for serializing individual records - but parquet is
good for efficiently storing a whole bunch of these objects.

Matt Massie has a good (slightly dated) blog post on using
Spark+Parquet+Avro (and you can pretty much s/Avro/Protobuf/) describing
how they all work together here:
http://zenfractal.com/2013/08/21/a-powerful-big-data-trio/

Your use case (storing dense features, presumably as a single column) is
pretty straightforward and the extra layers of indirection are maybe
overkill.

Lastly - you might consider using some of SparkSQL/DataFrame's built-in
features for persistence, which support lots of storage backends.
https://spark.apache.org/docs/1.3.0/sql-programming-guide.html#data-sources


"
Jonathan Coveney <jcoveney@gmail.com>,"Thu, 26 Mar 2015 18:07:05 -0400",Re: RDD.map does not allowed to preservesPartitioning?,Zhan Zhang <zzhang@hortonworks.com>,"This is just a deficiency of the api, imo. I agree: mapValues could
definitely be a function (K, V)=>V1. The option isn't set by the function,
it's on the RDD. So you could look at the code and do this.
https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala

 def mapValues[U](f: V => U): RDD[(K, U)] = {
    val cleanF = self.context.clean(f)
    new MapPartitionsRDD[(K, U), (K, V)](self,
      (context, pid, iter) => iter.map { case (k, v) => (k, cleanF(v)) },
      preservesPartitioning = true)
  }

What you want:

 def mapValues[U](f: (K, V) => U): RDD[(K, U)] = {
    val cleanF = self.context.clean(f)
    new MapPartitionsRDD[(K, U), (K, V)](self,
      (context, pid, iter) => iter.map { case t@(k, _) => (k, cleanF(t)) },
      preservesPartitioning = true)
  }

very easy :)

2015-03-26 17:54 GMT-04:00 Zhan Zhang <zzhang@hortonworks.com>:

ay
ther
:
(_+_).mapValues(_+1).reduceByKey(_+_).toDebugString
"
Patrick Wendell <pwendell@gmail.com>,"Thu, 26 Mar 2015 15:14:40 -0700",Re: RDD.map does not allowed to preservesPartitioning?,Jonathan Coveney <jcoveney@gmail.com>,"I think we have a version of mapPartitions that allows you to tell
Spark the partitioning is preserved:

https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L639

We could also add a map function that does same. Or you can just write
your map using an iterator.

- Patrick


---------------------------------------------------------------------


"
Zhan Zhang <zzhang@hortonworks.com>,"Thu, 26 Mar 2015 22:20:00 +0000",Re: RDD.map does not allowed to preservesPartitioning?,Patrick Wendell <pwendell@gmail.com>,"Thanks all for the quick response.

Thanks.

Zhan Zhang


e/spark/rdd/RDD.scala#L639
ote:
ion,
he/spark/rdd/RDD.scala
) },
t)) },
very
he
to
 may
ere
e:
ey(_+_).mapValues(_+1).reduceByKey(_+_).toDebugString
 that
g
ng


---------------------------------------------------------------------


"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Thu, 26 Mar 2015 22:27:23 +0000",RE: Storing large data for MLlib machine learning,Jeremy Freeman <freeman.jeremy@gmail.com>,"Thanks, Jeremy! I also work with time series data right now, so your suggestions are really relevant. However, we want to handle not the raw data, but already processed and prepared for machine learning.

Initially, we also wanted to have our own simple binary format, but we could not agree on handling little/big endian. We did not agree if we have to stick to a specific endian or to ship this information in metadata file. And metadata file sounds like another data format engineering (aka inventing the bicycle). Does this make sense to you?

From: Jeremy Freeman [mailto:freeman.jeremy@gmail.com]
Sent: Thursday, March 26, 2015 3:01 PM
To: Ulanov, Alexander
Cc: Stephen Boesch; dev@spark.apache.org
Subject: Re: Storing large data for MLlib machine learning

Hi Ulvanov, great question, we've encountered it frequently with scientific data (e.g. time series). Agreed text is inefficient for dense arrays, and we also found HDF5+Spark to be a pain.

Our strategy has been flat binary files with fixed length records. Loading these is now supported in Spark via the binaryRecords method, which wraps a custom Hadoop InputFormat we wrote.

An example (in python):

# write data from an array
from numpy import random
dat = random.randn(100,5)
f = open('test.bin', 'w')
f.write(dat)
f.close()

# load the data back in
from numpy import frombuffer
nrecords = 5
bytesize = 8
recordsize = nrecords * bytesize
data = sc.binaryRecords('test.bin', recordsize)
parsed = data.map(lambda v: frombuffer(buffer(v, 0, recordsize), 'float'))

# these should be equal
parsed.first()
dat[0,:]

Compared to something like Parquet, this is a little lighter-weight, and plays nicer with non-distributed data science tools (e.g. numpy). It also scales great (we use it routinely to process TBs of time series). And handles single files or directories. But it's extremely simple!

-------------------------
jeremyfreeman.net<http://jeremyfreeman.net>
@thefreemanlab



Thanks for suggestion, but libsvm is a format for sparse data storing in text file and I have dense vectors. In my opinion, text format is not appropriate for storing large dense vectors due to overhead related to parsing from string to digits and also storing digits as strings is not efficient.

From: Stephen Boesch [mailto:javadba@gmail.com]
Sent: Thursday, March 26, 2015 2:27 PM
To: Ulanov, Alexander
Cc: dev@spark.apache.org<mailto:dev@spark.apache.org>
Subject: Re: Storing large data for MLlib machine learning

There are some convenience methods you might consider including:

          MLUtils.loadLibSVMFile

and   MLUtils.loadLabeledPoint

2015-03-26 14:16 GMT-07:00 Ulanov, Alexander <alexander.ulanov@hp.com<mailto:alexander.ulanov@hp.com><mailto:alexander.ulanov@hp.com>>:
Hi,

Could you suggest what would be the reasonable file format to store feature vector data for machine learning in Spark MLlib? Are there any best practices for Spark?

My data is dense feature vectors with labels. Some of the requirements are that the format should be easy loaded/serialized, randomly accessible, with a small footprint (binary). I am considering Parquet, hdf5, protocol buffer (protobuf), but I have little to no experience with them, so any suggestions would be really appreciated.

Best regards, Alexander

"
Pala M Muthaia <mchettiar@rocketfuelinc.com>,"Thu, 26 Mar 2015 15:48:20 -0700",Re: Building spark 1.2 from source requires more dependencies,"Ted Yu <yuzhihong@gmail.com>, dev@spark.apache.org",#NAME?
Kannan Rajah <krajah@maprtech.com>,"Thu, 26 Mar 2015 17:29:53 -0700",Re: Understanding shuffle file name conflicts,Cheng Lian <lian.cs.zju@gmail.com>,"Thanks folks. I understood the workflow. I noticed there is some code in
Worker.scala that creates app specific local dir.


--
Kannan


e
p
ll
e
the
with
e
in
DD
t
"
Doug Balog <doug.sparkdev@dugos.com>,"Fri, 27 Mar 2015 04:48:56 -0400",Support for Hive 0.14 in secure mode on hadoop 2.6.0,dev@spark.apache.org,"Hi, 
  I'm just wondering if anybody is working on supporting Hive 0.14 in secure mode on hadoop 2.6.0 ?
I see once Jira referring to it  https://issues.apache.org/jira/browse/SPARK-5111
but it mentions no effort to move to 0.14.

Thanks,

Doug



---------------------------------------------------------------------


"
Cheng Lian <lian.cs.zju@gmail.com>,"Fri, 27 Mar 2015 18:13:34 +0800",Re: Support for Hive 0.14 in secure mode on hadoop 2.6.0,"Doug Balog <doug.sparkdev@dugos.com>, dev@spark.apache.org","We're planning to replace the current Hive version profiles and shim 
layer with an adaption layer in Spark SQL in 1.4. This adaption layer 
allows Spark SQL to connect to arbitrary Hive version greater than or 
equal to 0.12.0 (or maybe 0.13.1, not decided yet).

However, it's not a promise yet, since this requires major refactoring 
of the current Spark SQL Hive support.

Cheng



---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Fri, 27 Mar 2015 12:23:24 +0000",Re: Building spark 1.2 from source requires more dependencies,Pala M Muthaia <mchettiar@rocketfuelinc.com>,"I built from the head of branch-1.2 and spark-core compiled correctly
with your exact command. You have something wrong with how you are
building. For example, you're not trying to run this from the core
subdirectory are you?


---------------------------------------------------------------------


"
Stephen Boesch <javadba@gmail.com>,"Fri, 27 Mar 2015 10:02:27 -0700",Iterative pyspark / scala codebase development,"""dev@spark.apache.org"" <dev@spark.apache.org>","I am iteratively making changes to the scala side of some new pyspark code
and re-testing from the python/pyspark side.

Presently my only solution is to rebuild completely

      sbt assembly

after any scala side change - no matter how small.

Any better / expedited way for pyspark to see small scala side updates?
"
Reynold Xin <rxin@databricks.com>,"Fri, 27 Mar 2015 10:11:06 -0700",Re: Iterative pyspark / scala codebase development,Stephen Boesch <javadba@gmail.com>,"Python is tough if you need to change Scala at the same time.

sbt/sbt assembly/assembly

can be slightly faster than just assembly.



"
Davies Liu <davies@databricks.com>,"Fri, 27 Mar 2015 10:13:06 -0700",Re: Iterative pyspark / scala codebase development,Stephen Boesch <javadba@gmail.com>,"see https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools


---------------------------------------------------------------------


"
Davies Liu <davies@databricks.com>,"Fri, 27 Mar 2015 10:16:15 -0700",Re: Iterative pyspark / scala codebase development,Reynold Xin <rxin@databricks.com>,"I usually just open a terminal to do `build/sbt ~compile`, coding in
IntelliJ, then run python tests in another terminal once it compiled
successfully.


---------------------------------------------------------------------


"
Stephen Boesch <javadba@gmail.com>,"Fri, 27 Mar 2015 10:18:04 -0700",Re: Iterative pyspark / scala codebase development,Davies Liu <davies@databricks.com>,"Compile alone did not show the scala code changes AFAICT. I will reverify.

2015-03-27 10:16 GMT-07:00 Davies Liu <davies@databricks.com>:

"
Davies Liu <davies@databricks.com>,"Fri, 27 Mar 2015 10:21:30 -0700",Re: Iterative pyspark / scala codebase development,"Stephen Boesch <javadba@gmail.com>, ""dev@spark.apache.org"" <dev@spark.apache.org>","put these lines in your ~/.bash_profile

export SPARK_PREPEND_CLASSES=true
export SPARK_HOME=path_to_spark
export PYTHONPATH=""${SPARK_HOME}/python/lib/py4j-0.8.2.1-src.zip:${SPARK_HOME}/python:${PYTHONPATH}""

$ source ~/.bash_profile
$ build/sbt assembly
$ build/sbt ~compile  # do not stop this

Then in another terminal you could run python tests as
$ cd python/pyspark/
$  python rdd.py


cc to dev list



---------------------------------------------------------------------


"
Pala M Muthaia <mchettiar@rocketfuelinc.com>,"Fri, 27 Mar 2015 12:09:02 -0700",Re: Building spark 1.2 from source requires more dependencies,Sean Owen <sowen@cloudera.com>,"No, i am running from the root directory, parent of core.

Here is the first set of errors that i see when i compile from source
(sorry the error message is very long, but adding it in case it helps in
diagnosis). After i manually add javax.servlet dependency for  version 3.0,
these set of errors go away and i get the next set of errors about missing
classes under eclipse-jetty.

I am on maven 3.2.5 and java 1.7.

Error:

[INFO] --- scala-maven-plugin:3.2.0:compile (scala-compile-first) @
spark-core_2.10 ---
[WARNING] Zinc server is not available at port 3030 - reverting to normal
incremental compile
[INFO] Using incremental compilation
[INFO] compiler plugin:
BasicArtifact(org.scalamacros,paradise_2.10.4,2.0.1,null)
[INFO] Compiling 403 Scala sources and 33 Java sources to
/Users/mchettiar/code/spark/core/target/scala-2.10/classes...
[WARNING] Class javax.servlet.ServletException not found - continuing with
a stub.
[ERROR]
     while compiling:
/Users/mchettiar/code/spark/core/src/main/scala/org/apache/spark/HttpServer.scala
        during phase: typer
     library version: version 2.10.4
    compiler version: version 2.10.4
  reconstructed args: -deprecation -feature
-Xplugin:/Users/mchettiar/.m2/repository/org/scalamacros/paradise_2.10.4/2.0.1/paradise_2.10.4-2.0.1.jar
-bootclasspath
/Library/Java/JavaVirtualMachines/jdk1.7.0_75.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_75.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_75.jdk/Contents/Home/jre/lib/sunrsasign.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_75.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_75.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_75.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_75.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.7.0_75.jdk/Contents/Home/jre/classes:/Users/mchettiar/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar
-classpath
/Users/mchettiar/code/spark/core/target/scala-2.10/classes:/Users/mchettiar/.m2/repository/com/twitter/chill_2.10/0.5.0/chill_2.10-0.5.0.jar:/Users/mchettiar/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/mchettiar/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/mchettiar/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/mchettiar/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/mchettiar/.m2/repository/com/twitter/chill-java/0.5.0/chill-java-0.5.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-client/2.4.0/hadoop-client-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-common/2.4.0/hadoop-common-2.4.0.jar:/Users/mchettiar/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/mchettiar/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/mchettiar/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/Users/mchettiar/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/Users/mchettiar/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/Users/mchettiar/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/Users/mchettiar/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/mchettiar/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/mchettiar/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/mchettiar/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/mchettiar/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/Users/mchettiar/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/Users/mchettiar/.m2/repository/org/apache/avro/avro/1.7.6/avro-1.7.6.jar:/Users/mchettiar/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-auth/2.4.0/hadoop-auth-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/mchettiar/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.4.0/hadoop-hdfs-2.4.0.jar:/Users/mchettiar/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.4.0/hadoop-mapreduce-client-app-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.4.0/hadoop-mapreduce-client-common-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.4.0/hadoop-yarn-client-2.4.0.jar:/Users/mchettiar/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.4.0/hadoop-yarn-server-common-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.4.0/hadoop-mapreduce-client-shuffle-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.4.0/hadoop-yarn-api-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.4.0/hadoop-mapreduce-client-core-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.4.0/hadoop-yarn-common-2.4.0.jar:/Users/mchettiar/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/mchettiar/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/mchettiar/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/Users/mchettiar/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.4.0/hadoop-mapreduce-client-jobclient-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/hadoop/hadoop-annotations/2.4.0/hadoop-annotations-2.4.0.jar:/Users/mchettiar/code/spark/network/common/target/spark-network-common_2.10-1.2.2-SNAPSHOT.jar:/Users/mchettiar/code/spark/network/shuffle/target/spark-network-shuffle_2.10-1.2.2-SNAPSHOT.jar:/Users/mchettiar/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/Users/mchettiar/.m2/repository/commons-codec/commons-codec/1.5/commons-codec-1.5.jar:/Users/mchettiar/.m2/repository/org/apache/httpcomponents/httpclient/4.1.2/httpclient-4.1.2.jar:/Users/mchettiar/.m2/repository/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/Users/mchettiar/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/Users/mchettiar/.m2/repository/org/apache/curator/curator-recipes/2.4.0/curator-recipes-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/curator/curator-framework/2.4.0/curator-framework-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/curator/curator-client/2.4.0/curator-client-2.4.0.jar:/Users/mchettiar/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar:/Users/mchettiar/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/jetty-plus/8.1.14.v20131031/jetty-plus-8.1.14.v20131031.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/orbit/javax.transaction/1.1.1.v201105210645/javax.transaction-1.1.1.v201105210645.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/jetty-webapp/8.1.14.v20131031/jetty-webapp-8.1.14.v20131031.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/jetty-jndi/8.1.14.v20131031/jetty-jndi-8.1.14.v20131031.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/orbit/javax.mail.glassfish/1.4.1.v201005082020/javax.mail.glassfish-1.4.1.v201005082020.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/orbit/javax.activation/1.1.0.v201105071233/javax.activation-1.1.0.v201105071233.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/jetty-security/8.1.14.v20131031/jetty-security-8.1.14.v20131031.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar:/Users/mchettiar/.m2/repository/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar:/Users/mchettiar/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/Users/mchettiar/.m2/repository/org/apache/commons/commons-lang3/3.3.2/commons-lang3-3.3.2.jar:/Users/mchettiar/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/Users/mchettiar/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/mchettiar/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/Users/mchettiar/.m2/repository/org/slf4j/jul-to-slf4j/1.7.5/jul-to-slf4j-1.7.5.jar:/Users/mchettiar/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.5/jcl-over-slf4j-1.7.5.jar:/Users/mchettiar/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/mchettiar/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/Users/mchettiar/.m2/repository/com/ning/compress-lzf/1.0.0/compress-lzf-1.0.0.jar:/Users/mchettiar/.m2/repository/org/xerial/snappy/snappy-java/
1.1.1.6/snappy-java-1.1.1.6.jar:/Users/mchettiar/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/Users/mchettiar/.m2/repository/org/roaringbitmap/RoaringBitmap/0.4.5/RoaringBitmap-0.4.5.jar:/Users/mchettiar/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/Users/mchettiar/.m2/repository/org/spark-project/akka/akka-remote_2.10/2.3.4-spark/akka-remote_2.10-2.3.4-spark.jar:/Users/mchettiar/.m2/repository/org/spark-project/akka/akka-actor_2.10/2.3.4-spark/akka-actor_2.10-2.3.4-spark.jar:/Users/mchettiar/.m2/repository/com/typesafe/config/1.2.1/config-1.2.1.jar:/Users/mchettiar/.m2/repository/io/netty/netty/3.8.0.Final/netty-3.8.0.Final.jar:/Users/mchettiar/.m2/repository/org/spark-project/protobuf/protobuf-java/2.5.0-spark/protobuf-java-2.5.0-spark.jar:/Users/mchettiar/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/Users/mchettiar/.m2/repository/org/spark-project/akka/akka-slf4j_2.10/2.3.4-spark/akka-slf4j_2.10-2.3.4-spark.jar:/Users/mchettiar/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.10/json4s-jackson_2.10-3.2.10.jar:/Users/mchettiar/.m2/repository/org/json4s/json4s-core_2.10/3.2.10/json4s-core_2.10-3.2.10.jar:/Users/mchettiar/.m2/repository/org/json4s/json4s-ast_2.10/3.2.10/json4s-ast_2.10-3.2.10.jar:/Users/mchettiar/.m2/repository/com/thoughtworks/paranamer/paranamer/2.6/paranamer-2.6.jar:/Users/mchettiar/.m2/repository/org/scala-lang/scalap/2.10.4/scalap-2.10.4.jar:/Users/mchettiar/.m2/repository/org/scala-lang/scala-compiler/2.10.4/scala-compiler-2.10.4.jar:/Users/mchettiar/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.3.1/jackson-databind-2.3.1.jar:/Users/mchettiar/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.3.0/jackson-annotations-2.3.0.jar:/Users/mchettiar/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.3.1/jackson-core-2.3.1.jar:/Users/mchettiar/.m2/repository/org/apache/mesos/mesos/0.18.1/mesos-0.18.1-shaded-protobuf.jar:/Users/mchettiar/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/Users/mchettiar/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/Users/mchettiar/.m2/repository/com/codahale/metrics/metrics-core/3.0.0/metrics-core-3.0.0.jar:/Users/mchettiar/.m2/repository/com/codahale/metrics/metrics-jvm/3.0.0/metrics-jvm-3.0.0.jar:/Users/mchettiar/.m2/repository/com/codahale/metrics/metrics-json/3.0.0/metrics-json-3.0.0.jar:/Users/mchettiar/.m2/repository/com/codahale/metrics/metrics-graphite/3.0.0/metrics-graphite-3.0.0.jar:/Users/mchettiar/.m2/repository/org/tachyonproject/tachyon-client/0.5.0/tachyon-client-0.5.0.jar:/Users/mchettiar/.m2/repository/org/tachyonproject/tachyon/0.5.0/tachyon-0.5.0.jar:/Users/mchettiar/.m2/repository/org/scala-lang/scala-reflect/2.10.4/scala-reflect-2.10.4.jar:/Users/mchettiar/.m2/repository/org/spark-project/pyrolite/2.0.1/pyrolite-2.0.1.jar:/Users/mchettiar/.m2/repository/net/sf/py4j/py4j/0.8.2.1/py4j-0.8.2.1.jar:/Users/mchettiar/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/Users/mchettiar/.m2/repository/org/codehaus/groovy/groovy-all/2.3.7/groovy-all-2.3.7.jar
-unchecked

  last tree to typer: Ident(Server)
              symbol: <none> (flags: )
   symbol definition: <none>
       symbol owners:
      context owners: variable server -> class HttpServer -> package spark

== Enclosing template or block ==

Template( // val <local HttpServer>: <notype> in class HttpServer
  ""org.apache.spark.Logging"" // parents
  ValDef(
    private
    ""_""
    <tpt>
    <empty>
  )
  // 13 statements
  ValDef( // private[this] val conf: <?> in class HttpServer
    private <local> <paramaccessor>
    ""conf""
    ""SparkConf""
    <empty>
  )
  ValDef( // private[this] val resourceBase: <?> in class HttpServer
    private <local> <paramaccessor>
    ""resourceBase""
    ""File""
    <empty>
  )
  ValDef( // private[this] val securityManager: <?> in class HttpServer
    private <local> <paramaccessor>
    ""securityManager""
    ""SecurityManager""
    <empty>
  )
  ValDef( // private[this] val requestedPort: <?> in class HttpServer
    private <local> <paramaccessor>
    ""requestedPort""
    ""Int""
    <empty>
  )
  ValDef( // private[this] val serverName: <?> in class HttpServer
    private <local> <paramaccessor>
    ""serverName""
    ""String""
    <empty>
  )
  DefDef( // def <init>(conf: org.apache.spark.SparkConf,resourceBase:
java.io.File,securityManager:
org.apache.spark.SecurityManager,requestedPort: Int,serverName: String):
org.apache.spark.HttpServer in class HttpServer
    <method> <triedcooking>
    ""<init>""
    []
    // 1 parameter list
    ValDef( // conf: org.apache.spark.SparkConf
      <param> <paramaccessor>
      ""conf""
      ""SparkConf"" // class SparkConf extends Cloneable with Logging in
package spark, tree.tpe=org.apache.spark.SparkConf
      <empty>
    )
    ValDef( // resourceBase: java.io.File
      <param> <paramaccessor>
      ""resourceBase""
      ""File""
      <empty>
    )
    ValDef( // securityManager: org.apache.spark.SecurityManager
      <param> <paramaccessor>
      ""securityManager""
      ""SecurityManager"" // private[package spark] class SecurityManager
extends Logging with SecretKeyHolder in package spark,
tree.tpe=org.apache.spark.SecurityManager
      <empty>
    )
    ValDef( // requestedPort: Int
      <param> <defaultparam/trait> <paramaccessor>
      ""requestedPort""
      ""Int""
      0
    )
    ValDef( // serverName: String
      <param> <defaultparam/trait> <paramaccessor>
      ""serverName""
      ""String""
      ""HTTP server""
    )
    <tpt> // tree.tpe=org.apache.spark.HttpServer
    Block(
      Apply(
        super.""<init>""
        Nil
      )
      ()
    )
  )
  ValDef( // private[this] var server: <?> in class HttpServer
    private <mutable> <local>
    ""server""
    ""Server""
    null
  )
  ValDef( // private[this] var port: <?> in class HttpServer
    private <mutable> <local>
    ""port""
    ""Int""
    ""requestedPort""
  )
  DefDef( // def start(): Unit in class HttpServer
    <method> <triedcooking>
    ""start""
    []
    List(Nil)
    ""scala"".""Unit"" // final abstract class Unit extends AnyVal in package
scala, tree.tpe=Unit
    If(
      Apply(
        ""server"".""$bang$eq""
        null
      )
      Throw(
        Apply(
          new ServerStateException.""<init>""
          ""Server is already started""
        )
      )
      Block(
        // 5 statements
        Apply(
          ""logInfo""
          ""Starting HTTP Server""
        )
        ValDef(
          private <local> <synthetic>
          ""x$1""
          <tpt>
          Match(
            Annotated(
              Apply(
                new scala.unchecked.""<init>""
                Nil
              )
              Apply(
                TypeApply(
                  ""Server""
                )
                // 4 arguments
                ""requestedPort""
                ""doStart""
                ""conf""
                ""serverName""
              )
            )
            CaseDef(
              Apply(
                ""scala"".""Tuple2""
                // 2 arguments
                Bind(
                  ""actualServer""
                  ""_""
                )
                Bind(
                  ""actualPort""
                  ""_""
                )
              )
              Apply(
                ""scala"".""Tuple2""
                // 2 arguments
                ""actualServer""
                ""actualPort""
              )
            )
          )
        )
        ValDef(
          0
          ""actualServer""
          <tpt>
          ""x$1"".""_1""
        )
        ValDef(
          0
          ""actualPort""
          <tpt>
          ""x$1"".""_2""
        )
        Assign(
          ""server""
          ""actualServer""
        )
        Assign(
          ""port""
          ""actualPort""
        )
      )
    )
  )
  DefDef( // private def doStart: <?> in class HttpServer
    <method> private
    ""doStart""
    []
    // 1 parameter list
    ValDef(
      <param>
      ""startPort""
      ""Int""
      <empty>
    )
    AppliedTypeTree(
      ""scala"".""Tuple2""
      // 2 arguments
      ""Server""
      ""Int""
    )
    Block(
      // 16 statements
      ValDef(
        0
        ""server""
        <tpt>
        Apply(
          new Server.""<init>""
          Nil
        )
      )
      ValDef(
        0
        ""connector""
        <tpt>
        Apply(
          new SocketConnector.""<init>""
          Nil
        )
      )
      Apply(
        ""connector"".""setMaxIdleTime""
        Apply(
          60.""$times""
          1000
        )
      )
      Apply(
        ""connector"".""setSoLingerTime""
        -1
      )
      Apply(
        ""connector"".""setPort""
        ""startPort""
      )
      Apply(
        ""server"".""addConnector""
        ""connector""
      )
      ValDef(
        0
        ""threadPool""
        <tpt>
        Apply(
          new QueuedThreadPool.""<init>""
          Nil
        )
      )
      Apply(
        ""threadPool"".""setDaemon""
        true
      )
      Apply(
        ""server"".""setThreadPool""
        ""threadPool""
      )
      ValDef(
        0
        ""resHandler""
        <tpt>
        Apply(
          new ResourceHandler.""<init>""
          Nil
        )
      )
      Apply(
        ""resHandler"".""setResourceBase""
        ""resourceBase"".""getAbsolutePath""
      )
      ValDef(
        0
        ""handlerList""
        <tpt>
        Apply(
          new HandlerList.""<init>""
          Nil
        )
      )
      Apply(
        ""handlerList"".""setHandlers""
        Apply(
          ""Array""
          // 2 arguments
          ""resHandler""
          Apply(
            new DefaultHandler.""<init>""
            Nil
          )
        )
      )
      If(
        Apply(
          ""securityManager"".""isAuthenticationEnabled""
          Nil
        )
        Block(
          // 3 statements
          Apply(
            ""logDebug""
            ""HttpServer is using security""
          )
          ValDef(
            0
            ""sh""
            <tpt>
            Apply(
              ""setupSecurityHandler""
              ""securityManager""
            )
          )
          Apply(
            ""sh"".""setHandler""
            ""handlerList""
          )
          Apply(
            ""server"".""setHandler""
            ""sh""
          )
        )
        Block(
          Apply(
            ""logDebug""
            ""HttpServer is not using security""
          )
          Apply(
            ""server"".""setHandler""
            ""handlerList""
          )
        )
      )
      Apply(
        ""server"".""start""
        Nil
      )
      ValDef(
        0
        ""actualPort""
        <tpt>
        server.getConnectors()(0).""getLocalPort""
      )
      Apply(
        ""scala"".""Tuple2""
        // 2 arguments
        ""server""
        ""actualPort""
      )
    )
  )
  DefDef( // private def setupSecurityHandler: <?> in class HttpServer
    <method> private
    ""setupSecurityHandler""
    []
    // 1 parameter list
    ValDef(
      <param>
      ""securityMgr""
      ""SecurityManager""
      <empty>
    )
    ""ConstraintSecurityHandler""
    Block(
      // 16 statements
      ValDef(
        0
        ""constraint""
        <tpt>
        Apply(
          new Constraint.""<init>""
          Nil
        )
      )
      Apply(
        ""constraint"".""setName""
        ""Constraint"".""__DIGEST_AUTH""
      )
      Apply(
        ""constraint"".""setRoles""
        Apply(
          ""Array""
          ""user""
        )
      )
      Apply(
        ""constraint"".""setAuthenticate""
        true
      )
      Apply(
        ""constraint"".""setDataConstraint""
        ""Constraint"".""DC_NONE""
      )
      ValDef(
        0
        ""cm""
        <tpt>
        Apply(
          new ConstraintMapping.""<init>""
          Nil
        )
      )
      Apply(
        ""cm"".""setConstraint""
        ""constraint""
      )
      Apply(
        ""cm"".""setPathSpec""
        ""/*""
      )
      ValDef(
        0
        ""sh""
        <tpt>
        Apply(
          new ConstraintSecurityHandler.""<init>""
          Nil
        )
      )
      ValDef(
        0
        ""hashLogin""
        <tpt>
        Apply(
          new HashLoginService.""<init>""
          Nil
        )
      )
      ValDef(
        0
        ""userCred""
        <tpt>
        Apply(
          new Password.""<init>""
          Apply(
            ""securityMgr"".""getSecretKey""
            Nil
          )
        )
      )
      If(
        Apply(
          ""userCred"".""$eq$eq""
          null
        )
        Throw(
          Apply(
            new Exception.""<init>""
            ""Error: secret key is null with authentication on""
          )
        )
        ()
      )
      Apply(
        ""hashLogin"".""putUser""
        // 3 arguments
        Apply(
          ""securityMgr"".""getHttpUser""
          Nil
        )
        ""userCred""
        Apply(
          ""Array""
          ""user""
        )
      )
      Apply(
        ""sh"".""setLoginService""
        ""hashLogin""
      )
      Apply(
        ""sh"".""setAuthenticator""
        Apply(
          new DigestAuthenticator.""<init>""
          Nil
        )
      )
      Apply(
        ""sh"".""setConstraintMappings""
        Apply(
          ""Array""
          ""cm""
        )
      )
      ""sh""
    )
  )
  DefDef( // def stop(): Unit in class HttpServer
    <method> <triedcooking>
    ""stop""
    []
    List(Nil)
    ""scala"".""Unit"" // final abstract class Unit extends AnyVal in package
scala, tree.tpe=Unit
    If(
      Apply(
        ""server"".""$eq$eq""
        null
      )
      Throw(
        Apply(
          new ServerStateException.""<init>""
          ""Server is already stopped""
        )
      )
      Block(
        // 2 statements
        Apply(
          ""server"".""stop""
          Nil
        )
        Assign(
          ""port""
          -1
        )
        Assign(
          ""server""
          null
        )
      )
    )
  )
  DefDef( // def uri: String in class HttpServer
    <method> <triedcooking>
    ""uri""
    []
    Nil
    ""String""
    If(
      Apply(
        ""server"".""$eq$eq""
        null
      )
      Throw(
        Apply(
          new ServerStateException.""<init>""
          ""Server is not started""
        )
      )
      Apply(
        ""http://"".$plus(Utils.localIpAddress).$plus("":"").""$plus""
        ""port""
      )
    )
  )
)

uncaught exception during compilation: java.lang.AssertionError
[INFO]
------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO]
[INFO] Spark Project Parent POM ........................... SUCCESS [
 4.306 s]
[INFO] Spark Project Networking ........................... SUCCESS [
 6.978 s]
[INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [
 5.273 s]
[INFO] Spark Project Core ................................. SKIPPED
[INFO] Spark Project Bagel ................................ SKIPPED
[INFO] Spark Project GraphX ............................... SKIPPED
[INFO] Spark Project Streaming ............................ SKIPPED
[INFO] Spark Project Catalyst ............................. SKIPPED
[INFO] Spark Project SQL .................................. SKIPPED
[INFO] Spark Project ML Library ........................... SKIPPED
[INFO] Spark Project Tools ................................ SKIPPED
[INFO] Spark Project Hive ................................. SKIPPED
[INFO] Spark Project REPL ................................. SKIPPED
[INFO] Spark Project YARN Parent POM ...................... SKIPPED
[INFO] Spark Project YARN Stable API ...................... SKIPPED
[INFO] Spark Project Hive Thrift Server ................... SKIPPED
[INFO] Spark Project Assembly ............................. SKIPPED
[INFO] Spark Project External Twitter ..................... SKIPPED
[INFO] Spark Project External Flume Sink .................. SKIPPED
[INFO] Spark Project External Flume ....................... SKIPPED
[INFO] Spark Project External MQTT ........................ SKIPPED
[INFO] Spark Project External ZeroMQ ...................... SKIPPED
[INFO] Spark Project External Kafka ....................... SKIPPED
[INFO] Spark Project Examples ............................. SKIPPED
[INFO] Spark Project YARN Shuffle Service ................. SKIPPED
[INFO]
------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO]
------------------------------------------------------------------------
[INFO] Total time: 33.464 s
[INFO] Finished at: 2015-03-27T12:01:56-07:00
[INFO] Final Memory: 58M/541M
[INFO]
------------------------------------------------------------------------
---------------------------------------------------
constituent[0]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/aether-api-1.0.0.v20140518.jar
constituent[1]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/aether-connector-basic-1.0.0.v20140518.jar
constituent[2]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/aether-impl-1.0.0.v20140518.jar
constituent[3]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/aether-spi-1.0.0.v20140518.jar
constituent[4]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/aether-transport-wagon-1.0.0.v20140518.jar
constituent[5]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/aether-util-1.0.0.v20140518.jar
constituent[6]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/aopalliance-1.0.jar
constituent[7]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/cdi-api-1.0.jar
constituent[8]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/commons-cli-1.2.jar
constituent[9]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/commons-io-2.2.jar
constituent[10]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/commons-lang-2.6.jar
constituent[11]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/guava-18.0.jar
constituent[12]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/javax.inject-1.jar
constituent[13]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/jsoup-1.7.2.jar
constituent[14]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/jsr250-api-1.0.jar
constituent[15]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-aether-provider-3.2.5.jar
constituent[16]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-artifact-3.2.5.jar
constituent[17]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-compat-3.2.5.jar
constituent[18]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-core-3.2.5.jar
constituent[19]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-embedder-3.2.5.jar
constituent[20]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-model-3.2.5.jar
constituent[21]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-model-builder-3.2.5.jar
constituent[22]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-plugin-api-3.2.5.jar
constituent[23]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-repository-metadata-3.2.5.jar
constituent[24]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-settings-3.2.5.jar
constituent[25]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/maven-settings-builder-3.2.5.jar
constituent[26]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/org.eclipse.sisu.inject-0.3.0.M1.jar
constituent[27]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/org.eclipse.sisu.plexus-0.3.0.M1.jar
constituent[28]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/plexus-cipher-1.7.jar
constituent[29]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/plexus-component-annotations-1.5.5.jar
constituent[30]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/plexus-interpolation-1.21.jar
constituent[31]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/plexus-sec-dispatcher-1.3.jar
constituent[32]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/plexus-utils-3.0.20.jar
constituent[33]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/sisu-guice-3.2.3-no_aop.jar
constituent[34]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/slf4j-api-1.7.5.jar
constituent[35]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/slf4j-simple-1.7.5.jar
constituent[36]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/wagon-file-2.8.jar
constituent[37]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/wagon-http-2.8-shaded.jar
constituent[38]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/wagon-http-shared-2.8.jar
constituent[39]:
file:/usr/local/Cellar/maven/3.2.5/libexec/lib/wagon-provider-api-2.8.jar
constituent[40]: file:/usr/local/Cellar/maven/3.2.5/libexec/conf/logging/
---------------------------------------------------
Exception in thread ""main"" java.lang.AssertionError: assertion failed:
javax.servlet.ServletException
at scala.reflect.internal.Symbols$Symbol.info(Symbols.scala:1212)
at scala.reflect.internal.Symbols$Symbol.initialize(Symbols.scala:1374)
at
scala.tools.nsc.symtab.classfile.ClassfileParser.parseExceptions$1(ClassfileParser.scala:1051)
at
scala.tools.nsc.symtab.classfile.ClassfileParser.scala$tools$nsc$symtab$classfile$ClassfileParser$$parseAttribute$1(ClassfileParser.scala:920)
at
scala.tools.nsc.symtab.classfile.ClassfileParser.parseAttributes(ClassfileParser.scala:1080)
at
scala.tools.nsc.symtab.classfile.ClassfileParser.parseMethod(ClassfileParser.scala:666)
at
scala.tools.nsc.symtab.classfile.ClassfileParser.scala$tools$nsc$symtab$classfile$ClassfileParser$$queueLoad$1(ClassfileParser.scala:557)
at
scala.tools.nsc.symtab.classfile.ClassfileParser$$anonfun$parseClass$1.apply$mcV$sp(ClassfileParser.scala:567)
at
scala.tools.nsc.symtab.classfile.ClassfileParser.parseClass(ClassfileParser.scala:572)
at
scala.tools.nsc.symtab.classfile.ClassfileParser.parse(ClassfileParser.scala:88)
at
scala.tools.nsc.symtab.SymbolLoaders$ClassfileLoader.doComplete(SymbolLoaders.scala:261)
at
scala.tools.nsc.symtab.SymbolLoaders$SymbolLoader.complete(SymbolLoaders.scala:194)
at
scala.tools.nsc.symtab.SymbolLoaders$SymbolLoader.load(SymbolLoaders.scala:210)
at scala.reflect.internal.Symbols$Symbol.exists(Symbols.scala:893)
at scala.tools.nsc.typechecker.Typers$Typer.typedIdent$2(Typers.scala:5064)
at
scala.tools.nsc.typechecker.Typers$Typer.typedIdentOrWildcard$1(Typers.scala:5218)
at scala.tools.nsc.typechecker.Typers$Typer.typed1(Typers.scala:5561)
at org.scalamacros.paradise.typechecker.Analyzer$$anon$1.org
$scalamacros$paradise$typechecker$Typers$ParadiseTyper$$super$typed1(Analyzer.scala:19)
at
org.scalamacros.paradise.typechecker.Typers$ParadiseTyper$class.typed1(Typers.scala:44)
at
org.scalamacros.paradise.typechecker.Analyzer$$anon$1.typed1(Analyzer.scala:19)
at scala.tools.nsc.typechecker.Typers$Typer.typed(Typers.scala:5642)
at scala.tools.nsc.typechecker.Typers$Typer.typedType(Typers.scala:5769)
at scala.tools.nsc.typechecker.Typers$Typer.typedType(Typers.scala:5772)
at scala.tools.nsc.typechecker.Namers$Namer.valDefSig(Namers.scala:1317)
at scala.tools.nsc.typechecker.Namers$Namer.getSig$1(Namers.scala:1457)
at scala.tools.nsc.typechecker.Namers$Namer.typeSig(Namers.scala:1466)
at
scala.tools.nsc.typechecker.Namers$Namer$$anonfun$monoTypeCompleter$1$$anonfun$apply$1.apply$mcV$sp(Namers.scala:731)
at
scala.tools.nsc.typechecker.Namers$Namer$$anonfun$monoTypeCompleter$1$$anonfun$apply$1.apply(Namers.scala:730)
at
scala.tools.nsc.typechecker.Namers$Namer$$anonfun$monoTypeCompleter$1$$anonfun$apply$1.apply(Namers.scala:730)
at
scala.tools.nsc.typechecker.Namers$Namer.scala$tools$nsc$typechecker$Namers$Namer$$logAndValidate(Namers.scala:1499)
at
scala.tools.nsc.typechecker.Namers$Namer$$anonfun$monoTypeCompleter$1.apply(Namers.scala:730)
at
scala.tools.nsc.typechecker.Namers$Namer$$anonfun$monoTypeCompleter$1.apply(Namers.scala:729)
at
org.scalamacros.paradise.typechecker.Namers$$anon$3.completeImpl(Namers.scala:74"
"
Joseph Bradley <joseph@databricks.com>,Fri"," 27 Mar 2015 12:49:51 -0700""",Re: LogisticGradient Design,Debasish Das <debasish.das83@gmail.com>,"Makes sense!


"
Doug Balog <doug.sparkdev@dugos.com>,"Fri, 27 Mar 2015 15:57:49 -0400",Re: Support for Hive 0.14 in secure mode on hadoop 2.6.0,Cheng Lian <lian.cs.zju@gmail.com>,"Is there a JIRA for this adaption layer ? It sounds like a better long term solution.

If anybody knows what is require to get the current Shim layer working with Hive 0.14, please post what you know.
Im willing to spend some time on it, but Im still learning how things fit together and it might take me a while.
Ive been looking at the pr associated with SPARK-5111 for hints.

Thanks,

Doug


layer with an adaption layer in Spark SQL in 1.4. This adaption layer allows Spark SQL to connect to arbitrary Hive version greater than or equal to 0.12.0 (or maybe 0.13.1, not decided yet).
of the current Spark SQL Hive support.
secure mode on hadoop 2.6.0 ?
https://issues.apache.org/jira/browse/SPARK-5111


---------------------------------------------------------------------


"
Stephen Boesch <javadba@gmail.com>,"Fri, 27 Mar 2015 16:16:41 -0700",Re: Iterative pyspark / scala codebase development,Davies Liu <davies@databricks.com>,"Thx much!  This works.

My workflow is making changes to files in Intelij and running ipython to
execute pyspark.

Is there any way for ipython to ""see the updated class files without first
exiting?

2015-03-27 10:21 GMT-07:00 Davies Liu <davies@databricks.com>:

"
Zhan Zhang <zzhang@hortonworks.com>,"Fri, 27 Mar 2015 23:20:47 +0000",Re: Support for Hive 0.14 in secure mode on hadoop 2.6.0,Doug Balog <doug.sparkdev@dugos.com>,"Hi Doug,

Spark-5111 is to make spark work with security hadoop cluster in 2.6. There is some compatibility issue which need the fix Spark-5111 patch.
In insecure cluster, current spark can connect to hive-0.14 without problems.

By the way, I am really glad to hear that ""an adaption layer in Spark SQL in 1.4 and ""allows Spark SQL to connect to arbitrary Hive version

Thanks.

Zhan Zhang


rm solution.
th Hive 0.14, please post what you know.
gs fit together and it might take me a while.
er with an adaption layer in Spark SQL in 1.4. This adaption layer allows Spark SQL to connect to arbitrary Hive version greater than or equal to 0.12.0 (or maybe 0.13.1, not decided yet).
f the current Spark SQL Hive support.
cure mode on hadoop 2.6.0 ?
SPARK-5111


---------------------------------------------------------------------


"
jimfcarroll <jimfcarroll@gmail.com>,"Fri, 27 Mar 2015 17:54:58 -0700 (MST)",RDD.count,dev@spark.apache.org,"Hi all,

I was wondering why the RDD.count call recomputes the RDD in all cases? In
most cases it can simply ask the next dependent RDD. I have several RDD
implementations and was surprised to see a call like the following never
call my RDD's count method but instead recompute/traverse the entire
dataset:

   val myRDD: MyRDD = ...
   myRDD.map({ ... }).count()

Unless I'm mistaken, a MappedRDD never needs to do more than call 'count' on
the underlying RDD. The underlying RDD's count method (in all of my cases)
know their count without a recompute (e.g. one of them selects the count
from a DB). This is MUCH less expensive than recomputing the RDD.

Thanks.
Jim




--

---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Sat, 28 Mar 2015 04:04:40 +0000",Re: RDD.count,Jim Carroll <jimfcarroll@gmail.com>,"I assume because map() could have side effects? Even if that's not
generally a good idea. The expectation or contract is that it is still
invoked. In this program the caller could also call count() on the parent.

"
Davies Liu <davies@databricks.com>,"Fri, 27 Mar 2015 22:17:04 -0700",Re: Iterative pyspark / scala codebase development,Stephen Boesch <javadba@gmail.com>,"
No, iPython shell is statefull, it will have unexpected behavior when
you reload the library.


---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Sat, 28 Mar 2015 05:20:35 +0000",Re: Building spark 1.2 from source requires more dependencies,Pala M Muthaia <mchettiar@rocketfuelinc.com>,"This is not a compile error, but an error from the scalac compiler.
That is, the code and build are fine, but scalac is not compiling it.
Usually when this happens, a clean build fixes it.


---------------------------------------------------------------------


"
jimfcarroll <jimfcarroll@gmail.com>,"Sat, 28 Mar 2015 06:05:32 -0700 (MST)",Re: RDD.count,dev@spark.apache.org,"Hi Sean,

Thanks for the response.

I can't imagine a case (though my imagination may be somewhat limited) where
even map side effects could change the number of elements in the resulting
map.

I guess ""count"" wouldn't officially be an 'action' if it were implemented
this way. At least it wouldn't ALWAYS be one.

My example was contrived. We're passing RDDs to functions. If that RDD is an
instance of my class, then its count() may take a shortcut. If I
map/zip/zipWithIndex/mapPartition/etc. first then I'm stuck with a call that
literally takes 100s to 1000s of times longer (seconds vs hours on some of
our datasets) and since my custom RDDs are immutable they cache the count
call so a second invocation is the cost of a method call's overhead.

I could fix this in Spark if there's any interest in that change. Otherwise
I'll need to overload more RDD methods for my own purposes (like all of the
transformations). Of course, that will be more difficult because those
intermediate classes (like MappedRDD) are private, so I can't extend them.

Jim




--

---------------------------------------------------------------------


"
Sean Owen <sowen@cloudera.com>,"Sat, 28 Mar 2015 13:10:35 +0000",Re: RDD.count,jimfcarroll <jimfcarroll@gmail.com>,"No, I'm not saying side effects change the count. But not executing
the map() function at all certainly has an effect on the side effects
of that function: the side effects which should take place never do. I
am not sure that is something to be 'fixed'; it's a legitimate
question.

You can persist an RDD if you do not want to compute it twice.


---------------------------------------------------------------------


"
Sandy Ryza <sandy.ryza@cloudera.com>,"Sat, 28 Mar 2015 07:42:51 -0700",Re: RDD.count,Sean Owen <sowen@cloudera.com>,"I definitely see the value in this.  However, I think at this point it
would be an incompatible behavioral change.  People often use count in
Spark to exercise their DAG.  Omitting processing steps that were
previously included would likely mislead many users into thinking their
pipeline was running faster.

It's possible there might be room for something like a new smartCount API
or a new argument to count that allows it to avoid unnecessary
transformations.

-Sandy


"
Patrick Woody <patrick.woody1@gmail.com>,"Sat, 28 Mar 2015 11:26:44 -0400",Lazy casting with Catalyst,dev@spark.apache.org,"Hi all,

In my application, we take input from Parquet files where BigDecimals are
written as Strings to maintain arbitrary precision.

I was hoping to convert these back over to Decimal with Unlimited
precision, but I'd still like to maintain the Parquet column pruning (all
my attempts thus far seem to bring in the whole Row). Is it possible to do
this lazily through catalyst?

Basically I'd want to do Cast(col, DecimalType()) whenever col is actually
referenced. Any tips on how to approach this would be appreciated.

Thanks!
-Pat
"
Cheng Lian <lian.cs.zju@gmail.com>,"Sat, 28 Mar 2015 23:35:13 +0800",Re: Lazy casting with Catalyst,"Patrick Woody <patrick.woody1@gmail.com>, dev@spark.apache.org","Hi Pat,

I don't understand what ""lazy casting"" mean here. Why do you think 
current Catalyst casting is ""eager""? Casting happens at runtime, and 
doesn't disable column pruning.

Cheng



---------------------------------------------------------------------


"
Patrick Woody <patrick.woody1@gmail.com>,"Sat, 28 Mar 2015 12:26:48 -0400",Re: Lazy casting with Catalyst,Cheng Lian <lian.cs.zju@gmail.com>,"Hey Cheng,

I didn't meant that catalyst casting was eager, just that my approaches
thus far seem to have been. Maybe I should give a concrete example?

I have columns A, B, C where B is saved as a String but I'd like all
references to B to go through a Cast to decimal regardless of the code used
on the SchemaRDD. So if someone does a min(B) it uses Decimal ordering
instead of String.

casts on certain columns, but then when I did a count(literal(1)) on top of
that RDD it seemed to bring in the whole row.

Thanks!
-Pat


"
Cheng Lian <lian.cs.zju@gmail.com>,"Sun, 29 Mar 2015 00:34:36 +0800",Re: Lazy casting with Catalyst,Patrick Woody <patrick.woody1@gmail.com>,"
What version of Spark SQL are you using? Would you mind to provide a 
brief snippet that can reproduce this issue? This might be a bug 
depending on your concrete usage. Thanks in advance!

"
Patrick Woody <patrick.woody1@gmail.com>,"Sat, 28 Mar 2015 14:37:41 -0400",Re: Lazy casting with Catalyst,Cheng Lian <lian.cs.zju@gmail.com>,"So it looks like this was actually a combination of using out of date
artifacts and further debugging needed on my part. Ripping the logic out
and testing in spark-shell works fine, so it is likely something upstream
in my application that causes it to take the whole Row.

Thanks!
-Pat






"
Reynold Xin <rxin@databricks.com>,"Sat, 28 Mar 2015 16:34:45 -0700",Re: RDD.count,Sandy Ryza <sandy.ryza@cloudera.com>,"I think the worry here is that people often use count() to force execution,
and when coupled with transformations with side-effect, it is no longer
safe to not run it.

However, maybe we can add a new lazy val .size that doesn't require
recomputation.



"
jimfcarroll <jimfcarroll@gmail.com>,"Sat, 28 Mar 2015 18:14:06 -0700 (MST)",Re: RDD.count,dev@spark.apache.org,"Hello all,

I worked around this for now using the class (that I already had) that
inherits from RDD and is the one all of our custom RDDs inherit from. I did
the following:

1) Overload all of the transformations (that get used in our app) that don't
change the RDD size wrapping the results with a proxy rdd that intercepts
the count() call returning a cached version or calling an abstract
""calculateSize"" if it doesn't already know the count.

2) piggyback a count calculation on all actions that we use (aggregate,
reduce, fold, foreach) so that as a side effect of calling any of these, if
the count isn't already known, it's calculated and stored.

The one thing I couldn't do (at least yet) was get zipWithIndex to calculate
the count because it's implementation is too opaque inside of the RDD.

If anyone wants to see the code I can post it.

Thanks for the responses.

Jim




--

---------------------------------------------------------------------


"
Dale Richardson <dale__r@hotmail.com>,"Sun, 29 Mar 2015 20:47:14 +0000",,"""dev@spark.apache.org"" <dev@spark.apache.org>","Recently had an incident reported to me where somebody was analysing a directory of gzipped log files, and was struggling to load them into spark because one of the files was corrupted - calling sc.textFiles('hdfs:///logs/*.gz') caused an IOException on the particular executor that was reading that file, which caused the entire job to be cancelled after the retry count was exceeded, without any way of catching and recovering from the error.  While normally I think it is entirely appropriate to stop execution if something is wrong with your input, sometimes it is useful to analyse what you can get (as long as you are aware that input has been skipped), and treat corrupt files as acceptable losses.
To cater for this particular case I've added SPARK-6593 (PR at https://github.com/apache/spark/pull/5250). Which adds an option (spark.hadoop.ignoreInputErrors) to log exceptions raised by the hadoop Input format, but to continue on with the next task.
Ideally in this case you would want to report the corrupt file paths back to the master so they could be dealt with in a particular way (eg moved to a separate directory), but that would require a public API change/addition. I was pondering on an addition to Spark's hadoop API that could report processing status back to the master via an optional accumulator that collects filepath/Option(exception message) tuples so the user has some idea of what files are being processed, and what files are being skipped.
Regards,Dale. 		 	   		  "
Pala M Muthaia <mchettiar@rocketfuelinc.com>,"Sun, 29 Mar 2015 14:29:16 -0700",Re: Building spark 1.2 from source requires more dependencies,Sean Owen <sowen@cloudera.com>,"Sean,

I did a mvn clean and then build, it produces the same error. I also did a
fresh git clone of spark and invoked the same build command and it resulted
in identical error (I also had a colleague do a same thing, lest there was
some machine specific issue, and saw the same error). Unless i
misunderstood something, it doesn't look like clean build fixes this.


"
Sean Owen <sowen@cloudera.com>,"Sun, 29 Mar 2015 22:35:56 +0100",Re: Building spark 1.2 from source requires more dependencies,Pala M Muthaia <mchettiar@rocketfuelinc.com>,"Given that's it's an internal error from scalac, I think it may be
something to take up with the Scala folks to really fix. We can just
look for workarounds. Try blowing away your .m2 and .ivy cache for
example. FWIW I was running on Linux with Java 8u31, latest scala 2.11
AFAIK.


---------------------------------------------------------------------


"
Niranda Perera <niranda.perera@gmail.com>,"Mon, 30 Mar 2015 09:39:20 +0530",What is the meaning to of 'STATE' in a worker/ an executor?,"""dev@spark.apache.org"" <dev@spark.apache.org>, ""user@spark.apache.org"" <user@spark.apache.org>","Hi,

I have noticed in the Spark UI, workers and executors run on several
states, ALIVE, LOADING, RUNNING, DEAD etc?

What exactly are these states mean and what is the effect it has on working
with those executor?
ex: whether an executor can not be used in the loading state, etc

cheers

-- 
Niranda
"
Mark Hamstra <mark@clearstorydata.com>,"Sun, 29 Mar 2015 21:17:24 -0700",Re: What is the meaning to of 'STATE' in a worker/ an executor?,Niranda Perera <niranda.perera@gmail.com>,"A LOADING Executor is on the way to RUNNING, but hasn't yet been registered with the Master, so it isn't quite ready to do useful work.


te:
s, ALIVE, LOADING, RUNNING, DEAD etc?
g with those executor?

---------------------------------------------------------------------


"
yash datta <saucam@gmail.com>,"Mon, 30 Mar 2015 13:21:36 +0530",Re: Building spark 1.2 from source requires more dependencies,dev@spark.apache.org,"Hi all,


When selecting large data in sparksql (Select * query) , I see Buffer
overflow exception from kryo :


15/03/27 10:32:19 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 3.0
(TID 30, machine159): com.esotericsoftware.kryo.KryoException: Buffer
overflow. Available: 1, required: 2
Serialization trace:
values (org.apache.spark.sql.catalyst.expressions.GenericRow)
        at com.esotericsoftware.kryo.io.Output.require(Output.java:138)
        at com.esotericsoftware.kryo.io.Output.writeInt(Output.java:247)
        at
com.esotericsoftware.kryo.serializers.DefaultSerializers$IntSerializer.write(DefaultSerializers.java:95)
        at
com.esotericsoftware.kryo.serializers.DefaultSerializers$IntSerializer.write(DefaultSerializers.java:89)
        at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568)
        at
com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:318)
        at
com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:293)
        at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:501)
        at
com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.write(FieldSerializer.java:564)
        at
com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:213)
        at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568)
        at
com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:318)
        at
com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:293)
        at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:568)
        at
org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:167)
        at
org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:210)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown
Source)
        at java.lang.Thread.run(Unknown Source)



I thought maybe increasing these would resolve the problem, but the same
exception is seen :

set spark.kryoserializer.buffer.mb=4;
set spark.kryoserializer.buffer.max.mb=1024;


I have a parquet table with 5 Int columns , 100 million rows.

Can somebody guide why this exception is seen, am I missing some
configuration ?

Thanks
Yash





-- 
When events unfold with calm and ease
When the winds that blow are merely breeze
Learn from nature, from birds and bees
Live your life in love, and let joy not cease.
"
Peter Rudenko <petro.rudenko@gmail.com>,"Mon, 30 Mar 2015 15:02:37 +0300",[sql] How to uniquely identify Dataframe?,dev@spark.apache.org,"Hi i have some custom caching logic in my application. I need to 
identify somehow Dataframe, to check whether i saw it previously. Here’s 
a problem:

|scala> val data = sc.parallelize(1 to 1000) data: 
org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize 
at <console>:21 scala> data.id res0: Int = 0 scala> data.id res1: Int = 
0 scala> val dataDF = data.toDF dataDF: org.apache.spark.sql.DataFrame = 
[_1: int] scala> dataDF.rdd.id res3: Int = 2 scala> dataDF.rdd.id res4: 
Int = 3 |

For some reason it generates a new ID on each call. With schemaRDD i was 
able to call SchemaRDD.id.

Thanks,
Peter Rudenko

​
"
Cheng Lian <lian.cs.zju@gmail.com>,"Mon, 30 Mar 2015 20:38:37 +0800",Re: [sql] How to uniquely identify Dataframe?,"Peter Rudenko <petro.rudenko@gmail.com>, dev@spark.apache.org","This is because unlike SchemaRDD, DataFrame itself is no longer an RDD 
now. In the meanwhile, DataFrame.rdd is a function, which always returns 
a new RDD. I think you may use DataFrame.queryExecution.logical (the 
logical plan) as an ID. Maybe we should make it a ""lazy val"" rather than 
a ""def"". Personally I don't find a good reason that it has to be a 
""def"", but maybe I miss something here.

Filed JIRA ticket and PR for this:

- https://issues.apache.org/jira/browse/SPARK-6608
- https://github.com/apache/spark/pull/5265

Cheng



---------------------------------------------------------------------


"
Reynold Xin <rxin@databricks.com>,"Mon, 30 Mar 2015 09:31:41 -0700",Re: [sql] How to uniquely identify Dataframe?,Cheng Lian <lian.cs.zju@gmail.com>,"The only reason I can think of right now is that you might want to change
the config parameter to change the behavior of the optimizer and regenerate
the plan. However, maybe that's not a strong enough reasons to regenerate
the RDD everytime.



a
a
ut
y
a problem:
e at
 0
= [_1:
 =
"
Xiangrui Meng <mengxr@gmail.com>,"Mon, 30 Mar 2015 14:31:58 -0700",Re: mllib.recommendation Design,Debasish Das <debasish.das83@gmail.com>,"
We don't expose 3rd-party types in our public APIs. You can either
implement your algorithm under org.apache.spark or copy the
fromBreeze/toBreeze code over.


That sounds okay.


It breaks compatibility if we move it. I think it should be quite
flexible about where we put the implementation.


I'm really sorry about the late response on this. It is partially
because that I'm still not sure about whether there exist many
applications that need this feature. Please do list some public work
and help us to understand the need.


---------------------------------------------------------------------


"
Xiangrui Meng <mengxr@gmail.com>,"Mon, 30 Mar 2015 14:42:30 -0700",Re: Using CUDA within Spark / boosting linear algebra,Sean Owen <sowen@cloudera.com>,"Hi Alex,

Since it is non-trivial to make nvblas work with netlib-java, it would
be great if you can send the instructions to netlib-java as part of
the README. Hopefully we don't need to modify netlib-java code to use
nvblas.

Best,
Xiangrui


---------------------------------------------------------------------


"
"""Ganelin, Ilya"" <Ilya.Ganelin@capitalone.com>","Mon, 30 Mar 2015 19:40:31 -0400",Problems with cleanup throughout code base,dev <dev@spark.apache.org>,"Hi all, when looking into a fix for a deadlock in the SparkContext shutdown code for https://issues.apache.org/jira/browse/SPARK-6492, I noticed that the isStopped flag is set to true before executing the actual shutdown code. This is a problem since it means that if the shutdown sequence doesnt complete successfully that parts of the code will never get shut down. I looked deeper and found examples of this in other places as well. Ive created a JIRA for it here:

https://issues.apache.org/jira/browse/SPARK-6616

Is there a reason that this exists in its present state? I know that its a significant effort to fix this since there are definitely instances throughout the code where a double cleanup would break at the moment (e.g. AsynchronousBusListener.stop()). I would, however, be strongly in favor of fixing this, and I would be happy to do it since its a lot easier to solve the more obvious problems caused by an exception from a double cleanup than to find the insidious errors from an incomplete cleanup.

I would appreciate any feedback.
Thank you,
Ilya Ganelin

________________________________________________________

The information contained in this e-mail is confidential and/or proprietary is intended only for use by the individual or entity to which it is addressed.  If the reader of this message is not the intended recipient, you are hereby notified that any review, retransmission, dissemination, distribution, copying or other use of, or taking of any action in reliance upon this information is strictly prohibited. If you have received this communication in error, please contact the sender and delete the material from your computer.
"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Mon, 30 Mar 2015 23:59:49 +0000",Stochastic gradient descent performance,"""dev@spark.apache.org"" <dev@spark.apache.org>","Hi,

It seems to me that there is an overhead in ""runMiniBatchSGD"" function of MLlib's ""GradientDescent"". In particular, ""sample"" and ""treeAggregate"" might take time that is order of magnitude greater than the actual gradient computation. In particular, for mnist dataset of 60K instances, minibatch size = 0.001 (i.e. 60 samples) it take 0.15 s to sample and 0.3 to aggregate in local mode with 1 data partition on Core i5 processor. The actual gradient computation takes 0.002 s. I searched through Spark Jira and found that there was recently an update for more efficient sampling (SPARK-3250) that is already included in Spark codebase. Is there a way to reduce the sampling time and local treeRedeuce by order of magnitude?

Best regards, Alexander
"
"""Ulanov, Alexander"" <alexander.ulanov@hp.com>","Tue, 31 Mar 2015 00:11:34 +0000",RE: Using CUDA within Spark / boosting linear algebra,"Xiangrui Meng <mengxr@gmail.com>, Sam Halliday <sam.halliday@gmail.com>","Hi Sam, 

What is the best way to do it? Should I clone netlib-java, edit readme.md and make a PR?

Best regards, Alexander


-----Original Message-----
From: Xiangrui Meng [mailto:mengxr@gmail.com] 
Sent: Monday, March 30, 2015 2:43 PM
To: Sean Owen
Cc: Evan R. Sparks; Sam Halliday; dev@spark.apache.org; Ulanov, Alexander; jfcanny
Subject: Re: Using CUDA within Spark / boosting linear algebra

Hi Alex,

Since it is non-trivial to make nvblas work with netlib-java, it would be great if you can send the instructions to netlib-java as part of the README. Hopefully we don't need to modify netlib-java code to use nvblas.

Best,
Xiangrui

On Thu, Mar 26, 2015 at 9:54 AM, Sean Owen <sowen@cloudera.com> wrote:
> The license issue is with libgfortran, rather than OpenBLAS.
>
> (FWIW I am going through the motions to get OpenBLAS set up by default 
> on CDH in the near future, and the hard part is just handling
> libgfortran.)
>
> On Thu, Mar 26, 2015 at 4:07 PM, Evan R. Sparks <evan.sparks@gmail.com> wrote:
>> Alright Sam - you are the expert here. If the GPL issues are 
>> unavoidable, that's fine - what is the exact bit of code that is GPL?
>>
>> The suggestion to use OpenBLAS is not to say it's the best option, 
>> but that it's a *free, reasonable default* for many users - keep in 
>> mind the most common deployment for Spark/MLlib is on 64-bit linux on EC2[1].
>> Additionally, for many of the problems we're targeting, this 
>> reasonable default can provide a 1-2 orders of magnitude improvement 
>> in performance over the f2jblas implementation that netlib-java falls back on.
>
> ---------------------------------------------------------------------
> To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For 
> additional commands, e-mail: dev-help@spark.apache.org
>
"
Debasish Das <debasish.das83@gmail.com>,"Mon, 30 Mar 2015 19:08:09 -0700",Re: mllib.recommendation Design,Xiangrui Meng <mengxr@gmail.com>,"For alm I have started experimenting with the following:

1. rmse and map improvement from loglikelihood loss over least square loss.

2. Factorization for datasets that are not ratings (basically improvement
over implicit ratings)

3. Sparse topic generation using plsa. We are directly optimizing
likelihood under constraints here and so I feel it will improve upon EM
algorithm. Also the current LDA does not produce sparse topics and ALM
results can augment LDA flow. I am understanding LDA flow to see if the
sparsity and loglikelihood optimization can be added there.

I will understand more as I see the result. I am not sure if it is
supported by public packages like graphlab or scikit but the plsa papers
show interesting results.

"
"""wyphao.2007"" <wyphao.2007@163.com>","Tue, 31 Mar 2015 10:47:46 +0800 (CST)",=?GBK?Q?How_to_get_removed_RDD_from_windows=A3=BF?=,"user@spark.apache.org, dev@spark.apache.org","I want to get removed RDD from windows as follow, The old RDDs will removed from current window, 
//  _____________________________
// |  previous window   _________|___________________
// |___________________|       current window        |  --------------> Time
//                     |_____________________________|
//
// |________ _________|          |________ _________|
//          |                             |
//          V                             V
//       old RDDs                     new RDDs
//
I find  the slice function in DStream class can return the DStream between fromTime to  toTime. But when I use the function as follow:


    val now = System.currentTimeMillis()
    result.slice(new Time(now - 30 * 1000), new Time(now - 30 * 1000 + result.slideDuration.milliseconds)).foreach(item => println(""xxx"" + item))
    ssc.start()


30 is the window's duration,Then I got zeroTime has not been initialized exception. 


Is anyone can help me? thx!










"
"""wyphao.2007"" <wyphao.2007@163.com>","Tue, 31 Mar 2015 10:46:27 +0800 (CST)",=?GBK?Q?How_to_get_removed_RDD_from_windows=A3=BF?=,"user@spark.apache.org, dev@spark.apache.org","I want to get removed RDD from windows as follow, The old RDDs will removed from current window, 
//  _____________________________
// |  previous window   _________|___________________
// |___________________|       current window        |  --------------> Time
//                     |_____________________________|
//
// |________ _________|          |________ _________|
//          |                             |
//          V                             V
//       old RDDs                     new RDDs
//
I find  the slice function in DStream class can return the DStream between fromTime to  toTime. But when I use the function as follow:


    val now = System.currentTimeMillis()
    result.slice(new Time(now - 30 * 1000), new Time(now - 30 * 1000 + result.slideDuration.milliseconds)).foreach(item => println(""xxx"" + item))
    ssc.start()


30 is the window's duration,Then I got zeroTime has not been initialized exception. 


Is anyone can help me? thx!







"
Reynold Xin <rxin@databricks.com>,"Mon, 30 Mar 2015 23:37:56 -0700",Re: Spark config option 'expression language' feedback request,Dale Richardson <dale__r@hotmail.com>,"Reviving this to see if others would like to chime in about this
""expression language"" for config options.



"
Mike Hynes <91mbbh@gmail.com>,"Tue, 31 Mar 2015 09:06:34 -0400",Re: Spark config option 'expression language' feedback request,Reynold Xin <rxin@databricks.com>,"Hi,
This is just a thought from my experience setting up Spark to run on a
linux cluster. I found it a bit unusual that some parameters could be
specified as command line args to spark-submit, others as env variables,
and some in a configuration file. What I ended up doing was writing my own
bash script that exported all the variables and other scripts to call
spark-submit with the arguments I wanted.

I think that the ""expressive language"" idea would be doable by using an
entirely env variable based approach, or as commandline parameters. That
way there is only one configuration, which is easily scriptable,  and you
are still able to express relations like:
spark.driver.maxResultSize = spark.driver.memory * 0.8
in your config as
export SPARK_DRIVER_MAXRESULTSIZE = $(bc -l <<< ""0.8 *
$SPARK_DRIVER_MEMORY"")

It may not look as nice, but it does allow for everything to be in one
place, and to have separate config files for certain jobs. Admittedly, if
you want something like 0.8 * 2G, you first write a bash function to expand
all the ""G M k"" symbols,  but that's not too painful.

"

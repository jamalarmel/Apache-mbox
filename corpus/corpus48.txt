Reynold you're totally right, as discussed offline -- I didn't think about
the limit use case when I wrote this.  Sandy, is it easy to fix this as
part of your patch to use StatisticsData?  If not, I can fix it in a
separate patch.
On Sat, Jul 26, 2014 at 12:12 PM, Reynold Xin  wrote:
Hi all,
I've noticed a bunch of times lately where a pull request changes to be
pretty different from the original pull request, and the title /
description never get updated.  Because the pull request title and
description are used as the commit message, the incorrect description lives
on forever, making it harder to understand the reason behind a particular
commit without going back and reading the entire conversation on the pull
request.  If folks could try to keep these up to date (and committers, try
to remember to verify that the title and description are correct before
making merging pull requests), that would be awesome.
-Kay
Hi all,
The Spark Style Guide
says multi-line comments should formatted as:
/*
 * This is a
 * very
 * long comment.
 */
But in my experience, we almost always use "//" for multi-line comments:
// This is a
// very
// long comment.
Here are some examples:
   - Recent commit by Reynold, king of style:
   https://github.com/apache/spark/commit/bebf4c42bef3e75d31ffce9bfdb331c16f34ddb1#diff-d616b5496d1a9f648864f4ab0db5a026R58
   - RDD.scala:
   https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L361
   - DAGScheduler.scala:
   https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L281
Any objections to me updating the style guide to reflect this?  As with
other style issues, I think consistency here is helpful (and formatting
multi-line comments as "//" does nicely visually distinguish code comments
from doc comments).
-Kay
Hi Pradyumn,
Take a look at this pull request, which does something similar: https://github.com/apache/spark/pull/2342/files 
You can put JavaScript in  tags in Scala. That code takes a nice approach of putting most of the JavaScript in a new file, and then just calling into it from the HTML generated by the Scala files.
-Kay
---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
Hi all,
I've noticed the Spark tests getting increasingly flaky -- it seems more
common than not now that the tests need to be re-run at least once on PRs
before they pass.  This is both annoying and problematic because it makes
it harder to tell when a PR is introducing new flakiness.
To try to clean this up, I'd propose filing a JIRA *every time* Jenkins
fails on a PR (for a reason unrelated to the PR).  Just provide a quick
description of the failure -- e.g., "Flaky test: DagSchedulerSuite" or
"Tests failed because 250m timeout expired", a link to the failed build,
and include the "Tests" component.  If there's already a JIRA for the
issue, just comment with a link to the latest failure.  I know folks don't
always have time to track down why a test failed, but this it at least
helpful to someone else who, later on, is trying to diagnose when the issue
started to find the problematic code / test.
If this seems like too high overhead, feel free to suggest alternative ways
to make the tests less flaky!
-Kay

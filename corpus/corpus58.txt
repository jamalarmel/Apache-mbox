+1 Pulled & built on MacOS X, EC2 Amazon Linux Ran test programs on OS X, 5 node c3.4xlarge cluster Cheers On Wed, May 28, 2014 at 7:36 PM, Andy Konwinski  +1 Stephen, We are working thru Dell configurations; would be happy to review your diagrams and offer feedback from our experience. Let me know the URLs. Cheers On Thu, Jun 5, 2014 at 2:51 PM, Stephen Watt  wrote: +1 Compiled for CentOS 6.5, deployed in our 4 node cluster (Hadoop 2.2, YARN) Smoke Tests (sparkPi,spark-shell, web UI) successful Cheers On Thu, Jun 26, 2014 at 7:06 PM, Patrick Wendell  wrote: +1 - Compiled rc2 w/ CentOS 6.5, Yarn,Hadoop 2.2.0 - successful - Smoke Test (scala,python) (distributed cluster) - successful - We had ran Java/SparkSQL (count, distinct et al) ~250M records RDD over HBase 0.98.3 over last build (rc1) - successful - Stand alone multi-node cluster is working better for us than Yarn Cheers On Fri, Jul 4, 2014 at 12:40 PM, Patrick Wendell  wrote: Well done guys. MapReduce sort at that time was a good feat and Spark now has raised the bar with the ability to sort a PB. Like some of the folks in the list, a summary of what worked (and didn't) as well as the monitoring practices would be good. Cheers P.S: What are you folks planning next ? On Fri, Oct 10, 2014 at 7:54 AM, Matei Zaharia  Hi folks, +1 1. Compiled OSX 10.10 (Yosemite) mvn -Pyarn -Phadoop-2.4 -Dhadoop.version=2.4.0 -DskipTests clean package 10:49 min 2. Tested pyspark, mlib 2.1. statistics OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK 2.5. rdd operations OK 2.6. recommendation OK 2.7. Good work ! In 1.1.0, there was an error and my program used to hang (over memory allocation) consistently running validation using itertools, compute optimum rank, lambda,numofiterations/rmse; data - movielens medium dataset (1 million records) . It works well in 1.1.1 ! Cheers P.S: Missed Reply all, first time On Wed, Nov 12, 2014 at 8:35 PM, Andrew Or  wrote: +1 1. Compiled OSX 10.10 (Yosemite) mvn -Pyarn -Phadoop-2.4 -Dhadoop.version=2.4.0 -DskipTests clean package 10:49 min 2. Tested pyspark, mlib 2.1. statistics OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK 2.5. rdd operations OK 2.6. recommendation OK 2.7. Good work ! In 1.1.0, there was an error and my program used to hang (over memory allocation) consistently running validation using itertools, compute optimum rank, lambda,numofiterations/rmse; data - movielens medium dataset (1 million records) . It works well in 1.1.1 ! Cheers On Wed, Nov 19, 2014 at 6:00 PM, Xiangrui Meng  wrote: Looks like the documentation hasn't caught up with the new features. On the machine learning side, for example org.apache.spark.ml, RandomForest, gbtree and so forth. Is a refresh of the documentation planned ? Am happy to see these capabilities, but these would need good explanations as well, especially the new thinking around the ml ... pipelines, transformations et al. IMHO, the documentation is a -1. Will check out the compilation, mlib et al Cheers On Fri, Nov 28, 2014 at 9:16 PM, Patrick Wendell  wrote: +1 1. Compiled OSX 10.10 (Yosemite) mvn -Pyarn -Phadoop-2.4 -Dhadoop.version=2.4.0 -DskipTests clean package 16:46 min (slightly slower connection) 2. Tested pyspark, mlib - running as well as compare esults with 1.1.x 2.1. statistics OK 2.2. Linear/Ridge/Laso Regression OK Slight difference in the print method (vs. 1.1.x) of the model object - with a label & more details. This is good. 2.3. Decision Tree, Naive Bayes OK Changes in print(model) - now print (model.ToDebugString()) - OK Some changes in NaiveBayes. Different from my 1.1.x code - had to flatten list structures, zip required same number in partitions After code changes ran fine. 2.4. KMeans OK zip occasionally fails with error "localhost): org.apache.spark.SparkException: Can only zip RDDs with same number of elements in each partition"Has https://issues.apache.org/jira/browse/SPARK-2251 reappeared ? Made it work by doing a different transformation ie reusing an original rdd. 2.5. rdd operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. recommendation OK 2.7. Good work ! In 1.x.x, had a map distinct over the movielens medium dataset which never worked. Works fine in 1.2.0 ! 3. Scala Mlib - subset of examples as in #2 above, with Scala 3.1. statistics OK 3.2. Linear Regression OK 3.3. Decision Tree OK 3.4. KMeans OK Cheers P.S: Plan to add RF and .ml mechanics to this bank On Fri, Nov 28, 2014 at 9:16 PM, Patrick Wendell  wrote: Will do. Am on the road - will annotate an iPython notebook with what works & what didn't work ... Cheers On Wed, Dec 3, 2014 at 4:19 PM, Xiangrui Meng  wrote: - K-Means iPython notebook & data attached. - It is the zip that gives the error ; while one of the RDDs is from the prediction, most probably there is no problem with the K-Means. - Lines 34,35 & 36 essentially are the same. But only 36 works with 1.2.0. - Interestingly, lines 34,35 & 36 work with 1.1.1 (Checked just now) - The plot thickens! - In 1.1.1, freq_cluster_map.take(5) prints normally for 34 & 35, but in exponential form for 36. So there is some difference even in 1.1.1. - #34,#35 [(array([28143, 0, 174, 1, 0, 0, 7000]), 1), (array([19244,     0,   215,     2,     0,     0,  6968]), 1), (array([41354,     0,  4123,     4,     0,     0,  7034]), 1), (array([14776,     0,   500,     1,     0,     0,  6952]), 1), (array([97752,     0, 43300,    26,  2077,     4,  6935]), 0)] - #36 [(array([  2.81430000e+04,   0.00000000e+00,   1.74000000e+02, 1.00000000e+00,   0.00000000e+00,   0.00000000e+00, 7.00000000e+03]), 1), (array([  1.92440000e+04,   0.00000000e+00,   2.15000000e+02, 2.00000000e+00,   0.00000000e+00,   0.00000000e+00, 6.96800000e+03]), 1), (array([  4.13540000e+04,   0.00000000e+00,   4.12300000e+03, 4.00000000e+00,   0.00000000e+00,   0.00000000e+00, 7.03400000e+03]), 1), (array([  1.47760000e+04,   0.00000000e+00,   5.00000000e+02, 1.00000000e+00,   0.00000000e+00,   0.00000000e+00, 6.95200000e+03]), 1), (array([  9.77520000e+04,   0.00000000e+00,   4.33000000e+04, 2.60000000e+01,   2.07700000e+03,   4.00000000e+00, 6.93500000e+03]), 0)] - I had overwritten the naive bayes example. Will chase the older versions down Cheers On Wed, Dec 3, 2014 at 4:19 PM, Xiangrui Meng  wrote: --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org Forgot Reply To All ;o(+1 1. Compiled OSX 10.10 (Yosemite) OK Total time: 12:55 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -Phive -DskipTests 2. Tested pyspark, mlib - running as well as compare results with 1.1.x & 1.2.0 2.1. statistics OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK Fixed : org.apache.spark.SparkException in zip ! 2.5. rdd operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. recommendation OK Cheers On Mon, Jan 26, 2015 at 11:02 PM, Patrick Wendell  Please vote on releasing the following candidate as Apache Spark version +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 12:22 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -Phive -DskipTests 2. Tested pyspark, mlib - running as well as compare results with 1.1.x & 1.2.0 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK Fixed : org.apache.spark.SparkException in zip ! 2.5. rdd operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lmbda) with itertools OK Cheers On Wed, Jan 28, 2015 at 5:17 AM, Sean Owen  wrote: +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 11:13 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11 2. Tested pyspark, mlib - running as well as compare results with 1.1.x & 1.2.0 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK Fixed : org.apache.spark.SparkException in zip ! 2.5. rdd operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lmbda) with itertools OK 3. Scala - MLLib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWIthSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK Cheers On Mon, Feb 2, 2015 at 8:57 PM, Patrick Wendell  wrote: +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 14:50 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11 2. Tested pyspark, mlib - running as well as compare results with 1.1.x & 1.2.x 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK But MSE has increased from 40.81 to 105.86. Has some refactoring happened on SGD/Linear Models ? Or do we have some extra parameters ? or change of defaults ? 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK WSSSE has come down slightly 2.5. rdd operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lmbda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWIthSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK Cheers P.S: For some reason replacing  "import sqlContext.createSchemaRDD" with "import sqlContext.implicits._" doesn't do the implicit conversations. registerTempTable gives syntax error. I will dig deeper tomorrow. Has anyone seen this ? On Wed, Feb 18, 2015 at 3:25 PM, Sean Owen  wrote: Excellent. Explicit toDF() works. a) employees.toDF().registerTempTable("Employees") - works b) Also affects saveAsParquetFile - orders.toDF().saveAsParquetFile Adding to my earlier tests: 4.0 SQL from Scala and Python 4.1 result = sqlContext.sql("SELECT * from Employees WHERE State = 'WA'") OK 4.2 result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.3 result = sqlContext.sql("SELECT ShipCountry, Sum(OrderDetails.UnitPrice * Qty * Discount) AS ProductSales FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID GROUP BY ShipCountry") OK 4.4 saveAsParquetFile OK 4.5 Read and verify the 4.4 save - sqlContext.parquetFile, registerTempTable, sql OK Cheers & thanks Michael On Thu, Feb 19, 2015 at 12:02 PM, Michael Armbrust  P.S: For some reason replacing  "import sqlContext.createSchemaRDD" with "+1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 13:53 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11 2. Tested pyspark, mlib - running as well as compare results with 1.1.x & 1.2.x 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK But MSE has increased from 40.81 to 105.86. Has some refactoring happened on SGD/Linear Models ? Or do we have some extra parameters ? or change of defaults ? 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK WSSSE has come down slightly 2.5. rdd operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lmbda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWIthSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 4.0. SQL from Python 4.1. result = sqlContext.sql("SELECT * from Employees WHERE State = 'WA'") OK Cheers On Tue, Mar 3, 2015 at 8:19 PM, Patrick Wendell  wrote: It is the LR over car-data at https://github.com/xsankar/cloaked-ironman. 1.2.0 gives Mean Squared Error = 40.8130551358 1.3.0 gives Mean Squared Error = 105.857603953 I will verify it one more time tomorrow. Cheers On Tue, Mar 3, 2015 at 11:28 PM, Xiangrui Meng  wrote: Yep, otherwise this will become an N^2 problem - Scala versions X Hadoop Distributions X ... May be one option is to have a minimum basic set (which I know is what we are discussing) and move the rest to spark-packages.org. There the vendors can add the latest downloads - for example when 1.4 is released, HDP can build a release of HDP Spark 1.4 bundle. Cheers On Sun, Mar 8, 2015 at 2:11 PM, Patrick Wendell  wrote: Excellent, Thanks Xiangrui. The mystery is solved. Cheers On Mon, Mar 9, 2015 at 3:30 PM, Xiangrui Meng  wrote: +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 15:04 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11 2. Tested pyspark, mlib - running as well as compare results with 1.3.0 pyspark works well with the new iPython 3.0.0 release 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK On Sat, Apr 4, 2015 at 5:13 PM, Reynold Xin  wrote: +1 On Sun, Apr 5, 2015 at 4:24 PM, Patrick Wendell  wrote: +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 14:16 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -Phive -DskipTests -Dscala-2.11 2. Tested pyspark, mlib - running as well as compare results with 1.3.0 pyspark works well with the new iPython 3.0.0 release 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK On Tue, Apr 7, 2015 at 10:46 PM, Patrick Wendell  wrote: +1. All tests OK (same as RC2) Cheers On Fri, Apr 10, 2015 at 11:05 PM, Patrick Wendell  Please vote on releasing the following candidate as Apache Spark version Quick tests from my side - looks OK. The results are same or very similar to 1.3.1. Will add dataframes et al in future tests. +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 17:42 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -Phive -DskipTests 2. Tested pyspark, mlib - running as well as compare results with 1.3.1 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK Cheers On Tue, May 19, 2015 at 9:10 AM, Patrick Wendell  wrote: +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 16:52 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -DskipTests 2. Tested pyspark, mlib - running as well as compare results with 1.3.1 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 4.2. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.3. saveAsParquetFile OK 4.4. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK Cheers On Sun, May 24, 2015 at 12:22 AM, Patrick Wendell  Please vote on releasing the following candidate as Apache Spark version +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 17:07 min mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -DskipTests 2. Tested pyspark, mlib - running as well as compare results with 1.3.1 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK Cheers On Fri, May 29, 2015 at 4:40 PM, Patrick Wendell  wrote: +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 25:42 min (My brand new shiny MacBookPro12,1 : 16GB. Inaugurated the machine with compile & test 1.4.0-RC4 !) mvn clean package -Pyarn -Dyarn.version=2.6.0 -Phadoop-2.4 -Dhadoop.version=2.6.0 -DskipTests 2. Tested pyspark, mlib - running as well as compare results with 1.3.1 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK Cheers On Tue, Jun 2, 2015 at 8:53 PM, Patrick Wendell  wrote: Patrick, Haven't seen any replies on test results. I will byte ;o) - Should I test this version or is another one in the wings ? Cheers On Tue, Jun 23, 2015 at 10:37 PM, Patrick Wendell  Please vote on releasing the following candidate as Apache Spark version +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 13:26 min mvn clean package -Pyarn -Phadoop-2.6 -DskipTests 2. Tested pyspark, mllib 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 5.0. Packages 5.1. com.databricks.spark.csv - read/write OK Cheers On Tue, Jun 23, 2015 at 10:37 PM, Patrick Wendell  Please vote on releasing the following candidate as Apache Spark version Guys, Scala says except while python has subtract. (I verified that except doesn't exist in python) Why the difference in syntax for the same functionality ? Cheers Thanks. Forgot about that ;o(On Thu, Jul 2, 2015 at 11:57 PM, Reynold Xin  wrote: Yep, happens to me as well. Build loops. Cheers On Fri, Jul 3, 2015 at 2:40 PM, Ted Yu  wrote: I have 3.3.3 USS-Defiant:NW ksankar$ mvn -version Apache Maven 3.3.3 (7994120775791599e205a5524ec3e0dfe41d4a06; 2015-04-22T04:57:37-07:00) Maven home: /usr/local/apache-maven-3.3.3 Java version: 1.7.0_60, vendor: Oracle Corporation Java home: /Library/Java/JavaVirtualMachines/jdk1.7.0_60.jdk/Contents/Home/jre Default locale: en_US, platform encoding: UTF-8 OS name: "mac os x", version: "10.10.3", arch: "x86_64", family: "mac"Let me nuke it and reinstall maven. Cheers On Fri, Jul 3, 2015 at 3:41 PM, Patrick Wendell  wrote: Patrick, I assume an RC3 will be out for folks like me to test the distribution. As usual, I will run the tests when you have a new distribution. Cheers On Fri, Jul 3, 2015 at 4:38 PM, Patrick Wendell  wrote: +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 27:24 min mvn clean package -Pyarn -Phadoop-2.6 -DskipTests 2. Tested pyspark, mllib 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 5.0. Packages 5.1. com.databricks.spark.csv - read/write OK 6.0. DataFrames 6.1. cast,dtypes OK 6.2. groupBy,avg,crosstab,corr,isNull,na.drop OK 6.3. joins,sql,set operations,udf OK Cheers On Tue, Jul 7, 2015 at 12:06 PM, Patrick Wendell  wrote: +1 1. Compiled OSX 10.10 (Yosemite) OK Total time: 38:11 min mvn clean package -Pyarn -Phadoop-2.6 -DskipTests 2. Tested pyspark, mllib 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 5.0. Packages 5.1. com.databricks.spark.csv - read/write OK 6.0. DataFrames 6.1. cast,dtypes OK 6.2. groupBy,avg,crosstab,corr,isNull,na.drop OK 6.3. joins,sql,set operations,udf OK Cheers On Wed, Jul 8, 2015 at 10:55 PM, Patrick Wendell  wrote: I think the key is to vote a specific set of source tarballs without any binary artifacts. The specific binaries are useful but shouldn't be part of the voting process. Makes sense, we really cannot prove (and no need to) that the  binaries do not contain malware, but the source can be proven to be clean by inspection, I assume. Cheers On Mon, Oct 12, 2015 at 6:56 AM, Tom Graves  I know there are multiple things being talked about here, but  I agree Guys, The sc.version returns 1.5.1 in python and scala. Is anyone getting the same results ? Probably I am doing something wrong. Cheers On Sun, Oct 25, 2015 at 12:07 AM, Reynold Xin  wrote: Guys, The sc.version gives 1.6.0-SNAPSHOT. Need to change to 1.6.0. Can you pl verify ? Cheers On Sat, Dec 12, 2015 at 9:39 AM, Michael Armbrust  Please vote on releasing the following candidate as Apache Spark version +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 29:32 min mvn clean package -Pyarn -Phadoop-2.6 -DskipTests 2. Tested pyspark, mllib (iPython 4.0) 2.0 Spark version is 1.6.0 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 5.0. Packages 5.1. com.databricks.spark.csv - read/write OK (--packages com.databricks:spark-csv_2.10:1.3.0) 6.0. DataFrames 6.1. cast,dtypes OK 6.2. groupBy,avg,crosstab,corr,isNull,na.drop OK 6.3. All joins,sql,set operations,udf OK Cheers & Good work guys On Wed, Dec 16, 2015 at 1:32 PM, Michael Armbrust  Please vote on releasing the following candidate as Apache Spark version +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 29:25 min mvn clean package -Pyarn -Phadoop-2.6 -DskipTests 2. Tested pyspark, mllib (iPython 4.0) 2.0 Spark version is 1.6.0 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Laso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 5.0. Packages 5.1. com.databricks.spark.csv - read/write OK (--packages com.databricks:spark-csv_2.10:1.3.0) 6.0. DataFrames 6.1. cast,dtypes OK 6.2. groupBy,avg,crosstab,corr,isNull,na.drop OK 6.3. All joins,sql,set operations,udf OK Cheers & Holiday "Spark-ling" Wishes ! On Tue, Dec 22, 2015 at 12:10 PM, Michael Armbrust  Please vote on releasing the following candidate as Apache Spark version Hi, 1. Yep, GraphX is stable and would be a good choice for you to implement algorithms. For a quick intro you can refer to our Strata MLlib tutorial GraphX slides http://goo.gl/Ffq2Az 2. GraphX has implemented algorithms like PageRank & ConnectedComponents[1] 3. It also has primitives to develop the kind of algorithms that you are talking about 4. For you to implement interesting algorithms, the main APIs of interest would be the pregel API and the aggregateMessages API[2]. Am sure you will also use the map*, subgraph and the join APIs. Cheers [1] http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.graphx.GraphOps [2] http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.graphx.Graph On Thu, Apr 21, 2016 at 11:47 AM, tgensol  Hi there, +1. Looks Good. The mllib results are in line with 1.6.1. Deprecation messages. I will convert to ml and test later in the day. Also will try GraphX exercises for our Strata London Tutorial Quick Notes: 1. pyspark env variables need to be changed - IPYTHON and IPYTHON_OPTS are removed - This works - PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS="notebook"~/Downloads/spark-2.0.0-preview/bin/pyspark --packages com.databricks:spark-csv_2.10:1.4.0 2.  maven 3.3.9 is required. (I was running 3.3.3) 3.  Tons of interesting warnings and deprecations. - The messages look descriptive and very helpful (Thanks. This will 4. Compiled OSX 10.10 (Yosemite) OK Total time: 31:28 min mvn clean package -Pyarn -Phadoop-2.6 -DskipTests - Spark version is 2.0.0-preview - Tested pyspark, mllib (iPython 4.2.0) Cheers & Good work folks On Wed, May 18, 2016 at 7:28 AM, Sean Owen  wrote: Hi all, Just wanted to thank all for the dataset API - most of the times we see only bugs in these lists ;o). - Putting some context, this weekend I was updating the SQL chapters of my book - it had all the ugliness of SchemaRDD, registerTempTable, take(10).foreach(println) - I remember Hossein Falaki chiding me about the ugly println statements ! - Took me a little while to grok the dataset, sparksession, spark.read.option("header","true").option("inferSchema","true").csv(...) et al. - I am a big R fan and know the language pretty decent - so the constructs are familiar - Once I got it ( I am sure still there are more mysteries to uncover ...) it was just beautiful - well done folks !!! - One sees the contrast a lot better while teaching or writing books, because one has to think thru the old, the new and the transitional arc - I even remember the good old days when we were discussing whether Spark would get the dataframes like R at one of Paco's sessions ! - And now, it looks very decent for data wrangling. Cheers & keep up the good work P.S: My next chapter is the MLlib - need to convert to ml. Should be interesting ... I am a glutton for punishment - of the Spark kind, of course ! +1 (non-binding, of course) 1. Compiled OSX 10.10 (Yosemite) OK Total time: 37:11 min mvn clean package -Pyarn -Phadoop-2.6 -DskipTests 2. Tested pyspark, mllib (iPython 4.0) 2.0 Spark version is 1.6.2 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Lasso Regression OK 2.3. Decision Tree, Naive Bayes OK 2.4. KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 4.3 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 5.0. Packages 5.1. com.databricks.spark.csv - read/write OK (--packages com.databricks:spark-csv_2.10:1.4.0) 6.0. DataFrames 6.1. cast,dtypes OK 6.2. groupBy,avg,crosstab,corr,isNull,na.drop OK 6.3. All joins,sql,set operations,udf OK 7.0. GraphX/Scala 7.1. Create Graph (small and bigger dataset) OK 7.2. Structure APIs - OK 7.3. Social Network/Community APIs - OK 7.4. Algorithms (PageRank of 2 datasets, aggregateMessages() ) OK Cheers & Good Work, Folks On Sun, Jun 19, 2016 at 9:24 PM, Reynold Xin  wrote: Can't find the "spark-assembly-2.0.0-hadoop2.7.0.jar" after compilation. Usually it is in the assembly/target/scala-2.11 Has the packaging changed for 2.0.0 ? Cheers On Thu, Jul 14, 2016 at 11:59 AM, Reynold Xin  wrote: +1 (non-binding, of course) 1. Compiled OS X 10.11.5 (El Capitan) OK Total time: 26:27 min mvn clean package -Pyarn -Phadoop-2.7 -DskipTests 2. Tested pyspark, mllib (iPython 4.0) 2.0 Spark version is 2.0.0 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Lasso Regression OK 2.3. Classification : Decision Tree, Naive Bayes OK 2.4. Clustering : KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 3.6 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 5.0. Packages 5.1. com.databricks.spark.csv - read/write OK (--packages com.databricks:spark-csv_2.10:1.4.0) 6.0. DataFrames 6.1. cast,dtypes OK 6.2. groupBy,avg,crosstab,corr,isNull,na.drop OK 6.3. All joins,sql,set operations,udf OK [Dataframe Operations very fast from 11-12 secs to 3 secs, to 1.8 secs, to 1.5 secs! Good work !!!] 7.0. GraphX/Scala 7.1. Create Graph (small and bigger dataset) OK 7.2. Structure APIs - OK 7.3. Social Network/Community APIs - OK 7.4. Algorithms : PageRank of 2 datasets, aggregateMessages() - OK Cheers On Thu, Jul 14, 2016 at 11:59 AM, Reynold Xin  wrote: +1 (non-binding, of course) 1. Compiled OS X 10.11.5 (El Capitan) OK Total time: 24:07 min mvn clean package -Pyarn -Phadoop-2.7 -DskipTests 2. Tested pyspark, mllib (iPython 4.0) 2.0 Spark version is 2.0.0 2.1. statistics (min,max,mean,Pearson,Spearman) OK 2.2. Linear/Ridge/Lasso Regression OK 2.3. Classification : Decision Tree, Naive Bayes OK 2.4. Clustering : KMeans OK Center And Scale OK 2.5. RDD operations OK State of the Union Texts - MapReduce, Filter,sortByKey (word count) 2.6. Recommendation (Movielens medium dataset ~1 M ratings) OK Model evaluation/optimization (rank, numIter, lambda) with itertools OK 3. Scala - MLlib 3.1. statistics (min,max,mean,Pearson,Spearman) OK 3.2. LinearRegressionWithSGD OK 3.3. Decision Tree OK 3.4. KMeans OK 3.5. Recommendation (Movielens medium dataset ~1 M ratings) OK 3.6. saveAsParquetFile OK 3.7. Read and verify the 3.6 save(above) - sqlContext.parquetFile, registerTempTable, sql OK 3.8. result = sqlContext.sql("SELECT OrderDetails.OrderID,ShipCountry,UnitPrice,Qty,Discount FROM Orders INNER JOIN OrderDetails ON Orders.OrderID = OrderDetails.OrderID") OK 4.0. Spark SQL from Python OK 4.1. result = sqlContext.sql("SELECT * from people WHERE State = 'WA'") OK 5.0. Packages 5.1. com.databricks.spark.csv - read/write OK (--packages com.databricks:spark-csv_2.10:1.4.0) 6.0. DataFrames 6.1. cast,dtypes OK 6.2. groupBy,avg,crosstab,corr,isNull,na.drop OK 6.3. All joins,sql,set operations,udf OK [Dataframe Operations very fast from 11 secs to 3 secs, to 1.8 secs, to 1.5 secs! Good work !!!] 7.0. GraphX/Scala 7.1. Create Graph (small and bigger dataset) OK 7.2. Structure APIs - OK 7.3. Social Network/Community APIs - OK 7.4. Algorithms : PageRank of 2 datasets, aggregateMessages() - OK Cheers On Tue, Jul 19, 2016 at 7:35 PM, Reynold Xin  wrote:
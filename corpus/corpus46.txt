+1!
2014-02-10 20:27 GMT-08:00 Chris Mattmann  Hi Everyone,
Looks like you have a large number of distinct keys. As you suspect, this
maybe due to hash collisions, which only up to 4 billion. It could be
related to this PR: https://github.com/apache/incubator-spark/pull/612.
The other thing is we had some issues with the behavior of arbitrary
serialization/compression engines, and this is solved in the PR that Mridul
referenced. What compression and serialization libraries are you using?
2014-02-18 20:56 GMT-08:00 Mridul Muralidharan  I had not resolved it in time for 0.9 - but IIRC there was a recent PR
For compressing shuffle spills in 0.9, we added a hack such that it always
uses LZF, so actually your compression library shouldn't matter. We did
notice that Kryo was pre-fetching, however, such that batching reads led to
some items being lost. To fix this, we introduced a hack specifically for
Kryo that works around this. Although we tested it and the hack sufficed
back then, it is entirely possible that there are corner cases that we
missed. In any case, PR #533 (after 0.9 release) should have taken care of
the problem.
If you still run into the same problem on master, then it could be a corner
case that our current way of handling hash collisions missed. When you have
the time, do let us know what you find!
Andrew
2014-02-18 21:08 GMT-08:00 Andrew Ash  I'm using Kryo with these options:
+1 tested on OSX
On Mon, Mar 31, 2014 at 4:33 PM, Kevin Markey  I had specifically requested that the ASM shading be included in the RC,
Hi Art,
First of all thanks a lot for your PRs. We are currently in the middle of
all the Spark 1.0 release so most of us are swamped with the more core
features. To answer your questions:
1. Neither. We welcome changes from developers for all components of Spark,
including the EC2 scripts. Once the release is out we will have more time
to review the many PRs that we missed on the ride.
2. We prefer to keep the EC2 scripts within Spark, at least for now.
Cheers,
Andrew
On Friday, April 25, 2014, Art Peel  wrote:
+1
2014-05-13 6:49 GMT-07:00 Sean Owen  On Tue, May 13, 2014 at 9:36 AM, Patrick Wendell  wrote:
Apache has been having some problems lately. Do you guys see this message?
+1
2014-05-17 8:53 GMT-07:00 Mark Hamstra  +1
+1
2014-05-20 13:13 GMT-07:00 Tathagata Das  Please vote on releasing the following candidate as Apache Spark version
There is an issue with the SparkUI: the storage page continues to display
RDDs that are dropped from memory. This is fixed in
https://github.com/apache/spark/commit/21e0f77b6321590ed86223a60cdb8ae08ea4057f
but is not part of this RC.
2014-06-27 11:18 GMT-07:00 Matei Zaharia  +1
(Forgot to mention, that UI bug is not in Spark 1.0.0, so it is technically
a regression)
2014-06-27 15:42 GMT-07:00 Andrew Or  There is an issue with the SparkUI: the storage page continues to display
+1, verified that the UI bug is in fact fixed in
https://github.com/apache/spark/pull/1255.
2014-07-05 20:01 GMT-07:00 Soren Macbeth  +1
Hi Egor,
Here are a few answers to your questions:
1) Python needs to be installed on all machines, but not pyspark. The way
the executors get the pyspark code depends on which cluster manager you
use. In standalone mode, your executors need to have the actual python
files in their working directory. In yarn mode, python files are included
in the assembly jar, which is then shipped to your executor containers
through a distributed cache.
2) Pyspark is just a thin wrapper around Spark. When you write a closure in
python, it is shipped to the executors within the task itself the same way
scala closures are shipped. If you use a special library, then all of the
nodes will need to have that library pre-installed.
3) Are you trying to run your c++ code inside the "map" function? If so,
you need to make sure the compiled code is present in the working directory
on all the executors before-hand for python to "exec" it. I haven't done
this before, but maybe there are a few gotchas in doing this.
Maybe others can add more information?
Andrew
2014-07-11 5:50 GMT-07:00 Egor Pahomov  Hi, I want to use pySpark, but can't understand how it works. Documentation
+1, tested on standalone cluster and ran spark shell, pyspark and SparkPi
2014-07-18 0:03 GMT-07:00 Patrick Wendell  +1
+1 Tested on standalone and yarn clusters
2014-07-28 14:59 GMT-07:00 Tathagata Das  Let me add my vote as well.
Thanks Marcelo, I have moved the changes to a new PR to describe the
problems more clearly: https://github.com/apache/spark/pull/1845
@Gary Yeah, the goal is to get this into 1.1 as a bug fix.
2014-08-07 17:30 GMT-07:00 Gary Malouf  Can this be cherry-picked for 1.1 if everything works out?  In my opinion,
@Cody I took a quick glance at the Mesos code and it appears that we
currently do not even pass extra java options to executors except in coarse
grained mode, and even in this mode we do not pass them to executors
correctly. I have filed a related JIRA here:
https://issues.apache.org/jira/browse/SPARK-2921. This is a somewhat
serious limitation and we will try to fix this for 1.1.
-Andrew
2014-08-07 19:42 GMT-07:00 Andrew Or  Thanks Marcelo, I have moved the changes to a new PR to describe the
Ah, great to know this is already being fixed. Thanks Patrick, I have
marked my JIRA as a duplicate.
2014-08-07 21:42 GMT-07:00 Patrick Wendell  Andrew - I think your JIRA may duplicate existing work:
Thanks everyone. I look forward to continuing to work with all of you!
2014-08-08 3:23 GMT-07:00 Prashant Sharma  Congratulations Andrew and Joey.
+1 Tested on Yarn and Windows. Also verified that standalone cluster mode
is now fixed.
2014-09-03 1:25 GMT-07:00 Xiangrui Meng  +1. Tested some MLlib example code.
Hi Jun,
You can still set the authentication variables through `spark-env.sh`, by
exporting SPARK_MASTER_OPTS, SPARK_WORKER_OPTS, SPARK_HISTORY_OPTS etc to
include "-Dspark.auth.{...}". There is an open pull request that allows
these processes to also read from spark-defaults.conf, but this is not
merged into master yet.
Andrew
2014-09-15 6:44 GMT-07:00 Tom Graves  Spark authentication does work in standalone mode (atleast it did, I
2014-09-16 22:32 GMT-07:00 Jun Feng Liu  I see. Thank you, it works for me. It looks confusing to have two ways
I agree. We're working on it. :)
Hey Matt,
There's some prior work that compares consolidation performance on some
medium-scale workload:
http://www.cs.berkeley.edu/~kubitron/courses/cs262a-F13/projects/reports/project16_report.pdf
There we noticed about 2x performance degradation in the reduce phase on
ext3. I am not aware of any other concrete numbers. Maybe others have more
experiences to add.
-Andrew
2014-11-03 17:26 GMT-08:00 Matt Cheah  Hi everyone,
+1
2014-11-05 18:08 GMT-08:00 Patrick Wendell  I'm a +1 on this as well, I think it will be a useful model as we
Hi everyone,
I am the release manager for 1.1.1, and I am preparing to cut a release
tonight at midnight. 1.1.1 is a maintenance release which will ship several
important bug fixes to users of Spark 1.1. Many users are waiting for
these fixes so I would like to release it as soon as possible.
At this point, I believe we have already back ported all critical fixes
from master other than a few known ones. Below is a list of issues that
have been back ported into 1.1.1. If there are other critical fixes in the
master branch that are not in this list, please let me know and I will take
a look.
https://issues.apache.org/jira/browse/SPARK-3653?jql=project%20%3D%20SPARK%20AND%20fixVersion%20%3D%201.1.1%20AND%20fixVersion%20%3D%201.2.0
Best,
- Andrew
(Tonight at midnight being in PST 12am on 11/11)
2014-11-10 14:17 GMT-08:00 Andrew Or  Hi everyone,
Please vote on releasing the following candidate as Apache Spark version 1
.1.1.
This release fixes a number of bugs in Spark 1.1.0. Some of the notable
ones are
- [SPARK-3426] Sort-based shuffle compression settings are incompatible
- [SPARK-3948] Stream corruption issues in sort-based shuffle
- [SPARK-4107] Incorrect handling of Channel.read() led to data truncation
The full list is at http://s.apache.org/z9h and in the CHANGES.txt attached.
The tag to be voted on is v1.1.1-rc1 (commit 72a4fdbe):
http://s.apache.org/cZC
The release files, including signatures, digests, etc can be found at:
http://people.apache.org/~andrewor14/spark-1.1.1-rc1/
Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/andrewor14.asc
The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1034/
The documentation corresponding to this release can be found at:
http://people.apache.org/~andrewor14/spark-1.1.1-rc1-docs/
Please vote on releasing this package as Apache Spark 1.1.1!
The vote is open until Sunday, November 16, at 04:30 UTC and passes if
a majority of at least 3 +1 PMC votes are cast.
[ ] +1 Release this package as Apache Spark 1.1.1
[ ] -1 Do not release this package because ...
To learn more about Apache Spark, please see
http://spark.apache.org/
Cheers,
Andrew
---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
I will start the vote with a +1
2014-11-12 20:34 GMT-08:00 Andrew Or  Please vote on releasing the following candidate as Apache Spark version 1
Yeah, this seems to be somewhat environment specific too. The same test has
been passing here for a while:
https://amplab.cs.berkeley.edu/jenkins/job/Spark-1.1-Maven-pre-YARN/hadoop.version=1.0.4,label=centos/lastBuild/consoleFull
2014-11-13 11:26 GMT-08:00 Michael Armbrust  Hey Sean,
Hi all, since the vote ends on a Sunday, please let me know if you would
like to extend the deadline to allow more time for testing.
2014-11-13 12:10 GMT-08:00 Sean Owen  Ah right. This is because I'm running Java 8. This was fixed in
This seems like a legitimate blocker. We will cut another RC to include the
revert.
2014-11-16 17:29 GMT-08:00 Kousuke Saruta  Now I've finished to revert for SPARK-4434 and opened PR.
This is canceled in favor of RC2 with the following blockers:
https://issues.apache.org/jira/browse/SPARK-4434
https://issues.apache.org/jira/browse/SPARK-3633
The latter one involves a regression from 1.0.2 to 1.1.0, NOT from 1.1.0 to
1.1.1. For this reason, we are currently investigating this issue but may
not necessarily block on this to release 1.1.1.
2014-11-17 10:42 GMT-08:00 Debasish Das  I put up 1.1.1 branch and I am getting shuffle failures while doing
I will start with a +1
2014-11-19 14:51 GMT-08:00 Andrew Or  Please vote on releasing the following candidate as Apache Spark version 1
Please vote on releasing the following candidate as Apache Spark version 1
.1.1.
This release fixes a number of bugs in Spark 1.1.0. Some of the notable
ones are
- [SPARK-3426] Sort-based shuffle compression settings are incompatible
- [SPARK-3948] Stream corruption issues in sort-based shuffle
- [SPARK-4107] Incorrect handling of Channel.read() led to data truncation
The full list is at http://s.apache.org/z9h and in the CHANGES.txt attached.
Additionally, this candidate fixes two blockers from the previous RC:
- [SPARK-4434] Cluster mode jar URLs are broken
- [SPARK-4480][SPARK-4467] Too many open files exception from shuffle spills
The tag to be voted on is v1.1.1-rc2 (commit 3693ae5d):
http://s.apache.org/p8
The release files, including signatures, digests, etc can be found at:
http://people.apache.org/~andrewor14/spark-1.1.1-rc2/
Release artifacts are signed with the following key:
https://people.apache.org/keys/committer/andrewor14.asc
The staging repository for this release can be found at:
https://repository.apache.org/content/repositories/orgapachespark-1043/
The documentation corresponding to this release can be found at:
http://people.apache.org/~andrewor14/spark-1.1.1-rc2-docs/
Please vote on releasing this package as Apache Spark 1.1.1!
The vote is open until Saturday, November 22, at 23:00 UTC and passes if
a majority of at least 3 +1 PMC votes are cast.
[ ] +1 Release this package as Apache Spark 1.1.1
[ ] -1 Do not release this package because ...
To learn more about Apache Spark, please see
http://spark.apache.org/
Cheers,
Andrew
---------------------------------------------------------------------
To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org
For additional commands, e-mail: dev-help@spark.apache.org
The vote passes unanimously with 4 binding +1 votes, 5 non-binding +1
votes, and no +0 or -1 votes. The final release will be posted in the next
48 hours. Thanks to everyone who voted.
-Andrew
+1:
Andrew Or*
Xiangrui Meng*
Krishna Sankar
Matei Zaharia*
Sean Owen
Anant Asthana
Marcelo Vanzin
Patrick Wendell*
Debasish Das
+0:
-1:
*binding
I am happy to announce the availability of Spark 1.1.1! This is a
maintenance release with many bug fixes, most of which are concentrated in
the core. This list includes various fixes to sort-based shuffle, memory
leak, and spilling issues. Contributions from this release came from 55
developers.
Visit the release notes [1] to read about the new features, or
download [2] the release today.
[1] http://spark.apache.org/releases/spark-release-1-1-1.html
[2] http://spark.apache.org/downloads.html
Please e-mail me directly for any typo's in the release notes or name
listing.
Thanks for everyone who contributed, and congratulations!
-Andrew
I realize we're not voting, but +1 to this proposal since commit messages
can't be changed whereas JIRA issues can always be updated after the fact.
2014-12-02 13:05 GMT-08:00 Patrick Wendell  Also a note on this for committers - it's possible to re-word the
@Patrick and Josh actually we went even further than that. We simply
disable the UI for most tests and these used to be the single largest
source of port conflict.
Hi Preeze,
(still running in YARN) for collecting results at a later stage?
No, there is not support built into Spark for this. For this to happen
seamlessly the driver will have to start a server (pull model) or send the
results to some other server once the jobs complete (push model), both of
which add complexity to the driver. Alternatively, you can just poll on the
output files that your application produces; e.g. you can have your driver
write the results of a count to a file and poll on that file. Something
like that.
-Andrew
2015-01-19 5:59 GMT-08:00 Romi Kuntsman  "in yarn-client mode it only controls the environment of the executor
In my experience I find it much more natural to use // for short multi-line
comments (2 or 3 lines), and /* */ for long multi-line comments involving
one or more paragraphs. For short multi-line comments, there is no reason
not to use // if it just so happens that your first line exceeded 100
characters and you have to wrap it. For long multi-line comments, however,
using // all the way looks really awkward especially if you have multiple
paragraphs.
Thus, I would actually suggest that we don't try to pick a favorite and
document that both are acceptable. I don't expect developers to follow my
exact usage (i.e. with a tipping point of 2-3 lines) so I wouldn't enforce
anything specific either.
2015-02-09 13:36 GMT-08:00 Reynold Xin  Why don't we just pick // as the default (by encouraging it in the style
Hey Nathan, thanks for bringing this up I will look at this within the next
day or two.
2015-04-08 8:03 GMT-07:00 Nathan Kronenfeld  Could I get someone to look at PR 5140 please? It's been languishing more
Dear all,
I'm sure you have all noticed that the Spark tests have been fairly
unstable recently. I wanted to share a tool that I use to track which tests
have been failing most often in order to prioritize fixing these flaky
tests.
Here is an output of the tool. This spreadsheet reports the top 10 failed
tests this week (ending yesterday 5/5):
https://docs.google.com/spreadsheets/d/1Iv_UDaTFGTMad1sOQ_s4ddWr6KD3PuFIHmTSzL7LSb4
It is produced by a small project:
https://github.com/andrewor14/spark-test-failures
I have been filing JIRAs on flaky tests based on this tool. Hopefully we
can collectively stabilize the build a little more as we near the release
for Spark 1.4.
-Andrew
Thanks for pointing this out. I reverted that commit.
2015-05-08 19:01 GMT-07:00 Ted Yu  Looks like you're right:
Hi Ted,
Yes, those two options can be useful, but in general I think the standard
to set is that tests should never fail. It's actually the worst if tests
fail sometimes but not others, because we can't reproduce them
deterministically. Using -M and -A actually tolerates flaky tests to a
certain extent, and I would prefer to instead increase the determinism in
these tests.
-Andrew
2015-05-08 17:56 GMT-07:00 Ted Yu  Andrew:
It will be within the next few days
2015-06-01 9:17 GMT-07:00 Reynold Xin  I don't think so.
+1 (binding)
Ran the same tests I did for RC3:
Tested the standalone cluster mode REST submission gateway - submit /
status / kill
Tested simple applications on YARN client / cluster modes with and without
--jars
Tested python applications on YARN client / cluster modes with and without
--py-files*
Tested dynamic allocation on YARN client / cluster modes**
All good. A couple of known issues:
*SPARK-8017: YARN cluster python --py-files not working - not a blocker
(new feature)
** SPARK-8088: noisy output when min executors is set - not a blocker
(output can be disabled)
2015-06-04 13:35 GMT-07:00 Matei Zaharia  +1
Welcome!
2015-06-20 7:30 GMT-07:00 Debasish Das  Congratulations to All.
Hi Ted,
We haven't observed a StreamingContextSuite failure on our test
infrastructure recently. Given that we cannot reproduce it even locally it
is unlikely that this uncovers a real bug. Even if it does I would not
block the release on it because many in the community are waiting for a few
important fixes. In general, there will always be outstanding issues in
Spark that we cannot address in every release.
-Andrew
2015-06-29 14:29 GMT-07:00 Ted Yu  The test passes when run alone on my machine as well.
@Sean I believe that is a real issue. I have submitted a patch to fix it:
https://github.com/apache/spark/pull/7193. Unfortunately this would mean we
need to cut a new RC to include it. When we do so we should also do another
careful pass over the commits that are merged since the first RC.
-1
2015-07-02 9:10 GMT-07:00 Shivaram Venkataraman  +1 Tested the EC2 launch scripts and the Spark version and EC2 branch etc.
@Tarek and Ted, what maven versions are you using?
2015-07-03 17:35 GMT-07:00 Krishna Sankar  Patrick,
Thanks, I just tried it with 3.3.3 and I was able to reproduce it as well.
2015-07-03 18:51 GMT-07:00 Tarek Auel  That's mine
+1
Verified that the previous blockers SPARK-8781 and SPARK-8819 are now
resolved.
2015-07-07 12:06 GMT-07:00 Patrick Wendell  Please vote on releasing the following candidate as Apache Spark version
@Sean You actually need to run HiveSparkSubmitSuite with `-Phive` and
`-Phive-thriftserver`. The MissingRequirementsError is just complaining
that it can't find the right classes. The other one (DataFrameStatSuite) is
a little more concerning.
2015-07-08 10:43 GMT-07:00 Pradeep Bashyal  Hi Shivaram,
+1
2015-07-09 10:26 GMT-07:00 Michael Armbrust  +1
Hi Ray,
In standalone mode, you have this thing called the
SparkDeploySchedulerBackend, which has this thing called the AppClient.
This is the thing on the driver side that already talks to the Master to
register the application.
As for dynamic allocation in standalone mode, I literally *just* created a
patch on Github: https://github.com/apache/spark/pull/7532. Feel free to
have a look if you're interested. :)
-Andrew
2015-07-18 18:47 GMT-07:00 Dogtail Ray  Hi all,
Hi Yu,
As it stands today, they are identical except for trigger mechanism. When
you say "test this please" or push a commit, SparkPullRequestBuilder is the
one that's running the tests. SlowSparkPullRequestBuilder, however, is not
used by default, but only triggered when you say "slow test please".
Functionally there is currently no difference; the latter came about
recently in an ongoing experiment to make unit tests run faster.
-Andrew
2015-07-21 22:47 GMT-07:00 Yu Ishikawa  Hi all,
(merge into master, thanks for the quick fix Pete).
2015-09-04 15:58 GMT-07:00 Cheolsoo Park  Thank you Pete!
Thanks for reporting this, I have filed
https://issues.apache.org/jira/browse/SPARK-10548.
2015-09-10 9:09 GMT-07:00 Olivier Toupin  Look at this code:
@Olivier, did you use scala's parallel collections by any chance? If not,
what form of concurrency were you using?
2015-09-10 13:01 GMT-07:00 Andrew Or  Thanks for reporting this, I have filed
+1
Ran PageRank on standalone mode with 4 nodes and noticed a speedup after
the specific commits that were in RC2 but not RC1:
c247b6a Dec 10 [SPARK-12155][SPARK-12253] Fix executor OOM in unified
memory management
05e441e Dec 9 [SPARK-12165][SPARK-12189] Fix bugs in eviction of storage
memory by execution
Also jobs that triggered these issues now run successfully.
2015-12-14 10:45 GMT-08:00 Reynold Xin  +1
@syepes
I just run Spark 1.6 (881f254) on YARN with Hadoop 2.4.0. I was able to run
a simple application in cluster mode successfully.
Can you verify whether the org.apache.spark.yarn.ApplicationMaster class
exists in your assembly jar?
jar -tf assembly.jar | grep ApplicationMaster
-Andrew
2015-12-17 7:44 GMT-08:00 syepes  -1 (YARN Cluster deployment mode not working)
+1
2015-12-22 12:43 GMT-08:00 Reynold Xin  +1
Welcome!
2016-02-08 10:55 GMT-08:00 Bhupendra Mishra  Congratulations to both. and welcome to group.
+1
2016-03-08 10:59 GMT-08:00 Yin Huai  +1
+1, some maintainers are hard to find
2016-05-19 9:03 GMT-07:00 Imran Rashid  +1 (binding) on removal of maintainers

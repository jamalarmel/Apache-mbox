Test reply (I think my messages are being caught by the spam filter?) I've noticed that Spark's Java API is inconsistent in how it represents optional values. Some methods use scala.Option instances, while others use Guava's Optional: scala.Option is used in by methods like JavaSparkContext.getSparkHome(), and the *outerJoin methods return a JavaPairRDD[K, (V, Option[W])]. Guava Optional is used in methods like Java*RDD.getCheckpointFile() and JavaPairDStream.updateStateByKey() function arguments. I'd like to remove this inconsistency and settle on a single class for representing optional values in the Java API. Both APIs are similar, but the Guava API seems nicer for Java users.  For example, scala.Option.getOrElse(default) accepts a function, which isn't really usable from Java. http://www.scala-lang.org/api/current/index.html#scala.Option http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Optional.html If we switch to exclusively using Guava Optional, we'd have to convert join results before turning them into JavaRDDs so that we have JavaPairRDD[K, (V, Optional[W])].  I don't anticipate this being a large performance issue. This would be a backwards-incompatible API change and 0.8 seems like the easiest time to make it.  I'd appreciate any thoughts on whether I should use Guava Optional everywhere. Thanks, Josh I was thinking of making a backwards-incompatible API change in the Java API, described at https://mail-archives.apache.org/mod_mbox/incubator-spark-dev/201308.mbox/%3CCAOEPXP5iWWTSEhJGq5eafpPY1Dxp8ZTAfuhX9w-2%2BaQ3hApbfA%40mail.gmail.com%3E If nobody objects, I'll implement that change and submit a pull request to add it to 0.8.  I'm interested in doing this now because we won't break APIs in 0.8.1+, so it would have to wait until 0.9 if we don't do it now. I have several planned additions to the Java APIs to add the features missing from the Scala APIs, but those changes shouldn't introduce any incompatibilities and can be added in a minor release. Maybe we could run the tests that depend on the assembly during Maven's `integration-test` phase, which runs after the `package` phase.  I'm not sure what its sbt equivalent is. I've created two new pages on the Spark wiki to document the internals of the Java and Python APIs: https://cwiki.apache.org/confluence/display/SPARK/Java+API+Internals https://cwiki.apache.org/confluence/display/SPARK/PySpark+Internals These are only rough drafts; please let me know if there's anything that you'd like me to document (or feel free to add it yourself!). - Josh Hi Nick, I've seen several requests for SequenceFile support in PySpark, so there's definitely demand for this feature. I like the idea of passing MsgPack'ed data (or some other structured format) from Java to the Python workers.  My early prototype of custom serializers (described at https://cwiki.apache.org/confluence/display/SPARK/PySpark+Internals#PySparkInternals-customserializers) might be useful for implementing this.  Proper custom serializer support would handle the bookkeeping for tracking each stage's input and output formats and supplying the appropriate deserialization functions to the Python worker, so the Python worker would be able to directly read the MsgPack'd data that's sent to it. Regarding a wrapper API, it's actually possible to initially transform data using Scala/Java and perform the remainder of the processing in PySpark. This involves adding the appropriate compiled to the Java classpath and a bit of work in Py4J to create the Java/Scala RDD and wrap it for use by PySpark.  I can hack together a rough example of this if anyone's interested, but it would need some work to be developed into a user-friendly API. If you wanted to extend your proof-of-concept to handle the cases where keys and values have parseable toString() values, I think you could remove the need for a delimiter by creating a PythonRDD from the newHadoopFile JavaPairRDD and adding a new method to writeAsPickle (https://github.com/apache/incubator-spark/blob/master/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala#L224) to dump its contents as a pickled pair of strings.  (Aside: most of writeAsPickle() would probably need be eliminated or refactored when adding general custom serializer support). - Josh You don't have to install the sbt-idea plugin to generate the .idea file (although it can be useful for building Spark once you've imported the .idea project). Instead, you can use the version of SBT that's bundled with Spark: cd $SPARK_HOME; sbt/sbt update gen-idea. This is also documented on https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark Someone on the users list also encountered this exception: https://mail-archives.apache.org/mod_mbox/incubator-spark-user/201310.mbox/%3C64474308D680D540A4D8151B0F7C03F7025EF289%40SHSMSX104.ccr.corp.intel.com%3E Hi Nick, This is a nice start.  I'd prefer to keep the Java sequenceFileAsText() and newHadoopFileAsText() methods inside PythonRDD instead of adding them to JavaSparkContext, since I think these methods are unlikely to be used directly by Java users (you can add these methods to the PythonRDD companion object, which is how readRDDFromPickleFile is implemented: https://github.com/apache/incubator-spark/blob/branch-0.8/core/src/main/scala/org/apache/spark/api/python/PythonRDD.scala#L255 ) For MsgPack, the UnpicklingError is because the Python worker expects to receive its input in a pickled format.  In my prototype of custom serializers, I modified the PySpark worker to receive its serialization/deserialization function as input (https://github.com/JoshRosen/spark/blob/59b6b43916dc84fc8b83f22eb9ce13a27bc51ec0/python/pyspark/worker.py#L41) and added logic to pass the appropriate serializers based on each stage's input and output formats (https://github.com/JoshRosen/spark/blob/59b6b43916dc84fc8b83f22eb9ce13a27bc51ec0/python/pyspark/rdd.py#L42 ). At some point, I'd like to port my custom serializers code to PySpark; if anyone's interested in helping, I'd be glad to write up some additional notes on how this should work. - Josh I opened a pull request to add custom serializer support to PySpark: https://github.com/apache/incubator-spark/pull/146 My pull request adds the plumbing for transferring data from Java to Python using formats other than Pickle.  For example, look at how textFile() uses MUTF8Deserializer to read strings from Java.  Hopefully this provides all of the functionality needed to support MsgPack. - Josh I think that the reduce() action is implemented as mapPartitions.collect().reduce(), so the number of result tasks is determined by the degree of parallelism of the RDD being reduced. Some operations, like reduceByKey(), accept a `numPartitions` argument for configuring the number of reducers: https://spark.incubator.apache.org/docs/0.8.0/api/pyspark/index.html Thanks for organizing this!  I'll definitely be attending. - Josh Thanks for the link!  I wasn't aware of Dill, but it looks like a nice library.  I like that it's being actively developed: https://github.com/uqfoundation/dill It also seems to work correctly for a few edge-cases that cloudpickle didn't handle properly, such as serializing operator.itemgetter instances (see https://spark-project.atlassian.net/browse/SPARK-791). I'll put together a pull request to replace CloudPickle with Dill.  Dill uses a 3-clause BSD license, so we should be able to package it into an .egg in the python/lib/ folder like we did for Py4J.  It will be interesting to see whether the change has any performance impact, although the recent custom serializers pull request should help with that since it would let us use Dill for serializing functions and a faster serializer for serializing data. - Josh I tried replacing cloudpickle with Dill (https://github.com/JoshRosen/incubator-spark/commit/2ac8986f3009f0dc133b11d16887fc8ddb33c3d1) but I ran into a few issues. It looks like Dill pickles function closures differently for functions defined in doctests versus in module code / the shell, which breaks PySpark's test suite; I opened an issue for this in the Dill repo: https://github.com/uqfoundation/dill/issues/18. Its closure cleaning may work differently than cloudpickle's because I've also encountered some examples that also fail in the shell (accumulators). Many simple cases, like PySpark's wordcount.py example, work fine, so I'm hoping we'll be able to make the switch to Dill if those doctest issues are resolved. We can use git log to figure out which changes haven't made it into branch-0.8.  Here's a quick attempt, which only lists pull requests that were only merged into one of the branches.  For completeness, this could be extended to find commits that weren't part of a merge and are only present in one branch. *Script:* MASTER_BRANCH=origin/master RELEASE_BRANCH=origin/branch-0.8 git log --oneline --grep "Merge pull request" $MASTER_BRANCH  | cut -f 2- -d ' ' | sort > master-prs git log --oneline --grep "Merge pull request" $RELEASE_BRANCH | cut -f 2- -d ' ' | sort > release-prs comm -23 master-prs release-prs > master-only comm -23 release-prs master-prs > release-only *Master Branch Only:* Merge pull request #1 from colorant/yarn-client-2.2 Merge pull request #105 from pwendell/doc-fix Merge pull request #110 from pwendell/master Merge pull request #146 from JoshRosen/pyspark-custom-serializers Merge pull request #151 from russellcardullo/add-graphite-sink Merge pull request #154 from soulmachine/ClusterScheduler Merge pull request #156 from haoyuan/master Merge pull request #159 from liancheng/dagscheduler-actor-refine Merge pull request #16 from pwendell/master Merge pull request #185 from mkolod/random-number-generator Merge pull request #187 from aarondav/example-bcast-test Merge pull request #190 from markhamstra/Stages4Jobs Merge pull request #198 from ankurdave/zipPartitions-preservesPartitioning Merge pull request #2 from colorant/yarn-client-2.2 Merge pull request #203 from witgo/master Merge pull request #204 from rxin/hash Merge pull request #205 from kayousterhout/logging Merge pull request #206 from ash211/patch-2 Merge pull request #207 from henrydavidge/master Merge pull request #209 from pwendell/better-docs Merge pull request #210 from haitaoyao/http-timeout Merge pull request #212 from markhamstra/SPARK-963 Merge pull request #216 from liancheng/fix-spark-966 Merge pull request #217 from aarondav/mesos-urls Merge pull request #22 from GraceH/metrics-naming Merge pull request #220 from rxin/zippart Merge pull request #225 from ash211/patch-3 Merge pull request #226 from ash211/patch-4 Merge pull request #233 from hsaputra/changecontexttobackend Merge pull request #239 from aarondav/nit Merge pull request #242 from pwendell/master Merge pull request #3 from aarondav/pv-test Merge pull request #36 from pwendell/versions Merge pull request #37 from pwendell/merge-0.8 Merge pull request #39 from pwendell/master Merge pull request #45 from pwendell/metrics_units Merge pull request #56 from jerryshao/kafka-0.8-dev Merge pull request #64 from prabeesh/master Merge pull request #66 from shivaram/sbt-assembly-deps Merge pull request #670 from jey/ec2-ssh-improvements Merge pull request #71 from aarondav/scdefaults Merge pull request #78 from mosharaf/master Merge pull request #8 from vchekan/checkpoint-ttl-restore Merge pull request #80 from rxin/build Merge pull request #82 from JoshRosen/map-output-tracker-refactoring Merge pull request #86 from holdenk/master Merge pull request #938 from ilikerps/master Merge pull request #940 from ankurdave/clear-port-properties-after-tests Merge pull request #98 from aarondav/docs Merge pull request #99 from pwendell/master *Branch-0.8 Only* Merge pull request #138 from marmbrus/branch-0.8 Merge pull request #140 from aarondav/merge-75 Merge pull request #231 from pwendell/branch-0.8 Merge pull request #241 from pwendell/branch-0.8 Merge pull request #241 from pwendell/master Merge pull request #243 from pwendell/branch-0.8 Merge pull request #40 from pwendell/branch-0.8 Merge pull request #47 from xiliu82/branch-0.8 Merge pull request #79 from aarondav/scdefaults0.8 Merge pull request #801 from pwendell/print-launch-command Merge pull request #918 from pwendell/branch-0.8 Revert "Merge pull request #94 from aarondav/mesos-fix"I've thought about creating a setup.py file for PySpark; there are a couple of subtleties involved: - PySpark's uses Py4J to create a regular Java Spark driver, so it's subject to the same limitations that Scala / Java Spark have when connecting from a local machine to a remote cluster; a number of ports need to be opened (this is discussed in more detail in other posts on this list; try searching for "connect to remote cluster" or something like that). - PySpark needs the Spark assembly JAR, so you'd still have to point the SPARK_HOME environment variable to local copy of the Spark assemblies. - We need to be careful about communication between incompatible versions of the Python and Java portions of the library.  We can probably fix this by embedding version numbers in the Python and Java libraries and comparing those numbers when launching the Java gateway. If we decide to distribute a PySpark package on PyPI, we should integrate its release with the regular Apache release process for Spark. Does anyone know how other projects like Mesos distribute their Python bindings?  Is there a good existing model that we should emulate? - Josh There's a pair of open pull requests that implement replay debugging for newer versions of Spark: https://github.com/apache/incubator-spark/pull/224 https://github.com/apache/incubator-spark/pull/284 +1 Which JIRA are you trying to create an issue in?  For now, you should be creating issues in the https://spark-project.atlassian.net JIRA (in the long run, we're going to move to the Apache JIRA, but we're still waiting to import our issues there ). What's your username on the https://spark-project.atlassian.net JIRA? Apache INFRA has been trying to import our JIRA issues since June 2013: https://issues.apache.org/jira/browse/INFRA-6419.  It seems that JIRA introduces minor import incompatibilities with every update to JIRA OnDemand, so it's been a challenge to get the Apache and Atlasssian JIRA versions to sync up. The Contributing to Spark guide on the Spark Wiki provides a good overview on how to start contributing: https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark I think there's some discussion of this at https://issues.apache.org/jira/browse/SPARK-2387 and https://github.com/apache/spark/pull/1328. - Josh Reminder: this Jenkins migration is happening tomorrow morning (Monday). It looks like the Jenkins maven builds are broken, too.  Based on the Jenkins logs, I think that this pull request may have broken things (although I'm not sure why): https://github.com/apache/spark/pull/3030#issuecomment-62436181 Hi Gary, Could you create a Spark JIRA ticket for this so that it doesn't fall through the cracks?  Thanks! -1 I found a potential regression in 1.1.1 related to spark-submit and cluster deploy mode: https://issues.apache.org/jira/browse/SPARK-4434 I think that this is worth fixing. I've noticed that several users are attempting to post messages to Spark's user / dev mailing lists using the Nabble web UI (http://apache-spark-user-list.1001560.n3.nabble.com/).  However, there are many posts in Nabble that are not posted to the Apache lists and are flagged with "This post has NOT been accepted by the mailing list yet."errors. I suspect that the issue is that users are not completing the sign-up confirmation process (http://apache-spark-user-list.1001560.n3.nabble.com/mailing_list/MailingListOptions.jtp?forum=1), which is preventing their emails from being accepted by the mailing list. I wanted to mention this issue to the Spark community to see whether there are any good solutions to address this.  I have spoken to users who think that our mailing list is unresponsive / inactive because their un-posted messages haven't received any replies. - Josh Yeah, it looks like messages that are successfully posted via Nabble end up on the Apache mailing list, but messages posted directly to Apache aren't mirrored to Nabble anymore because it's based off the incubator mailing list.  We should fix this so that Nabble posts to / archives the non-incubator list. I reviewed and merged that PR, in case you want to try out the fix. - Josh This is timely, since I just ran into this issue myself while trying to write a test to reproduce a bug related to speculative execution (I wanted to configure a job so that the first attempt to compute a partition would run slow so that a second, fast speculative copy would be launched). I've opened a PR with a proposed fix: https://github.com/apache/spark/pull/3849 If you've been following AMPLab Jenkins today, you'll notice that there's been a huge number of Spark test failures in the maintenance branches and Maven builds. My best guess as to what's causing this is that I pushed a backport to all maintenance branches at a moment where Jenkins was otherwise idle, causing many builds to kick off at almost the exact same time and eventually fail due to port contention issues in SparkSubmit tests (we didn't disable the web UI when making external calls to ./spark-submit).  I pushed a hotfix to address this.  When the first wave of Jenkins builds failed, the next wave kicked off more-or-less in lockstep since there's only ever one active build for the master builds and the problem was hit again, this time failing a DriverSuite test (which has a port contention problem that needs a separate fix; I'll hotfix this soon). I believe that this flakiness is due to the lockstep synchronization of the first wave of builds (e.g. a bunch of builds that ran DriverSuite and SparkSubmitSuite within a minute or two of each other), and not changes in recent patches.  If the problem persists after further web UI disabling hotfixes, then I'll investigate the recent changes in more detail. Thanks, Josh The pull request builder and SCM-polling builds appear to be working fine, but the links in pull request comments won't work because the AMP Lab webserver is still down.  In the meantime, though, you can continue to access Jenkins through https://hadrian.ist.berkeley.edu/jenkins/ It looks like this may be fixed soon in Jenkins: https://issues.jenkins-ci.org/browse/JENKINS-25446 https://github.com/jenkinsci/flaky-test-handler-plugin/pull/1 Which version of Spark are you using?  What do you mean when you say that you used a hardcoded location for shuffle files? If you look at the current DiskBlockManager code, it looks like it will create a per-application subdirectory in each of the local root directories. Here's the call to create a subdirectory in each root dir: https://github.com/apache/spark/blob/c5cc41468e8709d09c09289bb55bc8edc99404b1/core/src/main/scala/org/apache/spark/storage/DiskBlockManager.scala#L126 This call to Utils.createDirectory() should result in a fresh subdirectory being created for just this application (note the use of random UUIDs, plus the check to ensure that the directory doesn't already exist): https://github.com/apache/spark/blob/c5cc41468e8709d09c09289bb55bc8edc99404b1/core/src/main/scala/org/apache/spark/util/Utils.scala#L273 So, although the filenames for shuffle files are not globally unique, their full paths should be unique due to these unique per-application subdirectories.  Have you observed an instance where this isn't the case? - Josh Thanks for catching this.  It looks like a recent Jenkins job configuration change inadvertently renamed the GITHUB_OAUTH_KEY environment variable to something else, causing this to break.  I've rolled back that change, so hopefully the GitHub posting should start working again. - Josh The leak will impact long running streaming jobs even if they don't write Hadoop files, although the problem may take much longer to manifest itself for those jobs. I think we currently leak an empty HashMap per stage submitted in the common case, so it could take a very long time for this to trigger an OOM.  On the other hand, the worst case behavior is quite bad for streaming jobs, so we should probably fix this so that 1.2.x streaming users can more safely upgrade to 1.3.x. - Josh Sent from my phone --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org Hi everyone, We just merged Python 3 support for PySpark into Spark's master branch (which will become Spark 1.4.0).  This means that PySpark now supports Python 2.6+, PyPy 2.5+, and Python 3.4+. To run with Python 3, download and build Spark from the master branch then configure the PYSPARK_PYTHON environment variable to point to a Python 3.4 executable.  For example: PYSPARK_PYTHON=python3.4 ./bin/pyspark For more details on this feature, see the pull request and JIRA: - https://github.com/apache/spark/pull/5173 - https://issues.apache.org/jira/browse/SPARK-4897 For Spark contributors, this change means that any open PySpark pull requests are now likely to have merge conflicts.  If a pull request does not have merge conflicts, we should still re-test it with Jenkins to check that it still works under Python 3.  When backporting Python patches, committers may wish to run the PySpark unit tests locally to make sure that the change still work correctly in older branches.  I can also help with backports / fixing conflicts. Thanks to Davies Liu, Shane Knapp, Thom Neale, Xiangrui Meng, and everyone else who helped with this patch. - Josh Do you have any more specific profiling data that you can share?  I'm curious to know where AppendOnlyMap.changeValue is being called from. Spark PRs didn't always used to handle the JIRA linking.  We used to rely on a Jenkins job that ran https://github.com/apache/spark/blob/master/dev/github_jira_sync.py.  We switched this over to Spark PRs at a time when the Jenkins GitHub Pull Request Builder plugin was having flakiness issues, but as far as I know that old script should still work. Reminder: the network migration has started this morning, so Jenkins is currently down. Status updates on the migration are being published at http://ucbsystems.org/ I think that @holdenk's *spark-testing-base* project publishes some of these test classes as well as some helper classes for testing streaming jobs: https://github.com/holdenk/spark-testing-base Which commit of master are you building off?  It looks like there was a bugfix for an issue related to KryoSerializer buffer configuration: https://github.com/apache/spark/pull/5934 That patch was committed two weeks ago, but you mentioned that you're building off a newer version of master.  Could you confirm the commit that you're running?  If this used to work but now throws an error, then this is a regression that should be fixed; we shouldn't require you to perform a mb -> kb conversion to work around this. Hey, want to file a JIRA for this?  This will make it easier to track progress on this issue.  Definitely upload the profiler screenshots there, too, since that's helpful information. https://issues.apache.org/jira/browse/SPARK The relevant JIRA that springs to mind is https://issues.apache.org/jira/browse/SPARK-2926 If an aggregator and ordering are both defined, then the map side of sort-based shuffle will sort based on the key ordering so that map-side spills can be efficiently merged.  We do not currently do a sort-based merge on the reduce side; implementing this is a little tricky because it will require more map partitions' output to be buffered on the reduce side.  I think that SPARK-2926 has some proposals of how to deal with this, including hierarchical merging of reduce outputs. RE: ExternalSorter#partitionedIterator, I don't think it's safe to do !ordering.isDefined && !aggregator.isDefined.  If an aggregator is defined but we don't have an ordering, then I don't think it makes sense to sort the keys based on their hashcodes or some default ordering, since hashcode collisions would lead to incorrect results for sort-based aggregation. This has been proposed before: https://issues.apache.org/jira/browse/SPARK-1267 There's currently tighter coupling between the Python and Java halves of PySpark than just requiring SPARK_HOME to be set; if we did this, I bet we'd run into tons of issues when users try to run a newer version of the Python half of PySpark against an older set of Java components or vice-versa. Whatever you do, DO NOT use the built-in JIRA 'releases' feature to migrate issues from 1.4.0 to another version: the JIRA feature will have the side-effect of automatically changing the target versions for issues that have been closed, which is going to be really confusing. I've made this mistake once myself and it was a bit of a hassle to clean up. Hey Peter, I think that this is actually due to an error-handling issue: if you look at the stack trace that you posted, the NPE is being thrown from an error-handling branch of a `finally` block: @Override public void write(scala.collection.Iterator<Product2<K, V>> records) throws IOException { boolean success = false; try { while (records.hasNext()) { insertRecordIntoSorter(records.next()); } closeAndWriteOutput(); success = true; } finally { if (!success) { sorter.cleanupAfterError(); // <---- this is the line throwing the error } } } I suspect that what's happening is that an exception is being thrown from user / upstream code in the initial call to records.next(), but the error-handling block is failing because sorter == null since we haven't initialized it yet. I'm going to file a JIRA for this and will try to add a set of regression tests to the ShuffleSuite to make sure exceptions from user code aren't swallowed like this. I've filed https://issues.apache.org/jira/browse/SPARK-8498 to fix this error-handling code. This is a side effect of the new pull request tester script interacting badly with a Jenkins plugin, not anything caused by your changes. I'm working on a fix but in the meantime I'd just trust what SparkQA says. Sent from my phone --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org At least a couple of those issues are mistargeted; some of the flaky test JIRAs + test improvement tasks should probably be targeted for 1.5.0 instead. This sounds like https://issues.apache.org/jira/browse/SPARK-7436, which has been fixed in Spark 1.4+ and in branch-1.3 (for Spark 1.3.2). Which Spark version are you using?  Can you file a JIRA for this issue? The 2.11 compile build is going to be green because this is an issue with tests, not compilation. I've filed https://issues.apache.org/jira/browse/SPARK-8903 to fix the DataFrameStatSuite test failure. The problem turned out to be caused by a mistake made while resolving a merge-conflict when backporting that patch to branch-1.4. I've submitted https://github.com/apache/spark/pull/7295 to fix this issue. Here's a helpful IntelliJ feature for writing and browsing Scala/Javadoc: You can press Ctrl-j (or View menu -> Quick Documentation) to bring up a popup which displays the Scaladoc / Javadoc for the currently-selected symbol: [image: Inline image 2] This window has a few neat features to make documentation writing easier. If you press the pin button in the upper right-hand corner, the popup window will be replaced by a window which stays on screen as you navigate around the code: [image: Inline image 3] There are options to anchor this as a floating window or to pin it into the side context bar: [image: Inline image 4] In this persistent window, there is one useful option to make documentation easier to work with.  The "Auto Update from Source" option causes the documentation to automatically refresh when you select a different symbol or when you edit the documentation itself.  This allows you to have a live preview when writing documentation. [image: Inline image 6] This feature has some limitations (namely, line breaks and lists in Scaladoc aren't rendered the same way that they would be in the displayed Scaladoc on the website), but most Scaladoc features work (including the {{{ syntax for code examples) and it works perfectly for Javadoc. Anyhow, just wanted to share this feature because it's a big productivity improver when writing docs. - Josh Also, check out https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark We may be able to fix this from the Spark side by adding appropriate exclusions in our Hadoop dependencies, right?  If possible, I think that we should do this. The "It is not a test" failed test message means that something went wrong in a suite-wide setup or teardown method.  This could be some sort of race or flakiness.  If this problem persists, we should file a JIRA and label it with "flaky-test" so that we can find it later. Yep, I emailed TD about it; I think that we may need to make a change to the pull request builder to fix this.  Pending that, we could just revert the commit that added this. Hi Richard, Thanks for your detailed investigation of this issue.  I agree with your observation that the finishedExecutors hashmap is a source of memory leaks for very-long-lived clusters.  It looks like the finishedExecutors map is only read when rendering the Worker Web UI and in constructing REST API responses.  I think that we could address this leak by adding a configuration to cap the maximum number of retained executors, applications, etc.  We already have similar caps in the driver UI.  If we add this configuration, I think that we should pick some sensible default value rather than an unlimited one.  This is technically a user-facing behavior change but I think it's okay since the current behavior is to crash / OOM. Regarding `KillExecutor`, I think that there might be some asynchrony and indirection masking the cleanup here.  Based on a quick glance through the code, it looks like ExecutorRunner's thread will end an ExecutorStateChanged RPC back to the Worker after the executor is killed, so I think that the cleanup will be triggered by that RPC.  Since this isn't clear from reading the code, though, it would be great to add some comments to the code to explain this, plus a unit test to make sure that this indirect cleanup mechanism isn't broken in the future. I'm not sure what's causing the Killed vs Exited issue, but I have one theory: does the behavior vary based on whether your application cleanly shuts down the SparkContext via SparkContext.stop()? It's possible that omitting the stop() could lead to a "Killed" exit status, but I don't know for sure.  (This could probably also be clarified with a unit test). To my knowledge, the spark-perf suite does not contain the sort of scale-testing workload that would expose these types of memory leaks; we have some tests for very long-lived individual applications, but not tests for long-lived clusters that run thousands of applications between restarts.  I'm going to create some tickets to add such tests. I've filed https://issues.apache.org/jira/browse/SPARK-9202 to follow up on the finishedExecutors leak. - Josh I have promoted https://issues.apache.org/jira/browse/SPARK-9202 to a blocker to ensure that we get a fix for it before 1.5.0  I'm pretty swamped with other tasks for the next few days, but I'd be happy to shepherd a bugfix patch for this (this should be pretty straightforward and the JIRA ticket contains a sketch of how I'd do it). I don't think that using git submodules is a good idea here: - The extra `git submodule init && git submodule update` step can lead to confusing problems in certain workflows. - We'd wind up with many commits that serve only to bump the submodule SHA; these commits will be hard to review since they won't contain line diffs (the author will have to manually provide a link to the diff of code changes). To help us track planned / finished configuration renames, defaults changes, and configuration deprecation for the upcoming 1.5.0 release, I have created https://issues.apache.org/jira/browse/SPARK-9550. As you make configuration changes or think of configurations that need to be audited, please update that ticket by editing it or posting a comment. This ticket will help us later when it comes time to draft release notes. Thanks, Josh +1.  I've been holding off on reviewing / merging patches like the run-tests-jenkins Python refactoring for exactly this reason. Can you clarify what you mean by "used for all stages"? OutputCommitCoordinator RPCs should only be initiated through SparkHadoopMapRedUtil.commitTask(), so while the OutputCommitCoordinator doesn't make a distinction between ShuffleMapStages and ResultStages there still should not be a performance penalty for this because the extra rounds of RPCs should only be performed when necessary. Prototype is at https://github.com/databricks/spark-pr-dashboard/pull/59 I ran into a similar problem while working on the spark-redshift library and was able to fix it by bumping that library's ScalaTest version. I'm still fighting some mysterious Scala issues while trying to test the spark-csv library against 1.5.0-RC1, so it's possible that a build or dependency change in Spark might be responsible for this. There are currently a few known issues with using KryoSerializer as the closure serializer, so it's going to require some changes to Spark if we want to properly support this. See https://github.com/apache/spark/pull/6361 and https://issues.apache.org/jira/browse/SPARK-7708 for some discussion of the difficulties here. Does anyone use ShuffleDependency directly in their Spark code or libraries? If so, how do you use it? Similarly, does anyone use ShuffleHandle directly? For quickly running individual suites: https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-RunningIndividualTests Check out SparkFirehoseListener, an adapter which forwards all events to a single `onEvent` method in order to let you do pattern-matching as you have described: https://github.com/apache/spark/blob/master/core/src/main/java/org/apache/spark/SparkFirehoseListener.java To clarify, we're asking about the *spark.sql.tungsten.enabled* flag, which was introduced in Spark 1.5 and enables Project Tungsten optimizations in Spark SQL. This option is set to *true* by default in Spark 1.5+ and exists primarily to allow users to disable the new code paths if they encounter bugs or performance regressions. If anyone sets spark.sql.tungsten.enabled=*false *in their SparkConf in order to *disable* these optimizations, we'd like to hear from you in order to figure out why you disabled them and to see whether we can make improvements to allow your workload to run with Tungsten enabled. Thanks, Josh The reason for having two separate interfaces is developer API backwards-compatibility, as far as I know. SparkFirehoseListener came later. Hey Luciano, This sounds like a reasonable plan to me. One of my colleagues has written some Dockerized MySQL testing utilities, so I'll take a peek at those to see if there are any specifics of their solution that we should adapt for Spark. Hi Mark, The shuffle memory leaks that I identified in SPARK-11239 have been around for multiple releases and it's not clear whether they have caused performance problems in real workloads, so I would say that it's fine to move the release forward without including my patch. If we have to cut another release candidate for some other reason, though, then it might be nice to include it then, but I don't think it qualifies as a release-blocker by itself. Hi Sjoerd, Did your job actually *fail* or did it just generate many spurious exceptions? While the stacktrace that you posted does indicate a bug, I don't think that it should have stopped query execution because Spark should have fallen back to an interpreted code path (note the "Failed to generate ordering, fallback to interpreted" in the error message). I noticed that you're using PyPy 2.2.1, but it looks like Spark 1.5.1's docs say that we only support PyPy 2.3+. Could you try using a newer PyPy version to see if that works? I just checked and it looks like our Jenkins tests are running against PyPy 2.5.1, so that version is known to work. I'm not sure what the actual minimum supported PyPy version is. Would you be interested in helping to investigate so that we can update the documentation or produce a fix to restore compatibility with earlier PyPy builds? Are you sure that the credentials are missing? Also: did you enable GitHub commit status updating by accident / configuration loss? That might explain the errors here, since our keys don't have permissions to use that API. As of https://github.com/apache/spark/pull/9575, Spark's build will no longer place every dependency JAR into lib_managed. Can you say more about how this affected spark-shell for you (maybe share a stacktrace)? Is the Hive profile enabled? I think it may need to be turned on in order for those JARs to be deployed. Can you file a JIRA issue to help me triage this further? Thanks! I think I've also seen this issue as well, but in a different suite. I wasn't able to easily get to the bottom of it, though. What JDK / JRE are you using? I'm on Java(TM) SE Runtime Environment (build 1.7.0_65-b17) Java HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode) on OSX. The JDBC drivers are currently being pulled in as test-scope dependencies of the `sql/core` module: https://github.com/apache/spark/blob/f2fbfa444f6e8d27953ec2d1c0b3abd603c963f9/sql/core/pom.xml#L91 In SBT, these wind up on the Docker JDBC tests' classpath as a transitive dependency of the `spark-sql` test JAR. However, what we *should* be doing is adding them as explicit test dependencies of the `docker-integration-tests` subproject, since Maven handles transitive test JAR dependencies differently than SBT (see https://github.com/apache/spark/pull/9876#issuecomment-158593498 for some discussion). If you choose to make that fix as part of your PR, be sure to move the version handling to the root POM's  section so that the versions in both modules stay in sync. We might also be able to just simply move the JDBC driver dependencies to docker-integration-tests'POM if it turns out that they're not used anywhere else (that's my hunch). Yep, I'm the point of contact between us and JetBrains. I forwarded the 2015 license renewal email to the private@ list, so it should be accessible via the archives. I'll go ahead and forward you a copy of our project license, which will have to be renewed in January of next year. I agree that we should unset this in our tests. Want to file a JIRA and submit a PR to do this? Can you write a script to download and install the JDBC driver to the local Maven repository if it's not already present? If we had that, we could just invoke it as part of dev/run-tests. Personally, I'd rather avoid the risk of breaking things during the reimport. In my experience we've had a lot of unforeseen problems with JIRA import/export and the benefit here doesn't seem huge (this issue only impacts people that are searching for the oldest JIRAs across all projects, which I think is pretty uncommon). Just my two cents. - Josh Would you mind copying this information into a JIRA ticket to make it easier to discover / track? Thanks! +1 I just merged https://github.com/apache/spark/pull/10461, a PR that adds new automated tooling to help us reason about dependency changes in Spark. Here's a summary of the changes: - The dev/run-tests script (used in the SBT Jenkins builds and for testing Spark pull requests) now generates a file which contains Spark's resolved runtime classpath for each Hadoop profile, then compares that file to a copy which is checked into the repository. These dependency lists are found at https://github.com/apache/spark/tree/master/dev/deps; there is a separate list for each Hadoop profile. - If a pull request changes dependencies without updating these manifest files, our test script will fail the build and the build console output will list the dependency diff . - If you are intentionally changing dependencies, run ./dev/test-dependencies.sh --replace-manifest to re-generate these dependency manifests then commit the changed files and include them with your pull request. The goal of this change is to make it simpler to reason about build changes: it should now be much easier to verify whether dependency exclusions worked properly or determine whether transitive dependencies changed in a way that affects the final classpath. Let me know if you have any questions about this change and, as always, feel free to submit pull requests if you would like to make any enhancements to this script. Thanks, Josh I updated the release packaging scripts to use SFTP via the *lftp* client: https://github.com/apache/spark/pull/11350 I'm starting the process of cutting a 1.6.1-RC1 tag and release artifacts right now, so please be extra careful about merging into branch-1.6 until after the release. Once the RC packaging completes, Michael or I will email the list to start a vote thread. - Josh Does anyone implement Spark's serializer interface (org.apache.spark.serializer.Serializer) in your own third-party code? If so, please let me know because I'd like to change this interface from a DeveloperAPI to private[spark] in Spark 2.0 in order to do some cleanup and refactoring. I think that the only reason it was a DeveloperAPI was Shark, but I'd like to confirm this by asking the community. Thanks, Josh See the instructions in the Spark documentation: https://spark.apache.org/docs/latest/building-spark.html#building-for-scala-211 Err, whoops, looks like this is a user app and not building Spark itself, so you'll have to change your deps to use the 2.11 versions of Spark. e.g. spark-streaming_2.10 -> spark-streaming_2.11. It looks like the Scala 2.10 Jenkins build is working: https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Compile/job/spark-master-compile-sbt-scala-2.10/ Can you share more details about how you're compiling with 2.10 (e.g. which commands you ran, git SHA, etc)? One clarification: there *are* Python interpreters running on executors so that Python UDFs and RDD API code can be executed. Some slightly-outdated but mostly-correct reference material for this can be found at https://cwiki.apache.org/confluence/display/SPARK/PySpark+Internals. See also: search the Spark codebase for PythonRDD and look at python/pyspark/worker.py In order to be able to run Java 8 API compatibility tests, I'm going to push a new set of Jenkins configurations for Spark's test and PR builders so that those jobs use a Java 8 JDK. I tried this once in the past and it seemed to introduce some rare, transient flakiness in certain tests, so if anyone observes new test failures please email me and I'll investigate right away. Note that this change has no impact on Spark's supported JDK versions and our build will still target Java 7 and emit Java 7 bytecode; the purpose of this change is simply to allow the Java 8 lambda tests to be run as part of PR builder runs. - Josh I've reverted the bulk of the conf changes while I investigate. I think that Zinc might be handling JAVA_HOME in a weird way and am SSH'ing to Jenkins to try to reproduce the problem in isolation. I finally figured out the problem: it seems that my *export JAVA_HOME=/path/to/java8/home* was somehow not affecting the javac executable that Zinc's SBT incremental compiler uses when it forks out to javac to handle Java source files. As a result, we were passing a -source 1.8 flag to the platform's default javac, which happens to be Java 7. To fix this, I'm going to modify the build to just prepend $JAVA_HOME/bin to $PATH while setting up the test environment +1; I think that it's preferable for code examples, especially third-party integration examples, to live outside of Spark. I think that this is a simpler case of https://issues.apache.org/jira/browse/SPARK-17405. I'm going to comment on that ticket with your simpler reproduction. I think that these tests are valuable so I'd like to keep them. If possible, though, we should try to get rid of our dependency on the Spotify docker-client library, since it's a dependency hell nightmare. Given our relatively simple use of Docker here, I wonder whether we could just write some simple scripting over the `docker` command-line tool instead of pulling in such a problematic library. +1 A useful tool for investigating test flakiness is my Jenkins Test Explorer service, running at https://spark-tests.appspot.com/ This has some useful timeline views for debugging flaky builds. For instance, at https://spark-tests.appspot.com/jobs/spark-master-test-maven-hadoop-2.6 (may be slow to load) you can see this chart: https://i.imgur.com/j8LV3pX.png. Here, each column represents a test run and each row represents a test which failed at least once over the displayed time period. In that linked example screenshot you'll notice that a few columns have grey squares indicating that tests were skipped but lack any red squares to indicate test failures. This usually indicates that the build failed due to a problem other than an individual test failure. For example, I clicked into one of those builds and found that one test suite failed in test setup because the previous suite had not properly cleaned up its SparkContext (I'll file a JIRA for this). You can click through the interface to drill down to reports on individual builds, tests, suites, etc. As an example of an individual test's detail page, https://spark-tests.appspot.com/test-details?suite_name=org.apache.spark.rdd.LocalCheckpointSuite&test_name=missing+checkpoint+block+fails+with+informative+message shows the patterns of flakiness in a streaming checkpoint test. Finally, there's an experimental "interesting new test failures" report which tries to surface tests which have started failing very recently: https://spark-tests.appspot.com/failed-tests/new. Specifically, entries in this feed are test failures which a) occurred in the last week, b) were not part of a build which had 20 or more failed tests, and c) were not observed to fail in during the previous week (i.e. no failures from [2 weeks ago, 1 week ago)), and d) which represent the first time that the test failed this week (i.e. a test case will appear at most once in the results list). I've also exposed this as an RSS feed at https://spark-tests.appspot.com/rss/failed-tests/new. I spotted the problem and it appears to be a misconfiguration / missing entry in the template which generates the packaging jobs. I've corrected the problem but now the jobs appear to be hanging / flaking on the Git clone. Hopefully this is just a transient issue, so let's retry tonight and see whether things are fixed.
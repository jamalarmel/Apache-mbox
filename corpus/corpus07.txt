Okie doke--added myself as a watcher on that issue.
On a related note, what are the thoughts on automatically spinning up/down
EC2 clusters and running tests against them? It would probably be way too
cumbersome to do that for every build, but perhaps on some schedule it
could help validate that we are still deploying EC2 clusters correctly.
Would something like that be valuable?
Nick
That's pretty neat.
How does it work? Do we just need to put the issue ID (e.g. SPARK-1234)
anywhere in the pull request?
Nick
I just created SPARK-2602  to
track this issue.
Are there others who can confirm this is an issue? Also, does this issue
extend to other OSes?
Nick
TD, there are a couple of unresolved issues slated for 1.0.2
.
Should they be edited somehow?
This sounds more like a user list 
question. This is the dev list, where people discuss things related to
contributing code and such to Spark.
+1 on using JIRA workflows to manage the backlog, and +9000 on having
decent descriptions for all JIRA issues.
Seems to be back up now.
FYI: Looks like Xiangrui's already got a JIRA issue for this.
SPARK-2622: Add Jenkins build numbers to SparkQA messages
2. "Pin" a message to the start or end of the PR
Should new JIRA issues for this item fall under the following umbrella
issue?
SPARK-2230: Improvements to Jenkins QA Harness
Nick
Howdy,
Do we think it's both feasible and worthwhile to invest in getting our unit
tests to finish in under 5 minutes (or something similarly brief) when run
by Jenkins?
Unit tests currently seem to take anywhere from 30 min to 2 hours. As
people add more tests, I imagine this time will only grow. I think it would
be better for both contributors and reviewers if they didn't have to wait
so long for test results; PR reviews would be shorter, if nothing else.
I don't know how how this is normally done, but maybe it wouldn't be too
much work to get a test cycle to feel lighter.
Most unit tests are independent and can be run concurrently, right? Would
it make sense to build a given patch on many servers at once and send
disjoint sets of unit tests to each?
I'd be interested in working on something like that if possible (and
sensible).
Nick
On a related note, I recently heard about Distributed R
, which is coming out of
HP/Vertica and seems to be their proposition for machine learning at scale.
It would be interesting to see some kind of comparison between that and
MLlib (and perhaps also SparkR ?),
especially since Distributed R has a concept of distributed arrays and
works on data in-memory. Docs are here.
Nick
Shivaram,
Can you point us to an example of that happening? The Jenkins console
output, that is.
Nick
OK, I've captured this in SPARK-3076
.
Patrick,
Is the problem that this run-tests
step
times out, and that is currently not handled gracefully? To be more
specific, it hangs for 120 minutes, times out, but the parent script for
some reason is also terminated. Does that sound right?
Nick
So 2 hours is a hard cap on how long a build can run. Okie doke.
Perhaps then I'll wrap the run-tests step as you suggest and limit it to
100 minutes or something, and cleanly report if it times out.
Sound good?
*Bam. *
Check this out:
https://github.com/apache/spark/pulls?q=is%3Aopen+is%3Apr+sort%3Aupdated-asc
We're hitting close to 300 open PRs. Those are the least recently updated
ones.
I think having a low number of stale (i.e. not recently updated) PRs is a
good thing to shoot for. It doesn't leave contributors hanging (which feels
bad for contributors), and reduces project clutter (which feels bad for
maintainers/committers).
What is our approach to tackling this problem?
I think communicating and enforcing a clear policy on how stale PRs are
handled might be a good way to reduce the number of stale PRs we have
without making contributors feel rejected.
I don't know what such a policy would look like, but it should be
enforceable and "lightweight"--i.e. it shouldn't feel like a hammer used to
reject people's work, but rather a necessary tool to keep the project's
contributions relevant and manageable.
Nick
Looks like we're currently at 1.568 so we should be getting a nice slew of
UI tweaks and bug fixes. Neat!
-1: I believe I've found a regression from 1.0.2. The report is captured in
SPARK-3333 .
What do people think of running the Big Data Benchmark
 (repo
) as part of preparing every new
release of Spark?
We'd run it just for Spark and effectively use it as another type of test
to track any performance progress or regressions from release to release.
Would doing such a thing be valuable? Do we already have a way of
benchmarking Spark performance that we use regularly?
Nick
Oh, that's sweet. So, a related question then.
Did those tests pick up the performance issue reported in SPARK-3333
? Does it make sense to
add a new test to cover that case?
Alright, sounds good! I've created databricks/spark-perf/issues/9
 as a reminder for us to
add a new test once we've root caused SPARK-3333.
Hi Shane!
Thank you for doing the Jenkins upgrade last week. It's nice to know that
infrastructure is gonna get some dedicated TLC going forward.
Welcome aboard!
Nick
In light of the discussion on SPARK-3333, I'll revoke my "-1" vote. The
issue does not appear to be serious.
Woohoo! Thanks Shane.
Do you know if queued PR builds will automatically be picked up? Or do we
have to ping the Jenkinmensch manually from each PR?
Nick
It appears that our main man is having trouble
 hearing new requests
.
Do we need some smelling salts?
Looks like during the last build
Jenkins was unable to execute a git fetch?
Hmm, looks like at least some builds
are working now, though this last one was from ~5 hours ago.
How's it going?
It looks like during the last build
from about 30 min ago Jenkins was still having trouble fetching from
GitHub. It also looks like not all requests for testing are triggering
builds.
Looks like Jenkins is back!
lol The poor guy has like a million builds
to catch up on.
After reading Erik's email, I found this Scala PR
 and immediately noticed a few
cool things:
   - Jenkins is hooked directly into GitHub somehow, so you get the "All is
   well" message in the merge status window, presumably based on the last test
   status
   - Jenkins is also tagging the PR based on its test status or need for
   review
   - Jenkins is also tagging the PR for a specific milestone
Do any of these things make sense to add to our setup? Or perhaps something
inspired by these features?
Nick
Aww, that's a bummer...
I'm looking forward to this. :)
Looks like Jenkins is having trouble triggering builds for new commits or
after user requests (e.g.
).
Hopefully that will be resolved tomorrow.
Nick
Nice work everybody! I'm looking forward to trying out this release!
How early can MiMa checks be run? Before Spark is even built
?
After the build but before the unit tests?
Sounds good! Thanks for the update Shane.
As discussed here , it would be
good to extend our Scala style checks to programmatically enforce as many
of our style rules as possible.
Does anyone know if it's relatively straightforward to enforce additional
rules like the "no trailing spaces" rule mentioned in the linked PR?
Nick
Ah, since there appears to be a built-in rule for end-of-line whitespace,
Michael and Cheng, y'all should be able to add this in pretty easily.
Nick
Yeah, I remember that hell when I added PEP 8 to the build checks and fixed
all the outstanding Python style issues. I had to keep rebasing and
resolving merge conflicts until the PR was merged.
It's a rough process, but thankfully it's also a one-time process. I might
be able to help with that in the next week or two if no-one else wants to
pick it up.
Nick
Thanks for posting that script, Patrick. It looks like a good place to
start.
Regarding Docker vs. Packer, as I understand it you can use Packer to
create Docker containers at the same time as AMIs and other image types.
Nick
FYI: I've created SPARK-3821: Develop an automated way of creating Spark
images (AMI, Docker, and others)
For starters, do we have a list of all the Scala style rules that are
currently not enforced automatically but are likely well-suited for
automation?
Let's put such a list together in a JIRA issue and work through
implementing them.
Nick
I've created SPARK-3849: Automate remaining Scala style rules
.
Please create sub-tasks on this issue for rules that we have not automated
and let's work through them as possible.
I went ahead and created the first sub-task, SPARK-3850: Scala style:
Disallow trailing spaces .
Nick
Does it make sense to point the Spark PR review board to read from
mesos/spark-ec2 as well? PRs submitted against that repo may reference
Spark JIRAs and need review just like any other Spark PR.
Nick
Thanks for doing this work Shane.
So is Jenkins in the new datacenter now? Do you know if the problems with
checking out patches from GitHub should be resolved now? Here's an example
from the past hour
.
Nick
Ah, that sucks. Thank you for looking into this.
*fingers crossed*
I support this effort. :thumbsup:
A quick scan through the Spark PR board  shows
no recent failures related to this git checkout problem.
Looks promising!
Nick
https://news.ycombinator.com/item?id=8471812
The parent thread has lots of interesting use cases for Docker, and the
linked comment seems most relevant to our testing predicament.
I might look into this after I finish something presentable with Packer and
our EC2 scripts, but if anyone else is interested, by all means...
Nick
So back to my original question... :)
If we wanted to post this guide to the user list or to a gist for easy
reference, would we rather have Maven or SBT listed? And is there anything
else about the steps that should be modified?
Nick
I know we don't want to be jumping at every benchmark someone posts out
there, but this one surprised me:
http://www.citusdata.com/blog/86-making-postgresql-scale-hadoop-style
This benchmark has Spark SQL failing to complete several queries in the
TPC-H benchmark. I don't understand much about the details of performing
benchmarks, but this was surprising.
Are these results expected?
Related HN discussion here: https://news.ycombinator.com/item?id=8539678
Nick
Minor question, but when would be the right time to update the default
Spark version
in the EC2 script?
FWIW, the "official" build instructions are here:
https://github.com/apache/spark#building-spark
Zinc, I believe, is something you can install and run to speed up your
Maven builds. It's not required.
I get a bunch of warnings when compiling with Maven, too. Dunno if they are
expected or not, but things work fine from there on.
Many people do indeed use sbt. I don't know where we have documentation on
how to use sbt (we recently removed it from the README), but sbt/sbt clean
followed by sbt/sbt assembly should work fine.
Maven is indeed the "proper" way to build Spark, but building with sbt is
supported too and most Spark devs I believe use it because it's faster than
Maven.
Nick
Ah, found it:
https://github.com/apache/spark/blob/master/docs/building-spark.md#building-with-sbt
This version of the docs should be published once 1.2.0 is released.
Nick
+1 on this proposal.
Did you mean to send this to the user list?
This is the dev list, where we discuss things related to development on
Spark itself.
I just watched Kay's talk from 2013 on Sparrow
. Is replacing Spark's native
scheduler with Sparrow still on the books?
The Sparrow repo  hasn't been updated
recently, and I don't see any JIRA issues about it.
It would be good to at least have a JIRA issue to track progress on this if
it's a long-term goal.
Nick
Did you mean 15 tasks per machine per second here? Or alternatively, 10
machines?
I don't know of any existing Spark clusters that have a large enough number
Actually, this was the reason I took interest in Sparrow--specifically, the
idea of a Spark cluster handling many very short (<< 50 ms) tasks.
At the recent Spark Committer Night
 in NYC, I asked Michael
if he thought that Spark SQL could eventually completely fill the need for
very low latency queries currently served by MPP databases like Redshift or
Vertica. If I recall correctly, he said that the main obstacle to that was
simply task startup time, which is on the order of 100 ms.
Is there interest in (or perhaps an existing initiative related to)
improving task startup times to the point where one could legitimately look
at Spark SQL as a low latency database that can serve many users or
applications at once? That would probably make a good use case for Sparrow,
no?
Nick
Sounds good. I'm looking forward to tracking improvements in this area.
Also, just to connect some more dots here, I just remembered that there is
currently an initiative to add an IndexedRDD
 interface. Some
interesting use cases mentioned there include (emphasis added):
To address these problems, we propose IndexedRDD, an efficient key-value
GraphX would be the first user of IndexedRDD, since it currently implements
Maybe some day we'll have Spark clusters directly serving up point lookups
or updates. I imagine the tasks running on clusters like that would be tiny
and would benefit from very low task startup times and scheduling latency.
Am I painting that picture correctly?
Anyway, thanks for explaining the current status of Sparrow.
Nick
I've posted
an initial proposal and implementation of using Packer to automate
generating Spark AMIs to SPARK-3821
.
Yeah, kudos to Josh for putting that together.
That's a good idea.
To encourage and leverage the community to review PRs and JIRA issues, we
should link to both the PR dashboard  and
the stale JIRA filter
 (or
whatever JIRA filter or dashboard we want) from someplace prominent,
perhaps from the CONTRIBUTING
 file.
Nick
https://github.com/apache/spark/blob/master/docs/building-spark.md#speeding-up-compilation-with-zinc
Could someone summarize how they invoke zinc as part of a regular
build-test-etc. cycle?
I'll add it in to the aforelinked page if appropriate.
Nick
Oh, derp. I just assumed from looking at all the options that there was
something to it. Thanks Sean.
Ted,
I posted some updates
on
JIRA on my progress (or lack thereof) getting SBT to parallelize test
suites properly. I'm currently stuck with SBT / ScalaTest, so I may move on
to trying Maven.
Andrew,
Once we have a basic grasp of how to parallelize some of the tests, the
next step will probably be to use containers (i.e. Docker) to allow more
parallelization, especially for those tests that, for example, contend for
ports.
Nick
I recently came across this blog post, which reminded me of this thread.
How to Discourage Open Source Contributions
We are currently at 320+ open PRs, many of which haven't been updated in
over a month. We have quite a few PRs that haven't been touched in 3-5
months.
*If you have the time and interest, please hop on over to the Spark PR
Dashboard , sort the PRs by
least-recently-updated, and update them where you can.*
I share the blog author's opinion that letting PRs go stale discourages
contributions, especially from first-time contributors, and especially more
so when the PR author is waiting on feedback from a committer or
contributor.
I've been thinking about simple ways to make it easier for all of us to
chip in on controlling stale PRs in an incremental way. For starters, would
it help if an automated email went out to the dev list once a week that a)
reported the number of stale PRs, and b) directly linked to the 5 least
recently updated PRs?
Nick
So all this time the tests that Jenkins has been running via Jenkins and
SBT + ScalaTest... those haven't been running any of the Java unit tests?
SPARK-4159  only mentions
Maven as a problem, but I'm wondering how these tests got through Jenkins
OK.
OK. That's concerning. Hopefully that's the only bug we'll dig up once we
run all the Java tests but who knows.
Patrick,
Shouldn't this be a release blocking bug for 1.2 (mostly just because it
has already been covered by a unit test)? Well, that, as well as any other
bugs that come up as we run these Java tests.
Nick
Nevermind, seems to be back up now.
For example: https://issues.apache.org/jira/browse/SPARK-3431
Where do we report/track issues with JIRA itself being down?
Nick
Every time we run a test cycle on our Jenkins cluster, we generate hundreds
of XML reports covering all the tests we have (e.g.
`streaming/target/test-reports/org.apache.spark.streaming.util.WriteAheadLogSuite.xml`).
These reports contain interesting information about whether tests succeeded
or failed, and how long they took to complete. There is also detailed
information about the environment they ran in.
It might be valuable to have a window into all these reports across all
Jenkins builds and across all time, and use that to track basic statistics
about our tests. That could give us basic insight into what tests are flaky
or slow, and perhaps drive other improvements to our testing infrastructure
that we can't see just yet.
Do people think that would be valuable? Do we already have something like
this?
I'm thinking for starters it might be cool if we automatically uploaded all
the XML test reports from the Master and the Pull Request builders to an S3
bucket and just opened it up for the dev community to analyze.
Nick
How about all of them ? How
much data per day would it roughly be if we uploaded all the logs for all
these builds?
Also, would Databricks be willing to offer up an S3 bucket for this purpose?
Nick
Shout-out to Michael and other Spark SQL contributors for really trimming
down the number of open/stale Spark SQL PRs
.
As of right now, the least recently updated open Spark SQL PR goes back
only 11 days.
Nice work!
Nick
Okie doke! (I just assumed there was an issue since the policy was brought
up.)
Does this include contributions made against the spark-ec2
 repo?
The correct docs link is:
https://spark.apache.org/docs/1.2.0/building-spark.html
Where did you get that bad link from?
Nick
Thanks for the pointer. This will be fixed in this PR
.
Do we have access to the SQL specification (say, SQL-92) for reference
during Spark SQL development? I know it's not freely available on the web.
Usually, you can only access drafts.
I know that, generally, we look to other systems (especially Hive) when
figuring out how something in Spark SQL should work, but it might be nice
to have the standard available for reference.
Nick
You sent this to the dev list. Please send it instead to the user list.
We use the dev list to discuss development on Spark itself, new features,
fixes to known bugs, and so forth.
The user list is to discuss issues using Spark, which I believe is what you
are looking for.
Nick
Side question: Should this section
in
the wiki link to Useful Developer Tools
?
What do y'all think of creating a standardized Spark development
environment, perhaps encoded as a Vagrantfile, and publishing it under
`dev/`?
The goal would be to make it easier for new developers to get started with
all the right configs and tools pre-installed.
If we use something like Vagrant, we may even be able to make it so that a
single Vagrantfile creates equivalent development environments across OS X,
Linux, and Windows, without having to do much (or any) OS-specific work.
I imagine for committers and regular contributors, this exercise may seem
pointless, since y'all are probably already very comfortable with your
workflow.
I wonder, though, if any of you think this would be worthwhile as a
improvement to the "new Spark developer" experience.
Nick
FYI: scalastyle just merged in a patch to add support for external rules
.
I forget why I was following the linked issue, but I assume it's related to
this discussion.
Nick
Do we have any open JIRA issues to add automated testing on Windows to
Jenkins? I assume that's something we want to do.
I believe this was changed for 1.2.1. Here are the relevant JIRA issues
.
Congratulations guys!
+9000 on cleaning up JIRA.
Thank you Sean for laying out some specific things to tackle. I will assist
with this.
Regarding email, I think Sandy is right. I only get JIRA email for issues
I'm watching.
Nick
Oh derp, missed the YARN component.
JIRA, does allow admins to make fields mandatory:
https://confluence.atlassian.com/display/JIRA/Specifying+Field+Behavior#SpecifyingFieldBehavior-Makingafieldrequiredoroptional
Nick
By the way, isn't it possible to make the "Component" field mandatory when
people open new issues? Shouldn't we do that?
Btw Patrick, don't we need a YARN component? I think our JIRA components
should roughly match the components on the PR dashboard
.
Nick
+1 to an "official" deprecation + redirecting users to some other project
that will or already is taking this on.
Nate?
I guess on a technicality the docs just say "first item in this RDD", not
"first line in the source text file". AFAIK there is no way apart from
filtering to remove header lines
.
As long as first() always returns the same value for a given RDD, I think
it's fine, no?
Nick
The first concern for Spark will probably be to ensure that we still build
and test against Python 2.6, since that's the minimum version of Python we
support.
Otherwise this seems OK. We use numpy and other Python packages in PySpark,
but I don't think we're pinned to any particular version of those packages.
Nick
Thanks for sharing the feedback about what works well for you!
It's nice to get that; as we all probably know, people generally reach out
only when they have problems.
https://github.com/apache/spark/blob/fd8d283eeb98e310b1e85ef8c3a8af9e547ab5e0/ec2/spark_ec2.py#L162-L164
Is there any reason we shouldn't update the default Hadoop major version in
spark-ec2 to 2?
Nick
Looks like the release is out:
http://spark.apache.org/releases/spark-release-1-3-0.html
Though, interestingly, I think we are missing the appropriate v1.3.0 tag:
https://github.com/apache/spark/releases
Nick
I've seen other projects use Appveyor  for CI on
Windows.
Has anyone used them before?
I've seen on more than one occasion something break on Windows without us
knowing, so it might be worth looking into using something like this if
it's relatively straightforward.
Nick
I've seen many other OSS projects ask contributors to sign CLAs. I've never
seen us do that.
I assume it's not an issue, since people opening PRs generally understand
what it means. But legally I'm sure there's some danger in taking an
implied vs. explicit license to do something.
So: Do we need to make people sign contributor CLAs?
I'm betting Sean Owen knows something about this... :)
Nick
SGTM.
Have you reviewed this guide?
https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark
Nick
Wow, I had an open email draft to whine (yet again) about our open PR count
and provide some suggestions.
Will redirect that to the JIRA Sean created. Sweet!
Nick
That's a great point, Burak. I think we are still figuring out when and how
to redirect people when their work doesn't fit the main Spark repo, and
Spark Packages should be a good destination in some cases.
Btw, my comment on JIRA (which Sean referenced) regarding rejecting more
patches is here
.
Nick
Would we be interested in having a public chat room?
Gitter  offers them for free for open source projects.
It's like web-based IRC.
Check out the Docker room for example:
https://gitter.im/docker/docker
And if people prefer to use actual IRC, Gitter offers a bridge for that
 to their service.
All we need is someone who's a member of the Apache GitHub group to create
a room for us.
It should show up under
https://gitter.im/apache/spark
when it's ready.
What do y'all think?
Nick
Is spark-ec2 intended for spinning up production Spark clusters?
I think the answer is no.
However, the docs for spark-ec2
 very much leave
that possibility open, and indeed I see many people asking questions or
opening issues that stem from some production use case they are trying to
fit spark-ec2 to.
Here's the latest example
of
someone using spark-ec2 to power their (presumably) production service.
Shouldn't we actively discourage people from using spark-ec2 in this way?
I understand there's no stopping people from doing what they want with it,
and certainly the questions and issues we receive about spark-ec2 are still
valid, even if they stem from discouraged use cases.
one-off jobs, prototypes, and so forth.
If that's the case, it's best to stress this in the docs.
Nick
Nate, could you point us to an example of how one would use Big Top as a
"more production-ish" replacement for spark-ec2? I look a look at the project
page , but couldn't find any usage
examples. Perhaps we can link to them from the spark-ec2 docs.
Regarding tests to validate that Spark was set up correctly, I am
using the JSON
feed from the Spark master web UI
 for starters. Y'all might find
it useful for the same purpose.
Nick
I like the idea of having design docs be kept up to date and tracked in
git.
If the Apache repo isn't a good fit, perhaps we can have a separate repo
just for design docs? Maybe something like github.com/spark-docs/spark-docs/
?
If there's other stuff we want to track but haven't, perhaps we can
generalize the purpose of the repo a bit and rename it accordingly (e.g.
spark-misc/spark-misc).
Nick
Oh, a GitHub wiki (which is separate from having docs in a repo) is yet
another approach we could take, though if we want to do that on the main
Spark repo we'd need permission from Apache, which may be tough to get...
And unfortunately, many Jenkins executor slots are being taken by stale
Spark PRs...
You can check JIRA for any existing plans. If there isn't any, then feel
free to create a JIRA and make the case there for why this would be a good
feature to add.
Nick
I understand the concern about cutting out users who still use Java 6, and
I don't have numbers about how many people are still using Java 6.
But I want to say at a high level that I support deprecating older versions
of stuff to reduce our maintenance burden and let us use more modern
patterns in our code.
Maintenance always costs way more than initial development over the
lifetime of a project, and for that reason "anti-support" is just as
important as support.
(On that note, I think Python 2.6 should be next on the chopping block
sometime later this year, but that's for another thread.)
Nick
Details are here: https://issues.apache.org/jira/browse/SPARK-7442
It looks like something specific to building against Hadoop 2.6?
Nick
And a link to SPARK-7035
 (which
Xiangrui mentioned in his initial email) for the lazy.
https://issues.apache.org/jira/browse/SPARK-1517
That issue should probably be unassigned since I am not actively working on
it. (I can't unassign myself.)
Nick
That happens automatically when you open a PR with the JIRA key in the PR
title.
There's no magic to it. We're doing the same, except Josh automated it in
the PR dashboard he created.
https://spark-prs.appspot.com/
Nick
taken
out for the release. If not, then it happens de facto anyway, which is
worse than managing it on purpose.
+1 to this.
I wouldn't mind helping go through open issues on JIRA targeted for the
next release around RC time to make sure that a) nothing major is getting
missed for the release and b) the JIRA backlog gets trimmed of the cruft
which is constantly building up. It's good housekeeping.
Nick
adding big new chunks of work. The stat is worth keeping an eye on.
+1, keeping in mind that burning down work also means just targeting it for
a different release or closing it. :)
Nick
The way to do that is to follow the "Unsubscribe" link here for dev@spark:
http://spark.apache.org/community.html
We can't drop you. You have to do it yourself.
Nick
See: https://issues.apache.org/jira/browse/SPARK-3533
Feel free to comment there and make a case if you think the issue should be
reopened.
Nick
You can find the source tagged for release on GitHub
, as was clearly
linked to in the thread to vote on the release (titled "[VOTE] Release
Apache Spark 1.5.1 (RC1)").
Is there something about that thread that was unclear?
Nick
https://s3.amazonaws.com/spark-related-packages/
spark-ec2 uses this bucket to download and install HDFS on clusters. Is it
owned by the Spark project or by the AMPLab?
Anyway, it looks like the latest Hadoop install available on there is
Hadoop 2.4.0.
Are there plans to add newer versions of Hadoop for use by spark-ec2 and
similar tools, or should we just be getting that stuff via an Apache mirror
? The latest version is 2.7.1, by
the way.
The problem with the Apache mirrors, if I am not mistaken, is that you
cannot use a single URL that automatically redirects you to a working
mirror to download Hadoop. You have to pick a specific mirror and pray it
doesn't disappear tomorrow.
Nick
Thanks for sharing this, Christian.
What build of Spark are you using? If I understand correctly, if you are
using Spark built against Hadoop 2.6+ then additional configs alone won't
help because additional libraries also need to be installed
.
Nick
That's the Spark version. I'm wondering what version of Hadoop your Spark
is built against.
For example, when you download Spark
 you have to select from a number
of packages (under "Choose a package type"), and each is built against a
different version of Hadoop. When Spark is built against Hadoop 2.6+, from
my understanding, you need to install additional libraries
 to access S3. When Spark
is built against Hadoop 2.4 or earlier, you don't need to do this.
I'm confirming that this is what is happening in your case.
Nick
-0
The spark-ec2 version is still set to 1.5.1
.
Nick
Yep, I think if you try spark-1.5.1-hadoop-2.6 you will find that you
cannot access S3, unfortunately.
I might be mistaken, but yes, even with the changes you mentioned you will
not be able to access S3 if Spark is built against Hadoop 2.6+ unless you
install additional libraries. The issue is explained in SPARK-7481
 and SPARK-7442
.
-0
If spark-ec2 is still a supported part of the project, then we should
update its version lists as new releases are made. 1.5.2 had the same issue.
https://github.com/apache/spark/blob/v1.6.0-rc1/ec2/spark_ec2.py#L54-L91
(I guess as part of the 2.0 discussions we should continue to discuss
whether spark-ec2 still belongs in the project. I'm starting to feel
awkward reporting spark-ec2 release issues...)
Nick
Alex has built tooling for this btw:
https://github.com/databricks/spark-pr-dashboard/pull/71
+1 to what Mark said. I've been following this discussion and I don't
understand where the sudden "Databricks vs. everybody else" narrative came
from.
Howdy,
It seems like every week we have at least a couple of people emailing the
user list in vain with "Unsubscribe" in the subject, the body, or both.
I remember a while back that every email on the user list used to include a
footer with a quick link to unsubscribe. It was removed, I believe, because
someone thought it was unnecessary clutter.
I disagree.
Please add that footer back in. It's a tiny cost to pay for giving users
the convenience of easily unsubscribing; it makes it much less likely that
people will mistakenly spam everybody as they have been; and it follows
modern email list conventions. The link can just be a "mailto:..." link
that does the same thing that you have to do today to unsubscribe.
I don't think we need to do the same thing on the dev list since the volume
of email is much lower, and since people on average here are probably more
familiar with the mechanics of subscribing to and unsubscribing from Apache
mailing lists.
Nick
Just curious: Did we have an RC3? I don't remember seeing one.
Oh nevermind, just noticed your note. Apologies.
It appears that RDDs can do a cartesian join, but not DataFrames. Is there
a fundamental reason why not, or is this just waiting for someone to
implement?
I know you can get the RDDs underlying the DataFrames and do the cartesian
join that way, but you lose the schema of course.
Nick
Don't know much about Spark + Arrow efforts myself; just wanted to share
the reference.
I wish JIRA would automatically show you potentially similar issues as you
are typing up a new one, like Stack Overflow does...
It would really help cut down on duplicate reports.
FYI: Support for both Python 2.6 and Java 7 was deprecated in 2.0 (see release
notes  under
Deprecations). The deprecation notice didn't offer a specific timeline for
completely dropping support other than to say they "might be removed in
future versions of Spark 2.x".
Not sure what the distinction between deprecating and dropping support is
for language versions, since in both cases it seems like it's OK to do
things not compatible with the deprecated versions.
Nick
Howdy folks,
I wonder if anybody has ever used Facebook's mention-bot in a project:
https://github.com/facebook/mention-bot
Seems like a useful tool to help address the problem of figuring out who to
ping for review.
If you've used it, what was your experience? Do you think it would be
helpful for Spark?
Nick
Some questions about this DAG visualization:
[image: Screen Shot 2016-11-17 at 11.57.14 AM.png]
1. What's the meaning of the green dot?
2. Should this be documented anywhere (if it isn't already)? Preferably a
tooltip or something directly in the UI would explain the significance.
Nick
I'm also curious about this. Is there something we can do to help
troubleshoot these leaks and file useful bug reports?
Same here. Nice to be able to deprecate most of the docs living on the wiki
and refer to them on GitHub.
matter how useless in practice this shouldn't go to another major release.
I agree that that issue is a major one since it relates to correctness, but
since it's not a regression it technically does not merit a -1 vote on the
release.
Nick
I don't think it makes sense to deprecate or drop support for Python 2.7
until at least 2020, when 2.7 itself will be EOLed. (As of Spark 2.0,
Python 2.6 support is deprecated and will be removed by Spark 2.2. Python
2.7 is only version of Python 2 that's still fully supported.)
Given the widespread industry use of Python 2.7, and the fact that it is
supported upstream by the Python core developers until 2020, I don't see
why Spark should even consider dropping support for it before then. There
is, of course, additional ongoing work to support Python 2.7, but it seems
more than justified by its level of use and popularity in the broader
community. And I say that as someone who almost exclusively develops in
Python 3.5+ these days.
Perhaps by 2018 the industry usage of Python 2 will drop precipitously and
merit a discussion about dropping support, but I think at this point it's
premature to discuss that and we should just wait and see.
Nick
The tagline on http://spark.apache.org/ says: "Apache Spark has an advanced
DAG execution engine that supports cyclic data flow and in-memory
computing."
Isn't that supposed to be "acyclic" rather than "cyclic"?
What does it mean to support cyclic data flow anyway?
Nick
Aye aye, cap'n. PRrrrrrrrr incoming.
I don't think this is the right place for questions about Databricks. I'm
pretty sure they have their own website with a forum for questions about
their product.
Maybe this? https://forums.databricks.com/

+1 This is a bit aside, but are we also getting jenkins machine in the apache domain? Tom On Friday, February 7, 2014 1:54 AM, Kostas Sakellis  wrote: +1 On Thursday, February 6, 2014, Sandy Ryza  wrote: I assume we will have an rc10 to fix the issues Matei found? Tom On Sunday, May 18, 2014 9:08 PM, Patrick Wendell  wrote: Hey Matei - the issue you found is not related to security. This patch a few days ago broke builds for Hadoop 1 with YARN support enabled. The patch directly altered the way we deal with commons-lang dependency, which is what is at the base of this stack trace. https://github.com/apache/spark/pull/754 - Patrick On Sun, May 18, 2014 at 5:28 PM, Matei Zaharia  wrote: +1. Ran some Spark on yarn jobs on a hadoop 2.4 cluster with authentication on. Tom On Friday, July 4, 2014 2:39 PM, Patrick Wendell  wrote: Please vote on releasing the following candidate as Apache Spark version 1.0.1! The tag to be voted on is v1.0.1-rc1 (commit 7d1043c): https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=7d1043c99303b87aef8ee19873629c2bfba4cc78 The release files, including signatures, digests, etc. can be found at: http://people.apache.org/~pwendell/spark-1.0.1-rc2/ Release artifacts are signed with the following key: https://people.apache.org/keys/committer/pwendell.asc The staging repository for this release can be found at: https://repository.apache.org/content/repositories/orgapachespark-1021/ The documentation corresponding to this release can be found at: http://people.apache.org/~pwendell/spark-1.0.1-rc2-docs/ Please vote on releasing this package as Apache Spark 1.0.1! The vote is open until Monday, July 07, at 20:45 UTC and passes if a majority of at least 3 +1 PMC votes are cast. [ ] +1 Release this package as Apache Spark 1.0.1 [ ] -1 Do not release this package because ... To learn more about Apache Spark, please see http://spark.apache.org/ === Differences from RC1 === This release includes only one "blocking" patch from rc1: https://github.com/apache/spark/pull/1255 There are also smaller fixes which came in over the last week. === About this release === This release fixes a few high-priority bugs in 1.0 and has a variety of smaller fixes. The full list is here: http://s.apache.org/b45. Some of the more visible patches are: SPARK-2043: ExternalAppendOnlyMap doesn't always find matching keys SPARK-2156 and SPARK-1112: Issues with jobs hanging due to akka frame size. SPARK-1790: Support r3 instance types on EC2. This is the first maintenance release on the 1.0 line. We plan to make additional maintenance releases as new fixes come in. +1. Ran spark on yarn on hadoop 0.23 and 2.x. Tom On Wednesday, September 3, 2014 2:25 AM, Patrick Wendell  wrote: Please vote on releasing the following candidate as Apache Spark version 1.1.0! The tag to be voted on is v1.1.0-rc4 (commit 2f9b2bd): https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=2f9b2bd7844ee8393dc9c319f4fefedf95f5e460 The release files, including signatures, digests, etc. can be found at: http://people.apache.org/~pwendell/spark-1.1.0-rc4/ Release artifacts are signed with the following key: https://people.apache.org/keys/committer/pwendell.asc The staging repository for this release can be found at: https://repository.apache.org/content/repositories/orgapachespark-1031/ The documentation corresponding to this release can be found at: http://people.apache.org/~pwendell/spark-1.1.0-rc4-docs/ Please vote on releasing this package as Apache Spark 1.1.0! The vote is open until Saturday, September 06, at 08:30 UTC and passes if a majority of at least 3 +1 PMC votes are cast. [ ] +1 Release this package as Apache Spark 1.1.0 [ ] -1 Do not release this package because ... To learn more about Apache Spark, please see http://spark.apache.org/ == Regressions fixed since RC3 == SPARK-3332 - Issue with tagging in EC2 scripts SPARK-3358 - Issue with regression for m3.XX instances == What justifies a -1 vote for this release? == This vote is happening very late into the QA period compared with previous votes, so -1 votes should only occur for significant regressions from 1.0.2. Bugs already present in 1.0.X will not block this release. == What default changes should I be aware of? == 1. The default value of "spark.io.compression.codec" is now "snappy"--> Old behavior can be restored by switching to "lzf"2. PySpark now performs external spilling during aggregations. --> Old behavior can be restored by setting "spark.shuffle.spill" to "false". 3. PySpark uses a new heuristic for determining the parallelism of shuffle operations. --> Old behavior can be restored by setting "spark.default.parallelism" to the number of cores in the cluster. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org Spark authentication does work in standalone mode (atleast it did, I haven't tested it in a while). The same shared secret has to be set on all the daemons (master and workers) and then also in the configs of any applications submitted.  Since everyone shares the same secret its by no means ideal or a strong authentication. Tom Any other comments or objections on this? Thanks,Tom On Tuesday, September 9, 2014 4:39 PM, Chester Chen  wrote: We were using it until recently, we are talking to our customers and see if we can get off it. Chester Alpine Data Labs On Tue, Sep 9, 2014 at 10:59 AM, Sean Owen  wrote: +1 tested on yarn. Tom On Friday, November 28, 2014 11:18 PM, Patrick Wendell  wrote: Please vote on releasing the following candidate as Apache Spark version 1.2.0! The tag to be voted on is v1.2.0-rc1 (commit 1056e9ec1): https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=1056e9ec13203d0c51564265e94d77a054498fdb The release files, including signatures, digests, etc. can be found at: http://people.apache.org/~pwendell/spark-1.2.0-rc1/ Release artifacts are signed with the following key: https://people.apache.org/keys/committer/pwendell.asc The staging repository for this release can be found at: https://repository.apache.org/content/repositories/orgapachespark-1048/ The documentation corresponding to this release can be found at: http://people.apache.org/~pwendell/spark-1.2.0-rc1-docs/ Please vote on releasing this package as Apache Spark 1.2.0! The vote is open until Tuesday, December 02, at 05:15 UTC and passes if a majority of at least 3 +1 PMC votes are cast. [ ] +1 Release this package as Apache Spark 1.1.0 [ ] -1 Do not release this package because ... To learn more about Apache Spark, please see http://spark.apache.org/ == What justifies a -1 vote for this release? == This vote is happening very late into the QA period compared with previous votes, so -1 votes should only occur for significant regressions from 1.0.2. Bugs already present in 1.1.X, minor regressions, or bugs related to new features will not block this release. == What default changes should I be aware of? == 1. The default value of "spark.shuffle.blockTransferService" has been changed to "netty"--> Old behavior can be restored by switching to "nio"2. The default value of "spark.shuffle.manager" has been changed to "sort". --> Old behavior can be restored by setting "spark.shuffle.manager" to "hash". == Other notes == Because this vote is occurring over a weekend, I will likely extend the vote if this RC survives until the end of the vote period. - Patrick --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org +1. Built from source and ran Spark on yarn on hadoop 2.6 in cluster and client mode. Tom On Thursday, March 5, 2015 8:53 PM, Patrick Wendell  wrote: Please vote on releasing the following candidate as Apache Spark version 1.3.0! The tag to be voted on is v1.3.0-rc2 (commit 4aaf48d4): https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=4aaf48d46d13129f0f9bdafd771dd80fe568a7dc The release files, including signatures, digests, etc. can be found at: http://people.apache.org/~pwendell/spark-1.3.0-rc3/ Release artifacts are signed with the following key: https://people.apache.org/keys/committer/pwendell.asc Staging repositories for this release can be found at: https://repository.apache.org/content/repositories/orgapachespark-1078 The documentation corresponding to this release can be found at: http://people.apache.org/~pwendell/spark-1.3.0-rc3-docs/ Please vote on releasing this package as Apache Spark 1.3.0! The vote is open until Monday, March 09, at 02:52 UTC and passes if a majority of at least 3 +1 PMC votes are cast. [ ] +1 Release this package as Apache Spark 1.3.0 [ ] -1 Do not release this package because ... To learn more about Apache Spark, please see http://spark.apache.org/ == How does this compare to RC2 == This release includes the following bug fixes: https://issues.apache.org/jira/browse/SPARK-6144 https://issues.apache.org/jira/browse/SPARK-6171 https://issues.apache.org/jira/browse/SPARK-5143 https://issues.apache.org/jira/browse/SPARK-6182 https://issues.apache.org/jira/browse/SPARK-6175 == How can I help test this release? == If you are a Spark user, you can help us test this release by taking a Spark 1.2 workload and running on this release candidate, then reporting any regressions. If you are happy with this release based on your own testing, give a +1 vote. == What justifies a -1 vote for this release? == This vote is happening towards the end of the 1.3 QA period, so -1 votes should only occur for significant regressions from 1.2.1. Bugs already present in 1.2.X, minor regressions, or bugs related to new features will not block this release. --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org +1. Tested spark on yarn against hadoop 2.6. Tom On Wednesday, April 8, 2015 6:15 AM, Sean Owen  wrote: Still a +1 from me; same result (except that now of course the UISeleniumSuite test does not fail) On Wed, Apr 8, 2015 at 1:46 AM, Patrick Wendell  wrote: --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org +1 tested on spark on yarn on hadoop 2.6 cluster with security. Tom On Sunday, April 5, 2015 6:25 PM, Patrick Wendell  wrote: Please vote on releasing the following candidate as Apache Spark version 1.2.2! The tag to be voted on is v1.2.2-rc1 (commit 7531b50): https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h=7531b50e406ee2e3301b009ceea7c684272b2e27 The list of fixes present in this release can be found at: http://bit.ly/1DCNddt The release files, including signatures, digests, etc. can be found at: http://people.apache.org/~pwendell/spark-1.2.2-rc1/ Release artifacts are signed with the following key: https://people.apache.org/keys/committer/pwendell.asc The staging repository for this release can be found at: https://repository.apache.org/content/repositories/orgapachespark-1082/ The documentation corresponding to this release can be found at: http://people.apache.org/~pwendell/spark-1.2.2-rc1-docs/ Please vote on releasing this package as Apache Spark 1.2.2! The vote is open until Thursday, April 08, at 00:30 UTC and passes if a majority of at least 3 +1 PMC votes are cast. [ ] +1 Release this package as Apache Spark 1.2.2 [ ] -1 Do not release this package because ... To learn more about Apache Spark, please see http://spark.apache.org/ --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org +1 Tom On Thursday, July 9, 2015 12:55 AM, Patrick Wendell  wrote: Please vote on releasing the following candidate as Apache Spark version 1.4.1! This release fixes a handful of known issues in Spark 1.4.0, listed here: http://s.apache.org/spark-1.4.1 The tag to be voted on is v1.4.1-rc4 (commit dbaa5c2): https://git-wip-us.apache.org/repos/asf?p=spark.git;a=commit;h= dbaa5c294eb565f84d7032e387e4b8c1a56e4cd2 The release files, including signatures, digests, etc. can be found at: http://people.apache.org/~pwendell/spark-releases/spark-1.4.1-rc4-bin/ Release artifacts are signed with the following key: https://people.apache.org/keys/committer/pwendell.asc The staging repository for this release can be found at: [published as version: 1.4.1] https://repository.apache.org/content/repositories/orgapachespark-1125/ [published as version: 1.4.1-rc4] https://repository.apache.org/content/repositories/orgapachespark-1126/ The documentation corresponding to this release can be found at: http://people.apache.org/~pwendell/spark-releases/spark-1.4.1-rc4-docs/ Please vote on releasing this package as Apache Spark 1.4.1! The vote is open until Sunday, July 12, at 06:55 UTC and passes if a majority of at least 3 +1 PMC votes are cast. [ ] +1 Release this package as Apache Spark 1.4.1 [ ] -1 Do not release this package because ... To learn more about Apache Spark, please see http://spark.apache.org/ --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org +1. Tested Spark on Yarn on Hadoop 2.6 and 2.7. Tom On Thursday, September 24, 2015 2:34 AM, Reynold Xin  wrote: Please vote on releasing the following candidate as Apache Spark version 1.5.1. The vote is open until Sun, Sep 27, 2015 at 10:00 UTC and passes if a majority of at least 3 +1 PMC votes are cast. [ ] +1 Release this package as Apache Spark 1.5.1[ ] -1 Do not release this package because ... The release fixes 81 known issues in Spark 1.5.0, listed here:http://s.apache.org/spark-1.5.1 The tag to be voted on is v1.5.1-rc1:https://github.com/apache/spark/commit/4df97937dbf68a9868de58408b9be0bf87dbbb94 The release files, including signatures, digests, etc. can be found at:http://people.apache.org/~pwendell/spark-releases/spark-1.5.1-rc1-bin/ Release artifacts are signed with the following key:https://people.apache.org/keys/committer/pwendell.asc The staging repository for this release (1.5.1) can be found at:https://repository.apache.org/content/repositories/orgapachespark-1148/ The documentation corresponding to this release can be found at:http://people.apache.org/~pwendell/spark-releases/spark-1.5.1-rc1-docs/ =======================================How can I help test this release?=======================================If you are a Spark user, you can help us test this release by taking an existing Spark workload and running on this release candidate, then reporting any regressions. ================================================What justifies a -1 vote for this release?================================================-1 vote should occur for regressions from Spark 1.5.0. Bugs already present in 1.5.0 will not block this release. ===============================================================What should happen to JIRA tickets still targeting 1.5.1?===============================================================Please target 1.5.2 or 1.6.0. +1 (binding) Tom On Thursday, May 19, 2016 10:35 AM, Matei Zaharia  wrote: Hi folks, Around 1.5 years ago, Spark added a maintainer process for reviewing API and architectural changes (https://cwiki.apache.org/confluence/display/SPARK/Committers#Committers-ReviewProcessandMaintainers) to make sure these are seen by people who spent a lot of time on that component. At the time, the worry was that changes might go unnoticed as the project grows, but there were also concerns that this approach makes the project harder to contribute to and less welcoming. Since implementing the model, I think that a good number of developers concluded it doesn't make a huge difference, so because of these concerns, it may be useful to remove it. I've also heard that we should try to keep some other instructions for contributors to find the "right" reviewers, so it would be great to see suggestions on that. For my part, I'd personally prefer something "automatic", such as easily tracking who reviewed each patch and having people look at the commit history of the module they want to work on, instead of a list that needs to be maintained separately. Matei --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org +1 (binding) Tom On Sunday, May 22, 2016 7:34 PM, Matei Zaharia  wrote: It looks like the discussion thread on this has only had positive replies, so I'm going to call a VOTE. The proposal is to remove the maintainer process in https://cwiki.apache.org/confluence/display/SPARK/Committers#Committers-ReviewProcessandMaintainers  given that it doesn't seem to have had a huge impact on the project, and it can unnecessarily create friction in contributing. We already have +1s from Mridul, Tom, Andrew Or and Imran on that thread. I'll leave the VOTE open for 48 hours, until 9 PM EST on May 24, 2016. Matei --------------------------------------------------------------------- To unsubscribe, e-mail: dev-unsubscribe@spark.apache.org For additional commands, e-mail: dev-help@spark.apache.org +1 Tom On Wednesday, June 15, 2016 2:01 PM, Reynold Xin  wrote: It's been a while and we have accumulated quite a few bug fixes in branch-1.6. I'm thinking about cutting 1.6.2 rc this week. Any patches somebody want to get in last minute? On a related note, I'm thinking about cutting 2.0.0 rc this week too. I looked at the 60 unresolved tickets and almost all of them look like they can be retargeted are are just some doc updates. I'm going to be more aggressive and pushing individual people about resolving those, in case this drags on forever. +1 to 4 months. Tom On Tuesday, September 27, 2016 2:07 PM, Reynold Xin  wrote: We are 2 months past releasing Spark 2.0.0, an important milestone for the project. Spark 2.0.0 deviated (took 6 month from the regular release cadence we had for the 1.x line, and we never explicitly discussed what the release cadence should look like for 2.x. Thus this email. During Spark 1.x, roughly every three months we make a new 1.x feature release (e.g. 1.5.0 comes out three months after 1.4.0). Development happened primarily in the first two months, and then a release branch was cut at the end of month 2, and the last month was reserved for QA and release preparation. During 2.0.0 development, I really enjoyed the longer release cycle because there was a lot of major changes happening and the longer time was critical for thinking through architectural changes as well as API design. While I don't expect the same degree of drastic changes in a 2.x feature release, I do think it'd make sense to increase the length of release cycle so we can make better designs. My strawman proposal is to maintain a regular release cadence, as we did in Spark 1.x, and increase the cycle from 3 months to 4 months. This effectively gives us ~50% more time to develop (in reality it'd be slightly less than 50% since longer dev time also means longer QA time). As for maintenance releases, I think those should still be cut on-demand, similar to Spark 1.x, but more aggressively. To put this into perspective, 4-month cycle means we will release Spark 2.1.0 at the end of Nov or early Dec (and branch cut / code freeze at the end of Oct). I am curious what others think.